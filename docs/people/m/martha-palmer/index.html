<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Martha Palmer - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Martha</span> <span class=font-weight-bold>Palmer</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-demo.19.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-demo--19 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-demo.19 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-demo.19/>A Graphical Interface for Curating Schemas</a></strong><br><a href=/people/p/piyush-mishra/>Piyush Mishra</a>
|
<a href=/people/a/akanksha-malhotra/>Akanksha Malhotra</a>
|
<a href=/people/s/susan-windisch-brown/>Susan Windisch Brown</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a>
|
<a href=/people/g/ghazaleh-kazeminejad/>Ghazaleh Kazeminejad</a><br><a href=/volumes/2021.acl-demo/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-demo--19><div class="card-body p-3 small">Much past work has focused on extracting information like <a href=https://en.wikipedia.org/wiki/Event_(philosophy)>events</a>, <a href=https://en.wikipedia.org/wiki/Legal_person>entities</a>, and <a href=https://en.wikipedia.org/wiki/Interpersonal_relationship>relations</a> from <a href=https://en.wikipedia.org/wiki/Document>documents</a>. Very little work has focused on analyzing these results for better <a href=https://en.wikipedia.org/wiki/Mathematical_model>model understanding</a>. In this paper, we introduce a curation interface that takes an Information Extraction (IE) system&#8217;s output in a pre-defined format and generates a graphical representation of its elements. The <a href=https://en.wikipedia.org/wiki/User_interface>interface</a> supports editing while curating schemas for complex events like Improvised Explosive Device (IED) based scenarios. We identify various schemas that either have linear event chains or contain parallel events with complicated temporal ordering. We iteratively update an induced schema to uniquely identify events specific to it, add optional events around them, and prune unnecessary events. The resulting schemas are improved and enriched versions of the machine-induced versions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dash-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dash-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dash-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.dash-1.14" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.dash-1.14/>TopGuNN : Fast NLP Training Data Augmentation using Large Corpora<span class=acl-fixed-case>T</span>op<span class=acl-fixed-case>G</span>u<span class=acl-fixed-case>NN</span>: Fast <span class=acl-fixed-case>NLP</span> Training Data Augmentation using Large Corpora</a></strong><br><a href=/people/r/rebecca-iglesias-flores/>Rebecca Iglesias-Flores</a>
|
<a href=/people/m/megha-mishra/>Megha Mishra</a>
|
<a href=/people/a/ajay-patel/>Ajay Patel</a>
|
<a href=/people/a/akanksha-malhotra/>Akanksha Malhotra</a>
|
<a href=/people/r/reno-kriz/>Reno Kriz</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a>
|
<a href=/people/c/chris-callison-burch/>Chris Callison-Burch</a><br><a href=/volumes/2021.dash-1/ class=text-muted>Proceedings of the Second Workshop on Data Science with Human in the Loop: Language Advances</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dash-1--14><div class="card-body p-3 small">Acquiring training data for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing systems</a> can be expensive and time-consuming. Given a few training examples crafted by experts, large corpora can be mined for thousands of semantically similar examples that provide useful variability to improve model generalization. We present TopGuNN, a fast contextualized k-NN retrieval system that can efficiently index and search over contextual embeddings generated from large corpora. TopGuNN is demonstrated for a training data augmentation use case over the Gigaword corpus. Using approximate k-NN and an efficient <a href=https://en.wikipedia.org/wiki/Computer_architecture>architecture</a>, TopGuNN performs queries over an <a href=https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms>embedding space</a> of 4.63 TB (approximately 1.5B embeddings) in less than a day.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-demos.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-demos--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-demos.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-demos.16" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-demos.16/>RESIN : A Dockerized Schema-Guided Cross-document Cross-lingual Cross-media Information Extraction and Event Tracking System<span class=acl-fixed-case>RESIN</span>: A Dockerized Schema-Guided Cross-document Cross-lingual Cross-media Information Extraction and Event Tracking System</a></strong><br><a href=/people/h/haoyang-wen/>Haoyang Wen</a>
|
<a href=/people/y/ying-lin/>Ying Lin</a>
|
<a href=/people/t/tuan-lai/>Tuan Lai</a>
|
<a href=/people/x/xiaoman-pan/>Xiaoman Pan</a>
|
<a href=/people/s/sha-li/>Sha Li</a>
|
<a href=/people/x/xudong-lin/>Xudong Lin</a>
|
<a href=/people/b/ben-zhou/>Ben Zhou</a>
|
<a href=/people/m/manling-li/>Manling Li</a>
|
<a href=/people/h/haoyu-wang/>Haoyu Wang</a>
|
<a href=/people/h/hongming-zhang/>Hongming Zhang</a>
|
<a href=/people/x/xiaodong-yu/>Xiaodong Yu</a>
|
<a href=/people/a/alexander-dong/>Alexander Dong</a>
|
<a href=/people/z/zhenhailong-wang/>Zhenhailong Wang</a>
|
<a href=/people/y/yi-fung/>Yi Fung</a>
|
<a href=/people/p/piyush-mishra/>Piyush Mishra</a>
|
<a href=/people/q/qing-lyu/>Qing Lyu</a>
|
<a href=/people/d/didac-suris/>Dídac Surís</a>
|
<a href=/people/b/brian-chen/>Brian Chen</a>
|
<a href=/people/s/susan-windisch-brown/>Susan Windisch Brown</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a>
|
<a href=/people/c/chris-callison-burch/>Chris Callison-Burch</a>
|
<a href=/people/c/carl-vondrick/>Carl Vondrick</a>
|
<a href=/people/j/jiawei-han/>Jiawei Han</a>
|
<a href=/people/d/dan-roth/>Dan Roth</a>
|
<a href=/people/s/shih-fu-chang/>Shih-Fu Chang</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a><br><a href=/volumes/2021.naacl-demos/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-demos--16><div class="card-body p-3 small">We present a new information extraction system that can automatically construct temporal event graphs from a collection of news documents from multiple sources, multiple languages (English and Spanish for our experiment), and multiple data modalities (speech, text, image and video). The system advances state-of-the-art from two aspects : (1) extending from sentence-level event extraction to cross-document cross-lingual cross-media event extraction, coreference resolution and temporal event tracking ; (2) using human curated event schema library to match and enhance the extraction output. We have made the dockerlized system publicly available for research purpose at GitHub, with a demo video.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.744.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--744 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.744 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929153 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.744" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.744/>Structured Tuning for Semantic Role Labeling</a></strong><br><a href=/people/t/tao-li/>Tao Li</a>
|
<a href=/people/p/parth-anand-jawale/>Parth Anand Jawale</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a>
|
<a href=/people/v/vivek-srikumar/>Vivek Srikumar</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--744><div class="card-body p-3 small">Recent neural network-driven semantic role labeling (SRL) systems have shown impressive improvements in F1 scores. These improvements are due to expressive input representations, which, at least at the surface, are orthogonal to knowledge-rich constrained decoding mechanisms that helped linear SRL models. Introducing the benefits of <a href=https://en.wikipedia.org/wiki/Mathematical_structure>structure</a> to inform neural models presents a methodological challenge. In this paper, we present a structured tuning framework to improve <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> using softened constraints only at training time. Our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> leverages the expressiveness of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> and provides <a href=https://en.wikipedia.org/wiki/Supervisor>supervision</a> with structured loss components. We start with a strong <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> (RoBERTa) to validate the impact of our approach, and show that our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> outperforms the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> by learning to comply with declarative constraints. Additionally, our experiments with smaller training sizes show that we can achieve consistent improvements under low-resource scenarios.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.dmr-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.dmr-1.0/>Proceedings of the Second International Workshop on Designing Meaning Representations</a></strong><br><a href=/people/n/nianwen-xue/>Nianwen Xue</a>
|
<a href=/people/j/johan-bos/>Johan Bos</a>
|
<a href=/people/w/william-croft/>William Croft</a>
|
<a href=/people/j/jan-hajic/>Jan Hajič</a>
|
<a href=/people/c/chu-ren-huang/>Chu-Ren Huang</a>
|
<a href=/people/s/stephan-oepen/>Stephan Oepen</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a>
|
<a href=/people/j/james-pustejovsky/>James Pustejovsky</a><br><a href=/volumes/2020.dmr-1/ class=text-muted>Proceedings of the Second International Workshop on Designing Meaning Representations</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.louhi-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--louhi-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.louhi-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38940047 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.louhi-1.12/>Defining and Learning Refined Temporal Relations in the Clinical Narrative</a></strong><br><a href=/people/k/kristin-wright-bettner/>Kristin Wright-Bettner</a>
|
<a href=/people/c/chen-lin/>Chen Lin</a>
|
<a href=/people/t/timothy-miller/>Timothy Miller</a>
|
<a href=/people/s/steven-bethard/>Steven Bethard</a>
|
<a href=/people/d/dmitriy-dligach/>Dmitriy Dligach</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a>
|
<a href=/people/j/james-h-martin/>James H. Martin</a>
|
<a href=/people/g/guergana-savova/>Guergana Savova</a><br><a href=/volumes/2020.louhi-1/ class=text-muted>Proceedings of the 11th International Workshop on Health Text Mining and Information Analysis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--louhi-1--12><div class="card-body p-3 small">We present refinements over existing temporal relation annotations in the Electronic Medical Record clinical narrative. We refined the THYME corpus annotations to more faithfully represent nuanced temporality and nuanced temporal-coreferential relations. The main contributions are in re-defining CONTAINS and OVERLAP relations into CONTAINS, CONTAINS-SUBEVENT, OVERLAP and NOTED-ON. We demonstrate that these refinements lead to substantial gains in learnability for state-of-the-art transformer models as compared to previously reported results on the original THYME corpus. We thus establish a baseline for the automatic extraction of these refined temporal relations. Although our study is done on clinical narrative, we believe it addresses far-reaching challenges that are corpus- and domain- agnostic.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3300.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3300/>Proceedings of the First International Workshop on Designing Meaning Representations</a></strong><br><a href=/people/n/nianwen-xue/>Nianwen Xue</a>
|
<a href=/people/w/william-croft/>William Croft</a>
|
<a href=/people/j/jan-hajic/>Jan Hajic</a>
|
<a href=/people/c/chu-ren-huang/>Chu-Ren Huang</a>
|
<a href=/people/s/stephan-oepen/>Stephan Oepen</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a>
|
<a href=/people/j/james-pustejovksy/>James Pustejovksy</a><br><a href=/volumes/W19-33/ class=text-muted>Proceedings of the First International Workshop on Designing Meaning Representations</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3318.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3318 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3318 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3318/>VerbNet Representations : Subevent Semantics for Transfer Verbs<span class=acl-fixed-case>V</span>erb<span class=acl-fixed-case>N</span>et Representations: Subevent Semantics for Transfer Verbs</a></strong><br><a href=/people/s/susan-windisch-brown/>Susan Windisch Brown</a>
|
<a href=/people/j/julia-bonn/>Julia Bonn</a>
|
<a href=/people/j/james-gung/>James Gung</a>
|
<a href=/people/a/annie-zaenen/>Annie Zaenen</a>
|
<a href=/people/j/james-pustejovsky/>James Pustejovsky</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a><br><a href=/volumes/W19-33/ class=text-muted>Proceedings of the First International Workshop on Designing Meaning Representations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3318><div class="card-body p-3 small">This paper announces the release of a new version of the English lexical resource VerbNet with substantially revised semantic representations designed to facilitate computer planning and reasoning based on human language. We use the transfer of possession and transfer of information event representations to illustrate both the general framework of the <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a> and the types of nuances the new <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a> can capture. These representations use a Generative Lexicon-inspired subevent structure to track attributes of event participants across time, highlighting oppositions and temporal and causal relations among the subevents.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4016.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4016 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4016 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-4016" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-4016/>Explaining Simple Natural Language Inference</a></strong><br><a href=/people/a/aikaterini-lida-kalouli/>Aikaterini-Lida Kalouli</a>
|
<a href=/people/a/annebeth-buis/>Annebeth Buis</a>
|
<a href=/people/l/livy-real/>Livy Real</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a>
|
<a href=/people/v/valeria-de-paiva/>Valeria de Paiva</a><br><a href=/volumes/W19-40/ class=text-muted>Proceedings of the 13th Linguistic Annotation Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4016><div class="card-body p-3 small">The vast amount of research introducing new <a href=https://en.wikipedia.org/wiki/Corpus_linguistics>corpora</a> and techniques for semi-automatically annotating corpora shows the important role that <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> play in today&#8217;s research, especially in the <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning community</a>. This rapid development raises concerns about the quality of the datasets created and consequently of the <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained, as recently discussed with respect to the Natural Language Inference (NLI) task. In this work we conduct an annotation experiment based on a small subset of the SICK corpus. The experiment reveals several problems in the annotation guidelines, and various challenges of the NLI task itself. Our quantitative evaluation of the experiment allows us to assign our empirical observations to specific linguistic phenomena and leads us to recommendations for future annotation tasks, for NLI and possibly for other tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K19-1034.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K19-1034 data-toggle=collapse aria-expanded=false aria-controls=abstract-K19-1034 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K19-1034/>Linguistic Analysis Improves Neural Metaphor Detection</a></strong><br><a href=/people/k/kevin-stowe/>Kevin Stowe</a>
|
<a href=/people/s/sarah-moeller/>Sarah Moeller</a>
|
<a href=/people/l/laura-michaelis/>Laura Michaelis</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a><br><a href=/volumes/K19-1/ class=text-muted>Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K19-1034><div class="card-body p-3 small">In the field of metaphor detection, <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning systems</a> are the ubiquitous and achieve strong performance on many tasks. However, due to the complicated procedures for manually identifying metaphors, the datasets available are relatively small and fraught with complications. We show that using syntactic features and lexical resources can automatically provide additional high-quality training data for metaphoric language, and this <a href=https://en.wikipedia.org/wiki/Data>data</a> can cover gaps and inconsistencies in metaphor annotation, improving state-of-the-art word-level metaphor identification. This novel application of automatically improving training data improves <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> across numerous tasks, and reconfirms the necessity of high-quality data for deep learning frameworks.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1224.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1224 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1224 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/C18-1224/>Automatically Extracting Qualia Relations for the Rich Event Ontology</a></strong><br><a href=/people/g/ghazaleh-kazeminejad/>Ghazaleh Kazeminejad</a>
|
<a href=/people/c/claire-bonial/>Claire Bonial</a>
|
<a href=/people/s/susan-windisch-brown/>Susan Windisch Brown</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1224><div class="card-body p-3 small">Commonsense, real-world knowledge about the events that entities or things in the world are typically involved in, as well as part-whole relationships, is valuable for allowing computational systems to draw everyday inferences about the world. Here, we focus on automatically extracting information about (1) the events that typically bring about certain entities (origins), (2) the <a href=https://en.wikipedia.org/wiki/Event_(probability_theory)>events</a> that are the typical functions of entities, and (3) part-whole relationships in entities. These correspond to the agentive, telic and constitutive qualia central to the Generative Lexicon. We describe our motivations and methods for extracting these qualia relations from the Suggested Upper Merged Ontology (SUMO) and show that human annotators overwhelmingly find the information extracted to be reasonable. Because <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontologies</a> provide a way of structuring this information and making it accessible to agents and computational systems generally, efforts are underway to incorporate the extracted information to an ontology hub of Natural Language Processing semantic role labeling resources, the Rich Event Ontology.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1313.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1313 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1313 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/C18-1313/>AMR Beyond the Sentence : the Multi-sentence AMR corpus<span class=acl-fixed-case>AMR</span> Beyond the Sentence: the Multi-sentence <span class=acl-fixed-case>AMR</span> corpus</a></strong><br><a href=/people/t/tim-ogorman/>Tim O’Gorman</a>
|
<a href=/people/m/michael-regan/>Michael Regan</a>
|
<a href=/people/k/kira-griffitt/>Kira Griffitt</a>
|
<a href=/people/u/ulf-hermjakob/>Ulf Hermjakob</a>
|
<a href=/people/k/kevin-knight/>Kevin Knight</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1313><div class="card-body p-3 small">There are few <a href=https://en.wikipedia.org/wiki/Text_corpus>corpora</a> that endeavor to represent the semantic content of entire documents. We present a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> that accomplishes one way of capturing document level semantics, by annotating <a href=https://en.wikipedia.org/wiki/Coreference>coreference</a> and similar phenomena (bridging and implicit roles) on top of gold Abstract Meaning Representations of sentence-level semantics. We present a new <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> of this <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a>, with analysis of its quality, alongside a plausible baseline for comparison. It is hoped that this Multi-Sentence AMR corpus (MS-AMR) may become a feasible method for developing rich representations of document meaning, useful for tasks such as <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction</a> and <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-4300.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-4300/>Proceedings of the Workshop Events and Stories in the News 2018</a></strong><br><a href=/people/t/tommaso-caselli/>Tommaso Caselli</a>
|
<a href=/people/b/ben-miller/>Ben Miller</a>
|
<a href=/people/m/marieke-van-erp/>Marieke van Erp</a>
|
<a href=/people/p/piek-vossen/>Piek Vossen</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a>
|
<a href=/people/t/teruko-mitamura/>Teruko Mitamura</a>
|
<a href=/people/d/david-caswell/>David Caswell</a>
|
<a href=/people/s/susan-windisch-brown/>Susan W. Brown</a>
|
<a href=/people/c/claire-bonial/>Claire Bonial</a><br><a href=/volumes/W18-43/ class=text-muted>Proceedings of the Workshop Events and Stories in the News 2018</a></span></p><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2700.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2700/>Proceedings of the Events and Stories in the News Workshop</a></strong><br><a href=/people/t/tommaso-caselli/>Tommaso Caselli</a>
|
<a href=/people/b/ben-miller/>Ben Miller</a>
|
<a href=/people/m/marieke-van-erp/>Marieke van Erp</a>
|
<a href=/people/p/piek-vossen/>Piek Vossen</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a>
|
<a href=/people/t/teruko-mitamura/>Teruko Mitamura</a>
|
<a href=/people/d/david-caswell/>David Caswell</a><br><a href=/volumes/W17-27/ class=text-muted>Proceedings of the Events and Stories in the News Workshop</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2712.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2712 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2712 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2712/>The Rich Event Ontology</a></strong><br><a href=/people/s/susan-windisch-brown/>Susan Brown</a>
|
<a href=/people/c/claire-bonial/>Claire Bonial</a>
|
<a href=/people/l/leo-obrst/>Leo Obrst</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a><br><a href=/volumes/W17-27/ class=text-muted>Proceedings of the Events and Stories in the News Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2712><div class="card-body p-3 small">In this paper we describe a new lexical semantic resource, The Rich Event On-tology, which provides an independent conceptual backbone to unify existing semantic role labeling (SRL) schemas and augment them with event-to-event causal and temporal relations. By unifying the FrameNet, VerbNet, Automatic Content Extraction, and Rich Entities, Relations and Events resources, the ontology serves as a shared hub for the disparate annotation schemas and therefore enables the combination of SRL training data into a larger, more diverse corpus. By adding temporal and causal relational information not found in any of the independent resources, the <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontology</a> facilitates reasoning on and across documents, revealing relationships between events that come together in temporal and causal chains to build more complex scenarios. We envision the open resource serving as a valuable tool for both moving from the <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontology</a> to text to query for event types and scenarios of interest, and for moving from text to the <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontology</a> to access interpretations of events using the combined semantic information housed there.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-1000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D17-1000/>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></strong><br><a href=/people/m/martha-palmer/>Martha Palmer</a>
|
<a href=/people/r/rebecca-hwa/>Rebecca Hwa</a>
|
<a href=/people/s/sebastian-riedel/>Sebastian Riedel</a><br><a href=/volumes/D17-1/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-1053.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-1053 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-1053 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-1053/>Unsupervised AMR-Dependency Parse Alignment<span class=acl-fixed-case>AMR</span>-Dependency Parse Alignment</a></strong><br><a href=/people/w/wei-te-chen/>Wei-Te Chen</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a><br><a href=/volumes/E17-1/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-1053><div class="card-body p-3 small">In this paper, we introduce an Abstract Meaning Representation (AMR) to Dependency Parse aligner. Alignment is a preliminary step for AMR parsing, and our aligner improves current AMR parser performance. Our aligner involves several different features, including named entity tags and semantic role labels, and uses Expectation-Maximization training. Results show that our aligner reaches an 87.1 % F-Score score with the experimental data, and enhances AMR parsing.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Martha+Palmer" title="Search for 'Martha Palmer' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/s/susan-windisch-brown/ class=align-middle>Susan Windisch Brown</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/c/claire-bonial/ class=align-middle>Claire Bonial</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/g/ghazaleh-kazeminejad/ class=align-middle>Ghazaleh Kazeminejad</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/piyush-mishra/ class=align-middle>Piyush Mishra</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/akanksha-malhotra/ class=align-middle>Akanksha Malhotra</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/c/chris-callison-burch/ class=align-middle>Chris Callison-Burch</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/tommaso-caselli/ class=align-middle>Tommaso Caselli</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/ben-miller/ class=align-middle>Ben Miller</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/marieke-van-erp/ class=align-middle>Marieke van Erp</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/piek-vossen/ class=align-middle>Piek Vossen</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/e/eduard-hovy/ class=align-middle>Eduard Hovy</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/teruko-mitamura/ class=align-middle>Teruko Mitamura</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/david-caswell/ class=align-middle>David Caswell</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/n/nianwen-xue/ class=align-middle>Nianwen Xue</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/w/william-croft/ class=align-middle>William Croft</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/jan-hajic/ class=align-middle>Jan Hajic</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/c/chu-ren-huang/ class=align-middle>Chu-Ren Huang</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/stephan-oepen/ class=align-middle>Stephan Oepen</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/james-pustejovsky/ class=align-middle>James Pustejovsky</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/tim-ogorman/ class=align-middle>Tim O’Gorman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-regan/ class=align-middle>Michael Regan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kira-griffitt/ class=align-middle>Kira Griffitt</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/u/ulf-hermjakob/ class=align-middle>Ulf Hermjakob</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kevin-knight/ class=align-middle>Kevin Knight</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tao-li/ class=align-middle>Tao Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/parth-anand-jawale/ class=align-middle>Parth Anand Jawale</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vivek-srikumar/ class=align-middle>Vivek Srikumar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rebecca-iglesias-flores/ class=align-middle>Rebecca Iglesias-Flores</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/megha-mishra/ class=align-middle>Megha Mishra</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ajay-patel/ class=align-middle>Ajay Patel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/reno-kriz/ class=align-middle>Reno Kriz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/leo-obrst/ class=align-middle>Leo Obrst</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/johan-bos/ class=align-middle>Johan Bos</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kristin-wright-bettner/ class=align-middle>Kristin Wright-Bettner</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chen-lin/ class=align-middle>Chen Lin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/timothy-miller/ class=align-middle>Timothy Miller</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/steven-bethard/ class=align-middle>Steven Bethard</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dmitriy-dligach/ class=align-middle>Dmitriy Dligach</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/james-h-martin/ class=align-middle>James H. Martin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/guergana-savova/ class=align-middle>Guergana Savova</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rebecca-hwa/ class=align-middle>Rebecca Hwa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sebastian-riedel/ class=align-middle>Sebastian Riedel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haoyang-wen/ class=align-middle>Haoyang Wen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/ying-lin/ class=align-middle>Ying Lin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tuan-lai/ class=align-middle>Tuan Lai</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaoman-pan/ class=align-middle>Xiaoman Pan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sha-li/ class=align-middle>Sha Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xudong-lin/ class=align-middle>Xudong Lin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/ben-zhou/ class=align-middle>Ben Zhou</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/manling-li/ class=align-middle>Manling Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haoyu-wang/ class=align-middle>Haoyu Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hongming-zhang/ class=align-middle>Hongming Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiaodong-yu/ class=align-middle>Xiaodong Yu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexander-dong/ class=align-middle>Alexander Dong</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/z/zhenhailong-wang/ class=align-middle>Zhenhailong Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yi-fung/ class=align-middle>Yi Fung</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/q/qing-lyu/ class=align-middle>Qing Lyu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/didac-suris/ class=align-middle>Dídac Surís</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/brian-chen/ class=align-middle>Brian Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/carl-vondrick/ class=align-middle>Carl Vondrick</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jiawei-han/ class=align-middle>Jiawei Han</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dan-roth/ class=align-middle>Dan Roth</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shih-fu-chang/ class=align-middle>Shih-Fu Chang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/heng-ji/ class=align-middle>Heng Ji</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/james-pustejovksy/ class=align-middle>James Pustejovksy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/julia-bonn/ class=align-middle>Julia Bonn</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/james-gung/ class=align-middle>James Gung</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/annie-zaenen/ class=align-middle>Annie Zaenen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/aikaterini-lida-kalouli/ class=align-middle>Aikaterini-Lida Kalouli</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/annebeth-buis/ class=align-middle>Annebeth Buis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/livy-real/ class=align-middle>Livy Real</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/valeria-de-paiva/ class=align-middle>Valeria de Paiva</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wei-te-chen/ class=align-middle>Wei-Te Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kevin-stowe/ class=align-middle>Kevin Stowe</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sarah-moeller/ class=align-middle>Sarah Moeller</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/laura-michaelis/ class=align-middle>Laura Michaelis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/dash/ class=align-middle>DaSH</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/dmr/ class=align-middle>DMR</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/louhi/ class=align-middle>Louhi</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/conll/ class=align-middle>CoNLL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>