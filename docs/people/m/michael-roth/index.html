<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Michael Roth - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Michael</span> <span class=font-weight-bold>Roth</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.unimplicit-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.unimplicit-1.0/>Proceedings of the 1st Workshop on Understanding Implicit and Underspecified Language</a></strong><br><a href=/people/m/michael-roth/>Michael Roth</a>
|
<a href=/people/r/reut-tsarfaty/>Reut Tsarfaty</a>
|
<a href=/people/y/yoav-goldberg/>Yoav Goldberg</a><br><a href=/volumes/2021.unimplicit-1/ class=text-muted>Proceedings of the 1st Workshop on Understanding Implicit and Underspecified Language</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.unimplicit-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--unimplicit-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.unimplicit-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.unimplicit-1.4/>UnImplicit Shared Task Report : Detecting Clarification Requirements in Instructional Text<span class=acl-fixed-case>U</span>n<span class=acl-fixed-case>I</span>mplicit Shared Task Report: Detecting Clarification Requirements in Instructional Text</a></strong><br><a href=/people/m/michael-roth/>Michael Roth</a>
|
<a href=/people/t/talita-anthonio/>Talita Anthonio</a><br><a href=/volumes/2021.unimplicit-1/ class=text-muted>Proceedings of the 1st Workshop on Understanding Implicit and Underspecified Language</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--unimplicit-1--4><div class="card-body p-3 small">This paper describes the data, task setup, and results of the shared task at the First Workshop on Understanding Implicit and Underspecified Language (UnImplicit). The task requires <a href=https://en.wikipedia.org/wiki/Computational_model>computational models</a> to predict whether a sentence contains aspects of meaning that are contextually unspecified and thus require clarification. Two teams participated and the best <a href=https://en.wikipedia.org/wiki/Scoring_system>scoring system</a> achieved an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 68 %.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.675.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--675 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.675 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939007 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.675/>Towards Modeling Revision Requirements in wikiHow Instructions<span class=acl-fixed-case>H</span>ow Instructions</a></strong><br><a href=/people/i/irshad-bhat/>Irshad Bhat</a>
|
<a href=/people/t/talita-anthonio/>Talita Anthonio</a>
|
<a href=/people/m/michael-roth/>Michael Roth</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--675><div class="card-body p-3 small">wikiHow is a resource of how-to guidesthat describe the steps necessary to accomplish a goal. Guides in this resource are regularly edited by a community of users, who try to improve instructions in terms of style, clarity and correctness. In this work, we test whether the need for such <a href=https://en.wikipedia.org/wiki/Editing>edits</a> can be predicted automatically. For this <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>, we extend an existing <a href=https://en.wikipedia.org/wiki/Resource>resource</a> of textual edits with a complementary set of approx. 4 million sentences that remain unedited over time and report on the outcome of two revision modeling experiments.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.crac-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--crac-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.crac-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.crac-1.4/>Predicting Coreference in Abstract Meaning Representations<span class=acl-fixed-case>A</span>bstract <span class=acl-fixed-case>M</span>eaning <span class=acl-fixed-case>R</span>epresentations</a></strong><br><a href=/people/t/tatiana-anikina/>Tatiana Anikina</a>
|
<a href=/people/a/alexander-koller/>Alexander Koller</a>
|
<a href=/people/m/michael-roth/>Michael Roth</a><br><a href=/volumes/2020.crac-1/ class=text-muted>Proceedings of the Third Workshop on Computational Models of Reference, Anaphora and Coreference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--crac-1--4><div class="card-body p-3 small">This work addresses <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> in Abstract Meaning Representation (AMR) graphs, a popular formalism for <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a>. We evaluate several current coreference resolution techniques on a recently published AMR coreference corpus, establishing baselines for future work. We also demonstrate that <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> can improve the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of a state-of-the-art <a href=https://en.wikipedia.org/wiki/Semantic_parser>semantic parser</a> on this <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.117.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--117 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.117 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.117/>What Can We Learn from Noun Substitutions in Revision Histories?</a></strong><br><a href=/people/t/talita-anthonio/>Talita Anthonio</a>
|
<a href=/people/m/michael-roth/>Michael Roth</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--117><div class="card-body p-3 small">In community-edited resources such as <a href=https://en.wikipedia.org/wiki/WikiHow>wikiHow</a>, sentences are subject to revisions on a daily basis. Recent work has shown that resulting improvements over time can be modelled computationally, assuming that each revision contributes to the improvement. We take a closer look at a subset of such revisions, for which we attempt to improve a <a href=https://en.wikipedia.org/wiki/Computational_model>computational model</a> and validate in how far the assumption that &#8216;revised means better&#8217; actually holds. The subset of revisions considered here are noun substitutions, which often involve interesting semantic relations, including <a href=https://en.wikipedia.org/wiki/Synonym>synonymy</a>, <a href=https://en.wikipedia.org/wiki/Opposite_(semantics)>antonymy</a> and <a href=https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy>hypernymy</a>. Despite the high <a href=https://en.wikipedia.org/wiki/Semantic_similarity>semantic relatedness</a>, we find that a <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised classifier</a> can distinguish the revised version of a sentence from an original version with an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> close to 70 %, when taking context into account. In a human annotation study, we observe that annotators identify the revised sentence as the &#8216;better version&#8217; with similar performance. Our analysis reveals a fair agreement among annotators when a revision improves fluency. In contrast, noun substitutions that involve other lexical-semantic relationships are often perceived as being equally good or tend to cause disagreements. While these findings are also reflected in classification scores, a comparison of results shows that our model fails in cases where humans can resort to factual knowledge or intuitions about the required level of <a href=https://en.wikipedia.org/wiki/Sensitivity_and_specificity>specificity</a>.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-6000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-6000/>Proceedings of the First Workshop on Commonsense Inference in Natural Language Processing</a></strong><br><a href=/people/s/simon-ostermann/>Simon Ostermann</a>
|
<a href=/people/s/sheng-zhang/>Sheng Zhang</a>
|
<a href=/people/m/michael-roth/>Michael Roth</a>
|
<a href=/people/p/peter-clark/>Peter Clark</a><br><a href=/volumes/D19-60/ class=text-muted>Proceedings of the First Workshop on Commonsense Inference in Natural Language Processing</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S19-1012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S19-1012 data-toggle=collapse aria-expanded=false aria-controls=abstract-S19-1012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S19-1012/>MCScript2.0 : A Machine Comprehension Corpus Focused on Script Events and Participants<span class=acl-fixed-case>MCS</span>cript2.0: A Machine Comprehension Corpus Focused on Script Events and Participants</a></strong><br><a href=/people/s/simon-ostermann/>Simon Ostermann</a>
|
<a href=/people/m/michael-roth/>Michael Roth</a>
|
<a href=/people/m/manfred-pinkal/>Manfred Pinkal</a><br><a href=/volumes/S19-1/ class=text-muted>Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*SEM 2019)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S19-1012><div class="card-body p-3 small">We introduce MCScript2.0, a machine comprehension corpus for the end-to-end evaluation of <a href=https://en.wikipedia.org/wiki/Scripting_language>script knowledge</a>. MCScript2.0 contains approx. 20,000 questions on approx. 3,500 texts, crowdsourced based on a new collection process that results in challenging questions. Half of the questions can not be answered from the reading texts, but require the use of commonsense and, in particular, script knowledge. We give a thorough analysis of our <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> and show that while the task is not challenging to humans, existing machine comprehension models fail to perform well on the <a href=https://en.wikipedia.org/wiki/Data>data</a>, even if they make use of a commonsense knowledge base. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> is available at http://www.sfb1102. uni-saarland.de/?page_id=2582</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1390.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1390 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1390 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N19-1390/>Combining Discourse Markers and Cross-lingual Embeddings for SynonymAntonym Classification</a></strong><br><a href=/people/m/michael-roth/>Michael Roth</a>
|
<a href=/people/s/shyam-upadhyay/>Shyam Upadhyay</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1390><div class="card-body p-3 small">It is well-known that distributional semantic approaches have difficulty in distinguishing between <a href=https://en.wikipedia.org/wiki/Synonym>synonyms</a> and <a href=https://en.wikipedia.org/wiki/Opposite_(semantics)>antonyms</a> (Grefenstette, 1992 ; Pad and Lapata, 2003). Recent work has shown that supervision available in <a href=https://en.wikipedia.org/wiki/English_language>English</a> for this <a href=https://en.wikipedia.org/wiki/Task_force>task</a> (e.g., lexical resources) can be transferred to other languages via cross-lingual word embeddings. However, this kind of transfer misses monolingual distributional information available in a target language, such as <a href=https://en.wikipedia.org/wiki/Contrast_(linguistics)>contrast relations</a> that are indicative of <a href=https://en.wikipedia.org/wiki/Opposite_(semantics)>antonymy</a> (e.g. hot... while... cold). In this work, we improve the transfer by exploiting <a href=https://en.wikipedia.org/wiki/Monolingualism>monolingual information</a>, expressed in the form of co-occurrences with <a href=https://en.wikipedia.org/wiki/Discourse_marker>discourse markers</a> that convey contrast. Our approach makes use of less than a dozen <a href=https://en.wikipedia.org/wiki/Marker_(linguistics)>markers</a>, which can easily be obtained for many languages. Compared to a baseline using only cross-lingual embeddings, we show absolute improvements of 410 % F1-score in <a href=https://en.wikipedia.org/wiki/Vietnamese_language>Vietnamese</a> and <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a>.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1119.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1119 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1119 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1119/>SemEval-2018 Task 11 : <a href=https://en.wikipedia.org/wiki/Machine_learning>Machine Comprehension</a> Using Commonsense Knowledge<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 11: Machine Comprehension Using Commonsense Knowledge</a></strong><br><a href=/people/s/simon-ostermann/>Simon Ostermann</a>
|
<a href=/people/m/michael-roth/>Michael Roth</a>
|
<a href=/people/a/ashutosh-modi/>Ashutosh Modi</a>
|
<a href=/people/s/stefan-thater/>Stefan Thater</a>
|
<a href=/people/m/manfred-pinkal/>Manfred Pinkal</a><br><a href=/volumes/S18-1/ class=text-muted>Proceedings of The 12th International Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1119><div class="card-body p-3 small">This report summarizes the results of the SemEval 2018 task on <a href=https://en.wikipedia.org/wiki/Machine_learning>machine comprehension</a> using <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a>. For this machine comprehension task, we created a new <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>, MCScript. It contains a high number of questions that require <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a> for finding the correct answer. 11 teams from 4 different countries participated in this shared <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, most of them used neural approaches. The best performing <a href=https://en.wikipedia.org/wiki/System>system</a> achieves an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 83.95 %, outperforming the <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baselines</a> by a large margin, but still far from the <a href=https://en.wikipedia.org/wiki/Upper_and_lower_bounds>human upper bound</a>, which was found to be at 98 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1023.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1023 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1023 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1023.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1023/>Looking Beyond the Surface : A Challenge Set for Reading Comprehension over Multiple Sentences</a></strong><br><a href=/people/d/daniel-khashabi/>Daniel Khashabi</a>
|
<a href=/people/s/snigdha-chaturvedi/>Snigdha Chaturvedi</a>
|
<a href=/people/m/michael-roth/>Michael Roth</a>
|
<a href=/people/s/shyam-upadhyay/>Shyam Upadhyay</a>
|
<a href=/people/d/dan-roth/>Dan Roth</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1023><div class="card-body p-3 small">We present a reading comprehension challenge in which questions can only be answered by taking into account information from multiple sentences. We solicit and verify questions and answers for this challenge through a 4-step crowdsourcing experiment. Our challenge dataset contains 6,500 + questions for 1000 + paragraphs across 7 different domains (elementary school science, <a href=https://en.wikipedia.org/wiki/News>news</a>, <a href=https://en.wikipedia.org/wiki/Guide_book>travel guides</a>, <a href=https://en.wikipedia.org/wiki/Narrative>fiction stories</a>, etc) bringing in linguistic diversity to the texts and to the questions wordings. On a subset of our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, we found <a href=https://en.wikipedia.org/wiki/Solver>human solvers</a> to achieve an <a href=https://en.wikipedia.org/wiki/F-number>F1-score</a> of 88.1 %. We analyze a range of <a href=https://en.wikipedia.org/wiki/Baseline_(surveying)>baselines</a>, including a recent state-of-art reading comprehension system, and demonstrate the difficulty of this challenge, despite a high human performance. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> is the first to study multi-sentence inference at scale, with an open-ended set of question types that requires reasoning skills.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-0900.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-0900/>Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics</a></strong><br><a href=/people/m/michael-roth/>Michael Roth</a>
|
<a href=/people/n/nasrin-mostafazadeh/>Nasrin Mostafazadeh</a>
|
<a href=/people/n/nathanael-chambers/>Nathanael Chambers</a>
|
<a href=/people/a/annie-louis/>Annie Louis</a><br><a href=/volumes/W17-09/ class=text-muted>Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-0906.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-0906 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-0906 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-0906/>LSDSem 2017 Shared Task : The Story Cloze Test<span class=acl-fixed-case>LSDS</span>em 2017 Shared Task: The Story Cloze Test</a></strong><br><a href=/people/n/nasrin-mostafazadeh/>Nasrin Mostafazadeh</a>
|
<a href=/people/m/michael-roth/>Michael Roth</a>
|
<a href=/people/a/annie-louis/>Annie Louis</a>
|
<a href=/people/n/nathanael-chambers/>Nathanael Chambers</a>
|
<a href=/people/j/james-allen/>James Allen</a><br><a href=/volumes/W17-09/ class=text-muted>Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-0906><div class="card-body p-3 small">The LSDSem&#8217;17 shared task is the Story Cloze Test, a new evaluation for story understanding and script learning. This test provides a <a href=https://en.wikipedia.org/wiki/System>system</a> with a four-sentence story and two possible endings, and the system must choose the correct ending to the story. Successful narrative understanding (getting closer to human performance of 100 %) requires systems to link various levels of <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> to <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a>. A total of eight systems participated in the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>shared task</a>, with a variety of <a href=https://en.wikipedia.org/wiki/Software_development_process>approaches</a> including.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D17-3004.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D17-3004 data-toggle=collapse aria-expanded=false aria-controls=abstract-D17-3004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D17-3004/>Semantic Role Labeling</a></strong><br><a href=/people/d/diego-marcheggiani/>Diego Marcheggiani</a>
|
<a href=/people/m/michael-roth/>Michael Roth</a>
|
<a href=/people/i/ivan-titov/>Ivan Titov</a>
|
<a href=/people/b/benjamin-van-durme/>Benjamin Van Durme</a><br><a href=/volumes/D17-3/ class=text-muted>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D17-3004><div class="card-body p-3 small">This tutorial describes semantic role labelling (SRL), the task of mapping text to shallow semantic representations of eventualities and their participants. The tutorial introduces the SRL task and discusses recent research directions related to the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. The audience of this tutorial will learn about the linguistic background and motivation for semantic roles, and also about a range of <a href=https://en.wikipedia.org/wiki/Computational_model>computational models</a> for this task, from early approaches to the current state-of-the-art. We will further discuss recently proposed variations to the traditional SRL task, including topics such as semantic proto-role labeling. We also cover techniques for reducing required annotation effort, such as methods exploiting unlabeled corpora (semi-supervised and unsupervised techniques), model adaptation across languages and domains, and methods for crowdsourcing semantic role annotation (e.g., question-answer driven SRL). Methods based on different machine learning paradigms, including <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>, generative Bayesian models, graph-based algorithms and bootstrapping style techniques. Beyond sentence-level SRL, we discuss work that involves semantic roles in discourse. In particular, we cover <a href=https://en.wikipedia.org/wiki/Data_set>data sets</a> and <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> related to the task of identifying implicit roles and linking them to discourse antecedents. We introduce different approaches to this task from the literature, including models based on <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a>, centering, and selectional preferences. We also review how new insights gained through them can be useful for the traditional SRL task.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Michael+Roth" title="Search for 'Michael Roth' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/t/talita-anthonio/ class=align-middle>Talita Anthonio</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/simon-ostermann/ class=align-middle>Simon Ostermann</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/n/nasrin-mostafazadeh/ class=align-middle>Nasrin Mostafazadeh</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/n/nathanael-chambers/ class=align-middle>Nathanael Chambers</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/annie-louis/ class=align-middle>Annie Louis</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/m/manfred-pinkal/ class=align-middle>Manfred Pinkal</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/shyam-upadhyay/ class=align-middle>Shyam Upadhyay</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/i/irshad-bhat/ class=align-middle>Irshad Bhat</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/james-allen/ class=align-middle>James Allen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sheng-zhang/ class=align-middle>Sheng Zhang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/peter-clark/ class=align-middle>Peter Clark</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/diego-marcheggiani/ class=align-middle>Diego Marcheggiani</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ivan-titov/ class=align-middle>Ivan Titov</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/benjamin-van-durme/ class=align-middle>Benjamin Van Durme</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tatiana-anikina/ class=align-middle>Tatiana Anikina</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexander-koller/ class=align-middle>Alexander Koller</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ashutosh-modi/ class=align-middle>Ashutosh Modi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/stefan-thater/ class=align-middle>Stefan Thater</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/daniel-khashabi/ class=align-middle>Daniel Khashabi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/snigdha-chaturvedi/ class=align-middle>Snigdha Chaturvedi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dan-roth/ class=align-middle>Dan Roth</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/reut-tsarfaty/ class=align-middle>Reut Tsarfaty</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yoav-goldberg/ class=align-middle>Yoav Goldberg</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/unimplicit/ class=align-middle>unimplicit</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/crac/ class=align-middle>CRAC</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>