<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Massimo Poesio - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Massimo</span> <span class=font-weight-bold>Poesio</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.crac-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.crac-1.0/>Proceedings of the Fourth Workshop on Computational Models of Reference, Anaphora and Coreference</a></strong><br><a href=/people/m/maciej-ogrodniczuk/>Maciej Ogrodniczuk</a>
|
<a href=/people/s/sameer-pradhan/>Sameer Pradhan</a>
|
<a href=/people/m/massimo-poesio/>Massimo Poesio</a>
|
<a href=/people/y/yulia-grishina/>Yulia Grishina</a>
|
<a href=/people/v/vincent-ng/>Vincent Ng</a><br><a href=/volumes/2021.crac-1/ class=text-muted>Proceedings of the Fourth Workshop on Computational Models of Reference, Anaphora and Coreference</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.204.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--204 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.204 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.204/>Beyond Black & White : Leveraging Annotator Disagreement via Soft-Label Multi-Task Learning</a></strong><br><a href=/people/t/tommaso-fornaciari/>Tommaso Fornaciari</a>
|
<a href=/people/a/alexandra-uma/>Alexandra Uma</a>
|
<a href=/people/s/silviu-paun/>Silviu Paun</a>
|
<a href=/people/b/barbara-plank/>Barbara Plank</a>
|
<a href=/people/d/dirk-hovy/>Dirk Hovy</a>
|
<a href=/people/m/massimo-poesio/>Massimo Poesio</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--204><div class="card-body p-3 small">Supervised learning assumes that a ground truth label exists. However, the <a href=https://en.wikipedia.org/wiki/Reliability_(statistics)>reliability</a> of this ground truth depends on human annotators, who often disagree. Prior work has shown that this disagreement can be helpful in training <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. We propose a novel method to incorporate this disagreement as information : in addition to the standard error computation, we use soft-labels (i.e., probability distributions over the annotator labels) as an auxiliary task in a multi-task neural network. We measure the <a href=https://en.wikipedia.org/wiki/Divergence>divergence</a> between the predictions and the target soft-labels with several <a href=https://en.wikipedia.org/wiki/Loss_function>loss-functions</a> and evaluate the models on various <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP tasks</a>. We find that the soft-label prediction auxiliary task reduces the penalty for errors on ambiguous entities, and thereby mitigates <a href=https://en.wikipedia.org/wiki/Overfitting>overfitting</a>. It significantly improves performance across <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>, beyond the standard approach and prior work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.329.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--329 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.329 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.329" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.329/>Stay Together : A System for Single and Split-antecedent Anaphora Resolution</a></strong><br><a href=/people/j/juntao-yu/>Juntao Yu</a>
|
<a href=/people/n/nafise-sadat-moosavi/>Nafise Sadat Moosavi</a>
|
<a href=/people/s/silviu-paun/>Silviu Paun</a>
|
<a href=/people/m/massimo-poesio/>Massimo Poesio</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--329><div class="card-body p-3 small">The state-of-the-art on basic, single-antecedent anaphora has greatly improved in recent years. Researchers have therefore started to pay more attention to more complex cases of <a href=https://en.wikipedia.org/wiki/Anaphora_(linguistics)>anaphora</a> such as split-antecedent anaphora, as in Time-Warner is considering a legal challenge to Telecommunications Inc&#8217;s plan to buy half of Showtime Networks Inca move that could lead to all-out war between the two powerful companies. Split-antecedent anaphora is rarer and more complex to resolve than single-antecedent anaphora ; as a result, it is not annotated in many datasets designed to test <a href=https://en.wikipedia.org/wiki/Coreference>coreference</a>, and previous work on resolving this type of <a href=https://en.wikipedia.org/wiki/Anaphora_(linguistics)>anaphora</a> was carried out in unrealistic conditions that assume gold mentions and/or gold split-antecedent anaphors are available. These systems also focus on split-antecedent anaphors only. In this work, we introduce a system that resolves both single and split-antecedent anaphors, and evaluate it in a more realistic setting that uses predicted mentions. We also start addressing the question of how to evaluate single and split-antecedent anaphors together using standard coreference evaluation metrics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.codi-sharedtask.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.codi-sharedtask.0/>Proceedings of the CODI-CRAC 2021 Shared Task on Anaphora, Bridging, and Discourse Deixis in Dialogue</a></strong><br><a href=/people/s/sopan-khosla/>Sopan Khosla</a>
|
<a href=/people/r/ramesh-manuvinakurike/>Ramesh Manuvinakurike</a>
|
<a href=/people/v/vincent-ng/>Vincent Ng</a>
|
<a href=/people/m/massimo-poesio/>Massimo Poesio</a>
|
<a href=/people/m/michael-strube/>Michael Strube</a>
|
<a href=/people/c/carolyn-rose/>Carolyn Rosé</a><br><a href=/volumes/2021.codi-sharedtask/ class=text-muted>Proceedings of the CODI-CRAC 2021 Shared Task on Anaphora, Bridging, and Discourse Deixis in Dialogue</a></span></p><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.cllrd-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--cllrd-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.cllrd-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.cllrd-1.4/>Speaking Outside the Box : Exploring the Benefits of Unconstrained Input in <a href=https://en.wikipedia.org/wiki/Crowdsourcing>Crowdsourcing</a> and Citizen Science Platforms</a></strong><br><a href=/people/j/jon-chamberlain/>Jon Chamberlain</a>
|
<a href=/people/u/udo-kruschwitz/>Udo Kruschwitz</a>
|
<a href=/people/m/massimo-poesio/>Massimo Poesio</a><br><a href=/volumes/2020.cllrd-1/ class=text-muted>Proceedings of the LREC 2020 Workshop on "Citizen Linguistics in Language Resource Development"</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--cllrd-1--4><div class="card-body p-3 small">Crowdsourcing approaches provide a difficult design challenge for developers. There is a trade-off between the efficiency of the task to be done and the reward given to the user for participating, whether it be <a href=https://en.wikipedia.org/wiki/Altruism>altruism</a>, social enhancement, <a href=https://en.wikipedia.org/wiki/Entertainment>entertainment</a> or money. This paper explores how <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing</a> and <a href=https://en.wikipedia.org/wiki/Citizen_science>citizen science systems</a> collect data and complete tasks, illustrated by a case study from the online language game-with-a-purpose Phrase Detectives. The <a href=https://en.wikipedia.org/wiki/Game_(retailer)>game</a> was originally developed to be a constrained interface to prevent player collusion, but subsequently benefited from posthoc analysis of over 76k unconstrained inputs from users. Understanding the interface design and task deconstruction are critical for enabling users to participate in such systems and the paper concludes with a discussion of the idea that <a href=https://en.wikipedia.org/wiki/List_of_social_networking_websites>social networks</a> can be viewed as form of <a href=https://en.wikipedia.org/wiki/Citizen_science>citizen science platform</a> with both constrained and unconstrained inputs making for a highly complex dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.crac-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--crac-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.crac-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.crac-1.3/>Anaphoric Zero Pronoun Identification : A Multilingual Approach</a></strong><br><a href=/people/a/abdulrahman-aloraini/>Abdulrahman Aloraini</a>
|
<a href=/people/m/massimo-poesio/>Massimo Poesio</a><br><a href=/volumes/2020.crac-1/ class=text-muted>Proceedings of the Third Workshop on Computational Models of Reference, Anaphora and Coreference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--crac-1--3><div class="card-body p-3 small">Pro-drop languages such as <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a>, <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>, <a href=https://en.wikipedia.org/wiki/Italian_language>Italian</a> or <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a> allow morphologically null but referential arguments in certain syntactic positions, called anaphoric zero-pronouns. Much NLP work on anaphoric zero-pronouns (AZP) is based on gold mentions, but models for their identification are a fundamental prerequisite for their resolution in real-life applications. Such <a href=https://en.wikipedia.org/wiki/Identity_(social_science)>identification</a> requires <a href=https://en.wikipedia.org/wiki/Complex_system>complex language understanding</a> and knowledge of real-world entities. Transfer learning models, such as BERT, have recently shown to learn surface, syntactic, and semantic information, which can be very useful in recognizing AZPs. We propose a BERT-based multilingual model for AZP identification from predicted zero pronoun positions, and evaluate it on the Arabic and Chinese portions of OntoNotes 5.0. As far as we know, this is the first neural network model of AZP identification for <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a> ; and our approach outperforms the stateof-the-art for <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>. Experiment results suggest that BERT implicitly encode information about AZPs through their surrounding context.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.315.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--315 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.315 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.coling-main.315" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.315/>Multitask Learning-Based Neural Bridging Reference Resolution</a></strong><br><a href=/people/j/juntao-yu/>Juntao Yu</a>
|
<a href=/people/m/massimo-poesio/>Massimo Poesio</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--315><div class="card-body p-3 small">We propose a multi task learning-based neural model for resolving bridging references tackling two key challenges. The first challenge is the lack of large corpora annotated with bridging references. To address this, we use <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a> to help bridging reference resolution with <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a>. We show that substantial improvements of up to 8 p.p. can be achieved on full bridging resolution with this <a href=https://en.wikipedia.org/wiki/Computer_architecture>architecture</a>. The second challenge is the different definitions of bridging used in different corpora, meaning that hand-coded systems or <a href=https://en.wikipedia.org/wiki/System>systems</a> using special features designed for one corpus do not work well with other corpora. Our neural model only uses a small number of corpus independent features, thus can be applied to different corpora. Evaluations with very different bridging corpora (ARRAU, ISNOTES, BASHI and SCICORP) suggest that our architecture works equally well on all corpora, and achieves the SoTA results on full bridging resolution for all corpora, outperforming the best reported results by up to 36.3 p.p..</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.wanlp-1.31.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--wanlp-1--31 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.wanlp-1.31 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.wanlp-1.31/>The QMUL / HRBDT contribution to the NADI Arabic Dialect Identification Shared Task<span class=acl-fixed-case>QMUL</span>/<span class=acl-fixed-case>HRBDT</span> contribution to the <span class=acl-fixed-case>NADI</span> <span class=acl-fixed-case>A</span>rabic Dialect Identification Shared Task</a></strong><br><a href=/people/a/abdulrahman-aloraini/>Abdulrahman Aloraini</a>
|
<a href=/people/m/massimo-poesio/>Massimo Poesio</a>
|
<a href=/people/a/ayman-alhelbawy/>Ayman Alhelbawy</a><br><a href=/volumes/2020.wanlp-1/ class=text-muted>Proceedings of the Fifth Arabic Natural Language Processing Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--wanlp-1--31><div class="card-body p-3 small">We present the Arabic dialect identification system that we used for the country-level subtask of the NADI challenge. Our model consists of three components : BiLSTM-CNN, character-level TF-IDF, and topic modeling features. We represent each tweet using these <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> and feed them into a <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural network</a>. We then add an effective <a href=https://en.wikipedia.org/wiki/Heuristic_(computer_science)>heuristic</a> that improves the overall performance. We achieved an F1-Macro score of 20.77 % and an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 34.32 % on the test set. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> was also evaluated on the Arabic Online Commentary dataset, achieving results better than the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.lrec-1.1" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.1/>Neural Mention Detection</a></strong><br><a href=/people/j/juntao-yu/>Juntao Yu</a>
|
<a href=/people/b/bernd-bohnet/>Bernd Bohnet</a>
|
<a href=/people/m/massimo-poesio/>Massimo Poesio</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--1><div class="card-body p-3 small">Mention detection is an important preprocessing step for annotation and interpretation in applications such as <a href=https://en.wikipedia.org/wiki/Near-infrared_spectroscopy>NER</a> and <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a>, but few stand-alone neural models have been proposed able to handle the full range of mentions. In this work, we propose and compare three neural network-based approaches to mention detection. The first approach is based on the mention detection part of a state of the art coreference resolution system ; the second uses ELMO embeddings together with a bidirectional LSTM and a biaffine classifier ; the third approach uses the recently introduced BERT model. Our best model (using a biaffine classifier) achieves gains of up to 1.8 percentage points on <a href=https://en.wikipedia.org/wiki/Recall_(memory)>mention recall</a> when compared with a strong <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baseline</a> in a HIGH RECALL coreference annotation setting. The same <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves improvements of up to 5.3 and 6.2 p.p. when compared with the best-reported mention detection F1 on the CONLL and CRAC coreference data sets respectively in a HIGH F1 annotation setting. We then evaluate our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> for <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> by using mentions predicted by our best <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> in start-of-the-art <a href=https://en.wikipedia.org/wiki/Coreference>coreference systems</a>. The enhanced <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieved absolute improvements of up to 1.7 and 0.7 p.p. when compared with our strong baseline systems (pipeline system and end-to-end system) respectively. For nested NER, the evaluation of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on the GENIA corpora shows that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> matches or outperforms state-of-the-art models despite not being specifically designed for this task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.11/>Cross-lingual Zero Pronoun Resolution</a></strong><br><a href=/people/a/abdulrahman-aloraini/>Abdulrahman Aloraini</a>
|
<a href=/people/m/massimo-poesio/>Massimo Poesio</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--11><div class="card-body p-3 small">In languages like <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a>, <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>, <a href=https://en.wikipedia.org/wiki/Italian_language>Italian</a>, <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a>, <a href=https://en.wikipedia.org/wiki/Korean_language>Korean</a>, <a href=https://en.wikipedia.org/wiki/Portuguese_language>Portuguese</a>, <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>, and many others, predicate arguments in certain syntactic positions are not realized instead of being realized as overt pronouns, and are thus called zero- or null-pronouns. Identifying and resolving such omitted arguments is crucial to <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction</a> and other NLP tasks, but depends heavily on semantic coherence and lexical relationships. We propose a BERT-based cross-lingual model for zero pronoun resolution, and evaluate it on the Arabic and Chinese portions of OntoNotes 5.0. As far as we know, ours is the first neural model of zero-pronoun resolution for <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a> ; and our model also outperforms the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> for <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>. In the paper we also evaluate BERT feature extraction and fine-tune models on the task, and compare them with our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. We also report on an investigation of BERT layers indicating which layer encodes the most suitable representation for the <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1408.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1408 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1408 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385196786 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1408" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1408/>Using Automatically Extracted Minimum Spans to Disentangle Coreference Evaluation from Boundary Detection</a></strong><br><a href=/people/n/nafise-sadat-moosavi/>Nafise Sadat Moosavi</a>
|
<a href=/people/l/leo-born/>Leo Born</a>
|
<a href=/people/m/massimo-poesio/>Massimo Poesio</a>
|
<a href=/people/m/michael-strube/>Michael Strube</a><br><a href=/volumes/P19-1/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1408><div class="card-body p-3 small">The common practice in <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> is to identify and evaluate the maximum span of mentions. The use of maximum spans tangles coreference evaluation with the challenges of mention boundary detection like prepositional phrase attachment. To address this problem, minimum spans are manually annotated in smaller corpora. However, this additional annotation is costly and therefore, this solution does not scale to large corpora. In this paper, we propose the MINA algorithm for automatically extracting minimum spans to benefit from minimum span evaluation in all corpora. We show that the extracted minimum spans by MINA are consistent with those that are manually annotated by experts. Our experiments show that using minimum spans is in particular important in cross-dataset coreference evaluation, in which detected mention boundaries are noisier due to domain shift. We have integrated MINA into https://github.com/ns-moosavi/coval for reporting standard coreference scores based on both maximum and automatically detected minimum spans.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-0700.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-0700/>Proceedings of the First Workshop on Computational Models of Reference, Anaphora and Coreference</a></strong><br><a href=/people/m/massimo-poesio/>Massimo Poesio</a>
|
<a href=/people/v/vincent-ng/>Vincent Ng</a>
|
<a href=/people/m/maciej-ogrodniczuk/>Maciej Ogrodniczuk</a><br><a href=/volumes/W18-07/ class=text-muted>Proceedings of the First Workshop on Computational Models of Reference, Anaphora and Coreference</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-0702.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-0702 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-0702 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-0702/>Anaphora Resolution with the ARRAU Corpus<span class=acl-fixed-case>ARRAU</span> Corpus</a></strong><br><a href=/people/m/massimo-poesio/>Massimo Poesio</a>
|
<a href=/people/y/yulia-grishina/>Yulia Grishina</a>
|
<a href=/people/v/varada-kolhatkar/>Varada Kolhatkar</a>
|
<a href=/people/n/nafise-sadat-moosavi/>Nafise Moosavi</a>
|
<a href=/people/i/ina-roesiger/>Ina Roesiger</a>
|
<a href=/people/a/adam-roussel/>Adam Roussel</a>
|
<a href=/people/f/fabian-simonjetz/>Fabian Simonjetz</a>
|
<a href=/people/a/alexandra-uma/>Alexandra Uma</a>
|
<a href=/people/o/olga-uryupina/>Olga Uryupina</a>
|
<a href=/people/j/juntao-yu/>Juntao Yu</a>
|
<a href=/people/h/heike-zinsmeister/>Heike Zinsmeister</a><br><a href=/volumes/W18-07/ class=text-muted>Proceedings of the First Workshop on Computational Models of Reference, Anaphora and Coreference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-0702><div class="card-body p-3 small">The ARRAU corpus is an <a href=https://en.wikipedia.org/wiki/Anaphora_(linguistics)>anaphorically annotated corpus of English</a> providing rich linguistic information about <a href=https://en.wikipedia.org/wiki/Anaphora_(linguistics)>anaphora resolution</a>. The most distinctive feature of the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> is the annotation of a wide range of <a href=https://en.wikipedia.org/wiki/Anaphora_(linguistics)>anaphoric relations</a>, including bridging references and <a href=https://en.wikipedia.org/wiki/Discourse_deixis>discourse deixis</a> in addition to identity (coreference). Other distinctive features include treating all NPs as markables, including non-referring NPs ; and the annotation of a variety of morphosyntactic and semantic mention and entity attributes, including the genericity status of the entities referred to by markables. The <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> however has not been extensively used for <a href=https://en.wikipedia.org/wiki/Anaphora_(linguistics)>anaphora resolution</a> research so far. In this paper, we discuss three datasets extracted from the ARRAU corpus to support the three subtasks of the CRAC 2018 Shared Taskidentity anaphora resolution over ARRAU-style markables, bridging references resolution, and discourse deixis ; the evaluation scripts assessing system performance on those datasets ; and preliminary results on these three tasks that may serve as baseline for subsequent research in these phenomena.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4210.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4210 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4210 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4210/>Incongruent Headlines : Yet Another Way to Mislead Your Readers</a></strong><br><a href=/people/s/sophie-chesney/>Sophie Chesney</a>
|
<a href=/people/m/maria-liakata/>Maria Liakata</a>
|
<a href=/people/m/massimo-poesio/>Massimo Poesio</a>
|
<a href=/people/m/matthew-purver/>Matthew Purver</a><br><a href=/volumes/W17-42/ class=text-muted>Proceedings of the 2017 EMNLP Workshop: Natural Language Processing meets Journalism</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4210><div class="card-body p-3 small">This paper discusses the problem of incongruent headlines : those which do not accurately represent the information contained in the article with which they occur. We emphasise that this phenomenon should be considered separately from recognised problematic headline types such as <a href=https://en.wikipedia.org/wiki/Clickbait>clickbait</a> and <a href=https://en.wikipedia.org/wiki/Sensationalism>sensationalism</a>, arguing that existing natural language processing (NLP) methods applied to these related concepts are not appropriate for the automatic detection of headline incongruence, as an analysis beyond stylistic traits is necessary. We therefore suggest a number of alternative <a href=https://en.wikipedia.org/wiki/Methodology>methodologies</a> that may be appropriate to the task at hand as a foundation for future work in this area. In addition, we provide an analysis of existing data sets which are related to this work, and motivate the need for a novel <a href=https://en.wikipedia.org/wiki/Data_set>data set</a> in this domain.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q17-1002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q17-1002 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q17-1002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234954554 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/Q17-1002/>Visually Grounded and Textual Semantic Models Differentially Decode Brain Activity Associated with Concrete and Abstract Nouns</a></strong><br><a href=/people/a/andrew-j-anderson/>Andrew J. Anderson</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a>
|
<a href=/people/s/stephen-clark/>Stephen Clark</a>
|
<a href=/people/m/massimo-poesio/>Massimo Poesio</a><br><a href=/volumes/Q17-1/ class=text-muted>Transactions of the Association for Computational Linguistics, Volume 5</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q17-1002><div class="card-body p-3 small">Important advances have recently been made using computational semantic models to decode brain activity patterns associated with <a href=https://en.wikipedia.org/wiki/Concept>concepts</a> ; however, this work has almost exclusively focused on concrete nouns. How well these <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> extend to decoding <a href=https://en.wikipedia.org/wiki/Noun>abstract nouns</a> is largely unknown. We address this question by applying state-of-the-art computational models to decode functional Magnetic Resonance Imaging (fMRI) activity patterns, elicited by participants reading and imagining a diverse set of both concrete and abstract nouns. One of the <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> we use is linguistic, exploiting the recent word2vec skipgram approach trained on <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>. The <a href=https://en.wikipedia.org/wiki/Second>second</a> is visually grounded, using <a href=https://en.wikipedia.org/wiki/Deep_learning>deep convolutional neural networks</a> trained on <a href=https://en.wikipedia.org/wiki/Google_Images>Google Images</a>. Dual coding theory considers concrete concepts to be encoded in the brain both linguistically and visually, and abstract concepts only linguistically. Splitting the fMRI data according to human concreteness ratings, we indeed observe that both models significantly decode the most concrete nouns ; however, accuracy is significantly greater using the text-based models for the most abstract nouns. More generally this confirms that current <a href=https://en.wikipedia.org/wiki/Computational_model>computational models</a> are sufficiently advanced to assist in investigating the representational structure of <a href=https://en.wikipedia.org/wiki/Concept>abstract concepts</a> in the brain.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Massimo+Poesio" title="Search for 'Massimo Poesio' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/j/juntao-yu/ class=align-middle>Juntao Yu</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/v/vincent-ng/ class=align-middle>Vincent Ng</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/abdulrahman-aloraini/ class=align-middle>Abdulrahman Aloraini</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/n/nafise-sadat-moosavi/ class=align-middle>Nafise Sadat Moosavi</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/m/maciej-ogrodniczuk/ class=align-middle>Maciej Ogrodniczuk</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/y/yulia-grishina/ class=align-middle>Yulia Grishina</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/alexandra-uma/ class=align-middle>Alexandra Uma</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/silviu-paun/ class=align-middle>Silviu Paun</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/m/michael-strube/ class=align-middle>Michael Strube</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/sophie-chesney/ class=align-middle>Sophie Chesney</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/maria-liakata/ class=align-middle>Maria Liakata</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/matthew-purver/ class=align-middle>Matthew Purver</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrew-j-anderson/ class=align-middle>Andrew J. Anderson</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/douwe-kiela/ class=align-middle>Douwe Kiela</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/stephen-clark/ class=align-middle>Stephen Clark</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jon-chamberlain/ class=align-middle>Jon Chamberlain</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/u/udo-kruschwitz/ class=align-middle>Udo Kruschwitz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sameer-pradhan/ class=align-middle>Sameer Pradhan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/tommaso-fornaciari/ class=align-middle>Tommaso Fornaciari</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/barbara-plank/ class=align-middle>Barbara Plank</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/dirk-hovy/ class=align-middle>Dirk Hovy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/varada-kolhatkar/ class=align-middle>Varada Kolhatkar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ina-roesiger/ class=align-middle>Ina Roesiger</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/adam-roussel/ class=align-middle>Adam Roussel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/fabian-simonjetz/ class=align-middle>Fabian Simonjetz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/olga-uryupina/ class=align-middle>Olga Uryupina</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/heike-zinsmeister/ class=align-middle>Heike Zinsmeister</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ayman-alhelbawy/ class=align-middle>Ayman Alhelbawy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/bernd-bohnet/ class=align-middle>Bernd Bohnet</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/leo-born/ class=align-middle>Leo Born</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sopan-khosla/ class=align-middle>Sopan Khosla</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ramesh-manuvinakurike/ class=align-middle>Ramesh Manuvinakurike</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/carolyn-rose/ class=align-middle>Carolyn Rose</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/crac/ class=align-middle>CRAC</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/lrec/ class=align-middle>LREC</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/tacl/ class=align-middle>TACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/cllrd/ class=align-middle>CLLRD</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/wanlp/ class=align-middle>WANLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/codi/ class=align-middle>CODI</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>