<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Marilyn Walker - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Marilyn</span> <span class=font-weight-bold>Walker</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-demo.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-demo--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-demo.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-demo.15/>Athena 2.0 : Contextualized Dialogue Management for an Alexa Prize SocialBot<span class=acl-fixed-case>A</span>lexa <span class=acl-fixed-case>P</span>rize <span class=acl-fixed-case>S</span>ocial<span class=acl-fixed-case>B</span>ot</a></strong><br><a href=/people/j/juraj-juraska/>Juraj Juraska</a>
|
<a href=/people/k/kevin-bowden/>Kevin Bowden</a>
|
<a href=/people/l/lena-reed/>Lena Reed</a>
|
<a href=/people/v/vrindavan-harrison/>Vrindavan Harrison</a>
|
<a href=/people/w/wen-cui/>Wen Cui</a>
|
<a href=/people/o/omkar-patil/>Omkar Patil</a>
|
<a href=/people/r/rishi-rajasekaran/>Rishi Rajasekaran</a>
|
<a href=/people/a/angela-ramirez/>Angela Ramirez</a>
|
<a href=/people/c/cecilia-li/>Cecilia Li</a>
|
<a href=/people/e/eduardo-zamora/>Eduardo Zamora</a>
|
<a href=/people/p/phillip-lee/>Phillip Lee</a>
|
<a href=/people/j/jeshwanth-bheemanpally/>Jeshwanth Bheemanpally</a>
|
<a href=/people/r/rohan-pandey/>Rohan Pandey</a>
|
<a href=/people/a/adwait-ratnaparkhi/>Adwait Ratnaparkhi</a>
|
<a href=/people/m/marilyn-walker/>Marilyn Walker</a><br><a href=/volumes/2021.emnlp-demo/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-demo--15><div class="card-body p-3 small">Athena 2.0 is an <a href=https://en.wikipedia.org/wiki/Alexa_Internet>Alexa Prize SocialBot</a> that has been a finalist in the last two Alexa Prize Grand Challenges. One reason for Athena&#8217;s success is its novel dialogue management strategy, which allows it to dynamically construct dialogues and responses from component modules, leading to novel conversations with every interaction. Here we describe <a href=https://en.wikipedia.org/wiki/Athena>Athena</a>&#8217;s system design and performance in the <a href=https://en.wikipedia.org/wiki/Alexa_Internet>Alexa Prize</a> during the 20/21 competition. A live demo of <a href=https://en.wikipedia.org/wiki/Athena>Athena</a> as well as video recordings will provoke discussion on the state of the art in conversational AI.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.224.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--224 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.224 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929169 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.224/>Bridging the Structural Gap Between <a href=https://en.wikipedia.org/wiki/Code>Encoding</a> and <a href=https://en.wikipedia.org/wiki/Code>Decoding</a> for Data-To-Text Generation</a></strong><br><a href=/people/c/chao-zhao/>Chao Zhao</a>
|
<a href=/people/m/marilyn-walker/>Marilyn Walker</a>
|
<a href=/people/s/snigdha-chaturvedi/>Snigdha Chaturvedi</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--224><div class="card-body p-3 small">Generating sequential natural language descriptions from <a href=https://en.wikipedia.org/wiki/Graph_(abstract_data_type)>graph-structured data</a> (e.g., knowledge graph) is challenging, partly because of the structural differences between the input <a href=https://en.wikipedia.org/wiki/Graph_(abstract_data_type)>graph</a> and the output text. Hence, popular sequence-to-sequence models, which require serialized input, are not a natural fit for this task. Graph neural networks, on the other hand, can better encode the input graph but broaden the structural gap between the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> and <a href=https://en.wikipedia.org/wiki/Codec>decoder</a>, making faithful generation difficult. To narrow this gap, we propose DualEnc, a dual encoding model that can not only incorporate the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a>, but can also cater to the <a href=https://en.wikipedia.org/wiki/Linearity>linear structure</a> of the output text. Empirical comparisons with strong single-encoder baselines demonstrate that dual encoding can significantly improve the quality of the generated text.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-8100.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-8100/>Proceedings of the 1st Workshop on Discourse Structure in Neural NLG</a></strong><br><a href=/people/a/anusha-balakrishnan/>Anusha Balakrishnan</a>
|
<a href=/people/v/vera-demberg/>Vera Demberg</a>
|
<a href=/people/c/chandra-khatri/>Chandra Khatri</a>
|
<a href=/people/a/abhinav-rastogi/>Abhinav Rastogi</a>
|
<a href=/people/d/donia-scott/>Donia Scott</a>
|
<a href=/people/m/marilyn-walker/>Marilyn Walker</a>
|
<a href=/people/m/michael-white/>Michael White</a><br><a href=/volumes/W19-81/ class=text-muted>Proceedings of the 1st Workshop on Discourse Structure in Neural NLG</a></span></p><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-3000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/C18-3000/>Proceedings of the 27th International Conference on Computational Linguistics: Tutorial Abstracts</a></strong><br><a href=/people/d/donia-scott/>Donia Scott</a>
|
<a href=/people/m/marilyn-walker/>Marilyn Walker</a>
|
<a href=/people/p/pascale-fung/>Pascale Fung</a><br><a href=/volumes/C18-3/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics: Tutorial Abstracts</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5003 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5003/>Modeling Linguistic and Personality Adaptation for Natural Language Generation</a></strong><br><a href=/people/z/zhichao-hu/>Zhichao Hu</a>
|
<a href=/people/j/jean-e-fox-tree/>Jean Fox Tree</a>
|
<a href=/people/m/marilyn-walker/>Marilyn Walker</a><br><a href=/volumes/W18-50/ class=text-muted>Proceedings of the 19th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5003><div class="card-body p-3 small">Previous work has shown that conversants adapt to many aspects of their partners&#8217; language. Other work has shown that while every person is unique, they often share general patterns of behavior. Theories of personality aim to explain these shared patterns, and studies have shown that many <a href=https://en.wikipedia.org/wiki/Sensory_cue>linguistic cues</a> are correlated with <a href=https://en.wikipedia.org/wiki/Trait_theory>personality traits</a>. We propose an adaptation measure for adaptive natural language generation for dialogs that integrates the predictions of both <a href=https://en.wikipedia.org/wiki/Personality_psychology>personality theories</a> and adaptation theories, that can be applied as a dialog unfolds, on a turn by turn basis. We show that our measure meets criteria for validity, and that adaptation varies according to corpora and task, speaker, and the set of <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> used to model it. We also produce fine-grained models according to the dialog segmentation or the speaker, and demonstrate the decaying trend of adaptation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5019.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5019 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5019 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5019/>Controlling Personality-Based Stylistic Variation with Neural Natural Language Generators</a></strong><br><a href=/people/s/shereen-oraby/>Shereen Oraby</a>
|
<a href=/people/l/lena-reed/>Lena Reed</a>
|
<a href=/people/s/shubhangi-tandon/>Shubhangi Tandon</a>
|
<a href=/people/s/sharath-t-s/>Sharath T.S.</a>
|
<a href=/people/s/stephanie-lukin/>Stephanie Lukin</a>
|
<a href=/people/m/marilyn-walker/>Marilyn Walker</a><br><a href=/volumes/W18-50/ class=text-muted>Proceedings of the 19th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5019><div class="card-body p-3 small">Natural language generators for task-oriented dialogue must effectively realize system dialogue actions and their associated <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a>. In many applications, it is also desirable for generators to control the style of an utterance. To date, work on task-oriented neural generation has primarily focused on semantic fidelity rather than achieving stylistic goals, while work on <a href=https://en.wikipedia.org/wiki/Style_(sociolinguistics)>style</a> has been done in contexts where it is difficult to measure content preservation. Here we present three different sequence-to-sequence models and carefully test how well they disentangle content and style. We use a statistical generator, Personage, to synthesize a new <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> of over 88,000 restaurant domain utterances whose style varies according to models of personality, giving us total control over both the semantic content and the stylistic variation in the training data. We then vary the amount of explicit stylistic supervision given to the three <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a>. We show that our most explicit model can simultaneously achieve high fidelity to both semantic and stylistic goals : this model adds a context vector of 36 stylistic parameters as input to the hidden state of the encoder at each time step, showing the benefits of explicit stylistic supervision, even when the amount of training data is large.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6536.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6536 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6536 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6536/>Neural Generation of Diverse Questions using Answer Focus, Contextual and Linguistic Features</a></strong><br><a href=/people/v/vrindavan-harrison/>Vrindavan Harrison</a>
|
<a href=/people/m/marilyn-walker/>Marilyn Walker</a><br><a href=/volumes/W18-65/ class=text-muted>Proceedings of the 11th International Conference on Natural Language Generation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6536><div class="card-body p-3 small">Question Generation is the task of automatically creating questions from <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>textual input</a>. In this work we present a new Attentional EncoderDecoder Recurrent Neural Network model for automatic question generation. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> incorporates linguistic features and an additional <a href=https://en.wikipedia.org/wiki/Sentence_embedding>sentence embedding</a> to capture meaning at both sentence and word levels. The linguistic features are designed to capture information related to <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>, word case, and entity coreference resolution. In addition our model uses a copying mechanism and a special answer signal that enables generation of numerous diverse questions on a given sentence. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves state of the art results of 19.98 Bleu_4 on a benchmark Question Generation dataset, outperforming all previously published results by a significant margin. A human evaluation also shows that the added <a href=https://en.wikipedia.org/wiki/Software_feature>features</a> improve the quality of the generated questions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1000/>Proceedings of the 2018 Conference of the North <span class=acl-fixed-case>A</span>merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></strong><br><a href=/people/m/marilyn-walker/>Marilyn Walker</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/a/amanda-stent/>Amanda Stent</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1014.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1014 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1014/>A Deep Ensemble Model with Slot Alignment for Sequence-to-Sequence Natural Language Generation</a></strong><br><a href=/people/j/juraj-juraska/>Juraj Juraska</a>
|
<a href=/people/p/panagiotis-karagiannis/>Panagiotis Karagiannis</a>
|
<a href=/people/k/kevin-bowden/>Kevin Bowden</a>
|
<a href=/people/m/marilyn-walker/>Marilyn Walker</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1014><div class="card-body p-3 small">Natural language generation lies at the core of generative dialogue systems and conversational agents. We describe an ensemble neural language generator, and present several novel methods for data representation and augmentation that yield improved results in our model. We test the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on three datasets in the restaurant, TV and laptop domains, and report both objective and subjective evaluations of our best <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. Using a range of automatic metrics, as well as <a href=https://en.wikipedia.org/wiki/Human&#8211;computer_interaction>human evaluators</a>, we show that our approach achieves better results than state-of-the-art models on the same <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-2000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-2000/>Proceedings of the 2018 Conference of the North <span class=acl-fixed-case>A</span>merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</a></strong><br><a href=/people/m/marilyn-walker/>Marilyn Walker</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/a/amanda-stent/>Amanda Stent</a><br><a href=/volumes/N18-2/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</a></span></p><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-2022.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-2022 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-2022 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234956090 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-2022/>Learning Lexico-Functional Patterns for First-Person Affect</a></strong><br><a href=/people/l/lena-reed/>Lena Reed</a>
|
<a href=/people/j/jiaqi-wu/>Jiaqi Wu</a>
|
<a href=/people/s/shereen-oraby/>Shereen Oraby</a>
|
<a href=/people/p/pranav-anand/>Pranav Anand</a>
|
<a href=/people/m/marilyn-walker/>Marilyn Walker</a><br><a href=/volumes/P17-2/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-2022><div class="card-body p-3 small">Informal first-person narratives are a unique resource for computational models of everyday events and people&#8217;s affective reactions to them. People blogging about their day tend not to explicitly say I am happy. Instead they describe situations from which other humans can readily infer their <a href=https://en.wikipedia.org/wiki/Affect_(psychology)>affective reactions</a>. However current sentiment dictionaries are missing much of the information needed to make similar inferences. We build on recent work that models affect in terms of lexical predicate functions and affect on the predicate&#8217;s arguments. We present a <a href=https://en.wikipedia.org/wiki/Scientific_method>method</a> to learn proxies for these <a href=https://en.wikipedia.org/wiki/Function_(mathematics)>functions</a> from <a href=https://en.wikipedia.org/wiki/First-person_narrative>first-person narratives</a>. We construct a novel fine-grained test set, and show that the patterns we learn improve our ability to predict first-person affective reactions to everyday events, from a Stanford sentiment baseline of.67F to.75F.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2708.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2708 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2708 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2708/>Inference of Fine-Grained Event Causality from Blogs and Films</a></strong><br><a href=/people/z/zhichao-hu/>Zhichao Hu</a>
|
<a href=/people/e/elahe-rahimtoroghi/>Elahe Rahimtoroghi</a>
|
<a href=/people/m/marilyn-walker/>Marilyn Walker</a><br><a href=/volumes/W17-27/ class=text-muted>Proceedings of the Events and Stories in the News Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2708><div class="card-body p-3 small">Human understanding of narrative is mainly driven by reasoning about <a href=https://en.wikipedia.org/wiki/Causality>causal relations</a> between events and thus recognizing them is a key capability for computational models of language understanding. Computational work in this area has approached this via two different routes : by focusing on acquiring a knowledge base of common causal relations between events, or by attempting to understand a particular story or macro-event, along with its storyline. In this position paper, we focus on knowledge acquisition approach and claim that <a href=https://en.wikipedia.org/wiki/News_agency>newswire</a> is a relatively poor source for learning fine-grained causal relations between everyday events. We describe experiments using an <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised method</a> to learn <a href=https://en.wikipedia.org/wiki/Causality>causal relations</a> between events in the narrative genres of <a href=https://en.wikipedia.org/wiki/First-person_narrative>first-person narratives</a> and film scene descriptions. We show that our method learns fine-grained causal relations, judged by humans as likely to be causal over 80 % of the time. We also demonstrate that the learned event pairs do not exist in publicly available event-pair datasets extracted from <a href=https://en.wikipedia.org/wiki/News_agency>newswire</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4904.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4904 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4904 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4904/>Harvesting Creative Templates for Generating Stylistically Varied Restaurant Reviews</a></strong><br><a href=/people/s/shereen-oraby/>Shereen Oraby</a>
|
<a href=/people/s/sheideh-homayon/>Sheideh Homayon</a>
|
<a href=/people/m/marilyn-walker/>Marilyn Walker</a><br><a href=/volumes/W17-49/ class=text-muted>Proceedings of the Workshop on Stylistic Variation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4904><div class="card-body p-3 small">Many of the creative and figurative elements that make language exciting are lost in <a href=https://en.wikipedia.org/wiki/Translation>translation</a> in current natural language generation engines. In this paper, we explore a method to harvest templates from positive and negative reviews in the restaurant domain, with the goal of vastly expanding the types of stylistic variation available to the <a href=https://en.wikipedia.org/wiki/Natural-language_generation>natural language generator</a>. We learn hyperbolic adjective patterns that are representative of the strongly-valenced expressive language commonly used in either positive or negative reviews. We then identify and delexicalize entities, and use <a href=https://en.wikipedia.org/wiki/Heuristic>heuristics</a> to extract generation templates from review sentences. We evaluate the learned templates against more traditional review templates, using subjective measures of convincingness, <a href=https://en.wikipedia.org/wiki/Interest_(emotion)>interestingness</a>, and <a href=https://en.wikipedia.org/wiki/Naturalness_(philosophy)>naturalness</a>. Our results show that the learned <a href=https://en.wikipedia.org/wiki/Template_(word_processing)>templates</a> score highly on these measures. Finally, we analyze the linguistic categories that characterize the learned positive and negative templates. We plan to use the learned <a href=https://en.wikipedia.org/wiki/Template_(word_processing)>templates</a> to improve the conversational style of dialogue systems in the restaurant domain.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4911.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4911 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4911 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4911/>Stylistic Variation in Television Dialogue for Natural Language Generation</a></strong><br><a href=/people/g/grace-lin/>Grace Lin</a>
|
<a href=/people/m/marilyn-walker/>Marilyn Walker</a><br><a href=/volumes/W17-49/ class=text-muted>Proceedings of the Workshop on Stylistic Variation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4911><div class="card-body p-3 small">Conversation is a critical component of <a href=https://en.wikipedia.org/wiki/Storytelling>storytelling</a>, where key information is often revealed by what / how a character says it. We focus on the issue of character voice and build stylistic models with <a href=https://en.wikipedia.org/wiki/Linguistic_description>linguistic features</a> related to <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language generation decisions</a>. Using a dialogue corpus of the television series, The <a href=https://en.wikipedia.org/wiki/The_Big_Bang_Theory>Big Bang Theory</a>, we apply <a href=https://en.wikipedia.org/wiki/Content_analysis>content analysis</a> to extract relevant linguistic features to build character-based stylistic models, and we test the model-fit through an user perceptual experiment with Amazon&#8217;s Mechanical Turk. The results are encouraging in that human subjects tend to perceive the generated utterances as being more similar to the character they are modeled on, than to another random character.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5540.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5540 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5540 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W17-5540.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W17-5540/>Inferring Narrative Causality between Event Pairs in Films</a></strong><br><a href=/people/z/zhichao-hu/>Zhichao Hu</a>
|
<a href=/people/m/marilyn-walker/>Marilyn Walker</a><br><a href=/volumes/W17-55/ class=text-muted>Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5540><div class="card-body p-3 small">To understand <a href=https://en.wikipedia.org/wiki/Narrative>narrative</a>, humans draw inferences about the underlying relations between <a href=https://en.wikipedia.org/wiki/Narrative>narrative events</a>. Cognitive theories of narrative understanding define these inferences as four different types of <a href=https://en.wikipedia.org/wiki/Causality>causality</a>, that include pairs of events A, B where A physically causes B (X drop, X break), to pairs of events where A causes emotional state B (Y saw X, Y felt fear). Previous work on learning narrative relations from <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>text</a> has either focused on strict physical causality, or has been vague about what relation is being learned. This paper learns pairs of causal events from a corpus of film scene descriptions which are action rich and tend to be told in chronological order. We show that event pairs induced using our methods are of high quality and are judged to have a stronger <a href=https://en.wikipedia.org/wiki/Causality>causal relation</a> than event pairs from Rel-Grams.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5543.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5543 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5543 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W17-5543.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W17-5543/>Modelling Protagonist Goals and Desires in First-Person Narrative</a></strong><br><a href=/people/e/elahe-rahimtoroghi/>Elahe Rahimtoroghi</a>
|
<a href=/people/j/jiaqi-wu/>Jiaqi Wu</a>
|
<a href=/people/r/ruimin-wang/>Ruimin Wang</a>
|
<a href=/people/p/pranav-anand/>Pranav Anand</a>
|
<a href=/people/m/marilyn-walker/>Marilyn Walker</a><br><a href=/volumes/W17-55/ class=text-muted>Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5543><div class="card-body p-3 small">Many genres of natural language text are narratively structured, a testament to our predilection for organizing our experiences as narratives. There is broad consensus that understanding a narrative requires identifying and tracking the goals and desires of the characters and their narrative outcomes. However, to date, there has been limited work on <a href=https://en.wikipedia.org/wiki/Computational_model>computational models</a> for this <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a>. We introduce a new dataset, DesireDB, which includes gold-standard labels for identifying statements of desire, textual evidence for desire fulfillment, and annotations for whether the stated desire is fulfilled given the evidence in the narrative context. We report experiments on tracking desire fulfillment using different methods, and show that LSTM Skip-Thought model achieves <a href=https://en.wikipedia.org/wiki/F-measure>F-measure</a> of 0.7 on our <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-1070.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-1070 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-1070 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-1070/>Argument Strength is in the Eye of the Beholder : Audience Effects in <a href=https://en.wikipedia.org/wiki/Persuasion>Persuasion</a></a></strong><br><a href=/people/s/stephanie-lukin/>Stephanie Lukin</a>
|
<a href=/people/p/pranav-anand/>Pranav Anand</a>
|
<a href=/people/m/marilyn-walker/>Marilyn Walker</a>
|
<a href=/people/s/steve-whittaker/>Steve Whittaker</a><br><a href=/volumes/E17-1/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-1070><div class="card-body p-3 small">Americans spend about a third of their time online, with many participating in online conversations on social and political issues. We hypothesize that social media arguments on such issues may be more engaging and persuasive than traditional media summaries, and that particular types of people may be more or less convinced by particular styles of argument, e.g. emotional arguments may resonate with some personalities while factual arguments resonate with others. We report a set of experiments testing at large scale how audience variables interact with argument style to affect the persuasiveness of an argument, an under-researched topic within <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. We show that belief change is affected by <a href=https://en.wikipedia.org/wiki/Personality_psychology>personality factors</a>, with conscientious, open and agreeable people being more convinced by emotional arguments.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Marilyn+Walker" title="Search for 'Marilyn Walker' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/l/lena-reed/ class=align-middle>Lena Reed</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/s/shereen-oraby/ class=align-middle>Shereen Oraby</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/p/pranav-anand/ class=align-middle>Pranav Anand</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/z/zhichao-hu/ class=align-middle>Zhichao Hu</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/d/donia-scott/ class=align-middle>Donia Scott</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/j/jiaqi-wu/ class=align-middle>Jiaqi Wu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/e/elahe-rahimtoroghi/ class=align-middle>Elahe Rahimtoroghi</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/j/juraj-juraska/ class=align-middle>Juraj Juraska</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/k/kevin-bowden/ class=align-middle>Kevin Bowden</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/v/vrindavan-harrison/ class=align-middle>Vrindavan Harrison</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/stephanie-lukin/ class=align-middle>Stephanie Lukin</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/heng-ji/ class=align-middle>Heng Ji</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/amanda-stent/ class=align-middle>Amanda Stent</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/pascale-fung/ class=align-middle>Pascale Fung</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chao-zhao/ class=align-middle>Chao Zhao</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/snigdha-chaturvedi/ class=align-middle>Snigdha Chaturvedi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sheideh-homayon/ class=align-middle>Sheideh Homayon</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/grace-lin/ class=align-middle>Grace Lin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ruimin-wang/ class=align-middle>Ruimin Wang</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/w/wen-cui/ class=align-middle>Wen Cui</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/omkar-patil/ class=align-middle>Omkar Patil</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rishi-rajasekaran/ class=align-middle>Rishi Rajasekaran</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/angela-ramirez/ class=align-middle>Angela Ramirez</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/cecilia-li/ class=align-middle>Cecilia Li</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eduardo-zamora/ class=align-middle>Eduardo Zamora</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/phillip-lee/ class=align-middle>Phillip Lee</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jeshwanth-bheemanpally/ class=align-middle>Jeshwanth Bheemanpally</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rohan-pandey/ class=align-middle>Rohan Pandey</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/adwait-ratnaparkhi/ class=align-middle>Adwait Ratnaparkhi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jean-e-fox-tree/ class=align-middle>Jean E. Fox Tree</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shubhangi-tandon/ class=align-middle>Shubhangi Tandon</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sharath-t-s/ class=align-middle>Sharath T.S.</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anusha-balakrishnan/ class=align-middle>Anusha Balakrishnan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vera-demberg/ class=align-middle>Vera Demberg</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chandra-khatri/ class=align-middle>Chandra Khatri</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/abhinav-rastogi/ class=align-middle>Abhinav Rastogi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-white/ class=align-middle>Michael White</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/panagiotis-karagiannis/ class=align-middle>Panagiotis Karagiannis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/steve-whittaker/ class=align-middle>Steve Whittaker</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">9</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>