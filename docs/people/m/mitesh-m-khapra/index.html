<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Mitesh M. Khapra - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Mitesh M.</span> <span class=font-weight-bold>Khapra</span></h2><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Mitesh <span class=font-weight-normal>Khapra</span></p><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-tutorials.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-tutorials--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-tutorials.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-tutorials.4/>A Tutorial on Evaluation Metrics used in Natural Language Generation</a></strong><br><a href=/people/m/mitesh-m-khapra/>Mitesh M. Khapra</a>
|
<a href=/people/a/ananya-b-sai/>Ananya B. Sai</a><br><a href=/volumes/2021.naacl-tutorials/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Tutorials</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-tutorials--4><div class="card-body p-3 small">The advent of <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Learning</a> and the availability of large scale datasets has accelerated research on <a href=https://en.wikipedia.org/wiki/Natural-language_generation>Natural Language Generation</a> with a focus on newer tasks and better <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. With such rapid progress, it is vital to assess the extent of scientific progress made and identify the areas / components that need improvement. To accomplish this in an automatic and reliable manner, the NLP community has actively pursued the development of automatic evaluation metrics. Especially in the last few years, there has been an increasing focus on evaluation metrics, with several criticisms of existing metrics and proposals for several new <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a>. This tutorial presents the evolution of automatic evaluation metrics to their current state along with the emerging trends in this field by specifically addressing the following questions : (i) What makes NLG evaluation challenging? (ii) Why do we need automatic evaluation metrics? (iii) What are the existing automatic evaluation metrics and how can they be organised in a coherent taxonomy? (iv) What are the criticisms and shortcomings of existing <a href=https://en.wikipedia.org/wiki/Performance_metric>metrics</a>? (v) What are the possible future directions of research?</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.261.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--261 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.261 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939356 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.261" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.261/>Towards Interpreting BERT for Reading Comprehension Based QA<span class=acl-fixed-case>BERT</span> for Reading Comprehension Based <span class=acl-fixed-case>QA</span></a></strong><br><a href=/people/s/sahana-ramnath/>Sahana Ramnath</a>
|
<a href=/people/p/preksha-nema/>Preksha Nema</a>
|
<a href=/people/d/deep-sahni/>Deep Sahni</a>
|
<a href=/people/m/mitesh-m-khapra/>Mitesh M. Khapra</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--261><div class="card-body p-3 small">BERT and its variants have achieved state-of-the-art performance in various NLP tasks. Since then, various works have been proposed to analyze the <a href=https://en.wikipedia.org/wiki/Linguistic_description>linguistic information</a> being captured in BERT. However, the current works do not provide an insight into how BERT is able to achieve near human-level performance on the task of Reading Comprehension based Question Answering. In this work, we attempt to interpret BERT for RCQA. Since BERT layers do not have predefined roles, we define a layer&#8217;s role or functionality using Integrated Gradients. Based on the defined roles, we perform a preliminary analysis across all layers. We observed that the initial <a href=https://en.wikipedia.org/wiki/Abstraction_layer>layers</a> focus on query-passage interaction, whereas later layers focus more on contextual understanding and enhancing the answer prediction. Specifically for quantifier questions (how much / how many), we notice that BERT focuses on <a href=https://en.wikipedia.org/wiki/Word_sense>confusing words</a> (i.e., on other numerical quantities in the passage) in the later <a href=https://en.wikipedia.org/wiki/Complexity>layers</a>, but still manages to predict the answer correctly. The fine-tuning and analysis scripts will be publicly available at https://github.com/iitmnlp/BERT-Analysis-RCQA.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.387.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--387 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.387 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929301 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.387" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.387/>Towards Transparent and Explainable Attention Models</a></strong><br><a href=/people/a/akash-kumar-mohankumar/>Akash Kumar Mohankumar</a>
|
<a href=/people/p/preksha-nema/>Preksha Nema</a>
|
<a href=/people/s/sharan-narasimhan/>Sharan Narasimhan</a>
|
<a href=/people/m/mitesh-m-khapra/>Mitesh M. Khapra</a>
|
<a href=/people/b/balaji-vasan-srinivasan/>Balaji Vasan Srinivasan</a>
|
<a href=/people/b/balaraman-ravindran/>Balaraman Ravindran</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--387><div class="card-body p-3 small">Recent studies on interpretability of <a href=https://en.wikipedia.org/wiki/Attentional_control>attention distributions</a> have led to notions of faithful and plausible explanations for a model&#8217;s predictions. Attention distributions can be considered a faithful explanation if a higher attention weight implies a greater impact on the model&#8217;s prediction. They can be considered a plausible explanation if they provide a human-understandable justification for the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s predictions. In this work, we first explain why current <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanisms</a> in LSTM based encoders can neither provide a faithful nor a plausible explanation of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s predictions. We observe that in LSTM based encoders the hidden representations at different time-steps are very similar to each other (high conicity) and attention weights in these situations do not carry much meaning because even a random permutation of the attention weights does not affect the model&#8217;s predictions. Based on experiments on a wide variety of tasks and datasets, we observe attention distributions often attribute the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s predictions to unimportant words such as <a href=https://en.wikipedia.org/wiki/Punctuation>punctuation</a> and fail to offer a plausible explanation for the predictions. To make attention mechanisms more faithful and plausible, we propose a modified LSTM cell with a diversity-driven training objective that ensures that the hidden representations learned at different time steps are diverse. We show that the resulting attention distributions offer more transparency as they (i) provide a more precise importance ranking of the hidden states (ii) are better indicative of words important for the model&#8217;s predictions (iii) correlate better with gradient-based attribution methods. Human evaluations indicate that the attention distributions learned by our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> offer a plausible explanation of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s predictions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.445.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--445 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.445 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.445/>IndicNLPSuite : Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for <a href=https://en.wikipedia.org/wiki/Languages_of_India>Indian Languages</a><span class=acl-fixed-case>I</span>ndic<span class=acl-fixed-case>NLPS</span>uite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for <span class=acl-fixed-case>I</span>ndian Languages</a></strong><br><a href=/people/d/divyanshu-kakwani/>Divyanshu Kakwani</a>
|
<a href=/people/a/anoop-kunchukuttan/>Anoop Kunchukuttan</a>
|
<a href=/people/s/satish-golla/>Satish Golla</a>
|
<a href=/people/g/gokul-n-c/>Gokul N.C.</a>
|
<a href=/people/a/avik-bhattacharyya/>Avik Bhattacharyya</a>
|
<a href=/people/m/mitesh-m-khapra/>Mitesh M. Khapra</a>
|
<a href=/people/p/pratyush-kumar/>Pratyush Kumar</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--445><div class="card-body p-3 small">In this paper, we introduce NLP resources for 11 major <a href=https://en.wikipedia.org/wiki/Languages_of_India>Indian languages</a> from two major language families. These resources include : (a) large-scale sentence-level monolingual corpora, (b) pre-trained word embeddings, (c) pre-trained language models, and (d) multiple NLU evaluation datasets (IndicGLUE benchmark). The monolingual corpora contains a total of 8.8 billion tokens across all 11 languages and <a href=https://en.wikipedia.org/wiki/Indian_English>Indian English</a>, primarily sourced from <a href=https://en.wikipedia.org/wiki/Web_crawler>news crawls</a>. The <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> are based on <a href=https://en.wikipedia.org/wiki/FastText>FastText</a>, hence suitable for handling morphological complexity of <a href=https://en.wikipedia.org/wiki/Languages_of_India>Indian languages</a>. The pre-trained language models are based on the compact ALBERT model. Lastly, we compile the (IndicGLUE benchmark for Indian language NLU. To this end, we create datasets for the following tasks : Article Genre Classification, Headline Prediction, Wikipedia Section-Title Prediction, Cloze-style Multiple choice QA, Winograd NLI and COPA. We also include publicly available datasets for some Indic languages for tasks like <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>Named Entity Recognition</a>, Cross-lingual Sentence Retrieval, <a href=https://en.wikipedia.org/wiki/Paraphrase_detection>Paraphrase detection</a>, etc. Our <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> are competitive or better than existing pre-trained embeddings on multiple tasks. We hope that the availability of the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> will accelerate Indic NLP research which has the potential to impact more than a billion people. It can also help the community in evaluating advances in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> over a more diverse pool of languages. The data and models are available at.<i>IndicGLUE</i> benchmark). The monolingual corpora contains a total of 8.8 billion tokens across all 11 languages and Indian English, primarily sourced from news crawls. The word embeddings are based on <i>FastText</i>, hence suitable for handling morphological complexity of Indian languages. The pre-trained language models are based on the compact ALBERT model. Lastly, we compile the (<i>IndicGLUE</i> benchmark for Indian language NLU. To this end, we create datasets for the following tasks: Article Genre Classification, Headline Prediction, Wikipedia Section-Title Prediction, Cloze-style Multiple choice QA, Winograd NLI and COPA. We also include publicly available datasets for some Indic languages for tasks like Named Entity Recognition, Cross-lingual Sentence Retrieval, Paraphrase detection, <i>etc.</i> Our embeddings are competitive or better than existing pre-trained embeddings on multiple tasks. We hope that the availability of the dataset will accelerate Indic NLP research which has the potential to impact more than a billion people. It can also help the community in evaluating advances in NLP over a more diverse pool of languages. The data and models are available at <url>https://indicnlp.ai4bharat.org</url>.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1326.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1326 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1326 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D19-1326.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D19-1326" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D19-1326/>Let’s Ask Again : Refine Network for Automatic Question Generation</a></strong><br><a href=/people/p/preksha-nema/>Preksha Nema</a>
|
<a href=/people/a/akash-kumar-mohankumar/>Akash Kumar Mohankumar</a>
|
<a href=/people/m/mitesh-m-khapra/>Mitesh M. Khapra</a>
|
<a href=/people/b/balaji-vasan-srinivasan/>Balaji Vasan Srinivasan</a>
|
<a href=/people/b/balaraman-ravindran/>Balaraman Ravindran</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1326><div class="card-body p-3 small">In this work, we focus on the task of Automatic Question Generation (AQG) where given a passage and an answer the task is to generate the corresponding question. It is desired that the generated question should be (i) grammatically correct (ii) answerable from the passage and (iii) specific to the given answer. An analysis of existing AQG models shows that they produce questions which do not adhere to one or more of the above-mentioned qualities. In particular, the generated questions look like an incomplete draft of the desired question with a clear scope for refinement. To alleviate this shortcoming, we propose a method which tries to mimic the human process of generating questions by first creating an initial draft and then refining it. More specifically, we propose Refine Network (RefNet) which contains two <a href=https://en.wikipedia.org/wiki/Code>decoders</a>. The second <a href=https://en.wikipedia.org/wiki/Code>decoder</a> uses a dual attention network which pays attention to both (i) the original passage and (ii) the question (initial draft) generated by the first <a href=https://en.wikipedia.org/wiki/Code>decoder</a>. In effect, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> refines the question generated by the first <a href=https://en.wikipedia.org/wiki/Code>decoder</a>, thereby making it more correct and complete. We evaluate RefNet on three datasets, viz., SQuAD, HOTPOT-QA, and DROP, and show that it outperforms existing state-of-the-art methods by 7-16 % on all of these datasets. Lastly, we show that we can improve the quality of the second decoder on specific <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a>, such as, <a href=https://en.wikipedia.org/wiki/Fluency>fluency</a> and answerability by explicitly rewarding revisions that improve on the corresponding <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> during training.<fixed-case>the above-mentioned qualities</fixed-case>. In particular, the generated questions look like an incomplete draft of the desired question with a clear scope for refinement. <fixed-case>To alleviate this shortcoming</fixed-case>, we propose a method which tries to mimic the human process of generating questions by first creating an initial draft and then refining it. More specifically, we propose Refine Network (RefNet) which contains two decoders. The second decoder uses a dual attention network which pays attention to both (i) the original passage and (ii) the question (initial draft) generated by the first decoder. In effect, it refines the question generated by the first decoder, thereby making it more correct and complete. We evaluate RefNet on three datasets, <i>viz.</i>, SQuAD, HOTPOT-QA, and DROP, and show that it outperforms existing state-of-the-art methods by 7-16% on all of these datasets. Lastly, we show that we can improve the quality of the second decoder on specific metrics, such as, fluency and answerability by explicitly rewarding revisions that improve on the corresponding metric during training. The code has been made publicly available .</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-1382.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-1382 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-1382 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N19-1382/>On Knowledge distillation from <a href=https://en.wikipedia.org/wiki/Complex_network>complex networks</a> for response prediction</a></strong><br><a href=/people/s/siddhartha-arora/>Siddhartha Arora</a>
|
<a href=/people/m/mitesh-m-khapra/>Mitesh M. Khapra</a>
|
<a href=/people/h/harish-g-ramaswamy/>Harish G. Ramaswamy</a><br><a href=/volumes/N19-1/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-1382><div class="card-body p-3 small">Recent advances in <a href=https://en.wikipedia.org/wiki/Question_answering>Question Answering</a> have lead to the development of very complex models which compute rich representations for query and documents by capturing all pairwise interactions between query and document words. This makes these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> expensive in space and time, and in practice one has to restrict the length of the documents that can be fed to these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. Such <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> have also been recently employed for the task of predicting dialog responses from available background documents (e.g., Holl-E dataset). However, here the documents are longer, thereby rendering these complex models infeasible except in select restricted settings. In order to overcome this, we use standard simple models which do not capture all pairwise interactions, but learn to emulate certain characteristics of a complex teacher network. Specifically, we first investigate the conicity of representations learned by a complex model and observe that it is significantly lower than that of simpler models. Based on this insight, we modify the simple architecture to mimic this <a href=https://en.wikipedia.org/wiki/Property_(philosophy)>characteristic</a>. We go further by using knowledge distillation approaches, where the simple model acts as a student and learns to match the output from the complex teacher network. We experiment with the Holl-E dialog data set and show that by mimicking characteristics and matching outputs from a teacher, even a simple network can give improved performance.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1255.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1255 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1255 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D18-1255.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/305939688 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1255" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1255/>Towards Exploiting Background Knowledge for Building Conversation Systems</a></strong><br><a href=/people/n/nikita-moghe/>Nikita Moghe</a>
|
<a href=/people/s/siddhartha-arora/>Siddhartha Arora</a>
|
<a href=/people/s/suman-banerjee/>Suman Banerjee</a>
|
<a href=/people/m/mitesh-m-khapra/>Mitesh M. Khapra</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1255><div class="card-body p-3 small">Existing dialog datasets contain a sequence of utterances and responses without any explicit background knowledge associated with them. This has resulted in the development of <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> which treat <a href=https://en.wikipedia.org/wiki/Conversation>conversation</a> as a sequence-to-sequence generation task (i.e., given a sequence of utterances generate the response sequence). This is not only an overly simplistic view of conversation but it is also emphatically different from the way humans converse by heavily relying on their background knowledge about the topic (as opposed to simply relying on the previous sequence of utterances). For example, it is common for humans to (involuntarily) produce utterances which are copied or suitably modified from background articles they have read about the topic. To facilitate the development of such natural conversation models which mimic the human process of conversing, we create a new dataset containing movie chats wherein each response is explicitly generated by copying and/or modifying sentences from unstructured background knowledge such as plots, comments and reviews about the movie. We establish baseline results on this dataset (90 K utterances from 9 K conversations) using three different models : (i) pure generation based models which ignore the background knowledge (ii) generation based models which learn to copy information from the background knowledge when required and (iii) span prediction based models which predict the appropriate response span in the background knowledge.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1429.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1429 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1429 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1429" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/D18-1429/>Towards a Better Metric for Evaluating Question Generation Systems</a></strong><br><a href=/people/p/preksha-nema/>Preksha Nema</a>
|
<a href=/people/m/mitesh-m-khapra/>Mitesh M. Khapra</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1429><div class="card-body p-3 small">There has always been criticism for using n-gram based similarity metrics, such as <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>, <a href=https://en.wikipedia.org/wiki/National_Institute_of_Standards_and_Technology>NIST</a>, etc, for evaluating the performance of NLG systems. However, these <a href=https://en.wikipedia.org/wiki/Performance_metric>metrics</a> continue to remain popular and are recently being used for evaluating the performance of systems which automatically generate questions from <a href=https://en.wikipedia.org/wiki/Document>documents</a>, <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graphs</a>, <a href=https://en.wikipedia.org/wiki/Image>images</a>, etc. Given the rising interest in such automatic question generation (AQG) systems, it is important to objectively examine whether these <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> are suitable for this task. In particular, it is important to verify whether such metrics used for evaluating AQG systems focus on answerability of the generated question by preferring questions which contain all relevant information such as question type (Wh-types), entities, relations, etc. In this work, we show that current automatic evaluation metrics based on n-gram similarity do not always correlate well with human judgments about answerability of a question. To alleviate this problem and as a first step towards better evaluation metrics for AQG, we introduce a scoring function to capture answerability and show that when this scoring function is integrated with existing <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a>, they correlate significantly better with human judgments. The scripts and data developed as a part of this work are made publicly available.<tex-math>n</tex-math>-gram based similarity metrics, such as BLEU, NIST, <i>etc</i>, for evaluating the performance of NLG systems. However, these metrics continue to remain popular and are recently being used for evaluating the performance of systems which automatically generate questions from documents, knowledge graphs, images, <i>etc</i>. Given the rising interest in such automatic question generation (AQG) systems, it is important to objectively examine whether these metrics are suitable for this task. In particular, it is important to verify whether such metrics used for evaluating AQG systems focus on <i>answerability</i> of the generated question by preferring questions which contain all relevant information such as question type (Wh-types), entities, relations, <i>etc</i>. In this work, we show that current automatic evaluation metrics based on <tex-math>n</tex-math>-gram similarity do not always correlate well with human judgments about <i>answerability</i> of a question. To alleviate this problem and as a first step towards better evaluation metrics for AQG, we introduce a scoring function to capture <i>answerability</i> and show that when this scoring function is integrated with existing metrics, they correlate significantly better with human judgments. The scripts and data developed as a part of this work are made publicly available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1022.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1022 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1022 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/Q18-1022/>Leveraging Orthographic Similarity for Multilingual Neural Transliteration</a></strong><br><a href=/people/a/anoop-kunchukuttan/>Anoop Kunchukuttan</a>
|
<a href=/people/m/mitesh-m-khapra/>Mitesh Khapra</a>
|
<a href=/people/g/gurneet-singh/>Gurneet Singh</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a><br><a href=/volumes/Q18-1/ class=text-muted>Transactions of the Association for Computational Linguistics, Volume 6</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1022><div class="card-body p-3 small">We address the task of joint training of transliteration models for multiple language pairs (multilingual transliteration). This is an instance of <a href=https://en.wikipedia.org/wiki/Multitask_learning>multitask learning</a>, where individual tasks (language pairs) benefit from sharing knowledge with related tasks. We focus on <a href=https://en.wikipedia.org/wiki/Transliteration>transliteration</a> involving related <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> i.e., <a href=https://en.wikipedia.org/wiki/Language_family>languages sharing writing systems</a> and <a href=https://en.wikipedia.org/wiki/Phoneme>phonetic properties</a> (orthographically similar languages). We propose a modified neural encoder-decoder model that maximizes parameter sharing across language pairs in order to effectively leverage orthographic similarity. We show that multilingual transliteration significantly outperforms bilingual transliteration in different scenarios (average increase of 58 % across a variety of languages we experimented with). We also show that multilingual transliteration models can generalize well to languages / language pairs not encountered during training and hence perform well on the zeroshot transliteration task. We show that further improvements can be achieved by using phonetic feature input.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1139.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1139 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1139 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1139" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1139/>Generating Descriptions from Structured Data Using a Bifocal Attention Mechanism and Gated Orthogonalization</a></strong><br><a href=/people/p/preksha-nema/>Preksha Nema</a>
|
<a href=/people/s/shreyas-shetty/>Shreyas Shetty</a>
|
<a href=/people/p/parag-jain/>Parag Jain</a>
|
<a href=/people/a/anirban-laha/>Anirban Laha</a>
|
<a href=/people/k/karthik-sankaranarayanan/>Karthik Sankaranarayanan</a>
|
<a href=/people/m/mitesh-m-khapra/>Mitesh M. Khapra</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1139><div class="card-body p-3 small">In this work, we focus on the task of generating natural language descriptions from a structured table of facts containing fields (such as nationality, occupation, etc) and values (such as <a href=https://en.wikipedia.org/wiki/Indian_people>Indian</a>, <a href=https://en.wikipedia.org/wiki/Actor>actor</a>, director, etc). One simple choice is to treat the table as a sequence of fields and values and then use a standard seq2seq model for this task. However, such a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> is too generic and does not exploit task specific characteristics. For example, while generating descriptions from a table, a human would attend to information at two levels : (i) the fields (macro level) and (ii) the values within the field (micro level). Further, a human would continue attending to a field for a few timesteps till all the information from that field has been rendered and then never return back to this field (because there is nothing left to say about it). To capture this behavior we use (i) a fused bifocal attention mechanism which exploits and combines this micro and macro level information and (ii) a gated orthogonalization mechanism which tries to ensure that a field is remembered for a few time steps and then forgotten. We experiment with a recently released dataset which contains fact tables about people and their corresponding one line biographical descriptions in English. In addition, we also introduce two similar <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> for <a href=https://en.wikipedia.org/wiki/French_language>French</a> and <a href=https://en.wikipedia.org/wiki/German_language>German</a>. Our experiments show that the proposed model gives 21 % relative improvement over a recently proposed state of the art method and 10 % relative improvement over basic seq2seq models.<url>https://github.com/PrekshaNema25/StructuredData_To_Descriptions</url>\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-2098.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-2098 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-2098 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-2098/>A Mixed Hierarchical Attention Based Encoder-Decoder Approach for Standard Table Summarization</a></strong><br><a href=/people/p/parag-jain/>Parag Jain</a>
|
<a href=/people/a/anirban-laha/>Anirban Laha</a>
|
<a href=/people/k/karthik-sankaranarayanan/>Karthik Sankaranarayanan</a>
|
<a href=/people/p/preksha-nema/>Preksha Nema</a>
|
<a href=/people/m/mitesh-m-khapra/>Mitesh M. Khapra</a>
|
<a href=/people/s/shreyas-shetty/>Shreyas Shetty</a><br><a href=/volumes/N18-2/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-2098><div class="card-body p-3 small">Structured data summarization involves <a href=https://en.wikipedia.org/wiki/Natural-language_generation>generation of natural language summaries</a> from <a href=https://en.wikipedia.org/wiki/Structured_data>structured input data</a>. In this work, we consider summarizing structured data occurring in the form of tables as they are prevalent across a wide variety of domains. We formulate the standard table summarization problem, which deals with tables conforming to a single predefined schema. To this end, we propose a mixed hierarchical attention based encoder-decoder model which is able to leverage the structure in addition to the content of the tables. Our experiments on the publicly available weathergov dataset show around 18 BLEU (around 30 %) improvement over the current <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1156.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1156 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1156 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1156.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1156" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1156/>DuoRC : Towards Complex Language Understanding with Paraphrased Reading Comprehension<span class=acl-fixed-case>D</span>uo<span class=acl-fixed-case>RC</span>: Towards Complex Language Understanding with Paraphrased Reading Comprehension</a></strong><br><a href=/people/a/amrita-saha/>Amrita Saha</a>
|
<a href=/people/r/rahul-aralikatte/>Rahul Aralikatte</a>
|
<a href=/people/m/mitesh-m-khapra/>Mitesh M. Khapra</a>
|
<a href=/people/k/karthik-sankaranarayanan/>Karthik Sankaranarayanan</a><br><a href=/volumes/P18-1/ class=text-muted>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1156><div class="card-body p-3 small">We propose DuoRC, a novel dataset for Reading Comprehension (RC) that motivates several new challenges for neural approaches in <a href=https://en.wikipedia.org/wiki/Language_understanding>language understanding</a> beyond those offered by existing RC datasets. DuoRC contains 186,089 unique question-answer pairs created from a collection of 7680 pairs of movie plots where each pair in the <a href=https://en.wikipedia.org/wiki/Collection_(abstract_data_type)>collection</a> reflects two versions of the same movie-one from Wikipedia and the other from IMDb-written by two different authors. We asked crowdsourced workers to create questions from one version of the plot and a different set of workers to extract or synthesize answers from the other version. This unique characteristic of DuoRC where questions and answers are created from different versions of a document narrating the same underlying story, ensures by design, that there is very little lexical overlap between the questions created from one version and the segments containing the answer in the other version. Further, since the two versions have different levels of plot detail, narration style, <a href=https://en.wikipedia.org/wiki/Vocabulary>vocabulary</a>, etc., answering questions from the second version requires deeper <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>language understanding</a> and incorporating external background knowledge. Additionally, the narrative style of passages arising from movie plots (as opposed to typical descriptive passages in existing datasets) exhibits the need to perform complex reasoning over events across multiple sentences. Indeed, we observe that state-of-the-art neural RC models which have achieved near human performance on the SQuAD dataset, even when coupled with traditional NLP techniques to address the challenges presented in DuoRC exhibit very poor performance (F1 score of 37.42 % on DuoRC v / s 86 % on SQuAD dataset).</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1098.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1098 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1098 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234956203 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P17-1098" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1098/>Diversity driven attention model for query-based abstractive summarization</a></strong><br><a href=/people/p/preksha-nema/>Preksha Nema</a>
|
<a href=/people/m/mitesh-m-khapra/>Mitesh M. Khapra</a>
|
<a href=/people/a/anirban-laha/>Anirban Laha</a>
|
<a href=/people/b/balaraman-ravindran/>Balaraman Ravindran</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1098><div class="card-body p-3 small">Abstractive summarization aims to generate a shorter version of the document covering all the salient points in a compact and coherent fashion. On the other hand, query-based summarization highlights those points that are relevant in the context of a given query. The encode-attend-decode paradigm has achieved notable success in <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, extractive summarization, dialog systems, etc. But <a href=https://en.wikipedia.org/wiki/It_(2017_film)>it</a> suffers from the drawback of generation of repeated phrases. In this work we propose a model for the query-based summarization task based on the encode-attend-decode paradigm with two key additions (i) a query attention model (in addition to document attention model) which learns to focus on different portions of the query at different time steps (instead of using a static representation for the query) and (ii) a new diversity based attention model which aims to alleviate the problem of repeating phrases in the summary. In order to enable the testing of this <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> we introduce a new query-based summarization dataset building on debatepedia. Our experiments show that with these two additions the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> clearly outperforms vanilla encode-attend-decode models with a gain of 28 % (absolute) in ROUGE-L scores.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Mitesh+M.+Khapra" title="Search for 'Mitesh M. Khapra' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/p/preksha-nema/ class=align-middle>Preksha Nema</a>
<span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/people/b/balaraman-ravindran/ class=align-middle>Balaraman Ravindran</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/anirban-laha/ class=align-middle>Anirban Laha</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/k/karthik-sankaranarayanan/ class=align-middle>Karthik Sankaranarayanan</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/akash-kumar-mohankumar/ class=align-middle>Akash Kumar Mohankumar</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/b/balaji-vasan-srinivasan/ class=align-middle>Balaji Vasan Srinivasan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/siddhartha-arora/ class=align-middle>Siddhartha Arora</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/a/anoop-kunchukuttan/ class=align-middle>Anoop Kunchukuttan</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/shreyas-shetty/ class=align-middle>Shreyas Shetty</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/p/parag-jain/ class=align-middle>Parag Jain</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/sahana-ramnath/ class=align-middle>Sahana Ramnath</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/deep-sahni/ class=align-middle>Deep Sahni</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/sharan-narasimhan/ class=align-middle>Sharan Narasimhan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nikita-moghe/ class=align-middle>Nikita Moghe</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/suman-banerjee/ class=align-middle>Suman Banerjee</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gurneet-singh/ class=align-middle>Gurneet Singh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pushpak-bhattacharyya/ class=align-middle>Pushpak Bhattacharyya</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ananya-b-sai/ class=align-middle>Ananya B. Sai</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/divyanshu-kakwani/ class=align-middle>Divyanshu Kakwani</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/satish-golla/ class=align-middle>Satish Golla</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gokul-n-c/ class=align-middle>Gokul N.C.</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/avik-bhattacharyya/ class=align-middle>Avik Bhattacharyya</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/pratyush-kumar/ class=align-middle>Pratyush Kumar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/harish-g-ramaswamy/ class=align-middle>Harish G. Ramaswamy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/amrita-saha/ class=align-middle>Amrita Saha</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rahul-aralikatte/ class=align-middle>Rahul Aralikatte</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/tacl/ class=align-middle>TACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>