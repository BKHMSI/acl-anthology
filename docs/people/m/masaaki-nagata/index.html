<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Masaaki Nagata - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Masaaki</span> <span class=font-weight-bold>Nagata</span></h2><hr><div class=row><div class=col-lg-9><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.41.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--41 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.41 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938923 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.41/>A Supervised Word Alignment Method based on Cross-Language Span Prediction using Multilingual BERT<span class=acl-fixed-case>BERT</span></a></strong><br><a href=/people/m/masaaki-nagata/>Masaaki Nagata</a>
|
<a href=/people/k/katsuki-chousa/>Katsuki Chousa</a>
|
<a href=/people/m/masaaki-nishino/>Masaaki Nishino</a><br><a href=/volumes/2020.emnlp-main/ class=text-muted>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--41><div class="card-body p-3 small">We present a novel supervised word alignment method based on cross-language span prediction. We first formalize a word alignment problem as a collection of independent predictions from a token in the source sentence to a span in the target sentence. Since this step is equivalent to a SQuAD v2.0 style question answering task, we solve it using the multilingual BERT, which is fine-tuned on manually created gold word alignment data. It is nontrivial to obtain accurate <a href=https://en.wikipedia.org/wiki/Sequence_alignment>alignment</a> from a set of independently predicted spans. We greatly improved the word alignment accuracy by adding to the question the source token&#8217;s context and symmetrizing two directional predictions. In experiments using five word alignment datasets from among <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>, <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a>, <a href=https://en.wikipedia.org/wiki/German_language>German</a>, <a href=https://en.wikipedia.org/wiki/Romanian_language>Romanian</a>, <a href=https://en.wikipedia.org/wiki/French_language>French</a>, and <a href=https://en.wikipedia.org/wiki/English_language>English</a>, we show that our proposed method significantly outperformed previous supervised and unsupervised word alignment methods without any bitexts for pretraining. For example, we achieved 86.7 <a href=https://en.wikipedia.org/wiki/F-number>F1 score</a> for the Chinese-English data, which is 13.3 points higher than the previous state-of-the-art <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised method</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.77.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--77 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.77 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.findings-emnlp.77.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.77/>Sequential Span Classification with Neural Semi-Markov CRFs for Biomedical Abstracts<span class=acl-fixed-case>M</span>arkov <span class=acl-fixed-case>CRF</span>s for Biomedical Abstracts</a></strong><br><a href=/people/k/kosuke-yamada/>Kosuke Yamada</a>
|
<a href=/people/t/tsutomu-hirao/>Tsutomu Hirao</a>
|
<a href=/people/r/ryohei-sasano/>Ryohei Sasano</a>
|
<a href=/people/k/koichi-takeda/>Koichi Takeda</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--77><div class="card-body p-3 small">Dividing biomedical abstracts into several segments with rhetorical roles is essential for supporting researchers&#8217; information access in the biomedical domain. Conventional methods have regarded the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> as a sequence labeling task based on sequential sentence classification, i.e., they assign a rhetorical label to each sentence by considering the context in the abstract. However, these methods have a critical problem : they are prone to mislabel longer continuous sentences with the same rhetorical label. To tackle the problem, we propose sequential span classification that assigns a rhetorical label, not to a single sentence but to a span that consists of continuous sentences. Accordingly, we introduce Neural Semi-Markov Conditional Random Fields to assign the labels to such spans by considering all possible spans of various lengths. Experimental results obtained from PubMed 20k RCT and NICTA-PIBOSO datasets demonstrate that our proposed method achieved the best micro sentence-F1 score as well as the best micro span-F1 score.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.wmt-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.wmt-1.0/>Proceedings of the Fifth Conference on Machine Translation</a></strong><br><a href=/people/l/loic-barrault/>Loïc Barrault</a>
|
<a href=/people/o/ondrej-bojar/>Ondřej Bojar</a>
|
<a href=/people/f/fethi-bougares/>Fethi Bougares</a>
|
<a href=/people/r/rajen-chatterjee/>Rajen Chatterjee</a>
|
<a href=/people/m/marta-r-costa-jussa/>Marta R. Costa-jussà</a>
|
<a href=/people/c/christian-federmann/>Christian Federmann</a>
|
<a href=/people/m/mark-fishel/>Mark Fishel</a>
|
<a href=/people/a/alexander-fraser/>Alexander Fraser</a>
|
<a href=/people/y/yvette-graham/>Yvette Graham</a>
|
<a href=/people/p/paco-guzman/>Paco Guzman</a>
|
<a href=/people/b/barry-haddow/>Barry Haddow</a>
|
<a href=/people/m/matthias-huck/>Matthias Huck</a>
|
<a href=/people/a/antonio-jimeno-yepes/>Antonio Jimeno Yepes</a>
|
<a href=/people/p/philipp-koehn/>Philipp Koehn</a>
|
<a href=/people/a/andre-f-t-martins/>André Martins</a>
|
<a href=/people/m/makoto-morishita/>Makoto Morishita</a>
|
<a href=/people/c/christof-monz/>Christof Monz</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a>
|
<a href=/people/t/toshiaki-nakazawa/>Toshiaki Nakazawa</a>
|
<a href=/people/m/matteo-negri/>Matteo Negri</a><br><a href=/volumes/2020.wmt-1/ class=text-muted>Proceedings of the Fifth Conference on Machine Translation</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.443.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--443 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.443 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.443/>JParaCrawl : A Large Scale Web-Based English-Japanese Parallel Corpus<span class=acl-fixed-case>JP</span>ara<span class=acl-fixed-case>C</span>rawl: A Large Scale Web-Based <span class=acl-fixed-case>E</span>nglish-<span class=acl-fixed-case>J</span>apanese Parallel Corpus</a></strong><br><a href=/people/m/makoto-morishita/>Makoto Morishita</a>
|
<a href=/people/j/jun-suzuki/>Jun Suzuki</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--443><div class="card-body p-3 small">Recent machine translation algorithms mainly rely on <a href=https://en.wikipedia.org/wiki/Parallel_corpora>parallel corpora</a>. However, since the availability of <a href=https://en.wikipedia.org/wiki/Parallel_text>parallel corpora</a> remains limited, only some resource-rich language pairs can benefit from them. We constructed a <a href=https://en.wikipedia.org/wiki/Parallel_text>parallel corpus</a> for <a href=https://en.wikipedia.org/wiki/Standard_Japanese>English-Japanese</a>, for which the amount of publicly available parallel corpora is still limited. We constructed the <a href=https://en.wikipedia.org/wiki/Parallel_corpus>parallel corpus</a> by broadly crawling the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>web</a> and automatically aligning parallel sentences. Our collected <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>, called JParaCrawl, amassed over 8.7 million sentence pairs. We show how it includes a broader range of domains and how a neural machine translation model trained with it works as a good pre-trained model for fine-tuning specific domains. The pre-training and fine-tuning approaches achieved or surpassed performance comparable to model training from the initial state and reduced the training time. Additionally, we trained the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> with an in-domain dataset and JParaCrawl to show how we achieved the best performance with them. JParaCrawl and the pre-trained models are freely available online for research purposes.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lrec-1.457.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lrec-1--457 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lrec-1.457 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lrec-1.457/>A Test Set for Discourse Translation from <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a> to <a href=https://en.wikipedia.org/wiki/English_language>English</a><span class=acl-fixed-case>J</span>apanese to <span class=acl-fixed-case>E</span>nglish</a></strong><br><a href=/people/m/masaaki-nagata/>Masaaki Nagata</a>
|
<a href=/people/m/makoto-morishita/>Makoto Morishita</a><br><a href=/volumes/2020.lrec-1/ class=text-muted>Proceedings of the 12th Language Resources and Evaluation Conference</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lrec-1--457><div class="card-body p-3 small">We made a test set for Japanese-to-English discourse translation to evaluate the power of context-aware machine translation. For each discourse phenomenon, we systematically collected examples where the translation of the second sentence depends on the first sentence. Compared with a previous study on test sets for English-to-French discourse translation (CITATION), we needed different approaches to make the data because <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a> has zero pronouns and represents different senses in different characters. We improved the <a href=https://en.wikipedia.org/wiki/Translation>translation accuracy</a> using context-aware neural machine translation, and the improvement mainly reflects the betterment of the <a href=https://en.wikipedia.org/wiki/Translation>translation</a> of zero pronouns.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1587.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1587 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1587 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1587/>Split or Merge : Which is Better for Unsupervised RST Parsing?<span class=acl-fixed-case>RST</span> Parsing?</a></strong><br><a href=/people/n/naoki-kobayashi/>Naoki Kobayashi</a>
|
<a href=/people/t/tsutomu-hirao/>Tsutomu Hirao</a>
|
<a href=/people/k/kengo-nakamura/>Kengo Nakamura</a>
|
<a href=/people/h/hidetaka-kamigaito/>Hidetaka Kamigaito</a>
|
<a href=/people/m/manabu-okumura/>Manabu Okumura</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1587><div class="card-body p-3 small">Rhetorical Structure Theory (RST) parsing is crucial for many downstream NLP tasks that require a discourse structure for a text. Most of the previous RST parsers have been based on supervised learning approaches. That is, they require an annotated corpus of sufficient size and quality, and heavily rely on the language and domain dependent corpus. In this paper, we present two language-independent unsupervised RST parsing methods based on <a href=https://en.wikipedia.org/wiki/Dynamic_programming>dynamic programming</a>. The first one builds the optimal tree in terms of a dissimilarity score function that is defined for splitting a text span into smaller ones. The second builds the optimal tree in terms of a similarity score function that is defined for merging two adjacent spans into a large one. Experimental results on English and German RST treebanks showed that our <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> based on span merging achieved the best score, around 0.8 F_1 score, which is close to the scores of the previous supervised parsers.<tex-math>_1</tex-math> score, which is close to the scores of the previous supervised parsers.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-1674.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-1674 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-1674 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-1674/>Generating Natural Anagrams : Towards <a href=https://en.wikipedia.org/wiki/Language_generation>Language Generation</a> Under Hard Combinatorial Constraints</a></strong><br><a href=/people/m/masaaki-nishino/>Masaaki Nishino</a>
|
<a href=/people/s/sho-takase/>Sho Takase</a>
|
<a href=/people/t/tsutomu-hirao/>Tsutomu Hirao</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a><br><a href=/volumes/D19-1/ class=text-muted>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-1674><div class="card-body p-3 small">An <a href=https://en.wikipedia.org/wiki/Anagram>anagram</a> is a sentence or a phrase that is made by permutating the characters of an input sentence or a phrase. For example, Trims cash is an anagram of Christmas. Existing automatic anagram generation methods can find possible combinations of words form an <a href=https://en.wikipedia.org/wiki/Anagram>anagram</a>. However, they do not pay much attention to the naturalness of the generated <a href=https://en.wikipedia.org/wiki/Anagram>anagrams</a>. In this paper, we show that simple <a href=https://en.wikipedia.org/wiki/Depth-first_search>depth-first search</a> can yield natural anagrams when it is combined with modern neural language models. Human evaluation results show that the proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a> can generate significantly more natural anagrams than baseline methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5622.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5622 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5622 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5622/>Mixed Multi-Head Self-Attention for Neural Machine Translation</a></strong><br><a href=/people/h/hongyi-cui/>Hongyi Cui</a>
|
<a href=/people/s/shohei-iida/>Shohei Iida</a>
|
<a href=/people/p/po-hsuan-hung/>Po-Hsuan Hung</a>
|
<a href=/people/t/takehito-utsuro/>Takehito Utsuro</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a><br><a href=/volumes/D19-56/ class=text-muted>Proceedings of the 3rd Workshop on Neural Generation and Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5622><div class="card-body p-3 small">Recently, the Transformer becomes a state-of-the-art architecture in the filed of neural machine translation (NMT). A key point of its high-performance is the multi-head self-attention which is supposed to allow the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to independently attend to information from different representation subspaces. However, there is no explicit mechanism to ensure that different attention heads indeed capture different features, and in practice, <a href=https://en.wikipedia.org/wiki/Redundancy_(engineering)>redundancy</a> has occurred in multiple heads. In this paper, we argue that using the same <a href=https://en.wikipedia.org/wiki/Attentional_control>global attention</a> in multiple heads limits multi-head self-attention&#8217;s capacity for learning distinct features. In order to improve the expressiveness of multi-head self-attention, we propose a novel Mixed Multi-Head Self-Attention (MMA) which models not only global and local attention but also forward and backward attention in different attention heads. This enables the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to learn distinct representations explicitly among multiple heads. In our experiments on both WAT17 English-Japanese as well as IWSLT14 German-English translation task, we show that, without increasing the number of parameters, our <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> yield consistent and significant improvements (0.9 BLEU scores on average) over the strong Transformer baseline.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5365.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5365 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5365 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5365/>NTT’s Machine Translation Systems for WMT19 Robustness Task<span class=acl-fixed-case>NTT</span>’s Machine Translation Systems for <span class=acl-fixed-case>WMT</span>19 Robustness Task</a></strong><br><a href=/people/s/soichiro-murakami/>Soichiro Murakami</a>
|
<a href=/people/m/makoto-morishita/>Makoto Morishita</a>
|
<a href=/people/t/tsutomu-hirao/>Tsutomu Hirao</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a><br><a href=/volumes/W19-53/ class=text-muted>Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5365><div class="card-body p-3 small">This paper describes NTT&#8217;s submission to the WMT19 robustness task. This <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> mainly focuses on translating <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noisy text</a> (e.g., posts on Twitter), which presents different difficulties from typical translation tasks such as <a href=https://en.wikipedia.org/wiki/News>news</a>. Our submission combined techniques including utilization of a synthetic corpus, <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a>, and a <a href=https://en.wikipedia.org/wiki/Placeholder_name>placeholder mechanism</a>, which significantly improved over the previous <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a>. Experimental results revealed the placeholder mechanism, which temporarily replaces the non-standard tokens including <a href=https://en.wikipedia.org/wiki/Emoji>emojis</a> and <a href=https://en.wikipedia.org/wiki/Emoticon>emoticons</a> with special placeholder tokens during <a href=https://en.wikipedia.org/wiki/Translation>translation</a>, improves <a href=https://en.wikipedia.org/wiki/Translation>translation accuracy</a> even with noisy texts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-2056.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-2056 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-2056 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-2056/>Using <a href=https://en.wikipedia.org/wiki/Semantic_similarity>Semantic Similarity</a> as Reward for <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>Reinforcement Learning</a> in Sentence Generation</a></strong><br><a href=/people/g/go-yasui/>Go Yasui</a>
|
<a href=/people/y/yoshimasa-tsuruoka/>Yoshimasa Tsuruoka</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a><br><a href=/volumes/P19-2/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-2056><div class="card-body p-3 small">Traditional model training for sentence generation employs cross-entropy loss as the <a href=https://en.wikipedia.org/wiki/Loss_function>loss function</a>. While cross-entropy loss has convenient properties for <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised learning</a>, it is unable to evaluate sentences as a whole, and lacks flexibility. We present the approach of training the generation model using the estimated semantic similarity between the output and reference sentences to alleviate the problems faced by the training with cross-entropy loss. We use the BERT-based scorer fine-tuned to the Semantic Textual Similarity (STS) task for semantic similarity estimation, and train the model with the estimated scores through reinforcement learning (RL). Our experiments show that <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a> with semantic similarity reward improves the BLEU scores from the baseline LSTM NMT model.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/C18-1052.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-C18-1052 data-toggle=collapse aria-expanded=false aria-controls=abstract-C18-1052 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/C18-1052/>Improving <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a> by Incorporating Hierarchical Subword Features</a></strong><br><a href=/people/m/makoto-morishita/>Makoto Morishita</a>
|
<a href=/people/j/jun-suzuki/>Jun Suzuki</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a><br><a href=/volumes/C18-1/ class=text-muted>Proceedings of the 27th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-C18-1052><div class="card-body p-3 small">This paper focuses on subword-based Neural Machine Translation (NMT). We hypothesize that in the NMT model, the appropriate subword units for the following three modules (layers) can differ : (1) the encoder embedding layer, (2) the decoder embedding layer, and (3) the decoder output layer. We find the <a href=https://en.wikipedia.org/wiki/Subword>subword</a> based on Sennrich et al. (2016) has a feature that a large vocabulary is a superset of a small vocabulary and modify the NMT model enables the incorporation of several different subword units in a single embedding layer. We refer these small subword features as hierarchical subword features. To empirically investigate our assumption, we compare the performance of several different subword units and hierarchical subword features for both the encoder and decoder embedding layers. We confirmed that incorporating hierarchical subword features in the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> consistently improves BLEU scores on the IWSLT evaluation datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1450.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1450 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1450 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D18-1450/>Automatic Pyramid Evaluation Exploiting EDU-based Extractive Reference Summaries<span class=acl-fixed-case>EDU</span>-based Extractive Reference Summaries</a></strong><br><a href=/people/t/tsutomu-hirao/>Tsutomu Hirao</a>
|
<a href=/people/h/hidetaka-kamigaito/>Hidetaka Kamigaito</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1450><div class="card-body p-3 small">This paper tackles automation of the pyramid method, a reliable manual evaluation framework. To construct a pyramid, we transform human-made reference summaries into extractive reference summaries that consist of Elementary Discourse Units (EDUs) obtained from source documents and then weight every EDU by counting the number of extractive reference summaries that contain the EDU. A summary is scored by the correspondences between EDUs in the summary and those in the pyramid. Experiments on DUC and TAC data sets show that our methods strongly correlate with various manual evaluations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1047.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1047 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1047 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1047/>Neural Tensor Networks with Diagonal Slice Matrices</a></strong><br><a href=/people/t/takahiro-ishihara/>Takahiro Ishihara</a>
|
<a href=/people/k/katsuhiko-hayashi/>Katsuhiko Hayashi</a>
|
<a href=/people/h/hitoshi-manabe/>Hitoshi Manabe</a>
|
<a href=/people/m/masashi-shimbo/>Masashi Shimbo</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1047><div class="card-body p-3 small">Although neural tensor networks (NTNs) have been successful in many NLP tasks, they require a large number of parameters to be estimated, which often leads to <a href=https://en.wikipedia.org/wiki/Overfitting>overfitting</a> and a long training time. We address these issues by applying <a href=https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix>eigendecomposition</a> to each slice matrix of a <a href=https://en.wikipedia.org/wiki/Tensor>tensor</a> to reduce its number of paramters. First, we evaluate our proposed NTN models on knowledge graph completion. Second, we extend the models to recursive NTNs (RNTNs) and evaluate them on logical reasoning tasks. These experiments show that our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> learn better and faster than the original (R)NTNs.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2002 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2002/>Supervised Attention for Sequence-to-Sequence Constituency Parsing</a></strong><br><a href=/people/h/hidetaka-kamigaito/>Hidetaka Kamigaito</a>
|
<a href=/people/k/katsuhiko-hayashi/>Katsuhiko Hayashi</a>
|
<a href=/people/t/tsutomu-hirao/>Tsutomu Hirao</a>
|
<a href=/people/h/hiroya-takamura/>Hiroya Takamura</a>
|
<a href=/people/m/manabu-okumura/>Manabu Okumura</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a><br><a href=/volumes/I17-2/ class=text-muted>Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2002><div class="card-body p-3 small">The sequence-to-sequence (Seq2Seq) model has been successfully applied to <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation (MT)</a>. Recently, MT performances were improved by incorporating supervised attention into the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. In this paper, we introduce supervised attention to constituency parsing that can be regarded as another translation task. Evaluation results on the PTB corpus showed that the bracketing F-measure was improved by supervised attention.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2008.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2008 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2008 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=I17-2008" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/I17-2008/>Input-to-Output Gate to Improve RNN Language Models<span class=acl-fixed-case>RNN</span> Language Models</a></strong><br><a href=/people/s/sho-takase/>Sho Takase</a>
|
<a href=/people/j/jun-suzuki/>Jun Suzuki</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a><br><a href=/volumes/I17-2/ class=text-muted>Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2008><div class="card-body p-3 small">This paper proposes a reinforcing method that refines the output layers of existing Recurrent Neural Network (RNN) language models. We refer to our proposed <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> as Input-to-Output Gate (IOG). IOG has an extremely simple structure, and thus, can be easily combined with any RNN language models. Our experiments on the <a href=https://en.wikipedia.org/wiki/Penn_Treebank>Penn Treebank</a> and WikiText-2 datasets demonstrate that IOG consistently boosts the performance of several different types of current topline RNN language models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-2043.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-2043 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-2043 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P17-2043/>Oracle Summaries of Compressive Summarization</a></strong><br><a href=/people/t/tsutomu-hirao/>Tsutomu Hirao</a>
|
<a href=/people/m/masaaki-nishino/>Masaaki Nishino</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a><br><a href=/volumes/P17-2/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-2043><div class="card-body p-3 small">This paper derives an Integer Linear Programming (ILP) formulation to obtain an oracle summary of the compressive summarization paradigm in terms of ROUGE. The oracle summary is essential to reveal the upper bound performance of the <a href=https://en.wikipedia.org/wiki/Paradigm>paradigm</a>. Experimental results on the DUC dataset showed that ROUGE scores of compressive oracles are significantly higher than those of extractive oracles and state-of-the-art summarization systems. These results reveal that compressive summarization is a promising paradigm and encourage us to continue with the research to produce informative summaries.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5702.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5702 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5702 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5702/>Controlling Target Features in <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a> via Prefix Constraints</a></strong><br><a href=/people/s/shunsuke-takeno/>Shunsuke Takeno</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a>
|
<a href=/people/k/kazuhide-yamamoto/>Kazuhide Yamamoto</a><br><a href=/volumes/W17-57/ class=text-muted>Proceedings of the 4th Workshop on Asian Translation (WAT2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5702><div class="card-body p-3 small">We propose prefix constraints, a novel method to enforce constraints on target sentences in <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a>. It places a sequence of special tokens at the beginning of target sentence (target prefix), while side constraints places a special token at the end of source sentence (source suffix). Prefix constraints can be predicted from source sentence jointly with target sentence, while side constraints (Sennrich et al., 2016) must be provided by the user or predicted by some other methods. In both <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>methods</a>, special tokens are designed to encode arbitrary features on target-side or metatextual information. We show that prefix constraints are more flexible than side constraints and can be used to control the behavior of neural machine translation, in terms of output length, bidirectional decoding, domain adaptation, and unaligned target word generation.<i>prefix constraints</i>, a novel method to enforce constraints on\n target sentences in neural machine translation. It places a sequence of\n special tokens at the beginning of target sentence (target prefix), while\n side constraints places a special token at the end of source sentence\n (source suffix). Prefix constraints can be predicted from source sentence\n jointly with target sentence, while side constraints (Sennrich et al., 2016) must be provided by\n the user or predicted by some other methods. In both methods, special\n tokens are designed to encode arbitrary features on target-side or\n metatextual information. We show that prefix constraints are more flexible\n than side constraints and can be used to control the behavior of neural\n machine translation, in terms of output length, bidirectional decoding,\n domain adaptation, and unaligned target word generation.\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-6308.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-6308 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-6308 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-6308/>Hierarchical Word Structure-based Parsing : A Feasibility Study on UD-style Dependency Parsing in <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a><span class=acl-fixed-case>UD</span>-style Dependency Parsing in <span class=acl-fixed-case>J</span>apanese</a></strong><br><a href=/people/t/takaaki-tanaka/>Takaaki Tanaka</a>
|
<a href=/people/k/katsuhiko-hayashi/>Katsuhiko Hayashi</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a><br><a href=/volumes/W17-63/ class=text-muted>Proceedings of the 15th International Conference on Parsing Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-6308><div class="card-body p-3 small">In applying word-based dependency parsing such as Universal Dependencies (UD) to <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a>, the uncertainty of <a href=https://en.wikipedia.org/wiki/Word_segmentation>word segmentation</a> emerges for defining a word unit of the dependencies. We introduce the following hierarchical word structures to dependency parsing in <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a> : morphological units (a short unit word, SUW) and syntactic units (a long unit word, LUW). An SUW can be used to segment a sentence consistently, while it is too short to represent syntactic construction. An LUW is a unit including functional multiwords and LUW-based analysis facilitates the capturing of syntactic structure and makes <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a> results more precise than SUW-based analysis. This paper describes the results of a feasibility study on the ability and the effectiveness of parsing methods based on hierarchical word structure (LUW chunking+parsing) in comparison to single layer word structure (SUW parsing). We also show joint analysis of LUW-chunking and dependency parsing improves the performance of identifying predicate-argument structures, while there is not much difference between overall results of them. not much difference between overall results of them.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-1037.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-1037 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-1037 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-1037/>Enumeration of Extractive Oracle Summaries</a></strong><br><a href=/people/t/tsutomu-hirao/>Tsutomu Hirao</a>
|
<a href=/people/m/masaaki-nishino/>Masaaki Nishino</a>
|
<a href=/people/j/jun-suzuki/>Jun Suzuki</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a><br><a href=/volumes/E17-1/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-1037><div class="card-body p-3 small">To analyze the limitations and the future directions of the extractive summarization paradigm, this paper proposes an Integer Linear Programming (ILP) formulation to obtain extractive oracle summaries in terms of ROUGE-N. We also propose an algorithm that enumerates all of the <a href=https://en.wikipedia.org/wiki/Oracle_machine>oracle summaries</a> for a set of reference summaries to exploit F-measures that evaluate which system summaries contain how many sentences that are extracted as an oracle summary. Our experimental results obtained from Document Understanding Conference (DUC) corpora demonstrated the following : (1) room still exists to improve the performance of extractive summarization ; (2) the F-measures derived from the enumerated oracle summaries have significantly stronger correlations with human judgment than those derived from single oracle summaries.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-2047.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-2047 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-2047 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-2047/>Cutting-off Redundant Repeating Generations for Neural Abstractive Summarization</a></strong><br><a href=/people/j/jun-suzuki/>Jun Suzuki</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a><br><a href=/volumes/E17-2/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-2047><div class="card-body p-3 small">This paper tackles the reduction of redundant repeating generation that is often observed in RNN-based encoder-decoder models. Our basic idea is to jointly estimate the upper-bound frequency of each target vocabulary in the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> and control the output words based on the estimation in the <a href=https://en.wikipedia.org/wiki/Codec>decoder</a>. Our method shows significant improvement over a strong RNN-based encoder-decoder baseline and achieved its best results on an abstractive summarization benchmark.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-2049.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-2049 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-2049 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-2049/>K-best Iterative Viterbi Parsing<span class=acl-fixed-case>V</span>iterbi Parsing</a></strong><br><a href=/people/k/katsuhiko-hayashi/>Katsuhiko Hayashi</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a><br><a href=/volumes/E17-2/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-2049><div class="card-body p-3 small">This paper presents an efficient and optimal parsing algorithm for probabilistic context-free grammars (PCFGs). To achieve faster <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a>, our proposal employs a pruning technique to reduce unnecessary edges in the <a href=https://en.wikipedia.org/wiki/Feasible_region>search space</a>. The key is to conduct repetitively Viterbi inside and outside parsing, while gradually expanding the <a href=https://en.wikipedia.org/wiki/Feasible_region>search space</a> to efficiently compute <a href=https://en.wikipedia.org/wiki/Heuristic_(computer_science)>heuristic bounds</a> used for <a href=https://en.wikipedia.org/wiki/Parsing>pruning</a>. Our experimental results using the English Penn Treebank corpus show that the proposed <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> is faster than the standard CKY parsing algorithm. In addition, we also show how to extend this <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> to extract k-best Viterbi parse trees.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Masaaki+Nagata" title="Search for 'Masaaki Nagata' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/t/tsutomu-hirao/ class=align-middle>Tsutomu Hirao</a>
<span class="badge badge-secondary align-middle ml-2">8</span></li><li class=list-group-item><a href=/people/m/makoto-morishita/ class=align-middle>Makoto Morishita</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/j/jun-suzuki/ class=align-middle>Jun Suzuki</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/k/katsuhiko-hayashi/ class=align-middle>Katsuhiko Hayashi</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/m/masaaki-nishino/ class=align-middle>Masaaki Nishino</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/h/hidetaka-kamigaito/ class=align-middle>Hidetaka Kamigaito</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/m/manabu-okumura/ class=align-middle>Manabu Okumura</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/sho-takase/ class=align-middle>Sho Takase</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/h/hiroya-takamura/ class=align-middle>Hiroya Takamura</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/katsuki-chousa/ class=align-middle>Katsuki Chousa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shunsuke-takeno/ class=align-middle>Shunsuke Takeno</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kazuhide-yamamoto/ class=align-middle>Kazuhide Yamamoto</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/takaaki-tanaka/ class=align-middle>Takaaki Tanaka</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/naoki-kobayashi/ class=align-middle>Naoki Kobayashi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kengo-nakamura/ class=align-middle>Kengo Nakamura</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hongyi-cui/ class=align-middle>Hongyi Cui</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shohei-iida/ class=align-middle>Shohei Iida</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/po-hsuan-hung/ class=align-middle>Po-Hsuan Hung</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/takehito-utsuro/ class=align-middle>Takehito Utsuro</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kosuke-yamada/ class=align-middle>Kosuke Yamada</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ryohei-sasano/ class=align-middle>Ryohei Sasano</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/koichi-takeda/ class=align-middle>Koichi Takeda</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/soichiro-murakami/ class=align-middle>Soichiro Murakami</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/takahiro-ishihara/ class=align-middle>Takahiro Ishihara</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hitoshi-manabe/ class=align-middle>Hitoshi Manabe</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/masashi-shimbo/ class=align-middle>Masashi Shimbo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/l/loic-barrault/ class=align-middle>Loïc Barrault</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/ondrej-bojar/ class=align-middle>Ondřej Bojar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/f/fethi-bougares/ class=align-middle>Fethi Bougares</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rajen-chatterjee/ class=align-middle>Rajen Chatterjee</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marta-r-costa-jussa/ class=align-middle>Marta R. Costa-jussà</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christian-federmann/ class=align-middle>Christian Federmann</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mark-fishel/ class=align-middle>Mark Fishel</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexander-fraser/ class=align-middle>Alexander Fraser</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yvette-graham/ class=align-middle>Yvette Graham</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/paco-guzman/ class=align-middle>Paco Guzman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/barry-haddow/ class=align-middle>Barry Haddow</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/matthias-huck/ class=align-middle>Matthias Huck</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/antonio-jimeno-yepes/ class=align-middle>Antonio Jimeno Yepes</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/philipp-koehn/ class=align-middle>Philipp Koehn</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andre-f-t-martins/ class=align-middle>André F. T. Martins</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/christof-monz/ class=align-middle>Christof Monz</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/toshiaki-nakazawa/ class=align-middle>Toshiaki Nakazawa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/matteo-negri/ class=align-middle>Matteo Negri</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/go-yasui/ class=align-middle>Go Yasui</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yoshimasa-tsuruoka/ class=align-middle>Yoshimasa Tsuruoka</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/ijcnlp/ class=align-middle>IJCNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/lrec/ class=align-middle>LREC</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/wmt/ class=align-middle>WMT</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>