<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Malak Abdullah - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Malak</span> <span class=font-weight-bold>Abdullah</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wanlp-1.44.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wanlp-1--44 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wanlp-1.44 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wanlp-1.44/>SarcasmDet at Sarcasm Detection Task 2021 in Arabic using AraBERT Pretrained Model<span class=acl-fixed-case>S</span>arcasm<span class=acl-fixed-case>D</span>et at Sarcasm Detection Task 2021 in <span class=acl-fixed-case>A</span>rabic using <span class=acl-fixed-case>A</span>ra<span class=acl-fixed-case>BERT</span> Pretrained Model</a></strong><br><a href=/people/d/dalya-faraj/>Dalya Faraj</a>
|
<a href=/people/d/dalya-faraj/>Dalya Faraj</a>
|
<a href=/people/m/malak-abdullah/>Malak Abdullah</a><br><a href=/volumes/2021.wanlp-1/ class=text-muted>Proceedings of the Sixth Arabic Natural Language Processing Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wanlp-1--44><div class="card-body p-3 small">This paper presents one of the top five winning solutions for the Shared Task on Sarcasm and Sentiment Detection in <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a> (Subtask-1 Sarcasm Detection). The goal of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is to identify whether a tweet is sarcastic or not. Our solution has been developed using <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensemble technique</a> with AraBERT pre-trained model. We describe the architecture of the submitted <a href=https://en.wikipedia.org/wiki/Solution>solution</a> in the <a href=https://en.wikipedia.org/wiki/Task_(computing)>shared task</a>. We also provide the experiments and the hyperparameter tuning that lead to this result. Besides, we discuss and analyze the results by comparing all the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that we trained or tested to achieve a better score in a table design. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is ranked fifth out of 27 teams with an F1 score of 0.5985. It is worth mentioning that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieved the highest <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy score</a> of 0.7830</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.semeval-1.37.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--semeval-1--37 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.semeval-1.37 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.semeval-1.37/>JUSTMasters at SemEval-2020 Task 3 : Multilingual Deep Learning Model to Predict the Effect of Context in Word Similarity<span class=acl-fixed-case>JUSTM</span>asters at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2020 Task 3: Multilingual Deep Learning Model to Predict the Effect of Context in Word Similarity</a></strong><br><a href=/people/n/nour-al-khdour/>Nour Al-khdour</a>
|
<a href=/people/m/mutaz-bni-younes/>Mutaz Bni Younes</a>
|
<a href=/people/m/malak-abdullah/>Malak Abdullah</a>
|
<a href=/people/m/mohammad-al-smadi/>Mohammad AL-Smadi</a><br><a href=/volumes/2020.semeval-1/ class=text-muted>Proceedings of the Fourteenth Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--semeval-1--37><div class="card-body p-3 small">There is a growing research interest in studying word similarity. Without a doubt, two similar words in a context may considered different in another context. Therefore, this paper investigates the effect of the <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context</a> in word similarity. The SemEval-2020 workshop has provided a shared task (Task 3 : Predicting the (Graded) Effect of Context in Word Similarity). In this task, the organizers provided unlabeled datasets for four languages, <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/Croatian_language>Croatian</a>, <a href=https://en.wikipedia.org/wiki/Finnish_language>Finnish</a> and <a href=https://en.wikipedia.org/wiki/Slovene_language>Slovenian</a>. Our team, JUSTMasters, has participated in this competition in the two subtasks : A and B. Our approach has used a weighted average ensembling method for different pretrained embeddings techniques for each of the four languages. Our proposed model outperformed the baseline models in both subtasks and acheived the best result for subtask 2 in <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/Finnish_language>Finnish</a>, with score 0.725 and 0.68 respectively. We have been ranked the sixth for subtask 1, with scores for <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/Croatian_language>Croatian</a>, <a href=https://en.wikipedia.org/wiki/Finnish_language>Finnish</a>, and <a href=https://en.wikipedia.org/wiki/Slovene_language>Slovenian</a> as follows : 0.738, 0.44, 0.546, 0.512.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.semeval-1.136.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--semeval-1--136 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.semeval-1.136 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.semeval-1.136/>MLEngineer at SemEval-2020 Task 7 : BERT-Flair Based Humor Detection Model (BFHumor)<span class=acl-fixed-case>MLE</span>ngineer at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2020 Task 7: <span class=acl-fixed-case>BERT</span>-Flair Based Humor Detection Model (<span class=acl-fixed-case>BFH</span>umor)</a></strong><br><a href=/people/f/fara-shatnawi/>Fara Shatnawi</a>
|
<a href=/people/m/malak-abdullah/>Malak Abdullah</a>
|
<a href=/people/m/mahmoud-hammad/>Mahmoud Hammad</a><br><a href=/volumes/2020.semeval-1/ class=text-muted>Proceedings of the Fourteenth Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--semeval-1--136><div class="card-body p-3 small">Task 7, Assessing the Funniness of Edited News Headlines, in the International Workshop SemEval2020 introduces two sub-tasks to predict the funniness values of edited news headlines from the Reddit website. This paper proposes the BFHumor model of the MLEngineer team that participates in both sub-tasks in this competition. The BFHumor&#8217;s model is defined as a BERT-Flair based humor detection model that is a combination of different pre-trained models with various Natural Language Processing (NLP) techniques. The Bidirectional Encoder Representations from Transformers (BERT) regressor is considered the primary pre-trained model in our approach, whereas Flair is the main NLP library. It is worth mentioning that the BFHumor model has been ranked 4th in sub-task1 with a root mean square error (RMSE) value of 0.51966, and it is 0.02 away from the first ranked model. Also, the team is ranked 12th in the sub-task2 with an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 0.62291, which is 0.05 away from the top-ranked model. Our results indicate that the BFHumor model is one of the top models for detecting humor in the text.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.semeval-1.229.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--semeval-1--229 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.semeval-1.229 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.semeval-1.229/>JUST at SemEval-2020 Task 11 : Detecting Propaganda Techniques Using BERT Pre-trained Model<span class=acl-fixed-case>JUST</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2020 Task 11: Detecting Propaganda Techniques Using <span class=acl-fixed-case>BERT</span> Pre-trained Model</a></strong><br><a href=/people/o/ola-altiti/>Ola Altiti</a>
|
<a href=/people/m/malak-abdullah/>Malak Abdullah</a>
|
<a href=/people/r/rasha-obiedat/>Rasha Obiedat</a><br><a href=/volumes/2020.semeval-1/ class=text-muted>Proceedings of the Fourteenth Workshop on Semantic Evaluation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--semeval-1--229><div class="card-body p-3 small">This paper presents the submission to semeval-2020 task 11, Detection of Propaganda Techniques in News Articles. Knowing that there are two subtasks in this competition, we have participated in the Technique Classification subtask (TC), which aims to identify the propaganda techniques used in a specific propaganda span. We have used and implemented various <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> to detect <a href=https://en.wikipedia.org/wiki/Propaganda>propaganda</a>. Our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is based on BERT uncased pre-trained language model as it has achieved state-of-the-art performance on multiple NLP benchmarks. The performance results of our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> have scored 0.55307 F1-Score, which outperforms the baseline model provided by the organizers with 0.2519 F1-Score, and our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is 0.07 away from the best performing team. Compared to other participating systems, our submission is ranked 15th out of 31 participants.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-5016.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-5016 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-5016 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-5016/>JUSTDeep at NLP4IF 2019 Task 1 : Propaganda Detection using Ensemble Deep Learning Models<span class=acl-fixed-case>JUSTD</span>eep at <span class=acl-fixed-case>NLP</span>4<span class=acl-fixed-case>IF</span> 2019 Task 1: Propaganda Detection using Ensemble Deep Learning Models</a></strong><br><a href=/people/h/hani-al-omari/>Hani Al-Omari</a>
|
<a href=/people/m/malak-abdullah/>Malak Abdullah</a>
|
<a href=/people/o/ola-altiti/>Ola AlTiti</a>
|
<a href=/people/s/samira-shaikh/>Samira Shaikh</a><br><a href=/volumes/D19-50/ class=text-muted>Proceedings of the Second Workshop on Natural Language Processing for Internet Freedom: Censorship, Disinformation, and Propaganda</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-5016><div class="card-body p-3 small">The <a href=https://en.wikipedia.org/wiki/Internet>internet</a> and the high use of <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> have enabled the modern-day journalism to publish, share and spread news that is difficult to distinguish if it is true or fake. Defining fake news is not well established yet, however, it can be categorized under several labels : false, biased, or framed to mislead the readers that are characterized as <a href=https://en.wikipedia.org/wiki/Propaganda>propaganda</a>. Digital content production technologies with <a href=https://en.wikipedia.org/wiki/Fallacy>logical fallacies</a> and emotional language can be used as <a href=https://en.wikipedia.org/wiki/Propaganda_techniques>propaganda techniques</a> to gain more readers or mislead the audience. Recently, several researchers have proposed deep learning (DL) models to address this issue. This research paper provides an ensemble deep learning model using BiLSTM, <a href=https://en.wikipedia.org/wiki/XGBoost>XGBoost</a>, and <a href=https://en.wikipedia.org/wiki/BERT>BERT</a> to detect <a href=https://en.wikipedia.org/wiki/Propaganda>propaganda</a>. The proposed <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> has been applied on the dataset provided by the challenge NLP4IF 2019, Task 1 Sentence Level Classification (SLC) and it shows a significant performance over the baseline model.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Malak+Abdullah" title="Search for 'Malak Abdullah' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/o/ola-altiti/ class=align-middle>Ola Altiti</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/dalya-faraj/ class=align-middle>Dalya Faraj</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/n/nour-al-khdour/ class=align-middle>Nour Al-Khdour</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mutaz-bni-younes/ class=align-middle>Mutaz Bni Younes</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mohammad-al-smadi/ class=align-middle>Mohammad AL-Smadi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/f/fara-shatnawi/ class=align-middle>Fara Shatnawi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mahmoud-hammad/ class=align-middle>Mahmoud Hammad</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rasha-obiedat/ class=align-middle>Rasha Obiedat</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hani-al-omari/ class=align-middle>Hani Al-Omari</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/samira-shaikh/ class=align-middle>Samira Shaikh</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/semeval/ class=align-middle>SemEval</a><span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/wanlp/ class=align-middle>WANLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>