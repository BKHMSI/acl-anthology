<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Milica Gasic - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Milica</span> <span class=font-weight-bold>Gasic</span></h2><p class="font-weight-light text-muted"><span class=font-italic>Also published as:</span>
Milica <span class=font-weight-normal>Gašić</span></p><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.623.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--623 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.623 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.623/>Uncertainty Measures in Neural Belief Tracking and the Effects on Dialogue Policy Performance</a></strong><br><a href=/people/c/carel-van-niekerk/>Carel van Niekerk</a>
|
<a href=/people/a/andrey-malinin/>Andrey Malinin</a>
|
<a href=/people/c/christian-geishauser/>Christian Geishauser</a>
|
<a href=/people/m/michael-heck/>Michael Heck</a>
|
<a href=/people/h/hsien-chin-lin/>Hsien-chin Lin</a>
|
<a href=/people/n/nurul-lubis/>Nurul Lubis</a>
|
<a href=/people/s/shutong-feng/>Shutong Feng</a>
|
<a href=/people/m/milica-gasic/>Milica Gasic</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--623><div class="card-body p-3 small">The ability to identify and resolve <a href=https://en.wikipedia.org/wiki/Uncertainty>uncertainty</a> is crucial for the <a href=https://en.wikipedia.org/wiki/Robustness_(evolution)>robustness</a> of a <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue system</a>. Indeed, this has been confirmed empirically on <a href=https://en.wikipedia.org/wiki/System>systems</a> that utilise <a href=https://en.wikipedia.org/wiki/Bayesian_inference>Bayesian approaches</a> to dialogue belief tracking. However, such <a href=https://en.wikipedia.org/wiki/System>systems</a> consider only <a href=https://en.wikipedia.org/wiki/Confidence_interval>confidence estimates</a> and have difficulty scaling to more complex settings. Neural dialogue systems, on the other hand, rarely take <a href=https://en.wikipedia.org/wiki/Uncertainty>uncertainties</a> into account. They are therefore overconfident in their decisions and less robust. Moreover, the performance of the tracking task is often evaluated in isolation, without consideration of its effect on the downstream policy optimisation. We propose the use of different uncertainty measures in neural belief tracking. The effects of these measures on the downstream task of policy optimisation are evaluated by adding selected measures of <a href=https://en.wikipedia.org/wiki/Uncertainty>uncertainty</a> to the <a href=https://en.wikipedia.org/wiki/Feature_space>feature space</a> of the policy and training policies through interaction with a user simulator. Both human and simulated user results show that incorporating these measures leads to improvements both of the performance and of the <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> of the downstream dialogue policy. This highlights the importance of developing neural dialogue belief trackers that take <a href=https://en.wikipedia.org/wiki/Uncertainty>uncertainty</a> into account.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.75.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--75 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.75 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.75/>Actor-Double-Critic : Incorporating Model-Based Critic for Task-Oriented Dialogue Systems</a></strong><br><a href=/people/y/yen-chen-wu/>Yen-chen Wu</a>
|
<a href=/people/b/bo-hsiang-tseng/>Bo-Hsiang Tseng</a>
|
<a href=/people/m/milica-gasic/>Milica Gasic</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--75><div class="card-body p-3 small">In order to improve the sample-efficiency of deep reinforcement learning (DRL), we implemented imagination augmented agent (I2A) in spoken dialogue systems (SDS). Although I2A achieves a higher success rate than <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> by augmenting predicted future into a policy network, its complicated architecture introduces unwanted instability. In this work, we propose actor-double-critic (ADC) to improve the stability and overall performance of I2A. ADC simplifies the architecture of I2A to reduce excessive parameters and hyper-parameters. More importantly, a separate model-based critic shares parameters between actions and makes <a href=https://en.wikipedia.org/wiki/Backpropagation>back-propagation</a> explicit. In our experiments on Cambridge Restaurant Booking task, ADC enhances success rates considerably and shows robustness to imperfect environment models. In addition, ADC exhibits the stability and sample-efficiency as significantly reducing the baseline standard deviation of success rates and reaching the 80 % success rate with half training data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.findings-emnlp.277.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--findings-emnlp--277 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.findings-emnlp.277 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.findings-emnlp.277/>Knowing What You Know : Calibrating Dialogue Belief State Distributions via Ensembles</a></strong><br><a href=/people/c/carel-van-niekerk/>Carel van Niekerk</a>
|
<a href=/people/m/michael-heck/>Michael Heck</a>
|
<a href=/people/c/christian-geishauser/>Christian Geishauser</a>
|
<a href=/people/h/hsien-chin-lin/>Hsien-chin Lin</a>
|
<a href=/people/n/nurul-lubis/>Nurul Lubis</a>
|
<a href=/people/m/marco-moresi/>Marco Moresi</a>
|
<a href=/people/m/milica-gasic/>Milica Gasic</a><br><a href=/volumes/2020.findings-emnlp/ class=text-muted>Findings of the Association for Computational Linguistics: EMNLP 2020</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--findings-emnlp--277><div class="card-body p-3 small">The ability to accurately track what happens during a conversation is essential for the performance of a <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue system</a>. Current state-of-the-art multi-domain dialogue state trackers achieve just over 55 % accuracy on the current go-to benchmark, which means that in almost every second dialogue turn they place full confidence in an incorrect dialogue state. Belief trackers, on the other hand, maintain a distribution over possible dialogue states. However, they lack in performance compared to dialogue state trackers, and do not produce well calibrated distributions. In this work we present state-of-the-art performance in <a href=https://en.wikipedia.org/wiki/Calibration>calibration</a> for multi-domain dialogue belief trackers using a calibrated ensemble of models. Our resulting dialogue belief tracker also outperforms previous dialogue belief tracking models in terms of <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sigdial-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sigdial-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sigdial-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href="https://youtube.com/watch?v=qWLnp4tPbPM" data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.sigdial-1.4/>TripPy : A Triple Copy Strategy for Value Independent Neural Dialog State Tracking<span class=acl-fixed-case>T</span>rip<span class=acl-fixed-case>P</span>y: A Triple Copy Strategy for Value Independent Neural Dialog State Tracking</a></strong><br><a href=/people/m/michael-heck/>Michael Heck</a>
|
<a href=/people/c/carel-van-niekerk/>Carel van Niekerk</a>
|
<a href=/people/n/nurul-lubis/>Nurul Lubis</a>
|
<a href=/people/c/christian-geishauser/>Christian Geishauser</a>
|
<a href=/people/h/hsien-chin-lin/>Hsien-Chin Lin</a>
|
<a href=/people/m/marco-moresi/>Marco Moresi</a>
|
<a href=/people/m/milica-gasic/>Milica Gasic</a><br><a href=/volumes/2020.sigdial-1/ class=text-muted>Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sigdial-1--4><div class="card-body p-3 small">Task-oriented dialog systems rely on dialog state tracking (DST) to monitor the user&#8217;s goal during the course of an interaction. Multi-domain and open-vocabulary settings complicate the task considerably and demand scalable solutions. In this paper we present a new approach to <a href=https://en.wikipedia.org/wiki/Discrete_cosine_transform>DST</a> which makes use of various copy mechanisms to fill slots with values. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> has no need to maintain a list of candidate values. Instead, all values are extracted from the <a href=https://en.wikipedia.org/wiki/Context_(computing)>dialog context</a> on-the-fly. A slot is filled by one of three copy mechanisms : (1) Span prediction may extract values directly from the user input ; (2) a value may be copied from a system inform memory that keeps track of the system&#8217;s inform operations (3) a value may be copied over from a different slot that is already contained in the dialog state to resolve coreferences within and across domains. Our approach combines the advantages of span-based slot filling methods with memory methods to avoid the use of value picklists altogether. We argue that our <a href=https://en.wikipedia.org/wiki/Strategy>strategy</a> simplifies the DST task while at the same time achieving state of the art performance on various popular evaluation sets including Multiwoz 2.1, where we achieve a joint goal accuracy beyond 55 %.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5900.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5900/>Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue</a></strong><br><a href=/people/s/satoshi-nakamura/>Satoshi Nakamura</a>
|
<a href=/people/m/milica-gasic/>Milica Gasic</a>
|
<a href=/people/i/ingrid-zuckerman/>Ingrid Zuckerman</a>
|
<a href=/people/g/gabriel-skantze/>Gabriel Skantze</a>
|
<a href=/people/m/mikio-nakano/>Mikio Nakano</a>
|
<a href=/people/a/alexandros-papangelis/>Alexandros Papangelis</a>
|
<a href=/people/s/stefan-ultes/>Stefan Ultes</a>
|
<a href=/people/k/koichiro-yoshino/>Koichiro Yoshino</a><br><a href=/volumes/W19-59/ class=text-muted>Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5920.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5920 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5920 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5920/>Tree-Structured Semantic Encoder with Knowledge Sharing for Domain Adaptation in Natural Language Generation</a></strong><br><a href=/people/b/bo-hsiang-tseng/>Bo-Hsiang Tseng</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/y/yen-chen-wu/>Yen-chen Wu</a>
|
<a href=/people/m/milica-gasic/>Milica Gasic</a><br><a href=/volumes/W19-59/ class=text-muted>Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5920><div class="card-body p-3 small">Domain adaptation in natural language generation (NLG) remains challenging because of the high complexity of input semantics across domains and limited data of a target domain. This is particularly the case for dialogue systems, where we want to be able to seamlessly include new domains into the conversation. Therefore, it is crucial for generation models to share knowledge across domains for the effective <a href=https://en.wikipedia.org/wiki/Adaptation>adaptation</a> from one domain to another. In this study, we exploit a tree-structured semantic encoder to capture the internal structure of complex semantic representations required for multi-domain dialogues in order to facilitate knowledge sharing across domains. In addition, a layer-wise attention mechanism between the <a href=https://en.wikipedia.org/wiki/Tree_traversal>tree encoder</a> and the <a href=https://en.wikipedia.org/wiki/Tree_traversal>decoder</a> is adopted to further improve the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s capability. The automatic evaluation results show that our model outperforms previous methods in terms of the BLEU score and the slot error rate, in particular when the <a href=https://en.wikipedia.org/wiki/Adaptation_data>adaptation data</a> is limited. In subjective evaluation, human judges tend to prefer the sentences generated by our model, rating them more highly on informativeness and <a href=https://en.wikipedia.org/wiki/Naturalness_(philosophy)>naturalness</a> than other <a href=https://en.wikipedia.org/wiki/System>systems</a>.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D18-1547.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D18-1547 data-toggle=collapse aria-expanded=false aria-controls=abstract-D18-1547 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/D18-1547.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/306141298 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=D18-1547" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/D18-1547/>MultiWOZ-A Large-Scale Multi-Domain Wizard-of-Oz Dataset for Task-Oriented Dialogue Modelling<span class=acl-fixed-case>M</span>ulti<span class=acl-fixed-case>WOZ</span> - A Large-Scale Multi-Domain <span class=acl-fixed-case>W</span>izard-of-<span class=acl-fixed-case>O</span>z Dataset for Task-Oriented Dialogue Modelling</a></strong><br><a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/t/tsung-hsien-wen/>Tsung-Hsien Wen</a>
|
<a href=/people/b/bo-hsiang-tseng/>Bo-Hsiang Tseng</a>
|
<a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/s/stefan-ultes/>Stefan Ultes</a>
|
<a href=/people/o/osman-ramadan/>Osman Ramadan</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a><br><a href=/volumes/D18-1/ class=text-muted>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D18-1547><div class="card-body p-3 small">Even though <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning</a> has become the major scene in dialogue research community, the real breakthrough has been blocked by the scale of data available. To address this fundamental obstacle, we introduce the Multi-Domain Wizard-of-Oz dataset (MultiWOZ), a fully-labeled collection of human-human written conversations spanning over multiple domains and topics. At a size of 10k dialogues, it is at least one order of magnitude larger than all previous annotated task-oriented corpora. The contribution of this work apart from the open-sourced dataset is two-fold : firstly, a detailed description of the data collection procedure along with a summary of data structure and analysis is provided. The proposed data-collection pipeline is entirely based on <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowd-sourcing</a> without the need of hiring professional annotators;secondly, a set of benchmark results of belief tracking, dialogue act and response generation is reported, which shows the usability of the data and sets a baseline for future studies.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5007.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5007 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5007 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5007/>Neural User Simulation for Corpus-based Policy Optimisation of Spoken Dialogue Systems</a></strong><br><a href=/people/f/florian-kreyssig/>Florian Kreyssig</a>
|
<a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a><br><a href=/volumes/W18-50/ class=text-muted>Proceedings of the 19th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5007><div class="card-body p-3 small">User Simulators are one of the major tools that enable offline training of task-oriented dialogue systems. For this <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a> the Agenda-Based User Simulator (ABUS) is often used. The ABUS is based on hand-crafted rules and its output is in semantic form. Issues arise from both properties such as limited diversity and the inability to interface a text-level belief tracker. This paper introduces the Neural User Simulator (NUS) whose behaviour is learned from a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> and which generates <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>, hence needing a less labelled dataset than simulators generating a semantic output. In comparison to much of the past work on this topic, which evaluates user simulators on corpus-based metrics, we use the <a href=https://en.wikipedia.org/wiki/National_University_of_Singapore>NUS</a> to train the policy of a reinforcement learning based Spoken Dialogue System. The <a href=https://en.wikipedia.org/wiki/National_University_of_Singapore>NUS</a> is compared to the ABUS by evaluating the <a href=https://en.wikipedia.org/wiki/Policy>policies</a> that were trained using the <a href=https://en.wikipedia.org/wiki/Simulation>simulators</a>. Cross-model evaluation is performed i.e. training on one <a href=https://en.wikipedia.org/wiki/Simulation>simulator</a> and testing on the other. Furthermore, the trained <a href=https://en.wikipedia.org/wiki/Policy>policies</a> are tested on real users. In both evaluation tasks the <a href=https://en.wikipedia.org/wiki/NUS>NUS</a> outperformed the <a href=https://en.wikipedia.org/wiki/ABUS>ABUS</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5032.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5032 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5032 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W18-5032.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W18-5032/>Addressing Objects and Their Relations : The Conversational Entity Dialogue Model</a></strong><br><a href=/people/s/stefan-ultes/>Stefan Ultes</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/l/lina-m-rojas-barahona/>Lina M. Rojas-Barahona</a>
|
<a href=/people/b/bo-hsiang-tseng/>Bo-Hsiang Tseng</a>
|
<a href=/people/y/yen-chen-wu/>Yen-Chen Wu</a>
|
<a href=/people/s/steve-young/>Steve Young</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a><br><a href=/volumes/W18-50/ class=text-muted>Proceedings of the 19th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5032><div class="card-body p-3 small">Statistical spoken dialogue systems usually rely on a single- or multi-domain dialogue model that is restricted in its capabilities of modelling complex dialogue structures, e.g., <a href=https://en.wikipedia.org/wiki/Interpersonal_relationship>relations</a>. In this work, we propose a novel dialogue model that is centred around entities and is able to model <a href=https://en.wikipedia.org/wiki/Binary_relation>relations</a> as well as multiple entities of the same type. We demonstrate in a prototype implementation benefits of relation modelling on the dialogue level and show that a trained <a href=https://en.wikipedia.org/wiki/Policy>policy</a> using these <a href=https://en.wikipedia.org/wiki/Binary_relation>relations</a> outperforms the multi-domain baseline. Furthermore, we show that by modelling the <a href=https://en.wikipedia.org/wiki/Binary_relation>relations</a> on the dialogue level, the <a href=https://en.wikipedia.org/wiki/System>system</a> is capable of processing <a href=https://en.wikipedia.org/wiki/Binary_relation>relations</a> present in the user input and even learns to address them in the system response.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5038.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5038 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5038 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5038/>Feudal Dialogue Management with Jointly Learned Feature Extractors</a></strong><br><a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/s/stefan-ultes/>Stefan Ultes</a>
|
<a href=/people/f/florian-kreyssig/>Florian Kreyssig</a>
|
<a href=/people/b/bo-hsiang-tseng/>Bo-Hsiang Tseng</a>
|
<a href=/people/y/yen-chen-wu/>Yen-chen Wu</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a><br><a href=/volumes/W18-50/ class=text-muted>Proceedings of the 19th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5038><div class="card-body p-3 small">Reinforcement learning (RL) is a promising dialogue policy optimisation approach, but traditional RL algorithms fail to scale to large domains. Recently, Feudal Dialogue Management (FDM), has shown to increase the scalability to large domains by decomposing the dialogue management decision into two steps, making use of the domain ontology to abstract the dialogue state in each step. In order to abstract the <a href=https://en.wikipedia.org/wiki/State_space>state space</a>, however, previous work on <a href=https://en.wikipedia.org/wiki/Finite-state_machine>FDM</a> relies on handcrafted feature functions. In this work, we show that these <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature functions</a> can be learned jointly with the <a href=https://en.wikipedia.org/wiki/Policy_model>policy model</a> while obtaining similar performance, even outperforming the handcrafted features in several environments and domains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5039.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5039 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5039 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5039/>Variational Cross-domain Natural Language Generation for Spoken Dialogue Systems</a></strong><br><a href=/people/b/bo-hsiang-tseng/>Bo-Hsiang Tseng</a>
|
<a href=/people/f/florian-kreyssig/>Florian Kreyssig</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/y/yen-chen-wu/>Yen-Chen Wu</a>
|
<a href=/people/s/stefan-ultes/>Stefan Ultes</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a><br><a href=/volumes/W18-50/ class=text-muted>Proceedings of the 19th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5039><div class="card-body p-3 small">Cross-domain natural language generation (NLG) is still a difficult task within spoken dialogue modelling. Given a <a href=https://en.wikipedia.org/wiki/Semantics>semantic representation</a> provided by the <a href=https://en.wikipedia.org/wiki/Dialogue_manager>dialogue manager</a>, the language generator should generate sentences that convey desired information. Traditional template-based generators can produce sentences with all necessary information, but these sentences are not sufficiently diverse. With RNN-based models, the diversity of the generated sentences can be high, however, in the process some information is lost. In this work, we improve an RNN-based generator by considering latent information at the sentence level during generation using conditional variational auto-encoder architecture. We demonstrate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms the original RNN-based generator, while yielding highly diverse sentences. In addition, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performs better when the training data is limited.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-2112.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-2112 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-2112 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-2112/>Feudal Reinforcement Learning for <a href=https://en.wikipedia.org/wiki/Dialogue_management>Dialogue Management</a> in Large Domains</a></strong><br><a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/p/pei-hao-su/>Pei-Hao Su</a>
|
<a href=/people/s/stefan-ultes/>Stefan Ultes</a>
|
<a href=/people/l/lina-m-rojas-barahona/>Lina M. Rojas-Barahona</a>
|
<a href=/people/b/bo-hsiang-tseng/>Bo-Hsiang Tseng</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a><br><a href=/volumes/N18-2/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-2112><div class="card-body p-3 small">Reinforcement learning (RL) is a promising approach to solve dialogue policy optimisation. Traditional RL algorithms, however, fail to scale to large domains due to the curse of dimensionality. We propose a novel Dialogue Management architecture, based on Feudal RL, which decomposes the decision into two steps ; a first step where a master policy selects a subset of primitive actions, and a second step where a primitive action is chosen from the selected subset. The structural information included in the <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>domain ontology</a> is used to abstract the dialogue state space, taking the decisions at each step using different parts of the abstracted state. This, combined with an information sharing mechanism between slots, increases the scalability to <a href=https://en.wikipedia.org/wiki/Domain_(software_engineering)>large domains</a>. We show that an implementation of this approach, based on Deep-Q Networks, significantly outperforms previous state of the art in several dialogue domains and environments, without the need of any additional reward signal.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5509.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5509 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5509 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5509/>Reward-Balancing for Statistical Spoken Dialogue Systems using Multi-objective Reinforcement Learning</a></strong><br><a href=/people/s/stefan-ultes/>Stefan Ultes</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/n/nikola-mrksic/>Nikola Mrkšić</a>
|
<a href=/people/l/lina-m-rojas-barahona/>Lina M. Rojas-Barahona</a>
|
<a href=/people/p/pei-hao-su/>Pei-Hao Su</a>
|
<a href=/people/t/tsung-hsien-wen/>Tsung-Hsien Wen</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a>
|
<a href=/people/s/steve-young/>Steve Young</a><br><a href=/volumes/W17-55/ class=text-muted>Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5509><div class="card-body p-3 small">Reinforcement learning is widely used for dialogue policy optimization where the <a href=https://en.wikipedia.org/wiki/Reward_system>reward function</a> often consists of more than one <a href=https://en.wikipedia.org/wiki/Function_(mathematics)>component</a>, e.g., the dialogue success and the dialogue length. In this work, we propose a structured method for finding a good balance between these components by searching for the optimal reward component weighting. To render this search feasible, we use multi-objective reinforcement learning to significantly reduce the number of training dialogues required. We apply our proposed method to find optimized component weights for six domains and compare them to a default baseline.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5512.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5512 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5512 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5512/>Sub-domain Modelling for <a href=https://en.wikipedia.org/wiki/Dialogue_management>Dialogue Management</a> with Hierarchical Reinforcement Learning</a></strong><br><a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/s/stefan-ultes/>Stefan Ultes</a>
|
<a href=/people/p/pei-hao-su/>Pei-Hao Su</a>
|
<a href=/people/n/nikola-mrksic/>Nikola Mrkšić</a>
|
<a href=/people/t/tsung-hsien-wen/>Tsung-Hsien Wen</a>
|
<a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/l/lina-m-rojas-barahona/>Lina M. Rojas-Barahona</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a><br><a href=/volumes/W17-55/ class=text-muted>Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5512><div class="card-body p-3 small">Human conversation is inherently complex, often spanning many different topics / domains. This makes <a href=https://en.wikipedia.org/wiki/Policy_learning>policy learning</a> for <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue systems</a> very challenging. Standard flat reinforcement learning methods do not provide an efficient <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> for modelling such <a href=https://en.wikipedia.org/wiki/Dialogue>dialogues</a>. In this paper, we focus on the under-explored problem of multi-domain dialogue management. First, we propose a new <a href=https://en.wikipedia.org/wiki/Methodology>method</a> for hierarchical reinforcement learning using the option framework. Next, we show that the proposed <a href=https://en.wikipedia.org/wiki/Architecture>architecture</a> learns faster and arrives at a better <a href=https://en.wikipedia.org/wiki/Policy>policy</a> than the existing flat ones do. Moreover, we show how pretrained policies can be adapted to more complex systems with an additional set of new actions. In doing that, we show that our approach has the potential to facilitate policy optimisation for more sophisticated multi-domain dialogue systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5518.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5518 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5518 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5518/>Sample-efficient Actor-Critic Reinforcement Learning with Supervised Data for Dialogue Management</a></strong><br><a href=/people/p/pei-hao-su/>Pei-Hao Su</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/s/stefan-ultes/>Stefan Ultes</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a>
|
<a href=/people/s/steve-young/>Steve Young</a><br><a href=/volumes/W17-55/ class=text-muted>Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5518><div class="card-body p-3 small">Deep reinforcement learning (RL) methods have significant potential for dialogue policy optimisation. However, <a href=https://en.wikipedia.org/wiki/They_(2017_film)>they</a> suffer from a poor performance in the early stages of learning. This is especially problematic for <a href=https://en.wikipedia.org/wiki/Educational_technology>on-line learning</a> with real users. Two <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>approaches</a> are introduced to tackle this problem. Firstly, to speed up the learning process, two sample-efficient neural networks algorithms : trust region actor-critic with experience replay (TRACER) and episodic natural actor-critic with experience replay (eNACER) are presented. For TRACER, the <a href=https://en.wikipedia.org/wiki/Trust_region>trust region</a> helps to control the learning step size and avoid catastrophic model changes. For eNACER, the natural gradient identifies the steepest ascent direction in policy space to speed up the <a href=https://en.wikipedia.org/wiki/Convergence_of_random_variables>convergence</a>. Both models employ off-policy learning with experience replay to improve sample-efficiency. Secondly, to mitigate the cold start issue, a corpus of demonstration data is utilised to pre-train the models prior to on-line reinforcement learning. Combining these two approaches, we demonstrate a practical approach to learn deep RL-based dialogue policies and demonstrate their effectiveness in a task-oriented information seeking domain.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q17-1022.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q17-1022 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q17-1022 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/Q17-1022/>Semantic Specialization of Distributional Word Vector Spaces using Monolingual and Cross-Lingual Constraints</a></strong><br><a href=/people/n/nikola-mrksic/>Nikola Mrkšić</a>
|
<a href=/people/i/ivan-vulic/>Ivan Vulić</a>
|
<a href=/people/d/diarmuid-o-seaghdha/>Diarmuid Ó Séaghdha</a>
|
<a href=/people/i/ira-leviant/>Ira Leviant</a>
|
<a href=/people/r/roi-reichart/>Roi Reichart</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a>
|
<a href=/people/a/anna-korhonen/>Anna Korhonen</a>
|
<a href=/people/s/steve-young/>Steve Young</a><br><a href=/volumes/Q17-1/ class=text-muted>Transactions of the Association for Computational Linguistics, Volume 5</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q17-1022><div class="card-body p-3 small">We present Attract-Repel, an <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> for improving the semantic quality of word vectors by injecting constraints extracted from lexical resources. Attract-Repel facilitates the use of constraints from mono- and cross-lingual resources, yielding semantically specialized cross-lingual vector spaces. Our evaluation shows that the method can make use of existing cross-lingual lexicons to construct high-quality vector spaces for a plethora of different languages, facilitating semantic transfer from high- to lower-resource ones. The effectiveness of our approach is demonstrated with state-of-the-art results on semantic similarity datasets in six languages. We next show that Attract-Repel-specialized vectors boost performance in the downstream task of dialogue state tracking (DST) across multiple languages. Finally, we show that cross-lingual vector spaces produced by our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> facilitate the training of multilingual DST models, which brings further performance improvements.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-1042.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-1042 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-1042 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-1042/>A Network-based End-to-End Trainable Task-oriented Dialogue System</a></strong><br><a href=/people/t/tsung-hsien-wen/>Tsung-Hsien Wen</a>
|
<a href=/people/d/david-vandyke/>David Vandyke</a>
|
<a href=/people/n/nikola-mrksic/>Nikola Mrkšić</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a>
|
<a href=/people/l/lina-m-rojas-barahona/>Lina M. Rojas-Barahona</a>
|
<a href=/people/p/pei-hao-su/>Pei-Hao Su</a>
|
<a href=/people/s/stefan-ultes/>Stefan Ultes</a>
|
<a href=/people/s/steve-young/>Steve Young</a><br><a href=/volumes/E17-1/ class=text-muted>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-1042><div class="card-body p-3 small">Teaching machines to accomplish tasks by conversing naturally with humans is challenging. Currently, developing task-oriented dialogue systems requires creating multiple components and typically this involves either a large amount of <a href=https://en.wikipedia.org/wiki/Handicraft>handcrafting</a>, or acquiring costly labelled datasets to solve a statistical learning problem for each component. In this work we introduce a neural network-based text-in, text-out end-to-end trainable goal-oriented dialogue system along with a new way of collecting dialogue data based on a novel pipe-lined Wizard-of-Oz framework. This approach allows us to develop <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue systems</a> easily and without making too many assumptions about the task at hand. The results show that the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> can converse with human subjects naturally whilst helping them to accomplish tasks in a restaurant search domain.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Milica+Gasic" title="Search for 'Milica Gasic' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/s/stefan-ultes/ class=align-middle>Stefan Ultes</a>
<span class="badge badge-secondary align-middle ml-2">10</span></li><li class=list-group-item><a href=/people/p/pawel-budzianowski/ class=align-middle>Paweł Budzianowski</a>
<span class="badge badge-secondary align-middle ml-2">10</span></li><li class=list-group-item><a href=/people/i/inigo-casanueva/ class=align-middle>Iñigo Casanueva</a>
<span class="badge badge-secondary align-middle ml-2">8</span></li><li class=list-group-item><a href=/people/b/bo-hsiang-tseng/ class=align-middle>Bo-Hsiang Tseng</a>
<span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/people/l/lina-m-rojas-barahona/ class=align-middle>Lina M. Rojas Barahona</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/p/pei-hao-su/ class=align-middle>Pei-Hao Su</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/s/steve-young/ class=align-middle>Steve Young</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/y/yen-chen-wu/ class=align-middle>Yen-Chen Wu</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/n/nikola-mrksic/ class=align-middle>Nikola Mrkšić</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/t/tsung-hsien-wen/ class=align-middle>Tsung-Hsien Wen</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/c/carel-van-niekerk/ class=align-middle>Carel van Niekerk</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/c/christian-geishauser/ class=align-middle>Christian Geishauser</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/m/michael-heck/ class=align-middle>Michael Heck</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/h/hsien-chin-lin/ class=align-middle>Hsien-Chin Lin</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/n/nurul-lubis/ class=align-middle>Nurul Lubis</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/f/florian-kreyssig/ class=align-middle>Florian Kreyssig</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/m/marco-moresi/ class=align-middle>Marco Moresi</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/i/ivan-vulic/ class=align-middle>Ivan Vulić</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/diarmuid-o-seaghdha/ class=align-middle>Diarmuid Ó Séaghdha</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ira-leviant/ class=align-middle>Ira Leviant</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/roi-reichart/ class=align-middle>Roi Reichart</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anna-korhonen/ class=align-middle>Anna Korhonen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/o/osman-ramadan/ class=align-middle>Osman Ramadan</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andrey-malinin/ class=align-middle>Andrey Malinin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/shutong-feng/ class=align-middle>Shutong Feng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/satoshi-nakamura/ class=align-middle>Satoshi Nakamura</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ingrid-zuckerman/ class=align-middle>Ingrid Zuckerman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/gabriel-skantze/ class=align-middle>Gabriel Skantze</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mikio-nakano/ class=align-middle>Mikio Nakano</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexandros-papangelis/ class=align-middle>Alexandros Papangelis</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/koichiro-yoshino/ class=align-middle>Koichiro Yoshino</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/david-vandyke/ class=align-middle>David Vandyke</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">9</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/findings/ class=align-middle>Findings</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/tacl/ class=align-middle>TACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/eacl/ class=align-middle>EACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/sigdial/ class=align-middle>SIGDIAL</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>