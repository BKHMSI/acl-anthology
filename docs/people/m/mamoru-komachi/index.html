<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Mamoru Komachi - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Mamoru</span> <span class=font-weight-bold>Komachi</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-srw.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-srw--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-srw.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-srw.15/>Modeling Text using the Continuous Space Topic Model with Pre-Trained Word Embeddings</a></strong><br><a href=/people/s/seiichi-inoue/>Seiichi Inoue</a>
|
<a href=/people/t/taichi-aida/>Taichi Aida</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a>
|
<a href=/people/m/manabu-asai/>Manabu Asai</a><br><a href=/volumes/2021.acl-srw/ class=text-muted>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: Student Research Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-srw--15><div class="card-body p-3 small">In this study, we propose a model that extends the continuous space topic model (CSTM), which flexibly controls word probability in a document, using pre-trained word embeddings. To develop the proposed model, we pre-train word embeddings, which capture the semantics of words and plug them into the CSTM. Intrinsic experimental results show that the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> exhibits a superior performance over the CSTM in terms of <a href=https://en.wikipedia.org/wiki/Perplexity>perplexity</a> and <a href=https://en.wikipedia.org/wiki/Convergence_of_random_variables>convergence speed</a>. Furthermore, extrinsic experimental results show that the proposed <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> is useful for a document classification task when compared with the baseline model. We qualitatively show that the latent coordinates obtained by training the proposed <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> are better than those of the baseline model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.197.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--197 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.197 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.197" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.197/>From Masked Language Modeling to <a href=https://en.wikipedia.org/wiki/Translation>Translation</a> : Non-English Auxiliary Tasks Improve Zero-shot Spoken Language Understanding<span class=acl-fixed-case>E</span>nglish Auxiliary Tasks Improve Zero-shot Spoken Language Understanding</a></strong><br><a href=/people/r/rob-van-der-goot/>Rob van der Goot</a>
|
<a href=/people/i/ibrahim-sharaf/>Ibrahim Sharaf</a>
|
<a href=/people/a/aizhan-imankulova/>Aizhan Imankulova</a>
|
<a href=/people/a/ahmet-ustun/>Ahmet Üstün</a>
|
<a href=/people/m/marija-stepanovic/>Marija Stepanović</a>
|
<a href=/people/a/alan-ramponi/>Alan Ramponi</a>
|
<a href=/people/s/siti-oryza-khairunnisa/>Siti Oryza Khairunnisa</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a>
|
<a href=/people/b/barbara-plank/>Barbara Plank</a><br><a href=/volumes/2021.naacl-main/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--197><div class="card-body p-3 small">The lack of publicly available evaluation data for low-resource languages limits progress in Spoken Language Understanding (SLU). As key tasks like intent classification and slot filling require abundant training data, it is desirable to reuse existing <a href=https://en.wikipedia.org/wiki/Data>data</a> in high-resource languages to develop models for low-resource scenarios. We introduce xSID, a new benchmark for cross-lingual (x) Slot and Intent Detection in 13 languages from 6 language families, including a very low-resource dialect. To tackle the challenge, we propose a joint learning approach, with English SLU training data and non-English auxiliary tasks from raw text, <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a> and <a href=https://en.wikipedia.org/wiki/Translation>translation</a> for transfer. We study two setups which differ by type and language coverage of the pre-trained embeddings. Our results show that jointly learning the main tasks with masked language modeling is effective for slots, while machine translation transfer works best for intent classification.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-srw.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-srw--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-srw.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-srw.16/>Comparison of <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>Grammatical Error Correction</a> Using Back-Translation Models</a></strong><br><a href=/people/a/aomi-koyama/>Aomi Koyama</a>
|
<a href=/people/k/kengo-hotate/>Kengo Hotate</a>
|
<a href=/people/m/masahiro-kaneko/>Masahiro Kaneko</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a><br><a href=/volumes/2021.naacl-srw/ class=text-muted>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-srw--16><div class="card-body p-3 small">Grammatical error correction (GEC) suffers from a lack of sufficient parallel data. Studies on GEC have proposed several methods to generate pseudo data, which comprise pairs of grammatical and artificially produced ungrammatical sentences. Currently, a mainstream approach to generate pseudo data is back-translation (BT). Most previous studies using <a href=https://en.wikipedia.org/wiki/BT_Group>BT</a> have employed the same <a href=https://en.wikipedia.org/wiki/Computer_architecture>architecture</a> for both the GEC and BT models. However, GEC models have different correction tendencies depending on the architecture of their <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. Thus, in this study, we compare the correction tendencies of GEC models trained on pseudo data generated by three BT models with different architectures, namely, Transformer, CNN, and LSTM. The results confirm that the correction tendencies for each error type are different for every BT model. In addition, we investigate the correction tendencies when using a combination of pseudo data generated by different BT models. As a result, we find that the combination of different BT models improves or interpolates the performance of each error type compared with using a single BT model with different seeds.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wat-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wat-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wat-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wat-1.13/>TMU NMT System with Japanese BART for the Patent task of WAT 2021<span class=acl-fixed-case>TMU</span> <span class=acl-fixed-case>NMT</span> System with <span class=acl-fixed-case>J</span>apanese <span class=acl-fixed-case>BART</span> for the Patent task of <span class=acl-fixed-case>WAT</span> 2021</a></strong><br><a href=/people/h/hwichan-kim/>Hwichan Kim</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a><br><a href=/volumes/2021.wat-1/ class=text-muted>Proceedings of the 8th Workshop on Asian Translation (WAT2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wat-1--13><div class="card-body p-3 small">In this paper, we introduce our TMU Neural Machine Translation (NMT) system submitted for the Patent task (Korean Japanese and English Japanese) of 8th Workshop on Asian Translation (Nakazawa et al., 2021). Recently, several studies proposed pre-trained encoder-decoder models using monolingual data. One of the pre-trained models, BART (Lewis et al., 2020), was shown to improve translation accuracy via fine-tuning with bilingual data. However, they experimented only Romanian!English translation using <a href=https://en.wikipedia.org/wiki/BART>English BART</a>. In this paper, we examine the effectiveness of Japanese BART using Japan Patent Office Corpus 2.0. Our experiments indicate that Japanese BART can also improve translation accuracy in both Korean Japanese and English Japanese translations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wat-1.20.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wat-1--20 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wat-1.20 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wat-1.20/>TMEKU System for the WAT2021 Multimodal Translation Task<span class=acl-fixed-case>TMEKU</span> System for the <span class=acl-fixed-case>WAT</span>2021 Multimodal Translation Task</a></strong><br><a href=/people/y/yuting-zhao/>Yuting Zhao</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a>
|
<a href=/people/t/tomoyuki-kajiwara/>Tomoyuki Kajiwara</a>
|
<a href=/people/c/chenhui-chu/>Chenhui Chu</a><br><a href=/volumes/2021.wat-1/ class=text-muted>Proceedings of the 8th Workshop on Asian Translation (WAT2021)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wat-1--20><div class="card-body p-3 small">We introduce our TMEKU system submitted to the English-Japanese Multimodal Translation Task for WAT 2021. We participated in the Flickr30kEnt-JP task and Ambiguous MSCOCO Multimodal task under the constrained condition using only the officially provided datasets. Our proposed system employs soft alignment of word-region for multimodal neural machine translation (MNMT). The experimental results evaluated on the BLEU metric provided by the WAT 2021 evaluation site show that the TMEKU system has achieved the best performance among all the participated systems. Further analysis of the case study demonstrates that leveraging word-region alignment between the textual and visual modalities is the key to performance enhancement in our TMEKU system, which leads to better visual information use.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.eamt-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--eamt-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.eamt-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.eamt-1.12/>Double Attention-based Multimodal Neural Machine Translation with Semantic Image Regions</a></strong><br><a href=/people/y/yuting-zhao/>Yuting Zhao</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a>
|
<a href=/people/t/tomoyuki-kajiwara/>Tomoyuki Kajiwara</a>
|
<a href=/people/c/chenhui-chu/>Chenhui Chu</a><br><a href=/volumes/2020.eamt-1/ class=text-muted>Proceedings of the 22nd Annual Conference of the European Association for Machine Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--eamt-1--12><div class="card-body p-3 small">Existing studies on multimodal neural machine translation (MNMT) have mainly focused on the effect of combining visual and textual modalities to improve translations. However, it has been suggested that the <a href=https://en.wikipedia.org/wiki/Visual_system>visual modality</a> is only marginally beneficial. Conventional visual attention mechanisms have been used to select the visual features from equally-sized grids generated by convolutional neural networks (CNNs), and may have had modest effects on aligning the visual concepts associated with textual objects, because the grid visual features do not capture semantic information. In contrast, we propose the application of semantic image regions for MNMT by integrating visual and textual features using two individual attention mechanisms (double attention). We conducted experiments on the Multi30k dataset and achieved an improvement of 0.5 and 0.9 BLEU points for English-German and English-French translation tasks, compared with the MNMT with grid visual features. We also demonstrated concrete improvements on <a href=https://en.wikipedia.org/wiki/Translation>translation</a> performance benefited from semantic image regions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-srw.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-srw--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-srw.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38928636 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-srw.5/>Grammatical Error Correction Using Pseudo Learner Corpus Considering Learner’s Error Tendency</a></strong><br><a href=/people/y/yujin-takahashi/>Yujin Takahashi</a>
|
<a href=/people/s/satoru-katsumata/>Satoru Katsumata</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a><br><a href=/volumes/2020.acl-srw/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-srw--5><div class="card-body p-3 small">Recently, several studies have focused on improving the performance of grammatical error correction (GEC) tasks using pseudo data. However, a large amount of pseudo data are required to train an accurate GEC model. To address the limitations of language and computational resources, we assume that introducing pseudo errors into sentences similar to those written by the language learners is more efficient, rather than incorporating random pseudo errors into monolingual data. In this regard, we study the effect of pseudo data on GEC task performance using two approaches. First, we extract sentences that are similar to the learners&#8217; sentences from monolingual data. Second, we generate realistic pseudo errors by considering error types that learners often make. Based on our comparative results, we observe that <a href=https://en.wikipedia.org/wiki/F-number>F0.5 scores</a> for the Russian GEC task are significantly improved.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.coling-main.415.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--coling-main--415 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.coling-main.415 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.coling-main.415/>Cross-lingual Transfer Learning for Grammatical Error Correction</a></strong><br><a href=/people/i/ikumi-yamashita/>Ikumi Yamashita</a>
|
<a href=/people/s/satoru-katsumata/>Satoru Katsumata</a>
|
<a href=/people/m/masahiro-kaneko/>Masahiro Kaneko</a>
|
<a href=/people/a/aizhan-imankulova/>Aizhan Imankulova</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a><br><a href=/volumes/2020.coling-main/ class=text-muted>Proceedings of the 28th International Conference on Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--coling-main--415><div class="card-body p-3 small">In this study, we explore cross-lingual transfer learning in grammatical error correction (GEC) tasks. Many languages lack the resources required to train <a href=https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units>GEC models</a>. Cross-lingual transfer learning from high-resource languages (the source models) is effective for training models of low-resource languages (the target models) for various tasks. However, in GEC tasks, the possibility of transferring grammatical knowledge (e.g., grammatical functions) across languages is not evident. Therefore, we investigate cross-lingual transfer learning methods for GEC. Our results demonstrate that <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> from other languages can improve the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of <a href=https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units>GEC</a>. We also demonstrate that proximity to source languages has a significant impact on the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of correcting certain types of errors.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.wmt-1.70.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--wmt-1--70 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.wmt-1.70 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939559 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.wmt-1.70" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.wmt-1.70/>Towards Multimodal Simultaneous Neural Machine Translation</a></strong><br><a href=/people/a/aizhan-imankulova/>Aizhan Imankulova</a>
|
<a href=/people/m/masahiro-kaneko/>Masahiro Kaneko</a>
|
<a href=/people/t/tosho-hirasawa/>Tosho Hirasawa</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a><br><a href=/volumes/2020.wmt-1/ class=text-muted>Proceedings of the Fifth Conference on Machine Translation</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--wmt-1--70><div class="card-body p-3 small">Simultaneous translation involves translating a sentence before the speaker&#8217;s utterance is completed in order to realize real-time understanding in multiple languages. This task is significantly more challenging than the general full sentence translation because of the shortage of input information during decoding. To alleviate this shortage, we propose multimodal simultaneous neural machine translation (MSNMT), which leverages visual information as an additional modality. Our experiments with the Multi30k dataset showed that MSNMT significantly outperforms its text-only counterpart in more timely translation situations with low latency. Furthermore, we verified the importance of visual information during decoding by performing an adversarial evaluation of MSNMT, where we studied how models behaved with incongruent input modality and analyzed the effect of different word order between source and target languages.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-4431.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-4431 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-4431 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-4431/>Grammatical-Error-Aware Incorrect Example Retrieval System for Learners of <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a> as a Second Language<span class=acl-fixed-case>J</span>apanese as a Second Language</a></strong><br><a href=/people/m/mio-arai/>Mio Arai</a>
|
<a href=/people/m/masahiro-kaneko/>Masahiro Kaneko</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a><br><a href=/volumes/W19-44/ class=text-muted>Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-4431><div class="card-body p-3 small">Existing example retrieval systems do not include grammatically incorrect examples or present only a few examples, if any. Even if a retrieval system has a wide coverage of incorrect examples along with the correct counterpart, learners need to know whether their query includes errors or not. Considering the usability of retrieving incorrect examples, our proposed method uses a large-scale corpus and presents correct expressions along with incorrect expressions using a grammatical error detection system so that the learner do not need to be aware of how to search for the examples. Intrinsic and extrinsic evaluations indicate that our method improves accuracy of example sentence retrieval and quality of learner&#8217;s writing.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5360.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5360 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5360 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5360/>Filtering Pseudo-References by Paraphrasing for Automatic Evaluation of <a href=https://en.wikipedia.org/wiki/Machine_translation>Machine Translation</a></a></strong><br><a href=/people/r/ryoma-yoshimura/>Ryoma Yoshimura</a>
|
<a href=/people/h/hiroki-shimanaka/>Hiroki Shimanaka</a>
|
<a href=/people/y/yukio-matsumura/>Yukio Matsumura</a>
|
<a href=/people/h/hayahide-yamagishi/>Hayahide Yamagishi</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a><br><a href=/volumes/W19-53/ class=text-muted>Proceedings of the Fourth Conference on Machine Translation (Volume 2: Shared Task Papers, Day 1)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5360><div class="card-body p-3 small">In this paper, we introduce our participation in the WMT 2019 Metric Shared Task. We propose an improved version of <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence BLEU</a> using filtered pseudo-references. We propose a method to filter pseudo-references by <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrasing</a> for automatic evaluation of machine translation (MT). We use the outputs of off-the-shelf MT systems as pseudo-references filtered by <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrasing</a> in addition to a single human reference (gold reference). We use BERT fine-tuned with paraphrase corpus to filter pseudo-references by checking the paraphrasability with the gold reference. Our experimental results of the WMT 2016 and 2017 datasets show that our method achieved higher correlation with human evaluation than the sentence BLEU (SentBLEU) baselines with a single reference and with unfiltered pseudo-references.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-3012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-3012 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-3012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N19-3012.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/355800547 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-3012" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N19-3012/>Multimodal Machine Translation with Embedding Prediction</a></strong><br><a href=/people/t/tosho-hirasawa/>Tosho Hirasawa</a>
|
<a href=/people/h/hayahide-yamagishi/>Hayahide Yamagishi</a>
|
<a href=/people/y/yukio-matsumura/>Yukio Matsumura</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a><br><a href=/volumes/N19-3/ class=text-muted>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-3012><div class="card-body p-3 small">Multimodal machine translation is an attractive application of neural machine translation (NMT). It helps computers to deeply understand <a href=https://en.wikipedia.org/wiki/Visual_system>visual objects</a> and their relations with <a href=https://en.wikipedia.org/wiki/Natural_language>natural languages</a>. However, multimodal NMT systems suffer from a shortage of available training data, resulting in poor performance for translating rare words. In NMT, pretrained word embeddings have been shown to improve NMT of low-resource domains, and a search-based approach is proposed to address the rare word problem. In this study, we effectively combine these two approaches in the context of multimodal NMT and explore how we can take full advantage of pretrained word embeddings to better translate rare words. We report overall performance improvements of 1.24 METEOR and 2.49 BLEU and achieve an improvement of 7.67 <a href=https://en.wikipedia.org/wiki/F-score>F-score</a> for rare word translation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-2020.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-2020 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-2020 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-2020/>Controlling Grammatical Error Correction Using Word Edit Rate</a></strong><br><a href=/people/k/kengo-hotate/>Kengo Hotate</a>
|
<a href=/people/m/masahiro-kaneko/>Masahiro Kaneko</a>
|
<a href=/people/s/satoru-katsumata/>Satoru Katsumata</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a><br><a href=/volumes/P19-2/ class=text-muted>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-2020><div class="card-body p-3 small">When professional English teachers correct grammatically erroneous sentences written by English learners, they use various methods. The correction method depends on how much corrections a learner requires. In this paper, we propose a method for neural grammar error correction (GEC) that can control the degree of correction. We show that it is possible to actually control the degree of GEC by using new training data annotated with word edit rate. Thereby, diverse corrected sentences is obtained from a single erroneous sentence. Moreover, compared to a GEC model that does not use information on the degree of correction, the proposed method improves correction accuracy.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3700.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3700/>Proceedings of the 5th Workshop on Natural Language Processing Techniques for Educational Applications</a></strong><br><a href=/people/y/yuen-hsien-tseng/>Yuen-Hsien Tseng</a>
|
<a href=/people/h/hsin-hsi-chen/>Hsin-Hsi Chen</a>
|
<a href=/people/v/vincent-ng/>Vincent Ng</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a><br><a href=/volumes/W18-37/ class=text-muted>Proceedings of the 5th Workshop on Natural Language Processing Techniques for Educational Applications</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6456.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6456 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6456 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W18-6456" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W18-6456/>RUSE : Regressor Using Sentence Embeddings for Automatic Machine Translation Evaluation<span class=acl-fixed-case>RUSE</span>: Regressor Using Sentence Embeddings for Automatic Machine Translation Evaluation</a></strong><br><a href=/people/h/hiroki-shimanaka/>Hiroki Shimanaka</a>
|
<a href=/people/t/tomoyuki-kajiwara/>Tomoyuki Kajiwara</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a><br><a href=/volumes/W18-64/ class=text-muted>Proceedings of the Third Conference on Machine Translation: Shared Task Papers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6456><div class="card-body p-3 small">We introduce the RUSE metric for the WMT18 metrics shared task. Sentence embeddings can capture global information that can not be captured by local features based on character or word N-grams. Although training <a href=https://en.wikipedia.org/wiki/Sentence_embedding>sentence embeddings</a> using small-scale translation datasets with manual evaluation is difficult, <a href=https://en.wikipedia.org/wiki/Sentence_embedding>sentence embeddings</a> trained from large-scale data in other tasks can improve the automatic evaluation of <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. We use a multi-layer perceptron regressor based on three types of <a href=https://en.wikipedia.org/wiki/Sentence_embedding>sentence embeddings</a>. The experimental results of the WMT16 and WMT17 datasets show that the RUSE metric achieves a state-of-the-art performance in both segment- and system-level metrics tasks with embedding features only.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-4014.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-4014 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-4014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-4014/>Japanese Predicate Conjugation for Neural Machine Translation<span class=acl-fixed-case>J</span>apanese Predicate Conjugation for Neural Machine Translation</a></strong><br><a href=/people/m/michiki-kurosawa/>Michiki Kurosawa</a>
|
<a href=/people/y/yukio-matsumura/>Yukio Matsumura</a>
|
<a href=/people/h/hayahide-yamagishi/>Hayahide Yamagishi</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a><br><a href=/volumes/N18-4/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-4014><div class="card-body p-3 small">Neural machine translation (NMT) has a drawback in that can generate only high-frequency words owing to the computational costs of the <a href=https://en.wikipedia.org/wiki/Softmax_function>softmax function</a> in the output layer. In Japanese-English NMT, Japanese predicate conjugation causes an increase in <a href=https://en.wikipedia.org/wiki/Japanese_vocabulary>vocabulary size</a>. For example, one verb can have as many as 19 surface varieties. In this research, we focus on <a href=https://en.wikipedia.org/wiki/Grammatical_conjugation>predicate conjugation</a> for compressing the vocabulary size in <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a>. The vocabulary list is filled with the various forms of verbs. We propose methods using predicate conjugation information without discarding <a href=https://en.wikipedia.org/wiki/Linguistic_description>linguistic information</a>. The proposed <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> can generate low-frequency words and deal with unknown words. Two methods were considered to introduce conjugation information : the first considers it as a token (conjugation token) and the second considers it as an embedded vector (conjugation feature). The results using these methods demonstrate that the vocabulary size can be compressed by approximately 86.1 % (Tanaka corpus) and the NMT models can output the words not in the training data set. Furthermore, BLEU scores improved by 0.91 points in <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese-to-English translation</a>, and 0.32 points in <a href=https://en.wikipedia.org/wiki/Japanese_language>English-to-Japanese translation</a> with <a href=https://en.wikipedia.org/wiki/ASPEC>ASPEC</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-4015.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-4015 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-4015 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-4015/>Metric for Automatic Machine Translation Evaluation based on Universal Sentence Representations</a></strong><br><a href=/people/h/hiroki-shimanaka/>Hiroki Shimanaka</a>
|
<a href=/people/t/tomoyuki-kajiwara/>Tomoyuki Kajiwara</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a><br><a href=/volumes/N18-4/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Student Research Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-4015><div class="card-body p-3 small">Sentence representations can capture a wide range of information that can not be captured by local features based on character or word N-grams. This paper examines the usefulness of universal sentence representations for evaluating the quality of <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. Al-though it is difficult to train sentence representations using small-scale translation datasets with manual evaluation, sentence representations trained from large-scale data in other tasks can improve the automatic evaluation of <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. Experimental results of the WMT-2016 dataset show that the proposed method achieves state-of-the-art performance with sentence representation features only.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-3016.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-3016 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-3016 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-3016" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-3016/>Graph-based Filtering of Out-of-Vocabulary Words for Encoder-Decoder Models</a></strong><br><a href=/people/s/satoru-katsumata/>Satoru Katsumata</a>
|
<a href=/people/y/yukio-matsumura/>Yukio Matsumura</a>
|
<a href=/people/h/hayahide-yamagishi/>Hayahide Yamagishi</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a><br><a href=/volumes/P18-3/ class=text-muted>Proceedings of ACL 2018, Student Research Workshop</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-3016><div class="card-body p-3 small">Encoder-decoder models typically only employ words that are frequently used in the training corpus because of the computational costs and/or to exclude noisy words. However, this vocabulary set may still include words that interfere with learning in encoder-decoder models. This paper proposes a method for selecting more suitable words for learning encoders by utilizing not only <a href=https://en.wikipedia.org/wiki/Frequency>frequency</a>, but also <a href=https://en.wikipedia.org/wiki/Co-occurrence>co-occurrence information</a>, which we capture using the <a href=https://en.wikipedia.org/wiki/HITS_algorithm>HITS algorithm</a>. The proposed method is applied to two <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> : <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> and <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>grammatical error correction</a>. For Japanese-to-English translation, this method achieved a BLEU score that was 0.56 points more than that of a <a href=https://en.wikipedia.org/wiki/Baseline_(typography)>baseline</a>. It also outperformed the baseline method for English grammatical error correction, with an <a href=https://en.wikipedia.org/wiki/F-measure>F-measure</a> that was 1.48 points higher.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-1009.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-1009 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-1009 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=I17-1009" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/I17-1009/>MIPA : Mutual Information Based Paraphrase Acquisition via Bilingual Pivoting<span class=acl-fixed-case>MIPA</span>: Mutual Information Based Paraphrase Acquisition via Bilingual Pivoting</a></strong><br><a href=/people/t/tomoyuki-kajiwara/>Tomoyuki Kajiwara</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a>
|
<a href=/people/d/daichi-mochihashi/>Daichi Mochihashi</a><br><a href=/volumes/I17-1/ class=text-muted>Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-1009><div class="card-body p-3 small">We present a pointwise mutual information (PMI)-based approach to formalize paraphrasability and propose a variant of PMI, called MIPA, for the paraphrase acquisition. Our paraphrase acquisition method first acquires lexical paraphrase pairs by bilingual pivoting and then reranks them by PMI and distributional similarity. The complementary nature of information from bilingual corpora and from monolingual corpora makes the proposed method robust. Experimental results show that the proposed method substantially outperforms bilingual pivoting and distributional similarity themselves in terms of metrics such as MRR, MAP, coverage, and Spearman&#8217;s correlation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5703.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5703 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5703 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5703/>Improving Japanese-to-English Neural Machine Translation by Paraphrasing the Target Language<span class=acl-fixed-case>J</span>apanese-to-<span class=acl-fixed-case>E</span>nglish Neural Machine Translation by Paraphrasing the Target Language</a></strong><br><a href=/people/y/yuuki-sekizawa/>Yuuki Sekizawa</a>
|
<a href=/people/t/tomoyuki-kajiwara/>Tomoyuki Kajiwara</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a><br><a href=/volumes/W17-57/ class=text-muted>Proceedings of the 4th Workshop on Asian Translation (WAT2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5703><div class="card-body p-3 small">Neural machine translation (NMT) produces sentences that are more fluent than those produced by <a href=https://en.wikipedia.org/wiki/Statistical_machine_translation>statistical machine translation (SMT)</a>. However, NMT has a very high <a href=https://en.wikipedia.org/wiki/Computational_cost>computational cost</a> because of the high dimensionality of the output layer. Generally, NMT restricts the size of vocabulary, which results in infrequent words being treated as out-of-vocabulary (OOV) and degrades the performance of the <a href=https://en.wikipedia.org/wiki/Translation>translation</a>. In evaluation, we achieved a statistically significant BLEU score improvement of 0.55-0.77 over the baselines including the <a href=https://en.wikipedia.org/wiki/State-of-the-art>state-of-the-art method</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5716.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5716 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5716 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5716/>Tokyo Metropolitan University Neural Machine Translation System for WAT 2017<span class=acl-fixed-case>T</span>okyo Metropolitan University Neural Machine Translation System for <span class=acl-fixed-case>WAT</span> 2017</a></strong><br><a href=/people/y/yukio-matsumura/>Yukio Matsumura</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a><br><a href=/volumes/W17-57/ class=text-muted>Proceedings of the 4th Workshop on Asian Translation (WAT2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5716><div class="card-body p-3 small">In this paper, we describe our neural machine translation (NMT) system, which is based on the attention-based NMT and uses long short-term memories (LSTM) as RNN. We implemented <a href=https://en.wikipedia.org/wiki/Beam_search>beam search</a> and ensemble decoding in the NMT system. The <a href=https://en.wikipedia.org/wiki/System>system</a> was tested on the 4th Workshop on Asian Translation (WAT 2017) shared tasks. In our experiments, we participated in the scientific paper subtasks and attempted Japanese-English, English-Japanese, and Japanese-Chinese translation tasks. The experimental results showed that implementation of <a href=https://en.wikipedia.org/wiki/Beam_search>beam search</a> and ensemble decoding can effectively improve the translation quality.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5911.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5911 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5911 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5911/>Suggesting Sentences for <a href=https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language>ESL</a> using Kernel Embeddings<span class=acl-fixed-case>ESL</span> using Kernel Embeddings</a></strong><br><a href=/people/k/kent-shioda/>Kent Shioda</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a>
|
<a href=/people/r/rue-ikeya/>Rue Ikeya</a>
|
<a href=/people/d/daichi-mochihashi/>Daichi Mochihashi</a><br><a href=/volumes/W17-59/ class=text-muted>Proceedings of the 4th Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA 2017)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5911><div class="card-body p-3 small">Sentence retrieval is an important NLP application for <a href=https://en.wikipedia.org/wiki/English_language>English</a> as a Second Language (ESL) learners. ESL learners are familiar with <a href=https://en.wikipedia.org/wiki/Web_search_engine>web search engines</a>, but generic web search results may not be adequate for composing documents in a specific domain. However, if we build our own <a href=https://en.wikipedia.org/wiki/Web_search_engine>search system</a> specialized to a domain, it may be subject to the data sparseness problem. Recently proposed <a href=https://en.wikipedia.org/wiki/Word2vec>word2vec</a> partially addresses the data sparseness problem, but fails to extract sentences relevant to queries owing to the modeling of the latent intent of the query. Thus, we propose a method of retrieving example sentences using kernel embeddings and N-gram windows. This method implicitly models latent intent of query and sentences, and alleviates the problem of noisy alignment. Our results show that our method achieved higher precision in sentence retrieval for <a href=https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language>ESL</a> in the domain of a university press release corpus, as compared to a previous unsupervised method used for a semantic textual similarity task.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Mamoru+Komachi" title="Search for 'Mamoru Komachi' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/t/tomoyuki-kajiwara/ class=align-middle>Tomoyuki Kajiwara</a>
<span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/people/y/yukio-matsumura/ class=align-middle>Yukio Matsumura</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/m/masahiro-kaneko/ class=align-middle>Masahiro Kaneko</a>
<span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/people/s/satoru-katsumata/ class=align-middle>Satoru Katsumata</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/people/h/hayahide-yamagishi/ class=align-middle>Hayahide Yamagishi</a>
<span class="badge badge-secondary align-middle ml-2">4</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/a/aizhan-imankulova/ class=align-middle>Aizhan Imankulova</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/h/hiroki-shimanaka/ class=align-middle>Hiroki Shimanaka</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/y/yuting-zhao/ class=align-middle>Yuting Zhao</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/c/chenhui-chu/ class=align-middle>Chenhui Chu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/daichi-mochihashi/ class=align-middle>Daichi Mochihashi</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/k/kengo-hotate/ class=align-middle>Kengo Hotate</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/t/tosho-hirasawa/ class=align-middle>Tosho Hirasawa</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/seiichi-inoue/ class=align-middle>Seiichi Inoue</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/taichi-aida/ class=align-middle>Taichi Aida</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/manabu-asai/ class=align-middle>Manabu Asai</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yujin-takahashi/ class=align-middle>Yujin Takahashi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yuuki-sekizawa/ class=align-middle>Yuuki Sekizawa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kent-shioda/ class=align-middle>Kent Shioda</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rue-ikeya/ class=align-middle>Rue Ikeya</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rob-van-der-goot/ class=align-middle>Rob van der Goot</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ibrahim-sharaf/ class=align-middle>Ibrahim Sharaf</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/ahmet-ustun/ class=align-middle>Ahmet Üstün</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marija-stepanovic/ class=align-middle>Marija Stepanović</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alan-ramponi/ class=align-middle>Alan Ramponi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/siti-oryza-khairunnisa/ class=align-middle>Siti Oryza Khairunnisa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/barbara-plank/ class=align-middle>Barbara Plank</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/aomi-koyama/ class=align-middle>Aomi Koyama</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hwichan-kim/ class=align-middle>Hwichan Kim</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yuen-hsien-tseng/ class=align-middle>Yuen-Hsien Tseng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/hsin-hsi-chen/ class=align-middle>Hsin-Hsi Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/v/vincent-ng/ class=align-middle>Vincent Ng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mio-arai/ class=align-middle>Mio Arai</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/ryoma-yoshimura/ class=align-middle>Ryoma Yoshimura</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/i/ikumi-yamashita/ class=align-middle>Ikumi Yamashita</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michiki-kurosawa/ class=align-middle>Michiki Kurosawa</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">7</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">4</span></li><li class=list-group-item><a href=/venues/wat/ class=align-middle>WAT</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/eamt/ class=align-middle>EAMT</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/ijcnlp/ class=align-middle>IJCNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/coling/ class=align-middle>COLING</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/wmt/ class=align-middle>WMT</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>