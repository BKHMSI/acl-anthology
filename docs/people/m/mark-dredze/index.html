<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Mark Dredze - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><span class=font-weight-normal>Mark</span> <span class=font-weight-bold>Dredze</span></h2><hr><div class=row><div class=col-lg-9><h4>2021</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.socialnlp-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--socialnlp-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.socialnlp-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.socialnlp-1.11" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.socialnlp-1.11/>Using Noisy Self-Reports to Predict Twitter User Demographics<span class=acl-fixed-case>T</span>witter User Demographics</a></strong><br><a href=/people/z/zach-wood-doughty/>Zach Wood-Doughty</a>
|
<a href=/people/p/paiheng-xu/>Paiheng Xu</a>
|
<a href=/people/x/xiao-liu/>Xiao Liu</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a><br><a href=/volumes/2021.socialnlp-1/ class=text-muted>Proceedings of the Ninth International Workshop on Natural Language Processing for Social Media</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--socialnlp-1--11><div class="card-body p-3 small">Computational social science studies often contextualize <a href=https://en.wikipedia.org/wiki/Content_analysis>content analysis</a> within standard <a href=https://en.wikipedia.org/wiki/Demography>demographics</a>. Since <a href=https://en.wikipedia.org/wiki/Demography>demographics</a> are unavailable on many <a href=https://en.wikipedia.org/wiki/Social_media>social media platforms</a> (e.g. Twitter), numerous studies have inferred <a href=https://en.wikipedia.org/wiki/Demography>demographics</a> automatically. Despite many studies presenting proof-of-concept inference of race and ethnicity, training of practical systems remains elusive since there are few annotated datasets. Existing datasets are small, inaccurate, or fail to cover the four most common <a href=https://en.wikipedia.org/wiki/Race_and_ethnicity_in_the_United_States>racial and ethnic groups</a> in the United States. We present a method to identify self-reports of race and ethnicity from Twitter profile descriptions. Despite the noise of automated supervision, our <a href=https://en.wikipedia.org/wiki/Self-report_study>self-report datasets</a> enable improvements in <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> performance on gold standard <a href=https://en.wikipedia.org/wiki/Self-report_study>self-report survey data</a>. The result is a reproducible method for creating <a href=https://en.wikipedia.org/wiki/Training_and_development>large-scale training resources</a> for <a href=https://en.wikipedia.org/wiki/Race_and_ethnicity_in_the_United_States>race and ethnicity</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.emnlp-main.149.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--emnlp-main--149 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.emnlp-main.149 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.emnlp-main.149" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.emnlp-main.149/>Everything Is All It Takes : A Multipronged Strategy for Zero-Shot Cross-Lingual Information Extraction</a></strong><br><a href=/people/m/mahsa-yarmohammadi/>Mahsa Yarmohammadi</a>
|
<a href=/people/s/shijie-wu/>Shijie Wu</a>
|
<a href=/people/m/marc-marone/>Marc Marone</a>
|
<a href=/people/h/haoran-xu/>Haoran Xu</a>
|
<a href=/people/s/seth-ebner/>Seth Ebner</a>
|
<a href=/people/g/guanghui-qin/>Guanghui Qin</a>
|
<a href=/people/y/yunmo-chen/>Yunmo Chen</a>
|
<a href=/people/j/jialiang-guo/>Jialiang Guo</a>
|
<a href=/people/c/craig-harman/>Craig Harman</a>
|
<a href=/people/k/kenton-murray/>Kenton Murray</a>
|
<a href=/people/a/aaron-steven-white/>Aaron Steven White</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a>
|
<a href=/people/b/benjamin-van-durme/>Benjamin Van Durme</a><br><a href=/volumes/2021.emnlp-main/ class=text-muted>Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--emnlp-main--149><div class="card-body p-3 small">Zero-shot cross-lingual information extraction (IE) describes the construction of an IE model for some target language, given existing annotations exclusively in some other language, typically <a href=https://en.wikipedia.org/wiki/English_language>English</a>. While the advance of pretrained multilingual encoders suggests an easy optimism of train on <a href=https://en.wikipedia.org/wiki/English_language>English</a>, run on any language, we find through a thorough exploration and extension of techniques that a combination of approaches, both new and old, leads to better performance than any one cross-lingual strategy in particular. We explore techniques including <a href=https://en.wikipedia.org/wiki/Projection_(linear_algebra)>data projection</a> and self-training, and how different pretrained encoders impact them. We use English-to-Arabic IE as our initial example, demonstrating strong performance in this setting for event extraction, <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>, <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a>, and dependency parsing. We then apply <a href=https://en.wikipedia.org/wiki/Projection_(linear_algebra)>data projection</a> and self-training to three tasks across eight target languages. Because no single set of techniques performs the best across all tasks, we encourage practitioners to explore various configurations of the techniques described in this work when seeking to improve on zero-shot training.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.clpsych-1.23.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--clpsych-1--23 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.clpsych-1.23 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.clpsych-1.23/>Towards Understanding the Role of Gender in Deploying Social Media-Based Mental Health Surveillance Models</a></strong><br><a href=/people/e/eli-sherman/>Eli Sherman</a>
|
<a href=/people/k/keith-harrigian/>Keith Harrigian</a>
|
<a href=/people/c/carlos-aguirre/>Carlos Aguirre</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a><br><a href=/volumes/2021.clpsych-1/ class=text-muted>Proceedings of the Seventh Workshop on Computational Linguistics and Clinical Psychology: Improving Access</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--clpsych-1--23><div class="card-body p-3 small">Spurred by advances in <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning</a> and <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>, developing social media-based mental health surveillance models has received substantial recent attention. For these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> to be maximally useful, it is necessary to understand how they perform on various subgroups, especially those defined in terms of <a href=https://en.wikipedia.org/wiki/Protected_group>protected characteristics</a>. In this paper we study the relationship between user demographics focusing on <a href=https://en.wikipedia.org/wiki/Gender>gender</a> and <a href=https://en.wikipedia.org/wiki/Depression_(mood)>depression</a>. Considering a population of Reddit users with known genders and depression statuses, we analyze the degree to which depression predictions are subject to biases along gender lines using domain-informed classifiers. We then study our models&#8217; parameters to gain qualitative insight into the differences in posting behavior across genders.</div></div><h4>2020</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.720.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--720 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.720 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.720.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.acl-main.720.Dataset.pdf data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929424 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.acl-main.720" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.720/>Sources of Transfer in Multilingual Named Entity Recognition</a></strong><br><a href=/people/d/david-mueller/>David Mueller</a>
|
<a href=/people/n/nicholas-andrews/>Nicholas Andrews</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--720><div class="card-body p-3 small">Named-entities are inherently multilingual, and <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a> in any given language may be limited. This motivates us to consider polyglot named-entity recognition (NER), where one model is trained using annotated data drawn from more than one language. However, a straightforward implementation of this simple idea does not always work in practice : naive training of NER models using annotated data drawn from multiple languages consistently underperforms <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained on monolingual data alone, despite having access to more training data. The starting point of this paper is a simple solution to this problem, in which polyglot models are fine-tuned on monolingual data to consistently and significantly outperform their monolingual counterparts. To explain this phenomena, we explore the sources of multilingual transfer in polyglot NER models and examine the weight structure of polyglot models compared to their monolingual counterparts. We find that polyglot models efficiently share many parameters across languages and that <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> may utilize a large number of those parameters.<i>polyglot</i> named-entity recognition (NER), where one model is trained using annotated data drawn from more than one language. However, a straightforward implementation of this simple idea does not always work in practice: naive training of NER models using annotated data drawn from multiple languages consistently underperforms models trained on monolingual data alone, despite having access to more training data. The starting point of this paper is a simple solution to this problem, in which polyglot models are <i>fine-tuned</i> on monolingual data to consistently and significantly outperform their monolingual counterparts. To explain this phenomena, we explore the sources of multilingual transfer in polyglot NER models and examine the weight structure of polyglot models compared to their monolingual counterparts. We find that polyglot models efficiently share many parameters across languages and that fine-tuning may utilize a large number of those parameters.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.acl-main.760.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--acl-main--760 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.acl-main.760 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929026 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.acl-main.760/>Clinical Concept Linking with Contextualized Neural Representations</a></strong><br><a href=/people/e/elliot-schumacher/>Elliot Schumacher</a>
|
<a href=/people/a/andriy-mulyar/>Andriy Mulyar</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a><br><a href=/volumes/2020.acl-main/ class=text-muted>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--acl-main--760><div class="card-body p-3 small">In traditional approaches to <a href=https://en.wikipedia.org/wiki/Entity_linking>entity linking</a>, linking decisions are based on three sources of information the similarity of the mention string to an entity&#8217;s name, the similarity of the context of the document to the entity, and broader information about the knowledge base (KB). In some domains, there is little contextual information present in the KB and thus we rely more heavily on mention string similarity. We consider one example of this, concept linking, which seeks to link mentions of medical concepts to a medical concept ontology. We propose an approach to concept linking that leverages recent work in contextualized neural models, such as ELMo (Peters et al. 2018), which create a token representation that integrates the surrounding context of the mention and concept name. We find a neural ranking approach paired with contextualized embeddings provides gains over a competitive baseline (Leaman et al. Additionally, we find that a pre-training step using <a href=https://en.wikipedia.org/wiki/Synonym>synonyms</a> from the <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontology</a> offers a useful initialization for the ranker.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--repl4nlp-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.repl4nlp-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929782 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.repl4nlp-1.16" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.16/>Are All Languages Created Equal in Multilingual BERT?<span class=acl-fixed-case>BERT</span>?</a></strong><br><a href=/people/s/shijie-wu/>Shijie Wu</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a><br><a href=/volumes/2020.repl4nlp-1/ class=text-muted>Proceedings of the 5th Workshop on Representation Learning for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--repl4nlp-1--16><div class="card-body p-3 small">Multilingual BERT (mBERT) trained on 104 languages has shown surprisingly good cross-lingual performance on several NLP tasks, even without explicit cross-lingual signals. However, these evaluations have focused on cross-lingual transfer with high-resource languages, covering only a third of the languages covered by mBERT. We explore how mBERT performs on a much wider set of languages, focusing on the quality of representation for low-resource languages, measured by within-language performance. We consider three tasks : <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>Named Entity Recognition</a> (99 languages), <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>Part-of-speech Tagging</a> and Dependency Parsing (54 languages each). mBERT does better than or comparable to baselines on high resource languages but does much worse for low resource languages. Furthermore, monolingual BERT models for these <a href=https://en.wikipedia.org/wiki/Language>languages</a> do even worse. Paired with similar languages, the performance gap between monolingual BERT and mBERT can be narrowed. We find that better <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> for low resource languages require more efficient pretraining techniques or more data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpcovid19-acl.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nlpcovid19-acl.0/>Proceedings of the 1st Workshop on <span class=acl-fixed-case>NLP</span> for <span class=acl-fixed-case>COVID-19</span> at <span class=acl-fixed-case>ACL</span> 2020</a></strong><br><a href=/people/k/karin-verspoor/>Karin Verspoor</a>
|
<a href=/people/k/k-bretonnel-cohen/>Kevin Bretonnel Cohen</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a>
|
<a href=/people/e/emilio-ferrara/>Emilio Ferrara</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/r/robert-munro/>Robert Munro</a>
|
<a href=/people/c/cecile-paris/>Cecile Paris</a>
|
<a href=/people/b/byron-c-wallace/>Byron Wallace</a><br><a href=/volumes/2020.nlpcovid19-acl/ class=text-muted>Proceedings of the 1st Workshop on NLP for COVID-19 at ACL 2020</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpcovid19-2.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nlpcovid19-2.0/>Proceedings of the 1st Workshop on <span class=acl-fixed-case>NLP</span> for <span class=acl-fixed-case>COVID</span>-19 (Part 2) at <span class=acl-fixed-case>EMNLP</span> 2020</a></strong><br><a href=/people/k/karin-verspoor/>Karin Verspoor</a>
|
<a href=/people/k/k-bretonnel-cohen/>Kevin Bretonnel Cohen</a>
|
<a href=/people/m/michael-conway/>Michael Conway</a>
|
<a href=/people/b/berry-de-bruijn/>Berry de Bruijn</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a>
|
<a href=/people/r/rada-mihalcea/>Rada Mihalcea</a>
|
<a href=/people/b/byron-c-wallace/>Byron Wallace</a><br><a href=/volumes/2020.nlpcovid19-2/ class=text-muted>Proceedings of the 1st Workshop on NLP for COVID-19 (Part 2) at EMNLP 2020</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.wnut-1.28.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--wnut-1--28 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.wnut-1.28 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.wnut-1.28.OptionalSupplementaryMaterial.pdf data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.wnut-1.28" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.wnut-1.28/>Civil Unrest on Twitter (CUT): A Dataset of Tweets to Support Research on Civil Unrest<span class=acl-fixed-case>T</span>witter (<span class=acl-fixed-case>CUT</span>): A Dataset of Tweets to Support Research on Civil Unrest</a></strong><br><a href=/people/j/justin-sech/>Justin Sech</a>
|
<a href=/people/a/alexandra-delucia/>Alexandra DeLucia</a>
|
<a href=/people/a/anna-l-buczak/>Anna L. Buczak</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a><br><a href=/volumes/2020.wnut-1/ class=text-muted>Proceedings of the Sixth Workshop on Noisy User-generated Text (W-NUT 2020)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--wnut-1--28><div class="card-body p-3 small">We present CUT, a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for studying <a href=https://en.wikipedia.org/wiki/Civil_disorder>Civil Unrest</a> on <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>. Our dataset includes 4,381 tweets related to <a href=https://en.wikipedia.org/wiki/Civil_disorder>civil unrest</a>, hand-annotated with information related to the study of civil unrest discussion and events. Our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> is drawn from 42 countries from 2014 to 2019. We present <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline systems</a> trained on this <a href=https://en.wikipedia.org/wiki/Data>data</a> for the identification of tweets related to <a href=https://en.wikipedia.org/wiki/Civil_disorder>civil unrest</a>. We include a discussion of ethical issues related to research on this topic.</div></div><h4>2019</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3013.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3013 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3013 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3013/>Mental Health Surveillance over <a href=https://en.wikipedia.org/wiki/Social_media>Social Media</a> with Digital Cohorts</a></strong><br><a href=/people/s/silvio-amir/>Silvio Amir</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a>
|
<a href=/people/j/john-w-ayers/>John W. Ayers</a><br><a href=/volumes/W19-30/ class=text-muted>Proceedings of the Sixth Workshop on Computational Linguistics and Clinical Psychology</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3013><div class="card-body p-3 small">The ability to track <a href=https://en.wikipedia.org/wiki/Mental_disorder>mental health conditions</a> via <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> opened the doors for large-scale, automated, mental health surveillance. However, inferring accurate population-level trends requires representative samples of the underlying population, which can be challenging given the biases inherent in social media data. While previous work has adjusted samples based on <a href=https://en.wikipedia.org/wiki/Demography>demographic estimates</a>, the populations were selected based on specific outcomes, e.g. specific <a href=https://en.wikipedia.org/wiki/Mental_disorder>mental health conditions</a>. We depart from these methods, by conducting analyses over demographically representative digital cohorts of social media users. To validated this approach, we constructed a cohort of US based Twitter users to measure the prevalence of depression and <a href=https://en.wikipedia.org/wiki/Posttraumatic_stress_disorder>PTSD</a>, and investigate how these illnesses manifest across demographic subpopulations. The analysis demonstrates that <a href=https://en.wikipedia.org/wiki/Cohort_study>cohort-based studies</a> can help control for <a href=https://en.wikipedia.org/wiki/Sampling_bias>sampling biases</a>, contextualize outcomes, and provide deeper insights into the data.</div></div><h4>2018</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-1114.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-1114 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-1114 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W18-1114" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W18-1114/>Predicting Twitter User Demographics from Names Alone<span class=acl-fixed-case>T</span>witter User Demographics from Names Alone</a></strong><br><a href=/people/z/zach-wood-doughty/>Zach Wood-Doughty</a>
|
<a href=/people/n/nicholas-andrews/>Nicholas Andrews</a>
|
<a href=/people/r/rebecca-marvin/>Rebecca Marvin</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a><br><a href=/volumes/W18-11/ class=text-muted>Proceedings of the Second Workshop on Computational Modeling of People’s Opinions, Personality, and Emotions in Social Media</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-1114><div class="card-body p-3 small">Social media analysis frequently requires tools that can automatically infer <a href=https://en.wikipedia.org/wiki/Demography>demographics</a> to contextualize trends. These tools often require hundreds of user-authored messages for each user, which may be prohibitive to obtain when analyzing millions of users. We explore character-level neural models that learn a representation of a user&#8217;s name and <a href=https://en.wikipedia.org/wiki/User_(computing)>screen name</a> to predict gender and ethnicity, allowing for demographic inference with minimal data. We release trained models1 which may enable new <a href=https://en.wikipedia.org/wiki/Demography>demographic analyses</a> that would otherwise require enormous amounts of data collection</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1034.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1034 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1034 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276397933 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1034" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1034/>Deep Dirichlet Multinomial Regression<span class=acl-fixed-case>D</span>irichlet Multinomial Regression</a></strong><br><a href=/people/a/adrian-benton/>Adrian Benton</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a><br><a href=/volumes/N18-1/ class=text-muted>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1034><div class="card-body p-3 small">Dirichlet Multinomial Regression (DMR) and other supervised topic models can incorporate arbitrary document-level features to inform topic priors. However, their ability to model corpora are limited by the representation and selection of these <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> a choice the topic modeler must make. Instead, we seek <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that can learn the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature representations</a> upon which to condition topic selection. We present deep Dirichlet Multinomial Regression (dDMR), a generative topic model that simultaneously learns document feature representations and topics. We evaluate dDMR on three datasets : New York Times articles with fine-grained tags, Amazon product reviews with product images, and Reddit posts with subreddit identity. dDMR learns representations that outperform DMR and LDA according to heldout perplexity and are more effective at downstream predictive tasks as the number of topics grows. Additionally, human subjects judge dDMR topics as being more representative of associated document features. Finally, we find that supervision leads to faster convergence as compared to an LDA baseline and that dDMR&#8217;s model fit is less sensitive to training parameters than DMR.</div></div><h4>2017</h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-1095.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-1095 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-1095 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P17-1095.Notes.zip data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/234955407 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P17-1095/>Bayesian Modeling of Lexical Resources for Low-Resource Settings<span class=acl-fixed-case>B</span>ayesian Modeling of Lexical Resources for Low-Resource Settings</a></strong><br><a href=/people/n/nicholas-andrews/>Nicholas Andrews</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a>
|
<a href=/people/b/benjamin-van-durme/>Benjamin Van Durme</a>
|
<a href=/people/j/jason-eisner/>Jason Eisner</a><br><a href=/volumes/P17-1/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-1095><div class="card-body p-3 small">Lexical resources such as <a href=https://en.wikipedia.org/wiki/Dictionary>dictionaries</a> and <a href=https://en.wikipedia.org/wiki/Gazetteer>gazetteers</a> are often used as auxiliary data for tasks such as part-of-speech induction and <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named-entity recognition</a>. However, discriminative training with lexical features requires annotated data to reliably estimate the lexical feature weights and may result in overfitting the lexical features at the expense of <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> which generalize better. In this paper, we investigate a more robust approach : we stipulate that the <a href=https://en.wikipedia.org/wiki/Lexicon>lexicon</a> is the result of an assumed generative process. Practically, this means that we may treat the lexical resources as observations under the proposed <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a>. The lexical resources provide training data for the <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a> without requiring separate data to estimate lexical feature weights. We evaluate the proposed approach in two settings : part-of-speech induction and low-resource named-entity recognition.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-2048.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P17-2048 data-toggle=collapse aria-expanded=false aria-controls=abstract-P17-2048 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P17-2048/>Pocket Knowledge Base Population</a></strong><br><a href=/people/t/travis-wolfe/>Travis Wolfe</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a>
|
<a href=/people/b/benjamin-van-durme/>Benjamin Van Durme</a><br><a href=/volumes/P17-2/ class=text-muted>Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P17-2048><div class="card-body p-3 small">Existing Knowledge Base Population methods extract relations from a closed relational schema with limited coverage leading to sparse KBs. We propose Pocket Knowledge Base Population (PKBP), the task of dynamically constructing a KB of entities related to a query and finding the best characterization of relationships between entities. We describe novel Open Information Extraction methods which leverage the PKB to find informative trigger words. We evaluate using existing KBP shared-task data as well anew annotations collected for this work. Our methods produce high quality KB from just text with many more entities and relationships than existing KBP systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P17-3000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P17-3000/>Proceedings of <span class=acl-fixed-case>ACL</span> 2017, Student Research Workshop</a></strong><br><a href=/people/a/allyson-ettinger/>Allyson Ettinger</a>
|
<a href=/people/s/spandana-gella/>Spandana Gella</a>
|
<a href=/people/m/matthieu-labeau/>Matthieu Labeau</a>
|
<a href=/people/c/cecilia-ovesdotter-alm/>Cecilia Ovesdotter Alm</a>
|
<a href=/people/m/marine-carpuat/>Marine Carpuat</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a><br><a href=/volumes/P17-3/ class=text-muted>Proceedings of ACL 2017, Student Research Workshop</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1612.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1612 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1612 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1612/>Ethical Research Protocols for Social Media Health Research</a></strong><br><a href=/people/a/adrian-benton/>Adrian Benton</a>
|
<a href=/people/g/glen-coppersmith/>Glen Coppersmith</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a><br><a href=/volumes/W17-16/ class=text-muted>Proceedings of the First ACL Workshop on Ethics in Natural Language Processing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1612><div class="card-body p-3 small">Social media have transformed data-driven research in <a href=https://en.wikipedia.org/wiki/Political_science>political science</a>, the <a href=https://en.wikipedia.org/wiki/Social_science>social sciences</a>, <a href=https://en.wikipedia.org/wiki/Health>health</a>, and <a href=https://en.wikipedia.org/wiki/Medicine>medicine</a>. Since <a href=https://en.wikipedia.org/wiki/Medical_research>health research</a> often touches on sensitive topics that relate to ethics of treatment and patient privacy, similar ethical considerations should be acknowledged when using social media data in <a href=https://en.wikipedia.org/wiki/Medical_research>health research</a>. While much has been said regarding the ethical considerations of social media research, <a href=https://en.wikipedia.org/wiki/Medical_research>health research</a> leads to an additional set of concerns. We provide practical suggestions in the form of guidelines for researchers working with social media data in <a href=https://en.wikipedia.org/wiki/Medical_research>health research</a>. These guidelines can inform an IRB proposal for researchers new to social media health research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2612.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2612 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2612 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2612/>Multi-task Domain Adaptation for Sequence Tagging</a></strong><br><a href=/people/n/nanyun-peng/>Nanyun Peng</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a><br><a href=/volumes/W17-26/ class=text-muted>Proceedings of the 2nd Workshop on Representation Learning for NLP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2612><div class="card-body p-3 small">Many domain adaptation approaches rely on learning cross domain shared representations to transfer the knowledge learned in one domain to other domains. Traditional <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> only considers adapting for one task. In this paper, we explore multi-task representation learning under the domain adaptation scenario. We propose a neural network framework that supports <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> for multiple tasks simultaneously, and learns shared representations that better generalize for <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a>. We apply the proposed framework to <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> for sequence tagging problems considering two tasks : <a href=https://en.wikipedia.org/wiki/Chinese_word_segmentation>Chinese word segmentation</a> and <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>. Experiments show that multi-task domain adaptation works better than disjoint domain adaptation for each task, and achieves the state-of-the-art results for both tasks in the <a href=https://en.wikipedia.org/wiki/Social_media>social media domain</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-2912.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-2912 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-2912 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-2912/>How Does Twitter User Behavior Vary Across Demographic Groups?<span class=acl-fixed-case>T</span>witter User Behavior Vary Across Demographic Groups?</a></strong><br><a href=/people/z/zach-wood-doughty/>Zach Wood-Doughty</a>
|
<a href=/people/m/michael-smith/>Michael Smith</a>
|
<a href=/people/d/david-broniatowski/>David Broniatowski</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a><br><a href=/volumes/W17-29/ class=text-muted>Proceedings of the Second Workshop on NLP and Computational Social Science</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-2912><div class="card-body p-3 small">Demographically-tagged social media messages are a common source of data for <a href=https://en.wikipedia.org/wiki/Computational_social_science>computational social science</a>. While these messages can indicate differences in beliefs and behaviors between demographic groups, we do not have a clear understanding of how different demographic groups use platforms such as <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>. This paper presents a preliminary analysis of how groups&#8217; differing behaviors may confound analyses of the groups themselves. We analyzed one million <a href=https://en.wikipedia.org/wiki/Twitter>Twitter users</a> by first inferring <a href=https://en.wikipedia.org/wiki/Demography>demographic attributes</a>, and then measuring several <a href=https://en.wikipedia.org/wiki/Indicator_(statistics)>indicators</a> of <a href=https://en.wikipedia.org/wiki/Twitter>Twitter behavior</a>. We find differences in these indicators across demographic groups, suggesting that there may be underlying differences in how different demographic groups use <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4405.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4405 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4405 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4405/>Constructing an Alias List for Named Entities during an Event</a></strong><br><a href=/people/a/anietie-andy/>Anietie Andy</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a>
|
<a href=/people/m/mugizi-rwebangira/>Mugizi Rwebangira</a>
|
<a href=/people/c/chris-callison-burch/>Chris Callison-Burch</a><br><a href=/volumes/W17-44/ class=text-muted>Proceedings of the 3rd Workshop on Noisy User-generated Text</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4405><div class="card-body p-3 small">In certain fields, real-time knowledge from events can help in making informed decisions. In order to extract pertinent real-time knowledge related to an event, it is important to identify the <a href=https://en.wikipedia.org/wiki/Named_entity>named entities</a> and their corresponding <a href=https://en.wikipedia.org/wiki/Pseudonym>aliases</a> related to the event. The problem of identifying aliases of named entities that spike has remained unexplored. In this paper, we introduce an <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a>, EntitySpike, that identifies entities that spike in popularity in tweets from a given time period, and constructs an alias list for these spiked entities. EntitySpike uses a temporal heuristic to identify named entities with similar context that occur in the same time period (within minutes) during an event. Each entity is encoded as a vector using this temporal heuristic. We show how these entity-vectors can be used to create a named entity alias list. We evaluated our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> on a dataset of temporally ordered tweets from a single event, the 2013 <a href=https://en.wikipedia.org/wiki/55th_Annual_Grammy_Awards>Grammy Awards show</a>. We carried out various experiments on tweets that were published in the same time period and show that our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> identifies most entity name aliases and outperforms a competitive baseline.</div></div></div><div class=col-lg-3><a class="btn btn-lg btn-secondary btn-block mb-2" href="https://www.semanticscholar.org/search?q=Mark+Dredze" title="Search for 'Mark Dredze' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class=pl-sm-2>Search</span></a><div class=row><div class="col-12 col-md-6 col-lg-12"><div class=card><h5 class=card-header>Co-authors</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/people/n/nicholas-andrews/ class=align-middle>Nicholas Andrews</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/b/benjamin-van-durme/ class=align-middle>Benjamin Van Durme</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/z/zach-wood-doughty/ class=align-middle>Zach Wood-Doughty</a>
<span class="badge badge-secondary align-middle ml-2">3</span></li><li class=list-group-item><a href=/people/a/adrian-benton/ class=align-middle>Adrian Benton</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/s/shijie-wu/ class=align-middle>Shijie Wu</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-coauthors aria-expanded=false aria-controls=more-coauthors>show all...</li><div class="collapse border-top" id=more-coauthors><li class=list-group-item><a href=/people/k/karin-verspoor/ class=align-middle>Karin Verspoor</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/k/k-bretonnel-cohen/ class=align-middle>K. Bretonnel Cohen</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/b/byron-c-wallace/ class=align-middle>Byron C. Wallace</a>
<span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/people/d/david-mueller/ class=align-middle>David Mueller</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/elliot-schumacher/ class=align-middle>Elliot Schumacher</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/andriy-mulyar/ class=align-middle>Andriy Mulyar</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jason-eisner/ class=align-middle>Jason Eisner</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/t/travis-wolfe/ class=align-middle>Travis Wolfe</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/allyson-ettinger/ class=align-middle>Allyson Ettinger</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/spandana-gella/ class=align-middle>Spandana Gella</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/matthieu-labeau/ class=align-middle>Matthieu Labeau</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/cecilia-ovesdotter-alm/ class=align-middle>Cecilia Ovesdotter Alm</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marine-carpuat/ class=align-middle>Marine Carpuat</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/p/paiheng-xu/ class=align-middle>Paiheng Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/x/xiao-liu/ class=align-middle>Xiao Liu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/glen-coppersmith/ class=align-middle>Glen Coppersmith</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/n/nanyun-peng/ class=align-middle>Nanyun Peng</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-smith/ class=align-middle>Michael Smith</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/d/david-broniatowski/ class=align-middle>David Broniatowski</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anietie-andy/ class=align-middle>Anietie Andy</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mugizi-rwebangira/ class=align-middle>Mugizi Rwebangira</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/chris-callison-burch/ class=align-middle>Chris Callison-Burch</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/mahsa-yarmohammadi/ class=align-middle>Mahsa Yarmohammadi</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/marc-marone/ class=align-middle>Marc Marone</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/h/haoran-xu/ class=align-middle>Haoran Xu</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/seth-ebner/ class=align-middle>Seth Ebner</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/g/guanghui-qin/ class=align-middle>Guanghui Qin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/y/yunmo-chen/ class=align-middle>Yunmo Chen</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jialiang-guo/ class=align-middle>Jialiang Guo</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/craig-harman/ class=align-middle>Craig Harman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/kenton-murray/ class=align-middle>Kenton Murray</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/aaron-steven-white/ class=align-middle>Aaron Steven White</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rebecca-marvin/ class=align-middle>Rebecca Marvin</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/s/silvio-amir/ class=align-middle>Silvio Amir</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/john-w-ayers/ class=align-middle>John W. Ayers</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/eli-sherman/ class=align-middle>Eli Sherman</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/k/keith-harrigian/ class=align-middle>Keith Harrigian</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/carlos-aguirre/ class=align-middle>Carlos Aguirre</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/e/emilio-ferrara/ class=align-middle>Emilio Ferrara</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/jonathan-may/ class=align-middle>Jonathan May</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/robert-munro/ class=align-middle>Robert Munro</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/c/cecile-paris/ class=align-middle>Cecile Paris</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/m/michael-conway/ class=align-middle>Michael Conway</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/b/berry-de-bruijn/ class=align-middle>Berry de Bruijn</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/r/rada-mihalcea/ class=align-middle>Rada Mihalcea</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/j/justin-sech/ class=align-middle>Justin Sech</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/alexandra-delucia/ class=align-middle>Alexandra DeLucia</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/people/a/anna-l-buczak/ class=align-middle>Anna L. Buczak</a>
<span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div><div class="col-12 col-md-6 col-lg-12"><div class="card my-2 my-md-0 my-lg-2"><h5 class=card-header>Venues</h5><ul class="list-group list-group-flush list-group-compact"><li class=list-group-item><a href=/venues/ws/ class=align-middle>WS</a><span class="badge badge-secondary align-middle ml-2">6</span></li><li class=list-group-item><a href=/venues/acl/ class=align-middle>ACL</a><span class="badge badge-secondary align-middle ml-2">5</span></li><li class=list-group-item><a href=/venues/nlpcovid19/ class=align-middle>NLP-COVID19</a><span class="badge badge-secondary align-middle ml-2">2</span></li><li class=list-group-item><a href=/venues/socialnlp/ class=align-middle>SocialNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/emnlp/ class=align-middle>EMNLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class="list-group-item list-group-toggle-btn py-1" data-toggle=collapse data-target=#more-venues aria-expanded=false aria-controls=more-venues>show all...</li><div class="collapse border-top" id=more-venues><li class=list-group-item><a href=/venues/repl4nlp/ class=align-middle>RepL4NLP</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/naacl/ class=align-middle>NAACL</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/clpsych/ class=align-middle>CLPsych</a><span class="badge badge-secondary align-middle ml-2">1</span></li><li class=list-group-item><a href=/venues/wnut/ class=align-middle>WNUT</a><span class="badge badge-secondary align-middle ml-2">1</span></li></div></ul></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>