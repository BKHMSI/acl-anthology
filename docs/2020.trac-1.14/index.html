<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Spyder : Aggression Detection on Multilingual TweetsSpyder: Aggression Detection on Multilingual Tweets - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="Spyder : Aggression Detection on Multilingual TweetsSpyder: Aggression Detection on Multilingual Tweets" name=citation_title><meta content="Anisha Datta" name=citation_author><meta content="Shukrity Si" name=citation_author><meta content="Urbi Chakraborty" name=citation_author><meta content="Sudip Kumar Naskar" name=citation_author><meta content="Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying" name=citation_conference_title><meta content="2020/5" name=citation_publication_date><meta content="https://aclanthology.org/2020.trac-1.14.pdf" name=citation_pdf_url><meta content="87" name=citation_firstpage><meta content="92" name=citation_lastpage><meta property="og:title" content="Spyder : Aggression Detection on Multilingual TweetsSpyder: Aggression Detection on Multilingual Tweets"><meta property="og:image" content="https://aclanthology.org/thumb/2020.trac-1.14.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2020.trac-1.14"><meta property="og:description" content="Anisha Datta, Shukrity Si, Urbi Chakraborty, Sudip Kumar Naskar. Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying. 2020."><link rel=canonical href=https://aclanthology.org/2020.trac-1.14></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder : Aggression Detection on Multilingual Tweets<span class=acl-fixed-case>S</span>pyder: Aggression Detection on Multilingual Tweets</a>
<a id=af_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Aggresiebeskrywing op Multilingual Tweets</a>
<a id=am_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Aggression Detection Multilingual Tweets</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>سبايدر: كشف العدوان على التغريدات متعددة اللغات</a>
<a id=az_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Çoxlu Dil Tövetlərində Agresiya Keşfeti</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Спайдър: Откриване на агресия при многоезични туитове</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Aggression Detection on Multilingual Tweets</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>སྒྲུང་ཐེངས་: སྐད་རིགས་གྱི་Tweets ཐོག་ཏུ་འཕགས་རིས་བསམ་བྱུང་།</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Detekcija agresije na višejezičkim tweetima</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Detection of Aggression on Multilingual Tweets</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Detekce agrese na vícejazyčných tweetech</a>
<a id=da_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Påvisning af aggression på flersprogede tweets</a>
<a id=de_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Aggressionserkennung auf mehrsprachigen Tweets</a>
<a id=el_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Ανίχνευση επιθετικότητας σε πολυγλωσσικά tweets</a>
<a id=es_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: detección de agresiones en tuits multilingües</a>
<a id=et_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Agressiooni tuvastamine mitmekeelsetes tweetides</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>اسپایدر: شناسایی افزایش روی Tweets Multilingual</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: aggression tunnistus monikielisissä twieteissä</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder : détection de l'agressivité sur les tweets multilingues</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Brath Ionsaithe ar Tweetanna Ilteangacha</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Phonon:: MMF:: EffectFactory</a>
<a id=he_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>ספיידר: גילוי התקף על טוויטים רבים שפותיים</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>स्पाइडर: बहुभाषी Tweets पर आक्रामकता का पता लगाना</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Detekcija agresije na višejezičkim Tweets</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Aggresszió észlelése többnyelvű tweeteken</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Սպիդեր. Ագրեսիայի հայտնաբերումը բազմալեզու թվիթերի վրա</a>
<a id=id_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Aggression Detection on Multilingual Tweets</a>
<a id=is_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Rilevamento di aggressività sui tweet multilingui</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder:多言語ツイートでの侵略検知</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spanish</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: მრავალენგური Tweets- ში Aggression Detection</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Спидер: Көптілікті Tweets- тегінде сәйкестік анықтау</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: 다국어 트위터의 공격 탐지</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Aggresijos nustatymas daugiakalbėse Tweetėse</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Спајдер: Детектирање на агресија на мултијазични твитови</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>സ്പൈഡര്‍: അഗ്രാഗ്രേഷന്‍ ഡിറ്റീറ്റീഷന്‍ പല ഭാഷകളുടെ ടൂട്ടുകള്‍</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Спидер: Ихэнх хэл tweets дээр асуудлын тодорхойлолт</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Pengesanan Aggresi pada Tweet Berbahasa</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Sejbien ta’ Aggressjoni fuq Tweets Multilingwi</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Aggressiedetectie op meertalige tweets</a>
<a id=no_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Aggressingsoppdaging på fleirspråk tweeter</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Wykrywanie agresji na wielojęzycznych tweetach</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: detecção de agressão em tweets multilíngues</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Detectarea agresiunii pe tweeturile multilingve</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Обнаружение агрессии в многоязычных твитах</a>
<a id=si_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>ස්පායිඩර්: ගොඩක් භාෂාවක් ට්විට්ස් වල සංවේදනය හොයාගන්න</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Zaznavanje agresije na večjezičnih Tweets</a>
<a id=so_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Gariirka heshiiska ee luqadaha badan Tweet</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Detektimi i agresionit në Tweets shumëgjuhës</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Detekcija agresije na višejezičkim tweetima</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Upptäckt av aggression på flerspråkiga tweets</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Kutambuliwa kwa Makubaliano kwa Twita za lugha nyingi</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Aggression Detection on Multilingual Tweets</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Süpler: Çoklu dilli Tweets üzerinde küçümsel tanınması</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>اسپیڈر: Multilingual Tweets پر Aggression Detection</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder: Tashkilot aniqlashni bir necha tillar foydalanish</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Gián điệp: Phát hiện xung kích trên Tweet ngôn ngữ</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2020.trac-1.14.pdf>Spyder:多言推文之攻击性检</a></h2><p class=lead><a href=/people/a/anisha-datta/>Anisha Datta</a>,
<a href=/people/s/shukrity-si/>Shukrity Si</a>,
<a href=/people/u/urbi-chakraborty/>Urbi Chakraborty</a>,
<a href=/people/s/sudip-kumar-naskar/>Sudip Kumar Naskar</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In the last few years, <a href=https://en.wikipedia.org/wiki/Hate_speech>hate speech</a> and aggressive comments have covered almost all the social media platforms like <a href=https://en.wikipedia.org/wiki/Facebook>facebook</a>, <a href=https://en.wikipedia.org/wiki/Twitter>twitter</a> etc. As a result hatred is increasing. This paper describes our (Team name : Spyder) participation in the Shared Task on <a href=https://en.wikipedia.org/wiki/Aggression>Aggression Detection</a> organised by TRAC-2, Second Workshop on <a href=https://en.wikipedia.org/wiki/Internet_troll>Trolling</a>, <a href=https://en.wikipedia.org/wiki/Aggression>Aggression</a> and <a href=https://en.wikipedia.org/wiki/Cyberbullying>Cyberbullying</a>. The Organizers provided datasets in three languages <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a> and <a href=https://en.wikipedia.org/wiki/Bengali_language>Bengali</a>. The task was to classify each instance of the test sets into three categories Overtly Aggressive (OAG), Covertly Aggressive (CAG) and Non-Aggressive (NAG). In this paper, we propose three different models using Tf-Idf, sentiment polarity and <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning based classifiers</a>. We obtained <a href=https://en.wikipedia.org/wiki/F-number>f1 score</a> of 43.10 %, 59.45 % and 44.84 % respectively for <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a> and <a href=https://en.wikipedia.org/wiki/Bengali_language>Bengali</a>.<b>Team name:</b>\n <b>Spyder</b>) participation in the Shared Task on Aggression Detection organised by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying. The Organizers provided datasets in three languages &#8211; English, Hindi and Bengali. The task was to classify each instance of the test sets into three categories &#8211; &#8220;Overtly Aggressive&#8221; (OAG), &#8220;Covertly Aggressive&#8221; (CAG) and &#8220;Non-Aggressive&#8221; (NAG). In this paper, we propose three different models using Tf-Idf, sentiment polarity and machine learning based classifiers. We obtained f1 score of 43.10%, 59.45% and 44.84% respectively for English, Hindi and Bengali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In die laaste paar jaar het haat spraak en aggressiewe kommentaar amper al die sosiale media platforme soos facebook, twitter ensfh. As 'n resultaat haat vergroei word. Hierdie papier beskrywe ons (Team name: Spyder) deelnadering in die Gedeelde Opdrag oor Aggresiedeteksie organiseer deur TRAC-2, tweede Werkshop op Trolling, Aggresie en Cyberbullying. Die Organiseerders het datastelle in drie tale verskaf - Engels, Hindi en Bengali. Die taak was om elke voorbeeld van die toets stel in drie kategorie te klassifiseer - 'Oorskynlik Aggressief' (OAG), 'Omdek Aggressive' (CAG) en 'Non- Aggressive' (NAG). In hierdie papier voorstel ons drie verskillende modele met gebruik van Tf-Idf, sentiment polariteit en masjien leer gebaseerde klassifiseerders. Ons het f1 telling van 43,10%, 59,45% en 44,84% respectively vir Engels, Hindi en Bengali ontvang.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ባለፉት ጥቂት ዓመታት፣ ጥላቻን ንግግር እና ተቃውሞ አካባቢ ማኅበራዊ ሚዲያ ጦማሪያዎች እንደ ፊትቡክ፣ twitter እና ድምፅ ይጨምራሉ፡፡ This paper describes our (Team name: Spyder) participation in the Shared Task on Aggression Detection organised by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying. አጋራጆች በሦስት ቋንቋ - እንግሊዘኛ፣ ሄንዲ እና በንጋሊ ዳታተርቶችን ሰጥተዋል፡፡ ስራው ሁሉንም ምሳሌዎች በሦስት categories - 'አብዛኛውን Aggressive' (OAG), 'Covertly Aggressive' (CAG) እና 'nonAggressive' (NAG). በዚህ ካላት፣ Tf-Idf፣ የስሜት ፖርቲካ እና የመኪና ትምህርት መተማር የተለየ ሦስት የተለየ ዓይነቶች እና መደበቂያ እናደርጋለን፡፡ በእንግሊዝኛ፣ Hindi እና በጋንጋል ላይ የፊዲ ቁጥር 43.10 በመቶ፥ 59.45 በመቶ እና 44.84 በመቶ አግኝተናል።</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>في السنوات القليلة الماضية ، غطى خطاب الكراهية والتعليقات العدوانية جميع منصات التواصل الاجتماعي تقريبًا مثل facebook و twitter وما إلى ذلك. ونتيجة لذلك ، تتزايد الكراهية. تصف هذه الورقة مشاركتنا (اسم الفريق: سبايدر) في المهمة المشتركة حول اكتشاف العدوان التي نظمتها TRAC-2 ، ورشة العمل الثانية حول التصيد والعدوان والتسلط عبر الإنترنت. قدم المنظمون مجموعات بيانات بثلاث لغات - الإنجليزية والهندية والبنغالية. كانت المهمة هي تصنيف كل حالة من مجموعات الاختبار إلى ثلاث فئات - "عدواني بشكل علني" (OAG) ، و "عدواني بشكل سري" (CAG) و "غير عدواني" (NAG). في هذه الورقة ، نقترح ثلاثة نماذج مختلفة باستخدام المصنفات القائمة على Tf-Idf وقطبية المشاعر والتعلم الآلي. حصلنا على درجة f1 بنسبة 43.10٪ و 59.45٪ و 44.84٪ على التوالي للغة الإنجليزية والهندية والبنغالية.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Son bir neçə il içində nifrət sözləri və agresif şəhadətlər facebook, twitter və ya da bənzər sosyal media platformlarını bürüdülər. Sonuçta nifrət artırır. Bu kağıt TRAC-2, Trolling, Aggresyon və Cyberbullying ilə organizasyon edilmiş Aggresyon Detection işimizin paylaşılmış işimizi təsdiqləyir. Organizerlər üç dildə verilən qurğular – İngilizce, Hindi və Bengali. Gözəl hər bir sınama quruluğunu üç kategoriya ilə dəyişdirmək idi: 'Çox Agressive' (OAG), 'Cover Aggressive' (CAG) və 'Non-Aggressive' (NAG). Bu kağızda Tf-Idf, sentiment polaritāti və maşın öyrənməsi tabanlı klasifikatçıları ilə üç fərqli modeli təklif edirik. Biz f1 nöqtəsini 43,10%, 59,45% və 44,84% İngilizce, Hindi və Bengali üçün aldıq.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>През последните няколко години речта на омразата и агресивните коментари обхванаха почти всички социални медийни платформи като В резултат на това омразата нараства. Настоящата статия описва нашето (име на екипа: Спайдър) участие в споделената задача за откриване на агресия, организирана от Втора работна среща по тролинг, агресия и кибертормоз. Организаторите предоставиха набори от данни на три езика - английски, хинди и бенгалски. Задачата беше да се класифицират всеки пример от тестовите групи в три категории - "прекалено агресивен" (OAG), "скрит агресивен" (CAG) и "неагресивен" (NAG). В настоящата статия предлагаме три различни модела, използващи класификатори, базирани на сентиментална полярност и машинно обучение. Получихме резултат от 43,10%, 59,45% и 44,84% съответно за английски, хинди и бенгалски.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>গত কয়েক বছরে ঘৃণা ভাষণ এবং অত্যাচারী মন্তব্য প্রায় সকল সামাজিক প্রচার মাধ্যমের প্লাটফর্ম ফেসবুক, টুইটার ইত্যাদি প্রকাশ করেছে, যার ফলে এই পত্রিকাটি আমাদের (দলের নাম: স্পাইডার) অংশগ্রহণের অংশগ্রহণ করেছে ট্রাক্লিং এবং সাইবার্বালিং এর দ্বিতীয় ওয়ার্কশপের আয়োজন করেছে। সংগঠনগুলো তিনটি ভাষায় তথ্য সংগ্রহ করেছে- ইংরেজি, হিন্দি এবং বাংলায়। The task was to classify each instance of the test sets into three categories - 'Overtly Aggressive' (OAG), 'Covertly Aggressive' (CAG) and 'Non-Aggressive' (NAG). এই কাগজটিতে আমরা টিএফ-আইডফ, আবেগের দূর্নীতি এবং মেশিন ভিত্তিক শিক্ষা ব্যবহার করে তিনটি ভিন্ন মডেল প্রস্তাব করি। আমরা ইংরেজি, হিন্দি এবং বাংলার জন্য ৪৪.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>འདས་བའི་ལོ་ངོ་ཤས་ཀྱི་རིང་ལ་་་ ཕྱིར་ཉེན་དགའ་ཕྱོགས་དང་བསྡུར་བའི་མཆན་བཤད་ཀྱི་གྲོས་ཁྱེར་གྱི་སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་རྒྱའི་ནང་དུ་ ཤོག་བྱང་འདིས་ང་ཚོའི་མཉམ་དུ་སྤྱི་ཚོགས་ཀྱི་མིང་། སྒྲིག་འཛུགས་པ་ཚོས་སྐད་རིགས་གསུམ་ནང་གི་གནད་སྡུད་གཞི་སྒྲིག་ཚོགས་གཅིག་གི་ནང་བྱིན་ཡོད། The task was to classify each instance of the test sets in three categories - 'Overly Aggressive' (OAG), 'Covertly Aggressive' (CAG) and 'Non-Aggressive' (NAG). ང་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་སྔོན་པ་ལ་མ་དབྱེ་བ་གསུམ་རྣམས་སྤྱོད་ཀྱི་ཐབས་ལམ་མ་འདུག Tf-Idf་དང་། སེམས་ཚོར ངེད་ཚོ་སྤྱི་ཚོགས་ཀྱི་ཨང་ཀི43.10%, 59.45% དང་། སྤྱི་ཚོགས་ཀྱི་ཨང་ཀིས་ཡིག་ཆ་གཅིག་ཙམ་གྱི་འབོར་ཡོད།</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>U posljednjih nekoliko godina, govor mržnje i agresivni komentari su pokrili skoro sve platforme socijalnih medija poput facebook, twitter itd. Ovaj papir opisuje naše (Tim name: Spyder) sudjelovanje u zajedničkom zadatku o detekciji agresije organiziranom TRAC-2, Drugom radionicom o trolling, Agresiji i kiberbullying. Organizatori su pružili podatke na tri jezika - engleski, Hindi i Bengali. Taj zadatak je bio klasifikacija svakog instanca testova u tri kategorije - pretjerano agresivno (OAG), 'Prikriveno agresivno' (CAG) i 'ne-agresivno' (NAG). U ovom papiru predlažemo tri različita modela koristeći Tf-Idf, polarnost sentimenta i klasifikatore na osnovu učenja strojeva. Dobili smo f1 rezultat od 43,10%, 59,45% i 44,84% za engleski, hindi i Bengali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>En els últims anys, el discurs d'odi i els comentaris agressius han cobert gairebé totes les plataformes dels mitjans socials com Facebook, Twitter, etc. Com a resultat, l'odi està creixent. Aquest article descriu la nostra participació (Nom de l'equip: Spyder) en la Task Shared on Aggression Detection organitzada per TRAC-2, Segona Workshop on Trolling, Aggression and Cyberbullying. The Organizers provided datasets in three languages - English, Hindi and Bengali. The task was to classify each instance of the test sets into three categories - 'Overtly Aggressive' (OAG), 'Covertly Aggressive' (CAG) and 'Non-Aggressive' (NAG). En aquest paper, proposem tres models diferents utilitzant Tf-Idf, polaritat sentimental i classificadors basats en l'aprenentatge màquina. We obtained f1 score of 43.10%, 59.45% and 44.84% respectively for English, Hindi and Bengali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>V posledních několika letech se nenávistná řeč a agresivní komentáře pokryly téměř všechny platformy sociálních médií jako Facebook, Twitter atd. V důsledku toho se nenávist zvyšuje. Tento článek popisuje naši (název týmu: Spyder) účast na Sdíleném úkolu detekce agrese organizovaném TRAC-2, Druhém workshopu o trollingu, agresi a kyberšikaně. Organizátoři poskytli datové sady ve třech jazycích: angličtině, hindštině a bengálštině. Úkolem bylo rozdělit každou instanci testovacích sad do tří kategorií: příliš agresivní (OAG), utajené agresivní (CAG) a neagresivní (NAG). V tomto článku navrhujeme tři různé modely používající Tf-Idf, polaritu sentimentu a klasifikátory založené na strojovém učení. Získali jsme f1 skóre 43,10%, 59,45% a 44,84% pro angličtinu, hindštinu a bengálštinu.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>I løbet af de sidste par år har had tale og aggressive kommentarer dækket næsten alle sociale medier platforme som facebook, twitter osv. Som følge heraf er hadet voksende. Denne artikel beskriver vores (Team name: Spyder) deltagelse i Delt Opgave om Aggression Detection organiseret af TRAC-2, Anden Workshop om Trolling, Aggression og Cybermobbing. Arrangørerne leverede datasæt på tre sprog - engelsk, hindi og bengali. Opgaven var at klassificere hver enkelt forekomst af testsættene i tre kategorier - "Over Aggressive" (OAG), "Coverly Aggressive" (CAG) og "Non-Aggressive" (NAG). I denne artikel foreslår vi tre forskellige modeller ved hjælp af Tf-Idf, sentiment polarity og machine learning baserede klassificeringer. Vi fik f1 score på 43,10%, 59,45% og 44,84% for henholdsvis engelsk, hindi og bengali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In den letzten Jahren haben Hassrede und aggressive Kommentare fast alle Social-Media-Plattformen wie Facebook, Twitter etc. abgedeckt, wodurch Hass zunimmt. Dieses Papier beschreibt unsere (Teamname: Spyder) Teilnahme an der von TRAC-2 organisierten Shared Task on Aggression Detection, Second Workshop on Trolling, Aggression and Cybermobbing. Die Organisatoren stellten Datensätze in drei Sprachen zur Verfügung: Englisch, Hindi und Bengali. Die Aufgabe bestand darin, jede Instanz der Testsätze in drei Kategorien zu klassifizieren: Overtly Aggressive (OAG), "Covertly Aggressive" (CAG) und "Non-Aggressive" (NAG). In diesem Beitrag schlagen wir drei verschiedene Modelle vor, die Tf-Idf, Sentiment Polarity und Machine Learning basierte Klassifikatoren verwenden. Für Englisch, Hindi und Bengali erreichten wir f1 Score von 43,10%, 59,45% und 44,84% .</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Τα τελευταία χρόνια, η ρητορική μίσους και τα επιθετικά σχόλια έχουν καλύψει σχεδόν όλες τις πλατφόρμες κοινωνικής δικτύωσης όπως κλπ. Ως αποτέλεσμα το μίσος αυξάνεται. Η παρούσα εργασία περιγράφει τη συμμετοχή μας (όνομα ομάδας: κατάσκοπος) στην Κοινή Εργασία για την Ανίχνευση Επιπτώσεων που διοργανώθηκε από το Δεύτερο Εργαστήριο για το Τρόλινγκ, την Επίθεση και τον Κυβερνοβουλισμό. Οι διοργανωτές παρείχαν σύνολα δεδομένων σε τρεις γλώσσες: Αγγλικά, Χίντι και Βεγγαλικά. Το καθήκον ήταν να ταξινομηθεί κάθε περίπτωση των συνόλων δοκιμών σε τρεις κατηγορίες: "Υπερβολικά επιθετική" (OAG), "Κρυμμένα επιθετική" (CAG) και "Μη επιθετική" (NAG). Στην παρούσα εργασία, προτείνουμε τρία διαφορετικά μοντέλα χρησιμοποιώντας ταξινομητές που βασίζονται σε πολικότητα συναισθημάτων και μηχανική μάθηση. Πήραμε βαθμολογία f1 43.10%, 59.45% και 44.84% αντίστοιχα για τα Αγγλικά, τα Χίντι και τα Βεγγαλικά.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>En los últimos años, el discurso de odio y los comentarios agresivos han cubierto casi todas las plataformas de medios sociales como Facebook, Twitter, etc. Como resultado, el odio está aumentando. Este artículo describe nuestra participación (Nombre del equipo: Spyder) en la tarea compartida sobre detección de agresión organizada por TRAC-2, Segundo taller sobre trolling, agresión y ciberacoso. Los organizadores proporcionaron conjuntos de datos en tres idiomas: inglés, hindi y bengalí. La tarea consistía en clasificar cada instancia de los conjuntos de pruebas en tres categorías: «Agresiva manifiesta» (OAG), «Agresiva encubierta» (CAG) y «No agresiva» (NAG). En este artículo, proponemos tres modelos diferentes que utilizan clasificadores basados en Tf-Idf, polaridad de sentimiento y aprendizaje automático. Obtuvimos una puntuación f1 del 43,10%, 59,45% y 44,84% respectivamente para inglés, hindi y bengalí.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Viimastel aastatel on vihakõne ja agressiivsed kommentaarid hõlmanud peaaegu kõiki sotsiaalmeedia platvorme nagu facebook, twitter jne, mille tulemusena vihkamine kasvab. Käesolevas dokumendis kirjeldatakse meie (meeskonna nimi: Spyder) osalemist TRAC-2 poolt korraldatud agressiooni tuvastamise jagatud ülesandes, mis käsitleb trollingut, agressiooni ja küberkiusamist. Korraldajad esitasid andmekogumeid kolmes keeles - inglise, hindi ja bengali keeles. Ülesanne oli klassifitseerida iga katsekogumi eksemplar kolme kategooriasse - "ülemääraselt agressiivne" (OAG), "varjatult agressiivne" (CAG) ja "mitteagressiivne" (NAG). Käesolevas töös pakume välja kolm erinevat mudelit, mis kasutavad Tf-Idf, sentimentaalse polaarsuse ja masinõppe alusel põhinevaid klassifitseerijaid. Inglise, hindi ja bengali puhul saime f1 skoori 43,10%, 59,45% ja 44,84%.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>در چند سال گذشته، از سخنرانی متنفر و توضیح‌های تجاوز تقریباً تمام platformهای رسانه‌های اجتماعی مانند facebook, twitter و غیر از آن پوشیده شده است. به نتیجه نفرت افزایش می‌یابد. این کاغذ (نام تیم: Spyder) مشارکت ما را توصیف می‌کند در کار مشترک در مورد بازرسی گروهی که توسط TRAC-2 سازمان شده است، کارگاه دوم در مورد ترولینگ، گروهی و سایبر بولینگ است. Organizers provided data sets in three languages - English, Hindi and Bengali. وظیفه این بود که هر نمونه از مجموعه‌های آزمایش را در سه گروه کلاس کنیم - 'زیادی گریز' (OAG), 'قابل گریز' (CAG) و 'ناگریز' (NAG). در این کاغذ، ما سه مدل متفاوتی را با استفاده از Tf-Idf پیشنهاد می کنیم، قطعیت احساسات و دستگاه یادگیری بر اساس مختلف راهنمایی. ما درصد f1 از 43.10%, 59.45% و 44.84% به عنوان انگلیسی, هندی و بنگالی دریافت کردیم.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Viime vuosina vihapuhe ja aggressiiviset kommentit ovat kattaneet lähes kaikki sosiaalisen median alustat, kuten Facebook, Twitter jne. Tämän seurauksena viha kasvaa. Tässä artikkelissa kuvataan (Team name: Spyder) osallistumistamme TRAC-2:n järjestämään aggression havaitsemista koskevaan yhteiseen tehtävään, joka on toinen Trolling-, Aggression- ja Cyberbullying-työpaja. Järjestäjät toimittivat aineistoja kolmella kielellä - englanti, hindi ja bengali. Tehtävänä oli luokitella testisarjat kolmeen luokkaan: "Yliaggressiivinen" (OAG), "Salaaggressiivinen" (CAG) ja "Ei aggressiivinen" (NAG). Tässä työssä ehdotamme kolmea eri mallia käyttäen Tf-Idf-, sentiment polarity- ja koneoppimispohjaisia luokittelijoita. Englannin, hindin ja bengalin f1-pisteet olivat 43,10%, 59,45% ja 44,84%.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Au cours des dernières années, les discours haineux et les commentaires agressifs ont couvert presque toutes les plateformes de médias sociaux comme Facebook, Twitter, etc. Cet article décrit notre participation (nom de l'équipe : Spyder) à la tâche partagée sur la détection de l'agression organisée par TRAC-2, Second Workshop on Trolling, Agressivité and Cyberbullying. Les organisateurs ont fourni des ensembles de données en trois langues : anglais, hindi et bengali. La tâche consistait à classer chaque instance des ensembles de tests en trois catégories : « ouvertement agressif » (OAG), « secrètement agressif » (CAG) et « non agressif » (NAG). Dans cet article, nous proposons trois modèles différents utilisant Tf-Idf, la polarité des sentiments et des classificateurs basés sur l'apprentissage automatique. Nous avons obtenu un score f1 de 43,10 %, 59,45 % et 44,84 % respectivement pour l'anglais, l'hindi et le bengali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Le blianta beaga anuas, clúdaíodh fuathchaint agus tráchtaireacht ionsaitheach ar bheagnach gach ardán meán sóisialta ar nós facebook, twitter etc. Mar thoradh air sin tá an fuath ag méadú. Déanann an páipéar seo cur síos ar ár rannpháirtíocht (Ainm Foirne: Spyder) sa Tasc Comhroinnte ar Bhrath Ionsaitheach arna eagrú ag TRAC-2, an Dara Ceardlann ar Throláil, Ionsaí agus Cibearbhulaíocht. Chuir na hEagraithe tacair shonraí ar fáil i dtrí theanga – Béarla, Hiondúis agus Beangáilis. Ba é an tasc a bhí ann ná gach cás de na tacair tástála a rangú i dtrí chatagóir – “Go hOllmhargach Ionsaitheach” (OAG), “Covertly Ionsaitheach” (CAG) agus “Neamh- Ionsaitheach” (NAG). Sa pháipéar seo, molaimid trí mhúnla éagsúla a úsáideann Tf-Idf, polaraíocht meon agus aicmitheoirí atá bunaithe ar mheaisín-fhoghlaim. Fuaireamar scór f1 de 43.10%, 59.45% agus 44.84% faoi seach do Bhéarla, Hiondúis agus Beangáilis.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Daga ƙidãyayyuta kaɗan, hoton ƙiyayya da mawaƙi sun rufe kowace platforms na mitanda na jamii kamar facebook, Twitter etc. Saboda haka, ƙiyayya ta ƙara. Wannan karatun yana bayyana mana (Team name: SPAYer) shirin ya zama a cikin aikin Shared on Aggression Dictionary organized by TRac-2, Shirin Sauq na Tõrlling, Aggression and cyberbullbullbullbullbullbulling. Shirin Ayuka na bãyar da data set cikin harshe uku - Ingiriya, Hindcha da Bangali. Kayan aikin ya zama mai rarraba ko wani halin na jarraba ta cikin nau'i uku - 'Totally Aggressive' (OAG), "Deptly Aggressive' (CAG) da 'Non-Aggressive' (NAG). In this paper, we propose three different models using Tf-Idf, sentiment polarity and machine learning based classifiers. Mun sãmi f1 score na 43.10%, 59.45% da 44.84% na Ingiriya, Hinddi da Bangali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>בשנים האחרונות, נאום שנאה והתגובות אגרסיביות כיסו כמעט את כל המתקנות של התקשורת החברתית כמו פייסבוק, טוויטר וכו"כ. כתוצאה מכך שנאה גדלה. העיתון הזה מתאר את השתתפות שלנו (שם צוות: ספיידר) במשימה המשותפת על גילוי התקפה מאורגנת על ידי TRAC-2, Workshop שני על טרולינג, התקפה וקייברבולינג. המארגנים סיפקו קבוצות נתונים בשלושה שפות - אנגלית, הינדית ובנגלית. The task was to classify each instance of the test sets into three categories - 'Overtly Aggressive' (OAG), 'Covertly Aggressive' (CAG) and 'Non-Aggressive' (NAG). בעיתון הזה, אנו מציעים שלושה דוגמנים שונים בשימוש ב-Tf-Idf, קוטביות רגשות ולמדות מכונות מסודרים. השגנו נקודת f1 של 43.10%, 59.45% ו-44.84% בהתאם לאנגלית, הינדית ובנגלית.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>पिछले कुछ वर्षों में, हेट स्पीच और आक्रामक टिप्पणियों ने फेसबुक, ट्विटर आदि जैसे लगभग सभी सोशल मीडिया प्लेटफार्मों को कवर किया है। नतीजतन नफरत बढ़ती जा रही है। यह पेपर TRAC-2, Trolling, आक्रामकता और Cyberbullying पर दूसरी कार्यशाला द्वारा आयोजित आक्रामकता का पता लगाने पर साझा कार्य में हमारी (टीम का नाम: Spyder) भागीदारी का वर्णन करता है। आयोजकों ने तीन भाषाओं - अंग्रेजी, हिंदी और बंगाली में डेटासेट प्रदान किए। कार्य परीक्षण सेट के प्रत्येक उदाहरण को तीन श्रेणियों में वर्गीकृत करना था - "अत्यधिक आक्रामक" (ओएजी), "गुप्त रूप से आक्रामक" (सीएजी) और "गैर-आक्रामक" (एनएजी)। इस पेपर में, हम Tf-Idf, भावना ध्रुवीयता और मशीन लर्निंग आधारित क्लासिफायरका उपयोग करके तीन अलग-अलग मॉडलों का प्रस्ताव करते हैं। हमने अंग्रेजी, हिंदी और बंगाली के लिए क्रमशः 43.10%, 59.45% और 44.84% का f1 स्कोर प्राप्त किया।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>U posljednjih nekoliko godina, govor mržnje i agresivni komentari pokrivali su skoro sve platforme društvenih medija poput facebook, twitter itd. Ovaj papir opisuje naše sudjelovanje (Tim name: Spyder) u zajedničkom zadatku o detectivu agresije organiziranom TRAC-2, Drugi radnički rad o trolling, Agresiji i kiberbullying. Organizatori su pružili podatke na tri jezika - engleski, Hindi i Bengali. Taj zadatak je bio klasifikacija svake primjere testova u tri kategorije - pretjerano agresivne (OAG), 'Prikriveno agresivne' (CAG) i 'ne agresivne' (NAG). U ovom papiru predlažemo tri različita modela koristeći Tf-Idf, polarnost osjećaja i klasifikatore na osnovu učenja strojeva. Dobili smo f1 rezultat od 43,10%, 59,45% i 44,84% za engleski, hindi i Bengali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Az elmúlt néhány évben a gyűlöletbeszéd és az agresszív megjegyzések szinte minden közösségi média platformra kiterjedtek, mint a facebook, a twitter stb. Ennek eredményeképpen növekszik a gyűlölet. Ez a tanulmány bemutatja (Csapatnév: Spyder) részvételünket a TRAC-2 által szervezett, a Trolling, Agresszió és Cyberbullying második workshopján. A Szervezők három nyelven – angol, hindi és bengáli nyelven – biztosítottak adatkészleteket. A feladat az volt, hogy a vizsgálati készletek minden egyes példányát három kategóriába sorolják: "Túlzottan agresszív" (OAG), "Túlzottan agresszív" (CAG) és "Nem agresszív" (NAG). Ebben a tanulmányban három különböző modellt javasolunk Tf-Idf, sentiment polarity és gépi tanulás alapú osztályozókat használva. Az angol, hindi és bengáli f1 pontszám 43,10%, 59,45%, illetve 44,84%.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Վերջին մի քանի տարիների ընթացքում ատելության խոսքը և ագրեսիվ մեկնաբանությունները ծածկել են գրեթե բոլոր սոցիալական լրատվամիջոցների պլատֆորմերը, ինչպիսիք են Ֆեյսբուքը, թվիթերը և այլն, ինչի արդյունքում ատելություն Այս հոդվածը նկարագրում է մեր (Թիմի անունը՝ Սպիդեր) մասնակցությունը Ագրեսիայի հայտնագործման ընդհանուր խնդրի մեջ, որը կազմակերպել է ԹրաԿ-2, Թրոլինգի, Ագրեսիայի և Կիբերբուլիգի երկրորդ աշխատասենյակում: The Organizers provided datasets in three languages - English, Hindi and Bengali. Հարտադրությունն էր դասակարգել փորձարկումների յուրաքանչյուր օրինակ երեք կատեգորիաների՝ չափազանց ագրեսիվ, թաքնված ագրեսիվ և ոչ ագրեսիվ: Այս թղթի մեջ մենք առաջարկում ենք երեք տարբեր մոդել, որոնք օգտագործում են Tf-IDf-ը, զգացմունքների մոտավորությունը և մեքենային ուսումնասիրության հիմնված դասակարգերը: Մենք ստացանք 43.10 տոկոսը, 59.45 տոկոսը և 44.84 տոկոսը անգլերենի, հինդի և բենգալիի համար:</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In the last few years, hate speech and aggressive comments have covered almost all the social media platforms like facebook, twitter etc. As a result hatred is increasing. This paper describes our (Team name: Spyder) participation in the Shared Task on Aggression Detection organised by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying. The Organizers provided datasets in three languages - English, Hindi and Bengali. The task was to classify each instance of the test sets into three categories - 'Overtly Aggressive' (OAG), 'Covertly Aggressive' (CAG) and 'Non-Aggressive' (NAG). Dalam kertas ini, kami mengusulkan tiga model yang berbeda menggunakan Tf-Idf, polaritas sentimen dan klasifikasi berbasis pembelajaran mesin. Kami mendapat skor f1 43,10%, 59,45% dan 44,84% respectively untuk Inggris, Hindi dan Bengali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Negli ultimi anni, discorsi d'odio e commenti aggressivi hanno coperto quasi tutte le piattaforme di social media come facebook, twitter ecc. Di conseguenza l'odio è in aumento. Questo articolo descrive la nostra partecipazione (Team name: Spyder) al Compito Condiviso sulla Rilevazione dell'Aggressione organizzato da TRAC-2, Secondo Workshop su Trolling, Aggressione e Cyberbullismo. Gli organizzatori hanno fornito set di dati in tre lingue - inglese, hindi e bengalese. Il compito era quello di classificare ogni istanza dei set di test in tre categorie - "Overtly Aggressive" (OAG), "Coverly Aggressive" (CAG) e "Non Aggressive" (NAG). In questo articolo, proponiamo tre diversi modelli che utilizzano Tf-Idf, polarità sentimentale e classificazione basata sull'apprendimento automatico. Abbiamo ottenuto il punteggio f1 del 43,10%, 59,45% e 44,84% rispettivamente per inglese, hindi e bengalese.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ここ数年、ヘイトスピーチや攻撃的なコメントは、facebook、twitterなどのソーシャルメディアプラットフォームのほぼすべてをカバーしています。そのため、憎悪が高まっている。この論文では、TRAC -2、トロール、アグレッション、ネットいじめに関する第2回ワークショップが主催する「侵略検出に関する共有タスク」への（チーム名： Spyder ）の参加について説明します。主催者は、英語、ヒンディー語、ベンガル語の3つの言語でデータセットを提供しました。このタスクは、テストセットの各インスタンスを、「露骨に攻撃的」（ OAG ）、「秘密裏に攻撃的」（ CAG ）、および「非攻撃的」（ NAG ）の3つのカテゴリに分類することでした。本稿では、Tf - Idf、センチメント極性、機械学習ベースの分類子を用いた3つの異なるモデルを提案する。英語、ヒンディー語、ベンガル語でそれぞれ43.10%、59.45%、44.84%のf 1スコアを得た。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nang acara sing ditambah dumadhi, cah-cah dumadhi lan komentar sing gak bener tentang karo hal-hal sing mengko kuwi padha kaé sistem media soti kowé karo netwisu, tuwitir, njl. sebelah kuwi mau kudu dunyane kuwi mau. Perintah iki dadi ono nggawe (Group name: spyrer) sumusunoi tanggal nggawe Tarjamahan kelas nggawe barang nggawe barang TROC-2, Second Workspace nang Trill, agegress lan Ciberbullying. Organiser politenessoffpolite"), and when there is a change ("assertivepoliteness Nang paper iki, kéné supoyo model sing sampeyan telu model sing gambar tf-Idf, polarity seneng karo sistem sing basa sak kelas. Awak dhéwé luwih tangané f1 puntuan sing katênêr, denganêr, limang-limang kanggo kalah-aman kanggo inggiles, barang-arang karo Bengal.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ოჲჟლვენთრვ ნწკჲლკჲ დჲეთნთ, მპაჱნთ დჲგჲპთ თ ადპვჟთგნთ კჲმვნრპთ ჟვ ჲბკპთგარ ოჲფრთ გჟთფკთ ჟჲუთალნთ მვეთწ ოლარტჲპმართ, კარჲ ტვიჟბსკ, რგთრვპ ეს დოკუნტი აღწერს ჩვენი (Team name: Spyder) დანაწილეობა საზოგადოებული დავალებაში TRAC-2, მეორე სამუშაო სამუშაო Trolling, Aggression და Cyberbullying-ზე. Organizers provided datasets in three languages - English, Hindi and Bengali. პარამეტრები იყო, რომ ტესტის სამი კატეგორიაში ყოველ ინსტანსის კლასიფიკაცია - 'ძალიან ადგრესიური' (OAG), 'სამხოლოდ ადგრესიური' (CAG) და 'არა ადგრესიური' (NAG). ამ დოკუნეში ჩვენ სამი განსხვავებული მოდელის გამოყენება Tf-Idf, სენტიმენტის პოლარიტი და მაქინის სწავლების კლასიფიკაციების გამოყენება. ჩვენ მივიღეთ f1 წერტილი 43,10%, 59,45% და 44,84% ანგლისურად, ჰინდი და ბენდალისთვის.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Соңғы бірнеше жылда сөйлесу және агрессивні түсініктемелер жалғастырып, Facebook, twitter және т.б. секілді жалғастырып жатыр. Бұл қағаз TRAC-2, Trolling, Aggression және Cyberbullying бойынша екінші жұмыс шоғырында ортақ тапсырмаға қатынасызды (Топ атауы: Spyder) қатынасызды таңдайды. Организаторлар үш тілде деректер қорларын - ағылшын, хинди және бенгали тілде берді. Тапсырма тексеру баптауларының әрбір инстанциясын үш санатына - 'Үлкен сұрақтық' (OAG), 'Мұқаралық сұрақтық' (CAG) және 'Сұрақтық емес' (NAG) классификациялауы болды. Бұл қағазда Tf-Idf, сезімдік поляриялық және машинаның оқыту классификаторын қолданатын үш түрлі үлгі моделдерді таңдаймыз. Біз f1 нөмірі 43,10%, 59,45% және 44,84% ағылшын, хинди және бенгали үшін алдық.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>지난 몇 년 동안 페이스북, 트위터 등 모든 소셜미디어 플랫폼에 원한 발언과 공격적인 댓글이 덮여 있어 원한이 증가하고 있다.본고는 우리(팀명: Spyder)가TRAC-2조직의 공격검측공유임무에 참여하고 제2기 제어, 공격과 인터넷 괴롭힘에 관한 세미나를 묘사한다.조직자는 영어, 인디언, 방글라데시어 세 가지 언어의 데이터 집합을 제공했다.임무는 테스트 집합의 각 실례를'공개공격'(OAG),'은폐공격'(CAG),'비공격'(NAG) 세 종류로 나누는 것이다.본고에서 우리는 Tf-Idf, 감정의 극성과 기계 학습을 바탕으로 하는 분류기를 이용하여 세 가지 다른 모델을 제시했다.우리의 f1영어, 인디언, 방글라데시어 성적은 각각 43.10%, 59.45%와 44.84% 였다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Per pastaruosius kelerius metus neapykantos kalba ir agresyvios pastabos apimo beveik visas socialinės žiniasklaidos platformas, pvz., Facebook, Twitter ir t. t. Dėl to didėja neapykanta. This paper describes our (Team name: Spyder) participation in the Shared Task on Aggression Detection organised by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying. Organizatoriai pateikė duomenų rinkinius trimis kalbomis - anglų, hindų ir bengalų kalbomis. Kiekvienas bandymų rinkinio atvejis buvo klasifikuojamas į tris kategorijas - "pernelyg agresyvus" (OAG), "apskritai agresyvus" (CAG) ir "nesuagresyvus" (NAG). Šiame dokumente siūlome tris skirtingus modelius, naudojančius Tf-Idf, jausmų poliarumą ir mašinų mokymosi klasifikatorius. We obtained f1 score of 43.10%, 59.45% and 44.84% respectively for English, Hindi and Bengali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In the last few years, hate speech and aggressive comments have covered almost all the social media platforms like facebook, twitter etc. As a result hatred is increasing. Овој весник го опишува нашето учество (името на тимот: Шпијдер) во заедничката задача за детекција на агресија организирана од TRAC-2, вториот работилник за тролинг, агресија и киберболитирање. Организаторите обезбедија податоци на три јазици - англиски, хинди и бенгали. Задачата беше да се класификува секоја инстанција од тестовите во три категории - „Премногу агресивно“ (OAG), „Сокриено агресивно“ (CAG) и „Неагресивно“ (NAG). Во овој весник предложуваме три различни модели кои користат Тф-Идф, поларитет на чувствата и класификатори базирани на машинско учење. Добивме оценка f1 од 43,10 отсто, 59,45 отсто и 44,84 отсто за англиски, хинди и бенгали.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>കഴിഞ്ഞ കുറച്ചു വര്‍ഷങ്ങളില്‍, വെറുപ്പുകളും അക്രമമായ വാക്കുകളും മുഴുവന്‍ സാമൂഹ്യ മീഡിയ പ്ലാറ്റ്ഫോമുകളും മൂടിയിട്ടുണ്ട്. ഫെസ ഈ പത്രത്തില്‍ ഞങ്ങളുടെ (ടീം പേര്: സ്പൈഡര്‍) പങ്കെടുത്ത ജോലിയില്‍ പങ്കുചേര്‍ക്കുന്നു സംഘടനക്കാര്‍ മൂന്നു ഭാഷകളില്‍ ഡാറ്റാസറ്റുകള്‍ നല്‍കിയിരിക്കുന്നു. ഇംഗ്ലീഷ്, ഹിന്ദി, ബെങ്കാ പരീക്ഷണ സജ്ജീകരണങ്ങളുടെ ഓരോ അവസ്ഥ മൂന്നു വിഭാഗങ്ങളായി - 'മുഴുവന്‍ അഗ്രാഗ്രാസ്റ്റീവ്' (OAG), 'കോപ്റ്റ്ലി Aggressive' (CAG) അല്ലാത്ത വിഭാഗങ്ങള്‍' ( ഈ പത്രത്തില്‍ ടിഫ്-ഐഡിഫിനെ ഉപയോഗിക്കുന്ന മൂന്നു വ്യത്യസ്ത മോഡലുകള്‍ ഞങ്ങള്‍ നിര്‍ദ്ദേശിക്കുന്നു. വിചാരപൂര്‍ണ്ണമ We obtained f1 score of 43.10%, 59.45% and 44.84% respectively for English, Hindi and Bengali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Өнгөрсөн хэдэн жилийн дотор үзэн ядах яриа, хүчирхийллэг сэтгэл зүйл нь facebook, twitter гэх мэт бүх нийгмийн медиа платформуудыг харуулж байна. Үүний үр дүнд үзэн ядах нь нэмэгддэг. Энэ цаас бидний (Баг нэр: Спидер) TRAC-2, Тролинг, Агресс, Цибербулингийн хоёр дахь ажиллагааны тухай хуваалцах ажилд оролцож байна. Организагчид гурван хэл дээр өгөгдлийн сангууд - Англи, Хинди, Бенгали. Үүний шалгалтын давхар бүрийг 3 категорид хэлбэрээр хэлбэртэй (OAG), 'Мөн хэлбэртэй' (CAG) болон 'Мөн хэлбэргүй' (NAG) хэлбэрээр ангилах байсан. Энэ цаасан дээр бид Tf-Idf, сэтгэл хөдлөл, машины сургалтын үндсэн хэлбэрүүдийг ашиглан гурван өөр загварыг санал болгож байна. Бид f1 оноо 43,10%, 59,45% болон 44,84% Англи, Хинди болон Бенгали хүмүүст авсан.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Dalam beberapa tahun terakhir, ucapan kebencian dan komentar agresif telah menutupi hampir semua platform media sosial seperti facebook, twitter dan sebagainya kebencian meningkat. Kertas ini menggambarkan (nama pasukan: Spyder) participasi kami dalam Tugas Berkongsi untuk pengesan Aggresi yang dirancang oleh TRAC-2, Workshop Kedua tentang Trolling, Aggression dan Cyberbullying. Pengurus menyediakan set data dalam tiga bahasa - Bahasa Inggeris, Hindi dan Bengali. The task was to classify each instance of the test sets into three categories - 'Overtly Aggressive' (OAG), 'Covertly Aggressive' (CAG) and 'Non-Aggressive' (NAG). Dalam kertas ini, kami cadangkan tiga model yang berbeza menggunakan Tf-Idf, polariti perasaan dan klasifikasi pembelajaran mesin. Kami mendapat skor f1 43.10%, 59.45% dan 44.84% respectively untuk bahasa Inggeris, Hindi dan Bengali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Fl-a ħħar ftit snin, id-diskors tal-mibegħda u l-kummenti aggressivi koprew kważi l-pjattaformi kollha tal-midja soċjali bħall-facebook, it-twitter eċċ. B’riżultat ta’ dan il-mibegħda qed tiżdied. Dan id-dokument jiddeskrivi l-parteċipazzjoni tagħna (Isem it-Tim: Spyder) fil-Kompitu Konġunt dwar id-Detezzjoni tal-Aggressjoni organizzat mit-TRAC-2, it-Tieni Workshop dwar it-Trolling, l-Aggressjoni u ċ-Ċiberbullying. L-Organizzaturi pprovdew settijiet ta’ dejta fi tliet lingwi - l-Ingliż, l-Indjan u l-Bengali. Il-kompitu kien li kull każ tas-settijiet tat-testijiet jiġi kklassifikat fi tliet kategoriji - 'Aggressivi żżejjed' (OAG), 'Aggressivi b'mod Kopert' (CAG) u 'Mhux Aggressivi' (NAG). In this paper, we propose three different models using Tf-Idf, sentiment polarity and machine learning based classifiers. Kisbu punteġġ f1 ta’ 43.10%, 59.45% u 44.84% rispettivament għall-Ingliż, l-Indjan u l-Bengali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In de afgelopen jaren hebben hate speech en agressieve reacties bijna alle sociale media platforms zoals facebook, twitter etc. bestraald waardoor haat toeneemt. Dit artikel beschrijft onze (Teamnaam: Spyder) deelname aan de Shared Task on Aggression Detection georganiseerd door TRAC-2, Tweede Workshop over Trolling, Aggressie en Cyberpesten. De Organisatoren leverden datasets in drie talen: Engels, Hindi en Bengaals. De taak was om elke instantie van de testsets te classificeren in drie categorieën: Overtly Aggressive (OAG), 'Covertly Aggressive' (CAG) en 'Non-Aggressive' (NAG). In dit artikel stellen we drie verschillende modellen voor met behulp van Tf-Idf, sentimentpolariteit en machine learning gebaseerde classificatoren. We behaalden f1 score van respectievelijk 43,10%, 59,45% en 44,84% voor Engels, Hindi en Bengaals.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>I dei siste få år har hatt tale og aggressiv kommentarar dekka nesten alle sosiale mediaplattformene som facebook, twitter osv. Som resultatet er hatt økt. Denne papiret beskriver vårt (gruppenamn: Spyder) deltakast i delt oppgåve om Aggressingsoppdaging organisert av TRAC-2, andre arbeidsområde på Trolling, Aggressing og Cyberbullying. Organisatorene oppgav datasett i tre språk – engelsk, hindisk og Bengalisk. Oppgåva var å klassifisera kvar instans av testsettet inn i tre kategoriar – overAggresiv (OAG), 'Covertly Aggressive' (CAG) og 'Non-Aggressive' (NAG). I denne papiret foreslår vi tre ulike modeller med Tf-Idf, sentiment-polaritet og maskinelæring basert klassifiserar. Vi har f1 poeng med 43,10%, 59,45% og 44,84% for engelsk, hindisk og bengalisk.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>W ciągu ostatnich kilku lat mowa nienawiści i agresywne komentarze obejmowały prawie wszystkie platformy mediów społecznościowych, takie jak facebook, twitter itp. W rezultacie nienawiść wzrasta. Niniejszy artykuł opisuje nasz (nazwa zespołu: Spyder) udział w wspólnym zadaniu wykrywania agresji organizowanym przez TRAC-2, Drugie warsztaty na temat trollingu, agresji i cyberprzemocy. Organizatorzy dostarczyli zbiory danych w trzech językach: angielskim, hindi i bengalskim. Zadaniem było podzielenie każdej instancji zestawów testowych na trzy kategorie: nadmiernie agresywne (OAG), "tajne agresywne" (CAG) i "nieagresywne" (NAG). W niniejszym artykule proponujemy trzy różne modele wykorzystujące klasyfikatory Tf-Idf, polaryzację sentymentów oraz klasyfikatory oparte na uczeniu maszynowym. Uzyskaliśmy wynik f1 43,10%, 59,45% i 44,84% odpowiednio dla angielskiego, hindi i bengalskiego.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nos últimos anos, discursos de ódio e comentários agressivos cobriram quase todas as plataformas de mídia social como facebook, twitter etc. Como resultado, o ódio está aumentando. Este artigo descreve nossa participação (nome da equipe: Spyder) na Tarefa Compartilhada de Detecção de Agressão organizada pelo TRAC-2, Segundo Workshop sobre Trolling, Agressão e Cyberbullying. Os organizadores forneceram conjuntos de dados em três idiomas – inglês, hindi e bengali. A tarefa foi classificar cada instância dos conjuntos de testes em três categorias – “Abertamente Agressivo” (OAG), “Cobertamente Agressivo” (CAG) e “Não Agressivo” (NAG). Neste artigo, propomos três modelos diferentes usando Tf-Idf, polaridade de sentimento e classificadores baseados em aprendizado de máquina. Obtivemos pontuação f1 de 43,10%, 59,45% e 44,84% respectivamente para inglês, hindi e bengali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>În ultimii ani, discursul de ură și comentariile agresive au acoperit aproape toate platformele de social media precum facebook, twitter etc. Ca urmare ura este în creștere. Această lucrare descrie participarea noastră (numele echipei: Spyder) la activitatea comună privind detectarea agresiunii organizată de TRAC-2, al doilea atelier privind trolling, agresiune și cyberbullying. Organizatorii au furnizat seturi de date în trei limbi - engleză, hindi și bengală. Sarcina a fost de a clasifica fiecare instanță a seturilor de teste în trei categorii - "excesiv agresiv" (OAG), "excesiv agresiv" (CAG) și "non-agresiv" (NAG). În această lucrare, propunem trei modele diferite folosind Tf-Idf, polaritatea sentimentului și clasificarea bazată pe machine learning. Am obținut scorul f1 de 43,10%, 59,45% și respectiv 44,84% pentru engleză, hindi și bengali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>За последние несколько лет ненавистнические высказывания и агрессивные комментарии охватили почти все социальные медиа-платформы, такие как facebook, Twitter и т. д. В результате ненависть усиливается. В этом документе описывается наше участие (название команды: Spyder) в Совместной задаче по обнаружению агрессии, организованной TRAC-2, Второй семинар по троллингу, агрессии и кибербуллингу. Организаторы представили наборы данных на трех языках – английском, хинди и бенгальском. Задача состояла в том, чтобы классифицировать каждый экземпляр тестовых наборов по трем категориям – «открыто агрессивные» (ОАГ), «скрыто агрессивные» (КАГ) и «неагрессивные» (НАГ). В этой статье мы предлагаем три различные модели с использованием Tf-Idf, полярности настроений и классификаторов на основе машинного обучения. Мы получили оценку f1 43,10%, 59,45% и 44,84% соответственно для английского, хинди и бенгальского языка.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>අන්තිම අවුරුදු කීපයක් වලින්, වෛර කරනවා කියලා සමාජික මධ්‍යමාධ්‍යම ප්‍රවෘත්තියක් වගේ ප්‍රවෘත්තියක් වගේ පැත මේ පැත්තේ අපේ සම්බන්ධ නාමය (කණ්ඩායම්: ස්පායිඩර්) සම්බන්ධ වැඩක් තියෙනවා TRAC-2, දෙවෙනි වැඩකරුව ට්‍රෝලින්, සායිබර්බුලින් වල සංයෝජනකරුවන් දත්ත සැට් තුනක් භාෂාවට දුන්නා - ඉංග්‍රීසි, හින්දි සහ බෙන්ගාලි. වැඩය තමයි පරීක්ෂණා සැකසුම් හැම සැකසුම් තුනක් වලට පරීක්ෂණය කරගන්න - 'වැඩියෙන් වැඩියි' (OAG), 'කවර්ට්ලි වැඩියි' (CAG) සහ 'වැඩියෙන් මේ පැත්තට, අපි Tf-Idb භාවිතා වෙනස් මොඩේල් තුනක් ප්‍රයෝජනය කරන්න ප්‍රයෝජනය කරනවා, දැනුම් ප්‍රයෝජනය සහ ම අපිට අංග්‍රීසි, හින්දි සහ බෙන්ගාලි වලට f1 ප්‍රමාණයක් ලැබුනා.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>V zadnjih nekaj letih so sovražni govor in agresivni komentarji pokrivali skoraj vse platforme socialnih medijev, kot so facebook, twitter itd., zaradi česar sovraštvo narašča. Ta prispevek opisuje naše sodelovanje (ime ekipe: Spyder) v skupni nalogi za odkrivanje agresije, ki jo organizira TRAC-2, Druga delavnica o trollingu, agresiji in kibernetskem ustrahovanju. Organizatorji so zagotovili nabore podatkov v treh jezikih - angleščini, hindijščini in bengalščini. Naloga je bila razvrstiti vsak primer preskusnih nizov v tri kategorije - "preveč agresivni" (OAG), "skriti agresivni" (CAG) in "neagressivni" (NAG). V prispevku predlagamo tri različne modele, ki uporabljajo klasifikatorje Tf-Idf, sentimentalno polarnost in strojno učenje. Za angleščino, hindijščino in bengalščino smo dobili oceno f1 43,10%, 59,45% oziroma 44,84%.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Sannadihii ugu dambeeyey, hadalka nacayb iyo commentarada kibirka ah waxay ku qariyeen jardiinada shabakadda bulshada oo dhan sida facebook, twitter etc. sababtoo darteed nacaybku waa sii kordhayaa. Qoraalkan waxaa ku qoran (Team name: Spyder) qayb ka dhigista shaqada la sharciyey Aggression Detection organized by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying. Waxay qabanqaabiyaan macluumaadyo ku qoran saddex luuqadood - Ingiriis, Hindi iyo Bengali. Shaqada waxaa lagu qoray inuu u kala sooco caymis kasta oo imtixaanka lagu sameeyo saddex categor - 'Overall Aggressive' (OAG), 'Covertly Aggressive' (CAG) iyo 'Non-Aggressive' (NAG). Qoraalkan waxaan ku soo jeedaynaa saddex tusaale oo kala duduwan oo isticmaalaya Tf-Idf, qasabka fikrada iyo waxbarashada machine-ka. Af Ingiriis, Hindi iyo Bengali ayaannu helnay boqolkiiba f1 boqolkiiba 43.10, 59.45 % iyo 44.84 boqolkiiba.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Në vitet e fundit, fjalimi i urrejtjes dhe komentet agresive kanë mbuluar pothuajse të gjitha platformet e medias sociale si facebook, twitter etj. Si rezultat i urrejtjes po rritet. This paper describes our (Team name: Spyder) participation in the Shared Task on Aggression Detection organised by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying. Organizuesit ofruan të dhëna në tre gjuhë - anglisht, hindisht dhe bengalisht. Detyra ishte të klasifikohej çdo rast i grupeve të testit në tre kategori - 'Shumë Aggresive' (OAG), 'Covertely Aggressive' (CAG) dhe 'Non-Aggressive' (NAG). In this paper, we propose three different models using Tf-Idf, sentiment polarity and machine learning based classifiers. We obtained f1 score of 43.10%, 59.45% and 44.84% respectively for English, Hindi and Bengali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>U poslednjih nekoliko godina, govor mržnje i agresivni komentari su pokrili skoro sve platforme društvenih medija poput facebook, twitter itd. Ovaj papir opisuje naše (Tim name: Spyder) sudjelovanje u zajedničkom zadatku o detekciji agresije organizovanom TRAC-2, drugom radionicom o trolling, Agresiji i kiberbullying. Organizatori su pružili podatke na tri jezika - engleski, Hindi i Bengali. Taj zadatak je bio da klasifikišemo svaku instancu testova u tri kategorije - pretjerano agresivno (OAG), 'Prikriveno agresivno' (CAG) i 'ne-agresivno' (NAG). U ovom papiru predlažemo tri različita modela koristeći Tf-Idf, polarnost sentimenta i klasifikatore osnovane na mašinama. Dobili smo f1 rezultat od 43,10%, 59,45% i 44,84% za engleski, hindi i Bengali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Under de senaste åren har hatpropaganda och aggressiva kommentarer täckt nästan alla sociala medieplattformar som facebook, twitter etc. Som ett resultat av detta ökar hatet. Denna uppsats beskriver vårt (Team name: Spyder) deltagande i Shared Task on Aggression Detection organiserad av TRAC-2, Andra Workshop om Trolling, Aggression och Cybermobbning. Arrangörerna tillhandahöll datauppsättningar på tre språk - engelska, hindi och bengaliska. Uppgiften var att klassificera varje instans av testuppsättningarna i tre kategorier - "Övergripande" (OAG), "Coverly Aggressive" (CAG) och "Non-Aggressive" (NAG). I denna uppsats föreslår vi tre olika modeller med hjälp av Tf-Idf, sentimentpolaritet och maskininlärningsbaserade klassificerare. Vi fick f1 poäng på 43,10%, 59,45% respektive 44,84% för engelska, hindi och bengali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Katika miaka michache iliyopita, hotuba ya chuki na maoni ya kibaguzi yamekuwa yakitangaza karibu majukwaa ya mitandao ya kijamii kama vile Facebook, twita etc. Matokeo yake yanaongezeka chuki. Gazeti hili linaelezea (jina la timu: Spyder) kushiriki katika kazi ya kushirikiana kwenye Utafiti wa Makubaliano ulioandaliwa na TRAC-2, Warsha ya pili kuhusu Uvunjifu, Matukio na Mtandao. Waandaaji walitoa taarifa kwa lugha tatu - Kiingereza, Kihindi na Bengali. Kazi hiyo ilikuwa ni kuwadhibiti kila aina ya jaribio hilo linatengeneza katika makundi matatu - 'Kwa ujumla Aggressive' (OAG), 'Maandamano makubwa' (CAG) na 'Sio Aggressive' (NAG). Katika karatasi hii, tunapendekeza mifano mitatu tofauti kwa kutumia Tf-Idf, unyanyasaji wa hisia na kujifunza mashine yenye msingi. Tumepata vipindi vya f1 kwa asilimia 43.10, 59.45% na 44.84 kwa ajili ya Kiingereza, Hindi na Bengali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>கடந்த சில ஆண்டுகளில், வெறுப்பு பேச்சு மற்றும் அக்கிரமமான கருத்துக்கள் கிட்டத்தட்ட அனைத்து சமூக ஊடக முறைமைகளை மூடியிருக்கிறத இந்த காகிதத்தில் எங்கள் (குழு பெயர்: ஸ்பைட்டர்) TRAC- 2 ஆல் நிறுவப்பட்ட வேலையில் பங்கிடப்பட்டுள்ளது என்ற பணியில் பகிர்ந்து கொள்ளப்படுகிறது, ட்ரால் நிறுவனர்கள் மூன்று மொழிகளில் தகவல் அமைப்பு சோதனை அமைப்புகளின் ஒவ்வொரு நிகழ்வும் மூன்று வகுப்புகளாக வகுப்படுத்த வேண்டும் 'மேலும் Aggressive' (OAG), 'Covertly Aggressive' (CAG) மற்றும் 'Aggressive' (NAG). இந்த காகிதத்தில், Tf-Idf, உணர்வு தீவிரம் மற்றும் இயந்திரம் வகுப்பாளர் நாங்கள் ஆங்கிலத்து, ஹின்டி மற்றும் பெங்காலிக்கு நிதியாக 43.10%, 59.45% மற்றும் 44.84% கிடைத்தோம்.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Soňky ýylda ýigrenýän çykyş we agresýji terjimeler diňe facebook, twitter we şeýle ýaly sosyal medialaryň platformlaryny üýtgedýär. netijeli ýigrenýän bolsa. Bu kagyz biziň (topar adymyzy: Spyder) TRAC-2, Ilkinji Trollin, Aggresiýa we Cyberbulliýa tarapyndan çykyşymyzyň (topar ady: Spyder) bölegimizi barlaýar. Gurganlar üç dilde maglumat setirini – Iňlisçe, Hindi we Bengali ýa dilde temin etdiler. Bu hat üç kategoriýa içine synanyşan her sahypany bejerilmek üçin. - 'Üzgün Aggresiýan' (OAG), 'Covertly Aggressive' (CAG) we 'Non-Aggressive' (NAG). Bu kagyzda Tf-Idf, duýgular polaritet we maşynyň öwrenmegi tabanly klassiflerden üç dürli nusgalary teklip edýäris. Biz f1 sany 43,10%, 59,45% we 44,84% iňlisçe, Hindiler we Bengaliler üçin aldyk.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>پچھلے چند سال میں، ناپسند بات اور سختی کی کمانٹیاں تقریباً تمام سوسیل میڈیا پٹرومٹیاں جیسے facebook, twitter اور اگلوں پر پورے ہوئے ہیں. نتیجہ میں نفرت بڑھتی ہے. This paper describes our (Team name: Spyder) participation in the Shared Task on Aggression Detection organized by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying. سازمان کرنے والوں نے تین زبانوں میں ڈاٹ سٹ دی - انگلیسی, ہندی اور بنگالی۔ اس کا کام یہ تھا کہ ہر امتحان سٹ کو تین کاٹیوں میں تقسیم کریں - 'زیادہ گریز' (OAG), 'Covertly Aggressive' (CAG) اور 'Non-Aggressive' (NAG)۔ اس کاغذ میں ہم Tf-Idf کے استعمال سے تین مختلف موڈل پیشنهاد کرتے ہیں، احساسات آلودگی اور ماشین سیکھنے کی بنیادی کلاسیٹر کے استعمال سے۔ ہم نے 43.10%, 59.45% اور 44.84% انگلیسی, ہندی اور بنگالی کے لئے f1 سکوٹ پائی۔</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Keyingi necha yil ichida, kuch aytish va aggressiv izohlar faqat facebook, twitter etc. kabi hamma jamiyat medya platformlarini qaraydi. natijada hat ko'prodi. Бу саҳифа бизнинг (Team номи: Spyder) TRAC-2, Тўғрилик, Китоб ва Кипробляция Қуйидаги ўзгартириш вазифасига шерик бўлишимизни айтиб беради. Dasturlar uch tillarda maʼlumotlar tarkibini ingliz, Hindi va Bengalcha tilida yaratadi. Name Bu qogʻozda, biz Tf-Idf, hissiyot polariyat va mashinalar asosida o'rganishga uchta boshqa modellarni rivojlanamiz. Biz ingliz, Hindi va Bengalchaga har xizmat 43.10%, 59.45% va 44.84% foizdan foydalandik.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Trong những năm gần đây, lời nói căm ghét và những bình luận tích cực đã bao trùm hầu hết các nền tảng truyền thông xã hội như facebook, twitter, v.v. Kết quả là sự căm ghét đang tăng dần. Tờ giấy này mô tả sự tham gia của chúng ta (tên của nhóm: Spyder) vào "Việc Điều tra tấn công" được chia sẻ được tổ chức bởi TRAC-2, Thứ nhì "Xưởng làm việc" về tội phạm, rối loạn và nạn nhân ảo. Các tổ chức cung cấp dữ liệu bằng ba ngôn ngữ: Anh, Hindi và Bengali. Nhiệm vụ là phân loại mỗi trường hợp của các thử nghiệm thành ba loại "Tổng tấn công" khủng khiếp (OAS nhận nhận dạng A.G). và "không hung hãn" (NAG). Trong tờ giấy này, chúng tôi đề xuất ba mẫu khác nhau sử dụng các phân loại cảm xúc và các phân loại máy móc. Chúng tôi có kết quả F1 số lượng của 43.10=, 59.45=. và 44.84=. for English, Hindi và Bengali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>在昔数年,仇言攻击性论几覆社交媒体台,如Facebook,Twitter等。 仇方增。 本文引我(团队名:Spyder)与TRAC-2侵检之共同任务,再拖钓侵网络之研讨会。 组织者给三语数集 - 英语,印地语孟加拉语。 分试集为例为三 - "公攻击性"(OAG),"隐攻击性"(CAG)"非攻击性"(NAG)。 本文中,发用Tf-Idf,情极性与机器学分类器三者不同。 英语、印地语、孟加拉语f1得分为43.10%、59.45%、44.84%。</span></div></div><dl><dt>Anthology ID:</dt><dd>2020.trac-1.14</dd><dt>Volume:</dt><dd><a href=/volumes/2020.trac-1/>Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying</a></dd><dt>Month:</dt><dd>May</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Marseille, France</dd><dt>Venues:</dt><dd><a href=/venues/lrec/>LREC</a>
| <a href=/venues/trac/>TRAC</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>European Language Resources Association (ELRA)</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>87–92</dd><dt>Language:</dt><dd>English</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.trac-1.14>https://aclanthology.org/2020.trac-1.14</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">datta-etal-2020-spyder</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Anisha Datta, Shukrity Si, Urbi Chakraborty, and Sudip Kumar Naskar. 2020. <a href=https://aclanthology.org/2020.trac-1.14>Spyder : Aggression Detection on Multilingual TweetsSpyder: Aggression Detection on Multilingual Tweets</a>. In <i>Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying</i>, pages 87–92, Marseille, France. European Language Resources Association (ELRA).</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2020.trac-1.14>Spyder : Aggression Detection on Multilingual TweetsSpyder: Aggression Detection on Multilingual Tweets</a> (Datta et al., TRAC 2020)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2020.trac-1.14.pdf>https://aclanthology.org/2020.trac-1.14.pdf</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2020.trac-1.14.pdf title="Open PDF of 'Spyder : Aggression Detection on Multilingual TweetsSpyder: Aggression Detection on Multilingual Tweets'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Spyder+%3A+Aggression+Detection+on+Multilingual+TweetsSpyder%3A+Aggression+Detection+on+Multilingual+Tweets" title="Search for 'Spyder : Aggression Detection on Multilingual TweetsSpyder: Aggression Detection on Multilingual Tweets' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'Spyder : Aggression Detection on Multilingual TweetsSpyder: Aggression Detection on Multilingual Tweets'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[Spyder : Aggression Detection on Multilingual TweetsSpyder: Aggression Detection on Multilingual Tweets](https://aclanthology.org/2020.trac-1.14) (Datta et al., TRAC 2020)</p><ul class=mt-2><li><a href=https://aclanthology.org/2020.trac-1.14>Spyder : Aggression Detection on Multilingual TweetsSpyder: Aggression Detection on Multilingual Tweets</a> (Datta et al., TRAC 2020)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Anisha Datta, Shukrity Si, Urbi Chakraborty, and Sudip Kumar Naskar. 2020. <a href=https://aclanthology.org/2020.trac-1.14>Spyder : Aggression Detection on Multilingual TweetsSpyder: Aggression Detection on Multilingual Tweets</a>. In <i>Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying</i>, pages 87–92, Marseille, France. European Language Resources Association (ELRA).</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>