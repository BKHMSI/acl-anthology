<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Harnessing Indirect Training Data for End-to-End Automatic Speech Translation : Tricks of the Trade - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="Harnessing Indirect Training Data for End-to-End Automatic Speech Translation : Tricks of the Trade" name=citation_title><meta content="Juan Pino" name=citation_author><meta content="Liezl Puzon" name=citation_author><meta content="Jiatao Gu" name=citation_author><meta content="Xutai Ma" name=citation_author><meta content="Arya D. McCarthy" name=citation_author><meta content="Deepak Gopinath" name=citation_author><meta content="Proceedings of the 16th International Conference on Spoken Language Translation" name=citation_conference_title><meta content="2019" name=citation_publication_date><meta content="https://aclanthology.org/2019.iwslt-1.18.pdf" name=citation_pdf_url><meta property="og:title" content="Harnessing Indirect Training Data for End-to-End Automatic Speech Translation : Tricks of the Trade"><meta property="og:image" content="https://aclanthology.org/thumb/2019.iwslt-1.18.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2019.iwslt-1.18"><meta property="og:description" content="Juan Pino, Liezl Puzon, Jiatao Gu, Xutai Ma, Arya D. McCarthy, Deepak Gopinath. Proceedings of the 16th International Conference on Spoken Language Translation. 2019."><link rel=canonical href=https://aclanthology.org/2019.iwslt-1.18></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2019.iwslt-1.18.pdf>Harnessing Indirect Training Data for End-to-End Automatic Speech Translation : Tricks of the Trade</a>
<a id=af_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Onderhou Indirekte Oefening Data vir Einde- na- Einde Automaties Spraak Vertaling: Tricks of the Trade</a>
<a id=am_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Tricks of the Trade</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>تسخير بيانات التدريب غير المباشر للترجمة التلقائية للكلام: حيل التجارة</a>
<a id=az_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Son-to-end avtomatik s칬z 칞evirilm톛si 칲칞칲n indir톛t t톛hsil m톛lumat캼 istifad톛 edilir: ticar톛t s캼ralar캼</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Използване на индиректни данни за обучение за автоматичен речен превод от край до край: трикове на търговията</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>স্বয়ংক্রিয়ভাবে স্বাক্ষরিক ভাষণ অনুবাদের জন্য স্থানীয় প্রশিক্ষণের তথ্য হার্নাসিং করছে: ট্রাইডের ট্রিক</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>མཇུག་ལ་མཇུག་གི་སྐད་ཡིག་ཆ་ལ་རང་འགུལ་གྱི་སྐད་བསྒྱུར་བཅོས་ཐབས་མེད་པའི་ཐད་ཚོགས་གཙོ་རིམ།</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Koristenje podataka o indirektnom obuci za automatski prevod govora do kraja: Trikovi trgovine</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Utilitzar les dades d'entrenament indirect per a traduir la llengua automàtica de final a final: trucs del comerç</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Využití nepřímých tréninkových dat pro komplexní automatický překlad řeči: triky obchodu</a>
<a id=da_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Udnyttelse af indirekte træningsdata til automatisk taleoversættelse end-to-end: Tricks of te Trade</a>
<a id=de_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Indirekte Trainingsdaten für die End-to-End automatische Sprachübersetzung nutzen: Tricks of the Trade</a>
<a id=el_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Αξιοποίηση έμμεσων δεδομένων κατάρτισης για την αυτόματη μετάφραση ομιλίας εξ ολοκλήρου: κόλπα του εμπορίου</a>
<a id=es_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Aprovechamiento de datos de entrenamiento indirectos para la traducción automática de voz de principio a fin: trucos del oficio</a>
<a id=et_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Kaudse koolituse andmete kasutamine otsast otsani automaatse kõnetõlke jaoks: kaubanduse trikid</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>استفاده از داده‌های آموزش غیرمستقیم برای ترجمه‌های گفتگوی خودکار پایان به پایان: ترکیب‌های تجارت</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Välillisten koulutustietojen hyödyntäminen päästä päähän automaattiseen puheen kääntämiseen: kaupan temput</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Exploiter les données de formation indirectes pour une traduction vocale automatique de bout en bout : les astuces du métier</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Leas a Bhaint as Sonraí Oiliúna Indíreacha le haghaidh Aistriúchán Urlabhra Uathoibríoch ó cheann go ceann: Seifteanna na Trádála</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>@ action</a>
<a id=he_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>שימוש מידע אימון אינדריט לתרגום אוטומטי של נאום סוף-סוף: טריקים של הסחר</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>एंड-टू-एंड स्वचालित भाषण अनुवाद के लिए अप्रत्यक्ष प्रशिक्षण डेटा का दोहन: व्यापार की ट्रिक्स</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Koristenje podataka o indirektnom obuku za automatski prevod govora do kraja: Trikovi trgovine</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Közvetett képzési adatok hasznosítása végpontos automatikus beszédfordításhoz: a kereskedelem trükkjei</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Օգտագործելով անուղղակի ուսուցման տվյալները վերջ-վերջ ավտոմատիկ խոսքի թարգմանման համար.</a>
<a id=id_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Menggunakan Data Pelatihan Indirekt untuk Perjemahan Ucapan Otomatis Akhir-Akhir: Tricks of the Trade</a>
<a id=is_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Sfruttare i dati di formazione indiretta per una traduzione vocale automatica end-to-end: trucchi del mestiere</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>エンドツーエンドの自動音声翻訳のための間接トレーニングデータの活用：取引のコツ</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>politenessoffpolite"), and when there is a change ("assertivepoliteness</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>ბოლოდან ბოლოდან ბოლოდან დასრულებული სიტყვების თავისწორება: სამუშაო თავისწორება</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Аяқтау- аяқтау автоматты сөйлеу аудармасының жетілдік оқыту деректерін қолдануға болады: Салымды тәртіптері</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>간접 트레이닝 데이터를 이용하여 끝에서 끝까지 자동 음성 번역: 기교</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Netiesioginio mokymo duomenų, skirtų automatiniam kalbos vertimui nuo pabaigos, panaudojimas: prekybos triukšmai</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Употреба на индиректни податоци за обука за автоматски превед на говор од крај до крај: Трикови од трговијата</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>അവസാന- മുതല്‍ അവസാനിക്കുന്ന സ്വയമായി സംസാര പരിശീലന വിവരങ്ങള്‍</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Бүтээгдэхүүний төгсгөл-төгсгөлд автоматически ярианы хөрөнгө оруулалт: Худалдааны шинжлэх ухаан</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Menggunakan Data Latihan Tidak Terlangsung untuk Terjemahan Ucapan Automatik Akhir-Akhir: Tricks of the Trade</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Harnessing Indirect Training Data for End-to-End Automatic Speech Translation: Tricks of the Trade</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Indirecte trainingsgegevens gebruiken voor end-to-end automatische spraakvertaling: trucs van de handel</a>
<a id=no_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Hentar indirekte treningsdata for automatisk taleomsetjing til slutt til slutt: Tricks of the Trade</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Wykorzystanie pośrednich danych szkoleniowych do kompleksowego automatycznego tłumaczenia mowy: sztuczki handlowe</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Aproveitando dados de treinamento indireto para tradução automática de fala de ponta a ponta: truques do comércio</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Utilizarea datelor indirecte de formare pentru traducerea automată a vorbirii end-to-end: trucurile comerțului</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Использование непрямых обучающих данных для сквозного автоматического перевода речи: торговые уловки</a>
<a id=si_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>අවසානයෙන් අවසානයෙන් ස්වයංක්‍රීය වාර්තාව සඳහා අනිත් ප්‍රධාන දත්ත සම්බන්ධ කරනවා: ව්‍යාපාරයේ ස</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Izkoriščanje podatkov o posrednem usposabljanju za avtomatsko prevajanje govora od konca do konca: triki trgovine</a>
<a id=so_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Turjumidda dhammaadka-to-End Automatic Speech: Tricks of the Trade</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Përdorimi i të dhënave të trajnimit të pavarur për përkthimin automatik të fjalës nga fundi në fund: Tricks of the Trade</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Koristenje indirektnih podataka obuke za automatski prevod govora do kraja: Trikovi trgovine</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Utnyttja indirekta träningsdata för automatisk talöversättning från början till slut: tricks of the trade</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Takwimu za mafunzo ya Kihindi kwa ajili ya Tafsiri ya kujieleza binafsi ya Kuishia hadi mwishoni: Tricks of the Trade</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>முடிவில் இருந்து முடிவில் இருந்து தானியங்கி பேச்சு மொழிபெயர்ப்பிற்கான குறிப்பிட்ட பயிற்சி தகவல்</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Soňra-soňra Awtomatik Sözler terjime etmek üçin Taýratyn Ewezam Maglumaty Hareketlenýän: Täkiýet Trikleri</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>پایان سے پایان کے لئے نازل ترینیننگ ڈاٹے کے مطابق اپنا انویٹ ژنرال کیا جا رہا ہے: تجارت کی تریکس</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Tricks of the Trade</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>Đang sử dụng dữ liệu giáo dục trực tiếp cho giai đoạn nói tự động cuối:</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2019.iwslt-1.18.pdf>因间接练数端到端自音译:交易技巧</a></h2><p class=lead><a href=/people/j/juan-pino/>Juan Pino</a>,
<a href=/people/l/liezl-puzon/>Liezl Puzon</a>,
<a href=/people/j/jiatao-gu/>Jiatao Gu</a>,
<a href=/people/x/xutai-ma/>Xutai Ma</a>,
<a href=/people/a/arya-d-mccarthy/>Arya D. McCarthy</a>,
<a href=/people/d/deepak-gopinath/>Deepak Gopinath</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>For automatic speech translation (AST), end-to-end approaches are outperformed by cascaded models that transcribe with automatic speech recognition (ASR), then trans- late with machine translation (MT). A major cause of the performance gap is that, while existing AST corpora are small, massive datasets exist for both the ASR and MT subsystems. In this work, we evaluate several data augmentation and pretraining approaches for <a href=https://en.wikipedia.org/wiki/Abstract_syntax_tree>AST</a>, by comparing all on the same <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>. Simple <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> by translating ASR transcripts proves most effective on the EnglishFrench augmented LibriSpeech dataset, closing the performance gap from 8.2 to 1.4 BLEU, compared to a very strong cascade that could directly utilize copious ASR and MT data. The same <a href=https://en.wikipedia.org/wiki/End-to-end_principle>end-to-end approach</a> plus <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> closes the gap on the EnglishRomanian MuST-C dataset from 6.7 to 3.7 <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>. In addition to these results, we present practical rec- ommendations for augmentation and pretraining approaches. Finally, we decrease the performance gap to 0.01 BLEU us- ing a Transformer-based architecture.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vir outomatiese woorde vertaling (AST), die einde- na- einde toegang word uitgevoer deur kaskadeerde modele wat met outomatiese woorde herken (ASR), dan trans- laat met masjien vertaling (MT). 'n Hoogte oorsaak van die prestasie gap is dat, terwyl bestaande AST korpora klein is, massiewe datastelle bestaan vir beide die ASR en MT subsystemes. In hierdie werk, ons evalueer veelvuldige data vergroot en voorskyning toegang vir AST deur almal op dieselfde datastelle te vergelyk. Eenvoudige data vergroot deur die vertaling van ASR-transkripte te bevestig mees effektief op die Engelse-Franse vergroot LibriSpeech-datastel, toe die prestasie afstand van 8.2 tot 1.4 BLEU toesluit, vergelyk met 'n baie sterk kaskade wat direk kan gebruik kopiese ASR en MT-data. Die selfde einde-tot-einde toegang plus fin-tuning sluit die afstand op die Engelse-Romaniese MuST-C datastel van 6.7 tot 3.7 BLEU. In addition to these results, we present practical rec- commands for augmentation and pretraining approaches. Eindelik, ons verklein die prestasie afstand tot 0,01 BLES ons - om 'n Transformer-gebaseerde arkitektuur te verminder.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>For automatic speech translation (AST), the final approach is made by cascaded models that write with automatic speech recognition (ASR), then trans-late with machine translation (MT). የድምፅ ውጤት ግንኙነት በጣም ትልቅ ምክንያት ነው፣ የአስቲ ኮርፖርት ግን ትንሽ ነው፣ የASR እና MT ደብዳቤዎች ደግሞ የብዙ ዳታተር ሰርቨሮች አሉ፡፡ በዚህ ስራ፣ የዳታ አካባቢ እና የAST ደረጃዎችን ለመፍጠር እናሳውቃለን፡፡ ASR transcripts በመግለጫ ቀላል ዳታ ማድረግ በአፍሪካዊ-ፈረንሳይኛ የተጨማሪው የልቤሪንግ ቋንቋ ማድረጊያውን በመግለጫው ይታያል፡፡ ከ8.2 እስከ 1.4 BLEU በመግለጫው ነው፡፡ ይህም የመጨረሻ ቀውስ እና ጥሩ ቀለሞች እንግሊዝኛ-ሮማኒያን MuST-C ዳታተር ከ6.7 ጀምሮ 3.7 BLEU ላይ የሚደረገውን ክፍተት ይጠብቃሉ፡፡ ከዚህም ፍጥረቶች በቀር፣ ለመደጋገፍ እና ለመዘጋጀት የሚደረገውን የስህተት አካባቢ አዳራሽ እናደርጋለን፡፡ በመጨረሻውም የድምፅ ውጤት ወደ 0.01 BLEU እናጎድልናለን - የTransformer-based መሠረት መሠረት እናሳድጋለን፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>بالنسبة للترجمة الآلية للكلام (AST) ، يتفوق أداء الأساليب الشاملة على النماذج المتتالية التي يتم نسخها باستخدام التعرف التلقائي على الكلام (ASR) ، ثم الترجمة الآلية (MT). أحد الأسباب الرئيسية لفجوة الأداء هو أنه في حين أن مجموعات AST الحالية صغيرة ، توجد مجموعات بيانات ضخمة لكل من النظامين الفرعيين لـ ASR و MT. في هذا العمل ، نقوم بتقييم العديد من أساليب زيادة البيانات والتدريب المسبق لـ AST ، من خلال مقارنة الكل في نفس مجموعات البيانات. أثبتت زيادة البيانات البسيطة عن طريق ترجمة نصوص ASR أنها أكثر فاعلية على مجموعة بيانات LibriSpeech المعززة باللغتين الإنجليزية والفرنسية ، مما أدى إلى سد فجوة الأداء من 8.2 إلى 1.4 BLEU ، مقارنة بسلسلة قوية جدًا يمكن أن تستخدم بشكل مباشر بيانات ASR و MT الوفيرة. نفس النهج الشامل بالإضافة إلى الضبط الدقيق يغلق الفجوة في مجموعة البيانات الإنجليزية-الرومانية MuST-C من 6.7 إلى 3.7 BLEU. بالإضافة إلى هذه النتائج ، نقدم توصيات عملية لزيادة وطرق التدريب. أخيرًا ، قمنا بتقليل فجوة الأداء إلى 0.01 BLEU باستخدام بنية قائمة على المحولات.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Avtomatik sözlər tercüməsi (AST) üçün, maşına tercüməsi (MT) ilə yazılan kaskadlı modellər tərəfindən istifadə edilir. Perfekt boşluğunun ən böyük səbəbi is ə, mevcut AST korporası kiçik olduğu halda, ASR və MT subsystemləri üçün çox böyük veri qurğuları var. Bu işdə, bir neçə məlumat artırmağı və AST üçün təklif metodlarını değerləşdiririk, bütün məlumat qurmaqlarını bir-birinə qarşılaşdırırıq. ASR transkriptlərini tercümə edərək basit məlumat artırması İngiliz-Fransızca yüksələn LibriSpeech veri qutusunda ən etkili göstərir, performans boşluğunu 8.2 ilə 1.4 BLEU ilə bağlayar, köpüsü ASR və MT veriləri istifadə edə bilən çox qüvvətli kascada ilə qarşılaşdırır. Aynı son-to-end approach artıq fin tuning İngiliz-Rumun MuST-C veri qutusu 6,7-3,7 BLEU-dən istifadə edir. Bu sonuçları da artırmaq və təmizləmək üçün praktik yenidən təkrar-təkrarları göstəririk. Sonunda, performans boşluğunu 0,01 BLEU-ə düşürürük - Transformer-based arhitektura.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>При автоматичен речен превод (АСТ) подходите от край до край се превъзхождат от каскадни модели, които транскрибират с автоматично разпознаване на речта (АСР), след което транслатират с машинен превод (МТ). Основна причина за разликата в ефективността е, че докато съществуващите корпуси на AST са малки, съществуват масивни набори от данни както за подсистемите ASR, така и MT. В тази работа ние оценяваме няколко подхода за увеличаване и предтрениране на данни за АСТ, като сравняваме всички на едни и същи набори от данни. Опростеното увеличаване на данните чрез превод на транскрипции се оказва най-ефективно върху английско-френския разширен набор от данни, затваряйки разликата в ефективността от 8.2 до 1.4 в сравнение с много силна каскада, която може директно да използва изобилни данни. Същият подход от край до край плюс фина настройка затваря разликата в английско-румънския набор от данни от 6.7 до 3.7 Блеу. В допълнение към тези резултати представяме практически препоръки за подходи за разширение и предобучение. И накрая, намаляваме разликата в производителността до 0.01 чрез изграждане на базирана на трансформатор архитектура.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>স্বয়ংক্রিয় ভাষণ অনুবাদের জন্য (AST) শেষ পর্যন্ত ক্যাস্কেডের মোডেল দ্বারা শেষ পর্যন্ত প্রদর্শন করা হয় যা স্বয়ংক্রিয় ভাষণ স্বীকৃতির সাথে লেখা লেখ প্রদর্শনের প্রধান কারণ হচ্ছে যে এসটি কোর্পোরা বিদ্যমান ছোট, এসআর আর এমটি সাবসিস্টেমের জন্য বিশাল ডাটাসেট রয়েছে। এই কাজে আমরা বেশ কয়েকটি তথ্য যোগাযোগ এবং আস্টের জন্য বৃষ্টিপাতের ক্ষেত্রেও মূল্যায়ন করি, একই তথ্যের সাথে তুলনা করে। Simple data augmentation by translating ASR transcripts proves most effective on the English-French augmented LibriSpeech dataset, closing the performance gap from 8.2 to 1.4 BLEU, compared to a very strong cascade that could directly utilize copious ASR and MT data. একই শেষ পর্যন্ত প্রতিক্রিয়া এবং সুন্দর টুনিং এর সাথে ইংরেজি-রোমানিয়ান মুস্টি-সি ডাটাসেট থেকে ৬. ৭ থেকে ৩. এই ফলাফল ছাড়াও আমরা বাড়তে পারি এবং বৃষ্টির প্রাকৃতিক পুনরাবৃত্তি উপস্থাপন করি। Finally, we decrease the performance gap to 0.01 BLEU us- ing a Transformer-based architecture.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>For automatic speech translation (AST), end-to-end approaches are outperformed by cascaded models that transcribe with automatic speech recognition (ASR), then trans-late with machine translation (MT). performance gaps་ལ་གལ་ཆེ་བའི་རྒྱུ་མཚན་ནི་གནས་ཡུལ་ཡོད་པའི་ AST སྒེར་གྱི་མཐུད་སྒྲིག་ཆ་ཆུང In this work, we evaluate several data augmentation and pretraining approaches for AST, by comparing all on the same data sets. Simple data augmentation by translating ASR transcripts proves most effective on the English-French augmented LibriSpeech dataset, closing the performance gap from 8.2 to 1.4 BLEU, compared to a very strong cascade that could directly utilize copious ASR and MT data. The same end-to-end approach plus fine-tuning closes the gaps on the English-Romanian MuST-C dataset from 6.7 to 3.7 BLEU. BLEU. གསལ་འབྲས་འདི་དག་ལས་བརྟེན། ང་ཚོས་རྒྱ་བསྐྱེད་སྐབས་སུ་གཏོང་བའི་ཐབས་ལམ་ལ་ཡང་བསྡད་པའི་བརྗོད་བཀོད་པ་ཞིག་ཡོད། མཐའ་མཇུག་དུ། འུ་ཅག་གིས་སྔར་ནས་དབྱིབས་བཟོས་པའི་བཟོ་བརྩིས་གཞི་བརྩིས་གཞི་བཟོ་བྱེད་ཀྱི་ཡོད་ཚད་0.01</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Za automatski prevod govora (AST), pristupi na kraju do kraja iznosi kaskadni modeli koji prepisuju automatskim priznanjem govora (ASR), a zatim prekasni sa prevodom mašine (MT). Veliki uzrok praznine predstave je da, iako postojeća AST korpora su mala, masivna podataka postoji za ASR i MT podsustava. U ovom poslu procjenjujemo povećanje podataka i pretvaranje pristupa AST-u, uspoređujući sve na istim podacima. Jednostavno povećanje podataka prevodeći transkript ASR pokazuje najučinkovitiji na kompletu povećanih podataka LibriSpeech na engleskom francuskom i francuskom, zatvarajući prazninu učinkovitosti od 8,2 do 1,4 BLEU, u usporedbi sa vrlo jakom kaskadom koja bi mogla izravno iskoristiti kopijske ASR i MT podatke. Isti pristup kraja do kraja plus fino podešavanje zatvara prazninu na dataset engleskog-rumunskog MuST-C od 6,7 do 3,7 BLEU. Osim ovih rezultata, predstavljamo praktične rekompendacije za povećanje i pretvaranje pristupa. Konačno, smanjujemo prazninu učinkovitosti na 0,01 BLEU-u koji nam je osnovana na transformatorskoj arhitekturi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>For automatic speech translation (AST), end-to-end approaches are outperformed by cascaded models that transcribe with automatic speech recognition (ASR), then trans- late with machine translation (MT). A major cause of the performance gap is that, while existing AST corpora are small, massive datasets exist for both the ASR and MT subsystems. En aquest treball, evaluem diversos enfocaments d'augment de dades i de pré-capacitació per a AST, comparant-los tots en els mateixos conjunts de dades. Simple data augmentation by translating ASR transcripts proves most effective on the English-French augmented LibriSpeech dataset, closing the performance gap from 8.2 to 1.4 BLEU, compared to a very strong cascade that could directly utilize copious ASR and MT data. El mateix enfocament de punta a punta, més ajustes, tanca la diferència en el conjunt de dades MuST-C anglo-rumun de 6,7 a 3,7 BLEU. A més d'aquests resultats, presentem recomanacions pràctiques per a l'augmentació i l'anticraining. Finalment, reduïm la diferència de rendiment a 0,01 BLEU, una arquitectura basada en Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>V případě automatického překladu řeči (AST) jsou koncové přístupy překonány kaskádovými modely, které přepisují s automatickým rozpoznáváním řeči (ASR) a poté překládají strojovým překladem (MT). Hlavní příčinou výkonnostní mezery je, že zatímco existující AST korpusy jsou malé, existují masivní datové sady jak pro subsystémy ASR, tak MT. V této práci vyhodnocujeme několik přístupů rozšíření a předškolení dat pro AST, porovnáním všech na stejných datových sadách. Jednoduchá rozšíření dat překladem ASR transkriptů se ukázalo jako nejúčinnější na anglicko-francouzském rozšířeném datovém souboru LibriSpeech, čímž uzavírá mezeru výkonu od 8.2 do 1.4 BLEU, ve srovnání s velmi silnou kaskádou, která by mohla přímo využít hojná ASR a MT data. Stejný end-to-end přístup a jemné ladění překlenují mezeru v anglicko-rumunské datové sadě MuST-C od 6.7 do 3.7 BLEU. Kromě těchto výsledků představujeme praktické doporučení pro augmentační a předškolení přístupů. Konečně snižujeme výkonnostní mezeru na 0.01 BLEU s architekturou založenou na Transformeru.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>For automatisk taleoversættelse (AST) udføres end-to-end-tilgange af kaskademodeller, der transkriber med automatisk talegenkendelse (ASR) og derefter transskriber med maskinoversættelse (MT). En væsentlig årsag til performance gap er, at mens eksisterende AST corpora er små, eksisterer massive datasæt for både ASR og MT delsystemer. I dette arbejde evaluerer vi flere data augmentation og pre-training metoder for AST ved at sammenligne alle på de samme datasæt. Enkel dataudvidelse ved oversættelse af ASR-transskriptioner viser sig at være mest effektiv på det engelsk-franske augmented LibriSpeech datasæt, hvilket lukker præstationshullet fra 8,2 til 1,4 BLEU sammenlignet med en meget stærk kaskade, der direkte kunne udnytte rigelige ASR- og MT-data. Den samme end-to-end-tilgang plus finjustering lukker hullet i det engelsk-rumænske MuST-C datasæt fra 6,7 til 3,7 BLEU. Ud over disse resultater præsenterer vi praktiske anbefalinger til forstærkning og forudtræning tilgange. Endelig mindsker vi præstationskløften til 0,01 BLEU ved at bruge en Transformer-baseret arkitektur.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bei der automatischen Sprachübersetzung (AST) werden End-to-End-Ansätze durch kaskadierte Modelle übertroffen, die mit automatischer Spracherkennung (ASR) transkribieren und dann mit maschineller Übersetzung (MT) übersetzen. Eine Hauptursache für die Leistungslücke ist, dass bestehende AST-Korpora zwar klein sind, aber massive Datensätze sowohl für das ASR- als auch für das MT-Subsystem existieren. In dieser Arbeit evaluieren wir verschiedene Ansätze zur Datenaugmentation und -pretraining für AST, indem wir alle auf denselben Datensätzen vergleichen. Die einfache Datenauswertung durch die Übersetzung von ASR-Transkripten erweist sich am effektivsten auf dem englisch-französischen erweiterten LibriSpeech-Datensatz und schließt die Leistungslücke von 8.2 bis 1.4 BLEU im Vergleich zu einer sehr starken Kaskade, die umfangreiche ASR- und MT-Daten direkt nutzen könnte. Der gleiche End-to-End-Ansatz und die Feinabstimmung schließen die Lücke im englisch-rumänischen MuST-C-Datensatz von 6.7 bis 3.7 BLEU. Zusätzlich zu diesen Ergebnissen präsentieren wir praktische Empfehlungen für Augmentations- und Vortrainingsansätze. Schließlich verringern wir die Leistungslücke auf 0.01 BLEU mit einer Transformer-basierten Architektur.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Για την αυτόματη μετάφραση ομιλίας (AST), οι ολοκληρωμένες προσεγγίσεις ξεπερνούν από διαδοχικά μοντέλα που μεταγραφούν με αυτόματη αναγνώριση ομιλίας (ASR) και στη συνέχεια μεταγραφούν με μηχανική μετάφραση (MT). Μια κύρια αιτία του χάσματος επιδόσεων είναι ότι, ενώ τα υπάρχοντα σώματα AST είναι μικρά, υπάρχουν τεράστια σύνολα δεδομένων τόσο για το υποσύστημα ASR όσο και για το MT. Στην εργασία αυτή, αξιολογούμε διάφορες προσεγγίσεις αύξησης και προεπιλογής δεδομένων για την AST, συγκρίνοντας όλα τα ίδια σύνολα δεδομένων. Η απλή αύξηση δεδομένων με τη μετάφραση μεταγραφών αποδεικνύεται πιο αποτελεσματική στο αγγλο-γαλλικό εμπλουτισμένο σύνολο δεδομένων κλείνοντας το χάσμα απόδοσης από 8.2 έως 1.4 σε σύγκριση με έναν πολύ ισχυρό καταρράκτη που θα μπορούσε άμεσα να χρησιμοποιήσει άφθονα δεδομένα ASR και MT. Η ίδια ολοκληρωμένη προσέγγιση και η τελειοποίηση κλείνουν το κενό στο αγγλο-ρουμανικό σύνολο δεδομένων MuST-C από 6.7 έως 3.7 BLEU. Εκτός από αυτά τα αποτελέσματα, παρουσιάζουμε πρακτικές συστάσεις για προσεγγίσεις αύξησης και προεπιλογής. Τέλος, μειώνουμε το χάσμα απόδοσης σε 0.01 δημιουργώντας μια αρχιτεκτονική βασισμένη στον μετασχηματιστή.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Para la traducción automática de voz (AST), los enfoques de extremo a extremo se ven superados por los modelos en cascada que transcriben con reconocimiento automático de voz (ASR) y luego se traducen con traducción automática (MT). Una de las principales causas de la brecha de rendimiento es que, si bien los cuerpos AST existentes son pequeños, existen conjuntos de datos masivos para los subsistemas ASR y MT. En este trabajo, evaluamos varios enfoques de aumento de datos y preentrenamiento para AST, comparando todos en los mismos conjuntos de datos. El simple aumento de datos mediante la traducción de transcripciones de ASR resulta más eficaz en el conjunto de datos de LibriSpeech ampliado en inglés y francés, ya que cierra la brecha de rendimiento de 8,2 a 1,4 BLEU, en comparación con una cascada muy sólida que podría utilizar directamente una gran cantidad de datos de ASR y MT. El mismo enfoque de extremo a extremo más el ajuste fino cierra la brecha en el conjunto de datos Must-C de inglés a rumano de 6,7 a 3,7 BLEU. Además de estos resultados, presentamos recomendaciones prácticas para enfoques de aumento y preentrenamiento. Finalmente, disminuimos la brecha de rendimiento a 0,01 BLEU mediante una arquitectura basada en Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Automaatse kõnetõlke (AST) puhul ületatakse otsast otsa lähenemisviise kaskaadimudelitega, mis transkribeeritakse automaatse kõnetuvastusega (ASR), seejärel transkribeeritakse masintõlkega (MT). Tulemuslikkuse lõhe peamine põhjus on see, et kuigi olemasolevad AST korpused on väikesed, on nii ASR kui ka MT allsüsteemide jaoks olemas massiivsed andmekogumid. Käesolevas töös hindame mitmeid AST-i andmete suurendamise ja eeltreeningu meetodeid, võrreldes kõiki samadel andmekogumitel. Lihtne andmete suurendamine ASR transkriptsioonide tõlkimisega osutub inglise-prantsuse täiendatud LibriSpeech andmekogumi puhul kõige tõhusamaks, sulgedes jõudluse lõhe 8,2 kuni 1,4 BLEU-ni, võrreldes väga tugeva kaskaadiga, mis võiks otseselt kasutada palju ASR- ja MT-andmeid. Sama lõplik lähenemisviis koos peenhäälestusega kaotab lõhe inglise-rumeenia MuST-C andmekogumis vahemikus 6,7 kuni 3,7 BLEU. Lisaks nendele tulemustele esitame praktilisi soovitusi laiendamise ja eelõpetamise lähenemisviiside kohta. Lõpuks vähendame jõudluse lõhet 0,01 BLEU-ni, luues Transformer-põhise arhitektuuri.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>برای ترجمه سخنرانی خودکار (AST) روش‌های پایان به پایان از مدل‌های کاسکیدی که با شناسایی سخنرانی خودکار (ASR) ترجمه می‌کنند، سپس با ترجمه‌های ماشین (MT) ترجمه می‌کنند. یک دلیل بزرگی از فاصله عملکرد این است که در حالی که شرکت AST موجود کوچک هستند، مجموعه‌های داده‌های بزرگ برای سیستم‌های ASR و MT وجود دارد. در این کار، ما چندین افزایش داده ها را ارزیابی می کنیم و به طریق مقایسه کردن همه روی مجموعه‌های داده‌ها و روش‌های پیش‌گیری برای AST، با مقایسه کردن همه روی مجموعه‌های یکسان داده‌ها. افزایش داده‌های ساده با ترجمه ترجمه‌های ASR بر مجموعه داده‌های LibriSpeech افزایش داده‌های انگلیسی-فرانسوی ثابت می‌کند، و فاصله‌های عملکرد از 8.2 تا 1.4 BLEU را بسته می‌کند، در مقایسه با یک کاسکید بسیار قوی که می‌تواند مستقیماً از داده‌های ASR و MT استفاده کن همان دستور پایان و پایان و تنظیم نیکویی در مجموعه داده های انگلیسی-رومانی MuST-C از 6.7 تا 3.7 BLEU بسته است. در addition to these results, we present practical rec-commands for increased and pretraining approaches. بالاخره، ما فاصله عملکرد را به 0.01 BLEU کاهش می‌دهیم که یک معماری بنیاد تغییر دهنده است.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Automaattisessa puheen kääntämisessä (AST) end-to-end-lähestymiset suoritetaan kaskadimalleilla, jotka transkriбираvat automaattisella puheentunnistuksella (ASR) ja sitten konekäännöksellä (MT). Suuri syy suorituskykyvajeeseen on se, että vaikka olemassa olevat AST-korpuset ovat pieniä, sekä ASR- että MT-osajärjestelmissä on massiivisia tietokokonaisuuksia. Tässä työssä arvioimme useita AST:n tiedonlisäys- ja esikoulutusmenetelmiä vertaamalla kaikkia samoja aineistoja. Yksinkertainen datan lisääminen kääntämällä ASR-transkriptit osoittautuu tehokkaimmaksi englannin-ranskan laajennetussa LibriSpeech-aineistossa, sulkemalla suorituskykykuilun 8.2:sta 1.4 BLEU:hun verrattuna erittäin vahvaan kaskadiin, joka voisi suoraan hyödyntää runsaasti ASR- ja MT-dataa. Sama kokonaisvaltainen lähestymistapa ja hienosäätö sulkevat englannin ja romanian MuST-C-aineiston kuilun 6,7–3,7 BLEU. Näiden tulosten lisäksi esittelemme käytännön suosituksia lisä- ja esikoulutukseen. Lopuksi vähennämme suorituskykykuilua 0,01 BLEU:hun Transformer-pohjaisen arkkitehtuurin avulla.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Pour la traduction vocale automatique (AST), les approches de bout en bout sont surpassées par les modèles en cascade qui transcrivent avec la reconnaissance vocale automatique (ASR), puis traduisent avec la traduction automatique (MT). L'une des principales causes de l'écart de performance est que, alors que les corpus AST existants sont petits, il existe des ensembles de données massifs pour les sous-systèmes ASR et MT. Dans ce travail, nous évaluons plusieurs approches d'augmentation de données et de pré-entraînement pour l'AST, en comparant toutes les approches sur les mêmes ensembles de données. L'augmentation simple des données par la traduction des transcriptions ASR s'avère plus efficace sur le jeu de données LibriSpeech augmenté anglais-français, comblant l'écart de performance de 8,2 à 1,4 UEBL, par rapport à une très forte cascade qui pourrait directement utiliser de nombreuses données ASR et MT. La même approche de bout en bout et le réglage fin comblent l'écart sur l'ensemble de données anglais-roumain MUST-C de 6,7 à 3,7 UEBL. En plus de ces résultats, nous présentons des recommandations pratiques pour les approches d'augmentation et de préentraînement. Enfin, nous réduisons l'écart de performance à 0,01 BLEU en utilisant une architecture basée sur Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Maidir le haistriúchán cainte uathoibríoch (AST), tá cur chuige ceann-go-deireadh níos fearr ag samhlacha cascáideacha a thras-scríobhtar le haitheantas cainte uathoibríoch (ASR), a thrasnaíonn le haistriúchán meaisín (MT) ansin. Príomhchúis leis an mbearna feidhmíochta is ea, cé go bhfuil corparáidí AST reatha beag, go bhfuil tacair shonraí ollmhóra ann do na fochórais ASR agus MT araon. San obair seo, déanaimid meastóireacht ar roinnt cineálacha cur chuige um mhéadú sonraí agus réamhoiliúint do AST, trí chomparáid a dhéanamh idir iad uile ar na tacair sonraí céanna. Is éifeachtaí méadú sonraí simplí trí thrascríbhinní ASR a aistriú ar thacar sonraí méadaithe LibriSpeech Béarla-Fraincis, ag dúnadh na bearna feidhmíochta ó 8.2 go 1.4 BLEU, i gcomparáid le easghluaiseachta an-láidir a d’fhéadfadh úsáid dhíreach a bhaint as sonraí ollmhóra ASR agus MT. Dúnann an cur chuige ceann go ceann céanna chomh maith le mionchoigeartú an bhearna ar an tacar sonraí Béarla-Rómhánach MST-C ó 6.7 go 3.7 BLEU. Chomh maith leis na torthaí seo, cuirimid i láthair moltaí praiticiúla maidir le cur chuige méadaithe agus réamhoiliúint. Ar deireadh, laghdóimid an bhearna feidhmíochta go 0.01 BLEU ag baint úsáide as ailtireacht Claochladán-bhunaithe.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>@ action: button Maɓalli wa gaura na aikin aiki ni'anar cẽwa, a lokacin da ke iya ƙaranci na shirin ATATAT, ana ƙunsa da data masu ƙaranci wa biyu masu ƙaranci na ATR da MT. Daga wannan aikin, muna ƙaddara ƙaramako da akan data da za'a ƙayyade hanyõyi wa ATATA, da sami-sami duk kan daidaita data. @ item license (short name) Tsarin duk ƙari zuwa ta ƙari kodi da tuning mai kyau yana rufe gap kan maɓallin Ingiriya-Romian Mustan-C na daga 6.7 zuwa 3.7 BLEU. Babu wannan matsayi, Munã halatar da mazaɓa na mazauni-mazaɓa wa ƙãri da kuma misãlai. Gani, Munã ƙarantar gaura da za'a kai 0.01 BLEU - ke samun makarantar da aka Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>עבור התרגום אוטומטי של דיבור (AST), גישות סוף-סוף מתקדמות על ידי דוגמנים קאסקודים שטרנסקודים עם זיהוי דיבור אוטומטי (ASR), ואז טרנס- מאוחר עם התרגום מכונת (MT). סיבה גדולה של הפער ביצועי היא שבעוד גופות AST קיימות הן קטנות, קבוצות מידע מסיביות קיימות גם עבור מערכות ASR וגם MT. בעבודה הזו, אנו מעריכים מספר שיעורים של נתונים ולגישות מחדש של AST, על ידי השוואה של כולם על אותם קבוצות נתונים. שיעור נתונים פשוט על ידי תרגום תורגם ASR מוכיח הכי יעיל על קבוצת נתונים של LibriSpeech הגדלה אנגלית-צרפתית, לסגור את הפער ביצועים מ-8.2 ל-1.4 BLEU, בהשוואה לקסקד חזק מאוד שיכול להשתמש ישירות בנתונים ASR ומטה. באותו גישה מסוף-לסוף ועוד התרגיל עצום את הפער על קבוצת מידע MuST-C אנגלי-רומנית מ-6.7 ל-3.7 BLEU. בנוסף לתוצאות אלה, אנו מציגים המלצות מעשיות לגבילה ולגישות מחדש. סוף סוף, אנחנו מפחידים את הפער ביצועים ל-0.01 BLEU אנחנו - הארכיטקטורה מבוססת Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>स्वचालित भाषण अनुवाद (एएसटी) के लिए, एंड-टू-एंड दृष्टिकोण कैस्केड मॉडल द्वारा बेहतर प्रदर्शन किया जाता है जो स्वचालित भाषण मान्यता (एएसआर) के साथ प्रतिलेखन करते हैं, फिर मशीन अनुवाद (एमटी) के साथ ट्रांस-लेट होते हैं। प्रदर्शन अंतर का एक प्रमुख कारण यह है कि, जबकि मौजूदा एएसटी कॉर्पोरेट छोटे हैं, एएसआर और एमटी सबसिस्टम दोनों के लिए बड़े पैमाने पर डेटासेट मौजूद हैं। इस काम में, हम एक ही डेटासेट पर सभी की तुलना करके एएसटी के लिए कई डेटा वृद्धि और प्रीट्रेनिंग दृष्टिकोणों का मूल्यांकन करते हैं। एएसआर टेपों का अनुवाद करके सरल डेटा वृद्धि अंग्रेजी-फ्रांसीसी संवर्धित LibriSpeech डेटासेट पर सबसे प्रभावी साबित होती है, 8.2 से 1.4 BLEU तक प्रदर्शन अंतर को बंद कर देती है, एक बहुत ही मजबूत कैस्केड की तुलना में जो सीधे प्रचुर मात्रा में एएसआर और एमटी डेटा का उपयोग कर सकती है। एक ही एंड-टू-एंड दृष्टिकोण प्लस फाइन-ट्यूनिंग अंग्रेजी-रोमानियाई MuST-C डेटासेट पर 6.7 से 3.7 BLEU तक के अंतर को बंद कर देता है। इन परिणामों के अलावा, हम वृद्धि और pretraining दृष्टिकोण के लिए व्यावहारिक rec-ommendations प्रस्तुत करते हैं। अंत में, हम प्रदर्शन अंतर को 0.01 BLEU तक कम करते हैं, जो हमें एक ट्रांसफॉर्मर-आधारित आर्किटेक्चर को कम करता है।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Za automatski prevod govora (AST), pristupi na kraju do kraja iznosi kaskadirani modeli koji prepisuju s automatskim priznanjem govora (ASR), a zatim transkasnim s prevodom stroja (MT). Veliki uzrok praznine učinkovitosti je da, iako postojeća AST korpora su mala, masivna podaci postoje za ASR i MT podsustava. U ovom poslu procjenjujemo povećanje podataka i pretvaranje pristupa AST-u, uspoređujući sve na istim podacima. Jednostavno povećanje podataka prevodeći transkripte ASR pokazuje najučinkovitiji na kompletu povećanih podataka LibriSpeech na engleskom francuskom i francuskom, zatvarajući prazninu učinkovitosti od 8,2 do 1,4 BLEU, u usporedbi s vrlo jakom kaskadom koja bi mogla izravno iskoristiti kopijske podatke ASR i MT-a. Isti pristup kraja do kraja plus fino podešavanje zatvara prazninu podataka engleskog-rumunskog MuST-C iz 6,7 do 3,7 BLEU-a. Osim ovih rezultata, predstavljamo praktične rekompendacije za povećanje i pretvaranje pristupa. Konačno, smanjujemo prazninu učinkovitosti na 0,01 BLEU-u koji nam je osnovana na transformeri arhitektura.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Az automatikus beszédfordítás (AST) esetében a end-to-end megközelítéseket olyan kaszkádos modellek végzik, amelyek automatikus beszédfelismeréssel (ASR), majd gépi fordítással (MT) transzformálják. A teljesítmény hiányának egyik fő oka, hogy míg a meglévő AST testek kicsi, nagy adatkészletek léteznek mind az ASR, mind az MT alrendszerek esetében. Ebben a munkában több adatbővítési és előkészítési megközelítést értékelünk az AST esetében, ugyanazon adatkészletek összehasonlításával. Az ASR átiratok fordításával történő egyszerű adatbővítés a leghatékonyabbnak bizonyul az angol-francia kiterjesztett LibriSpeech adatkészleten, csökkentve a teljesítmény hiányát 8.2 és 1.4 BLEU között, összehasonlítva egy nagyon erős kaszkáddal, amely közvetlenül felhasználható bőséges ASR és MT adatokat. Ugyanez a teljes körű megközelítés és finomhangolás csökkenti az angol-román MuST-C adatkészlet 6.7-től 3.7-ig terjedő rését. Ezen eredmények mellett gyakorlati ajánlásokat is bemutatunk a kiterjesztési és előkészítési megközelítésekre vonatkozóan. Végezetül, a teljesítmény hiányát 0,01 BLEU-ra csökkentjük egy Transformer alapú architektúrával.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ավտոմատիկ խոսքի թարգմանման (AST) համար վերջ-վերջ մոտեցումները դուրս են գալիս կասկադված մոդելների միջոցով, որոնք թարգմանվում են ավտոմատիկ խոսքի ճանաչման (ASR) միջոցով, հետո թարգմանվում են մեքենայի թարգմանման (MT) միջո Արդյունավետության բացառության հիմնական պատճառը այն է, որ մինչդեռ գոյություն ունի AST-ի կառուցվածքներ փոքր են, ASR-ի և MT-ի ենթահամակարգերի համար գոյություն ունի հսկայական տվյալներ: Այս աշխատանքի ընթացքում մենք գնահատում ենք որոշ տվյալների աճը և AST-ի նախադասական մոտեցումները' համեմատելով բոլորը նույն տվյալների համակարգերի վրա: ASR-ի թարգմանման միջոցով պարզ տվյալների աճը ամենաարդյունավետ է ապացուցում անգլերեն-ֆրանսերեն աճեցված գրադարձ տվյալների համակարգի վրա, փակելով արդյունավետության տարբերությունը 8.2-ից 1.4-ին, համեմատած շատ ուժեղ կասկադի հետ, որը կարող է անմիջապես օգտագործել ASR-ի և MT The same end-to-end approach plus fine-tuning closes the gap on the English-Romanian MuST-C dataset from 6.7 to 3.7 BLEU. Ավելին այս արդյունքներին, մենք ներկայացնում ենք ավելացման և նախադասական մոտեցումների պրակտիկ խորհուրդներ: Վերջապես, մենք նվազեցնում ենք արտադրողականության բացառությունը մինչև 0.01 ԲԼԵՎ-ը, որը մեզ հիմնված է Թանֆերմերների ճարտարապետության միջոցով:</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Untuk terjemahan pidato otomatis (AST), pendekatan akhir-akhir dilakukan oleh model kaskade yang transkrip dengan pengenal pidato otomatis (ASR), kemudian trans-terlambat dengan terjemahan mesin (MT). A major cause of the performance gap is that, while existing AST corpora are small, massive datasets exist for both the ASR and MT subsystems. Dalam pekerjaan ini, kami mengevaluasi beberapa data meningkat dan pendekatan pretraining untuk AST, dengan membandingkan semua pada set data yang sama. Pembesaran data sederhana dengan menerjemahkan transkrip ASR terbukti paling efektif pada set data LibriSpeech bertambah Inggris-Perancis, menutup ruang prestasi dari 8.2 ke 1.4 BLEU, dibandingkan dengan kaskade yang sangat kuat yang dapat langsung menggunakan data ASR dan MT yang saling berkuasa. Pendekatan akhir-akhir yang sama ditambah penyesuaian menutup ruang di dataset MuST-C Inggris-Romania dari 6.7 ke 3.7 BLEU. Selain hasil-hasil ini, kami mempersembahkan rekomandasi praktis untuk peningkatan dan pendekatan pretraining. Akhirnya, kita mengurangi ruang prestasi ke 0,01 BLEU kita- menjadi arsitektur berasaskan Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Per la traduzione vocale automatica (AST), gli approcci end-to-end sono superati da modelli a cascata che trascrivono con riconoscimento vocale automatico (ASR), quindi trans-late con traduzione automatica (MT). Una delle principali cause del gap di performance è che, mentre i corpi AST esistenti sono piccoli, esistono enormi set di dati sia per i sottosistemi ASR che MT. In questo lavoro, valutiamo diversi approcci di aumento dei dati e pre-formazione per AST, confrontando tutti sugli stessi set di dati. Il semplice aumento dei dati attraverso la traduzione di trascrizioni ASR si rivela più efficace sul set di dati LibriSpeech aumentato inglese-francese, chiudendo il gap di prestazioni da 8.2 a 1.4 BLEU, rispetto a una cascata molto forte che potrebbe utilizzare direttamente abbondanti dati ASR e MT. Lo stesso approccio end-to-end e la messa a punto di fine-tuning colmano il gap sul set di dati MuST-C inglese-rumeno da 6.7 a 3.7 BLEU. Oltre a questi risultati, presentiamo raccomandazioni pratiche per gli approcci di aumento e pre-formazione. Infine, riduciamo il gap di performance a 0,01 BLEU con un'architettura basata su Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>自動音声翻訳（ ＡＳＴ ）の場合、エンドツーエンドのアプローチは、自動音声認識（ ＡＳＲ ）で転写し、次に機械翻訳（ Ｍ Ｔ ）で遅れて転写するカスケードモデルによって凌駕される。 パフォーマンスギャップの主な原因は、既存のASTコーラが小さい一方で、ASRサブシステムとMTサブシステムの両方に大規模なデータセットが存在することです。 この研究では、同じデータセット上のすべてを比較することによって、ASTのいくつかのデータ拡張および事前トレーニングアプローチを評価します。 ASRトランスクリプトを翻訳することによる単純なデータ拡張は、英仏の拡張LibriSpeechデータセットで最も効果的であることが証明されており、膨大なASRおよびMTデータを直接利用できる非常に強力なカスケードと比較して、8.2から1.4 BLEUまでのパフォーマンスギャップを埋めます。 同じエンドツーエンドのアプローチと微調整は、英語-ルーマニア語のMuST - Cデータセットの6.7から3.7 BLEUのギャップを埋めます。 これらの結果に加えて、拡張および事前トレーニングアプローチのための実用的な推奨事項を提示します。 最後に、トランスフォーマーベースのアーキテクチャでは、パフォーマンスギャップを0.01 BLEUに減らします。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Wurungu perusahaan langgambar (AST), dadi kapan-kowe lan mbuh dumateng manut karo model kascade kang karo perusahaan karo perusahaan sesik (ASR), iso terusahaan karo terjamahan (MT). Mbak perusahaan langkung wigatahan kanggo ngerasai, terus akeh AST dumadhi kuwi mungkin, dadi akeh dumadhi kanggo sistem ASR karo MT Nyong-ngobro iki, awak dhéwé ngeremus akeh data nyang diuntingi podho karo AST ngono nggawe dataset sing berarti. Go Sampeyan nganggo cah-sampeyan nganggo cah-sampeyan ngupakan kelas telas nang ingkang-rumani MuRT-C dataset dadi 6.7 sampeyan 3.7 B Nambah gambarang iki, kita ngomong wektu nggawe rerakke praksi- ommendasi kanggo ngilangno karo hal-hal maneh. Lha wiwit, kita ngulinakake perusahaan kanggo 0.1</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ავტომატიკური სიტყვის განსაგულისხმებისთვის (AST) დასასრულისხმებისთვის დასასრულისხმებისთვის მოდელები, რომლებიც ავტომატიკური სიტყვის განსაგულისხმებით (ASR), შემდეგ მაქინის განსაგულისხმე მნიშვნელოვანი მიზეზი იყო, რომ არსებობს AST კოპორაა პატარა, მასტივი მონაცემები არსებობს ორივე ASR და MT სუფსისტემებისთვის. ამ სამუშაოში, რამდენიმე მონაცემების აგგენტაცია და AST-ის წინასწორება გავაკეთებთ, ყველაფერი იგივე მონაცემების შესაბამისად. მარტივი მონაცემების აზექტირება, რომელიც ASR ტრანსკრიპტის ტრანსკრიპტის გადატანა უფრო ეფექტიური ინგლისურ- ფრანგური აზექტირებული LibriSpeech მონაცემების შესახებ, რომელიც 8.2-დან 1.4 BLEU-დან გამოსახულებული გან იგივე დასრულებული დასრულებული დასრულებული დასრულებული დასრულება ინგლისური-პომინური მონაცემების მონაცემების დასრულება 6,7-3,7 BLEU-დან. ამ შედეგების დამატებით, ჩვენ გვეყვანეთ პრაქტიკური რეკომენდეციების შესახებ აზემონტიკაციის და წარმოდგენის შესახებ. საბოლოოდ, ჩვენ გავაკეთებთ სამუშაო განსხვავებას 0,01 BLEU-ში, რომელიც განსხვავებულია ტრანფორმეტრის მიერ აქტიქტურაცია.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Автоматты сөздерді аудару (AST) үшін аяқтау- аяқтау керектері автоматты сөздерді анықтау (ASR) мен аудару үлгілерімен аудару үлгілері (MT) жазылады. АҚШ корпорасы кішкентай болғанда, ASR және MT субжүйелер үшін үлкен деректер қорлары бар. Бұл жұмыс ішінде бірнеше деректер көптегендіруді және AST үшін келесі жағдайларды салыстырып, барлығын бір деректер жиындарына салыстырып бағалаймыз. ASR транскрипттерді аударып қарапайым деректерді көбейту үшін ағылшын- французша ағылшын- французша көбейтілген LibriSpeech деректер жиынында ең ең эффективні көрсетеді, 8. 2- 1. 4 BLEU- ден жұмыс аралығын жабу үшін, көп ASR мен MT дер Бірақ соңындағы жағдайды бірнеше баптау жағдайды ағылшын-руман МАСТ-С деректер жиынының 6,7-3,7 BLEU бойынша жабылады. Бұл нәтижелердің қосымша, көптегендіру және өзгерту арқылы практикалық қайта командаларды таңдаймыз. Соңғы сәтте, біз жылдамдығын 0,01 BLEU-ге қысқартамыз. Трансферлердің архитектурасы.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>자동음성번역(AST)의 경우 종단 연결 모델보다 종단 연결 방법이 우수하며, 종단 연결 모델은 자동음성인식(ASR)으로 전송한 뒤 기계번역(MT)으로 번역한다.성능 차이의 주요 원인은 기존의AST 어료 라이브러리는 매우 작지만 ASR과 MT 서브시스템에 대량의 데이터 집합이 존재하기 때문이다.이 작업에서 우리는 같은 데이터 집합을 비교하여AST의 몇 가지 데이터 확장과 예비 훈련 방법을 평가했다.ASR 전사본 번역을 통한 간단한 데이터 확충은 영어-프랑스어 증강형 Libri Speech 데이터 세트에서 가장 효과적이며, ASR과 MT 데이터의 막대한 종속 연결을 직접 활용하기보다는 8.2BLEU에서 1.4BLEU로 성능 격차를 좁히는 것으로 나타났다.같은 끝에서 끝까지의 방법에 미세한 조정을 더해 영국-루마니아 MuST-C 데이터 세트의 6.7 BLEU에서 3.7 BLEU까지의 격차를 좁혔다.이러한 결과 외에 우리는 증강과 예훈련 방법의 실용적인 건의도 제기했다.마지막으로 우리는 변압기 기반 아키텍처를 사용하여 성능 격차를 0.01 BLEUus로 줄였습니다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Automatiniam kalbos vertimui (AST) taikomi kaskadiniai modeliai, kurie transkribuojami automatiniu kalbos atpažinimu (ASR), o vėliau transkribuojami mašininiu vertimu (MT). Pagrindinė veikimo spragos priežastis yra ta, kad nors esami AST korporai yra maži, esami masiniai ASR ir MT posistemių duomenų rinkiniai. Šiame darbe vertiname keletą AST duomenų didinimo ir išankstinio mokymo metodų, palygindami visus tuos pačius duomenų rinkinius. Paprastas duomenų didinimas vertant ASR transkriptas įrodo, kad labiausiai veiksmingas anglų ir prancūzų tarpusavyje padidinto LibriSpeech duomenų rinkinio atžvilgiu, panaikinant veiklos spragą nuo 8,2 iki 1,4 BLEU, palyginti su labai stipria kaskada, kuri galėtų tiesiogiai panaudoti kopijuotus ASR ir MT duomenis. Taikant tą patį metodą nuo pabaigos prie pabaigos ir tiksliai koreguojant, anglų ir Rumunijos MUST-C duomenų rinkinio spraga užbaigiama nuo 6,7 iki 3,7 BLEU. Be šių rezultatų, pateikiame praktines rekomendacijas dėl didinimo ir išankstinio mokymo metodų. Finally, we decrease the performance gap to 0.01 BLEU us- ing a Transformer-based architecture.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>За автоматски превод на говор (AST), пристапите од крај до крај се надминуваат од каскадирани модели кои се препишуваат со автоматско препознавање на говорот (ASR), потоа транс- доцна со машински превод (MT). Големата причина за разликата во резултатите е дека, иако постојните АСТ корпора се мали, постојат масовни податоци за подсистемите АСР и МТ. Во оваа работа, проценуваме неколку податоци за зголемување и претренирање на пристапите за АСТ, споредувајќи ги сите на истите податоци. Simple data augmentation by translating ASR transcripts proves most effective on the English-French augmented LibriSpeech dataset, closing the performance gap from 8.2 to 1.4 BLEU, compared to a very strong cascade that could directly utilize copious ASR and MT data. Истиот пристап од крај до крај плус фино прилагодување ја затвора празнината на англиско-романското множество податоци МУСТ-Ц од 6,7 на 3,7 БЛЕУ. Покрај овие резултати, претставуваме практични препораки за зголемување и претренирање пристапи. Конечно, ја намалуваме празнината во резултатите на 0,01 БЛЕУ со трансформска архитектура.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>For automatic speech translation (AST), end-to-end approaches are outperformed by cascaded models that transcribe with automatic speech recognition (ASR), then trans- late with machine translation (MT). പ്രകടനത്തിന്റെ പ്രധാന കാരണം, നിലവിലുള്ള ആസ്റ്റ് കോര്‍പ്പോര കൊണ്ട് ചെറുതായിരിക്കുമ്പോള്‍, ആസാരിന്റെയും എംടി ഉപസിസ് ഈ പ്രവര്‍ത്തനത്തില്‍, നമ്മള്‍ പല ഡേറ്റാ കൂട്ടുന്നതിനെയും ആസ്റ്റിന്റെ അടുത്തുനിന്നും പ്രതീക്ഷിക്കുന്നതിനെയും പരിഗ ASR ട്രാന്‍സ്ക്രിപ്റ്റുകള്‍ പരിശോധിപ്പിക്കുന്നതിനാല്‍ എളുപ്പമുള്ള ഡേറ്റാ കൂട്ടിച്ചേര്‍ക്കുന്നതിനാല്‍ ഇംഗ്ലീഷ്- ഫ്രെഞ്ച് കൂട്ടിച്ചേര്‍ത്ത ലിബ്രിസ്പെച്ച് ഡാറ അതേ അവസാനത്തിന്റെ അടുത്തേക്കുള്ള വഴിക്കുറിച്ചും സുന്ദരിക്കുന്നതും ഇംഗ്ലീഷ്-റോമാനിയന്‍ മുസ്റ്റ്-സി ഡാറ്റാസറ്റെറ്റിന ഈ ഫലങ്ങളെക്കൂടാതെ, നമ്മള്‍ കൂടുതല്‍ പ്രാകൃതിക വീണ്ടും മാറ്റുന്നതിനും വേണ്ടിയാണ്. അവസാനം, നമ്മള്‍ പ്രകടന വ്യത്യാസം 0.01 ബില്യൂ വരെ കുറവ് വരുത്തുന്നു. ട്രാന്‍സ്ഫോര്‍മാര്‍ അടിസ്ഥാനമായ ഒരു ആര്‍ക്കിട്</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Автоматик ярианы хөрөнгө оруулалт (AST), төгсгөл-төгсгөл арга барилгууд автоматжуулан ярианы хүлээн зөвшөөрөх (ASR) загвараар автоматжуулан хэлэлцдэг загварууд, дараа нь машин хөрөнгө оруулалт ( АСТ корпора нь жижиг, АСР болон MT субсистем хоёулаа маш том өгөгдлийн сангууд байдаг. Энэ ажил дээр бид олон өгөгдлийн нэмэгдүүлэлт болон АСТ-ийн арга баримтуудыг ижил өгөгдлийн санд харьцуулахад үнэлдэг. ASR транскриптүүдийг орчуулахад энгийн өгөгдлийн нэмэгдүүлэлт нь Англи-Францын нэмэгдсэн LibriSpeech өгөгдлийн санд хамгийн үр дүнтэй харагдаж байна. 8.2-аас 1.4 BLEU-ээс үр дүнтэй ялгааг хадгалж байна. Яг ижил төгсгөл, төгсгөл ойлголт нэмэх нь сайхан зохицуулах нь Англи-Румын МАСТ-С өгөгдлийн сангийн ялгааг 6.7-ээс 3.7 БЛЮС руу холбоотой. Эдгээр үр дүнд нэмэхэд бид дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахин дахи Эцэст нь бид үйл ажиллагааны ялгааг 0.01 БЛУС-д багасгаж байна. Трансформатор суурилсан архитектур.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Untuk terjemahan ucapan automatik (AST), pendekatan akhir-akhir dilakukan oleh model kaskad yang ditranskrip dengan pengenalan ucapan automatik (ASR), kemudian ditranslasi dengan terjemahan mesin (MT). Sebab utama bagi ruang prestasi ialah, walaupun korpra AST yang wujud adalah kecil, set data besar wujud untuk kedua-dua subsistem ASR dan MT. Dalam kerja ini, kita menilai beberapa data meningkat dan pendekatan pretraining untuk AST, dengan membandingkan semua pada set data yang sama. Pembesaran data sederhana dengan menerjemahkan transkrip ASR membuktikan yang paling berkesan pada set data LibriSpeech bertambah bahasa Inggeris-Perancis, menutup ruang prestasi dari 8.2 hingga 1.4 BLEU, dibandingkan dengan kaskad yang sangat kuat yang boleh menggunakan data ASR dan MT yang berkumpul secara langsung. Pendekatan hujung-hujung yang sama ditambah penyesuaian menutup ruang pada set data MuST-C Inggeris-Romania dari 6.7 ke 3.7 BLEU. Selain daripada hasil ini, kami memperkenalkan rekomansi praktik untuk peningkatan dan pendekatan pretraining. Akhirnya, kita menurunkan jarak prestasi kepada 0.01 BLEU kita- menjadi arkitektur berasaskan Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Għal traduzzjoni awtomatika tad-diskors (AST), l-approċċi minn tarf sa tarf jitwettqu minn mudelli kaskati li jittraskrivu b’rikonoxximent awtomatiku tad-diskors (ASR), imbagħad jittraskrivu b’traduzzjoni bil-magna (MT). Kawża ewlenija tad-diskrepanza fil-prestazzjoni hija li, filwaqt li l-korpi AST eżistenti huma żgħar, jeżistu settijiet ta’ dejta massivi kemm għas-sottosistemi ASR kif ukoll MT. F’dan ix-xogħol, aħna jevalwaw diversi approċċi ta’ żieda fid-dejta u ta’ taħriġ minn qabel għall-AST, billi nqabblu kollha fuq l-istess settijiet ta’ dejta. Żieda sempliċi fid-dejta bit-traduzzjoni tat-traskrizzjonijiet ASR hija l-aktar effettiva fuq is-sett tad-dejta LibriSpeech miżjud bl-Ingliż-Franċiż, li jagħlaq id-distakk fil-prestazzjoni minn 8.2 għal 1.4 BLEU, meta mqabbel ma’ kaskata qawwija ħafna li tista’ tuża direttament dejta kopja ASR u MT. L-istess approċċ minn tarf għal tarf flimkien ma’ aġġustament fin jagħlaq id-distakk fis-sett tad-dejta MuST-C Ingliż-Rumen minn 6.7 sa 3.7 BLEU. Minbarra dawn ir-riżultati, qed nippreżentaw rakkomandazzjonijiet prattiċi għal approċċi ta’ żieda u taħriġ minn qabel. Fl-a ħħar nett, naqsu d-distakk fil-prestazzjoni għal 0.01 BLEU billi nibnu arkitettura bbażata fuq it-Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Voor automatische spraakvertaling (AST) worden end-to-end benaderingen overtroffen door cascademodellen die transcriberen met automatische spraakherkenning (ASR) en vervolgens translate met machine translation (MT). Een belangrijke oorzaak van de prestatiekloof is dat, hoewel bestaande AST-corpora's klein zijn, enorme datasets bestaan voor zowel het ASR- als MT-subsysteem. In dit werk evalueren we verschillende data augmentatie en pretraining benaderingen voor AST, door ze allemaal op dezelfde datasets te vergelijken. Eenvoudige gegevensvergroting door ASR-transcripten te vertalen blijkt het meest effectief op de Engels-Franse augmented LibriSpeech dataset, waardoor de prestatiekloof van 8.2 tot 1.4 BLEU wordt dichten, vergeleken met een zeer sterke cascade die direct gebruik kan maken van overvloedige ASR- en MT-gegevens. Dezelfde end-to-end aanpak plus fine-tuning sluit de kloof op de Engels-Roemeense MuST-C dataset van 6.7 tot 3.7 BLEU. Naast deze resultaten presenteren we praktische aanbevelingen voor augmentatie en pretraining benaderingen. Tot slot verkleinen we de prestatiekloof tot 0.01 BLEU met een Transformer-gebaseerde architectuur.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>For automatisk taleomsetjing (AST) blir tilnærmingar til slutten utført av kaskaderte modeller som transkriver med automatisk tale- gjenkjenning (ASR), og så trans late med maskinsomsetjing (MT). Eit viktig grunn av utgangspunktet er at, mens eksisterande AST-korpora er lite, finst massiv datasett for både ASR og MT-undersystema. I dette arbeidet evaluerer vi fleire data-augmentasjon og trekking av tilnærmingar for AST ved å sammenligne alle på samme datasett. Ein enkel data-økning ved å oversette ASR-transkript viser det mest effektivt på den anglesk-fransk augmenterte LibriSpeech-dataset, og lukkar utgangspunktet frå 8,2 til 1,4 BLEU, sammenlignet med ein veldig sterk kaskade som kunne direkte bruka kopøre ASR-og MT-data. Dette same ende-til-slutt tilnærming pluss fin-tuning lukkar mellomrommet på datasettet engelsk-rumensk MuST-C frå 6,7 til 3,7 BLEU. I tillegg til desse resultatene presenterer vi praktiske rekommendringar for augmentasjon og trekking av tilnærmingar. I slutten reduserer vi utgangspunktet til 0,01 BLEU som gjer ein transformeringsarkitektur.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>W przypadku automatycznego tłumaczenia mowy (AST) podejścia końcowe są przewyższane przez modele kaskadowe, które transkrybują z automatycznym rozpoznawaniem mowy (ASR), a następnie transkrybują z tłumaczeniem maszynowym (MT). Główną przyczyną luki w wydajności jest to, że podczas gdy istniejące korpusy AST są małe, masowe zbiory danych istnieją zarówno dla podsystemów ASR, jak i MT. W niniejszej pracy oceniamy kilka metod zwiększania i wstępnego treningu danych dla AST, porównując wszystkie na tych samych zbiorach danych. Proste powiększanie danych poprzez tłumaczenie transkrypcji ASR okazuje się najbardziej skuteczne na angielsko-francuskim rozszerzonym zbiorze danych LibriSpeech, zmniejszając lukę wydajności od 8.2 do 1.4 BLEU, w porównaniu z bardzo silną kaskadą, która może bezpośrednio wykorzystać obfite dane ASR i MT. To samo kompleksowe podejście oraz precyzyjne dostosowanie zamyka lukę w angielsko-rumuńskim zbiorze danych MuST-C od 6.7 do 3.7 BLEU. Oprócz tych wyników przedstawiamy praktyczne zalecenia dotyczące podejść do rozszerzenia i wstępnego treningu. Wreszcie zmniejszamy lukę wydajnościową do 0.01 BLEU z architekturą opartą na Transformerze.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Para tradução automática de fala (AST), as abordagens de ponta a ponta são superadas por modelos em cascata que transcrevem com reconhecimento automático de fala (ASR) e depois traduzem com tradução automática (MT). Uma das principais causas da lacuna de desempenho é que, embora os corpora AST existentes sejam pequenos, existem grandes conjuntos de dados para os subsistemas ASR e MT. Neste trabalho, avaliamos várias abordagens de aumento de dados e pré-treinamento para AST, comparando todas nos mesmos conjuntos de dados. O aumento simples de dados traduzindo transcrições de ASR se mostra mais eficaz no conjunto de dados LibriSpeech aumentado em inglês-francês, fechando a lacuna de desempenho de 8,2 para 1,4 BLEU, em comparação com uma cascata muito forte que poderia utilizar diretamente dados copiosos de ASR e MT. A mesma abordagem de ponta a ponta mais o ajuste fino fecha a lacuna no conjunto de dados MuST-C inglês-romeno de 6,7 para 3,7 BLEU. Além desses resultados, apresentamos recomendações práticas para abordagens de aumento e pré-treinamento. Finalmente, reduzimos a diferença de desempenho para 0,01 BLEU usando uma arquitetura baseada em Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Pentru traducerea automată a vorbirii (AST), abordările end-to-end sunt depășite de modele în cascadă care transcriu cu recunoașterea automată a vorbirii (ASR), apoi cu traducerea automată (MT). O cauză majoră a decalajului de performanță este că, în timp ce corpurile AST existente sunt mici, există seturi de date masive atât pentru subsistemele ASR, cât și MT. În această lucrare, evaluăm mai multe abordări de mărire a datelor și pre-formare pentru AST, prin compararea tuturor pe aceleași seturi de date. Amplificarea simplă a datelor prin traducerea transcrierilor ASR se dovedește cea mai eficientă pe setul de date LibriSpeech augmentat englez-francez, reducând decalajul de performanță de la 8.2 la 1.4 BLEU, comparativ cu o cascadă foarte puternică care ar putea utiliza direct numeroase date ASR și MT. Aceeași abordare end-to-end plus ajustarea fină elimină decalajul în setul de date MuST-C englez-român de la 6.7 la 3.7 BLEU. Pe lângă aceste rezultate, prezentăm recomandări practice pentru abordările de augmentare și pre-formare. În cele din urmă, reducem decalajul de performanță până la 0,01 BLEU pentru o arhitectură bazată pe Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Для автоматического перевода речи (AST) сквозные подходы превосходят каскадные модели, которые транскрибируют с автоматическим распознаванием речи (ASR), а затем транслируют с машинным переводом (MT). Основная причина разрыва в производительности заключается в том, что, хотя существующие корпуса AST являются небольшими, массивные наборы данных существуют как для подсистем ASR, так и для подсистем MT. В этой работе мы оцениваем несколько подходов к увеличению данных и предварительной подготовке для AST, сравнивая все на одних и тех же наборах данных. Простое увеличение данных путем перевода транскриптов ASR оказывается наиболее эффективным в наборе данных LibriSpeech с расширением на английском и французском языках, сокращая разрыв в производительности с 8,2 до 1,4 BLEU, по сравнению с очень сильным каскадом, который может непосредственно использовать обширные данные ASR и MT. Тот же сквозной подход плюс точная настройка сокращают разрыв на английском-румынском наборе данных MuST-C с 6,7 до 3,7 БЛЮ. В дополнение к этим результатам мы представляем практические рекомендации по подходам к увеличению и предварительной подготовке. Наконец, мы уменьшаем разрыв в производительности до 0,01 BLEU с помощью архитектуры на основе трансформатора.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ස්වයංක්‍රිය කතාවක් අවවාදය (AST) සඳහා, end-to-end අවවාදය නිසා ස්වයංක්‍රිය කතාවක් අවවාදය (ASR) සඳහා ස්වයංක්‍රිය කතාවක් අවවාදය (MT) ස ප්‍රශ්නයක් ප්‍රධානයක් තියෙන්නේ AST කොර්පෝරා පුංචි වෙලාවක්, ASR සහ MT සබස්සිස්ටම් දෙන්නම් ගොඩක් දත්ත සැට් මේ වැඩේ අපි දත්ත විශාලනය සහ AST වෙනුවෙන් ප්‍රතික්‍රීයාවක් විශාලනය කරනවා, එකම දත්ත සේට් වල හැම දේවල්ම සමානු Name එකම අවසානයෙන් අවසානයෙන් අවසානයෙන් හොඳ අවසානය වෙනුවෙන් ඉංග්‍රීසිය-රෝමානියාන් මුස්ට් සී දත්ත සැටුම 6.7 ඉඳල මේ ප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍ර අන්තිමේදි, අපි ප්‍රාර්ථනාවක් අවස්ථාවක් 0.01 බ්ලූස් වලට අඩු කරනවා. අපිට ප්‍රාර්ථනාවක් අධාරිත වින</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Pri avtomatskem govornem prevajanju (AST) se pristopi od konca do konca izvajajo s kaskadnimi modeli, ki prepišejo s samodejnim prepoznavanjem govora (ASR), nato pa s strojnim prevajanjem (MT). Glavni vzrok za vrzel v uspešnosti je, da so obstoječe korpuse AST majhne, vendar obstajajo ogromni podatkovni nizi za podsistema ASR in MT. V tem delu smo ocenili več pristopov povečanja in predtreninga podatkov za AST s primerjavo vseh na istih naborih podatkov. Enostavno povečanje podatkov s prevajanjem ASR transkripcij se izkaže za najučinkovitejše na angleško-francoskem naboru podatkov LibriSpeech, saj zmanjšuje vrzel v zmogljivosti od 8,2 do 1,4 BLEU v primerjavi z zelo močno kaskado, ki bi lahko neposredno uporabila obilne ASR in MT podatke. Isti pristop od konca do konca in natančno uravnavanje zapolnjuje vrzel v angleško-romunskem naboru podatkov MuST-C od 6,7 do 3,7 BLEU. Poleg teh rezultatov predstavljamo tudi praktične priporočila za pristope povečanja in predurjenja. Nazadnje pa zmanjšamo vrzel v zmogljivosti na 0,01 BLEU, kar pomeni arhitekturo, ki temelji na transformatorju.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tilmaamaha hadalka oo automatic ah (AST), waxaa lagu sameeyaa qaabab dhammaadka ugu dambaysta ah oo lagu qorayo qoraalka ku qoran aqoonsashada hadalka (ASR), dabadeedna trans-late with translation of machine (MT). Sababta ugu weyn ee burburka sameynta waa in marka shirkadda AST ay jiraan ay yaryihiin, waxaa jira sawirada macluumaadka badan ee ASR iyo MT hoosdhigyada. Markaas waxan, waxaynu qiimeynaynaa kordhiska macluumaadka iyo ka hor-soocidda AST, si aan u barbardhigno dhammaan sawirada isku mid ah. Soo saaridda macluumaadka fudud ee turjumidda qoraalka ASR waxay cadaynaysaa kuwa ugu shaqeeya ee ku saabsan macluumaadka afriiska-Faraansiinta oo afgeysay LibriSpeech, wuxuuna dabooli karaa gafafka performance ka baxay 8.2-1.4 BLEU, compared to a cascade aad u adag oo toos u isticmaali kara macluumaadka ASR iyo MT. Dhaqdooyinka ugu dambeeya isla dhamaadka iyo qurxinta qurxinta ayaa daboolaya burburka warqada ingiriisiga-Romanian MuST-C ee laga soo bilaabo 6.7-3.7 BLEU. Arrimahaan ka sokow, waxan soo bandhignaynaa dib-u-beddelasho ah oo la kordhiyo iyo soo-beddelasho. Ugu dambaysta, waxaynu hoos u dhignaa booska sameynta ilaa 0.01 BLEU - dhismaha baabuurta.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>For automatic speech translation (AST), end-to-end approaches are outperformed by cascaded models that transcribe with automatic speech recognition (ASR), then trans- late with machine translation (MT). Një shkak kryesor i daljes së performancës është se, ndërsa korprat ekzistuese AST janë të vogla, të dhënat masive ekzistojnë si për nënsistemet ASR ashtu edhe MT. Në këtë punë, ne vlerësojmë disa rritje të të dhënave dhe metoda përpara stërvitjes për AST, duke krahasuar të gjitha në të njëjtat grupe të të dhënave. Rritja e thjeshtë e të dhënave duke përkthyer transkriptet ASR tregohet më e efektshme në grupin e të dhënave LibriSpeech të rritur anglisht-francez, duke mbyllur dallimin e performancës nga 8.2 në 1.4 BLEU, krahasuar me një kaskade shumë të fortë që mund të përdorte drejtpërdrejt të dhënat kopjoze ASR dhe MT. E njëjta qasje nga fundi në fund plus rregullimi e hollësisë mbyll boshllëkun në grupin e të dhënave anglo-rumune MuST-C nga 6.7 në 3.7 BLEU. Përveç këtyre rezultateve, ne paraqesim rekomandime praktike për rritje dhe metoda paratrajnimi. Më në fund, ne e zvogëlojmë dallimin e performancës në 0.01 BLEU - duke bërë një arkitekturë me bazë në Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Za automatski prevod govora (AST), pristupi na kraj do kraja iznosi kaskadni modeli koji prepisuju automatskim priznanjem govora (ASR), a zatim prekasni sa prevodom mašine (MT). Veliki uzrok praznine izvedbe je da, iako postojeća AST korpora su mala, masivna podataka postoji za ASR i MT podsustava. U ovom poslu procjenjujemo povećanje podataka i pretvaranje pristupa AST-u, uspoređujući sve na istim podacima. Jednostavno povećanje podataka prevodeći transkript ASR pokazuje najefikasniji na kompetu podataka o povećanju biblioteke na engleskom francuskom i francuskom jeziku, zatvarajući prazninu učinkovitosti od 8,2 do 1,4 BLEU, u usporedbi sa veoma jakom kaskadom koja bi mogla izravno iskoristiti kopijske ASR i MT podatke. Isti pristup do kraja plus fino podešavanje zatvara prazninu na podacima engleskog-rumunskog MuST-C od 6,7 do 3,7 BLEU. Pored ovih rezultata, predstavljamo praktične rekompendacije za povećanje i pretvaranje pristupa. Konačno, smanjujemo prazninu učinkovitosti na 0,01 BLEU-u koja nas je osnovala na transformeri arhitektura.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>För automatisk talöversättning (AST) överträffas end-to-end-tillvägagångssätt av kaskadmodeller som transkriberar med automatisk taligenkänning (ASR) och sedan transkriberar med maskinöversättning (MT). En viktig orsak till prestandakravet är att även om befintliga AST-kroppar är små, finns det massiva datauppsättningar för både ASR- och MT-delsystemet. I detta arbete utvärderar vi flera dataförstärknings- och pretrainingmetoder för AST, genom att jämföra alla på samma datauppsättningar. Enkel dataökning genom att översätta ASR-transkript visar sig vara mest effektiv på den engelsk-franska förstärkta LibriSpeech-datauppsättningen, vilket minskar prestandakravet från 8,2 till 1,4 BLEU, jämfört med en mycket stark kaskad som direkt kunde utnyttja rikliga ASR- och MT-data. Samma heltäckande tillvägagångssätt plus finjustering minskar gapet i den engelsk-rumänska MuST-C-datauppsättningen från 6,7 till 3,7 BLEU. Utöver dessa resultat presenterar vi praktiska rekommendationer för förstärkning och pre-training metoder. Slutligen minskar vi prestandabalansen till 0,01 BLEU genom att använda en Transformer-baserad arkitektur.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kwa kutafsiri hotuba ya kujitegemea (AST), mbinu za mwisho za mwisho zinaendeshwa na miundo mbinu yenye mabadiliko yanayoandikwa kwa kutambua hotuba ya kujitegemea (ASR), kisha kwa muda mrefu kwa kutafsiri mashine (MT). Sababu kubwa ya mchanganyiko wa utendaji ni kwamba, wakati kampuni ya AST iko ndogo, kuna seti kubwa za data kwa ajili ya mifumo ya ASR na MT. Katika kazi hii, tunatathmini kuongeza takwimu kadhaa na kutengeneza matukio ya AST, kwa kulinganisha vyote katika seti hizo za data. Kuongezeka kwa takwimu rahisi kwa kutafsiri maandishi ya ASR yanaonyesha kuwa na ufanisi zaidi kwenye seti ya data za LibriSpeech zilizoongezewa kwa Kiingereza-Kifaransa, kufunga gaidi ya utendaji kutoka 8.2 hadi 1.4 BLEU, ukilinganisha na kaskadi yenye nguvu sana inayoweza kutumia takwimu za ASR na MT. Mtakatifu huo mwishoni wa mwisho pamoja na ujumbe mzuri unafungua gaidi kuhusu takwimu za Kiingereza-Romanian MuST-C kutoka 6.7 hadi 3.7 BLEU. Zaidi ya matokeo haya, tunatoa mabadiliko ya hali halisi kwa ajili ya kuongeza na kutengeneza mbinu za kutengeneza. Mwisho, tunapunguza kiwango cha utendaji cha BLEU hadi 0.01 BLEU – kutufanya ujenzi wa asili ya Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>@ info செயல்பாட்டு வேறுபாட்டின் மிகப்பெரிய காரணம் என்னவென்றால், இருக்கும் AST நிறுவனத்தில் இருக்கும் போது ASR மற்றும் MT உப அமைப்ப இந்த வேலையில், நாம் பல தரவு அதிகரிப்பு மற்றும் AST க்கான முன்னேற்றம் செய்ய வேண்டும் மற்றும் அதே தரவு அமைப்புகளை ஒப்பி ASR எழுத்துருக்களை மொழிமாற்றி சுலபமான தகவல் மேலும் ஆங்கிலம்- பிரெஞ்சு மேம்படுத்தப்பட்ட லிப்ரிஸ்பேச் தகவல் அமைப்பில் மிகவும் விளைவாக தெரியும், செயல்பாட்டு வெளியேற்றம் 8. அதே முடிவில் இருந்து முடிவு நெருக்கம் கூட்டல் நன்றாக மூடுகிறது ஆங்கிலத்தில் இருந்து ரோமானியன் முஸ்ட்- C தரவுத்தளத்தில் இருந இந்த முடிவுகளுக்கும் தவிர, நாம் மேம்படுத்தல் மற்றும் முன்னோக்கம் செய்ய முடிவுகளை கூட்டுதல் மற்றும் பெரும இறுதியில், நாம் செயல்பாட்டு இடைவெளியை 0.01 பிலியு எங்களுக்கு குறைக்கிறோம் - மாற்று அடிப்படையில் உள்ள ஒரு கட்டு</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Otomatik çykyş terjime üçin Görniş gapysynyň esasy sebäbi bolsa, bar AST korporasy kiçi bolsa hem ASR we MT subsystemleriň üçin gaty maglumat setirleri bar. Bu işde, biz birnäçe maglumat üýtgetmesini we AST üçin golaýlaryny deňlendirip, hemmesini birnäçe veri setlerde karşılaştyrarak deňlendirip duruyoruz. ASR terjime edip basit maglumatlar ýetişdirilýär, iňlisçe-fransuzça gelişmiş LibriSpeech veri setinde iň täsirli ýagdaýda, performansyň gapysyny 8.2 we 1.4 BLEU-dan ýapýarylýar, kopy ASR we MT maglumatyny ullanabilen örän güýçli bir kaskada we deňleýär. Şol ýagdaý soňunda ýakynlaşdyrmak üçin iňlisçe-rumynça MuST-C veri sahypalarynyň 6.7 we 3.7 BLEU-dan çykarýar. Bu sonuçlar da arttırmak ve önlenme metodları için pratik bir tekrarlama komutanları sunuyoruz. Sonunda, performans boşluklarını 0.01 BLEU'a düşürüp, Transformer tabanlı bir arhitektura çevirdik.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>اپنی بات کی ترجمہ (AST) کے لئے آخر-to-end approaches are performed by cascaded models that transcribe with automatic speech recognition (ASR) and then trans late with machine translation (MT). عملکرد فاصلہ کی ایک بڑی دلیل یہ ہے کہ، حالانکہ موجود AST کورپورا چھوٹے ہیں، ASR اور MT سوسٹیموں کے لئے بڑی ڈاٹ سٹ موجود ہیں. اس کام میں ہم نے بہت سی ڈیٹا اضافہ اور آسٹی کے لئے پرٹرینٹ کی طریقے کا ارزش کیا ہے، سب ایک ڈیٹ سٹ پر مقایسہ کرکے۔ ASR ٹرنسکرپٹوں کو ترجمہ کرنے کے ذریعہ ساده ڈاٹ اضافہ کرتا ہے انگلیسی-فرانسوی اضافہ کی لیبری اسپیچ ڈاٹ سٹ پر بہت اثر دیتا ہے، جو 8.2 سے 1.4 بلیوس سے کامپیوتر فاصلہ بند کرتا ہے، ایک بہت مضبوط کاسڈ کے مقابلے میں جو سیدھی آس آر اور ٹی ڈا اسی طرح انگلیسی-رومین ماسٹ-سی ڈاٹ سٹ کے اندر 6.7 سے 3.7 بلیوس کے لئے فاصلہ بند کرتا ہے۔ ان نتائج کے علاوہ، ہم اضافہ اور زیادتی کی طریقوں کے لئے قابل تدبیر کماندر پیش کرتے ہیں. آخر میں، ہم ایک تغییر پھیلانے والی معماری کو 0.01 BLEU تک کم کر رہے ہیں۔</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>@ info: whatsthis Va bajarish gapirishining asosiy sababi, mavjud ASAT kompaniya juda kichkina maʼlumot tizimi ASR va MT tizimlari uchun juda katta maʼlumot tizimi mavjud. Bu ishda biz bir necha maʼlumot qoʻshishni qiymatmiz va ASAT uchun yozish usullarini qiymatimiz, hamma bir necha maʼlumot sahifalarni bir necha ko'paytuvchimiz. Name Bu bir oxiriga qo'yish usuli va yaxshi suhbat usuli ingliz-Rumincha MuST-C maʼlumotlar tarkibini 6.7 dan 3.7 BLEU bilan o'zgartiradi. Bu natijalardan boshqa esa, biz tashkilotni oshirish va taqdim qilish usullarini bajaramiz. Endi biz tashkilotni 0.01 BLEU'ga kamaytamiz - Transformer asosiy arxituvchi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Đối với dịch ngôn ngữ tự động (AST), các phương pháp cuối-tới-cuối được thực hiện bởi các mô-đun ngẫu nhiên chuyển qua bằng nhận dạng ngôn ngữ tự động (ASR), sau đó chuyển mới bằng dịch cỗ máy (MTV). Một nguyên nhân quan trọng của việc đó là một trong số hệ thống ASR và MTV. Trong công việc này, chúng tôi đánh giá nhiều phương pháp gia tăng dữ liệu và nâng cấp cho AST bằng cách so sánh tất cả các bộ dữ liệu giống nhau. Đơn giản gia tăng dữ liệu bằng cách dịch chuyển các ghi chép ASR cho thấy hiệu quả nhất với hệ thống dữ liệu LyriSpeech cường Anh-Pháp, thu hồi khoảng cách hiệu suất từ 8.2 đến 1.4 bleU, so với một thác rất mạnh có thể trực tiếp sử dụng dữ liệu ASR và MTV. C ùng một phương pháp cuối cùng cộng với độ chỉnh sửa sửa sửa sửa sửa chữa lỗ hổng trong bộ nhớ dữ liệu giọng Tây Ban Nha MuST-C từ 6.7 tới 3.7 BleU. Ngoài những kết quả này, chúng tôi còn đưa ra các dự án thực tế cho việc tăng trưởng và nâng cấp phương pháp. Cuối cùng, chúng ta giảm khoảng trống hiệu suất đến 0.13 LEU- đang tạo ra một kiến trúc biến hình.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>其自语音译 (AST),端到端优于级联,用自语音 (ASR) 转录之,然后用机器翻译 (MT) 后期译。 性所以去者,虽见AST语料库小,而ASRMT子系统皆大集。 于此等事,比较同集数以增预训练方法,评AST数以增预训练方法。 译 ASR 转录本简数增于英语-法语增强型 LibriSpeech 数集上验为最效,与可径用多 ASR 与 MT 数之极强者比,将性相去自 8.2 BLEU缩小至 1.4%。 同端到端加微调英语 - 罗马尼亚MuST-C数集差从6.7缩小至3.7 BLEU。 自此之外,增预训练方法之实用建议。 最后,相去缩小0.01 BLEU基于Transformer架构。</span></div></div><dl><dt>Anthology ID:</dt><dd>2019.iwslt-1.18</dd><dt>Volume:</dt><dd><a href=/volumes/2019.iwslt-1/>Proceedings of the 16th International Conference on Spoken Language Translation</a></dd><dt>Month:</dt><dd>November 2-3</dd><dt>Year:</dt><dd>2019</dd><dt>Address:</dt><dd>Hong Kong</dd><dt>Venues:</dt><dd><a href=/venues/emnlp/>EMNLP</a>
| <a href=/venues/iwslt/>IWSLT</a></dd><dt>SIG:</dt><dd><a href=/sigs/sigslt/>SIGSLT</a></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd></dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2019.iwslt-1.18>https://aclanthology.org/2019.iwslt-1.18</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">pino-etal-2019-harnessing</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Juan Pino, Liezl Puzon, Jiatao Gu, Xutai Ma, Arya D. McCarthy, and Deepak Gopinath. 2019. <a href=https://aclanthology.org/2019.iwslt-1.18>Harnessing Indirect Training Data for End-to-End Automatic Speech Translation : Tricks of the Trade</a>. In <i>Proceedings of the 16th International Conference on Spoken Language Translation</i>, Hong Kong. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2019.iwslt-1.18>Harnessing Indirect Training Data for End-to-End Automatic Speech Translation : Tricks of the Trade</a> (Pino et al., IWSLT 2019)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2019.iwslt-1.18.pdf>https://aclanthology.org/2019.iwslt-1.18.pdf</a></dd><dt>Data</dt><dd><a href=https://paperswithcode.com/dataset/librispeech>LibriSpeech</a>,&nbsp;<a href=https://paperswithcode.com/dataset/must-c>MuST-C</a>,&nbsp;<a href=https://paperswithcode.com/dataset/wmt-2014>WMT 2014</a>,&nbsp;<a href=https://paperswithcode.com/dataset/wmt-2016>WMT 2016</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2019.iwslt-1.18.pdf title="Open PDF of 'Harnessing Indirect Training Data for End-to-End Automatic Speech Translation : Tricks of the Trade'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Harnessing+Indirect+Training+Data+for+End-to-End+Automatic+Speech+Translation+%3A+Tricks+of+the+Trade" title="Search for 'Harnessing Indirect Training Data for End-to-End Automatic Speech Translation : Tricks of the Trade' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'Harnessing Indirect Training Data for End-to-End Automatic Speech Translation : Tricks of the Trade'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[Harnessing Indirect Training Data for End-to-End Automatic Speech Translation : Tricks of the Trade](https://aclanthology.org/2019.iwslt-1.18) (Pino et al., IWSLT 2019)</p><ul class=mt-2><li><a href=https://aclanthology.org/2019.iwslt-1.18>Harnessing Indirect Training Data for End-to-End Automatic Speech Translation : Tricks of the Trade</a> (Pino et al., IWSLT 2019)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Juan Pino, Liezl Puzon, Jiatao Gu, Xutai Ma, Arya D. McCarthy, and Deepak Gopinath. 2019. <a href=https://aclanthology.org/2019.iwslt-1.18>Harnessing Indirect Training Data for End-to-End Automatic Speech Translation : Tricks of the Trade</a>. In <i>Proceedings of the 16th International Conference on Spoken Language Translation</i>, Hong Kong. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>