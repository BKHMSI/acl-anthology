<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Semantic Structural Decomposition for Neural Machine Translation - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="Semantic Structural Decomposition for Neural Machine Translation" name=citation_title><meta content="Elior Sulem" name=citation_author><meta content="Omri Abend" name=citation_author><meta content="Ari Rappoport" name=citation_author><meta content="Proceedings of the Ninth Joint Conference on Lexical and Computational Semantics" name=citation_conference_title><meta content="2020/12" name=citation_publication_date><meta content="https://aclanthology.org/2020.starsem-1.6.pdf" name=citation_pdf_url><meta content="50" name=citation_firstpage><meta content="57" name=citation_lastpage><meta property="og:title" content="Semantic Structural Decomposition for Neural Machine Translation"><meta property="og:image" content="https://aclanthology.org/thumb/2020.starsem-1.6.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2020.starsem-1.6"><meta property="og:description" content="Elior Sulem, Omri Abend, Ari Rappoport. Proceedings of the Ninth Joint Conference on Lexical and Computational Semantics. 2020."><link rel=canonical href=https://aclanthology.org/2020.starsem-1.6></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2020.starsem-1.6.pdf>Semantic Structural Decomposition for Neural Machine Translation</a>
<a id=af_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Name</a>
<a id=am_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>position for neural machine translation</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>التحلل الهيكلي الدلالي لترجمة الآلة العصبية</a>
<a id=az_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Nöral Makin Çeviri üçün Semantik Struktural Dekompozisyon</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Семантично структурно разлагане за неврален машинен превод</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>নিউরাল মেশিন অনুবাদের জন্য সেম্যান্টিক ক্ষেত্রের ডিমোম্পোস্ট</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>སྤྱིར་བཏང་བའི་དབྱིབས་རྩིས་གཞུང་གི་མཐའ་འཁོར་བརྗོད་ཀྱི་</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Semantička strukturna dekompozicija za neuronski prevod mašine</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Semantic Structural Decomposition for Neural Machine Translation</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Sémantická strukturní dekompozice pro neuronový strojový překlad</a>
<a id=da_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Semantisk strukturel nedbrydning til neural maskinoversættelse</a>
<a id=de_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Semantische strukturelle Dekomposition für neuronale maschinelle Übersetzung</a>
<a id=el_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Σημαντική δομική αποσύνθεση για τη νευρωνική μηχανική μετάφραση</a>
<a id=es_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Descomposición estructural semántica para la traducción automática neuronal</a>
<a id=et_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Semantiline struktuuriline lagunemine neuroaalse masintõlke jaoks</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>تعادل ساختار ساختاری سیماتیک برای ترجمه ماشین عصبی</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Semanttinen rakenteellinen hajoaminen hermojen konekääntämiseen</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Décomposition structurale sémantique pour la traduction automatique neuronale</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Dianscaoileadh Séimeantach Struchtúrtha le haghaidh Aistriúchán Meaisín Néarach</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>position for translation</a>
<a id=he_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>התפרצות מבנה סמנטית לתרגום מכונות נוירות</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>तंत्रिका मशीन अनुवाद के लिए शब्दार्थ संरचनात्मक अपघटन</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Semantička strukturna dekompozicija za neuronski prevod strojeva</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Szemantikus strukturális bontás a neurális gépi fordításhoz</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Semantic Structural Decomposition for Neural Machine Translation</a>
<a id=id_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Semantic Structural Decomposition for Neural Machine Translation</a>
<a id=is_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Decomposizione strutturale semantica per la traduzione automatica neurale</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>神経機械翻訳のための意味論的構造分解</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Ngucap Samantar</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Name</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Нейрондық машинаның аудармасының семантикалық структуралық декомпозициясы</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>신경 기계 번역 중의 의미 구조 분해</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Semantinis struktūrinis sklaidos sklaida, skirta neurologiniam mašinų vertimui</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Семантичка структурна декомпозиција за превод на неврални машини</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>നെയുറല്‍ മെഷീന്‍ പരിഭാഷക്കുള്ള സെമാന്റിക് സ്ട്രാക്ട്രോക്ടറില്‍ ഡെക്കോമ്പോസ്റ്റ്</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Цөмийн машины хөгжлийн Semantic Structureural Decomposition for Neural Machine Translation</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Semantic Structural Decomposition for Neural Machine Translation</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Dekompożizzjoni Strutturali Semantika għat-Traduzzjoni tal-Magna Newrali</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Semantische structurele decompositie voor neurale machinevertaling</a>
<a id=no_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Name</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Semantyczny rozkład strukturalny dla neuronowego tłumaczenia maszynowego</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Decomposição Estrutural Semântica para Tradução Automática Neural</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Decompoziție structurală semantică pentru traducerea automată neurală</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Семантическое структурное разложение для нейронного машинного перевода</a>
<a id=si_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>සෙමැන්ටික් සංවිධානය සංවිධානය නිර්මාණය සඳහා</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Semantna strukturna razgradnja za strojno prevajanje nevronov</a>
<a id=so_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Semantic structural Decomposition for Neural machine Translation</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Dekompozicioni strukturor Semantik për Translation Neural Machine</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Semantička strukturalna dekompozicija za neurološki prevod mašine</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Semantisk strukturell nedbrytning för neural maskinöversättning</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Udhibiti wa Miundombinu kwa Tafsiri ya Mashine ya Nguvu</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>புதிய இயந்திரம் மொழிபெயர்ப்புக்கான செமான்டிக் கட்டுப்பாட்டு குறைப்பு</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Neural Maşynyň terjimesine görkezilen çykyş</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>نیورال ماشین ترجمہ کے لئے سیمنٹی ساخترال ناکامپوسٹ</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Name</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>Phân chia thành phần mềm cho máy móc thần kinh</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2020.starsem-1.6.pdf>用于神经机器翻译者语义结构分解</a></h2><p class=lead><a href=/people/e/elior-sulem/>Elior Sulem</a>,
<a href=/people/o/omri-abend/>Omri Abend</a>,
<a href=/people/a/ari-rappoport/>Ari Rappoport</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Building on recent advances in <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a> and text simplification, we investigate the use of semantic splitting of the source sentence as preprocessing for <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. We experiment with a Transformer model and evaluate using large-scale crowd-sourcing experiments. Results show a significant increase in <a href=https://en.wikipedia.org/wiki/Fluency>fluency</a> on long sentences on an English-to- French setting with a training corpus of 5 M sentence pairs, while retaining comparable <a href=https://en.wikipedia.org/wiki/Adequality>adequacy</a>. We also perform a manual analysis which explores the tradeoff between adequacy and <a href=https://en.wikipedia.org/wiki/Fluency>fluency</a> in the case where all sentence lengths are considered.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>By gebou van onlangse vorderings in semantiese verwerking en teks vereenvoudiging, ondersoek ons die gebruik van semantiese verdeeling van die bron seting as voorafverwerking vir masjien vertaling. Ons eksperimenteer met 'n Transformer model en evalueer met groot-skaal skaal-sourcing eksperimente. Resultate wys 'n betekende versterking in fluiditeit op lange setnings op 'n Engels- na- Frans instelling met 'n oefening korpus van 5M setnings paar, terwyl die vergelykbare adekuasie hou. Ons doen ook 'n handaandeling wat die verkrywing tussen adekuasie en fluiditeit ondersoek in die geval waar al die setlengte beskou word.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Building on recent advances in semantic parsing and text simplification, we investigate the use of semantic splitting of the source sentence as preprocessing for machine translation. በተመሳሳይ የብዙው የድምፅ ጉዳይ ፈተና እናረጋግጣለን፡፡ ፍጥረቶቹ በይንግልዝኛ-ወደ ፈረንሳይኛ የ5M ፍርድ ክፍል የረጅም ፈቃድ ውርደት ያሳያል፡፡ የሥርዓት ዕድሜ በሚቆጠሩበት ወቅት መካከል የሚያስፈልገውን ግጭት እናሳውቃለን፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>بناءً على التطورات الحديثة في التحليل الدلالي وتبسيط النص ، فإننا نتحرى عن استخدام التقسيم الدلالي للجملة المصدر كتجهيز مسبق للترجمة الآلية. نقوم بتجربة نموذج Transformer وتقييمه باستخدام تجارب التعهيد الجماعي واسعة النطاق. تظهر النتائج زيادة ملحوظة في الطلاقة في الجمل الطويلة في بيئة من الإنجليزية إلى الفرنسية مع مجموعة تدريب مكونة من 5 ملايين أزواج من الجمل ، مع الحفاظ على كفاية مماثلة. نقوم أيضًا بإجراء تحليل يدوي يستكشف المفاضلة بين الكفاية والطلاقة في الحالة التي يتم فيها أخذ جميع أطوال الجملة في الاعتبار.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Semantik ayırma və metin basitləşdirməsi üçün yeni ilerləşmələri in şa etdik, maşın tercüməsi üçün ilk işləmə üçün mənbə cümləsinin semantik ayırmasını araşdırırıq. Biz bir Transformer modeli ilə təcrübə edirik və böyük ölçüdə qüvvətli təcrübələr vasitəsilə təcrübə edirik. Sonuçlar 5 M cümləlik çiftlərinin təhsil korpusu ilə İngilizə-Fransızca təhsil edilməsi üçün uzun cümlələr üzərində böyüklük artırmağı göstərər, müqayisədə uyğunluğu saxlayaraq. Biz həmçin in bütün cümlələrin uzunluğunu düşündüyü təqdirdə adeqliyyat və fərqliyyat arasındakı ticarəti keşfetən əlavə analizi çəkirik.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Въз основа на скорошните постижения в семантичното анализиране и опростяването на текста, изследваме използването на семантично разделяне на изходното изречение като предварителна обработка за машинен превод. Експериментираме с модел на трансформатор и оценяваме с помощта на мащабни експерименти за групово снабдяване. Резултатите показват значително увеличение на владеенето на дълги изречения в английско-френска обстановка с тренировъчен корпус от 5 милиона двойки изречения, като същевременно се запазва сравнима адекватност. Извършваме и ръчен анализ, който изследва компромиса между адекватност и плавност в случая, когато се вземат предвид всички дължини на изреченията.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Building on recent advances in semantic parsing and text simplification, we investigate the use of semantic splitting of the source sentence as preprocessing for machine translation. আমরা একটি ট্রান্সফ্রান্সফার মডেল দিয়ে পরীক্ষা করি এবং বিশাল মানুষ-সোর্সিং পরীক্ষা ব্যবহার করে মূল্যায়ন করি। ফলাফল দেখা যাচ্ছে একটি ইংরেজি থেকে ফ্রেঞ্চ ব্যবহারের উপর দীর্ঘ শাস্তিতে প্রভাব বৃদ্ধি প্রদর্শন করা হয়েছে, যার প্রশিক্ষণ ৫ এম কারাদণ্ডের জোড় আমরা একই সাথে একটি হাতিয়াল বিশ্লেষণ করি যা যথাযথ এবং প্রভাবের মধ্যে ব্যাপারটি বিশ্লেষণ করে যেখানে সকল বাক্যের দীর্ঘ সময় বিবেচন</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Building on recent advances in semantic parsing and text simplification, we investigate the use of semantic splitting of the source sentence as preprocessing for machine translation. ང་ཚོས་གཞུང་བཟོ་བྱེད་པའི་མ་དབུགས་ཞིག་གིས་བརྟག་དཔྱད་བྱེད་ཀྱི་ཡོད་ཚད་ཆེན་པོ་ཞིག་གིས་ གྲུབ་འབྲས་གཞི་ལྟ་བུའི་ཚིག་རྐང་ཐག་གཅིག་ལས་དབྱིན་ཡིག་གཟུགས་འགྱུར་བ་སྐྱེལ་ཅན་ཏུ་མངོན་གསལ་གཏོང་། ང་ཚོས་དུས་མཐུན་དང་དཔྱད་དབར་གྱི་བཟོ་བཅོས་ལ་ལག་བཟོས་དཔྱད་ཞིག་བྱེད་ཀྱི་ཡོད་པ་ཞིག་གནང་བ་རེད།</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Na osnovu nedavnog napreda u semantičkom analizu i pojednostavljanju teksta istražujemo korištenje semantičkog dijeljenja izvorne rečenice kao predobrazovanje za prevod mašine. Eksperimentiramo sa modelom Transformer a i procjenjujemo koristeći velike gomilu-izvorenje eksperimenata. Rezultati pokazuju značajno povećanje tečnosti na dugim rečenicama na engleskom i francuskom postavljanju sa obučnim korpusom od pare kazne 5M, dok zadržavaju usporedbenu adekvatnost. Također provodimo ručnu analizu koja istražuje trgovinu između adekvatnosti i tekućine u slučaju u kojem se smatra dužin a rečenica.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Construïnt-nos en avanços recents en l'analització semàntica i la simplificació del text, investigam l'ús de la divisió semàntica de la frase fontcom a preparació per a la traducció automàtica. Experimentem amb un model Transformer i evaluem fent servir experiments de crowd sourcing a gran escala. Els resultats mostren un augment significatiu de fluència en frases llargues en un entorn anglès-francès amb un cos d'entrenament de parells de frases de 5M, mantenint la adequació comparable. També fem una anàlisi manual que explora el compromís entre adequació i fluïtat en el cas en què es consideren totes les llargues de frases.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Na základě nedávných pokroků v oblasti sémantického parsování a zjednodušení textu zkoumáme využití sémantického rozdělení zdrojové věty jako předzpracování pro strojový překlad. Experimentujeme s transformátorovým modelem a hodnotíme pomocí rozsáhlých crowdsourcingových experimentů. Výsledky ukazují výrazný nárůst plynulosti dlouhých vět v anglicko-francouzském prostředí s výcvikovým korpusem 5M větových párů při zachování srovnatelné adekvátnosti. Dále provádíme manuální analýzu, která zkoumá kompromis mezi adekvátností a plynulostí v případě, kdy jsou zohledněny všechny délky věty.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Med udgangspunkt i de seneste fremskridt inden for semantisk parsing og tekstforenkling undersøger vi brugen af semantisk opdeling af kildesætningen som forbehandling til maskinoversættelse. Vi eksperimenterer med en Transformer model og evaluerer ved hjælp af store crowd-sourcing eksperimenter. Resultaterne viser en betydelig stigning i flydenhed på lange sætninger på en engelsk-fransk indstilling med et træningskorpus på 5M sætningspar, samtidig med at de bevarer tilsvarende tilstrækkelighed. Vi udfører også en manuel analyse, der undersøger afvigelsen mellem tilstrækkelighed og flydende i tilfælde, hvor alle sætningslængder tages i betragtning.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Aufbauend auf den jüngsten Fortschritten in der semantischen Parsing und Textvereinfachung untersuchen wir die Verwendung der semantischen Aufteilung des Ausgangssatzes als Vorverarbeitung für maschinelle Übersetzung. Wir experimentieren mit einem Transformer-Modell und evaluieren diese mithilfe von groß angelegten Crowdsourcing-Experimenten. Die Ergebnisse zeigen einen signifikanten Anstieg der Fließfähigkeit von langen Sätzen in einem Englisch-Französisch Setting mit einem Trainingskorpus aus 5M Satzpaaren bei gleichbleibender Angemessenheit. Wir führen auch eine manuelle Analyse durch, die den Kompromiss zwischen Angemessenheit und Fluency untersucht, wenn alle Satzlängen berücksichtigt werden.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Με βάση τις πρόσφατες εξελίξεις στη σημασιολογική ανάλυση και την απλοποίηση κειμένου, ερευνούμε τη χρήση της σημασιολογικής διάσπασης της πρότασης προέλευσης ως προεπεξεργασία για τη μηχανική μετάφραση. Πειραματιζόμαστε με ένα μοντέλο μετασχηματιστή και αξιολογούμε χρησιμοποιώντας πειράματα μεγάλης κλίμακας. Τα αποτελέσματα δείχνουν σημαντική αύξηση της ευκρίνειας σε μεγάλες προτάσεις σε ένα περιβάλλον αγγλικά-γαλλικού με εκπαιδευτικό σώμα από ζεύγη προτάσεων 5Μ, διατηρώντας παράλληλα συγκρίσιμη επάρκεια. Επίσης, διεξάγουμε μια χειρωνακτική ανάλυση που διερευνά το συμβιβασμό μεταξύ επάρκειας και ευκρίνειας στην περίπτωση που λαμβάνονται υπόψη όλα τα μήκη των προτάσεων.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Sobre la base de los avances recientes en el análisis semántico y la simplificación del texto, investigamos el uso de la división semántica de la oración fuente como preprocesamiento para la traducción automática. Experimentamos con un modelo Transformer y evaluamos mediante experimentos de crowdsourcing a gran escala. Los resultados muestran un aumento significativo de la fluidez en frases largas en un entorno de inglés a francés con un corpus de entrenamiento de 5 millones de pares de oraciones, manteniendo una adecuación comparable. También realizamos un análisis manual que explora el equilibrio entre la adecuación y la fluidez en el caso de que se tengan en cuenta todas las longitudes de oración.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tuginedes hiljutistele edusammudele semantilises parsimises ja teksti lihtsustamises, uurime lähtelause semantilise jagamise kasutamist masintõlke eeltöötlusena. Me eksperimenteerime Transformeri mudeliga ja hindame suuremahuliste ühishankimise katsete abil. Tulemused näitavad, et pikkade lausete sujuva oskuse märkimisväärne suurenemine inglise-prantsuse keeles, kus koolituskorpus koosneb 5 miljonist lausepaarist, säilitades samas võrreldava piisavuse. Samuti teostame käsitsi analüüsi, mis uurib kompromisse piisavuse ja sujuvuse vahel juhul, kui arvestatakse kõiki lausepikkusi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>بر اساس پیشرفت های اخیر در تجزیه‌سازی و ساده‌سازی متن، ما استفاده از تقسیم‌سازی از جمله منبع به عنوان پیش‌پردازی برای ترجمه‌سازی ماشین تحقیق می‌کنیم. ما با یک مدل تغییر دهنده آزمایش می کنیم و با استفاده از آزمایش‌های سرمایه‌گذاری جمعیت بزرگ ارزیابی می‌کنیم. نتیجه‌ها اضافه‌ای بزرگی بر جمله‌های طولانی در یک تنظیم انگلیسی به فرانسوی با یک جفت آموزشی از جفت‌های جمله 5M نشان می‌دهند، در حالی که قابلیت قابل مقایسه نگه می‌دارند. ما همچنین یک تحلیل دستی انجام می دهیم که تجارت بین عدالت و مایع در مورد هر طول جمله به نظر می رسد، تحقیق می کند.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Seminttisen jäsentämisen ja tekstin yksinkertaistamisen viimeaikaisen kehityksen pohjalta tutkimme lähdelauseen semanttisen jakamisen käyttöä konekäännöksen esikäsittelyssä. Kokeilemme Transformer-mallia ja arvioimme sen laajamittaisilla joukkohankintakokeiluilla. Tulokset osoittavat, että pitkien lauseiden sujuvuus lisääntyi merkittävästi englanti-ranska-ympäristössä, kun koulutuskorpus oli 5 miljoonaa lauseparia. Teemme myös manuaalisen analyysin, jossa selvitetään riittävyyden ja sujuvuuden välistä kompromissia siinä tapauksessa, että kaikki lauseen pituudet otetaan huomioon.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>En nous appuyant sur les récents progrès en matière d'analyse sémantique et de simplification de texte, nous étudions l'utilisation de la division sémantique de la phrase source comme prétraitement pour la traduction automatique. Nous expérimentons un modèle Transformer et l'évaluons à l'aide d'expériences de crowdsourcing à grande échelle. Les résultats montrent une augmentation significative de la fluidité des phrases longues dans un contexte anglo-français avec un corpus d'entraînement de 5 millions de paires de phrases, tout en conservant une adéquation comparable. Nous effectuons également une analyse manuelle qui explore le compromis entre adéquation et fluidité dans le cas où toutes les longueurs de phrase sont prises en compte.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ag tógáil ar an dul chun cinn a rinneadh le déanaí i bparsáil shéimeantach agus i simpliú téacs, déanaimid imscrúdú ar úsáid scoilteadh shéimeantach na habairte foinse mar réamhphróiseáil d’aistriúchán meaisín. Déanaimid turgnamh le samhail Trasfhoirmeoir agus déanaimid meastóireacht ag baint úsáide as turgnaimh slua-fhoinsithe ar scála mór. Léiríonn torthaí méadú suntasach ar líofacht ar abairtí fada ar shuíomh Béarla-go-Fraincis le corpas oiliúna de phéirí abairtí 5M, agus leordhóthanacht inchomparáide á choinneáil ag an am céanna. Déanaimid anailís láimhe freisin a dhéanann iniúchadh ar an gcomhbhabhtáil idir leordhóthanacht agus líofacht sa chás go ndéantar gach abairt a mheas.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tsarin da aka samu masu ƙara cikin parse na semantic da mai sauƙin matsayi, za'a yi ƙidãya wa amfani da cutarwa na semantic ko pre-zartar da fassarar maɓalli. Za jarraba da wani misali mai Transformer kuma tuna hakar jarrabo masu girma ga mutane-sourcen. Mataimakin na nuna significant ƙari ga furuci a kan sauran da aka daidaita na Ingiriya-zuwa-French mai daidaita da wani shirin cire-nau'in 5 M, kuma yana retain daidai. Tuna sami wani anayyar da hannun aiki wanda ke jarraba fatauci tsakanin da kuma ma'ishi idan an yi bincike da duk cire.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>בניין על התקדמות האחרונות באבחן סמנטי ופשטות טקסט, אנו חוקרים את השימוש בהחלקה סמנטית של המשפט המקורי כהתהליך לתרגום מכונות. אנו מנסים עם מודל טרנספורר ומעריכים בשימוש ניסויים במקורי קהל גדולים. התוצאות מראות עלייה משמעותית במשפטים ארוכים במצב אנגלי-צרפתי עם גוף אימון של זוגות משפטים של 5 מיליון, בזמן שמירה מתאימה שווה. אנו גם מבצעים ניתוח ידני שמחקר את ההחלטה בין התאימות לבין השקטות במקרה שבו כל אורך המשפט נחשב.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>शब्दार्थ पार्सिंग और पाठ सरलीकरण में हाल की प्रगति पर निर्माण, हम मशीन अनुवाद के लिए preprocessing के रूप में स्रोत वाक्य के शब्दार्थ विभाजन के उपयोग की जांच करते हैं। हम एक ट्रांसफॉर्मर मॉडल के साथ प्रयोग करते हैं और बड़े पैमाने पर भीड़-सोर्सिंग प्रयोगों का उपयोग करके मूल्यांकन करते हैं। परिणाम 5M वाक्य जोड़े के प्रशिक्षण कॉर्पस के साथ एक अंग्रेजी-से-फ्रांसीसी सेटिंग पर लंबे वाक्यों पर प्रवाह में महत्वपूर्ण वृद्धि दिखाते हैं, जबकि तुलनीय पर्याप्तता को बनाए रखते हैं। हम एक मैनुअल विश्लेषण भी करते हैं जो उस मामले में पर्याप्तता और प्रवाह के बीच ट्रेडऑफ की पड़ताल करता है जहां सभी वाक्य लंबाई पर विचार किया जाता है।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Na temelju nedavnog napreda u semantičkom analizu i pojednostavljanju teksta istražujemo upotrebu semantičkog dijeljenja izvorne rečenice kao predobrazovanje za prevod strojeva. Eksperimentiramo s modelom Transformer a i procjenjujemo koristeći velike prometne eksperimente. Rezultati pokazuju značajno povećanje tečnosti dugih rečenica na engleskom i francuskom postavljanju s obučnim korpusom od pare kazne 5M, dok zadržavaju usporedbenu adekvatnost. Također provodimo ručnu analizu koja istražuje trgovinu između adekvatnosti i tekućine u slučaju u kojem se razmatra dužin a kazne.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A szemantikai elemzés és a szövegegyszerűsítés legutóbbi előrehaladásaira építve vizsgáljuk a forráskód szemantikai felosztásának használatát a gépi fordítás előfeldolgozásaként. Kísérletezünk egy Transformer modellel, és nagyszabású közösségi források kísérletekkel értékeljük. Az eredmények azt mutatják, hogy a hosszú mondatok folyékonyságának jelentős növekedése angol-francia nyelvű környezetben 5 millió mondatpárból álló képzéssel, miközben hasonló megfelelőséget biztosítanak. Kézi elemzést is végezünk, amely feltárja a megfelelőség és a folyékonyság közötti megkülönböztetést abban az esetben, amikor az összes mondathosszt figyelembe vesszük.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Հիմնվելով սեմանտիկ վերլուծության և տեքստի պարզեցման վերջին առաջընթացների վրա, մենք ուսումնասիրում ենք, թե ինչպես է օգտագործվում աղբյուր նախադասության սեմանտիկ բաժանելը որպես մեքենայի թարգմանման նախամշակում: Մենք փորձում ենք տրանֆորմային մոդելի միջոցով և գնահատում ենք, օգտագործելով մեծ մասշտաբով ժողովրդավար փորձեր: Արդյունքները ցույց են տալիս, որ երկար նախադասությունների ճկունության մեծ աճ է անգլերեն-ֆրանսիացի միջավայրում 5M նախադասությունների զույգերի ուսումնասիրության կորպոսի հետ, մինչդեռ համեմատությունը պահպանվում է: We also perform a manual analysis which explores the tradeoff between adequacy and fluency in the case where all sentence lengths are considered.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Berdasarkan kemajuan baru-baru ini dalam penghuraian semantis dan penyimplifikasi teks, kami menyelidiki penggunaan pemisahan semantis dari kalimat sumber sebagai persiapan untuk terjemahan mesin. Kami eksperimen dengan model Transformer dan mengevaluasi menggunakan eksperimen crowd-sourcing skala besar. Results show a significant increase in fluency on long sentences on an English-to- French setting with a training corpus of 5M sentence pairs, while retaining comparable adequacy. Kami juga melakukan analisis manual yang mengeksplorasi perdagangan antara keperluan dan keterlaluan dalam kasus di mana semua panjang kalimat dianggap.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Basandoci sui recenti progressi nell'analisi semantica e nella semplificazione del testo, esaminiamo l'uso della divisione semantica della frase sorgente come preprocessing per la traduzione automatica. Sperimentiamo un modello Transformer e valutiamo utilizzando esperimenti di crowd-sourcing su larga scala. I risultati mostrano un significativo aumento della fluidità sulle frasi lunghe in un ambiente inglese-francese con un corpus di formazione di 5M coppie di frasi, pur mantenendo un'adeguatezza comparabile. Eseguiamo anche un'analisi manuale che esplora il compromesso tra adeguatezza e fluidità nel caso in cui tutte le lunghezze delle frasi siano considerate.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>セマンティック構文解析とテキスト簡略化の最近の進歩に基づいて、機械翻訳の前処理としてのソース文のセマンティック分割の使用を調査します。トランスフォーマーモデルを実験し、大規模なクラウドソーシング実験を使用して評価します。結果は、同等の妥当性を維持しながら、5 Mの文章ペアのトレーニングコーパスを持つ英語からフランス語の設定で、長文の流暢性が大幅に向上したことを示しています。また、すべての文の長さを考慮した場合の妥当性と流暢性のトレードオフを探る手動分析も行います。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Daerah ono nggawe advances in semanti karo semanti karo perusahaan teks semanti, kita yatênggunaé perusahaan semanti nggawe aturan kelompok nggawe barang kelompok nggawe sistem tarjamahan. Awak dhéwé éntuk karo model Transformer kuwi nggawe nyimpen banter-kalaha ujaran. Pamita puteh ngomong kedhanan langkung dolanan kapan-dolanan nganggo dolanan ingkang karo- Perancis Awak dhéwé éntuk manut karo hal-manut sing bisa mlebu nggawe gerakan gambar deweke karo kapan kanggo ngilanggar kuwi kesempatan kanggo nggawe barang langgar kuwi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>სემონტიკური პარასტის და ტექსტის განსხვავებაზე, ჩვენ განსხვავებთ სემონტიკური პარასტის გამოყენების გამოყენების გამოყენება, როგორც მაქსინის განსხვავლებისთვის პრეპროცესი. ჩვენ რენსპერიმენტებერის მოდელზე ექსპერიმენტებით გავაკეთებთ და გამოყენებთ დიდი მანძილური crowd-sourcing ექსპერიმენტებით. შედეგი გამოჩვენება მარტივი ფრანგულისთვის განმავლობაში სიგრძნობის გაზრძელება, რომელიც მარტივი მარტივის 5M კოსტატის კოსტატის კოსტატის განმავლობაში, როცა მარტი ჩვენ ასევე ვაკეთებთ ხელსახური ანალიზაცია, რომელიც განსხვავებს შესაძლებლობა და ფუნქციის განმავლობაში, რომელიც ყველა სიტყვების განმავლობა იყოს.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Семантикалық талдау және мәтін қарапайымдастыру үшін жаңа жағдайларды қолдану үшін біз көзінің семантикалық бөлігін машина аудару үшін алдын- ала түзету үшін зерттеуді зерттеуді. Біз түрлендіру үлгісімен тәжірибе және үлкен көпшілік көпшілік көпшілікті тәжірибелерді қолдануға болады. Нәтижелер 5M мәтінінің жұмыс корпус арқылы ағылшын және французша сөздерінің ұзындық сөздерінің көбіректігін көрсетеді, салыстыруға мүмкін. Біз сондай-ақ қолмен анализ істейміз. Бүкіл сөйлеменің ұзындығын қарастыру үшін адекциялық мен жылдамдықтық арасындағы тәртіпсіздігін зерттеді.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>의미 분석과 텍스트 간소화의 최신 진전을 바탕으로 우리는 원어구의 의미 분해를 기계 번역의 예처리로 연구했다.우리는 변압기 모형을 사용하여 실험을 하고 대규모의 패키지 실험을 사용하여 평가를 한다.그 결과 영어-프랑스어 환경에서 500만 개의 문장이 맞는 훈련 어료 라이브러리를 사용하면 긴 문장의 유창도가 현저히 높아지고 상당한 충분성을 유지한 것으로 나타났다.우리는 모든 문장의 길이를 고려할 때 적절성과 유창성 간의 균형을 수동적으로 분석했다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Remdamiesi neseniai padaryta pažanga semantinio analizavimo ir teksto supaprastinimo srityje, mes tiriame semantinio pradinio sakinio padalijimo naudojimą kaip parengiamąjį procesą mašininiam vertimui. Eksperimentuojame su Transformer modeliu ir vertiname naudojant didelio masto visuomenės išteklių eksperimentus. Results show a significant increase in fluency on long sentences on an English-to- French setting with a training corpus of 5M sentence pairs, while retaining comparable adequacy. We also perform a manual analysis which explores the tradeoff between adequacy and fluency in the case where all sentence lengths are considered.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Користејќи се на неодамнешните напредоци во семантичното анализирање и поедноставувањето на текстот, ние ја истражуваме употребата на семантичното поделба на изворната реченица како преработка за машински превод. Експериментираме со трансформен модел и проценуваме користејќи големи експерименти за публички извори. Резултатите покажуваат значителен зголемување на течноста на долгите реченици на англиско-француско место со обука на парови од 5 милиони реченици, при што се задржува споредлива адекватност. Исто така, спроведуваме рачна анализа која ја истражува разликата помеѓу соодветноста и течноста во случајот кога се разгледуваат сите должини на речениците.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>സെമാന്റിക് പാര്‍സിങ്ങിലും ടെക്സ്റ്റ് എളുപ്പമാക്കുന്നതിലും അടുത്തുള്ള മുന്‍ഗണങ്ങള്‍ നിര്‍മ്മിക്കുന്നു, മെഷിന്‍ പരിഭാഷയ്ക്കു നമ്മള്‍ ഒരു ട്രാന്‍സ്ഫോര്‍മാറ്റര്‍ മോഡല്‍ കൊണ്ട് പരീക്ഷിക്കുകയും, വലിയ പ്രാപ്റ്റ് സോര്‍സിങ് പരീക്ഷണങ്ങള്‍ ഉപ അന്ത്യഫലങ്ങള്‍ ഒരു ഇംഗ്ലീഷില്‍ നിന്നും ഫ്രെഞ്ചില്‍ നീണ്ട വാക്കുകളില്‍ നീണ്ട വാക്കുകളില്‍ ഫ്രെഞ്ചില്‍ നീണ്ട വാക്കുകള്‍ കൂടുതല്‍ വലുതാ എല്ലാ വാക്കുകളുടെയും നീളം വിചാരിക്കുന്ന കാര്യത്തില്‍ നമ്മള്‍ ഒരു കൈകാര്യ അന്യായം പ്രവര്‍ത്തിപ്പിക്കുന്നു.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Сүүлийн үеийн шинжлэх ухаан болон текст хялбарчлалын тулд бид эх үүсвэрийн өгүүлбэрийг машин орчуулахын тулд анхны үйлдвэрлэхийг судалж байна. Бид Трансформерийн загвартай туршилт хийж, олон нийтийн эх үүсвэрийн туршилтыг ашиглан үнэлэх болно. Үүний үр дүнд англи болон французтай холбоотой урт өгүүлбэрүүдийн тухай 5M өгүүлбэрийн холбоотой сургалтын корпус дээр ихэвчлэн ихэвчлэн байна. Мөн бид бүх өгүүлбэрийн урт нь тодорхойлогдож байгаа тохиолдлыг судлах гарын шинжилгээ хийдэг.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Membangun pada kemajuan baru-baru ini dalam penghuraian semantik dan pemudahan teks, kami menyelidiki penggunaan pemisahan semantik kalimat sumber sebagai pemprosesan untuk terjemahan mesin. Kami eksperimen dengan model Transformer dan menilai menggunakan eksperimen crowd-sourcing skala besar. Hasil menunjukkan peningkatan yang signifikan pada kalimat panjang pada tetapan Inggeris-Perancis dengan korpus latihan pasangan kalimat 5M, sementara menyimpan keperluan yang boleh dibandingkan. Kami juga melakukan analisis manual yang mengeksplorasi perdagangan antara keperluan dan keseluruhan dalam kes di mana semua panjang kalimat dianggap.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Filwaqt li nibnu fuq avvanzi reċenti fl-analiżi semantika u s-simplifikazzjoni tat-test, ninvestigaw l-użu tal-qsim semantiku tas-sentenza tas-sors bħala proċessar minn qabel għat-traduzzjoni bil-magna. Aħna ninsperimentaw b’mudell ta’ Transformer u nivvalutaw bl-użu ta’ esperimenti ta’ crowd sourcing fuq skala kbira. Ir-riżultati juru żieda sinifikanti fil-fluwenza fuq sentenzi twal fuq ambjent Ingliż-Franċiż b’korpus ta’ taħriġ ta’ pari ta’ sentenzi ta’ 5M, filwaqt li tinżamm adegwatezza komparabbli. Għandna nagħmlu wkoll analiżi manwali li tesplora l-kompromess bejn l-adegwatezza u l-fluwenza fil-każ fejn it-tul kollu tas-sentenza jiġi kkunsidrat.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Voortbouwend op recente ontwikkelingen in semantische parsing en tekstvereenvoudiging, onderzoeken we het gebruik van semantische splitsing van de bronzin als voorbewerking voor machinevertaling. We experimenteren met een Transformer model en evalueren met behulp van grootschalige crowdsourcing experimenten. De resultaten tonen een significante toename van de vloeibaarheid van lange zinnen in een Engels-Frans setting met een trainingscorpus van 5M zinnenparen, met behoud van vergelijkbare adequaatheid. We voeren ook een handmatige analyse uit die de afweging tussen adequaatheid en vloeiendheid onderzoekt in het geval dat alle zinnenlengtes worden overwogen.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>For å bygge på nyleg avansert i semantisk tolking og tekstforenkling, så undersøker vi bruken av semantisk deleting av kjeldesetninga som forhandtering for maskineoversettelse. Vi eksperimenterer med ein transformeringsmodell og evaluerer med stor masseskaler- eksperimenter. Resultater viser ein signifikant økning i flukt på lange setningar på ein engelsk- til- fransk innstilling med opplæringskorpus med 5M setningar, mens det beholder sammenlignbare adekvitet. Vi utfører også ein handbokanalyse som utforskar utviklinga mellom adekvitet og fluktet i tilfellet der alle setningane vert betrakte.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Opierając się na ostatnich postępach w parsowaniu semantycznym i uproszczeniu tekstu, badamy zastosowanie semantycznego podziału zdania źródłowego jako wstępnego przetwarzania do tłumaczenia maszynowego. Eksperymentujemy z modelem Transformera i oceniamy za pomocą dużych eksperymentów crowdsourcingowych. Wyniki wskazują na znaczący wzrost płynności w długich zdaniach w otoczeniu angielsko-francuskim z korpusem treningowym 5M par zdań, przy zachowaniu porównywalnej adekwatności. Przeprowadzamy również analizę ręczną, która bada kompromis między adekwatnością a płynnością w przypadku, gdy uwzględnia się wszystkie długości zdania.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Com base nos avanços recentes na análise semântica e simplificação de texto, investigamos o uso da divisão semântica da frase fonte como pré-processamento para tradução automática. Experimentamos um modelo Transformer e avaliamos usando experimentos de crowdsourcing em larga escala. Os resultados mostram um aumento significativo na fluência em frases longas em um ambiente de inglês para francês com um corpus de treinamento de 5 milhões de pares de frases, mantendo uma adequação comparável. Também realizamos uma análise manual que explora o tradeoff entre adequação e fluência no caso em que todos os comprimentos das frases são considerados.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bazându-ne pe progresele recente în analizarea semantică și simplificarea textului, investigăm utilizarea divizării semantice a propoziției sursă ca preprocesare pentru traducerea automată. Experimentăm cu un model Transformer și evaluăm utilizând experimente de crowdsourcing la scară largă. Rezultatele arată o creștere semnificativă a fluenței propozițiilor lungi într-un cadru engleză-franceză cu un corpus de formare de 5M perechi de propoziții, păstrând în același timp o adecvare comparabilă. De asemenea, efectuăm o analiză manuală care explorează compromisul dintre adecvare și fluență în cazul în care sunt luate în considerare toate lungimile propozițiilor.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Основываясь на последних достижениях в семантическом разборе и упрощении текста, мы исследуем использование семантического разделения исходного предложения в качестве предварительной обработки для машинного перевода. Экспериментируем с трансформаторной моделью и оцениваем с помощью крупномасштабных краудсорсинговых экспериментов. Результаты показывают значительное увеличение беглости в длинных предложениях в англо-французской среде с обучающим корпусом из 5 пар предложений при сохранении сопоставимой адекватности. Мы также проводим ручной анализ, который исследует компромисс между адекватностью и беглостью в случае, когда учитываются все длины предложений.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>සෙමැන්ටික් විශ්ලේෂණය සහ පාළුව සරලේෂණය සඳහා අලුත් ප්‍රධානය සඳහා නිර්මාණය කරනවා, අපි පරීක්ෂණය කරන්නේ මුළු වාක්ෂණය අපි පරීක්ෂණය කරන්නේ ත්‍රාණ්පර් මොඩේල් එකක් සමග විශාල පරීක්ෂණය සඳහා ලොකු ප්‍රමාණයක් ප්‍රයෝජනය ප්‍රතිචාරය පෙන්වන්නේ ඉංග්‍රීසියට- ෆ්‍රෑන්සියට ප්‍රශ්නයක් 5M වාක්ෂාවක් ජෝඩියට ප්‍රශ්නයක් තියෙන්නේ ලොක අපි පුළුවන් විශ්ලේෂණයක් කරනවා ඒ වගේම සේරම වාක්ය විශ්ලේෂණයක් පරීක්ෂණය කරනවා කියලා සේරම වාක්ය විශ්</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Na podlagi nedavnega napredka semantičnega razčlenjanja in poenostavitve besedila raziskujemo uporabo semantičnega razdelitve izvornega stavka kot predobdelave za strojno prevajanje. Eksperimentiramo s transformatorskim modelom in ocenjujemo z uporabo obsežnih množičnih eksperimentov. Rezultati kažejo znatno povečanje tekočosti pri dolgih stavkih v angleško-francoskem okolju s korpusom usposabljanja 5 M parov stavkov, ob ohranjanju primerljive ustreznosti. Izvajamo tudi ročno analizo, ki raziskuje kompromis med ustreznostjo in tekočostjo v primeru, ko upoštevamo vse dolžine stavka.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Buildida horumarinta ugu dambeeya baaritaanka semantika iyo sahlisashada qoraalka, waxaynu baaraynaa isticmaalka kala soocminta qoraalka asalka ah oo loo baaraandegayo turjumidda machine. We experiment with a Transformer model and evaluate using large-scale crowd-sourcing experiments. Midhaha la’aanta waxaa ka muuqda faa’iido aad u korodhsan dhegaha dhaadheer ee ku qoran af Ingiriis-ilaa-Faraansiis, iyadoo haysta mid u eg labada xabsi 5M. Anagu waxaynu sameynaa baaritaanka dhakhtarka, kaasoo baaraya dhibaatada u dhexeeya saxda iyo faa’iidada marka lagu tiriyo dhererka xukunka oo dhan.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Duke u mbështetur në përparimet e fundit në analizimin semantik dhe thjeshtimin e tekstit, ne hetojmë përdorimin e ndarjes semantike të fjalës së burimit si përgatitje për përkthimin e makinave. Ne eksperimentojmë me një model Transformer dhe vlerësojmë duke përdorur eksperimente të madhe crowd-sourcing. Rezultatet tregojnë një rritje të rëndësishme në fluencën e dënimeve të gjata në një ambient anglez-në-francez me një korpus trajnimi të çifteve të dënimeve 5M, duke mbajtur përshtatshmërinë e krahasueshme. Ne kryejmë gjithashtu një analizë manuale që eksploron kompromisin midis përshtatshmërisë dhe fluencës në rastin ku të gjitha gjatësitë e dënimit konsiderohen.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Na osnovu nedavnog napreda semantičkog analiza i pojednostavljanja teksta, istražujemo korištenje semantičkog dijeljenja izvorne rečenice kao predobrazovanje za prevod mašine. Mi eksperimentiramo sa modelom transformera i procjenjujemo koristeći velike većine eksperimenata koji izvode gomilu. Rezultati pokazuju značajno povećanje tečnosti dugih rečenica na engleskom i francuskom postavljanju sa treninganskim korpusom od par rečenica od 5M, dok zadržavaju usporednu adekvatnost. Takoðe izvršavamo ruènu analizu koja istražuje trgovinu izmeðu adekvatnosti i tekućine u slučaju u kojem se smatra dužin a rečenica.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Utifrån de senaste framstegen inom semantisk tolkning och textförenkling undersöker vi användningen av semantisk uppdelning av källmeningen som förbehandling för maskinöversättning. Vi experimenterar med en Transformer modell och utvärderar med hjälp av storskaliga crowdsourcing-experiment. Resultaten visar en signifikant ökning av flytande på långa meningar i en engelsk-fransk miljö med en träningskorpus på 5M meningspar, samtidigt som jämförbar tillräcklighet bibehålls. Vi utför också en manuell analys som undersöker avvägningen mellan lämplighet och flytande i de fall där alla meningslängder beaktas.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Building on recent advances in semantic parsing and text simplification, we investigate the use of semantic splitting of the source sentence as preprocessing for machine translation. Tunajaribu kwa mtindo wa Transformer na kutathmini kwa kutumia majaribio makubwa yanayotumiwa na vyanzo vya umma. Matokeo yanaonyesha kuongezeka kwa ufanisi mkubwa katika hukumu ndefu juu ya kitendo cha Kiingereza-hadi Kifaransa kinachotumiwa na kikundi cha mafunzo cha kifungo cha wanandoa 5M, wakati wakiendelea kuwa na usawa wa kutosha. Pia tunafanya uchambuzi wa mkono unaoelezea hali ya kutokea kati ya usawa na ufanisi katika kesi ambapo hukumu zote zinachukuliwa kwa muda mrefu.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>பெமான்டிக் பாசிங் மற்றும் உரை எளிதாக்கத்தில் சமீபத்தில் முன்னேற்றங்களை உருவாக்குதல் மூலத்தின் பிரிப்பு வாக்கியத்தின் முன் நாங்கள் ஒரு மாற்று மாதிரி முறைமையைக் கொண்டு பரிசோதிக்கிறோம் மற்றும் பெரிய அளவு கூட்டத்தின் மூல மூலம் @ info: whatsthis நாம் ஒரு கைமுறை ஆராய்ச்சி செய்கிறோம். அது தேவையான மற்றும் விளைவுகளுக்கிடையே இடையேயுள்ள இடைவெளிப்பாட்டை தெரிய</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Semantik anal첵힊inde we metin bejerilmesinde 첵okary geli힊melere 첵체ze 챌yky힊 edip, ma힊yny흫 terjime 체챌in 철흫체nden i힊len첵채n semantik s철zl채ni ulanmagyny barla첵arys. Biz bir Transformer modeli bilen synany힊첵arys we uly 철l챌ekli k철p sourcing deneylerini ulanyp de흫le첵채ris. Netijenler 5M s철zlem 챌ift sanynda u흫 s철zlemler i흫lis챌e- fransuz챌a d체z체mlenme 체챌in 철r채n k철pr채k 체첵tge첵채r, me흫ze힊li 첵erlilikde durul첵ar. Biz hem el analizi yapar캇z. Bu durumda, b체t체n s철zlerin uzunlu휓u d체힊체n체len durumda, adetleik we akyllyk aras캇ndaki ticareti ke힊fetmesini 챌철zer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>سیمنٹی پارسینگ اور ٹیکسٹ سادگی میں اچھی پیشرفت پر بنا رہے ہیں، ہم نے ماشین ترجمہ کے لئے پیش پردازی کے طور پر سیمنٹی پاٹینٹ کے استعمال کا تحقیق کیا ہے. ہم ایک ٹرانسفور موڈل کے ساتھ آزمائش کرتے ہیں اور بڑی اسکیل جماعت سورسینگ آزمائش کے مطابق ارزش کرتے ہیں. نتیجے ایک انگلیسی سے فرانسوی سٹینٹ پر طویل جماعت پر بہت اضافہ ہونے کے لئے 5M جماعت جوڑوں کی تدریس کورپوس کے ساتھ دکھائے جاتے ہیں، جبکہ برابری کے ساتھ قائم رہتے ہیں. ہم نے بھی ایک مہمانی تحلیل کرتا ہے جس میں ہر جماعت کی طول کی نظر کی جاتی ہے اس موقع میں کہ adequacy اور fluency کے درمیان تجارت کا تحقیق کرتا ہے.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>@ info: whatsthis Biz Transformer model bilan tizimiz qilamiz va katta ko'pchilik jamoatlar tizimini ishlatish mumkin. @ info: whatsthis Biz qoʻlbola analyzerni bajaramiz va hamma maxsus soʻzni tasavvur qilinadigan holatda yetarli narsalarni o'rganadi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Dựa trên những tiến bộ gần đây về phân tích ngữ pháp và việc đơn giản văn bản, chúng tôi điều tra việc sử dụng chữ thập theo ngữ pháp như việc xử lý trước phiên bản máy. Chúng tôi thử nghiệm với một mô hình transformer và đánh giá bằng cách thí nghiệm buôn lậu diện rộng. Kết quả cho thấy khả năng cao của các án dài trên một trường hợp Anh-Pháp với tập thể huấn của các cặp án 5M, đồng thời giữ mức độ phù hợp tương xứng. Chúng tôi cũng làm một phân tích bằng tay để tìm hiểu sự thỏa thuận giữa sự phù hợp và khéo léo trong trường hợp mọi độ dài các câu nói được xem xét.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>盖语义解析文简化之最新进展,研用源句之语义,分为机器翻译预处理。 Transformer以实验,大众包实验以质。 结果显示在英语法语中,长句流利,教语料库为5M句,兼保比充分性。 执手动析之,穷思句端,充分性流畅性之权衡。</span></div></div><dl><dt>Anthology ID:</dt><dd>2020.starsem-1.6</dd><dt>Volume:</dt><dd><a href=/volumes/2020.starsem-1/>Proceedings of the Ninth Joint Conference on Lexical and Computational Semantics</a></dd><dt>Month:</dt><dd>December</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Barcelona, Spain (Online)</dd><dt>Venues:</dt><dd><a href=/venues/starsem/>*SEM</a>
| <a href=/venues/coling/>COLING</a>
| <a href=/venues/semeval/>SemEval</a></dd><dt>SIGs:</dt><dd><a href=/sigs/siglex/>SIGLEX</a>
|
<a href=/sigs/sigsem/>SIGSEM</a></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>50–57</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.starsem-1.6>https://aclanthology.org/2020.starsem-1.6</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">sulem-etal-2020-semantic</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Elior Sulem, Omri Abend, and Ari Rappoport. 2020. <a href=https://aclanthology.org/2020.starsem-1.6>Semantic Structural Decomposition for Neural Machine Translation</a>. In <i>Proceedings of the Ninth Joint Conference on Lexical and Computational Semantics</i>, pages 50–57, Barcelona, Spain (Online). Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2020.starsem-1.6>Semantic Structural Decomposition for Neural Machine Translation</a> (Sulem et al., *SEM 2020)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2020.starsem-1.6.pdf>https://aclanthology.org/2020.starsem-1.6.pdf</a></dd><dt>Code</dt><dd><a href=https://github.com/eliorsulem/semantic-structural-decomposition-for-nmt><i class="fab fa-github"></i>&nbsp;eliorsulem/semantic-structural-decomposition-for-nmt</a></dd><dt>Data</dt><dd><a href=https://paperswithcode.com/dataset/wikisplit>WikiSplit</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2020.starsem-1.6.pdf title="Open PDF of 'Semantic Structural Decomposition for Neural Machine Translation'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Semantic+Structural+Decomposition+for+Neural+Machine+Translation" title="Search for 'Semantic Structural Decomposition for Neural Machine Translation' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-secondary d-flex flex-wrap justify-content-center" href="https://paperswithcode.com/paper/?acl=2020.starsem-1.6" title="Code for 'Semantic Structural Decomposition for Neural Machine Translation' on Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-big" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg><span class="pl-sm-2 d-none d-sm-inline">Code</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'Semantic Structural Decomposition for Neural Machine Translation'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[Semantic Structural Decomposition for Neural Machine Translation](https://aclanthology.org/2020.starsem-1.6) (Sulem et al., *SEM 2020)</p><ul class=mt-2><li><a href=https://aclanthology.org/2020.starsem-1.6>Semantic Structural Decomposition for Neural Machine Translation</a> (Sulem et al., *SEM 2020)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Elior Sulem, Omri Abend, and Ari Rappoport. 2020. <a href=https://aclanthology.org/2020.starsem-1.6>Semantic Structural Decomposition for Neural Machine Translation</a>. In <i>Proceedings of the Ninth Joint Conference on Lexical and Computational Semantics</i>, pages 50–57, Barcelona, Spain (Online). Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>