<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Does External Knowledge Help Explainable Natural Language Inference? Automatic Evaluation vs. Human Ratings - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="Does External Knowledge Help Explainable Natural Language Inference? Automatic Evaluation vs. Human Ratings" name=citation_title><meta content="Hendrik Schuff" name=citation_author><meta content="Hsiu-Yu Yang" name=citation_author><meta content="Heike Adel" name=citation_author><meta content="Ngoc Thang Vu" name=citation_author><meta content="Proceedings of the Fourth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP" name=citation_conference_title><meta content="2021/11" name=citation_publication_date><meta content="https://aclanthology.org/2021.blackboxnlp-1.3.pdf" name=citation_pdf_url><meta content="26" name=citation_firstpage><meta content="41" name=citation_lastpage><meta content="10.18653/v1/2021.blackboxnlp-1.3" name=citation_doi><meta property="og:title" content="Does External Knowledge Help Explainable Natural Language Inference? Automatic Evaluation vs. Human Ratings"><meta property="og:image" content="https://aclanthology.org/thumb/2021.blackboxnlp-1.3.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2021.blackboxnlp-1.3"><meta property="og:description" content="Hendrik Schuff, Hsiu-Yu Yang, Heike Adel, Ngoc Thang Vu. Proceedings of the Fourth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP. 2021."><link rel=canonical href=https://aclanthology.org/2021.blackboxnlp-1.3></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Does <a href=https://en.wikipedia.org/wiki/Knowledge>External Knowledge</a> Help Explainable <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>Natural Language Inference</a>? Automatic Evaluation vs. Human Ratings</a>
<a id=af_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Het eksterne kennis hulp verduidelik Natuurlike Taal Inferensie? Outomatiese evaluering teen menslike waardelings</a>
<a id=am_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>የውጭ እውቀት የባሕላዊ ቋንቋ መግለጫ ይችላልን? ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>هل المعرفة الخارجية تساعد في تفسير استدلال اللغة الطبيعية؟ التقييم التلقائي مقابل التقييمات البشرية</a>
<a id=az_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>External Knowledge Yard캼m edir M톛xluqat Dili Inference? 캻nsan qiym톛tl톛ri</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Външното знание помага ли за обяснимото природно езиково заключение? Автоматична оценка спрямо човешките рейтинги</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>বাইরের জ্ঞান কি স্বাভাবিক ভাষা ব্যাখ্যা করতে সাহায্য করে? স্বয়ংক্রিয়ভাবে মানুষের রেটিং</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>ཕྱི་རིང་གི་ཤེས་པའི་རོགས་རམ་བསླབ་བཏུབ་པའི་རང་བཞིན་སྐད་ཀྱི་ཆ་གཤིས་ཡིན་ནམ། རང་འགུལ་གྱིས་མིའི་རིམ་པ</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Da li vanjska znanja pomaže objašnjavajući prirodni jezik? Automatska procjena protiv ljudskih ocjena</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>El coneixement extern ajuda a explicar la llengua natural? Evaluació automàtica contra valoracions humanes</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Pomáhají externí znalosti vysvětlitelnému závěru přirozeného jazyka? Automatické hodnocení vs. lidské hodnocení</a>
<a id=da_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Hjælper ekstern viden med at forklare naturlige sproginfektioner? Automatisk evaluering i forhold til menneskelige vurderinger</a>
<a id=de_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Hilft externes Wissen bei erklärbaren Schlussfolgerungen natürlicher Sprache? Automatische Bewertung vs. Human Ratings</a>
<a id=el_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Βοηθά η εξωτερική γνώση στην εξήγηση της φυσικής γλώσσας; Αυτόματη αξιολόγηση έναντι των ανθρώπινων βαθμολογιών</a>
<a id=es_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>¿El conocimiento externo ayuda a la inferencia explicable del lenguaje natural? Evaluación automática frente a calificaciones humanas</a>
<a id=et_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Kas välised teadmised aitavad selgitada loodusliku keele järeldust? Automaatne hindamine vs inimhinnangud</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>آیا دانش خارجی کمک می کند تفاوت زبان طبیعی توضیح داده شود؟ ارزیابی خودکار با ارزیابی انسان</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Auttaako ulkoinen tietämys selittäviä luonnollisen kielen päätelmiä? Automaattinen arviointi verrattuna ihmisten luokituksiin</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Les connaissances externes contribuent-elles à l'inférence explicable du langage naturel ? Évaluation automatique par rapport aux évaluations humaines</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>An Cuidíonn Eolas Seachtrach Tátail Inmhínithe Teanga Nádúrtha? Meastóireacht Uathoibríoch vs. Rátálacha Daonna</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Shin, Aiki na Bayan Cilmi na Bayan Aiki na Bayan Taurar da za'a bayyana Infez da Lugha na Natural? @ action</a>
<a id=he_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>האם הידע החיצוני עוזר להסביר שפת טבעית חולה? Automatic Evaluation vs. Human Ratings</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>क्या बाहरी ज्ञान प्राकृतिक भाषा अनुमान को समझाने में मदद करता है? स्वचालित मूल्यांकन बनाम मानव रेटिंग</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Da li vanjska znanja pomaže objašnjivim prirodnim jezikom? Automatska procjena protiv ljudskih ocjena</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Segít a külső tudás megmagyarázni a természetes nyelvi fertőzést? Automatikus értékelés vs. humán minősítések</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Does External Knowledge Help Explainable Natural Language Inference? Comment</a>
<a id=id_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Apakah Pengetahuan Luar membantu Penjelasan Bahasa Alami Inferensi? Evaluasi Otomatis vs. Rating Manusia</a>
<a id=is_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>La conoscenza esterna aiuta a spiegare l'inferenza del linguaggio naturale? Valutazione automatica contro valutazioni umane</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>外部知識は説明可能な自然言語推論に役立ちますか？自動評価と人間評価</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Opo kowe paling Panjenengan langkung popolahan apik ? drawable-action</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>გარეშე ცნობიერების დახმარება გამოსახულებელი თავისუფლიო ენაზე? ადამიანის რეტინგის ავტომატური განსაზღვრება</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Сыртқы білім көмегімен түсініктіретін табиғи тілдер қатынасы бар ма? Адам бағалауына қарсы автоматты түрде оқу</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>외부 지식은 자연 언어의 추리를 해석하는 데 도움이 됩니까?자동 평가와 인공 평가</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Ar išorinės žinios padeda paaiškinti gamtinės kalbos trūkumą? Automatinis vertinimas, palyginti su žmogaus vertinimais</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Дали надворешното знаење помага да се објасни природната инференција на јазикот? Automatic Evaluation vs. Human Ratings</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>പുറത്തുള്ള അറിവ് സ്വാഭാവികമായ ഭാഷ വിശദീകരിക്കാന്‍ സഹായിക്കുന്നുണ്ടോ? മനുഷ്യരുടെ റേറ്റിങ്ങുകള്‍</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Байгалийн мэдлэг нь тайлбарлах байгалийн хэл хамааралтай туслах уу? Хүн төрөлхтний тооны эсрэг автоматтын үнэлгээ</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Adakah Pengetahuan Luar Bantu Dijelaskan Bahasa Bahasa Alami? Evaluasi Automatik vs. Nilai Manusia</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>L-Għarfien Estern jgħin fl-Inferenza tal-Lingwi Naturali Spjegabbli? Evalwazzjoni Awtomatika vs. Klassifikazzjonijiet tal-Bniedem</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Helpt Externe Kennis Verklaarbare Natuurlijke Taal Inferentie? Automatische evaluatie versus menselijke ratings</a>
<a id=no_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Er eksterne kunnskap hjelp for utforskar naturspråk? Automatisk evaluering mot menneske verdiar</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Czy wiedza zewnętrzna pomaga wyjaśnić wniosek języka naturalnego? Automatyczna ocena w porównaniu z oceną ludzką</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>O conhecimento externo ajuda a inferência de linguagem natural explicável? Avaliação automática versus classificações humanas</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Cunoștințele externe ajută la explicarea inferenței limbajului natural? Evaluare automată comparativ cu evaluările umane</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Помогают ли внешние знания сделать вывод о естественном языке? Автоматическая оценка в сравнении с человеческими оценками</a>
<a id=si_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>පුරුද්ගලික දැනගන්න උදව් කරන්න පුරුද්ගලික භාෂාව ප්‍රශ්නය කරන්න පුළුවන්ද? ස්වයංක්‍රියාත්මක විශ්වාස කරන්න</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Ali zunanje znanje pomaga pojasniti sklepanje naravnega jezika? Avtomatsko ocenjevanje v primerjavi z oceno ljudi</a>
<a id=so_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Ma cawinaada aqoonta dibadda ah oo la caddeyn karo afka asalka ah? Qedemeynta bilowga</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>A ndihmon njohuria e jashtme të shpjegohet për gjuhën natyrore? Vlerësim automatik kundër vlerësimeve njerëzore</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Da li vanjska znanja pomaže da objasni prirodni jezik? Automatic Evaluation vs. Human Ratings</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Hjälper extern kunskap till att förklara naturliga språkinfektioner? Automatisk utvärdering jämfört med mänskliga värderingar</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Je, maarifa ya nje inasaidia kuingilia lugha ya asili? Uchunguzi wa kujitegemea dhidi ya mabomu ya binadamu</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>வெளி அறிவு இயல்பான மொழி புதுப்பிக்க உதவுகிறதா? தானியங்கி மதிப்பீடு</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Daşarydaky Bilim Tebiýaly Dili Aňlamakda Kömek edip bilýärmi? Otomatik Taýýarlama</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>کیا خارجی علم کی تعریف قابل توسطی زبان کی نسبت مدد کرتی ہے؟ اٹوٹوکیٹ ارتفاع انسانی راٹینگ</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Tashqi maò¥lumot Natalik tilni aniqlashni istaysizmi? Avto- toò£gò£rilash</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>Hỗ trợ hiểu biết đối diện Giải thích ngôn ngữ tự nhiên? Đánh giá tự động tương ứng con người</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>外知有助于可解者自然语言理乎? 自料与人工评级</a></h2><p class=lead><a href=/people/h/hendrik-schuff/>Hendrik Schuff</a>,
<a href=/people/h/hsiu-yu-yang/>Hsiu-Yu Yang</a>,
<a href=/people/h/heike-adel/>Heike Adel</a>,
<a href=/people/n/ngoc-thang-vu/>Ngoc Thang Vu</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Natural language inference (NLI) requires models to learn and apply commonsense knowledge. These reasoning abilities are particularly important for explainable NLI systems that generate a <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language explanation</a> in addition to their label prediction. The integration of external knowledge has been shown to improve NLI systems, here we investigate whether it can also improve their explanation capabilities. For this, we investigate different sources of external knowledge and evaluate the performance of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on in-domain data as well as on special transfer datasets that are designed to assess fine-grained reasoning capabilities. We find that different sources of knowledge have a different effect on reasoning abilities, for example, <a href=https://en.wikipedia.org/wiki/Implicit_knowledge>implicit knowledge</a> stored in language models can hinder reasoning on numbers and <a href=https://en.wikipedia.org/wiki/Negation>negations</a>. Finally, we conduct the largest and most fine-grained explainable NLI crowdsourcing study to date. It reveals that even large differences in automatic performance scores do neither reflect in human ratings of label, explanation, commonsense nor <a href=https://en.wikipedia.org/wiki/Grammar>grammar correctness</a>.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Natuurlike taal inferensie (NLI) benodig modele om gemeenskaplike kennis te leer en toewend. Hierdie redelike moontlikhede is besonderlik belangrik vir verduidelike NLI stelsels wat 'n natuurlike taal uitduidelik genereer in addition to their label prediction. Die integrasie van eksterne kennis is vertoon om NLI stelsels te verbeter, hier ondersoek ons of dit ook hulle uitduidelingskapasiteite kan verbeter. Vir hierdie, ons ondersoek verskillende bronne van eksterne kennis en evalueer die effektiviteit van ons modele op in-domein data as ook op spesiale oordrag datastelle wat ontwerp word om fin-kornerede redekening kapasiteite te asseer. Ons vind dat verskillende bronne van kennis 'n ander effek het op redekende kapasiteite, byvoorbeeld, inplisite kennis wat in taal modele gestoor is, kan hinder redensie op getalle en negasies. Eindelik, ons doen die grootste en mees fyn-korne verduidelik NLI skakering studie tot nou. Dit openbaar dat selfs groot verskil in outomatiese prestasie punte geen reflekteer in menslike reetings van etiket, uitduidelikheid, gewoonlik of grammatiese regverdigheid.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Natural language inference (NLI) requires models to learn and apply commonsense knowledge. እነዚህ የሚያስተባብሉ ስልጣናት ይልቅ ለማይታወቅ የNLI ስርዓቶች ፍጥረታዊ ቋንቋን ለመፍጠር የሚችሉ ናቸው፡፡ የውጭ እውቀት ማጠናቀል NLI ስርዓቶች ማሻሻል ታይቷል፡፡ በዚህ ደግሞ መፍረጃቸውን ማሻሻል ይችላልን፡፡ ለዚህ ምክንያት የውጭ እውቀት መልዕክቶችን እናሳውቃለን እና የዶሜን ዳታዎችን እና የተመሳሳይ አእምሮዎችን ማረጋገጥ በተለየ የተለየ የዳታ መስኮት ላይ እናስተውላለን፡፡ የልዩ የእውቀት ምንጮች ለልዩ አካባቢዎች በቋንቋ ምሳሌዎች የተደብቀው እውቀት የቁጥር እና ውቀትን የሚከለክል ነው ብለን እናገኛለን፡፡ በመጨረሻም፣ ከሁሉ የበለጠ እና የበለጠ የNLI የድብፅ ጉዳይ ትምህርት እናደርጋለን፡፡ በራሱ አካባቢ ትልቅ ልውጤቶች ቢሆን በአካባቢው ስርዓት፣ ትርጓሜ፣ ትርጓሜ እና ትክክለኛ ትክክል በሚገልጽ አይመለከትም፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>يتطلب الاستدلال اللغوي الطبيعي (NLI) نماذج للتعلم وتطبيق المعرفة المنطقية. تعتبر قدرات التفكير هذه مهمة بشكل خاص لأنظمة NLI القابلة للتفسير والتي تولد تفسيرًا للغة الطبيعية بالإضافة إلى تنبؤ التسمية الخاصة بهم. لقد ثبت أن تكامل المعرفة الخارجية يحسن أنظمة NLI ، وهنا نتحرى ما إذا كان بإمكانه أيضًا تحسين قدرات التفسير الخاصة بها. لهذا ، نحن نبحث في مصادر مختلفة للمعرفة الخارجية ونقيم أداء نماذجنا على بيانات المجال وكذلك على مجموعات بيانات النقل الخاصة المصممة لتقييم قدرات التفكير الدقيقة. نجد أن مصادر المعرفة المختلفة لها تأثير مختلف على قدرات التفكير ، على سبيل المثال ، المعرفة الضمنية المخزنة في نماذج اللغة يمكن أن تعيق التفكير في الأرقام والنفي. أخيرًا ، نجري أكبر دراسة تعهيد جماعي قابلة للتفسير وأكثرها دقة حتى الآن. ويكشف أنه حتى الاختلافات الكبيرة في درجات الأداء التلقائية لا تنعكس في التصنيفات البشرية للتسمية والتفسير والمنطق ولا صحة القواعد.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Təbiətli dil infeksiyonu (NLI) öyrənmək və müxtəlif bilikləri istifadə etmək üçün modellər lazımdır. Bu müzakirə qabiliyyətlər özlərinin etiketlərinin öngörünüşünü artıran təbiətli dil a çıqlaması yaradan NLI sistemlərinə münasibdir. Dərzində bilgi integrasiyası NLI sistemlərini yaxşılaşdırmaq üçün göstərildi. Burada onların açıqlama kapasitələrini də yaxşılaşdırmaq mümkündür. Buna görə, biz dış bilgisinin müxtəlif mənbələrini incidirik və modellərimizin əməllərini domain verilənlərin və müxtəlif təkrar verilənlərin qurğularını müəyyən etmək üçün tasarlanmışdır. Biz bilirik ki, müxtəlif bilimin mənbələrinin razılıq qabiliyyətlərinə, məsələn dil modellerində qoyulan imkanlı bilgi sayılar və negasyonlar barəsində müzakirə edə bilər. Sonunda biz NLI crowdsourcing təhsil edilən ən ən böyük və ən gözəl taxıl təhsil etdik. Bu göstərir ki, otomatik performans nöqtələrində hətta böyük fərqli etiketlərin, açıq-aydınlıqların, yayınlıqların və gramatik düzgünlüklərində olmaz.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Природните езикови изводи (НЛИ) изискват модели за учене и прилагане на разумни знания. Тези способности за разсъждаване са особено важни за обясними системи, които генерират естествено езиково обяснение в допълнение към прогнозирането на етикета. Доказано е, че интегрирането на външни знания подобрява системите на НЛИ, тук изследваме дали може да подобри и техните обяснителни възможности. За тази цел ние изследваме различни източници на външни знания и оценяваме ефективността на нашите модели върху вътрешни данни, както и върху специални набори от данни за трансфер, които са предназначени да оценят фините възможности за разсъждаване. Откриваме, че различните източници на знания имат различен ефект върху способностите за разсъждаване, например имплицитното знание, съхранявано в езиковите модели, може да възпрепятства разсъждаването на числа и отрицания. И накрая, ние провеждаме най-голямото и най-фино обяснимо проучване на НЛИ crowdsourcing досега. Тя разкрива, че дори големите разлики в автоматичните резултати не отразяват нито в оценките на етикета, обяснението, благоразумието, нито граматическата коректност.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>স্বাভাবিক ভাষার আক্রান্ত (NLI) কমন্সেন্সের জ্ঞান শিক্ষা ও প্রয়োগ করার জন্য মডেল প্রয়োজন। এনলিআই সিস্টেমের জন্য এই কারণের ক্ষমতা বিশেষ গুরুত্বপূর্ণ যা তাদের লেবেলের ভবিষ্যতের ছাড়াও প্রাকৃতিক ভাষার ব্য এনলিআই সিস্টেম উন্নত করার জন্য বাইরের জ্ঞানের একত্রিত করা হয়েছে, এখানে আমরা তদন্ত করছি এটা তাদের ব্যাখ্যা ক্ষমতা উন্নত কিনা। এর জন্য আমরা বাইরের জ্ঞানের বিভিন্ন সূত্র তদন্ত করি এবং ডোমেইনের তথ্যে আমাদের মডেলের প্রভাবের বিষয়টি মূল্য করি এবং সাথে বিশেষ পরিবহনের তথ্যের বিষয়ে যা ভ আমরা খুঁজে পাচ্ছি যে বিভিন্ন জ্ঞানের উৎস বিভিন্ন ক্ষমতার প্রভাব রয়েছে, যেমন, ভাষার মডেলে সংরক্ষিত জ্ঞানের বিষয়টি সংরক্ষিত করা অবশেষে, আমরা এখন পর্যন্ত সবচেয়ে বৃহত্তম এবং সবচেয়ে ভালোভাবে কাজ করি এনলি জনসোর্সিং গবেষণা। এটি প্রকাশ করে যে স্বয়ংক্রিয়ভাবে প্রদর্শনের স্কোরে বিশাল পার্থক্য তারা লেবেল, ব্যাখ্যা, কমান্সেন্স এবং গ্রামের সঠিক ম</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>སྤྱིར་བཏང་ནུས་ཀྱི་སྐད་རིགས་ཕལ་ཆེ་བ(NLI)ལ་མིག་གཟུགས་རིས་དཔེ་གཏོང་དང་མཉམ་དུ་མཐུན རྟོགས་བསམ་ནུས་པ་འདི་དག་གི་ཁྱད་པར་གལ་ཆེན་ཡིན་པའི་NLI་རིགས ཕྱི་ལ་གྱི་ཤེས་ཡོད་ཚད་ཀྱི་ཆ་ཁ་ཤས་གཅིག་སྟོན་ཡོད་པས་NLI་རིམ་པ་ལ་ཡར་རྒྱས་གཏོང་ན། དེ་ནས་ང་ཚོའི་ནང་དུ་འོས་ཡོད For this, we investigate different sources of external knowledge and evaluate the performance of our models on in-domain data as well as on special transfer datasets that are designed to assess fine-grained reasoning capabilities. ང་ཚོར་ཤེས་པའི་ཐོག་ཁུངས་མི་འདྲ་བ་ལ་རྟོགས་བསམ་བློ་གཏོང་ནུས་པའི་དབང་རྩལ་དང་། དཔེར་ན། སྐད་ཡིག མཐའ་མར་དུ་འུ་ཅག་གིས་གནད་དོན་ཕལ་ཆེ་ཤོས་དང་ཆེ་བའི་ལྕགས་རིས་མང་ཤོས་ཀྱི་ཉེན་བརྗོད་བྱེད་ཀྱི་ཡོད། It reveals that even large differences in automatic performance scores do not reflect in human ratings of label, explanation, commonsense nor grammar correctness.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Prirodna infekcija jezika (NLI) zahtijeva modele za naučenje i primjenu znanja zajedničkog smisla. Ove razumne sposobnosti su posebno važne za objašnjavajuće NLI sisteme koje stvaraju prirodno objašnjenje jezika u dodatnom predviđanju etiketa. Integracija vanjskih znanja pokazala je kako bi poboljšala NLI sisteme, ovdje istražujemo da li može i poboljšati njihove mogućnosti objašnjenja. Za to istražujemo različite izvore vanjskih znanja i procjenjujemo učinkovitost naših modela o podacima u domenu, kao i o specijalnim prijenosnim podacima koje su dizajnirane za procjenu kvalitetnih razumnih mogućnosti. Nalazimo da različiti izvori znanja imaju različite utjecaje na razumne sposobnosti, na primjer, implicitno znanje koje se čuvaju u jezičkim modelima može spriječiti razgovor na brojeve i negacije. Konačno ćemo provesti najveću i najbolje objašnjavajuću studiju NLI za crowdsourcing do sada. Ono otkriva da čak i velike razlike u rezultatima automatskih učinka ne odražavaju ni u ljudskim ocjenama etikete, objašnjenja, češće smisla niti gramatske ispravnosti.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>La inferència de llenguatges naturals (NLI) requereix models per aprendre i aplicar coneixements comuns. Aquestes habilitats de raonament són particularment importants per a sistemes explicables de l'INN que generen una explicació natural de llenguatge a més de la seva predicció d'etiqueta. La integració del coneixement extern ha demostrat millorar els sistemes de l'INN, aquí investigam si també pot millorar les seves capacitats d'explicació. Per això, investigam diferents fonts de coneixement extern i evaluem el rendiment dels nostres models en dades internes i en conjunts de dades especials de transfer ència dissenyats per avaluar capacitats de raonament fins. Trobem que diferents fonts de coneixement tenen un efecte diferent en les habilitats de raonament, per exemple, el coneixement implícit emmagatzemat en models lingüístics pot impedir el raonament en números i negatius. Finally, we conduct the largest and most fine-grained explainable NLI crowdsourcing study to date. revela que fins i tot les grans diferències en les puntuacions automàtiques de rendiment no reflecteixen ni en les puntuacions humanes d'etiqueta, explicació, comú ni correcció gramàtica.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Inference přirozeného jazyka (NLI) vyžaduje modely k učení se a aplikaci znalostí zdravého rozumu. Tyto schopnosti uvažování jsou obzvláště důležité pro vysvětlitelné NLI systémy, které vedle predikce etiket generují vysvětlení přirozeného jazyka. Bylo prokázáno, že integrace externích znalostí zlepšuje NLI systémy, zde zkoumáme, zda může také zlepšit jejich vysvětlovací schopnosti. Za tímto účelem zkoumáme různé zdroje externích znalostí a vyhodnocujeme výkonnost našich modelů na doménových datech i na speciálních datových sadách přenosu, které jsou navrženy k posouzení jemně zraněných možností uvažování. Zjišťujeme, že různé zdroje znalostí mají různý vliv na schopnosti uvažování, například implicitní znalosti uložené v jazykových modelech mohou bránit uvažování o číslech a negacích. Nakonec provádíme největší a nejjemnější vysvětlitelnou NLI crowdsourcingovou studii dosud. Odhaluje, že ani velké rozdíly v automatickém skórování výkonu se neodrážejí v lidském hodnocení označení, vysvětlení, zdravého rozumu ani gramatické správnosti.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Naturligt sprog inference (NLI) kræver modeller til at lære og anvende almindelig viden. Disse ræsonnement evner er særligt vigtige for forklarelige NLI-systemer, der genererer en naturlig sprogforklaring ud over deres etiket forudsigelse. Integrationen af ekstern viden har vist sig at forbedre NLI systemer, her undersøger vi, om det også kan forbedre deres forklaringsmuligheder. Til dette undersøger vi forskellige kilder til ekstern viden og evaluerer ydeevnen af vores modeller på domænedata såvel som på særlige overførselsdatasæt, der er designet til at vurdere finkornede ræsonnementsfunktioner. Vi finder ud af, at forskellige kilder til viden har en anden effekt på ræsonnement evner, for eksempel kan implicit viden lagret i sprogmodeller hindre ræsonnement om tal og negationer. Endelig gennemfører vi den største og mest finkornede forklarelige NLI crowdsourcing undersøgelse hidtil. Det afslører, at selv store forskelle i automatiske resultater hverken afspejler i menneskelige vurderinger af etiket, forklaring, almindelighed eller grammatik korrekthed.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Natural Language Inference (NLI) erfordert Modelle, um gesundes Wissen zu lernen und anzuwenden. Diese Argumentationsfﾃ､higkeiten sind besonders wichtig fﾃｼr erklﾃ､rbare NLI-Systeme, die zusﾃ､tzlich zu ihrer Label-Vorhersage eine natﾃｼrliche Spracherklﾃ､rung generieren. Die Integration von externem Wissen hat gezeigt, dass NLI-Systeme verbessert werden, hier untersuchen wir, ob es auch deren Erklﾃ､rungsfﾃ､higkeit verbessern kann. Dazu untersuchen wir verschiedene Quellen externer Erkenntnisse und bewerten die Performance unserer Modelle sowohl auf In-Domain-Daten als auch auf speziellen Transferdatensﾃ､tzen, die zur Beurteilung feingranularer Denkfﾃ､higkeiten konzipiert sind. Wir stellen fest, dass unterschiedliche Wissensquellen unterschiedliche Auswirkungen auf die Denkfﾃ､higkeit haben. Beispielsweise kann implizites Wissen, das in Sprachmodellen gespeichert ist, das Argumentieren von Zahlen und Negationen behindern. Schlieﾃ殕ich fﾃｼhren wir die bisher grﾃｶﾃ殳e und feinkﾃｶrnigste erklﾃ､rbare NLI Crowdsourcing-Studie durch. Es zeigt sich, dass sich selbst groﾃ歹 Unterschiede in den automatischen Leistungswerten weder in der menschlichen Bewertung von Label, Erklﾃ､rung, gesundem Menschenverstand noch grammatikalischer Korrektheit widerspiegeln.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Το συμπέρασμα φυσικής γλώσσας απαιτεί μοντέλα για να μάθουν και να εφαρμόσουν γνώση κοινής λογικής. Αυτές οι ικανότητες συλλογισμού είναι ιδιαίτερα σημαντικές για τα εξηγητά συστήματα που παράγουν μια φυσική εξήγηση γλώσσας εκτός από την πρόβλεψη ετικετών τους. Η ενσωμάτωση εξωτερικών γνώσεων έχει αποδειχθεί ότι βελτιώνει τα συστήματα Εδώ ερευνούμε αν μπορεί επίσης να βελτιώσει τις δυνατότητες εξήγησης τους. Για το σκοπό αυτό, διερευνούμε διαφορετικές πηγές εξωτερικής γνώσης και αξιολογούμε την απόδοση των μοντέλων μας σε δεδομένα εντός του τομέα καθώς και σε ειδικά σύνολα δεδομένων μεταφοράς που έχουν σχεδιαστεί για την αξιολόγηση των δυνατοτήτων λεπτού συλλογισμού. Διαπιστώνουμε ότι διαφορετικές πηγές γνώσης έχουν διαφορετική επίδραση στις ικανότητες συλλογισμού, για παράδειγμα, η σιωπηρή γνώση που αποθηκεύεται σε γλωσσικά μοντέλα μπορεί να εμποδίσει τη συλλογιστική αριθμών και αρνήσεων. Τέλος, διεξάγουμε τη μεγαλύτερη και πιο λεπτόκοκκη επεξηγητή μελέτη μέχρι σήμερα. Αποκαλύπτει ότι ακόμη και μεγάλες διαφορές στις αυτόματες βαθμολογίες απόδοσης δεν αντικατοπτρίζονται στις ανθρώπινες αξιολογήσεις της ετικέτας, της επεξήγησης, της κοινής λογικής ή της γραμματικής ορθότητας.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>La inferencia de lenguaje natural (NLI) requiere modelos para aprender y aplicar el conocimiento de sentido común. Estas habilidades de razonamiento son particularmente importantes para los sistemas de NLI explicables que generan una explicación en lenguaje natural además de la predicción de su etiqueta. Se ha demostrado que la integración del conocimiento externo mejora los sistemas de NLI, aquí investigamos si también puede mejorar sus capacidades de explicación. Para ello, investigamos diferentes fuentes de conocimiento externo y evaluamos el rendimiento de nuestros modelos en datos de dominio, así como en conjuntos de datos de transferencia especiales que están diseñados para evaluar capacidades de razonamiento minuciosas. Encontramos que las diferentes fuentes de conocimiento tienen un efecto diferente en las habilidades de razonamiento, por ejemplo, el conocimiento implícito almacenado en los modelos de lenguaje puede dificultar el razonamiento sobre números y negaciones. Finalmente, llevamos a cabo el mayor y más detallado estudio de crowdsourcing explicable de NLI hasta la fecha. Revela que incluso las grandes diferencias en las puntuaciones automáticas de rendimiento no se reflejan en las calificaciones humanas de etiqueta, explicación, sentido común ni corrección gramatical.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Looduskeele järeldus (NLI) nõuab mudeleid, et õppida ja rakendada üldse mõistlikke teadmisi. Need arutlusvõimed on eriti olulised seletatavate NLI süsteemide puhul, mis loovad lisaks oma märgise prognoosile looduskeelse selgituse. Välisteadmiste integreerimine on näidanud NLI süsteemide parandamist, siin uurime, kas see võib parandada ka nende selgitusvõimet. Selleks uurime erinevaid välisteadmiste allikaid ja hindame oma mudelite jõudlust nii domeenisiseste andmete kui ka spetsiaalsete edastamisandmekogumite puhul, mis on mõeldud hindama peenete arutlusvõimeid. Leiame, et erinevatel teadmisteallikatel on erinev mõju mõtlemisvõimele, näiteks keelemudelites salvestatud kaudsed teadmised võivad takistada arvude ja negatsioonide arutlemist. Lõpuks viime läbi seni suurima ja kõige peenema selgitatava NLI ühishankimise uuringu. See näitab, et isegi suured erinevused automaatsete tulemuste skoorides ei kajasta inimeste hinnanguid sildi, selgituse, mõistuse ega grammatika õigsuse kohta.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>آلودگی زبان طبیعی (NLI) نیاز به مدل‌های یادگیری و استفاده از دانش معمولی است. این توانایی منطقی برای سیستم های NLI قابل توضیح و توضیح زبان طبیعی در addition to their label prediction مهم است. جمع علم خارجی نشون داده شده تا سیستم‌های NLI را بهتر کند، اینجا تحقیق کنیم که آیا می‌تواند توانایی توضیح‌شان را بهتر کند. برای این، ما منبع های مختلف دانش خارجی را تحقیق می کنیم و عملکرد مدل های ما را در اطلاعات دامنی‌های خاص و در مجموعه‌های انتقال داده‌های خاصی که طراحی شده‌اند برای ارزیابی توانایی‌های منطقی‌کننده‌های پاکیزه‌ی دانه‌های خارجی ارزی ما متوجه شدیم که منابع مختلف علم تأثیر متفاوتی بر توانایی منطقی دارند، برای مثال، دانش معمولی که در مدلهای زبانی ذخیره شده است، می تواند منطقی در شماره و منطقی را متوقف کند. بالاخره، ما بزرگترین و بهترین دانه‌های توضیح قابل توضیح عمومی NLI را تا حالا انجام می‌دهیم. این نشان می دهد که حتی تفاوت های بزرگ در امتیاز عملکرد خودکار در امتیاز های نقاشی، توضیح، معمولی و درستی نقاشی انسان تفکیر نمی کنند.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Luonnonkielen päättely (NLI) edellyttää malleja, joilla voidaan oppia ja soveltaa järjetöntä tietoa. Nämä päättelytaidot ovat erityisen tärkeitä selitettävissä oleville NLI-järjestelmille, jotka tuottavat etikettiennusteen lisäksi luonnollisen kielen selityksen. Ulkoisen tiedon integroinnin on osoitettu parantavan NLI-järjestelmiä, tässä selvitämme, voiko se myös parantaa niiden selityskykyä. Tätä varten tutkimme erilaisia ulkoisen tiedon lähteitä ja arvioimme malliemme suorituskykyä sekä sisäisissä tiedoissa että erityisissä siirtotietoaineistoissa, jotka on suunniteltu arvioimaan hienojakoisia päättelykykyjä. Havaitsemme, että eri tietolähteillä on erilainen vaikutus päättelykykyyn, esimerkiksi kielimalleihin tallennettu implisiittinen tieto voi haitata lukujen ja kiistojen päättelyä. Lopuksi toteutamme tähän mennessä suurimman ja hienorakeisen selitettävän NLI-joukkohankintatutkimuksen. Se paljastaa, että jopa suuret erot automaattisissa suorituspisteissä eivät heijastu ihmisten luokituksia etiketistä, selityksestä, järkevyydestä tai kieliopin oikeellisuudesta.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>L'inférence en langage naturel (NLI) nécessite des modèles pour apprendre et appliquer des connaissances de bon sens. Ces capacités de raisonnement sont particulièrement importantes pour les systèmes NLI explicables qui génèrent une explication en langage naturel en plus de leur prédiction d'étiquette. Il a été démontré que l'intégration de connaissances externes améliore les systèmes NLI. Nous examinons ici si elle peut également améliorer leurs capacités d'explication. Pour cela, nous étudions différentes sources de connaissances externes et évaluons les performances de nos modèles sur des données internes au domaine ainsi que sur des ensembles de données de transfert spéciaux conçus pour évaluer des capacités de raisonnement précis. Nous constatons que différentes sources de connaissances ont un effet différent sur les capacités de raisonnement. Par exemple, les connaissances implicites stockées dans les modèles linguistiques peuvent entraver le raisonnement sur les nombres et les négations. Enfin, nous menons l'étude de crowdsourcing NLI explicable la plus importante et la plus fine à ce jour. Il révèle que même de grandes différences dans les scores de performance automatiques ne se reflètent pas dans les évaluations humaines de l'étiquette, de l'explication, du bon sens ou de la correction grammaticale.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Teastaíonn samhlacha ó thátal nádúrtha teanga (NLI) chun eolas ciallmhar a fhoghlaim agus a chur i bhfeidhm. Tá na cumais réasúnaíochta seo thar a bheith tábhachtach do chórais NLI inmhínithe a ghineann míniúchán teanga nádúrtha i dteannta lena dtuar lipéid. Léiríodh go bhfeabhsaítear córais LNÉ trí chomhtháthú an eolais sheachtraigh, agus anseo fiosraimid an féidir leis a gcumas míniúcháin a fheabhsú freisin. Chuige sin, déanaimid imscrúdú ar fhoinsí éagsúla eolais sheachtraigh agus déanaimid meastóireacht ar fheidhmíocht ár samhlacha ar shonraí in-fhearainn agus ar thacair sonraí aistrithe speisialta atá deartha chun cumais réasúnaíochta mhínínithe a mheas. Faighimid amach go mbíonn tionchar difriúil ag foinsí éagsúla eolais ar chumais réasúnaíochta, mar shampla, is féidir le heolas intuigthe atá stóráilte i múnlaí teanga bac a chur ar réasúnaíocht ar uimhreacha agus ar dhiúltaí. Ar deireadh, déanaimid an staidéar sluafhoinsithe de chuid LNÉ is mó agus is míne inmhínithe go dtí seo. Léiríonn sé nach léiríonn fiú difríochtaí móra sna scóir feidhmíochta uathoibríocha sna rátálacha daonna maidir le lipéad, míniú, tuiscint choitianta ná cruinneas gramadaí.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>@ info: whatsthis Ga wannan abinci masu inganci ne mafiya muhimu ga system-NLI waɗanda bã da an bayyana shi ba, ta ƙãga fassarar harshen kawaici da kuma ba da gabanin littafan su ba. An nuna integratewa da ilmi na baka don ya ƙara tsarin NLI, a nan, Munã tambaya ko za ta ƙara da abincin fassararsu. Daga wannan, Munã tambayi sourcen sanyin baka da kuma munã ƙaddara game da aikin misãlai masu cikin-danne da kuma kan data masu shige da aka ƙaddara don a ƙaddara abincin da aka naƙasa. We find that different sources of knowledge have a different effect on reasoning abilities, for example, implicit knowledge stored in language models can hinder reasoning on numbers and negations. Haƙĩƙa, Munã tafiyar da mafi girma da mafi kyaun karatun na NLI da ake bayyana wa maɓallin sourcer zuwa yanzu. Yana bayyana cewa, kõ dã sãɓa masu girma cikin score na-performance farat ɗaya ba su yi tunãni ba a cikin rabo-rayin mutum, fassarar, farin ciki, kuma kuma kuma daman shiryarwa.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>תוצאת שפת טבעית (NLI) דורשת דוגמנים ללמוד ולהשתמש בידע משותף. היכולות ההיגיון הללו חשובות במיוחד למערכות NLI מסבירות שמוצרות הסבר טבעי לשפה בנוסף לחזות התווית שלהם. The integration of external knowledge has been shown to improve NLI systems, here we investigate whether it can also improve their explanation capabilities. For this, we investigate different sources of external knowledge and evaluate the performance of our models on in-domain data as well as on special transfer datasets that are designed to assess fine-grained reasoning capabilities. אנו מוצאים שלמקורות שונים של ידע יש השפעה שונה על יכולות ההיגיון, לדוגמא, ידע מרושע שמחסן בדוגמנים לשפה יכול לעצור ההיגיון על מספרים ושלילות. סוף סוף, אנו מבצעים את המחקר הגדול ביותר והמוסבר ביותר במקורי קהל NLI עד היום. הוא מגלה שאפילו הבדלים גדולים בתוצאות ביצועים אוטומטיים לא משקפים בכישורים אנושיים של תווית, הסבר, משמעותי או תקנות גרמטיקה.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>प्राकृतिक भाषा अनुमान (एनएलआई) को सामान्य ज्ञान ज्ञान को सीखने और लागू करने के लिए मॉडल की आवश्यकता होती है। ये तर्क क्षमताएं विशेष रूप से स्पष्ट एनएलआई प्रणालियों के लिए महत्वपूर्ण हैं जो उनके लेबल की भविष्यवाणी के अलावा एक प्राकृतिक भाषा स्पष्टीकरण उत्पन्न करती हैं। बाहरी ज्ञान के एकीकरण को एनएलआई प्रणालियों में सुधार करने के लिए दिखाया गया है, यहां हम जांच करते हैं कि क्या यह उनकी स्पष्टीकरण क्षमताओं में भी सुधार कर सकता है। इसके लिए, हम बाहरी ज्ञान के विभिन्न स्रोतों की जांच करते हैं और इन-डोमेन डेटा के साथ-साथ विशेष हस्तांतरण डेटासेट पर हमारे मॉडल के प्रदर्शन का मूल्यांकन करते हैं जो ठीक-ठाक तर्क क्षमताओं का आकलन करने के लिए डिज़ाइन किए गए हैं। हम पाते हैं कि ज्ञान के विभिन्न स्रोतों का तर्क क्षमताओं पर एक अलग प्रभाव पड़ता है, उदाहरण के लिए, भाषा मॉडल में संग्रहीत अंतर्निहित ज्ञान संख्याओं और नकारों पर तर्क में बाधा डाल सकता है। अंत में, हम आज तक के सबसे बड़े और सबसे ठीक-ठाक स्पष्ट एनएलआई क्राउडसोर्सिंग अध्ययन का संचालन करते हैं। यह पता चलता है कि स्वचालित प्रदर्शन स्कोर में भी बड़े अंतर न तो लेबल, स्पष्टीकरण, कॉमनसेंस और न ही व्याकरण शुद्धता की मानव रेटिंग में प्रतिबिंबित होते हैं।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Prirodna infekcija jezika (NLI) zahtijeva modele za naučenje i primjenu znanja običnog smisla. Ove razumne sposobnosti su posebno važne za objašnjavajuće NLI sustave koji stvaraju prirodno objašnjenje jezika u dodatnoj predviđanju etiketa. Integracija vanjskih znanja pokazala je kako bi poboljšala NLI sustave, ovdje istražujemo može li i poboljšati njihove mogućnosti objašnjenja. Za to istražujemo različite izvore vanjskih znanja i procjenjujemo učinkovitost naših modela na podacima u domenu, kao i na specijalne prijenosne podatke koje su dizajnirane za procjenu potpunih razumnih mogućnosti. Nalazimo da različiti izvori znanja imaju različit učinak na razumne sposobnosti, na primjer, implicitno znanje koje se čuvaju u jezičkim modelima može spriječiti razumjevanje brojeva i negacija. Konačno ćemo provesti najveću i najbolje objašnjavajuću studiju NLI crowdsourcing do sada. Otkriva se da čak i velike razlike u automatskim rezultatima učinka ne odražavaju ni u ljudskim ocjenama etikete, objašnjenja, češće smisla niti ispravnosti gramatike.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A természetes nyelvi következtetés (NLI) modelleket igényel a közértelmes ismeretek tanulásához és alkalmazásához. Ezek az érvelési képességek különösen fontosak a megmagyarázható NLI rendszerek esetében, amelyek természetes nyelvi magyarázatot generálnak a címke előrejelzése mellett. A külső tudás integrációja bizonyítottan javítja az NLI rendszereket, itt azt vizsgáljuk, hogy képes-e javítani a magyarázat képességeit is. Ennek érdekében a külső ismeretek különböző forrásait vizsgáljuk, és értékeljük modelleink teljesítményét a tartományon belüli adatokon, valamint speciális átviteli adatkészleteken, amelyek a finomszemcsés érvelési képességek felmérésére szolgálnak. Megállapítjuk, hogy a különböző tudásforrások eltérő hatással vannak az érvelési képességekre, például a nyelvi modellekben tárolt implicit tudás akadályozhatja a számok és tagadások érvelését. Végül végezzük el az eddigi legnagyobb és legfinomabb magyarázható NLI crowdsourcing tanulmányt. Feltárja, hogy még az automatikus teljesítmény pontszámok közötti nagy különbségek sem tükröznek az emberi értékelésekben a címke, magyarázat, közérzet vagy nyelvtani helyesség.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Բնական լեզվի եզրակացությունը պահանջում է մոդելներ սովորելու և կիրառելու համար ընդհանուր գիտելիքներ: Այս մտածողական հնարավորությունները հատկապես կարևոր են ՀՆԱ-ի բացատրելի համակարգերի համար, որոնք ստեղծում են բնական լեզվի բացատրություն, բացի իրենց պիտակների կանխատեսումից: Պարզվել է, որ արտաքին գիտելիքների ինտեգրացիան բարելավում է ՆԼԻ համակարգերը, այստեղ մենք ուսումնասիրում ենք, արդյոք այն կարող է նաև բարելավել իրենց բացատրական ունակությունները: Այս դեպքում մենք ուսումնասիրում ենք արտաքին գիտելիքների տարբեր աղբյուրներ և գնահատում ենք մեր մոդելների արտադրողականությունը բնագավառի տվյալների, ինչպես նաև հատուկ տեղափոխման տվյալների համակարգերի վրա, որոնք նախագծված են նրբագեղ մտածողականության հ Մենք հայտնաբերում ենք, որ տարբեր գիտելիքների աղբյուրները տարբեր ազդեցություններ ունեն մտածողական ունակությունների վրա, օրինակ, լեզվի մոդելներում պահպանված ենթարկված գիտելիքները կարող են խոչընդոտել մտածողությունը թվերի և բացասական Վերջապես, մենք կատարում ենք մինչ այժմ ամենամեծ և ամենագեղեցիկ բացատրելի ՆԼԻ-ի ժողովրդավարման ուսումնասիրությունը: It reveals that even large differences in automatic performance scores do neither reflect in human ratings of label, explanation, commonsense nor grammar correctness.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Keputusan bahasa alam (NLI) membutuhkan model untuk belajar dan menerapkan pengetahuan umum. Kemampuan alasan ini sangat penting untuk sistem NLI yang dapat dijelaskan yang menghasilkan penjelasan bahasa alami selain prediksi label mereka. Integrasi pengetahuan luar telah menunjukkan untuk meningkatkan sistem NLI, di sini kita menyelidiki apakah itu juga dapat meningkatkan kemampuan penjelasan mereka. Untuk ini, kami menyelidiki sumber-sumber pengetahuan luar yang berbeda dan mengevaluasi prestasi model kami pada data dalam domain serta pada set data transfer khusus yang direncanakan untuk mengevaluasi kemampuan pemikiran yang baik. Kami menemukan bahwa sumber pengetahuan yang berbeda memiliki efek yang berbeda pada kemampuan reasoning, misalnya, pengetahuan implicit yang disimpan dalam model bahasa dapat menghalangi reasoning pada angka dan negati. Akhirnya, kami melakukan penelitian crowdsourcing NLI yang paling besar dan paling bagus yang bisa dijelaskan sampai saat ini. Hal ini mengungkapkan bahkan perbedaan besar dalam skor prestasi otomatis tidak merefleksikan dalam nilai manusia label, penjelasan, umum atau persis grammar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>L'inferenza del linguaggio naturale (NLI) richiede modelli per imparare e applicare conoscenze di senso comune. Queste capacità di ragionamento sono particolarmente importanti per i sistemi NLI spiegabili che generano una spiegazione del linguaggio naturale in aggiunta alla loro previsione dell'etichetta. L'integrazione delle conoscenze esterne ha dimostrato di migliorare i sistemi NLI, qui si studia se può anche migliorare le loro capacità di spiegazione. Per questo, esaminiamo diverse fonti di conoscenza esterna e valutiamo le prestazioni dei nostri modelli su dati in-domain e su set di dati speciali di trasferimento progettati per valutare capacità di ragionamento a grana fine. Troviamo che diverse fonti di conoscenza hanno un effetto diverso sulle capacità di ragionamento, ad esempio, le conoscenze implicite memorizzate nei modelli linguistici possono ostacolare il ragionamento su numeri e negazioni. Infine, conduciamo lo studio di crowdsourcing NLI più ampio e spiegabile fino ad oggi. Essa rivela che anche le grandi differenze nei punteggi delle prestazioni automatiche non riflettono nelle valutazioni umane di etichetta, spiegazione, senso comune o correttezza grammaticale.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>自然言語推論（ NLI ）では、モデルが常識的な知識を学び、適用する必要がある。 これらの推論能力は、ラベル予測に加えて自然言語の説明を生成する説明可能なNLIシステムにとって特に重要です。 外部知識の統合はNLIシステムを改善することが示されており、ここではそれらの説明能力を向上させることができるかどうかを調査します。 このため、外部知識のさまざまなソースを調査し、ドメイン内データおよび細かい推論能力を評価するように設計された特別な転送データセットでのモデルのパフォーマンスを評価します。 異なる知識源は、例えば、言語モデルに保存された暗黙の知識が、数値や否定に関する推論を妨げる可能性があるなど、推論能力に異なる影響を及ぼすことがわかっている。 最後に、これまでで最大かつ最も細かく説明可能なNLIクラウドソーシング研究を行います。 自動パフォーマンススコアの大きな違いでさえ、ラベル、説明、常識、文法の正しさの人間的評価に反映されないことが明らかになりました。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nari kesalahan kelas (NLI) butakon model kanggo sampek karo aplikasi kesalahan ingkang dipun. Awarti punika dipunanggé kuwi nggawe barang akeh luwih apik kanggo ngerasakno NLI iki dadi kapan tanggal sing dirambut kanggo ngerasakno tambah kanggo ngerasakno ning etiket. Entekan wong liyane ing rak segala sing nyerampun kanggo nggawe sistem NLI, kene awak dhéwé ujian sisaan kaya ngono iso nggawe akeh perusahaan kapasituran kanggo mbanjurakno. Saiki iki, we istrage diwurune buktuan samihan kelas barang nggawe barang nggawe model karo data-domain lan karo perusahaan dataset sing dibenaanye nggawe kanggo assess Awak dhéwé éntuk sistem sing dipun ajeng-sistem dadi kapan kuwi tindang yen manut karo nggawe barang, bisa ngono kuwi tindang kuwi tindang kejahatan Nyong-ngopo, kita praksi sing paling awak dhéwé anu nggawe gerakan oleh dumadhi NLI sing susahe nggawe ujak. Punika-punika sing ngerasakno akeh luwih akeh gak bener</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ნაირადი ენის ინფრენცია (NLI) უნდა მოდელების შესწავლება და გამოყენება საერთო სიცოცხლე. ეს პარამენტიური შესაძლებლობა განსაზღვრებელი NLI სისტემებისთვის მნიშვნელოვანია, რომელიც თავის ლაბეტის წარმოდგენის დამატებით ნახვა ენის გახსნა. გარეშე ცნობილების ინტერგურაცია გამოჩვენებულია, რომ NLI სისტემების უფრო მეტირებად, აქ ჩვენ ვაკეთებთ თუ ეს შეუძლია ასევე უფრო მეტირება შესაძლებლობა. ამისთვის, ჩვენ განსხვავებული გარეშე ცნობილების განსხვავებული გამოყენება და ჩვენი მოდელების გამოყენება დემომინის მონაცემებზე და სპეციალური გარეშე მონაცემების შესახებ, რომლებიც განაზღვრებულია ჩვენ ვიფიქრობთ, რომ განსხვავებული მეცნიერების გამოსახულების განსხვავებული ეფექტი არსებობს რაოდენობის შესაძლებლობაზე, მაგალითად, ენის მოდელში მუშაობული მეცნიერების შესაძლებელია რაო საბოლოოდ, ჩვენ გავაკეთებთ უფრო დიდი და უკეთესი განახსენებელი NLI მუშაობის სწავლა. ეს აღმოჩნდება, რომ კიდევ დიდი განსხვავებები ავტომატური განსხვავებაში არ განსხვავებენ ადამიანის რეტენტირებში, განსხვავებაში, საშუალოდ განსხვავებაში არ განსხვავებენ,</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Табиғлық тіл инференциясы (NLI) үлгілерін үйрену және көпшілік мәліметтерді қолдану үшін керек. Бұл сезімдік мүмкіндіктері өзінің белгілерін таңдау үшін түсініктіретін NLI жүйелері үшін өте маңызды. Сыртқы білімдердің интеграциясы NLI жүйелерін жақсарту үшін көрсетілді. Бұл жерде біз оның түсіндіру мүмкіндіктерін де жақсартуға болады. Бұл үшін біз сыртқы білім көзін зерттеп, домен деректерінің үлгілеріміздің және арнайы аудару деректер жиындарын оқу үшін құрылған. Мысалы, тіл үлгілерінде сақталған мәліметтердің түрлі мәліметтерінің басқа нәтижелері сандар мен негативтер үшін тұратын мәліметтердің әртүрлі нәтижелері бар. Соңында, біз NLI көпшілік көпшіліктерінің ең үлкен және ең жақсы түсінікті зерттеуді жасадық. Бұл автоматты істеу нәтижесінің үлкен түрлері адамдардың белгілері, түсініктемелері, көпшілікті және грамматикалық дұрыстығын көрсетпейді.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>자연 언어 추리(NLI)는 상식 지식을 모형 학습하고 응용해야 한다.이러한 추리력은 해석 가능한 NLI 시스템에 특히 중요하다. 이런 시스템은 라벨 예측 외에 자연 언어 해석도 생성한다.외부 지식의 통합이 NLI 시스템을 개선할 수 있다는 것이 증명되었는데, 여기서 우리는 그것이 그들의 해석 능력을 향상시킬 수 있는지를 연구한다.이를 위해 우리는 외부 지식의 서로 다른 출처를 조사하고 우리의 모델이 역내 데이터와 세립도 추리 능력을 평가하는 특수 전송 데이터 집합의 성능을 평가했다.우리는 서로 다른 지식의 출처가 추리 능력에 서로 다른 영향을 미친다는 것을 발견했다. 예를 들어 언어 모델에 저장된 숨은 지식은 숫자와 부정에 대한 추리를 방해할 수 있다.마지막으로 우리는 지금까지 규모가 가장 크고 입도가 가장 가는 NLI 클러스터 연구를 진행했다.연구에 따르면 자동 성적의 큰 차이도 라벨, 해석, 상식과 문법의 정확성에 대한 인류의 평점에 반영되지 않는다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Natural language inference (NLI) requires models to learn and apply commonsense knowledge. Šie pagrįstieji gebėjimai ypač svarbūs aiškioms NLI sistemoms, kurios, be etiketės prognozės, sukuria natūralų kalbos paaiškinimą. Įrodyta, kad išorės žinių integracija pagerina NLI sistemas, čia mes tiriame, ar ji taip pat gali pagerinti jų paaiškinimo gebėjimus. For this, we investigate different sources of external knowledge and evaluate the performance of our models on in-domain data as well as on special transfer datasets that are designed to assess fine-grained reasoning capabilities. Nustatome, kad skirtingi žinių šaltiniai turi skirtingą poveikį pagrįstiesiems gebėjimams, pavyzdžiui, netiesioginės kalbų modeliuose saugomos žinios gali trukdyti pagrįsti skaičių ir neigiamus gebėjimus. Galiausiai iki šiol atliekame didžiausią ir geriausiai paaiškinamą NLI visuomenės išteklių tyrimą. Iš jo matyti, kad net dideli automatinių veikimo rezultatų skirtumai neatspindi nei žmogaus etiketės, paaiškinimo, bendro pobūdžio, nei gramatinio tikslumo vertinimų.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Природната инференција на јазикот (NLI) бара модели за учење и примена на заедничко знаење. Овие размислувачки способности се особено важни за објаснливите системи на НЛИ кои генерираат природно објаснување на јазикот покрај нивните предвидувања на етикетата. Интеграцијата на надворешното знаење покажа дека ќе ги подобри системите на НЛИ, тука истражуваме дали тоа може, исто така, да ги подобри нивните објаснувачки способности. For this, we investigate different sources of external knowledge and evaluate the performance of our models on in-domain data as well as on special transfer datasets that are designed to assess fine-grained reasoning capabilities. Најдовме дека различните извори на знаење имаат различен ефект на размислувачките способности, на пример, имплицитното знаење складирано во јазичките модели може да го попречи размислувањето на броевите и негативите. Конечно, досега ја спроведуваме најголемата и најубавата објаснлива студија на НЛИ за пулсорсирање. Истата открива дека дури и големите разлики во автоматските резултати не одразуваат ниту во човечките рејтинзи на етикетата, објаснувањето, заедничката ниту граматичната коректност.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>സ്വാഭാവികമായ ഭാഷ അപരിഹാരം ആവശ്യപ്പെടുന്നു. കമോണ്‍സണ്‍സെന്‍സ് അറിവ് പഠിക്കുകയും പ്രയോഗിക്കുകയും ചെയ്യാ ഈ കാരണങ്ങളുടെ കഴിവുകള്‍ വ്യക്തമാക്കാന്‍ കഴിയുന്ന NLI സിസ്റ്റമുകള്‍ക്ക് പ്രധാനപ്പെട്ടതാണ്. അവയുടെ ലേബിള്‍ പ്രവചനങ്ങള്‍ക് പുറത്തുള്ള അറിവുകളുടെ കൂട്ടത്തില്‍ NLI സിസ്റ്റം മെച്ചപ്പെടുത്തുന്നതിനായി കാണിച്ചിരിക്കുന്നു. ഇവിടെ നമ്മള്‍ അന് ഇതിനുവേണ്ടി ഞങ്ങള്‍ പുറത്തുള്ള അറിവുകളുടെ വ്യത്യസ്ത സ്രോതസ്സുകള്‍ അന്വേഷിക്കുകയും, നമ്മുടെ മോഡലുകളുടെ പ്രഭാവം ഡോമെയിന്‍ ഡേറ്റാകളുടെ പ്രഭാവം വി വ്യത്യസ്ത അറിവുകളുടെ സ്രോതസ്സുകള്‍ക്ക് വ്യത്യസ്ത പ്രഭാവം ഉണ്ടെന്ന് ഞങ്ങള്‍ കണ്ടെത്തുന്നു. ഉദാഹരണത്തിനായി ഭാഷ മോഡലില്‍ സൂക്ഷ അവസാനം, നമ്മള്‍ ഏറ്റവും വലിയ കിട്ടിയിട്ടുള്ള ഏറ്റവും സുന്ദരിയായിട്ടുള്ള ഏറ്റവും നല്ല കാര്യങ്ങള്‍ പ്രവര്‍ത്തിക്കുന സ്വയം പ്രവര്‍ത്തിപ്പിക്കുന്ന സ്കോര്‍സില്‍ വലിയ വ്യത്യാസങ്ങള്‍ പോലും മനുഷ്യരുടെ ലേബ്ലെറ്റിന്‍റെയും വിശദീകരണങ്ങള്‍, കമോണ്‍സണ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Байгалийн хэл халдвар (NLI) нь ерөнхий мэдрэмжтэй мэдлэг сурах, ашиглах загваруудыг шаарддаг. Эдгээр ойлголтын чадварууд нь ихэвчлэн хамгийн чухал NLI системүүдэд байгалийн хэл тодорхойлолт бий болгодог. Гадаан мэдлэгийн нэгтгэл нь NLI системийг сайжруулахын тулд харагдсан. Энд бид түүний тайлбарлалтын чадварыг сайжруулж чадах эсэхийг судалж байна. Үүний тулд бид гадаад мэдлэгийн өөр өөр эх үүсвэрүүдийг судалж, дотоод өгөгдлийн загварын үйл ажиллагааг үнэлэх боломжтой. Мөн өөр өөр шилжүүлэлтийн өгөгдлийн сангуудыг үнэлэх зорилготой. Бид өөр өөр мэдлэгийн эх үүсвэрүүд нь ойлголтын чадвар дээр өөр нөлөөтэй, жишээ нь хэл загваруудад хадгалагдсан үндсэн мэдлэг нь тоо болон сөрөг талаар бодохыг зогсоож чадна. Эцэст нь бид НЛИ-ын олон нийтийн хүмүүсийн асуудлын судалгааг хүртэл хамгийн том, хамгийн сайхан тарианы судалгаа хийсэн. Энэ нь автоматик үйлдвэрлэлийн оноо дээр маш их ялгаа ч хүн төрөлхтний загвар, тодорхойлолт, ерөнхий ойлголт, грамматик зөв байдлыг харуулж чадахгүй.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Keputusan bahasa semulajadi (NLI) memerlukan model untuk belajar dan melaksanakan pengetahuan umum. These reasoning abilities are particularly important for explainable NLI systems that generate a natural language explanation in addition to their label prediction. Penyempurnaan pengetahuan luaran telah menunjukkan untuk meningkatkan sistem NLI, di sini kita menyelidiki sama ada ia juga boleh meningkatkan kemampuan penjelasan mereka. Untuk ini, kami menyelidiki sumber-sumber pengetahuan luaran yang berbeza dan mengevaluasi prestasi model kami pada data dalam domain serta pada set data pemindahan khas yang direka untuk mengevaluasi kemampuan pemakaian yang sempurna. Kami mendapati bahawa sumber pengetahuan berbeza mempunyai kesan yang berbeza pada kemampuan reasoning, misalnya, pengetahuan implicit yang disimpan dalam model bahasa boleh menghalang reasoning pada nombor dan negatif. Akhirnya, kami melakukan penelitian crowdsourcing NLI yang paling besar dan paling baik yang boleh dijelaskan sehingga kini. Ia mengungkapkan bahawa walaupun perbezaan besar dalam skor prestasi automatik tidak mencerminkan dalam nilai manusia label, penjelasan, umum atau kebijaksanaan grammar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>L-inferenza lingwistika naturali (NLI) teħtieġ mudelli biex jitgħallmu u japplikaw għarfien komuni. Dawn l-abbiltajiet ta’ raġunament huma partikolarment importanti għal sistemi NLI li jistgħu jiġu spjegati li jiġġeneraw spjegazzjoni tal-lingwa naturali minbarra t-tbassir tat-tikketta tagħhom. Intwera li l-integrazzjoni tal-għarfien estern ittejjeb is-sistemi NLI, hawnhekk ninvestigaw jekk tistax ittejjeb ukoll il-kapaċitajiet ta’ spjegazzjoni tagħhom. Għal dan, ninvestigaw sorsi differenti ta’ għarfien estern u ninvestigaw il-prestazzjoni tal-mudelli tagħna fuq id-dejta fid-dominju kif ukoll fuq settijiet ta’ dejta speċjali ta’ trasferiment li huma mfassla biex jivvalutaw il-kapaċitajiet ta’ raġunament imfassla fin. Issibu li sorsi differenti ta’ għarfien għandhom effett differenti fuq il-ħiliet ta’ raġunament, pereżempju, għarfien impliċitu maħżun fil-mudelli lingwistiċi jista’ jfixkel ir-raġunament fuq in-numri u n-negazzjonijiet. Fl-aħħar nett, sal-lum qed nagħmlu l-akbar u l-aktar studju spjegabbli tal-crowdsourcing NLI. Jiżvela li anki differenzi kbar fil-punteġġi awtomatiċi tal-prestazzjoni la jirriflettu fil-klassifikazzjonijiet umani tat-tikketta, l-ispjegazzjoni, il-kunsens komuni u lanqas il-korrettezza grammarja.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Natural language inference (NLI) vereist modellen om gezond verstand te leren en toe te passen. Deze redeneringsvaardigheden zijn vooral belangrijk voor uitlegbare NLI-systemen die naast hun labelvoorspelling ook een natuurlijke taalverklaring genereren. De integratie van externe kennis is aangetoond om NLI-systemen te verbeteren, hier onderzoeken we of het ook hun verklaringsmogelijkheden kan verbeteren. Hiervoor onderzoeken we verschillende bronnen van externe kennis en evalueren we de prestaties van onze modellen op in-domain data en op speciale transfer datasets die zijn ontworpen om fijngranige redeneermogelijkheden te beoordelen. We vinden dat verschillende bronnen van kennis een ander effect hebben op redeneringsvermogen, bijvoorbeeld impliciete kennis opgeslagen in taalmodellen kan redeneren over getallen en ontkenningen belemmeren. Tot slot voeren we de grootste en meest fijngranige uitlegbare NLI crowdsourcing studie uit tot nu toe. Het toont aan dat zelfs grote verschillen in automatische prestatiescores geen weerspiegeling zijn in menselijke beoordelingen van label, uitleg, gezond verstand of grammatica correctheid.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Naturspråk-infeksjon (NLI) krev modeller for å læra og bruka vanleg kunnskap. Desse grunnleggjande kapasitetene er spesielt viktige for forklarbare NLI-systemer som lagar eit naturleg språk-forklaring i tillegg til merkelappen sin forhåndsvising. Integreringen av eksterne kunnskap er vist for å forbetra NLI-systemet. Her er vi undersøk om det også kan forbetra utklaringskapasiteten sine. For dette, vi undersøker ulike kjelde for eksterne kunnskap og evaluerer utviklinga av våre modeller på interne domenedata, og på spesielle overføringsdata som er utforma for å vurdere fin-kornerte redensingskapasiteten. Vi finn at forskjellige kjelde av kunnskap har ein annan effekt på rasjonskobilitetar, for eksempel, implisitt kunnskap lagra i språk-modeller kan hindra rasjon på tall og negasjon. Etter slutt, vi gjer den største og mest fyrste forklarbare NLI crowdsourcing studien til dag. Det viser at sjølv store forskjeller i automatiske funksjonspoeng ikkje reflekterer i menneskelige retningar av etikett, forklaring, fellesskap eller gramatisk rettighet.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Inferencja języka naturalnego (NLI) wymaga modeli do nauki i stosowania wiedzy zdrowego rozsądku. Te zdolności rozumowania są szczególnie ważne dla wyjaśnionych systemów NLI, które generują wyjaśnienie języka naturalnego oprócz przewidywania etykiety. Wykazano, że integracja wiedzy zewnętrznej poprawia systemy NLI, tutaj badamy, czy może ona również poprawić ich możliwości wyjaśniania. W tym celu badamy różne źródła wiedzy zewnętrznej i oceniamy wydajność naszych modeli na danych wewnątrz domeny, jak również na specjalnych zbiorach danych transferowych, które mają na celu ocenę możliwości precyzyjnego rozumowania. Odkrywamy, że różne źródła wiedzy mają różny wpływ na zdolności rozumowania, na przykład wiedza domniemana przechowywana w modelach językowych może utrudniać rozumowanie liczb i negacji. Wreszcie prowadzimy do tej pory największe i najbardziej precyzyjne badanie crowdsourcingu NLI. Ujawnia ona, że nawet duże różnice w automatycznych wynikach wydajności nie odzwierciedlają ludzkiej oceny etykiety, wyjaśnienia, zdrowego rozsądku czy poprawności gramatycznej.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A inferência de linguagem natural (NLI) requer modelos para aprender e aplicar o conhecimento do senso comum. Essas habilidades de raciocínio são particularmente importantes para sistemas NLI explicáveis que geram uma explicação em linguagem natural além de sua previsão de rótulo. A integração do conhecimento externo mostrou melhorar os sistemas NLI, aqui investigamos se também pode melhorar suas capacidades de explicação. Para isso, investigamos diferentes fontes de conhecimento externo e avaliamos o desempenho de nossos modelos em dados no domínio, bem como em conjuntos de dados de transferência especiais projetados para avaliar recursos de raciocínio refinado. Descobrimos que diferentes fontes de conhecimento têm um efeito diferente nas habilidades de raciocínio, por exemplo, o conhecimento implícito armazenado em modelos de linguagem pode dificultar o raciocínio sobre números e negações. Por fim, realizamos o maior e mais detalhado estudo de crowdsourcing NLI explicável até o momento. Ele revela que mesmo grandes diferenças nas pontuações de desempenho automático não refletem nas classificações humanas de rótulo, explicação, senso comum ou correção gramatical.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Inferența limbajului natural (NLI) necesită modele pentru a învăța și aplica cunoștințele de bun simț. Aceste abilități de raționament sunt deosebit de importante pentru sistemele NLI explicabile care generează o explicație de limbaj natural în plus față de predicția etichetei lor. Integrarea cunoștințelor externe a demonstrat că îmbunătățește sistemele NLI, aici investigăm dacă poate îmbunătăți și capacitățile lor de explicare. În acest scop, investigăm diferite surse de cunoștințe externe și evaluăm performanța modelelor noastre pe date în domeniu, precum și pe seturi de date speciale de transfer, concepute pentru a evalua capacitățile de raționament fină. Considerăm că diferitele surse de cunoaștere au un efect diferit asupra abilităților de raționament, de exemplu, cunoștințele implicite stocate în modele lingvistice pot împiedica raționamentul asupra numerelor și negațiilor. În cele din urmă, efectuăm cel mai mare și cel mai fin studiu de crowdsourcing explicabil NLI până în prezent. Aceasta dezvăluie că chiar și diferențele mari în scorurile automate de performanță nu reflectă în evaluările umane de etichetă, explicație, sens comun sau corectitudine gramaticală.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Вывод о естественном языке (NLI) требует, чтобы модели изучали и применяли знания здравого смысла. Эти способности рассуждения особенно важны для объяснимых систем NLI, которые генерируют объяснение естественного языка в дополнение к их предсказанию метки. Интеграция внешних знаний, как было показано, улучшает системы NLI, здесь мы исследуем, может ли она также улучшить их возможности объяснения. Для этого мы исследуем различные источники внешних знаний и оцениваем эффективность наших моделей на основе внутридоменных данных, а также на основе специальных наборов данных о переносе, которые предназначены для оценки возможностей мелкозернистого мышления. Мы обнаружили, что разные источники знаний по-разному влияют на способности к рассуждению, например, скрытые знания, хранящиеся в языковых моделях, могут препятствовать рассуждению о цифрах и отрицаниях. Наконец, мы проводим крупнейшее и наиболее мелкомасштабное объяснимое на сегодняшний день исследование краудсорсинга NLI. Это показывает, что даже большие различия в автоматических оценках производительности не отражаются ни на человеческих оценках этикетки, объяснения, здравого смысла, ни на правильности грамматики.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ස්වභාවික භාෂාව ප්‍රමාණය (NLI) අවශ්‍ය වෙනවා සාමාන්‍ය භාෂාවික දැනගන්න සහ අවශ්‍ය වෙන් මේ හේතුවක් ප්‍රශ්නයක් විශේෂයෙන් වැදගත් NLI පද්ධතියක් විස්තර කරන්න පුළුවන් විදිහට වැදගත් වෙනවා ඔවුන් පුරුද්ගලික දන්නවගේ සම්බන්ධයක් පෙන්වන්න පුළුවන් NLI පද්ධතිය වැඩ කරන්න, මෙතන අපි පරීක්ෂණය කරන්න පුළුවන් ක මේක සඳහා අපි ප්‍රතිශේෂ විවිධ දැනයේ වෙනස් ප්‍රතිශ්නයක් පරීක්ෂා කරනවා සහ අපේ මොඩේල්ස් ගැන ප්‍රතිශේෂ දත්ත සඳහා විශේෂ සං අපිට හොයාගන්න පුළුවන් වෙනස් දැනගන්න ප්‍රශ්නයක් තියෙනවා කියලා, උදාහරණයෙන්, භාෂා මොඩල් වල සංකේතයෙන් තියෙන අ අන්තිමේදි, අපි ලොකුම සහ හොඳම ප්‍රශ්නයක් කරනවා නිලි ජාතික විස්තර කරන්න පුළුවන් ප්‍රශ්නයක් තියෙන ඒක ප්‍රකාශ කරන්නේ ස්වයංක්‍රියාත්මක ක්‍රියාත්මක ක්‍රියාත්මක වෙනස් වගේම මිනිස්සුන්ගේ රේටින්ස් වලින් ප්‍රතිකා</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Sklepanje naravnega jezika (NLI) zahteva modele za učenje in uporabo splošnega smisla znanja. Te sposobnosti razmišljanja so še posebej pomembne za pojasnljive sisteme NLI, ki poleg napovedi oznake ustvarjajo razlago naravnega jezika. Pokazalo se je, da integracija zunanjega znanja izboljšuje sisteme NLI, tukaj pa raziskujemo, ali lahko izboljša tudi njihove razlage. V ta namen raziskujemo različne vire zunanjega znanja in ocenjujemo učinkovitost naših modelov na domenskih podatkih in na posebnih naborih prenosov podatkov, ki so zasnovani za ocenjevanje drobnozrnatih sposobnosti razmišljanja. Ugotavljamo, da različni viri znanja različno vplivajo na sposobnosti razmišljanja, npr. implicitno znanje, shranjeno v jezikovnih modelih, lahko ovira razmišljanje o številih in zanikah. Na koncu izvajamo največjo in najbolj natančno razložljivo študijo množičnega nabora NLI doslej. Razkriva, da tudi velike razlike v avtomatskih ocenah uspešnosti ne odražajo niti v ocenah oznake, razlage, splošnega smisla niti slovnične pravilnosti.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Cudurka afka asalka ah (NLI) wuxuu u baahan yahay qaabab barashada iyo codsashada aqoonta shirkadda. Aqooyinkan sababta ah si gaar ah waa muhiim u ah nidaamka NLI ee aan la caddeyn karin, taas oo soo saara fasirada afka dabiicadda ah, iyadoo aan laguu sii sheegin calaamada. La-qabsashada aqoonta dibadda waxaa lagu muujiyey in la kordhiyo nidaamka NLI, halkan waxaynu baaraynaa inay kordhin karto awoodooda turjumista. Taas darteed waxaynu baaraynaa noocyo kala duduwan aqoonta dibadda ah iyo waxaynu qiimeynaynaa sameynta sameynta modellka macluumaadka gudaha iyo sawirada macluumaadka gaarka ah oo loo qoray si aan u qiimeyno awoodaha garashada. Waxaynu aragnaa in noocyada aqoonta kala duduwan ay saameyn u leeyihiin waxyaabo kala duduwan, tusaale ahaan aqoonta ku saabsan noocyada luuqada lagu kaydiyey waxay ka hor mari karaan arrimaha ku saabsan lambarada iyo waxyaabaha la naco. Ugu dambaysta, waxaynu sameynaa waxbarashada kooxaha dadka NLI ee ugu waaweyn ee ugu fiican. Waxay muuqataa in xittaa kala duwanaanshaha badan oo ay iskuulaadka farsamada iskuulka ah ku jiraan kuma fikiraan qiyaastii dadka, fasax, faqan ama hagaajinta qofka.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Përfundimi natyror i gjuhës (NLI) kërkon modele për të mësuar dhe aplikuar njohuri të përbashkët. Këto aftësi arsyetimi janë veçanërisht të rëndësishme për sistemet e shpjeguara të NLI që gjenerojnë një shpjegim natyror gjuhës përveç parashikimit të etiketës së tyre. Integrimi i njohurive të jashtme është treguar për të përmirësuar sistemet NLI, këtu ne hetojmë nëse mund të përmirësojë gjithashtu aftësitë e tyre të shpjegimit. Për këtë, ne hetojmë burime të ndryshme të njohurive të jashtme dhe vlerësojmë performancën e modeleve tona në të dhënat në domeni si dhe në grupe të dhënash të posaçme transferimi që janë dizajnuar për të vlerësuar aftësitë e arsyetimit të hollësishëm. We find that different sources of knowledge have a different effect on reasoning abilities, for example, implicit knowledge stored in language models can hinder reasoning on numbers and negations. Më në fund, ne kryejmë studimin më të madh dhe më të hollë të shpjeguar të NLI crowdsourcing deri tani. Ajo zbulon se edhe dallime të mëdha në rezultatet e performancës automatike nuk pasqyrojnë as në vlerësimet njerëzore të etiketës, shpjegimit, të zakonshme as korrektësisë gramatike.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Prirodna jezička infekcija (NLI) zahteva modele za naučenje i primjenu znanja zajedničkog smisla. Ove razumne sposobnosti su posebno važne za objašnjavajuće NLI sisteme koje stvaraju prirodno objašnjenje jezika u dodatnom predviđanju etiketa. Integracija vanjskih znanja je pokazala kako bi poboljšala NLI sisteme, ovde istražujemo da li može i poboljšati njihove mogućnosti objašnjenja. Za to istražujemo različite izvore vanjskog znanja i procjenjujemo učinkovitost naših modela na podacima u domenu, kao i na specijalne sete podataka koji su dizajnirani za procjenu kvalitetnih razumnih mogućnosti. Nalazimo da različiti izvori znanja imaju različit uticaj na razumne sposobnosti, na primer, implicitno znanje koje se čuvaju u jezičkim modelima može spriječiti razumljivanje na brojeve i negacije. Konačno, provedem najveću i najbolje objašnjavajuću studiju NLI za crowdsourcing do sada. To otkriva da čak i velike razlike u automatskim rezultatima uspeha ne odražavaju ni u ljudskim ocjenama etikete, objašnjenja, čestitosti niti gramatičke ispravnosti.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Naturligt språk inferens (NLI) kräver modeller för att lära sig och tillämpa allmännyttig kunskap. Dessa resonemang förmågor är särskilt viktiga för förklaringsbara NLI-system som genererar en naturlig språkförklaring utöver deras etikettprediktion. Integrationen av extern kunskap har visat sig förbättra NLI-system, här undersöker vi om det också kan förbättra deras förklaringsförmåga. För detta undersöker vi olika källor till extern kunskap och utvärderar prestandan hos våra modeller på domändata samt på speciella överföringsdatauppsättningar som är utformade för att bedöma finkorniga resonemang. Vi finner att olika kunskapskällor har en annan effekt på resonemang förmågor, till exempel implicit kunskap lagrad i språkmodeller kan hindra resonemang om siffror och negationer. Slutligen genomför vi den största och mest finkorniga förklaringsbara NLI crowdsourcingsstudien hittills. Det avslöjar att även stora skillnader i automatiska prestationspoäng varken återspeglar mänskliga bedömningar av etikett, förklaring, allmänst eller grammatik korrekthet.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Upunguzo wa lugha ya asili (NLI) unahitaji mifano ya kujifunza na kutumia maarifa ya umma. Tamko hizi zinazoelezea ni muhimu kwa mfumo wa NLI unaotengeneza maelezo ya lugha asili zaidi ya utabiri wao wa alama. Ushirikiano wa maarifa ya nje umeonyesha kuboresha mifumo ya NLI, hapa tunachunguza kama inaweza pia kuboresha uwezo wa maelezo yao. Kwa hili, tunachunguza vyanzo tofauti vya ufahamu wa nje na kutathmini ufanisi wa mifano yetu kwenye data za ndani pamoja na kwenye seti maalum za usafirishaji ambazo zinalengwa kutathmini uwezo wa kufikiriwa vizuri. Tunapata kwamba vyanzo tofauti vya maarifa vina athari tofauti juu ya uwezo wa kuzingatia, kwa mfano, maarifa yaliyohifadhiwa katika mifano ya lugha yanaweza kuzuia mawazo kuhusu idadi na hasi. Mwisho, tunafanya utafiti mkubwa zaidi na wenye ufafanuzi mkubwa zaidi wa vyama vya habari vya NLI mpaka sasa. Inaonyesha kwamba hata tofauti kubwa katika vipimo vya utendaji vya kujitegemea hazitafakari katika viwango vya kibinadamu vya alama, maelezo, makubaliano wala sahihi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>இயல்பான மொழி குறைவு (NLI) தொழில்நுட்ப அறிவை கற்று பயன்படுத்த மாதிரிகள் தேவைப்படுகிறது. இந்த காரணங்கள் விளக்கமுடியாத NLI அமைப்புகளுக்கு குறிப்பாக முக்கியமானது. அது ஒரு இயல்பான மொழி விளக்கம் உருவாக்குகிறது வெளி அறிவின் ஒன்றிணைப்பு NLI முறைமைகளை மேம்படுத்துவதற்கு காண்பிக்கப்பட்டுள்ளது, இது அவர்களுடைய விளக்கங்களின் இயல்புகளை இதுக்கு, நாம் வெளி அறிவின் மூலங்களை ஆராய்ச்சி மற்றும் எங்கள் மாதிரிகளின் செயல்பாட்டை கண்டறிக்கிறோம் மற்றும் சிறப்பு மாற்றும் தகவல் அமைப்புகளில மொழி மாதிரிகளில் சேமிக்கப்பட்ட அறிவு மூலம் எண்கள் மற்றும் எதிர்மங்கள் பற்றி குறித்துக் கொள்ள வேறு விளைவுகள் இருக்கும் என்பதை நா இறுதியில், நாங்கள் பெரிய மற்றும் மிகவும் நல்ல பிரச்சனையான NLI மக்கள் மூல வளைவு பட்டியலை நடத்துகிறோம். அது தானியங்கி செய்யும் புள்ளிகளில் பெரிய வேறுபாடுகளுக்கு கூட தெளிவுபடுத்துகிறது விளக்கத்தின் விளக்கங்கள், விளக்கம</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tebiýal dil azalyşyk (NLI) duýdury bilgi öwrenmek we uygulamak üçin nusgalary gerek. Bu razylyk başaryşlary etiket öňünden boşluşyk bilen tebigy dili düşündirjek NLI sistemalary üçin has möhüm. Daşarydaky bilim üýtgetmegi NLI sistemalaryny geliştirmek üçin görkezildi. Şu ýerde biz munuň olaryň düşündirişi başarylygyny geliştirmegi mümkin edýändigini soradyk. Bu üçin biz daşarydaky bilim sistemleriniň farklı çeşmelerini inceleýäris we domençe maglumatlarymyzda modellerimiziň eserini deňleýäris we gowy gabat etmek üçin tasarlanýan aýratyn transfers veri setirlerini deňleýäris Bilim sistemleriniň farklı kaynaklarynyň düşünüp ukyplaryna üýtgeşik bar, meselâ, dil modellerinde gaýd edilen bilim sistemleri rakamlar we bölümlerde düşünüpden çykaryp biler. Soňunda biz iň uly we iň gowy görnümli NLI köpüşiklik isleýän ylgamy ýerine ýetirdik. Muny otomatik netijesinde hatda näçe üýtgeşmeler etiket, düşündirim, jemgyýetçilik we gramatik dogrylygynda täsirleýändirler.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>طبیعی زبان ایفارنس (NLI) کی مدل کی ضرورت ہے کہ معمولی علم کی تعلیم اور استعمال کریں۔ یہ منطقی قابلیت ان کے لیبل پیش بینی کے علاوہ ایک طبیعی زبان کی توضیح پیدا کرتی ہیں۔ بیرونی علم کی تعلیم NLI سیستموں کو بہتر کرنے کے لئے دکھائی گئی ہے، یہاں ہم تحقیق کرتے ہیں کہ یہ ان کی توضیح کے قابلیت بھی بہتر کر سکتا ہے. اس کے لئے ہم باہر علم کے مختلف سراسروں کی تحقیق کرتے ہیں اور ہمارے مدلکوں کے عملکرد کو دامین میں ڈیٹے پر مطالعہ کرتے ہیں اور ویسی ترنسیٹ ڈیٹ سٹ پر بھی مطالعہ کئے جاتے ہیں جو مطالعہ اندازے کے قابلیت کی آزمائش کے لئے طراحی ک ہمیں معلوم ہے کہ علم کے مختلف سرمالوں کے باعث منطقی قابلیت پر مختلف اثر ہے، مثال، زبان مدلکوں میں ذخیره ہوئی معلومات کی تعداد اور منطقی کے باعث منطقی کرسکتی ہے. آخر میں ہم نے سب سے بڑے اور بہترین دانے کا مفصل کر لیا ہے۔ یہ ظاہر کرتا ہے کہ اٹوٹیٹ کروٹ سکونٹوں میں بھی بہت بڑی اختلاف بھی نہیں کرتی لیبل، توضیح، معمولی اور گرامی اصلاح میں.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Natalik til infeksiyati (NLI) modellarni o'rganish va qoʻllash uchun kerak. Bu sabablar qobiliyatlari ularning yorliq oldini oldinga oddiy tilning forklarini yaratadigan NLI tizimlariga muhim. Tashqi ta'limning birlashtirish NLI tizimlarini yaxshi ko'rsatadi. Bu yerda biz ularning fikrlarining imkoniyatlarini bajarishi mumkin deb o'rganamiz. Bu uchun, biz tashqi ta'limning boshqa manbalarini qidirib, domen maʼlumotidagi modellarimizning natijasini qiymatimiz, va xavfsiz tarkib maʼlumotlar tarkibida o'zgartirish qoidalarini qidirish uchun qo'llanmalar mumkin. Biz o'ylaymiz, boshqa ta'lim manbaslari haqida ma'lumotga ega bo'ladi. Masalan, tildagi modellarda saqlangan ilmo'zi sonlar va negativ haqida g'oyalarni o'zgartiradi. Endi biz hozirda eng katta va eng yaxshi ajoyib bo'lgan NLI jamoatlarni o'rganamiz. U avtomatik foydalanuvchi darajadagi katta ўзгаришларни ko'rsatadi, odamning qismlarini, faqat fasirlash, murakkab va grammatik toʻgʻri haqida o'ylamaydi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kết quả ngôn ngữ tự nhiên (NLI) đòi hỏi các mẫu học hỏi và áp dụng các kiến thức thông thường. Những khả năng lập luận này rất quan trọng với hệ thống NIL có thể giải thích ngôn ngữ tự nhiên, cùng với dự đoán nhãn hiệu của chúng. Sự hợp nhất của kiến thức bên ngoài đã được cho thấy nhằm cải thiện hệ thống NIL, tại đây chúng tôi đang tìm hiểu liệu nó có thể cải thiện khả năng giải thích của chúng. Chúng tôi nghiên cứu các nguồn kiến thức bên ngoài khác nhau và đánh giá khả năng làm việc của các mẫu trên dữ liệu nội bộ, cũng như các tập tin giao dịch đặc biệt được thiết kế để đánh giá các khả năng lập luận ổn định. Chúng tôi thấy những nguồn kiến thức khác nhau có ảnh hưởng khác nhau đến khả năng lập luận, ví dụ, kiến thức ngầm được cất giữ trong mô hình ngôn ngữ có thể gây trở ngại việc lập luận về con số và âm bản. Cuối cùng, chúng tôi tiến hành nghiên cứu tài nguyên cao nhất và được giải thích cao nhất. Nó tiết lộ rằng thậm chí sự khác nhau lớn trong tỉ số hiệu suất tự động cũng không phản ánh các đánh giá của nhân loại về nhãn hiệu, cách giải thích, lẽ thường hay sửa ngữ pháp.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>自然语言推理(NLI)求模形学用常识。 其于可解者NLI统尤要,非生成之外,犹生自然语言解。 外知之整合,已验可以改善NLI统,于此论其可以益其说。 故论外知之本,而论域内之数,及指评细粒度理能之殊传输数据集上。 臣等见异端,有异于推理,如言语模形隐性则碍数否之理。 最后迄今为止规模最大,最细粒度者可解NLI众包究。 明虽性能分数差异,不能见于人,说,常识语法正确性之评级也。</span></div></div><dl><dt>Anthology ID:</dt><dd>2021.blackboxnlp-1.3</dd><dt>Volume:</dt><dd><a href=/volumes/2021.blackboxnlp-1/>Proceedings of the Fourth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP</a></dd><dt>Month:</dt><dd>November</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Punta Cana, Dominican Republic</dd><dt>Venues:</dt><dd><a href=/venues/blackboxnlp/>BlackboxNLP</a>
| <a href=/venues/emnlp/>EMNLP</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>26–41</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.blackboxnlp-1.3>https://aclanthology.org/2021.blackboxnlp-1.3</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/2021.blackboxnlp-1.3 title="To the current version of the paper by DOI">10.18653/v1/2021.blackboxnlp-1.3</a></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">schuff-etal-2021-external</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Hendrik Schuff, Hsiu-Yu Yang, Heike Adel, and Ngoc Thang Vu. 2021. <a href=https://aclanthology.org/2021.blackboxnlp-1.3>Does External Knowledge Help Explainable Natural Language Inference? Automatic Evaluation vs. Human Ratings</a>. In <i>Proceedings of the Fourth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP</i>, pages 26–41, Punta Cana, Dominican Republic. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2021.blackboxnlp-1.3>Does External Knowledge Help Explainable Natural Language Inference? Automatic Evaluation vs. Human Ratings</a> (Schuff et al., BlackboxNLP 2021)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf>https://aclanthology.org/2021.blackboxnlp-1.3.pdf</a></dd><dt>Code</dt><dd><a href=https://github.com/boschresearch/external-knowledge-explainable-nli><i class="fab fa-github"></i>&nbsp;boschresearch/external-knowledge-explainable-nli</a></dd><dt>Data</dt><dd><a href=https://paperswithcode.com/dataset/conceptnet>ConceptNet</a>,&nbsp;<a href=https://paperswithcode.com/dataset/snli>SNLI</a>,&nbsp;<a href=https://paperswithcode.com/dataset/e-snli>e-SNLI</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2021.blackboxnlp-1.3.pdf title="Open PDF of 'Does External Knowledge Help Explainable Natural Language Inference? Automatic Evaluation vs. Human Ratings'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Does+External+Knowledge+Help+Explainable+Natural+Language+Inference%3F+Automatic+Evaluation+vs.+Human+Ratings" title="Search for 'Does External Knowledge Help Explainable Natural Language Inference? Automatic Evaluation vs. Human Ratings' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-secondary d-flex flex-wrap justify-content-center" href="https://paperswithcode.com/paper/?acl=2021.blackboxnlp-1.3" title="Code for 'Does External Knowledge Help Explainable Natural Language Inference? Automatic Evaluation vs. Human Ratings' on Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-big" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg><span class="pl-sm-2 d-none d-sm-inline">Code</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'Does External Knowledge Help Explainable Natural Language Inference? Automatic Evaluation vs. Human Ratings'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[Does External Knowledge Help Explainable Natural Language Inference? Automatic Evaluation vs. Human Ratings](https://aclanthology.org/2021.blackboxnlp-1.3) (Schuff et al., BlackboxNLP 2021)</p><ul class=mt-2><li><a href=https://aclanthology.org/2021.blackboxnlp-1.3>Does External Knowledge Help Explainable Natural Language Inference? Automatic Evaluation vs. Human Ratings</a> (Schuff et al., BlackboxNLP 2021)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Hendrik Schuff, Hsiu-Yu Yang, Heike Adel, and Ngoc Thang Vu. 2021. <a href=https://aclanthology.org/2021.blackboxnlp-1.3>Does External Knowledge Help Explainable Natural Language Inference? Automatic Evaluation vs. Human Ratings</a>. In <i>Proceedings of the Fourth BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP</i>, pages 26–41, Punta Cana, Dominican Republic. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>