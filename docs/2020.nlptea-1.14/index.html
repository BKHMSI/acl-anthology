<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Chinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared TaskChinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared Task - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="Chinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared TaskChinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared Task" name=citation_title><meta content="Hongying Zan" name=citation_author><meta content="Yangchao Han" name=citation_author><meta content="Haotian Huang" name=citation_author><meta content="Yingjie Yan" name=citation_author><meta content="Yuke Wang" name=citation_author><meta content="Yingjie Han" name=citation_author><meta content="Proceedings of the 6th Workshop on Natural Language Processing Techniques for Educational Applications" name=citation_conference_title><meta content="2020/12" name=citation_publication_date><meta content="https://aclanthology.org/2020.nlptea-1.14.pdf" name=citation_pdf_url><meta content="102" name=citation_firstpage><meta content="107" name=citation_lastpage><meta property="og:title" content="Chinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared TaskChinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared Task"><meta property="og:image" content="https://aclanthology.org/thumb/2020.nlptea-1.14.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2020.nlptea-1.14"><meta property="og:description" content="Hongying Zan, Yangchao Han, Haotian Huang, Yingjie Yan, Yuke Wang, Yingjie Han. Proceedings of the 6th Workshop on Natural Language Processing Techniques for Educational Applications. 2020."><link rel=canonical href=https://aclanthology.org/2020.nlptea-1.14></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2020.nlptea-1.14.pdf>Chinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared Task<span class=acl-fixed-case>C</span>hinese Grammatical Errors Diagnosis System Based on <span class=acl-fixed-case>BERT</span> at <span class=acl-fixed-case>NLPTEA</span>-2020 <span class=acl-fixed-case>CGED</span> Shared Task</a>
<a id=af_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Sjinese Gramatiese Foute Diagnosies Stelsel Gebaseer op BERT by NLPTEA- 2020 CGED Gedeelde Opdrag</a>
<a id=am_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Chinese Grammatical Error Diagnosis System Based on NLPTEA-2020 CGED Shared Task</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>نظام تشخيص الأخطاء النحوية الصيني المستند إلى BERT في المهمة المشتركة NLPTEA-2020 CGED</a>
<a id=az_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>NLPTEA-2020 CGED paylaşdırılmış Gözmə Based on BERT</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Система за диагностика на китайски граматични грешки въз основа на споделена задача</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>NLPTEA-2020 CGED ভাগাভাগি করা কাজের উপর ভিত্তিক চীনা গ্রামাটিক্যাল ত্রুটি ডিয়াগনিং সিস্টেম</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>རྒྱ་ནག་གི་Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared Task</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Kineski sistem za dijagnozu grešaka baziran na BERT na NLPTEA-2020 CGED zajedničkom zadatku</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Sistema de diagnòstic d'errors gramàtics xinès basat en BERT a NLPTEA-2020 CGED Shared Task</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Čínský systém diagnostiky gramatických chyb založený na BERT na NLPTEA-2020 CGED Shared Task</a>
<a id=da_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Kinesisk grammatiske fejldiagnosesystem baseret på BERT ved NLPTEA-2020 CGED delt opgave</a>
<a id=de_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Chinesisches Grammatikfehler-Diagnosesystem basierend auf BERT bei NLPTEA-2020 CGED Shared Task</a>
<a id=el_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Κινεζικό σύστημα διάγνωσης γραμματικών σφαλμάτων βασισμένο στο Κοινή Εργασία</a>
<a id=es_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Sistema de diagnóstico de errores gramaticales chinos basado en BERT en NLPTEA-2020 CGED Shared Task</a>
<a id=et_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Hiina grammatiliste vigade diagnostika süsteem, mis põhineb BERT-il NLPTEA-2020 CGED jagatud ülesanne</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>سیستم شناسایی خطاهای گرماتیک چینی بر اساس BERT در کار مشترک NLPTEA-2020</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Kiinan kielioppivirheiden diagnosointijärjestelmä perustuu BERT-järjestelmään NLPTEA-2020 CGED Shared Task -tapahtumassa</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Système de diagnostic des erreurs grammaticales chinoises basé sur le BERT lors de la tâche partagée NLPTEA-2020 CGED</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Córas Diagnóisithe Earráidí Gramadaí na Síne Bunaithe ar BERT ag Tasc Comhroinnte CGED NLPTEA-2020</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>KCharselect unicode block name</a>
<a id=he_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Chinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared Task</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>चीनी व्याकरणिक त्रुटियाँ निदान प्रणाली NLPTEA-2020 CGED साझा कार्य पर BERT पर आधारित</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Kineski sistem za dijagnozu grešaka baziran na BERT-u na NLPTEA-2020 CGED zajedničkom zadatku</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Kínai nyelvtani hibák diagnosztikai rendszere BERT alapján az NLPTEA-2020 CGED megosztott feladaton</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Չինաստանի գրամմատիկ սխալների ախտորոշման համակարգը, հիմնված BER-ի վրա, ՆԼՊՏԵԱ-2020 թվականի CGeD ընդհանուր հանձնարարության ժամանակ</a>
<a id=id_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Sistem Diagnosis Galat Grammatis Cina Berdasarkan BERT di NLPTEA-2020 CGED Shared Task</a>
<a id=is_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Sistema di diagnosi degli errori grammaticali cinesi basato su BERT al compito condiviso CGED NLPTEA-2020</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>NLPTEA -2020 CGED共有タスクでのBERTに基づく中国語文法エラー診断システム</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Chinese Graph Eror</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>QFontDatabase</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>NLPTEA- 2020 CGED ортақ тапсырмасына негізделген қытайша грамматикалық қателер диагнозы жүйесі</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>BERT 기반 NLPTEA-2020 CGED 공유 작업 중국어 문법 오류 진단 시스템</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Kinijos gramatinių klaidų diagnozavimo sistema, pagrįsta BERT NLPTEA-2020 CGED bendroje užduotyje</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Кинескиот систем за дијагностика на граматски грешки базиран на BERT на NLPTEA-2020 CGED споделена задача</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>NLPTEA- 2020 CGED പങ്കുചേര്‍ത്ത പണിയില്‍ BERT അടിസ്ഥാനമായി അടിസ്ഥാനമായി ചൈനീസ് ഗ്രാമാറ്റിക്കല്‍ പിശകുകള്‍</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>НLPTEA-2020 CGED хуваалтын ажил дээр BERT-д багтсан Хятад Грамматикийн алдаа</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Sistem Diagnosis Ralat Grammatik Cina Berdasarkan BERT pada Tugas Berkongsi NLPTEA-2020 CGED</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Sistema ta’ Dijanjożi ta’ Żbalji Grammatiċi Ċiniżi bbażata fuq BERT f’Kompitu Konġunt NLPTEA-2020 CGED</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Chinese grammaticale fouten diagnosesysteem gebaseerd op BERT bij NLPTEA-2020 CGED Gedeelde taak</a>
<a id=no_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Kinesisk Grammatiske feil Diagnosis System basert på BERT på NLPTEA-2020 CGED delt oppgåve</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Chiński system diagnostyki błędów gramatycznych oparty na BERT w NLPTEA-2020 CGED Shared Task</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Sistema de diagnóstico de erros gramaticais chinês com base no BERT na tarefa compartilhada NLPTEA-2020 CGED</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Sistemul de diagnosticare a erorilor gramaticale chinezești bazat pe BERT la activitatea partajată CGED NLPTEA-2020</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Китайская система диагностики грамматических ошибок на основе BERT на NLPTEA-2020 CGED Shared Task</a>
<a id=si_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>චීනි ග්‍රාම්ටික් වැරදිලි සංඥානය පද්ධතිය NLPTEA-2020දී පද්ධතිය</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Kitajski slovnični sistem diagnosticiranja napak na podlagi BERT na skupni nalogi NLPTEA-2020 CGED</a>
<a id=so_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Xiineeya dhibaatooyinka ku saabsan diagnosis System Based on BERT at NLPTEA-2020 CGED Shared Task</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Sistemi Kinez i Diagnozës së Gabimeve Gramatike Bazuar në BERT në NLPTEA-2020 CGED Task Shared</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Kineski sistem za dijagnozu grešaka baziran na BERT na NLPTEA-2020 CGED zajedničkom zadatku</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Kinesiskt grammatiska fel Diagnossystem baserat på BERT vid NLPTEA-2020 CGED delad uppgift</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Mfumo wa Uchaguzi wa Tamko wa Kichina umetokana na BERT kwenye kazi ya NLPTEA-2020 CGED</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Comment</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Grammatikal Hatalar</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>NLPTEA-2020 CGED Shared Task پر BERT پر بنیاد رکھی چینی گرامٹیکل تخطار</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Name</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>Hệ thống phân tích biểu đồ học của Trung Quốc</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2020.nlptea-1.14.pdf>盖BERT之汉语语法错误诊断系统在NLPTEA-2020 CGED共之</a></h2><p class=lead><a href=/people/h/hongying-zan/>Hongying Zan</a>,
<a href=/people/y/yangchao-han/>Yangchao Han</a>,
<a href=/people/h/haotian-huang/>Haotian Huang</a>,
<a href=/people/y/yingjie-yan/>Yingjie Yan</a>,
<a href=/people/y/yuke-wang/>Yuke Wang</a>,
<a href=/people/y/yingjie-han/>Yingjie Han</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In the process of learning <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>, <a href=https://en.wikipedia.org/wiki/Second-language_acquisition>second language learners</a> may have various <a href=https://en.wikipedia.org/wiki/Grammatical_error>grammatical errors</a> due to the negative transfer of native language. This paper describes our submission to the NLPTEA 2020 shared task on CGED. We present a <a href=https://en.wikipedia.org/wiki/Hybrid_system>hybrid system</a> that utilizes both detection and correction stages. The detection stage is a sequential labelling model based on BiLSTM-CRF and BERT contextual word representation. The correction stage is a hybrid model based on the <a href=https://en.wikipedia.org/wiki/N-gram>n-gram</a> and Seq2Seq. Without adding additional features and external data, the BERT contextual word representation can effectively improve the performance metrics of Chinese grammatical error detection and correction.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In die proses van die leer van Sjinese, tweede taal leerders mag verskeie grammatiese foute hê vanweë die negatiewe oordrag van die taal. Hierdie papier beskrywe ons onderskrywing aan die NLPTEA 2020 deel taak op CGED. Ons stel 'n hybrid stelsel wat gebruik word beide opdekking en korreksie stadige. Die opdekking stadium is 'n sekwensielle etiketting model gebaseer op BiLSTM- CRF en BERT konteksual woord voorsiening. Die korreksie stadium is 'n hibridmodel gebaseer op die n-gram en Seq2Seq. Sonder om addisionele funksies en eksterne data byvoeg te voeg, kan die BERT contextual woord verteenwoording effektief die prestasie metries van Sjinese grammatiese fout opdecking en korreksie verbeter.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ቻይና በተማሩ ክፍል፣ ሁለተኛው ቋንቋ ተማሪዎቹ በአገሪው ቋንቋ መዘዋወር ምክንያት የግራማዊ ስህተት ይኖራል፡፡ ይህ ገጽ በCGED ላይ 2020 የNLPTEA አካባቢነታችንን ይናገራል፡፡ የኬብሪድ ስርዓት እና ማስታወቂያውን እና ማስታወቂያውን የሚጠቀም ነው፡፡ በቢLSTM-CRF እና BERT በተገኘ ቃላት መልዕክት ላይ የተመሳሳይ የጽሑፍ ሞዴል ነው፡፡ የ-ግራም እና Seq2Seq የተመሠረተ የኬብሪድ ሞዴል ነው፡፡ ባይጨመር ምርጫዎች እና ውጭ ዳታ ባይጨመር፣ የBERT የአሁኑን ቃል መልዕክት የቻይና የግራማሲካዊ ስህተት ማግኘት እና ማስተካከል ማድረግ ይችላል፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>في عملية تعلم اللغة الصينية ، قد يكون لمتعلمي اللغة الثانية أخطاء نحوية مختلفة بسبب النقل السلبي للغة الأم. تصف هذه الورقة تقديمنا إلى المهمة المشتركة لـ NLPTEA 2020 على CGED. نقدم نظامًا هجينًا يستخدم كل من مرحلتي الكشف والتصحيح. مرحلة الاكتشاف عبارة عن نموذج تصنيف متسلسل يعتمد على تمثيل الكلمات السياقية BiLSTM-CRF و BERT. مرحلة التصحيح عبارة عن نموذج هجين يعتمد على n-gram و Seq2Seq. بدون إضافة ميزات وبيانات خارجية إضافية ، يمكن لتمثيل الكلمات السياقية BERT تحسين مقاييس أداء اكتشاف الأخطاء النحوية الصينية وتصحيحها بشكل فعال.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Çinli dilləri öyrənmək üçün ikinci dil öyrənənənçilərin yerli dillərin negatif tərəfindən müxtəlif qrammatik xətaları olar. Bu kağıt bizim NLPTEA 2020 CGED barəsində paylaşdığımız işləri tarif edir. Biz hər ikisini tanıma və düzəltmə fərqlərini istifadə edən hibrid sistemini göstəririk. İnternet sahəsi BiLSTM-CRF və BERT müxtəlif söz göstəricisinə dayanan sıralar etiketləmə modelidir. Düzeltme sahəsi n-gram və Seq2Seq üzərində dayanan hibrid modelidir. Əlavə fərqli və dış məlumatları əlavə etmədən, BERT müxtəlif sözlərin göstəricisi Çin qrammatik xətaların keşfini və düzəltməsini etkili olaraq daha yaxşılaşdıra bilər.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>В процеса на изучаване на китайски, обучаващите се на втори език могат да имат различни граматически грешки поради отрицателния трансфер на родния език. Настоящата статия описва нашето представяне на споделената задача на НЛПТЕА 2020 по ЦЕД. Представяме хибридна система, която използва както етапите на откриване, така и на корекция. Етапът на откриване е модел на последователно етикетиране, базиран на контекстното представяне на думи. Етапът на корекция е хибриден модел, базиран на n-грама и Seq2Seq. Без добавяне на допълнителни функции и външни данни, контекстното представяне на думи може ефективно да подобри показателите за ефективност на откриването и корекцията на китайската граматична грешка.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>চীনা শিক্ষা প্রক্রিয়ায় দ্বিতীয় ভাষা শিক্ষার্থীদের স্থানীয় ভাষার নেতিবাচক পরিবর্তনের কারণে বিভিন্ন গ্রামাট এই পত্রিকাটি সিজেডিতে আমাদের এনএলপিটেয়া ২০২০ সালের প্রতি আমাদের প্রতিষ্ঠান বর্ণনা করেছে। আমরা একটা হাইব্রিড সিস্টেম উপস্থাপন করছি যা আবিষ্কার এবং সংস্কারের মাধ্যমে ব্যবহার করে। বিএলস্টিএম-CRF এবং বিবের্টি প্রতিনিধিত্বের উপর ভিত্তিক একটি পরবর্তী লেবেলিং মডেল। ন-গ্রাম এবং সেক২সেকের উপর ভিত্তিক একটি হাইব্রিড মডেল। অতিরিক্ত বৈশিষ্ট্য এবং বাইরের তথ্য যোগ করা ছাড়াই বিবেরেটি প্রতিনিধিত্ব বিভিন্ন শব্দের প্রতিনিধিত্বে চীনা গ্রাম্যাটিক্যাল ত্র</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>རྒྱ་ནག་གི་སློབ་བརྗོད་ཀྱི་ལས་སྦྱོར་ནང་ན་སྐད་རིགས་ཤེས་པ་གཉིས་ཀྱི་ནང་དུ་ནོར ཤོག་བྱང་འདིས་ང་ཚོའི་རྗེས་སུ་NLPTEA 2020་ལ་མཉམ་དུ་གཏོང་གི་བྱ་རིམ་CGED་དུ་བཤད་པ ང་ཚོས་རྟོགས་དང་བདེ་འཇགས་ཀྱི་ཆེན་གཉིས་ལས་སྤྱོད་པའི་ཆ་རྐྱེན་གྱི་མ་ལག་གི་སྟོན་པ་ཞིག་འཆར་ཡོད། The detection stage is a sequential labelling model based on BiLSTM-CRF and BERT contextual word representation. The correction stage is a hybrid model based on the n-gram and Seq2Seq. Without adding additional features and external data, the BERT contextual word representation can effectively improve the performance metrics of Chinese grammatical error detection and correction.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>U procesu učenja kineskog jezika, učitelji drugih jezika mogu imati različite gramatične greške zbog negativnog prenošenja jezika. Ovaj papir opisuje našu predanost podijeljenom zadatku NLPTEA 2020 o CGED-u. Predstavljamo hibridni sistem koji koristi detektive i korekcije. Stadija otkrivanja je sekvencijski model označavanja na temelju BiLSTM-CRF i BERT kontekstualne riječi. Korekcija je hibridni model baziran n a n-gramu i Seq2Seq. Bez dodavanja dodatnih karakteristika i vanjskih podataka, predstavljanje BERT-a kontekstualne riječi može učinkovito poboljšati metriku učinkovitosti kineskog gramatičkog otkrivanja i isprave grešaka.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In the process of learning Chinese, second language learners may have various grammatical errors due to the negative transfer of native language. Aquest paper descriu la nostra presentació a la tasca compartida NLPTEA 2020 sobre CGED. Presentam un sistema híbrid que utilitza les etapes de detecció i correcció. L'etapa de detecció és un model d'etiquetage seqüencial basat en la representació contextual de paraules BiLSTM-CRF i BERT. L'etapa de correcció és un model híbrid basat en n-gram i Seq2Seq. Sense afegir característiques adicionals i dades externes, la representació contextual de paraules BERT pot millorar efectivament les mètriques de rendiment de la detecció i correcció d'errors gramàtics xinesos.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Během výuky čínštiny mohou studenti druhého jazyka mít různé gramatické chyby v důsledku negativního přenosu rodného jazyka. Tento článek popisuje náš předložení sdíleného úkolu NLPTEA 2020 na CGED. Představujeme hybridní systém, který využívá jak detekční, tak korekční fáze. Detekční fáze je sekvenční model značení založený na kontextové reprezentaci slov BiLSTM-CRF a BERT. Korekční fáze je hybridní model založený na n-gramu a Seq2Seq. Bez přidávání dalších funkcí a externích dat může kontextová reprezentace slov BERT efektivně zlepšit výkonnostní metriky čínské gramatické chyby detekce a opravy.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>I processen med at lære kinesisk, andetsprogslærere kan have forskellige grammatiske fejl på grund af den negative overførsel af modersmål. Denne artikel beskriver vores indsendelse til NLPTEA 2020 delte opgave på CGED. Vi præsenterer et hybridsystem, der bruger både detektions- og korrektionsstadier. Detektionsfasen er en sekventiel mærkningsmodel baseret på BiLSTM-CRF og BERT kontekstuel ordrepræsentation. Korrektionsfasen er en hybridmodel baseret på n-grammet og Seq2Seq. Uden at tilføje yderligere funktioner og eksterne data kan BERT's kontekstuelle ordrepræsentation effektivt forbedre ydelsesmålingerne for registrering og korrektion af kinesisk grammatisk fejl.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Während des Lernens von Chinesisch können Zweitsprachenlerner aufgrund des negativen Transfers der Muttersprache verschiedene grammatikalische Fehler haben. Dieses Papier beschreibt unsere Einreichung zur gemeinsamen Aufgabe NLPTEA 2020 auf CGED. Wir präsentieren ein Hybridsystem, das sowohl Detektions- als auch Korrekturstufen nutzt. Die Erkennungsstufe ist ein sequentielles Beschriftungsmodell basierend auf BiLSTM-CRF und BERT kontextueller Wortdarstellung. Die Korrekturstufe ist ein Hybridmodell basierend auf dem n-Gramm und Seq2Seq. Ohne zusätzliche Funktionen und externe Daten hinzuzufügen, kann die BERT kontextbezogene Wortdarstellung die Leistungskennzahlen der chinesischen grammatischen Fehlererkennung und -korrektur effektiv verbessern.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Κατά τη διαδικασία εκμάθησης κινέζικων, οι μαθητές δεύτερης γλώσσας ενδέχεται να έχουν διάφορα γραμματικά λάθη λόγω της αρνητικής μεταφοράς της μητρικής γλώσσας. Η παρούσα εργασία περιγράφει την υποβολή μας στο κοινό έργο του NLPTEA 2020 για την CGED. Παρουσιάζουμε ένα υβριδικό σύστημα που χρησιμοποιεί τόσο τα στάδια ανίχνευσης όσο και διόρθωσης. Το στάδιο ανίχνευσης είναι ένα διαδοχικό μοντέλο επισήμανσης βασισμένο στην αναπαράσταση λέξεων BiLSTM-CRF και BERT. Το στάδιο διόρθωσης είναι ένα υβριδικό μοντέλο βασισμένο στο n-γραμμάριο και το Seq2Seq. Χωρίς προσθήκη πρόσθετων χαρακτηριστικών και εξωτερικών δεδομένων, η απεικόνιση λέξεων στο πλαίσιο μπορεί αποτελεσματικά να βελτιώσει τις μετρήσεις απόδοσης της κινεζικής γραμματικής ανίχνευσης και διόρθωσης σφαλμάτων.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>En el proceso de aprendizaje del chino, los estudiantes de un segundo idioma pueden tener varios errores gramaticales debido a la transferencia negativa de la lengua materna. Este documento describe nuestra presentación a la tarea compartida de la NLPTEA 2020 sobre CGED. Presentamos un sistema híbrido que utiliza etapas de detección y corrección. La etapa de detección es un modelo de etiquetado secuencial basado en la representación de palabras contextuales BILSTM-CRF y BERT. La etapa de corrección es un modelo híbrido basado en n-gram y Seq2Seq. Sin añadir funciones adicionales ni datos externos, la representación contextual de palabras BERT puede mejorar eficazmente las métricas de rendimiento de la detección y corrección de errores gramaticales chinos.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Hiina keele õppimisel võivad teise keele õppijatel olla emakeele negatiivse ülekande tõttu erinevad grammatikavead. Käesolevas dokumendis kirjeldatakse meie esitamist NLPTEA 2020 jagatud ülesandele CGED. Esitleme hübriidsüsteemi, mis kasutab nii tuvastamise kui ka parandamise etappi. Avastamisetapp on järjestikuse märgistuse mudel, mis põhineb BiLSTM-CRF ja BERT kontekstipõhisel sõnaesitusel. Korrigeerimisetapp on hübriidmudel, mis põhineb n-grammil ja Seq2Seq-il. Täiendavaid funktsioone ja välisandmeid lisamata saab BERT kontekstipõhine sõnaesitus tõhusalt parandada hiina grammatiliste vigade tuvastamise ja parandamise jõudlusnäitajaid.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>در فرایند یادگیری چینی، دانش‌آموزان دوم زبان ممکن است اشتباه‌های گرامیک مختلف داشته باشد به سبب انتقال منفی زبان مادری. این کاغذ تحویل ما به کار مشترک NLPTEA 2020 در CGED توصیف می‌کند. ما یک سیستم هیبرید را پیشنهاد می‌کنیم که از مرحله‌های شناسایی و اصلاح استفاده می‌کند. مرحله شناسایی یک مدل نقاشی دنباله بر اساس نمایش کلمات متوسط BiLSTM-CRF و BERT است. مرحله اصلاح یک مدل hybrid بر اساس n-gram و Seq2Seq است. بدون اضافه کردن ویژگی‌های اضافه و داده‌های خارجی، نمایش کلمه‌های متوسط BERT می‌تواند به طور تاثیر متریک عملکرد خطاهای گراماتیکی چینی را دریافت و درست کند.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Toisen kielen oppijoilla voi olla erilaisia kieliopillisia virheitä äidinkielen negatiivisen siirron vuoksi. Tässä artikkelissa kuvataan osallistumismme NLPTEA 2020:n yhteiseen tehtävään CGED:ssä. Esittelemme hybridijärjestelmän, joka hyödyntää sekä havaitsemis- että korjausvaihetta. Havaintovaihe on BiLSTM-CRF- ja BERT-kontekstuaaliseen sanaesitykseen perustuva perättäinen merkintämalli. Korjausvaihe on hybridimalli, joka perustuu n-grammiin ja Seq2Seq. Ilman lisäominaisuuksia ja ulkoista dataa BERT-kontekstuaalinen sanaesitys voi tehokkaasti parantaa kiinalaisten kielioppivirheiden havaitsemisen ja korjaamisen suorituskykymittareita.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Dans le processus d'apprentissage du chinois, les apprenants de langue seconde peuvent avoir diverses erreurs grammaticales en raison du transfert négatif de la langue maternelle. Ce document décrit notre soumission à la tâche partagée NLPTEA 2020 sur la CGED. Nous présentons un système hybride qui utilise à la fois des étapes de détection et de correction. L'étape de détection est un modèle de marquage séquentiel basé sur la représentation de mots contextuels BILSTM-CRF et BERT. L'étape de correction est un modèle hybride basé sur le n-gramme et Seq2Seq. Sans ajouter de fonctionnalités supplémentaires ni de données externes, la représentation contextuelle des mots BERT peut améliorer efficacement les mesures de performance de la détection et de la correction des erreurs grammaticales chinoises.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>I bpróiseas foghlama na Síne, d’fhéadfadh go mbeadh earráidí gramadaí éagsúla ag foghlaimeoirí dara teanga mar gheall ar aistriú diúltach na teanga dúchais. Déanann an páipéar seo cur síos ar ár n-aighneacht do thasc roinnte NLPTEA 2020 ar CGED. Cuirimid córas hibrideach i láthair a úsáideann céimeanna braite agus ceartúcháin araon. Múnla lipéadaithe seicheamhach atá sa chéim braite bunaithe ar léiriú focal comhthéacsúla BiLSTM-CRF agus BERT. Samhail hibrideach atá sa chéim cheartúcháin bunaithe ar an n-gram agus an Seq2Seq. Gan gnéithe breise agus sonraí seachtracha a chur leis, is féidir le hionadaíocht focail comhthéacsúla BERT feabhas a chur go héifeachtach ar mhéadracht feidhmíochta braite agus ceartú earráide gramadaí na Síne.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Haƙĩƙa, a cikin jararin da aka karanta wa China, masu kara na lugha na ƙarƙashin, watau su iya da wasu ɓatattu masu karatun grammaci ne sababin shige-motsi na lugha native. This paper describes our submission to the NLPTEA 2020 shared task on CGED. Muna halatar da wani na'ura da ya yi amfani da duk ganin da za'a sani. Halin da za'a gane shi wata salon mai biyayyar bayãni ne a kan bincike BiLStM-CRF da maɓallin maganar da BERT. Halin da aka daidaita shi yana wata salon zaɓani n a n-gram da Seq2Seq. Bai ƙara da wasu hushi da data masu ƙaranci, mai gaya maganar BERT na koma, yana iya amfani da gyarata metric mai gyarawa na ganin ɓata na grammati na China.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In the process of learning Chinese, second language learners may have various grammatical errors due to the negative transfer of native language. העיתון הזה מתאר את ההעברה שלנו למשימה משותפת NLPTEA 2020 על CGED. אנחנו מציגים מערכת היברידית שמשתמשת בשלבי גילוי ותיקון. The detection stage is a sequential labelling model based on BiLSTM-CRF and BERT contextual word representation. שלב התיקון הוא מודל היברידי מבוסס על n-גרם וסקק2Seq. Without adding additional features and external data, the BERT contextual word representation can effectively improve the performance metrics of Chinese grammatical error detection and correction.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>चीनी सीखने की प्रक्रिया में, दूसरी भाषा सीखने वालों में मूल भाषा के नकारात्मक हस्तांतरण के कारण विभिन्न व्याकरणिक त्रुटियां हो सकती हैं। यह पेपर CGED पर NLPTEA 2020 साझा कार्य के लिए हमारे सबमिशन का वर्णन करता है। हम एक हाइब्रिड सिस्टम प्रस्तुत करते हैं जो पता लगाने और सुधार दोनों चरणों का उपयोग करता है। पता लगाने का चरण BiLSTM-CRF और BERT प्रासंगिक शब्द प्रतिनिधित्व के आधार पर एक अनुक्रमिक लेबलिंग मॉडल है। सुधार चरण n-gram और Seq2Seq पर आधारित एक हाइब्रिड मॉडल है। अतिरिक्त सुविधाओं और बाहरी डेटा को जोड़ने के बिना, BERT प्रासंगिक शब्द प्रतिनिधित्व प्रभावी ढंग से चीनी व्याकरणिक त्रुटि का पता लगाने और सुधार के प्रदर्शन मैट्रिक्स में सुधार कर सकते हैं।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>U procesu učenja kineskog jezika, učitelji drugih jezika mogu imati različite gramatičke greške zbog negativnog prenošenja jezika. Ovaj papir opisuje naše podnošenje zajedničkom zadatku NLPTEA 2020 o CGED-u. Predstavljamo hibridni sustav koji koristi detektive i korekcije. Stadija otkrivanja je sekvencijski model označavanja na temelju BiLSTM-CRF i BERT kontekstualne riječi. Pozor isprave je hibridni model baziran n a n-gramu i Seq2Seq. Bez dodavanja dodatnih karakteristika i vanjskih podataka, predstavljanje BERT-a kontekstualne riječi može učinkovito poboljšati provedbenu metriku kineskog gramatičkog otkrivanja i isprave grešaka.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A kínai tanulás során a második nyelvtanulóknak különböző nyelvtani hibák lehetnek az anyanyelv negatív átadása miatt. Ez a tanulmány bemutatja, hogy benyújtottunk az NLPTEA 2020 közös feladatra a CGED-re. Bemutatunk egy hibrid rendszert, amely mind az észlelési, mind a korrekciós szakaszokat használja. Az észlelési szakasz egy szekvenciális címkézési modell, amely BiLSTM-CRF és BERT kontextuális szóábrázoláson alapul. A korrekciós szakasz egy hibrid modell, amely az n-grammon és Seq2Seq alapul. További funkciók és külső adatok hozzáadása nélkül a BERT kontextuális szóábrázolása hatékonyan javíthatja a kínai nyelvtani hibaészlelés és -korrekció teljesítménymutatóit.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Չինաստանի ուսումնասիրության ընթացքում երկրորդ լեզվի ուսանողները կարող են ունենալ տարբեր գրամատիկ սխալներ՝ ծննդյան լեզվի բացասական փոխանցման պատճառով: Այս հոդվածը նկարագրում է մեր ներկայացումը ՆԼՊՏԵԱ 2020-ի ընդհանուր հանձնարարությանը CGeD-ի մասին: Մենք ներկայացնում ենք հիբրիդ համակարգ, որը օգտագործում է բացահայտումների և ուղղումների փուլերը: Բացահայտության փուլը հաջորդական պիտակագրման մոդել է, որը հիմնված է ԲիLSԹՄ-ԿՌՖ և ԲԵԹ-ի կոնտեքստային բառերի ներկայացման վրա: Կարգավորման փուլը հիբրիդ մոդել է, որը հիմնված է n-գրամի և SeQ2SeQ-ի վրա: Առանց ավելացնելու առանձնահատկություններ և արտաքին տվյալներ, BER-ի կոնտեքստիկ բառերի ներկայացումը կարող է արդյունավետ բարելավել չինական գրամատիկ սխալների հայտնաբերման և ուղղումների արտադրողականության չափում</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Dalam proses belajar bahasa Cina, para pelajar bahasa kedua mungkin memiliki beberapa kesalahan grammatik karena transfer negatif bahasa asli. Kertas ini menjelaskan pengiriman kita ke NLPTEA 2020 tugas berbagi di CGED. Kami mempersembahkan sistem hibrid yang menggunakan kedua tahap deteksi dan koreksi. The detection stage is a sequential labelling model based on BiLSTM-CRF and BERT contextual word representation. Stadium koreksi adalah model hibrid berdasarkan n-gram dan Seq2Seq. Tanpa menambahkan karakteristik tambahan dan data luar, representasi kata kontekstual BERT dapat secara efektif meningkatkan metrik prestasi dari deteksi dan koreksi kesalahan grammatik Cina.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nel processo di apprendimento del cinese, gli studenti di seconda lingua possono avere vari errori grammaticali a causa del trasferimento negativo della lingua madre. Questo articolo descrive la nostra presentazione al compito condiviso NLPTEA 2020 su CGED. Presentiamo un sistema ibrido che utilizza sia fasi di rilevamento che di correzione. La fase di rilevamento è un modello di etichettatura sequenziale basato sulla rappresentazione contestuale di parole BiLSTM-CRF e BERT. La fase di correzione è un modello ibrido basato su n-gram e Seq2Seq. Senza aggiungere funzionalità aggiuntive e dati esterni, la rappresentazione contestuale delle parole BERT può migliorare efficacemente le metriche di performance del rilevamento e correzione degli errori grammaticali cinesi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>中国語を学習する過程で、第二言語の学習者はネガティブな母国語の転送のためにさまざまな文法的誤りを抱える可能性があります。本稿では、CGEDに関するNLPTEA 2020共有タスクへの提出について説明します。検出段階と補正段階の両方を利用するハイブリッドシステムを提示します。検出段階は、ＢｉＬＳＴＭ － ＣＲＦ及びＢＥＲＴ文脈的単語表現に基づく逐次標識モデルである。補正段階は、n - gramとSeq 2 Seqに基づくハイブリッドモデルである。追加機能や外部データを追加することなく、BERTコンテキスト単語表現は、中国語文法のエラー検出と修正のパフォーマンスメトリクスを効果的に改善することができます。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nang pengguna sampeyan Cines, sampeyan tanggal saiki unyak gak bener Perintah iki rambarang nggawe nyimpen NLPMEA 2020 nganggo CGED Awak dhéwé éntuk sistem sing wis ana ing nggo tahirno karo Ngubah Sayensi Kampèng rection kuwi model HyBridge sing basa ning n-gram karo Seq2Seq. Nanging nambah peringatan tambah lan data anyar, gambar BERT contextual</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ჩინეთის სწავლების პროცესში, მეორე ენის სწავლებელი შესაძლებელია განსხვავებული გრამიმატური შეცდომილებები, რადგან მისი ენის გადატანსტრიქციის განსაკუთრებული ეს დოკუმენტი ჩვენი გახსნა NLPTEA 2020-ის გაყოფილი CGED-ზე. ჩვენ აჩვენებთ ჰიბრიდის სისტემა, რომელიც გამოიყენებს განახლება და კონფიგურაცია. განახლების ფაეზი არის სიტყვების გამოსახულება BiLSTM-CRF და BERT კონტექსტური სიტყვების გამოსახულება. კონფიგურაციის ფაეზია n-გრამის და Seq2Seq-ის დაბაზეული ჰიბრიტის მოდელი. BERT-ის კონტექსტური სიტყვების გამოსახულება შეუძლია წინასწარმოდგენება ჩინეთის გრამიკალური შეცდომის განსახულება და კონტექსტური შეცდომის გამოსახულება.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Қытай тілді оқыту процесінде, екінші тілді оқытушылардың негативті тілді аудару үшін грамматикалық қатесі болуы мүмкін. Бұл қағаз NLPTEA 2020 бағытталған тапсырмаға CGED жіберімізді таңдайды. Біз анықтау мен түзету сәттерін қолданатын гибрид жүйесін таңдаймыз. Табу кезегі - BiLSTM- CRF және BERT контекстік сөздерді таңдау үлгісі. Түзету кезегі n- грамма және Seq2Seq негіздеген гибрид моделі. Қосымша мүмкіндіктерді және сыртқы деректерді қосуға болмаса, BERT контексті сөздерді таңдау үшін Қытай грамматикалық қателерді анықтау және түзетуге болады.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>중국어를 배우는 과정에서 모국어의 마이너스 변화로 인해 제2언어 학습자는 각종 문법 오류가 발생할 수 있다.이 문서에서는 NLPTEA 2020 CGED 공유 임무에 제출된 상황을 설명합니다.우리는 검측과 교정 단계를 이용한 혼합 시스템을 제시했다.체크 단계는 BiLSTM CRF 및 BERT 컨텍스트 단어를 기반으로 하는 순차 태그 모델입니다.교정 단계는 n-gram과 Seq2Seq를 기반으로 한 혼합 모델이다.BERT 컨텍스트 단어는 추가 피쳐와 외부 데이터를 추가하지 않고도 중국어 구문 오류를 효과적으로 감지하고 수정할 수 있는 성능 지표를 나타냅니다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mokymosi kinų kalba metu antrosios kalbos mokytojai gali patirti įvairių gramatinių klaidų dėl neigiamo gimtosios kalbos perdavimo. Šiame dokumente apibūdinamas mūsų pranešimas bendrai NLPTEA 2020 uždaviniui CGED. Mes pristatome hibridinę sistemą, kuri naudoja ir aptikimo, ir koregavimo etapus. Nustatymo etapas yra sekos ženklinimo model is, pagrįstas BiLSTM-CRF ir BERT kontekstiniu žodžių vaizdu. Korekcijos etapas yra hibridinis model is, pagrįstas n-gramais ir Seq2Seq. Be papildomų charakteristikų ir išorinių duomenų BERT kontekstinis žodžių atstovavimas gali veiksmingai pagerinti Kinijos gramatinių klaidų nustatymo ir ištaisymo rezultatų rodiklius.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Во процесот на учење кинески, учениците на вториот јазик можеби имаат различни граматични грешки поради негативниот трансфер на родниот јазик. Овој документ го опишува нашето поднесување на заедничката задача на НЛПТЕА 2020 за ЦГЕД. Презентираме хибриден систем кој ги користи и стадиите на детекција и корекција. Стапата на детекција е секвенцијален модел за означување базиран на БиLSTM-CRF и BERT контекстна претстава на зборовите. Стапата на корекција е хибриден модел базиран на n-грам и Seq2Seq. Без додавање дополнителни карактеристики и надворешни податоци, контекстното претставување на зборовите БЕРТ може ефикасно да ја подобри метриката на резултатите на детекцијата и корекцијата на кинеските граматички грешки.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ചൈനീസ് പഠിക്കുന്ന പ്രക്രിയയില്‍, രണ്ടാമത്തെ ഭാഷ പഠിക്കുന്നവര്‍ക്ക് നേരിട്ട് ഭാഷ മാറ്റുന്നതിനാല്‍ പല ഗ്രാമാ ഈ പത്രത്തില്‍ സിജെഡിയില്‍ പങ്കുചേര്‍ത്ത ജോലിയെ നമ്മുടെ നിയന്ത്രണത്തെക്കുറിച്ച് പറയുന്നു. ഞങ്ങള്‍ ഒരു ഹൈബ്രിഡ് സിസ്റ്റം കൊണ്ടുവരുന്നു. അത് കണ്ടുപിടിക്കുന്നതും ശരിയാക്കുന്നതും ഉപയോഗിക്കു ബിഎല്‍എസ്റ്റി- CRF- നെ അടിസ്ഥാനമാക്കിയ ഒരു സാധാരണ ലേബെലിങ്ങ് മോഡലാണ് കണ്ടുപിടിക്കുന്നത്. ബെര്‍ട്ടി നിലവിലുള്ള ന്‍ ഗ്രാമും സെക്ക്2സെക്കും അടിസ്ഥാനമായി ഒരു ഹൈബ്രിഡ് മോഡലാണ്. കൂടുതല്‍ ഗുണഗണങ്ങളും പുറത്തുള്ള വിവരങ്ങളും കൂട്ടിചേര്‍ക്കാതെ, ബെര്‍ട്ടി നിലവിലുള്ള വാക്ക് പ്രദര്‍ശിപ്പിക്കുന്നത് ചൈനീസ് ഗ്രാമ്ര</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Хятад хэлний суралцах үйл явцдаа хоёр дахь хэл сурагчид ээж хэлийн сөрөг шилжүүлэлтийн шалтгаан олон грамматикийн алдаа байж болно. Энэ цаас бидний NLPTEA 2020-ийн CGED-д хуваалцах ажлыг тайлбарладаг. Бид олох болон зөв загварыг ашигладаг гибрид системийг харуулж байна. Тайлбарлах шатан нь BiLSTM-CRF болон BERT контекст үг илэрхийлэх загвар юм. Шулгалтын шатан нь n-грамм болон Seq2Seq-ын үндсэн гибрид загвар юм. Нэг нэмэлт чанар болон гадаад өгөгдлийг нэмэгдэхгүй байвал, BERT-ын орчин үеийн үзүүлэлт нь Хятад грамматикийн алдаа гаргах болон шууд байдлын үйлдвэрлэлтийн метрикийг үр дүнтэй сайжруулж чадн</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Dalam proses belajar bahasa Cina, pelajar bahasa kedua mungkin mempunyai pelbagai ralat grammatik disebabkan pemindahan negatif bahasa asli. Kertas ini menjelaskan penghantaran kami kepada tugas kongsi NLPTEA 2020 pada CGED. Kami memperkenalkan sistem hibrid yang menggunakan kedua-dua tahap pengesan dan pembetulan. Tahap pengesan adalah model label sekuensi berdasarkan perwakilan perkataan kontekstual BiLSTM-CRF dan BERT. Tahap penyesuaian adalah model hibrid berdasarkan n-gram dan Seq2Seq. Tanpa menambah ciri-ciri tambahan dan data luaran, perwakilan perkataan kontekstual BERT boleh meningkatkan metrik prestasi pengesan dan perbaikan ralat grammatik Cina.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Fil-proċess tat-tagħlim taċ-Ċiniż, l-istudenti tat-tieni lingwa jista’ jkollhom diversi żbalji grammatiċi minħabba t-trasferiment negattiv tal-lingwa nattiva. Dan id-dokument jiddeskrivi s-sottomissjoni tagħna lill-kompitu komuni NLPTEA 2020 dwar is-CGED. Aħna nippreżentaw sistema ibrida li tuża kemm l-istadji ta’ detezzjoni kif ukoll ta’ korrezzjoni. L-istadju ta’ detezzjoni huwa mudell sekwenzjali ta’ tikkettar ibbażat fuq ir-rappreżentazzjoni kuntestwali tal-kelma BiLSTM-CRF u BERT. L-istadju ta’ korrezzjoni huwa mudell ibridu bbażat fuq n-gramma u Seq2Seq. Mingħajr iż-żieda ta’ karatteristiċi addizzjonali u dejta esterna, ir-rappreżentanza tal-kelma kuntestwali BERT tista’ ttejjeb b’mod effettiv il-metriċi tal-prestazzjoni tal-identifikazzjoni u l-korrezzjoni ta’ żbalji grammatiċi Ċiniżi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tijdens het leren van Chinees kunnen tweetalige leerlingen verschillende grammaticale fouten hebben als gevolg van de negatieve overdracht van moedertaal. Dit document beschrijft onze inzending aan de NLPTEA 2020 gedeelde taak op CGED. We presenteren een hybride systeem dat zowel detectie- als correctiefasen gebruikt. De detectiefase is een sequentieel labelmodel gebaseerd op BiLSTM-CRF en BERT contextuele woordweergave. De correctiefase is een hybride model gebaseerd op de n-gram en Seq2Seq. Zonder extra functies en externe gegevens toe te voegen, kan de contextuele woordweergave van BERT de prestatiestatistieken van Chinese grammaticale foutdetectie en -correctie effectief verbeteren.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>I læring av kinesisk kan andre språkelærar ha ulike grammatiske feil på grunn av negativt overføring av språk. Denne papiret beskriver vårt oppføring til delt oppgåve NLPTEA 2020 på CGED. Vi presenterer eit hybrid system som brukar både oppdaging og rettingsstader. Oppdagingsstaden er ein sekvensisk merkelappemodell basert på BiLSTM-CRF og BERT-kontekstalt ordrepresentasjon. Korrigeringsstaden er ein hybridmodell basert på n-gram og Seq2Seq. Utan å leggja til eksterne funksjonar og eksterne data, kan BERT- kontekst- ordrepresentasjonen effektivt forbedra utviklingsmeterikatoren til kinesisk grammatisk feiloppdaging og retting.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>W procesie nauki chińskiego uczący się języka drugiego mogą mieć różne błędy gramatyczne z powodu negatywnego transferu języka ojczystego. Niniejszy artykuł opisuje nasze zgłoszenie do wspólnego zadania NLPTEA 2020 na CGED. Prezentujemy system hybrydowy, który wykorzystuje zarówno etapy detekcji, jak i korekcji. Etap wykrywania jest sekwencyjnym modelem etykietowania opartym na kontekstowej reprezentacji słów BiLSTM-CRF i BERT. Etap korekcji jest modelem hybrydowym opartym na n-gramie i Seq2Seq. Bez dodawania dodatkowych funkcji i danych zewnętrznych, kontekstowa reprezentacja słów BERT może skutecznie poprawić wskaźniki wydajności chińskiego wykrywania i korekcji błędów gramatycznych.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>No processo de aprendizagem do chinês, os aprendizes de segunda língua podem ter vários erros gramaticais devido à transferência negativa da língua nativa. Este artigo descreve nossa submissão à tarefa compartilhada NLPTEA 2020 no CGED. Apresentamos um sistema híbrido que utiliza etapas de detecção e correção. A etapa de detecção é um modelo de rotulagem sequencial baseado na representação de palavras contextuais BiLSTM-CRF e BERT. A etapa de correção é um modelo híbrido baseado no n-gram e Seq2Seq. Sem adicionar recursos adicionais e dados externos, a representação de palavras contextuais do BERT pode melhorar efetivamente as métricas de desempenho da detecção e correção de erros gramaticais em chinês.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>În procesul de învățare a limbii chineze, cursanții de limbă a doua pot avea diferite erori gramaticale din cauza transferului negativ al limbii materne. Această lucrare descrie prezentarea noastră la sarcina comună NLPTEA 2020 privind CGED. Vă prezentăm un sistem hibrid care utilizează atât etapele de detecție, cât și cele de corecție. Etapa de detectare este un model de etichetare secvențială bazat pe reprezentarea contextuală a cuvintelor BiLSTM-CRF și BERT. Etapa de corecție este un model hibrid bazat pe n-gram și Seq2Seq. Fără a adăuga caracteristici suplimentare și date externe, reprezentarea contextuală a cuvintelor BERT poate îmbunătăți eficient măsurătorile performanței detectării și corectării erorilor gramaticale chinezești.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>В процессе изучения китайского языка, изучающие второй язык, могут иметь различные грамматические ошибки из-за отрицательной передачи родного языка. В этом документе описывается наше представление совместной задаче NLPTEA 2020 по CGED. Мы представляем гибридную систему, которая использует как стадии обнаружения, так и стадии коррекции. Этап обнаружения представляет собой последовательную модель маркировки, основанную на представлении контекстного слова BiLSTM-CRF и BERT. Этап коррекции представляет собой гибридную модель, основанную на n-грамме и Seq2Seq. Без добавления дополнительных функций и внешних данных представление контекстного слова BERT может эффективно улучшить показатели производительности китайского грамматического обнаружения и исправления ошибок.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>චීනි භාෂාව ඉගෙන ගන්න ප්‍රකාරයේ දෙවෙනි භාෂාව ඉගෙන ගන්න පුළුවන් විවිධ වැරදිලි තියෙන්න පුළු මේ පැත්තේ අපේ පිළිගන්නේ NLPTEA 2020යි CGED ගැන කැමති වැඩක් විතරයි. අපි හායිබ්‍රිඩ් පද්ධතියක් පෙන්වන්නේ, ඒ වගේම හොයාගන්න සහ සුදුසුම් පද්ධතියක් ප්‍රයෝජන හොයාගන්න ස්ථානය තමයි BiLSTM-CRF සහ BERT සාමාන්‍ය වචන ප්‍රතිනිධානය සඳහා ප්‍රතිනිධානයක් විසින් ලේබිල් මඩ The correction stage is a hybroid Model based on the n-gram and Seq2Seq. විශේෂතාවක් සහ ප්‍රතික්‍රිය දත්ත සම්බන්ධ නොකරලා, BERT සම්බන්ධ වාර්තාවක් වචන ප්‍රතික්‍රියාපනය ප්‍රතික්‍රියාපන</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>V procesu učenja kitajščine imajo učenci drugega jezika lahko različne slovnične napake zaradi negativnega prenosa maternega jezika. Ta prispevek opisuje našo predložitev skupni nalogi NLPTEA 2020 na CGED. Predstavljamo hibridni sistem, ki uporablja tako stopnjo odkrivanja kot korekcije. Stopnja odkrivanja je model zaporednega označevanja, ki temelji na kontekstni predstavitvi besed BiLSTM-CRF in BERT. Korekcijska faza je hibridni model, ki temelji na n-gramu in Seq2Seq. Brez dodajanja dodatnih funkcij in zunanjih podatkov lahko kontekstna predstavitev besed BERT učinkovito izboljša meritve učinkovitosti kitajskega slovničnega odkrivanja in popravljanja napak.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Marka lagu jiro barashada Shiino waxaa laga yaabaa in dadka baranaya luqada labaad ay leeyihiin khalad kala duduwan grammatika sababtoo ah wareejinta afka hooyo. This paper describes our submission to the NLPTEA 2020 shared task on CGED. Waxaan keenaynaa nidaam hibir ah oo isticmaalaya baaritaanka iyo hagitaanka. Xarunta caddeyntu waa model sawir ah oo ku saleysan BiLSTM-CRF iyo BERT oo ku qoran qoraalka xilliga ah. Heerka hagitaanku waa muusikada hybridka oo ku saleysan n-gram iyo Seq2Seq. Xiriir dheeraad ah iyo macluumaad dibadda ah la'aanta, qayb-dhigista erayga joogtada ah ee BERT wuxuu si fiican u beddeli karaa qaababka ku saabsan cadayn iyo hagaajinta khaladda ee Shiino.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Në procesin e mësimit të kinezës, mësuesit e gjuhës së dytë mund të kenë gabime të ndryshme grammatike për shkak të transferimit negativ të gjuhës natyrore. Ky dokument përshkruan paraqitjen tonë në detyrën e përbashkët të NLPTEA 2020 për CGED. Ne prezantojmë një sistem hibridë që përdorë si fazat e zbulimit, ashtu edhe të korrigjimit. Faza e zbulimit është një model shequencial etiketash bazuar në përfaqësimin kontekstual të fjalëve BiLSTM-CRF dhe BERT. Faza e korrigjimit është një model hibridë bazuar n ë n-gram dhe Seq2Seq. Pa shtimin e karakteristikave shtesë dhe të dhënave të jashtme, përfaqësimi kontekstual i fjalëve BERT mund të përmirësojë efektivisht metrikat e performancës të zbulimit dhe korrektimit të gabimeve grammatike kineze.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>U procesu učenja kineskog jezika drugi učitelji mogu imati različite gramatičke greške zbog negativnog prenošenja jezika. Ovaj papir opisuje našu predanost podijeljenom zadatku NLPTEA 2020 o CGED-u. Predstavljamo hibridni sistem koji koristi detektive i korekcije. Stadija otkrivanja je sekvencijski model označavanja na temelju BiLSTM-CRF i BERT kontekstualne reči. Korekcija je hibridni model baziran n a n-gramu i Seq2Seq. Bez dodavanja dodatnih karakteristika i spoljnih podataka, predstavljanje BERT-a kontekstualne reči može učinkovito poboljšati metriku učinkovitosti kineskog gramatičkog otkrivanja i isprave grešaka.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>I processen att lära sig kinesiska kan andraspråkslärare ha olika grammatiska fel på grund av negativ överföring av modersmål. Denna uppsats beskriver vår inlämning till NLPTEA 2020 delade uppgift om CGED. Vi presenterar ett hybridsystem som använder både detekterings- och korrigeringsstadier. Detektionssteget är en sekventiell märkningsmodell baserad på BiLSTM-CRF och BERT kontextuell ordrepresentation. Korrigeringsfasen är en hybridmodell baserad på n-gram och Seq2Seq. Utan att lägga till ytterligare funktioner och externa data kan BERT:s kontextuella ordrepresentation effektivt förbättra prestandamätningarna för detektering och korrigering av kinesiska grammatiska fel.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Katika mchakato wa kujifunza Kichina, wanafunzi wa lugha ya pili wanaweza kuwa na makosa mbalimbali ya kiuchumi kutokana na uhamishaji hasi wa lugha ya asili. Gazeti hili linaelezea ujumbe wetu wa NLPTEA 2020 uliosambazwa na kazi ya CGED. We present a hybrid system that utilizes both detection and correction stages. Jukwaa la kutambua ni modeli ya maambukizi inayohusiana na BiLSTM-CRF na uwakilishi wa maneno ya wakati wa BERT. Jukwaa la uharibifu ni modeli ya hybrid inayotumiwa n a n-gram na Seq2Seq. Bila kuongezea vipengele vya ziada na takwimu za nje, uwakilishi wa maneno ya sasa ya BERT yanaweza kuboresha mbinu za uchunguzi wa makosa ya kiuchumi nchini China na kuharibiwa.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>சீன கற்றுக்கொள்ளும் செயல்பாட்டில், இரண்டாவது மொழி கற்றுக்கொள்பவர் This paper describes our submission to the NLPTEA 2020 shared task on CGED. நாம் கண்டறிதல் மற்றும் திருத்தம் முறைகளை பயன்படுத்தும் ஒரு ஹைப்ரி அமைப்பை காண்பிக்கிறோம். The detection stage is a sequential labelling model based on BiLSTM- CRF and BERT contextual word representation. The correction stage is a hybrid model based on the n- gram and Seq2Seq. கூடுதல் குணங்கள் மற்றும் வெளி தரவுகளை சேர்க்காமல், BERT தற்காலிக வார்த்தை குறிப்பிடுதல் சீனா வரையறை பிழை கண்டுபிடிப்பு மற்றும் திருத</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Çinçe öwrenmek procesinde, ikinji dil öwrenmeýänleriň ene diliniň göçürmesi üçin dürli gramatik hatalarynyň bolup biler. Bu kagyz NLPTEA 2020-nji ýygnagymyzy CGED barada paýlaşýar. Biz bir hybrid sistemini tanyş we düzeltmek sahypalaryny ulanýan Bu deteksion sahnesi BiLSTM-CRF we BERT tesbitli kelime temsiline dayanan bir sıralan etiketleme modeldir. Düzeltmek sahypasy n-gram we Seq2Seq-a dayanan hybrid nusgasydir. Eger özellikler we daşarydaky maglumatlary eklemeýän bolsa, BERT senesasy sözleriň üýtgetmesi Çinçe gramatik hatalaryň tanymasynyň we düzeltmeginin üstine çykaryp biler.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>چین کی تعلیم کے مطابق دوسری زبان سکھانے والوں کے لئے مختلف گراماتیکی خطا ہوسکتے ہیں ماں کی زبان کی منفی ترافرست کے سبب۔ This paper describes our submission to the NLPTEA 2020 shared task on CGED. ہم ایک ہیبراڈ سیستم کو پیش کریں جو پہچان اور اصلاح مرحلے کو استعمال کرتا ہے۔ آشنا سٹیج BiLSTM-CRF اور BERT contextual word representation پر بنیاد ایک سٹیل لیبلینگ موڈل ہے. اصلاح مرحلہ ایک ہیبراڈ موڈل ہے جو n-گرم اور Seq2Seq پر بنیاد ہے. بغیر اس کے کہ زیادہ ویژگی اور بیرونی ڈیٹا اضافہ نہ کریں، BERT کنٹکسٹیول کلمات کی نمایش چینی گراماتیکی خطا شناسایی اور اصلاح کی عملکرد متریک کو عمدہ کر سکتی ہے.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Xitoycha o'rganishda ikkinchi tillar o'rganishlari natiy tillarining negativ tarjima qilishi sababini boshqa grammatik xatolari bo'lishi mumkin. Bu qogʻoz CGED (NLPTEA 2020) bilan birlashtirilgan vazifani anglatadi. Biz haybrid tizimini aniqlash va toʻgʻrilash holatidan foydalanishimiz. Name Toʻgʻri sahifa - n- gram va Seq2Seq asosida ishlatilgan hybrid modeli. Qoʻshimcha moslamalar va externa maʼlumot qoʻshilmaydi, BERT'ning davomida soʻzni taʼminlashtirish va Xitoycha grammatikal xato aniqlashni va toʻgʻrilishini bajarishi mumkin.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Trong quá trình học tiếng Trung, học giả ngôn ngữ thứ hai có thể có lỗi theo ngữ pháp khác nhau do sự chuyển đổi âm tính của ngôn ngữ bản xứ. Tờ giấy này mô tả việc chúng tôi đăng ký vào một nhiệm vụ chung chung NLlái 2020 ở CGEDed. Chúng tôi giới thiệu một hệ thống lai sử dụng cả các giai đoạn phát hiện và sửa chữa. Phát hiện trường là một mô hình mô phỏng sắp xếp dựa trên BiLSTM-CRF và BERT nền đại diện các từ ngữ. Bộ sửa chữa là một mô hình lai dựa trên n-gram và Seq2Seq. Không cần thêm các tính năng và dữ liệu bên ngoài, sự mô tả ngữ cảnh của thiếu sót sót sót sót sót sót của ngôn ngữ học Trung Hoa có thể cải thiện tỉ lệ hiệu quả.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>学汉语者,母语负面移,第二语言学者或有语法错误。 本文介我NELPTEA 2020交CGED共之。 臣等建一混合系统,当以检测校正之。 检者,BiLSTM-CRFBERT上下文词之序也。 校正者,n-gramSeq2Seq之混形也。 不加特征、外数者,BERT语境词有效汉语语法错误检正之性能指标。</span></div></div><dl><dt>Anthology ID:</dt><dd>2020.nlptea-1.14</dd><dt>Volume:</dt><dd><a href=/volumes/2020.nlptea-1/>Proceedings of the 6th Workshop on Natural Language Processing Techniques for Educational Applications</a></dd><dt>Month:</dt><dd>December</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Suzhou, China</dd><dt>Venues:</dt><dd><a href=/venues/aacl/>AACL</a>
| <a href=/venues/nlptea/>NLP-TEA</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>102–107</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.nlptea-1.14>https://aclanthology.org/2020.nlptea-1.14</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">zan-etal-2020-chinese</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Hongying Zan, Yangchao Han, Haotian Huang, Yingjie Yan, Yuke Wang, and Yingjie Han. 2020. <a href=https://aclanthology.org/2020.nlptea-1.14>Chinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared TaskChinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared Task</a>. In <i>Proceedings of the 6th Workshop on Natural Language Processing Techniques for Educational Applications</i>, pages 102–107, Suzhou, China. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2020.nlptea-1.14>Chinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared TaskChinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared Task</a> (Zan et al., NLP-TEA 2020)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2020.nlptea-1.14.pdf>https://aclanthology.org/2020.nlptea-1.14.pdf</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2020.nlptea-1.14.pdf title="Open PDF of 'Chinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared TaskChinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared Task'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Chinese+Grammatical+Errors+Diagnosis+System+Based+on+BERT+at+NLPTEA-2020+CGED+Shared+TaskChinese+Grammatical+Errors+Diagnosis+System+Based+on+BERT+at+NLPTEA-2020+CGED+Shared+Task" title="Search for 'Chinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared TaskChinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared Task' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'Chinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared TaskChinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared Task'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[Chinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared TaskChinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared Task](https://aclanthology.org/2020.nlptea-1.14) (Zan et al., NLP-TEA 2020)</p><ul class=mt-2><li><a href=https://aclanthology.org/2020.nlptea-1.14>Chinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared TaskChinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared Task</a> (Zan et al., NLP-TEA 2020)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Hongying Zan, Yangchao Han, Haotian Huang, Yingjie Yan, Yuke Wang, and Yingjie Han. 2020. <a href=https://aclanthology.org/2020.nlptea-1.14>Chinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared TaskChinese Grammatical Errors Diagnosis System Based on BERT at NLPTEA-2020 CGED Shared Task</a>. In <i>Proceedings of the 6th Workshop on Natural Language Processing Techniques for Educational Applications</i>, pages 102–107, Suzhou, China. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>