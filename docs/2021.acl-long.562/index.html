<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Beyond Noise : Mitigating the Impact of Fine-grained Semantic Divergences on Neural Machine Translation - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="Beyond Noise : Mitigating the Impact of Fine-grained Semantic Divergences on Neural Machine Translation" name=citation_title><meta content="Eleftheria Briakou" name=citation_author><meta content="Marine Carpuat" name=citation_author><meta content="Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)" name=citation_conference_title><meta content="2021/8" name=citation_publication_date><meta content="https://aclanthology.org/2021.acl-long.562.pdf" name=citation_pdf_url><meta content="7236" name=citation_firstpage><meta content="7249" name=citation_lastpage><meta content="10.18653/v1/2021.acl-long.562" name=citation_doi><meta property="og:title" content="Beyond Noise : Mitigating the Impact of Fine-grained Semantic Divergences on Neural Machine Translation"><meta property="og:image" content="https://aclanthology.org/thumb/2021.acl-long.562.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2021.acl-long.562"><meta property="og:description" content="Eleftheria Briakou, Marine Carpuat. Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 2021."><link rel=canonical href=https://aclanthology.org/2021.acl-long.562></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2021.acl-long.562.pdf>Beyond Noise : Mitigating the Impact of Fine-grained Semantic Divergences on Neural Machine Translation</a>
<a id=af_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Buitend ruis: Mitigating the Impact of Fine-grained Semantic Divergences on Neural Machine Translation</a>
<a id=am_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>undo-type</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>ما بعد الضوضاء: التخفيف من تأثير الاختلافات الدلالية الدقيقة على الترجمة الآلية العصبية</a>
<a id=az_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Ses öyrənməsindən: Nöral Makinat Çevirməsində yaxşı dənələr təsirlərinin etkisini küçültmək</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Отвъд шума: смекчаване на въздействието на фините семантични отклонения върху невралния машинен превод</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>নিউরাল মেশিন অনুবাদের উপর ভালো গ্রেফতার সেম্যান্টিক ডিভারেজেন্সের প্রভাব কমানো</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>འོད་ཀྱང་དཀྲོག་མྱུར་བའི་འགྱུར་བ་དེ་འགྱུར་བའི་རྐྱེན་རྐྱེན་གྱི་སྐྱེས་ཆེན་དང་།</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Iza glasa: ometanje utjecaja semantičkih različitih djelovanja na neurološki prevod strojeva</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Després del soroll: Mitigar l'impacte de les divergències Semàtiques fines sobre la traducció de màquines neurals</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Kromě hluku: zmírnění vlivu jemnozrnných sémantických divergencí na neuronový strojový překlad</a>
<a id=da_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Udover støj: Mindskelse af virkningen af finkornede semantiske afvigelser på neural maskinoversættelse</a>
<a id=de_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Jenseits von Rauschen: Minderung der Auswirkungen feinkörniger semantischer Divergenzen auf die neuronale maschinelle Übersetzung</a>
<a id=el_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Πέρα από τον θόρυβο: Μείωση των επιπτώσεων των λεπτόκοκκων Σημαντικών αποκλίσεων στη Νευρική Μηχανική Μετάφραση</a>
<a id=es_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Más allá del ruido: mitigar el impacto de las divergencias semánticas detalladas en la traducción automática neuronal</a>
<a id=et_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Müra kõrval: peeneteraliste semantiliste lahknevuste mõju leevendamine neuromasintõlkele</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>بیرون صدا: تأثیر تغییرات سیمانتیک‌های خوشمزه بر ترجمه ماشین عصبی</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Melun ulkopuolella: hienorakeisten semanttisten erojen vaikutuksen lieventäminen hermokonekäännöksiin</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Au-delà du bruit : atténuer l'impact des divergences sémantiques fines sur la traduction automatique neuronale</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Thar Torann: Tionchar Éagsúlachtaí Séimeantacha Míne ar Aistriú Meaisín Néarach a Mhaolú</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>KCharselect unicode block name</a>
<a id=he_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Beyond Noise: Mitigating the Impact of Fine-grained Semantic Divergences on Neural Machine Translation</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>शोर से परे: तंत्रिका मशीन अनुवाद पर ठीक दाने दार शब्दार्थ विचलन के प्रभाव को कम करना</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Izvan glasa: Smanjivanje utjecaja semantičkih različitih djelovanja na neurološki prevod strojeva</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>A zajon túl: a finomszemű szemantikus eltérések idegi fordításra gyakorolt hatásának enyhítése</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Առաջ աղմուկից' նվազեցնել նրբագեղ սեմատիկ տարբերությունների ազդեցությունը նյարդային մեքենաների թարգմանման վրա</a>
<a id=id_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Beyond Noise: Mitigating the Impact of Fine-grained Semantic Divergences on Neural Machine Translation</a>
<a id=is_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Oltre il rumore: mitigare l'impatto delle divergenze semantiche a grana fine sulla traduzione automatica neurale</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>ノイズを超えて：神経機械翻訳における細かいセマンティックの乖離の影響を軽減する</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Learn Mode</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>ჩუდის გარეშე: ჩუდის სიმენტიკური განსხვავებების შესაძლებლობას შემდეგ შემცირება</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Дыбыс үстінен: Нейрондық машинаның аудармасындағы семантикалық дивергенциялардың нәтижесін шектеу</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>소음 초월: 세립도 의미 차이 감소 신경기계 번역에 미친 영향</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Beyond Noise: Mitigation of the impact of Fine-grained Semantic Divergences on Neural Machine Translation</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Покрај бучавата: олеснување на влијанието на фино растените семантични разлики врз преведувањето на невралните машини</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>നെയുറല്‍ മെഷീന്‍ പരിഭാഷപ്പെടുത്തുന്നതില്‍ സെമാന്റിക് ഡിവര്‍ജെന്‍സുകളുടെ പ്രവര്‍ത്തനത്തെ കുറ്റം ചെയ്യുന്നു</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Дугаас гадна: Сэтгэл Машины хөгжүүлэлт дээр сайн тарианы үр дүнг багасгах</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Beyond Noise: Mitigating the Impact of Fine-grained Semantic Divergences on Neural Machine Translation</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Lil hinn mill-istorbju: It-taffija tal-impatt tad-Diverġenzi Semantiċi b’Ħruġ Fin fuq it-Traduzzjoni tal-Magni Newrali</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Behalve ruis: het verminderen van de impact van fijnkorrelige semantische divergenties op neurale machinevertaling</a>
<a id=no_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Utan støy: Gjennomsikt effekten av fingrenserte semantiske forskjeller på neuralmaskineoversettelsa</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Poza hałasem: łagodzenie wpływu drobnoziarnistych rozbieżności semantycznych na neuronowe tłumaczenie maszynowe</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Além do ruído: mitigando o impacto das divergências semânticas refinadas na tradução automática neural</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Dincolo de zgomot: atenuarea impactului divergențelor semantice cu granule fine asupra traducerii automate neurale</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Beyond Noise: Смягчение влияния мелкозернистых семантических расхождений на нейронный машинный перевод</a>
<a id=si_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>ශීරයක් වලින්: හොඳ සිමාන්තික විවෘත්තියක් ගැන ප්‍රතිචාරයක් සිමාන්තික විවෘත්තියක් නිර්මාණය</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Zunaj hrupa: ublažitev vpliva drobnozrnatih semantičnih razlik na živčni strojni prevod</a>
<a id=so_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Border Noise: Mitigating the Impact of Fine-grained Semantic Digences on Neural machine Translation</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Përtej zhurmës: Mjaftimi i ndikimit të Divergjencave Semantike me kokërra të bukura mbi përkthimin e makinës nervore</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Iza glasa: Smanjivanje utjecaja semantičnih različitih djelovanja na neurološki prevod mašine</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Bortom buller: Minska effekterna av finkorniga semantiska avvikelser på neural maskinöversättning</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Zaidi ya Noise: Kuzuia madhara ya Utafiti wa Kisemantiki unaofanywa vizuri kwenye Tafsiri ya Mashine ya Neural</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>குறிப்புக்குப் பின்: புதிய இயந்திரம் மொழிபெயர்ப்பில் நல்ல பிடிக்கப்பட்ட செமாண்டிக் வித்தியின் விளைவு</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Ses ertesi:</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>صدا کے بعد: نیورل ماشین ترجمہ پر نیک دانے کے سیمنٹی مختلف اثرات کو مٹیجیٹ کرنا</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Name</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>Vượt qua tiếng ồn: giảm tác động của các phân biệt trung học vùng fine trên phiên dịch máy thần kinh</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2021.acl-long.562.pdf>越噪声:轻细粒度语义散神经机器翻译</a></h2><p class=lead><a href=/people/e/eleftheria-briakou/>Eleftheria Briakou</a>,
<a href=/people/m/marine-carpuat/>Marine Carpuat</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>While it has been shown that Neural Machine Translation (NMT) is highly sensitive to noisy parallel training samples, prior work treats all types of mismatches between source and target as <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noise</a>. As a result, it remains unclear how samples that are mostly equivalent but contain a small number of semantically divergent tokens impact NMT training. To close this gap, we analyze the impact of different types of fine-grained semantic divergences on Transformer models. We show that <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> trained on synthetic divergences output degenerated text more frequently and are less confident in their predictions. Based on these findings, we introduce a divergent-aware NMT framework that uses factors to help NMT recover from the degradation caused by naturally occurring divergences, improving both translation quality and model calibration on EN-FR tasks.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Alhoewel dit vertoon is dat Neurale Masjien Vertaling (NMT) baie sensitief is tot geluide parallele onderwerking voorbeelde, vooraf werk behandel alle tipes ongelukkige ooreenstemmings tussen bron en doel as geluid. As 'n resultaat, bly dit onbekend hoe voorbeelde wat meeste gelykbaar is, maar bevat 'n klein aantal semantiese divergente tekens invloek van NMT-oefening. Om hierdie gap te sluit, analyseer ons die effekt van verskillende tipes van fine-grained semantiese divergensies op Transformer-modelles. Ons wys dat modele op sintetiese divergensies uitvoer gedegenereerde teks meer dikwels en is minder vertrou in hulle voorskoude. Basies op hierdie gevinde, introduseer ons 'n verskillende-bekende NMT raamwerk wat faktore gebruik om NMT te herstel van die verskilding wat veroorsaak word deur natuurlik verskillende verskilinge, verbeter beide vertaling kwaliteit en model kalibrering op EN-FR-opdragte.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>የኔural machine ትርጓሜ (NMT) በማሰናከል ተማሪ ምሳሌዎችን ለማሰናከል እጅግ አስተዋይ እንደሆነ ሲታየው፣ አስቀድሞ ሥራው በምዕራብ እና በማሰናከል መካከል የክፋት ዓይነት ሁሉ ድምፅ ነው፡፡ ስለዚህ ምሳሌዎች አብዛኛውን እንዴት እንደሚተያያዩ ነገር ግን የተለየ ጥያቄ የNMT ትምህርት ማቀናቀል የሚያስፈልገው ትንሽ ጥያቄ የሚቆጠሩ ምልክቶች ይኖራሉ፡፡ ይህንን ስፋት ለመዝጋት፣ የተለያዩ ዓይነቶች የስሜኒካዊ ግንኙነት በተለየ በቴንቨርስቲካ ዓይነቶች ላይ እናስተምር፡፡ እናሳያቸዋለን የሲንቲካዊ ግንኙነት አካባቢ ጽሑፎችን አብዛኛውን እናስታውቃለን፡፡ እነዚህን ፍጥረቶች በመሠረት፣ የNMT ፍሬማር በሥርዓት ግንኙነት ከታዋቂው ውርደት እንዲያድግ እና በEN-FR ስርዓቶች ላይ ትርጓሜ ጥያቄ እና የሞዴል ክሊተርሚት ማድረግ የሚጠቅመውን አነስተኛል፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>بينما ثبت أن الترجمة الآلية العصبية (NMT) حساسة للغاية لعينات التدريب الموازية الصاخبة ، فإن العمل السابق يتعامل مع جميع أنواع عدم التطابق بين المصدر والهدف كضوضاء. نتيجة لذلك ، لا يزال من غير الواضح كيف تؤثر العينات المتكافئة في الغالب ولكنها تحتوي على عدد صغير من الرموز المميزة المتباينة لغويًا على تدريب NMT. لسد هذه الفجوة ، نقوم بتحليل تأثير أنواع مختلفة من الاختلافات الدلالية الدقيقة على نماذج المحولات. نظهر أن النماذج المُدرَّبة على الاختلافات التركيبية تُخرج نصًا منحطًا بشكل أكثر تكرارًا وتكون أقل ثقة في تنبؤاتها. بناءً على هذه النتائج ، نقدم إطار عمل NMT مدرك للتباين يستخدم عوامل لمساعدة NMT على التعافي من التدهور الناجم عن الاختلافات التي تحدث بشكل طبيعي ، وتحسين جودة الترجمة ومعايرة النموذج في مهام EN-FR.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Neural Machine Translation (NMT) səslə parallel təhsil örnəklərinə çox duyarlıdır, əvvəlki işlər mənbə və məqsəd arasındakı hər cür müqayisədə səs kimi təhsil edir. Növbəti olaraq, çox ekvivalent nümunələrin necə olduğunu bilmir, amma NMT təhsil təhsil etməsində küçük bir neçə semantik dəyişiklik əlamətlərinin etkisi vardır. Bu boşluğu kapatmaq üçün, Transformer modellərinin müxtəlif təsirlərinin etkisini analiz edirik. Biz sintetik dəyişikliklər üzərində təhsil edilən modellərin daha çox degener metinlərini və onların tədbirlərinə daha az güvenilir. Bu tapındıqların üstündə, biz müxtəlif xəbərdar NMT framework ünü təşkil edirik ki, NMT'nin doğal tərzlərindən fərqləndirilənlərdən NMT'nin yenilənməsinə kömək etmək üçün faktorlarını istifadə edir, EN-FR işlərində tercümə keyfiyyətini və modellərin kalibrəsini yaxşılaşdırır.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Въпреки че е доказано, че невралният машинен превод (НМТ) е силно чувствителен към шумни паралелни проби за обучение, предишната работа третира всички видове несъответствия между източника и целта като шум. В резултат на това остава неясно как образците, които са предимно еквивалентни, но съдържат малък брой семантично различаващи се символи, оказват влияние върху обучението по НМТ. За да запълним тази празнина, анализираме въздействието на различните видове фини семантични дивергенция върху моделите на трансформаторите. Показваме, че моделите, обучени върху синтетични дивергенции, произвеждат дегенерирал текст по-често и са по-малко уверени в своите прогнози. Въз основа на тези констатации, ние въвеждаме дивергентна рамка за НМТ, която използва фактори, за да помогне на НМТ да се възстанови от деградацията, причинена от естествено възникващи отклонения, като подобрява както качеството на превода, така и калибрирането на модела по задачите.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>যদিও এটি দেখা যাচ্ছে যে নিউরাল মেশিন অনুবাদ (এনএমটি) শব্দের প্যারালেল প্রশিক্ষণের উদাহরণের জন্য অত্যন্ত সংবেদনশীল, কাজের পূর্বে সূত্র এবং লক্ষ এর ফলে এটা এখনো পরিষ্কার যে নমুনা বেশীরভাগ সমতুল্য কিন্তু এনএমটি প্রশিক্ষণের প্রভাব ফেলে রাখে সামান্য সংখ্যার মধ্যে। এই বিভ্রান্তি বন্ধ করার জন্য আমরা বিভিন্ন ধরনের ভিন্ন ধরনের ভিন্ন ধরনের ভিন্ন ভিন্ন ভিন্ন ধরনের প্রভাব বিশ্লেষণ করি। আমরা দেখাচ্ছি যে মডেল সিন্টেটিক বিভিন্ন বিভিন্ন আউটপুটের প্রশিক্ষণ প্রদান করা হয়েছে এবং তাদের ভবিষ্যদ্বাণীতে কম নি এইসব আবিস্কারের ভিত্তিতে আমরা একটি বিভিন্ন পরিচিত এনএমটি ফ্রেমের চিহ্নিত করি যা এনএমটি কার্যক্রম ব্যবহার করে স্বাভাবিক ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভিন্ন ভ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>རང་ཉིད་ཀྱི་མིའི་ལག་འཁྱེར་གྱི་སྐད་ཡིག་ཆ་ལྟ་བུའི་དཔེ་བརྗོད་པར་ཆས་མཐུན་པས། གཟུགས་བ་འདི་ལྟ་བུའི་ནང་དུ་མི་ཤེས་པ་ཡིན་པས། དཔེ་དབྱིབས་རྩལ་ཆེ་ཆུང་ཉུང་ཡོད་ནའང་semantically་འགྱུར་བའི་གྲངས་ཀ་ཆུང་ཀུ་ཡོད། བར་སྟོང་འདི་སྒོ་རྒྱག་དགོས་ན། ང་ཚོས་རྣམས་མེད་པའི་དབྱེ་བ་མིན་འདུག་གི་གནོད་འགུལ་གྱི་རྒྱུ་དངོས་ལ། We show that models trained on synthetic divergences output degenerated text more frequently and are less confident in their predictions. འུ་ཅག་གིས་མཐོང་སྣང་འདི་དག་ལ་གཞི་བརྟེན་ནས་(divergent-aware NMT)རྩ་གཞི་འདི་དག་ལས་ཕན་འབྱུང་རྒྱུ་བ་ཞིག་སྤྲོད་ཀྱི་ཡོད་པ་ལས་ཕན་རྐྱེན་བཟོ་བ་རྒྱུ་དང་།</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Iako je pokazalo da je neurološki prevod mašine (NMT) veoma osjetljiv na uzorke buke paralelne obuke, prije nego što je rad tretirao sve vrste nesklade između izvora i cilja kao buku. Kao rezultat toga, još uvijek nije jasno kako su uzorci uglavnom ekvivalenti, ali sadrže mali broj semantički različitih znakova utjecaja na obuku NMT-a. Da bi zatvorili ovu prazninu, analiziramo uticaj različitih vrsta semantičkih razlika na modele transformera. Pokazujemo da su modeli obučeni na izlazu sintetičkih razlika češće degenerirani tekst i manje uvjereni u njihove predviđanja. Na temelju tih nalaza, predstavljamo okvir NMT-a koji koristi faktore kako bi pomogli NMT da se oporavi iz degradacije uzrokovane prirodnim razlikama, poboljšavanje kvalitete prevoda i kalibracije modela na zadatke EN-FR-a.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>While it has been shown that Neural Machine Translation (NMT) is highly sensitive to noisy parallel training samples, prior work treats all types of mismatches between source and target as noise. Com a resultat, encara no és clar com les mostres que són majoritàriament equivalents però contenen un petit nombre de mostres semànticament divergents afecten l'entrenament en NMT. Per acabar amb aquest buit, analitzem l'impacte de diferents tipus de divergències semàntiques fins a grans sobre els models Transformer. Mostrem que els models entrenats en divergències sintètiques produeixen text degenerat de manera més freqüent i tenen menys confiança en les seves prediccions. Sobre la base d'aquests descobriments, introduim un marc NMT conscient divergent que utilitza factors per ajudar a recuperar-se de la degradació causada per divergències naturals, millorant la qualitat de la traducció i la calibració del model de les tasques EN-FR.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Zatímco bylo prokázáno, že neuronový strojový překlad (NMT) je vysoce citlivý na hlučné paralelní tréninkové vzorky, předchozí práce považuje všechny typy nesouladů mezi zdrojem a cílem za šum. V důsledku toho zůstává nejasné, jak vzorky, které jsou většinou ekvivalentní, ale obsahují malý počet sémanticky divergentních tokenů ovlivňují NMT trénink. Abychom tuto mezeru uzavřeli, analyzujeme vliv různých typů jemnozrnných sémantických divergencí na transformátorové modely. Ukazujeme, že modely trénované na syntetických divergencích produkují degenerovaný text častěji a jsou méně jisté svým predikcím. Na základě těchto poznatků představujeme divergentně vědomý NMT rámec, který používá faktory, které pomáhají NMT zotavit se z degradace způsobené přirozeně vyskytujícími se divergenty, což zlepšuje jak kvalitu překladu, tak kalibraci modelu na EN-FR úlohách.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mens det er blevet påvist, at Neural Machine Translation (NMT) er meget følsom over for støjende parallelle træningsprøver, behandler tidligere arbejde alle typer mismatch mellem kilde og mål som støj. Som følge heraf er det stadig uklart, hvordan prøver, der for det meste er ækvivalente, men indeholder et lille antal semantisk divergente tokens påvirker NMT træning. For at lukke dette hul analyserer vi effekten af forskellige typer finkornede semantiske divergenser på Transformer modeller. Vi viser, at modeller, der er trænet i syntetiske divergenser, oftere udsender degenereret tekst og er mindre sikre på deres forudsigelser. På baggrund af disse resultater introducerer vi en divergerende-bevidst NMT ramme, der bruger faktorer til at hjælpe NMT med at komme sig fra nedbrydningen forårsaget af naturligt forekommende divergenser, hvilket forbedrer både oversættelseskvaliteten og modelkalibreringen på EN-FR opgaver.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Zwar hat sich gezeigt, dass die neuronale maschinelle Übersetzung (NMT) sehr empfindlich gegenüber lauten parallelen Trainingsmustern ist, doch frühere Arbeiten behandeln alle Arten von Diskrepanzen zwischen Quelle und Ziel als Rauschen. Infolgedessen bleibt unklar, wie sich Samples, die meist äquivalent sind, aber eine geringe Anzahl semantisch divergenter Token auf das NMT-Training auswirken. Um diese Lücke zu schließen, analysieren wir die Auswirkungen verschiedener Arten feinkörniger semantischer Divergenzen auf Transformer-Modelle. Wir zeigen, dass Modelle, die auf synthetischen Divergenzen trainiert sind, häufiger degenerierten Text ausgeben und weniger zuversichtlich in ihre Vorhersagen sind. Basierend auf diesen Erkenntnissen führen wir ein divergent-bewusstes NMT-Framework ein, das Faktoren verwendet, um NMT zu helfen, sich von der Degradation zu erholen, die durch natürlich auftretende Divergenzen verursacht wird, was sowohl die Übersetzungsqualität als auch die Modellkalibrierung bei EN-FR-Aufgaben verbessert.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ενώ έχει αποδειχθεί ότι η Νευρική Μηχανική Μετάφραση (NMT) είναι ιδιαίτερα ευαίσθητη σε θορυβώδη δείγματα παράλληλης εκπαίδευσης, προηγούμενες εργασίες αντιμετωπίζουν όλους τους τύπους των παρεκκλίσεων μεταξύ πηγής και στόχου ως θόρυβο. Ως αποτέλεσμα, παραμένει ασαφές πώς τα δείγματα που είναι ως επί το πλείστον ισοδύναμα αλλά περιέχουν έναν μικρό αριθμό σημασιολογικά αποκλίνων σημάτων επηρεάζουν την εκπαίδευση NMT. Για να καλυφθεί αυτό το χάσμα, αναλύουμε την επίδραση διαφορετικών τύπων λεπτόκοκκων σημασιολογικών αποκλίσεων στα μοντέλα μετασχηματιστών. Δείχνουμε ότι μοντέλα εκπαιδευμένα σε συνθετικές αποκλίσεις παράγουν πιο συχνά εκφυλισμένο κείμενο και είναι λιγότερο σίγουροι για τις προβλέψεις τους. Με βάση αυτά τα ευρήματα, εισάγουμε ένα πλαίσιο που χρησιμοποιεί παράγοντες για να βοηθήσει την NMT να ανακτήσει από την υποβάθμιση που προκαλείται από φυσικά εμφανιζόμενες αποκλίσεις, βελτιώνοντας τόσο την ποιότητα της μετάφρασης όσο και τη βαθμονόμηση του μοντέλου σε εργασίες EN-FR.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Si bien se ha demostrado que la traducción automática neuronal (NMT) es muy sensible a las muestras de entrenamiento paralelas ruidosas, trabajos anteriores tratan todos los tipos de desajustes entre la fuente y el objetivo como ruido. Como resultado, sigue sin estar claro cómo las muestras que son en su mayoría equivalentes pero que contienen un pequeño número de tokens semánticamente divergentes afectan el entrenamiento de NMT. Para cerrar esta brecha, analizamos el impacto de diferentes tipos de divergencias semánticas de grano fino en los modelos Transformer. Demostramos que los modelos entrenados en divergencias sintéticas generan texto degenerado con mayor frecuencia y tienen menos confianza en sus predicciones. Sobre la base de estos hallazgos, introducimos un marco de NMT sensible a la divergencia que utiliza factores para ayudar a la NMT a recuperarse de la degradación causada por las divergencias naturales, mejorando tanto la calidad de la traducción como la calibración del modelo en las tareas EN-FR.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kuigi on tõestatud, et neuraalne masintõlge (NMT) on väga tundlik mürakate paralleelsete treeningnäidiste suhtes, käsitletakse eelnevates töödes kõiki allika ja sihtmärgi vahelisi ebakõlasid mürana. Sellest tulenevalt jääb ebaselgeks, kuidas mõjutavad NMT koolitust enamasti samaväärsed, kuid sisaldavad väikest arvu semantiliselt erinevaid märke. Selle lõhe kõrvaldamiseks analüüsime eri tüüpi peeneteraliste semantiliste erinevuste mõju Transformeri mudelitele. Näitame, et sünteetiliste lahknevuste kohta koolitatud mudelid väljastavad teksti sagedamini degenereerunud ja on oma prognoosides vähem kindlad. Nende tulemuste põhjal tutvustame erinevat teadlikku NMT raamistikku, mis kasutab faktoreid, et aidata NMT taastuda looduslikest erinevustest tingitud lagunemisest, parandades nii tõlkekvaliteeti kui ka mudeli kalibreerimist EN-FR ülesannete puhul.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>در حالی که نشان داده شده که ترجمه ماشین عصبی (NMT) بسیار حساس به نمونه‌های آموزش‌های متفاوتی صوتی است، پیش از کار همه نوع مخالفت بین منبع و هدف به عنوان صدا درمان می‌کند. در نتیجه، نمونه‌های بیشتر برابر هستند، ولی تعداد کوچک نشانه‌های متفاوتی از semantically متفاوت بر آموزش NMT تاثیر می‌دهد. برای بستن این فاصله، ما تاثیر نوع متفاوتی از متفاوت‌های طبیعی به مدل‌های تغییر‌دهنده تحلیل می‌کنیم. ما نشان می دهیم که مدل های آموزش روی متفاوت های متفاوتی متفاوت بیشتر از اوضاع متفاوت نابود شده و کمتر به پیش بینی های آنها اعتماد دارند. Based on these findings, we introduce a different NMT framework that uses factors to help NMT recover from the degradation caused by natural differences occurring, improving both translation quality and model calibration on EN-FR tasks.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vaikka on osoitettu, että neurokonekäännös (NMT) on erittäin herkkä meluisille rinnakkaisille harjoitusnäytteille, aiemmassa työssä käsitellään kaikenlaisia lähteen ja kohteen välisiä eroja meluna. Tämän seurauksena on epäselvää, miten näytteet, jotka ovat enimmäkseen samanarvoisia mutta sisältävät pienen määrän semanttisesti poikkeavia merkkejä, vaikuttavat NMT-koulutukseen. Tämän aukon korjaamiseksi analysoimme erityyppisten hienorakeisten semanttisten eroavuuksien vaikutusta Transformer-malleihin. Osoitamme, että synteettisiin eroavuuksiin koulutetut mallit tuottavat huonontunutta tekstiä useammin ja ovat vähemmän luottavaisia ennustuksiinsa. Näiden löydösten pohjalta esittelemme erilaisesti tietoisen NMT-viitekehyksen, joka käyttää tekijöitä auttaakseen NMT:tä toipumaan luonnossa esiintyvien eroavuuksien aiheuttamasta hajoamisesta parantaen sekä käännöslaatua että mallin kalibrointia EN-FR-tehtävissä.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bien qu'il ait été démontré que la traduction automatique neuronale (NMT) est très sensible aux échantillons d'apprentissage parallèles bruités, des travaux antérieurs traitent tous les types de discordance entre la source et la cible comme du bruit. Par conséquent, on ne sait toujours pas comment les échantillons qui sont pour la plupart équivalents mais qui contiennent un petit nombre de jetons sémantiquement divergents ont un impact sur la formation NMT. Pour combler cet écart, nous analysons l'impact de différents types de divergences sémantiques fines sur les modèles Transformer. Nous montrons que les modèles formés sur des divergences synthétiques produisent plus fréquemment du texte dégénéré et sont moins confiants dans leurs prévisions. Sur la base de ces résultats, nous introduisons un cadre NMT sensible aux divergences qui utilise des facteurs pour aider le NMT à se remettre de la dégradation causée par les divergences naturelles, améliorant à la fois la qualité de la traduction et l'étalonnage du modèle sur les tâches EN-FR.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Cé go bhfuil sé léirithe go bhfuil Neural Machine Translation (NMT) an-íogair do shamplaí oiliúna comhthreomhara fuaimiúla, déileálann réamhobair le gach cineál neamhréire idir foinse agus sprioc mar thorann. Mar thoradh air sin, níl sé soiléir cén chaoi a mbíonn tionchar ag samplaí atá comhionann den chuid is mó ach a bhfuil líon beag de chomharthaí atá éagsúil go seimeantach ar oiliúint NMT. Chun an bhearna seo a dhúnadh, déanaimid anailís ar an tionchar atá ag cineálacha éagsúla éagsúlachtaí séimeantacha míne ar mhúnlaí Trasfhoirmeora. Léirímid go n-aschuireann samhlacha atá oilte ar éagsúlachtaí sintéiseacha téacs meathlaithe níos minice agus nach bhfuil siad chomh muiníneach as a gcuid tuartha. Bunaithe ar na torthaí seo, tugaimid isteach creat NMT atá feasach ar éagsúlacht a úsáideann fachtóirí chun cabhrú le NMT téarnamh ón díghrádú a tharlaíonn de bharr éagsúlachtaí a tharlaíonn go nádúrtha, ag feabhsú cáilíocht an aistriúcháin agus calabrú samhlacha ar thascanna EN-FR.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A lõkacin da aka nuna Translate na Mashine na Neural (NMT) yana mai sauti wa misãlai masu tsari da parallel, kafin aiki na tunkuɗe duk nau'in misfitai tsakanin source da goa kamar sauti. Haƙĩƙa, ba ya kasa da jinsi misãlai masu daidaita ko kuma ana ƙunsa da ƙidãyar ko da ãyõyi masu diffdi na semantically-diffraɗe ta yi amfani da shirin NMT. Dõmin ya rufe wannan gap, za mu yi anayya ga matsayin nau'i-nau'i-nau'i mai kyau na samu'in diffaniki kan misãlai na Transformer. Tuna nũna wa misãlai wanda aka yi wa shirin a kan diffukan sigarin da suka nuna matsayin da aka yi sauri sauri ko da yawa kuma ba su zama masu ƙaranci ba ga bayanin su. Based on these findings, we introduce a divergent-aware NMT framework that uses factors to help NMT recover from the degradation caused by naturally occurring divergences, improving both translation quality and model calibration on EN-FR tasks.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>While it has been shown that Neural Machine Translation (NMT) is highly sensitive to noisy parallel training samples, prior work treats all types of mismatches between source and target as noise. As a result, it remains unclear how samples that are mostly equivalent but contain a small number of semantically divergent tokens impact NMT training. To close this gap, we analyze the impact of different types of fine-grained semantic divergences on Transformer models. אנחנו מראים שדוגמנים מאומנים על מגוונים סינטטיים יוציאים טקסט משוגע יותר לעתים קרובות והם פחות בטוחים בחזויות שלהם. בהתבסס על הממצאים האלה, אנחנו מכירים מסגרת NMT מודעת שונה אשר משתמשת בגורמים כדי לעזור NMT להתאושש מהפיצול שנגרם ע"י פיצולים מתרחשים באופן טבעי, לשפר את איכות התרגום וכמודל קליברציה על משימות EN-FR.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>हालांकि यह दिखाया गया है कि न्यूरल मशीन ट्रांसलेशन (एनएमटी) शोर समानांतर प्रशिक्षण नमूनों के प्रति अत्यधिक संवेदनशील है, पूर्व कार्य स्रोत और लक्ष्य के बीच सभी प्रकार के बेमेलों को शोर के रूप में मानता है। नतीजतन, यह स्पष्ट नहीं है कि नमूने जो ज्यादातर बराबर होते हैं लेकिन उनमें थोड़ी संख्या में शब्दार्थ रूप से अलग-अलग टोकन होते हैं, एनएमटी प्रशिक्षण को कैसे प्रभावित करते हैं। इस अंतर को बंद करने के लिए, हम ट्रांसफॉर्मर मॉडल पर विभिन्न प्रकार के ठीक-ठीक शब्दार्थ विचलन के प्रभाव का विश्लेषण करते हैं। हम दिखाते हैं कि सिंथेटिक विचलन पर प्रशिक्षित मॉडल अधिक बार विघटित पाठ आउटपुट करते हैं और उनकी भविष्यवाणियों में कम आत्मविश्वास रखते हैं। इन निष्कर्षों के आधार पर, हम एक अलग-अलग-जागरूक एनएमटी फ्रेमवर्क पेश करते हैं जो एनएमटी को स्वाभाविक रूप से होने वाले विचलन के कारण गिरावट से उबरने में मदद करने के लिए कारकों का उपयोग करता है, एन-एफआर कार्यों पर अनुवाद की गुणवत्ता और मॉडल अंशांकन दोनों में सुधार करता है।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Iako je pokazalo da je neurološki prevod strojeva (NMT) jako osjetljiv na uzorke buke paralelne vježbe, prije rada tretira sve vrste nesklade između izvora i cilja kao buku. Kao rezultat toga, još uvijek nije jasno kako su uzorci uglavnom ekvivalenti ali sadrže mali broj semantički različitih znakova utjecaja na obuku NMT-a. Da bi zatvorili taj praznik, analizirali smo utjecaj različitih vrsta semantičkih različitih različitih na modele transformera. Pokazujemo da su modeli obučeni na izlazu sintetičkih različitih različitih proizvoda češće degenerirani tekst i manje uvjereni u njihove predviđanje. Na temelju tih nalaza, predstavljamo okvir NMT-a koji koristi faktore kako bi se NMT vratio iz degradacije uzrokovanog prirodnim razlikama, poboljšali kvalitetu prevoda i kalibraciju modela na zadatke EN-FR-a.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bár kimutatták, hogy a Neural Machine Translation (NMT) rendkívül érzékeny a zajos párhuzamos edzési mintákra, az előző munkák zajként kezelik a forrás és a cél közötti összes típusú eltérést. Ennek eredményeképpen továbbra sem világos, hogy a többnyire egyenértékű, de kis számú szemantikailag eltérő tokent tartalmazó minták milyen hatással vannak az NMT képzésre. Ennek a szakadéknak a bezárása érdekében elemezzük a finomszemcsés szemantikai eltérések különböző típusainak hatását a Transformer modellekre. Megmutatjuk, hogy a szintetikus eltérésekre képzett modellek gyakrabban eredményeznek degenerált szöveget, és kevésbé bíznak az előrejelzéseikben. Ezen eredmények alapján bevezetünk egy eltérő tudatos NMT keretrendszert, amely tényezőket használ arra, hogy segítse az NMT regenerálódását a természetes eltérések okozta lebomlásból, javítva mind a fordítási minőséget, mind pedig a modell kalibrálását az EN-FR feladatokban.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Մինչդեռ ցույց է տվել, որ նյարդային մեքենայի թարգմանությունը (NMT) շատ զգայուն է աղմկոտ զուգահեռ ուսումնասիրության նմուշների նկատմամբ, նախորդ աշխատանքը աղբյուրի և նպատակի միջև բոլոր տեսակի անհամապատասխանություններ վերաբեր Արդյունքում, դեռևս անհասկանալի է, թե ինչպես են նմուշները, որոնք հիմնականում հավասար են, բայց պարունակում են մի փոքր քանակ սեմանտիկապես տարբեր նմուշներ ազդում NMT-ի ուսուցման վրա: Այս տարբերությունը փակելու համար մենք վերլուծում ենք տարբեր տեսակի գեղեցիկ սեմանտիկ տարբերությունների ազդեցությունը տրանֆորմային մոդելների վրա: We show that models trained on synthetic divergences output degenerated text more frequently and are less confident in their predictions. Հաշվի առնելով այս բացահայտումներին, մենք ներկայացնում ենք տարբեր գիտակցած NMT-ի շրջանակը, որը օգնում է NMT-ին վերականգնվել բնական տարբերությունների պատճառով առաջացած դեգրադացիայից, բարելավելով անգամ թարգմանման որակը, ինչպես նաև կալիբրացման մոդելը, երբ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Sementara telah menunjukkan bahwa Translation Neural Machine (NMT) sangat sensitif kepada sampel pelatihan paralel berisik, pekerjaan sebelumnya memperlakukan semua jenis ketidakcocokan antara sumber dan sasaran sebagai suara. Sebagai hasilnya, masih tidak jelas bagaimana sampel yang kebanyakan sama tapi mengandung sejumlah kecil token semantis divergent mempengaruhi pelatihan NMT. Untuk menutup ruang ini, kami menganalisis dampak dari jenis berbeda dari divergensi semantis berbeda-baik pada model Transformer. We show that models trained on synthetic divergences output degenerated text more frequently and are less confident in their predictions. Berdasarkan penemuan-penemuan ini, kami memperkenalkan rangka NMT yang sadar divergent yang menggunakan faktor untuk membantu NMT pulih dari degradasi disebabkan oleh divergensi yang terjadi secara alami, meningkatkan kualitas terjemahan dan kalibrasi model pada tugas EN-FR.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mentre è stato dimostrato che la traduzione automatica neurale (NMT) è altamente sensibile ai campioni di allenamento paralleli rumorosi, i lavori precedenti trattano tutti i tipi di disallineamenti tra sorgente e bersaglio come rumore. Di conseguenza, non è chiaro come i campioni che sono per lo più equivalenti ma contengono un piccolo numero di token semanticamente divergenti influiscano sulla formazione NMT. Per colmare questo gap, analizziamo l'impatto di diversi tipi di divergenze semantiche a grana fine sui modelli Transformer. Mostriamo che i modelli formati sulle divergenze sintetiche producono testo degenerato più frequentemente e sono meno fiduciosi nelle loro previsioni. Sulla base di questi risultati, introduciamo un framework NMT divergente-aware che utilizza fattori per aiutare NMT a recuperare dalla degradazione causata da divergenze naturali, migliorando sia la qualità della traduzione che la calibrazione del modello sulle attività EN-FR.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>神経機械翻訳（ NMT ）は、ノイズの多い並列トレーニングサンプルに対して非常に敏感であることが示されているが、先行研究では、ソースとターゲットの間のあらゆるタイプのミスマッチをノイズとして扱っている。その結果、ほとんど同等であるが、意味的に乖離した少数のトークンを含むサンプルがNMTトレーニングにどのような影響を与えるかは不明のままである。このギャップを埋めるために、異なるタイプの細かいセマンティック発散がトランスフォーマーモデルに与える影響を分析します。合成発散に関する訓練を受けたモデルは、テキストを出力する頻度が高くなり、予測に自信がないことが示されています。これらの知見に基づいて、私たちは、自然発生の乖離によって引き起こされる劣化からNMTを回復するのに役立つ因子を使用し、EN - FRタスクの翻訳品質とモデルの較正の両方を改善する、乖離を認識したNMTフレームワークを導入します。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Anyone wis dipoleh kanggo ngerasakno itokke maneh (NMT) Yo wis dipoleh, dadi kuwi ora ngerasakno dadi sinar tentang karo ngono ngangge ulih dumadhi sematik tarjamahan Genjer-genjer diunting langgampun iki, kita tah cara perusahaan penting nggawe sistem semanti-perusahaan kanggo model Transformer. Awak dhéwé éntuk model sing beraksi lan akeh sistem sing luwih dumaten teks ditambah barang langgar sampek kuwi mau. Ngawe jenis-jenis awak dhéwé, kita nggunakake sistem NMT sing wis ngawe barang karo pakem nganggep ngéwangi tanggal NMT seneng nggawe gerakan kelangan karo perusahaan tanggal nggapiane winih dhéwé, iso nglanggar kuwi tanggal nggawe tarjamahan karo kalibrasi model nang nggawe lan cara nggawe</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>როცა ჩვენ ჩვენებულია, რომ ნეიროლური მაქსინის გარგზავნა (NMT) ძალიან სიგრძნელი პარალელური გარგზავნის ჩაწერებისთვის, პირველი სამუშაო ყველა ტიპების გარგზავნის შემდეგ როგორც შედეგი, ეს უცნობიერია, როგორ ჩანაწერები, რომლებიც უფრო ეკვალენტურია, მაგრამ არსებობს პატარა რაოდენობა სმენტიკურად განსხვავებული სიმბოლოების ამ განსხვავებას დახურებისთვის, ჩვენ განსხვავებული ტიპის სემონტიკური განსხვავებების განსხვავებას განსხვავებთ ტრანფორმეტრის მოდელზე. ჩვენ ჩვენ აჩვენებთ, რომ მოდელები სინტეტიკური განსხვავებების გამოყენებაში უფრო მეტი განსხვავებული ტექსტი და უფრო მეტი დარწმუნებულია მათი წარმოდგენება ჩვენ განვითარებით განსხვავებული NMT ფრამეტრის გამოყენება, რომელიც გამოყენებს ფრამეტრები, რომელიც NMT განსხვავებას განსხვავებული განსხვავებებისგან გამოიყენება, რომელიც განსხვავებული კალიბრებას და მოდელური კალიბრებას EN-FR</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Нейрондық машинаның аудармасы (NMT) дыбыс параллелі оқыту үлгілеріне өте сезімді, алдындағы жұмыс көзі мен мақсаттың арасындағы бүкіл сәйкестік түрлерін дыбыс ретінде тұрады. Нәтижесінде, көпшілік үлгілер қандай еквивалент болып тұрғанын түсінбейді, бірақ бірнеше семантикалық диверензиялық таңбалардың саны NMT оқытуына әсер етеді. Бұл аралығын жабу үшін, Трансформалер үлгілерінде әртүрлі түрлерінің семантикалық дивергенциялардың нәтижесін анализирақ. Біз синтетикалық дивергенциялар үлгілерінде оқыту үлгілерін көбірек дегенерациялық мәтінді дегенерациялық және олардың алдындағыларына сенімді болмайды. Бұл тапсырмалардың негізінде, NMT деградациясынан қайтару үшін факторларды қолданатын NMT бағдарламасын тапсырмалардан қайтаруға көмектесетін NMT бағдарламасын тапсырмаларды өзгертіп, EN-FR тапсырмалардың аудармалардың сапасын</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>신경기계번역(NMT)이 소음이 있는 병행훈련 샘플에 고도로 민감하다는 사실이 입증됐지만, 이전 작업에서는 소스와 목표 사이의 모든 유형의 불일치를 소음으로 봤다.따라서 주요 효과는 알 수 없지만 소량의 의미가 다른 표기를 포함하는 샘플이 NMT 훈련에 어떻게 영향을 미치는지 알 수 없다.이 격차를 좁히기 위해 우리는 서로 다른 유형의 세립도 의미 차이가 변환기 모델에 미친 영향을 분석했다.우리는 합성 불일치 훈련을 바탕으로 한 모델이 퇴화 텍스트를 출력하는 빈도가 높고 예측에 대한 신뢰도가 낮다는 것을 발견했다.이러한 발견을 바탕으로 우리는 발산의식이 있는 NMT 프레임워크를 도입했다. 이 프레임워크는 각종 요소를 이용하여 NMT가 자연 발생한 발산으로 인한 퇴화에서 회복하도록 도와주고 번역의 질과 EN-FR 임무의 모델 교정을 향상시켰다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nors buvo įrodyta, kad neurologinių mašinų vertimas (NMT) yra labai jautrus triukšmingiems lygiagretaus mokymo mėginiams, atlikus ankstesnį darbą visų rūšių neatitikimai tarp šaltinio ir taikinio laikomi triukšmu. As a result, it remains unclear how samples that are mostly equivalent but contain a small number of semantically divergent tokens impact NMT training. Siekiant užkirsti kelią šiam atotrūkiui, analizuojame įvairių rūšių smulkių semantinių skirtumų poveikį Transformuotojų modeliams. Mes rodome, kad modeliai, mokomi sintetinių skirtumų išrašyti degeneruotą tekstą dažniau ir mažiau pasitiki jų prognozėmis. Remiantis šiomis išvadomis, įvedame skirtingai žinomą NMT sistemą, kurioje naudojami veiksniai, padedantys NMT atsigauti nuo natūralių skirtumų sukelto degradacijos, gerinant vertimo kokybę ir modelio kalibravimą EN-FR užduočių atžvilgiu.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>И покрај тоа што се покажа дека неуралната машина преведува (НМТ) е многу чувствителна на бучни паралелни примероци на обука, претходната работа ги третира сите видови на несогласувања помеѓу изворот и метата како бука. Како резултат на тоа, останува нејасно како примероците кои се претежно еквивалентни, но содржат мал број семантички дивергентни знаци влијаат на обуката на НМТ. To close this gap, we analyze the impact of different types of fine-grained semantic divergences on Transformer models. We show that models trained on synthetic divergences output degenerated text more frequently and are less confident in their predictions. На основа на овие откритија, воведуваме дивергентна Свесна НМТ рамка која користи фактори за да помогне НМТ да се опорави од деградацијата предизвикана од природни дивергенции, подобрувајќи го квалитетот на превод и калибрацијата на моделот на задачите на EN-FR.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>നെയുറല്‍ മെഷീന്‍ പരിഭാഷ (NMT) ശബ്ദത്തിന്റെ പാരാളില്‍ പരിശീലന പരിശീലനങ്ങള്‍ക്ക് വളരെ ശ്രദ്ധയുള്ളതാണെന്ന് തെളിയിക്കപ്പെട്ടിരിക്കുന്നു അതിന്റെ ഫലമായി, മാതൃകങ്ങള്‍ എങ്ങനെയാണ് സമമായത്, പക്ഷെ എംഎം ട്രെയിനിങ്ങള്‍ക്ക് പ്രഭാവം ഉണ്ടാക്കുന്നതെന്ന് കുറച്ച് എണ്ണി ഈ വേര്‍പ്പ് അടയ്ക്കാന്‍, നമ്മള്‍ വ്യത്യസ്ത തരത്തിലുള്ള സെമാന്റിക് വ്യത്യസ്ത വ്യത്യാസങ്ങളുടെ പ്രഭാവം അന്വേഷിക്ക നമ്മള്‍ കാണിച്ചു കൊടുക്കുന്നത് സിന്തെറ്റിക്ക് വ്യത്യസ്തമായ വ്യത്യാസങ്ങളില്‍ പരിശീലിക്കപ്പെട്ട മോഡലുകളാണെന് ഈ കണ്ടെത്തുന്നതിന് അടിസ്ഥാനമായി നമ്മള്‍ ഒരു വ്യത്യസ്തമായി അറിയുന്ന NMT ഫ്രെയിമെക്കോര്‍ട്ട് പരിചയപ്പെടുത്തുന്നു. അത് സ്വാഭാവികമായ വ്യത്യസ്ത വ്യത്യാസങ്ങളില്‍ നി</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ньюрал машины хөгжүүлэлт (NMT) нь чимээгүй параллел дасгал хөгжүүлэлтийн жишээнд маш чухал байдаг гэдгийг харуулсан ч өмнө нь ажил эх үүсвэр болон зорилго хоорондын бүх төрлийн хоорондоо чимээгүй байдлыг дуу Үүний үр дүнд, ихэнхдээ хэдэн жижиг хэмжээний шинж тэмдэг нь NMT дасгал хөдөлгөөнийг нөлөөлдөг нь тодорхой байдаг. Энэ хоорондын тулд бид Трансформер загварын өөр өөр төрлийн зэрэг зэрэг тарианы үр дүнг шинжилдэг. Бид синтетик хувьсалын талаар сургалтын загваруудыг илүү ихэвчлэн бууруулсан мөн тэдний таамаглалд итгэлтэй байдаг. Эдгээр ололтуудын үндсэнд бид NMT-г өөр өөр өөр өөр ойлголтын системийг танилцуулж, NMT-г байгалийн ялгаатай байдлын үр дүнээс бууруулахад тусалдаг хүчин зүйлсийг ашиглаж, EN-FR даалгаварын түвшинд орчуулах чадварыг болон загварын калибрийг сай</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Walaupun telah dipaparkan bahawa Penerjemahan Mesin Neural (NMT) sangat sensitif kepada sampel latihan paralel yang bunyi, kerja sebelumnya memperlakukan semua jenis ketidaksepadan antara sumber dan sasaran sebagai bunyi. Sebagai hasilnya, masih tidak jelas bagaimana sampel yang paling sama tetapi mengandungi bilangan kecil token secara semantik yang berbeza mempengaruhi latihan NMT. Untuk menutup ruang ini, kami menganalisis kesan dari jenis berbeza perbezaan semantik-benih halus pada model Transformer. Kami menunjukkan bahawa model dilatih pada pelbagai sintetik output teks degenerasi lebih sering dan kurang percaya pada ramalan mereka. Berdasarkan penemuan ini, kami memperkenalkan kerangka NMT yang sedar-berbeza yang menggunakan faktor untuk membantu NMT pulih dari degradation disebabkan oleh perbezaan yang berlaku secara alami, meningkatkan kualiti terjemahan dan kalibrasi model pada tugas EN-FR.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Filwaqt li ntwera li t-Traduzzjoni tal-Magni Newrali (NMT) hija sensittiva ħafna għal kampjuni ta’ taħriġ paralleli storbjużi, ix-xogħol preċedenti jittratta t-tipi kollha ta’ diskrepanzi bejn is-sors u l-mira bħala storbju. B’riżultat ta’ dan, għadu mhux ċar kif kampjuni li huma l-aktar ekwivalenti iżda fihom numru żgħir ta’ tokens diverġenti semantikament jaffettwaw it-taħriġ NMT. To close this gap, we analyze the impact of different types of fine-grained semantic divergences on Transformer models. Aħna nuru li mudelli mħarrġa fuq diverġenzi sintetiċi jipproduċu test deġenerat aktar ta’ spiss u huma inqas kunfidenti fit-tbassir tagħhom. Abbażi ta’ dawn is-sejbiet, a ħna nintroduċu qafas NMT li jkun konxju mid-diverġenza li juża fatturi biex jgħin lill-NMT jirkupra mid-degradazzjoni kkawżata mid-diverġenzi li jseħħu b’mod naturali, u jtejjeb kemm il-kwalità tat-traduzzjoni kif ukoll il-kalibrazzjoni tal-mudell fuq il-kompiti EN-FR.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Hoewel is aangetoond dat Neural Machine Translation (NMT) zeer gevoelig is voor lawaaierige parallelle trainingsmonsters, behandelt eerdere werkzaamheden alle soorten mismatches tussen bron en doel als ruis. Hierdoor blijft onduidelijk hoe monsters die meestal equivalent zijn maar een klein aantal semantisch divergente tokens bevatten invloed hebben op NMT training. Om deze kloof te dichten analyseren we de impact van verschillende soorten fijnkorrelige semantische divergenties op Transformer modellen. We laten zien dat modellen getraind op synthetische divergenties vaker gedegenereerde tekst produceren en minder vertrouwen hebben in hun voorspellingen. Op basis van deze bevindingen introduceren we een divergent-awarened NMT framework dat factoren gebruikt om NMT te helpen herstellen van de degradatie veroorzaakt door natuurlijk optredende divergenties, waardoor zowel de vertaalkwaliteit als de modelkalibratie op EN-FR taken worden verbeterd.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mens det er vist at nøyralmaskinsomsetjing (NMT) er svært sensitivt til støyparallelle øvingsprøver, før arbeidet behandler alle typar ikkje samsvar mellom kjelde og mål som støy. Som resultat blir det ikkje klart korleis prøver som er mest ekvivalente, men inneheld ein liten tal av semantisk divergente teikn påvirkar NMT-trening. For å lukka dette mellomrommet, analyserer vi effekten av ulike typar fine-grained semantiske forskjeller på transformeringsmodeller. Vi viser at modeller trengte på syntetiske forskjeller utdata av degenererte tekst oftast og er mindre sikker på forhåndsvisingane sine. Basert på disse opplysningane, introduserer vi eit forskjellige NMT-rammeverk som brukar faktorer for å hjelpa NMT gjenoppretta frå degradasjonen som følgjer av naturleg forskjeller, forbetra både omsetjingskvaliteten og modellekalibrering på EN-FR-oppgåver.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Chociaż wykazano, że neuronowe tłumaczenie maszynowe (NMT) jest bardzo wrażliwe na hałaśliwe równoległe próbki treningowe, wcześniejsze prace traktują wszystkie rodzaje niedopasowań między źródłem a docelowym jako hałas. W rezultacie pozostaje niejasne, w jaki sposób próbki, które są w większości równoważne, ale zawierają niewielką liczbę rozbieżnych semantycznie tokenów, wpływają na szkolenie NMT. Aby zamknąć tę lukę, analizujemy wpływ różnych typów drobnoziarnistych rozbieżności semantycznych na modele Transformera. Pokazujemy, że modele trenowane na podstawie rozbieżności syntetycznych częściej wydają zdegenerowany tekst i są mniej pewne swoich przewidywań. Na podstawie tych ustaleń wprowadzamy rozbieżne ramy NMT, które wykorzystują czynniki, aby pomóc NMT odzyskać się od degradacji spowodowanej naturalnie rozbieżnościami, poprawiając zarówno jakość tłumaczenia, jak i kalibrację modelu w zadaniach EN-FR.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Embora tenha sido demonstrado que a tradução automática neural (NMT) é altamente sensível a amostras de treinamento paralelo ruidosas, trabalhos anteriores tratam todos os tipos de incompatibilidades entre a origem e o destino como ruído. Como resultado, ainda não está claro como as amostras que são principalmente equivalentes, mas contêm um pequeno número de tokens semanticamente divergentes, afetam o treinamento do NMT. Para fechar essa lacuna, analisamos o impacto de diferentes tipos de divergências semânticas refinadas nos modelos Transformer. Mostramos que modelos treinados em divergências sintéticas produzem texto degenerado com mais frequência e são menos confiantes em suas previsões. Com base nessas descobertas, apresentamos uma estrutura NMT com reconhecimento de divergências que usa fatores para ajudar a NMT a se recuperar da degradação causada por divergências que ocorrem naturalmente, melhorando a qualidade da tradução e a calibração do modelo em tarefas EN-FR.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Deși s-a demonstrat că Neural Machine Translation (NMT) este foarte sensibil la eșantioanele de antrenament paralel zgomotoase, lucrările anterioare tratează toate tipurile de neconcordanțe între sursă și țintă ca zgomot. Ca urmare, rămâne neclar modul în care eșantioanele care sunt în mare parte echivalente, dar conțin un număr mic de jetoane divergente semantic influențează formarea NMT. Pentru a elimina acest decalaj, analizăm impactul diferitelor tipuri de divergențe semantice fine asupra modelelor Transformer. Noi arătăm că modelele instruite pe divergențe sintetice produc text degenerat mai frecvent și sunt mai puțin încrezătoare în previziunile lor. Pe baza acestor constatări, introducem un cadru NMT conștient de divergențe, care utilizează factori pentru a ajuta NMT să se recupereze din degradarea cauzată de divergențele naturale, îmbunătățind atât calitatea traducerii, cât și calibrarea modelului în sarcinile EN-FR.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Хотя было показано, что нейронный машинный перевод (НМП) очень чувствителен к шумным параллельным обучающим образцам, предыдущая работа рассматривает все типы несоответствий между источником и целью как шум. В результате остается неясным, как образцы, которые в основном эквивалентны, но содержат небольшое количество семантически расходящихся токенов, влияют на обучение НБП. Чтобы закрыть этот пробел, мы анализируем влияние различных типов мелкозернистых семантических расхождений на модели Трансформатора. Мы показываем, что модели, обученные синтетическим дивергенциям, чаще выводят вырожденный текст и менее уверены в своих прогнозах. Основываясь на этих выводах, мы вводим расходящуюся структуру NMT, которая использует факторы, чтобы помочь NMT восстановиться после деградации, вызванной естественными расхождениями, улучшая как качество трансляции, так и калибровку модели на задачах EN-FR.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ඒක පෙන්වන්න පුළුවන් වෙලා තියෙන්නේ න්‍යූරල් මැෂින් වාර්ථාපනය (NMT) ගොඩක් සංවේදනය සමාන්‍ය ප්‍රීක්ෂණා සැමැල්ම් වලට, ප්‍රතිචාරයෙන්, ඒක නැති වෙන්නේ නිර්මාණය කොහොමද සාම්ප්ලේස් එක්ක සමාන්‍යයි කියලා, නමුත් සාම්ප්ලේසිකයෙන් ප්‍ අපි මේ විශාල වහන්න, වෙනස් වර්ගයක් විශේෂ කරනවා වෙනස් වර්ගයක් විශේෂ කරලා තියෙන ප්‍රතිචාර විශේෂ ක අපි පෙන්වන්නේ මෝඩේල් සංවේදනය විදිහට ප්‍රශ්නය කරලා තියෙන්නේ ප්‍රශ්නයක් විදිහට වඩා ප්‍රශ්නයක් විදි මේ හොයාගන්න පුළුවන් විදිහට, අපි විදිහට පරීක්ෂා කරපු NMT පරීක්ෂණයක් ප්‍රයෝජනය කරනවා කියලා NMT පරීක්ෂණයෙන් ප්‍රයෝජනය කරපු විදිහට උදව් කරන්න ප්‍</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Medtem ko je bilo dokazano, da je nevralni strojni prevod (NMT) zelo občutljiv na hrupne vzorce vzporednega treninga, predhodno delo obravnava vse vrste neskladja med viri in ciljem kot hrup. Zato ostaja nejasno, kako vzorci, ki so večinoma enakovredni, vendar vsebujejo majhno število semantično različnih žetonov, vplivajo na usposabljanje NMT. Za zapolnitev te vrzeli analiziramo vpliv različnih vrst drobnozrnatih semantičnih divergenc na modele transformatorjev. Pokazali smo, da modeli, usposobljeni za sintetične divergence, izdajajo degenerirano besedilo pogosteje in so manj prepričani v svoje napovedi. Na podlagi teh ugotovitev predstavljamo različno zavedajoč se okvir NMT, ki uporablja dejavnike za pomoč NMT pri okrevanju od razgradnje, ki jo povzročajo naravne razlike, s čimer izboljšuje kakovost prevajanja in kalibracijo modela pri nalogah EN-FR.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Inta lagu muujiyo tarjumidda maskinka ee Neural (NMT) waa mid aad u xiisaysan samooyinka waxbarashada si siman ah, shaqo horay u dhaqdhaqaaqsan dhammaan noocyo qalloocan ah oo u dhexeeya sourceed iyo waxqabadka sida cod oo kale. Sababtaas darteed ma ahan sida tusaalooyinku ugu mid yihiin, laakiin waxay leedahay mid yar oo calaamado kala duwan oo ka mid ah, waxayna saameyn ku leedahay waxbarashada NMT. Si aan u xidhno gafkan, waxaynu u baaraynaa saamaynta noocyada kala duduwan oo kala duwan oo kala duduwan kala duwan oo kala duduwan dabeecada ah. Waxaynu tusnaynaa in modellada lagu tababaray wax ka baran kara qoraal kala duduwan ee muuqashada la soo degay marar badan iyo in ka yar kalsoonaan karo wixii la soo sheegay. Sida lagu saleynayo arimahan, waxaan soo bandhigaynaa firaaqad aan kala duwan oo aan aqoon lahayn NMT oo isticmaalaya waxyaabaha uu u caawinayo in NMT ka soo noqdo dhibaatada dabiicadda ka soo dhaca, oo horumarinaya qiimo turjumista iyo kalibration model oo ku saabsan shaqada EN-FR.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ndërsa është treguar se Translacioni i Makinës Neurale (NMT) është shumë i ndjeshëm ndaj muzikave të stërvitjes paralele zhurmuese, puna e mëparshme trajton të gjitha llojet e mospërputhjeve midis burimit dhe objektivit si zhurmë. Si rezultat, mbetet e paqartë se si mostrat që janë kryesisht ekvivalente por përmbajnë një numër të vogël shenjash semantikisht të ndryshme ndikojnë në trainimin e NMT. Për të mbyllur këtë boshllëk, ne analizojmë ndikimin e llojeve të ndryshme të dallimeve semantike të holla në modelet Transformer. Ne tregojmë se modelet e trajnuar në divergjenca sintetike nxjerrin tekst të degeneruar më shpesh dhe janë më pak të bindur në parashikimet e tyre. Bazuar në këto gjetje, ne futim një kuadër NMT të ndërgjegjshëm të ndryshëm që përdor faktorë për të ndihmuar NMT të rimëkëmbet nga degradimi i shkaktuar nga dallimet natyrore, duke përmirësuar si cilësinë e përkthimit ashtu dhe kalibrimin e modelit në detyrat EN-FR.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Iako je pokazalo da je neurološki prevod mašine (NMT) veoma osetljiv na uzorke buke paralelne obuke, pre posla tretira sve vrste nesklade između izvora i cilja kao buku. Kao rezultat toga, još uvek nije jasno kako su uzorci uglavnom ekvivalenti, ali sadrže mali broj semantički različitih znakova utjecaja na obuku NMT-a. Da bi zatvorili ovu prazninu, analiziramo uticaj različitih vrsta semantičkih razlika na modele transformera. Pokazujemo da su modeli obučeni na izlazu sintetičkih razlika češće degenerirani tekst i manje uvereni u njihove predviđanja. Na temelju tih nalaza, predstavljamo različite NMT okvir koji koristi faktore da pomogne NMT da se oporavi iz degradacije uzrokovane prirodnim razlikovima, poboljšavamo kvalitetu prevoda i kalibraciju model a na zadatke EN-FR-a.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Även om det har visat sig att Neural Machine Translation (NMT) är mycket känslig för bullriga parallella träningsprover, behandlar tidigare arbete alla typer av missmatchningar mellan källa och mål som buller. Som ett resultat är det fortfarande oklart hur prover som mestadels är likvärdiga men innehåller ett litet antal semantiskt avvikande tokens påverkar NMT-träning. För att överbrygga detta gap analyserar vi effekten av olika typer av finkorniga semantiska avvikelser på Transformers modeller. Vi visar att modeller tränade på syntetiska avvikelser producerar degenererad text oftare och är mindre säkra på sina förutsägelser. Baserat på dessa resultat introducerar vi ett divergent-medvetet NMT ramverk som använder faktorer för att hjälpa NMT återhämta sig från nedbrytningen orsakad av naturligt förekommande avvikelser, vilket förbättrar både översättningskvaliteten och modellkalibreringen på EN-FR uppgifter.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Wakati imeonyeshwa kuwa Tafsiri ya Mashine ya Neural (NMT) ni yenye vizuri sana kwa sampuli za mafunzo yanayopambana na kelele, kabla ya kazi inakabiliwa na aina zote za makosa kati ya chanzo na lengo kama sauti. Matokeo yake, bado haijaeleweka jinsi sampuli zinavyofanana zaidi lakini zina idadi ndogo ya ishara tofauti za kisiasa zinazoathiri mafunzo ya NMT. Ili kufungwa kwa kipindi hiki, tunachambua athari ya aina mbalimbali za tofauti za aina nzuri za mifano ya kigaidi kwenye mifano ya Transfer. Tunaonyesha kuwa mifano imefunzwa kuhusu utofauti wa utofauti wa pamoja umeongezeka mara nyingi zaidi na bado hawana imani katika matabiro yao. Kwa mujibu wa matokeo haya, tunaonyesha mfumo wa NMT unaofahamika tofauti unaotumia sababu za kusaidia NMT kupata upya kutokana na udhalilishaji unaotokana na tofauti zinazotokana na asili, kuboresha viwango vya tafsiri na mifano katika kazi za EN-FR.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>நியூரால் இயந்திரத்தின் மொழிபெயர்ப்பு (NMT) ஒலி இணைய பயிற்சி மாதிரிகளுக்கு மிகவும் உணர்வுடையதாக இருக்கிறது, முன்னால் வேலை மூலம் மற்றும் இலக்க முடிவில், அது பெரும்பாலான மாதிரிகள் எப்படி சமமாக இருக்கிறது ஆனால் குறைந்த எண்ணிக்கையில் இருக்கும் சிறிய மாறுபட்ட குறிகள் N இந்த இடைவெளி மூட வேண்டுமானால், நாம் வேறு வகைகளின் விளைவுகளை பரிசோதிக்க வேண்டும் நன்றாக பிடிக்கப்பட்ட semantic வேறுபா நாம் காண்பிக்கிறோம் மாதிரிகள் ஒருங்கிணைப்பு வெளியீடுகளில் பயிற்சி செய்யப்பட்டுள்ளது வெளியீட்டு வெளியீட இந்த கண்டுபிடிப்புகளை அடிப்படையில், நாம் ஒரு வித்தியாசமான அறிந்த NMT சட்டத்தை குறிப்பிடுகிறோம். அது காரணிகளை பயன்படுத்துகிறது என்எம்டி திரும்ப மாறுபாடுகளை இயல்பா</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Neural maşynyň terjimesiniň Sonuçta, köplenç örnekler nähili ekvivalen bolup ýok emma NMT okuwçysynyň töweregini bar. Bu boşluky ýapmak üçin, transformer modellerinde dürli görnüş semantik taýýarlaryň täsirini çözeriz. Biz sintetik çalşyrlyklarda öwrenmeli modelleriň köplenç deňleşen metin çykarýandygyny görkeýäris we olaryň tahminlerine ynamly däldigini görkeýäris. Bu tapylyklaryň üstüne görä, NMT'iň üýtgeşiklerinden çykmak üçin faktörleri ulanan farklı düşünjeli NMT çarpyşmasyna kömek etmek üçin farklı bir çarpyşma çerçevesini tapdyryp, EN-FR görevlerinde hem terjime howplygyny ýagdaýlaşdyrmak üçin üýtgedýäris.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>اگرچہ اس کو دکھایا گیا ہے کہ نیورل ماشین ترجمہ (NMT) صدا کے مطابق مشابہ ترکین نمونے کے لئے بہت حساس ہے، پہلے کام تمام مختلف طریقوں کو سورج اور موجود کے درمیان غلط مطابق سمجھتا ہے۔ اس کے نتیجے میں یہ غیر معلوم ہے کہ نمونے کس طرح برابر ہیں لیکن نمونے کے ذریعہ ایک چھوٹی سیمنٹی مختلف ٹوکینوں کو NMT تعلیم پر اثر دیتے ہیں۔ اس جگہ بند کرنے کے لئے ہم مختلف طریقوں کی تغییرات ٹرنفسر موڈل پر فرق کرتے ہیں۔ ہم دکھاتے ہیں کہ سینٹیسی ڈیورٹیسی ڈیورٹیسی ڈیورٹیسی ڈیورٹیس کے ذریعہ آموزش کئے گئے ہیں اور ان کی پیش بینی میں کم یقین رکھتے ہیں۔ یہ نتیجے پر، ہم ایک مختلف غیر جاننے والی NMT فرمیک کو معرفی کرتے ہیں جو NMT کو دھوکا کرنے کی مدد کرنے کے لئے فاکتوروں کو استعمال کرتا ہے، جن کی وجہ سے طبیعی طرح مختلف ہوتی ہے، انٹر کے کاموں پر ترجمہ کی کیفیت اور موڈل کی kaliبریزی improving کرتی ہے.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Agar belgilansa, Neural Mashine tarjima qilish (NMT) to ʻgʻri taʼminlovchi misollariga juda juda juda juda sensitive, birinchi ishni bir necha ishlayotgan manba va shaxsiy soʻzlar sifatida hamma turlarini toʻxtatish mumkin. Natijada, ko'pchilik misollar qanday o'xshash mumkin, lekin semantik ajratilgan ko'pchilik belgilari NMT trenligini ishga tushirish juda ko'p ko'pchilik yo'nalishi mumkin. Bu gapni yopish uchun biz boshqa turlarning natijasini o'ylab turamiz, Transformer modellarida ajratilgan semantik ajoyib chiqaramiz. Biz modellar syntetik ajoyib chiqarish uchun o'rganishni ko'rsatamiz, ko'p ko'p ko'paytirilgan matnni o'rganishni ko'rsatamiz va ularning hozirga ishonchilariga kam ishonch kelmaydi. Bu natijalar asosida, biz biz biz oddiy tarjima qiladigan NMT jadvallaridan foydalanuvchilarni asl tomonidan foydalanishga yordam beradi va tarjima holatlarni o'zgartirish mumkin va EN-FR vazifalarini o'zgartirish mumkin.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Trong khi đã được cho thấy rằng Dịch lắp máy thần kinh (NMB) rất nhạy cảm với các thử nghiệm song song thời ồn ào, các công việc trước đối xử với mọi loại không phù hợp giữa nguồn và mục tiêu như nhiễu. Kết quả là vẫn chưa rõ các mẫu có thể gần nhau như nhau nhưng có một số lượng nhỏ các thẻ khác nhau về mặt phân biệt biệt ảnh hưởng đến huấn luyện NMT. Để lấp chỗ trống này, chúng tôi phân tích tác động của các loại khác nhau các phân biệt ngữ pháp mĩ điệu trên các mô hình transformer. Chúng tôi cho thấy các mô hình được huấn luyện về sai lệch tổng hợp văn bản thoái hóa thường xuyên hơn và ít tự tin hơn về dự đoán của chúng. Dựa trên những kết quả này, chúng ta sẽ tạo ra một hệ thống NMT khác biệt, sử dụng các yếu tố để giúp NMT phục hồi từ sự phân hủy do những khác biệt tự nhiên xảy ra, nâng cao cả chất lượng dịch và định vị mô hình về việc sở hữu người Anh.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>虽已验神经机器翻译(NMT)并行训练样本敏,而前事以源、趋之间诸类为噪声。 是以未详其多等效而含少语义散之令牌样本何以加于NMT。 为之相去,论其细粒度语义散变形金刚。 示以合散之法,更输退化本,而其占心为下。 盖引一散发之NMT框架,当框架用因子以助之NMT自然之背退化恢复过来,以重EN-FR之译校准。</span></div></div><dl><dt>Anthology ID:</dt><dd>2021.acl-long.562</dd><dt>Volume:</dt><dd><a href=/volumes/2021.acl-long/>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</a></dd><dt>Month:</dt><dd>August</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Online</dd><dt>Venues:</dt><dd><a href=/venues/acl/>ACL</a>
| <a href=/venues/ijcnlp/>IJCNLP</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>7236–7249</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.acl-long.562>https://aclanthology.org/2021.acl-long.562</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/2021.acl-long.562 title="To the current version of the paper by DOI">10.18653/v1/2021.acl-long.562</a></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">briakou-carpuat-2021-beyond</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Eleftheria Briakou and Marine Carpuat. 2021. <a href=https://aclanthology.org/2021.acl-long.562>Beyond Noise : Mitigating the Impact of Fine-grained Semantic Divergences on Neural Machine Translation</a>. In <i>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</i>, pages 7236–7249, Online. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2021.acl-long.562>Beyond Noise : Mitigating the Impact of Fine-grained Semantic Divergences on Neural Machine Translation</a> (Briakou & Carpuat, ACL 2021)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2021.acl-long.562.pdf>https://aclanthology.org/2021.acl-long.562.pdf</a></dd><dt>Code</dt><dd><a href=https://github.com/awslabs/sockeye><i class="fab fa-github"></i>&nbsp;awslabs/sockeye</a>
+
<a href="https://paperswithcode.com/paper/?acl=2021.acl-long.562"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg>&nbsp;additional community code</a></dd><dt>Data</dt><dd><a href=https://paperswithcode.com/dataset/wikimatrix>WikiMatrix</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2021.acl-long.562.pdf title="Open PDF of 'Beyond Noise : Mitigating the Impact of Fine-grained Semantic Divergences on Neural Machine Translation'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Beyond+Noise+%3A+Mitigating+the+Impact+of+Fine-grained+Semantic+Divergences+on+Neural+Machine+Translation" title="Search for 'Beyond Noise : Mitigating the Impact of Fine-grained Semantic Divergences on Neural Machine Translation' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-secondary d-flex flex-wrap justify-content-center" href="https://paperswithcode.com/paper/?acl=2021.acl-long.562" title="Code for 'Beyond Noise : Mitigating the Impact of Fine-grained Semantic Divergences on Neural Machine Translation' on Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-big" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg><span class="pl-sm-2 d-none d-sm-inline">Code</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'Beyond Noise : Mitigating the Impact of Fine-grained Semantic Divergences on Neural Machine Translation'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[Beyond Noise : Mitigating the Impact of Fine-grained Semantic Divergences on Neural Machine Translation](https://aclanthology.org/2021.acl-long.562) (Briakou & Carpuat, ACL 2021)</p><ul class=mt-2><li><a href=https://aclanthology.org/2021.acl-long.562>Beyond Noise : Mitigating the Impact of Fine-grained Semantic Divergences on Neural Machine Translation</a> (Briakou & Carpuat, ACL 2021)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Eleftheria Briakou and Marine Carpuat. 2021. <a href=https://aclanthology.org/2021.acl-long.562>Beyond Noise : Mitigating the Impact of Fine-grained Semantic Divergences on Neural Machine Translation</a>. In <i>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</i>, pages 7236–7249, Online. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>