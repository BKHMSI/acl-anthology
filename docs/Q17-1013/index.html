<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Nonparametric Bayesian Semi-supervised Word SegmentationBayesian Semi-supervised Word Segmentation - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="Nonparametric Bayesian Semi-supervised Word SegmentationBayesian Semi-supervised Word Segmentation" name=citation_title><meta content="Ryo Fujii" name=citation_author><meta content="Ryo Domoto" name=citation_author><meta content="Daichi Mochihashi" name=citation_author><meta content="Transactions of the Association for Computational Linguistics" name=citation_journal_title><meta content="5" name=citation_volume><meta content="2017" name=citation_publication_date><meta content="https://aclanthology.org/Q17-1013.pdf" name=citation_pdf_url><meta content="179" name=citation_firstpage><meta content="189" name=citation_lastpage><meta content="10.1162/tacl_a_00054" name=citation_doi><meta property="og:title" content="Nonparametric Bayesian Semi-supervised Word SegmentationBayesian Semi-supervised Word Segmentation"><meta property="og:image" content="https://aclanthology.org/thumb/Q17-1013.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/Q17-1013"><meta property="og:description" content="Ryo Fujii, Ryo Domoto, Daichi Mochihashi. Transactions of the Association for Computational Linguistics, Volume 5. 2017."><link rel=canonical href=https://aclanthology.org/Q17-1013></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/Q17-1013.pdf>Nonparametric Bayesian Semi-supervised Word Segmentation<span class=acl-fixed-case>B</span>ayesian Semi-supervised Word Segmentation</a>
<a id=af_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Geparametriese Bayesian semi- superviseer Woord Segmentasie</a>
<a id=am_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>parameteric Bayesian Semi-supervised Word Segmentation</a>
<a id=ar_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>تجزئة كلمة بايزي غير معلمية شبه خاضعة للإشراف</a>
<a id=az_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Parametrik olmayan Bayesiya yarısını gözləyir Kelimi Segmentasyonu</a>
<a id=bg_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Непараметрична бейзийска полунадзорна сегментация на думи</a>
<a id=bn_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>কোনো প্যারামিট্রিক বেয়েসিয়ান সেমি- পর্যবেক্ষণ করা শব্দ বিভাগ</a>
<a id=bo_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Nonparametric Bayesian Semi-supervised Word Segmentation</a>
<a id=bs_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Neparametrična Bayesijska polu nadzorna segmentacija riječi</a>
<a id=ca_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Segmentació de paraules semi-supervisada de Bayesia</a>
<a id=cs_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Neparametrická Bayesovská polovičně dohledová segmentace slov</a>
<a id=da_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Ikke- parametrisk bayesisk semiovervåget ordsegmentering</a>
<a id=de_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Nicht parametrische Bayesische Halbüberwachte Wortsegmentierung</a>
<a id=el_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Μη παραμετρική Bayesian Semi-εποπτευόμενη τμηματοποίηση λέξεων</a>
<a id=es_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Segmentación de palabras semisupervisada bayesiana no paramétrica</a>
<a id=et_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Mitteparameetriline bayesia pooljärelevalvega sõnade segmenteerimine</a>
<a id=fa_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>بخش کلمه‌های نیمه مراقبت بی‌اسیایی غیر پارامتریک</a>
<a id=fi_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Ei-parametrinen Bayesian Semi-supervised Word Segmentation</a>
<a id=fl_title style=display:none href=https://aclanthology.org/Q17-1013.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Segmentation de mots semi-supervisée bayésienne non paramétrique</a>
<a id=ga_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Deighleog Focal Leath-mhaoirsithe Bayesian Neamhparaiméadrach</a>
<a id=ha_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>KCharselect unicode block name</a>
<a id=he_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>ניתוח מילים לא פארמטרי</a>
<a id=hi_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Nonparametric Bayesian अर्ध पर्यवेक्षित वर्ड विभाजन</a>
<a id=hr_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Neparametrična Bayesijska polu nadzorna segmentacija riječi</a>
<a id=hu_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Nem parametrikus bayesiai félig felügyelt szószegmentáció</a>
<a id=hy_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Nonparametric Bayesian Semi-supervised Word Segmentation</a>
<a id=id_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Nonparametric Bayesian Semi-supervised Word Segmentation</a>
<a id=is_title style=display:none href=https://aclanthology.org/Q17-1013.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Segmentazione vocale semisupervisionata bayesiana non parametrica</a>
<a id=ja_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>ノンパラメトリックベイジアンセミスペシャルワードセグメンテーション</a>
<a id=jv_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Languages</a>
<a id=ka_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Name</a>
<a id=kk_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Байезия жарты бақылаған сөз сегментациясы жоқ</a>
<a id=ko_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>비변수 베일스 반감독분사</a>
<a id=lt_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Neparametrinė Bayezijos pusiau prižiūrima žodžių segmentacija</a>
<a id=mk_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Nonparametric Bayesian Semi-supervised Word Segmentation</a>
<a id=ml_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Nonparametric Bayesian Semi-supervised Word Segmentation</a>
<a id=mn_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Гэвч параметр биезийн хагас дамжуулагдсан үг хэвлэлт</a>
<a id=ms_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Segmentasi Kata Semi-Dijaga Bayesia Tidak Parametrik</a>
<a id=mt_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Segmentazzjoni tal-Kliem Semi-Sorveljata Bajesjana Mhux Parametrika</a>
<a id=nl_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Niet-parametrische Bayesian Semi-supervised Word Segmentatie</a>
<a id=no_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Ikkje parametrisk Bayesiansk semioversikt ordsegmentasjon</a>
<a id=pl_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Nieparametryczna Bayesońska pół nadzorowana segmentacja słowa</a>
<a id=pt_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Segmentação de palavras semissupervisionada bayesiana não paramétrica</a>
<a id=ro_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Segmentarea vocală semisupravegheată bayeziană nonparametrică</a>
<a id=ru_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Непараметрическая байесовская полунаблюдаемая сегментация слов</a>
<a id=si_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>ප්‍රමාණික බේසියාන් සම්බන්ධ වචනය</a>
<a id=sk_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Neparametrična bajzijska polnadzorovana segmentacija besed</a>
<a id=so_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Nonparametric Bayesian Semi-supervised Word Segmentation</a>
<a id=sq_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Segmentacioni i Fjalëve jo parametrik i mbikqyrur nga Bayesia</a>
<a id=sr_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Непараметрична бејезијска половинадзорна речна сегментација</a>
<a id=sv_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Icke parametrisk bayesian semiövervakad ordsegmentering</a>
<a id=sw_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Kitendo cha Bayesia cha Semi kinachofuatiliwa kwa neno la Kutenga</a>
<a id=ta_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>அளபுருவில்லை பெய்சியன் பெமி- கண்காணிக்கப்பட்ட வார்த்தை பிரிப்பு</a>
<a id=tr_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>Sözlük bir Bayezi Semi-gözlemiş Kelime Segmentasyonu</a>
<a id=uk_title style=display:none href=https://aclanthology.org/Q17-1013.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>غیر پارامیٹریک بیسین نصف-supervised Word Segmentation</a>
<a id=uz_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>QFontDatabase</a>
<a id=vi_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>KCharselect unicode block name</a>
<a id=zh_title style=display:none href=https://aclanthology.org/Q17-1013.pdf>非参数贝叶斯半督分词</a></h2><p class=lead><a href=/people/r/ryo-fujii/>Ryo Fujii</a>,
<a href=/people/r/ryo-domoto/>Ryo Domoto</a>,
<a href=/people/d/daichi-mochihashi/>Daichi Mochihashi</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>This paper presents a novel hybrid generative / discriminative model of word segmentation based on nonparametric Bayesian methods. Unlike ordinary discriminative word segmentation which relies only on labeled data, our <a href=https://en.wikipedia.org/wiki/Semi-supervised_learning>semi-supervised model</a> also leverages a huge amounts of unlabeled text to automatically learn new words, and further constrains them by using a labeled data to segment non-standard texts such as those found in <a href=https://en.wikipedia.org/wiki/Social_networking_service>social networking services</a>. Specifically, our hybrid model combines a discriminative classifier (CRF ; Lafferty et al. (2001) and unsupervised word segmentation (NPYLM ; Mochihashi et al. (2009)), with a transparent exchange of information between these two model structures within the semi-supervised framework (JESS-CM ; Suzuki and Isozaki (2008)). We confirmed that it can appropriately segment non-standard texts like those in <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> and <a href=https://en.wikipedia.org/wiki/Sina_Weibo>Weibo</a> and has nearly state-of-the-art accuracy on standard datasets in <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a>, <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>, and <a href=https://en.wikipedia.org/wiki/Thai_language>Thai</a>.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Hierdie papier stel 'n roman hybrid genereerbare/diskriminasiewe model van woord segmentasie gebaseer op nie-parametriese Bayesian metodes. Ongelyks van gewone diskriminasiewe woord segmentasie wat slegs op etiketeerde data aflys, ons semi-ondersoekte model het ook 'n groot hoeveelheid ongeabelde teks aan automaties leer nuwe 'woorde', en verdere beperk hulle deur 'n etiketeerde data te gebruik na segmenteer nie-standaard teks soos wat in sosiale netwerking dienste gevind is. Spesifieke, ons hibrid model kombinieer 'n diskriminasiewe klassifiseerder (CRF; Lafferty et al. (2001) en ononderwerpende woord segmentasie (NPYLM; Mochihashi et al. (2009)), met 'n deursigtige vervang van inligting tussen hierdie twee model strukture binne die semi-onderwerp raamwerk (JESS-CM; Suzuki en Isozaki (2008)). Ons het bevestig dat dit behoorlik kan segment nie-standaard teks soos die in Twitter en Weibo en het byna staat-van-kuns-presies op standaard datastelle in Japanse, Sjinese en Thaise.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ይህም ፕሮግራም የባይስያ ሥርዓት ባይሄስቲ ባሕያዊ ሥርዓት ላይ የቃላት ግንኙነቶችን አቀረበ፡፡ በተለየ ጥያቄ ቃላት በጽሑፎች ላይ ብቻ የሚታመን እና በጽሑፍ ማቀናቀል፣ የsemi-ተጠባባቂው ሞዴሌዎቻችን ደግሞ አዲስ ቃልን ለራሱ ማምረጥ ትልቅ የጽሑፍ ክፍል ያሰጣቸዋል፡፡ በተለየ ጊዜ የኬብሪድ ሞዴል (CRF; Lafferty et al. (2001) እና ያልጠበቀ ቃላት segmentation (NPYLM; ሞኪሐሺ et al. (2009)) በተለየ በሁለት ሞዴል አካውንቶች መካከል የተለየ የእውይይይት መረጃዎችን (JESS-CM; ሱዙኪ እና ይስozaki (2008). በትዊተር እና Weibo ያሉትን የድምፅ ጽሑፎችን እንደሚያስፈልግ አረጋገጥን፤ በጃፓን፣ ቻይና እና ታይኛ የዳርቻ ጽሑፎች የደረጃ ግንኙነት አቅራቢያ አለበት፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>تقدم هذه الورقة نموذجًا توليديًا / تمييزيًا جديدًا هجينًا لتجزئة الكلمات بناءً على طرق بايز غير معلمية. على عكس تجزئة الكلمات التمييزية العادية التي تعتمد فقط على البيانات المصنفة ، فإن نموذجنا شبه الخاضع للإشراف يستفيد أيضًا من كميات هائلة من النص غير المصنف لتعلم "كلمات" جديدة تلقائيًا ، ويزيد من تقييدها باستخدام البيانات المصنفة لتقسيم النصوص غير القياسية مثل تلك الموجودة في خدمات الشبكات الاجتماعية. على وجه التحديد ، يجمع نموذجنا الهجين بين المصنف التمييزي (CRF ؛ Lafferty et al. (2001) وتجزئة الكلمات غير الخاضعة للإشراف (NPYLM ؛ Mochihashi et al. (2009)) ، مع تبادل شفاف للمعلومات بين هذين النموذجين داخل الهياكل شبه. إطار عمل خاضع للإشراف (JESS-CM؛ Suzuki and Isozaki (2008)). أكدنا أنه يمكن تقسيم النصوص غير القياسية بشكل مناسب مثل تلك الموجودة في Twitter و Weibo ولديه دقة متطورة تقريبًا في مجموعات البيانات القياسية باللغات اليابانية والصينية ، والتايلاندية.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bu kağıt, parametrik Bayesiya metodlarına dayanan yeni hibrid generikatlı/diskriminatlı söz segmentasiyasının modelini göstərir. Yalnız etiketli məlumatlar üzərində təvəkkül edən sıradan diskriminativ söz segmentasiyası kimi, yarı-gözləyirli modellərimiz də yeni sözləri öyrənmək üçün çox böyük dəyişiklik məlumatları yaratdı və daha sonra etiketli məlumatları sosyal netverk servislərdə bulunan məlumatları segment etmək üçün dəyişiklik edir. Özellikle, hibrid modellərimiz yarı-gözləyirli çerçevesinin içində bu iki modellərin arasındakı məlumatları orta-gözləyir (JESS-CM; Suzuki və Isozaki (2008)) ilə birləşdirir. Biz təsdiqlədik ki, o, Twitter və Weibo kimi standart olmayan məktubları yaxşı bölüşdürə bilər və Yaponca, Çinlə və Tayla standart veri setlərinin dəqiqliyinə bənzəyir.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Настоящата статия представя нов хибриден генеративен/дискриминативен модел на сегментация на думи, базиран на непараметрични баезийски методи. За разлика от обикновената дискриминационна сегментация на думи, която разчита само на етикетирани данни, нашият полу-надзорен модел също използва огромни количества незабелязан текст, за да научи автоматично нови "думи", и допълнително ги ограничава, като използва етикетирани данни, за да сегментира нестандартни текстове като тези, намерени в социалните мрежи услуги. По-конкретно, нашият хибриден модел съчетава дискриминационен класификатор (CRF; Lafferty et al. (2001) и неконтролирана словна сегментация (NPYLM; Mochihashi et al. (2009)), с прозрачен обмен на информация между тези две структури на модела в рамките на полунадзорната рамка (JESS-CM; Suzuki и Isozaki (2008)). Потвърдихме, че може правилно да сегментира нестандартни текстове като тези в Туитър и Уайбо и има почти най-съвременна точност на стандартните набори от данни на японски, китайски и тайландски език.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>এই পত্রিকাটি প্যারামেট্রিক বেয়েসিয়ান পদ্ধতির উপর ভিত্তিক শব্দের বিভিন্ন ভিন্ন ভিন্ন ভিত্তিক ভিত্তিক শব্দের বৈষম্ Unlike ordinary discriminative word segmentation which relies only on labeled data, our semi-supervised model also leverages a huge amounts of unlabeled text to automatically learn new 'words', and further constrains them by using a labeled data to segment non-standard texts such as those found in social networking services. বিশেষ করে, আমাদের হাইব্রিড মডেল একটি বৈষম্যিক শ্রেণীবিভাগের (সিএসএফ; ল্যাফার্টি আর আল. (২০০১) এবং অরক্ষণশীল শব্দ বিভাগ (NPYLM; মোচিহি et al. (২০০৯)) স্বচ্ছতাভাবে এই দুই মডেল কাঠামোর মধ্যে স্বচ্ছতা বিনিময়ে ত আমরা নিশ্চিত করেছি যে এটি টুইটার এবং উইবোতে যেমন স্ট্যান্ডার্ড না লেখাগুলো বিভক্ত করতে পারে এবং জাপানি, চীন এবং থাই-এর স্ট্যান্ডার্ডার ডাটাসেটগ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>This paper presents a novel hybrid generative/discriminative model of word segmentation based on nonparametric Bayesian methods. Unlike ordinary discriminative word segmentation which relies only on labeled data, our semi-supervised model also leverages a huge amounts of unlabeled text to automatically learn new 'words', and further constrains them by using a labeled data to segment non-standard texts such as those found in social networking services. Specifically, our hybrid model combines a discriminative classifier (CRF; Lafferty et al. (2001) and unsupervised word segmentation (NPYLM; Mochihashi et al. (2009)), with a transparent exchange of information between these two model structures within the semi-supervised framework (JESS-CM; Suzuki and Isozaki (2008)). ངེད་གཉིས་ཀྱིས་ཌིས་ཌིར་དང་ཝེ་པོ་ནང་གི་ཡིག</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ovaj papir predstavlja nov hibridni generativni/diskriminacijski model segmentacije riječi na temelju neparametričkih Bayesijskih metoda. Za razliku od obične diskriminacijske segmentacije riječi koja se oslanja samo na etiketirane podatke, naš polu nadzorni model također utječe na ogromne količine nenabeliranog teksta kako bi automatski naučio nove 'riječi', a dalje ih ograničava koristeći etiketirane podatke na segmentiranje neustandardnih tekstova kao što su pronađeni u službama socijalnih mreža. Posebno, naš hibridni model kombinira diskriminativnu klasifikaciju (CRF; Lafferty et al. (2001) i neodređenu segmentaciju riječi (NPYLM; Mochihashi et al. (2009)), sa transparentnom razmjenom informacija između tih dva modelnih struktura u polu nadzornom okviru (JESS-CM; Suzuki i Isozaki (2008)). Potvrdili smo da može odgovarajući segmentirati ne standardne tekste poput one na Twitter i Weibo i da ima skoro stanje umjetnosti preciznosti na standardnim podacima na japanskom, kineskom i tajlandskom.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Aquest paper presenta un nou model hibridgenerador/discriminatiu de segmentació de paraules basat en mètodes baièsius no paramètrics. A diferència de la segmentació de paraules discriminatòries habitual que només es basa en dades etiquetades, el nostre model semisupervisat també aprofita una gran quantitat de text no etiquetat per aprendre automàticament noves "paraules", i altres les limita fent servir una data etiquetada per segmentar textos no estàndard com els que es troben en serveis de xarxa social. Concretament, el nostre model híbrid combina un classificador discriminatiu (CRF; Lafferty et al. (2001) i una segmentació de paraules no supervisada (NPYLM; Mochihashi et al. (2009)), amb un intercanvi transparent d'informació entre aquestes dues estructures models dins l'estructura semisupervisada (JESS-CM; Suzuki i Isozaki (2008)). Vam confirmar que pot segmentar adequadament textos no estàndard com els de Twitter i Weibo i que té gairebé la precisió més moderna en conjunts de dades estàndard en japonès, xinès i tailandes.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tento článek představuje nový hybridní generativní/diskriminační model segmentace slov založený na neparametrických Bayesovských metodách. Na rozdíl od běžné diskriminační segmentace slov, která se opírá pouze o označená data, náš model s polovým dohledem také využívá obrovské množství neoznačeného textu k automatickému učení se nových "slov", a dále je omezuje použitím označených dat k segmentování nestandardních textů, jako jsou ty, které se nacházejí ve službách sociálních sítí. Konkrétně, náš hybridní model kombinuje diskriminační klasifikátor (CRF; Lafferty et al. (2001) a bez dozoru segmentaci slov (NPYLM; Mochihashi et al. (2009)), s transparentní výměnou informací mezi těmito dvěma modelovými strukturami v rámci semi-supervised frameworku (JESS-CM; Suzuki a Isozaki (2008)). Potvrdili jsme, že může vhodně segmentovat nestandardní texty, jako jsou například na Twitteru a Weibo a má téměř nejmodernější přesnost na standardních datových sadách v japonštině, čínštině a thajsku.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Denne artikel præsenterer en ny hybrid generativ / diskriminerende model af ordsegmentering baseret på nonparametriske bayesiske metoder. I modsætning til almindelig diskriminerende ordsegmentering, som kun er afhængig af mærkede data, udnytter vores halvovervågede model også en enorm mængde ikke-mærket tekst til automatisk at lære nye 'ord', og begrænser dem yderligere ved at bruge en mærket data til at segmentere ikke-standardtekster som dem, der findes i sociale netværkstjenester. Specielt kombinerer vores hybridmodel en diskriminerende klassificering (CRF; Lafferty m.fl. (2001) og en ukontrolleret ordsegmentering (NPYLM; Mochihashi m.fl. (2009)), med en gennemsigtig udveksling af oplysninger mellem disse to modelstrukturer inden for rammerne af den halvovervågede ramme (JESS-CM; Suzuki og Isozaki (2008)). Vi bekræftede, at det på passende vis kan segmentere ikke-standardtekster som dem i Twitter og Weibo og har næsten state-of-the-art nøjagtighed på standarddatasæt på japansk, kinesisk og thailandsk.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Diese Arbeit stellt ein neuartiges hybrides generatives/diskriminierendes Modell der Wortsegmentierung vor, das auf nichtparametrischen Bayesischen Methoden basiert. Im Gegensatz zu gewöhnlicher diskriminierender Wortsegmentierung, die nur auf beschrifteten Daten beruht, nutzt unser halbüberwachtes Modell auch eine große Menge an unbekennzeichneten Texten, um automatisch neue "Wörter" zu lernen. Außerdem werden diese durch die Verwendung von beschrifteten Daten zur Segmentierung nicht standardisierter Texte, wie sie in sozialen Netzwerken gefunden werden, weiter eingeschränkt. Konkret kombiniert unser Hybridmodell einen diskriminierenden Klassifikator (CRF; Lafferty et al. (2001) und eine unüberwachte Wortsegmentierung (NPYLM; Mochihashi et al. (2009)), mit einem transparenten Informationsaustausch zwischen diesen beiden Modellstrukturen im semi-supervised framework (JESS-CM; Suzuki und Isozaki (2008)). Wir haben bestätigt, dass es nicht-standardisierte Texte wie Twitter und Weibo angemessen segmentieren kann und nahezu State-of-the-Art-Genauigkeit auf Standard-Datensätzen in Japanisch, Chinesisch und Thai aufweist.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Η παρούσα εργασία παρουσιάζει ένα νέο υβριδικό παραγωγικό/διακριτικό μοντέλο τμηματοποίησης λέξεων βασισμένο σε μη παραμετρικές Bayesian μεθόδους. Σε αντίθεση με τη συνηθισμένη διαφοροποιημένη τμηματοποίηση λέξεων που βασίζεται μόνο σε δεδομένα με ετικέτα, το ημι-εποπτευμένο μοντέλο μας χρησιμοποιεί επίσης τεράστιες ποσότητες χωρίς ετικέτα κειμένου για να μάθει αυτόματα νέες "λέξεις", και τις περιορίζει περαιτέρω χρησιμοποιώντας δεδομένα με ετικέτα για να ταξινομήσει μη τυποποιημένα κείμενα, όπως αυτά που βρίσκονται στις υπηρεσίες κοινωνικής δικτύωσης. Ειδικότερα, το υβριδικό μας μοντέλο συνδυάζει έναν διαχωριστικό ταξινομητή (CRF, Lafferty et al. (2001) και μια χωρίς επίβλεψη τμηματοποίηση λέξεων (NPYLM, Mochihashi et al. (2009)), με μια διαφανή ανταλλαγή πληροφοριών μεταξύ αυτών των δύο δομών μοντέλου στο πλαίσιο ημιεπιτήρησης (Suzuki και Isozaki (2008)). Επιβεβαιώσαμε ότι μπορεί να ταξινομήσει κατάλληλα μη τυποποιημένα κείμενα όπως αυτά στο Twitter και το Weibo και έχει σχεδόν υπερσύγχρονη ακρίβεια σε τυποποιημένα σύνολα δεδομένων στα ιαπωνικά, κινέζικα και ταϊλανδέζικα.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Este artículo presenta un novedoso modelo híbrido generativo/discriminativo de segmentación de palabras basado en métodos bayesianos no paramétricos. A diferencia de la segmentación de palabras discriminativa ordinaria, que se basa únicamente en datos etiquetados, nuestro modelo semi-supervisado también aprovecha una enorme cantidad de texto sin etiqueta para aprender automáticamente nuevas «palabras» y las restringe aún más mediante el uso de datos etiquetados para segmentar textos no estándar, como los que se encuentran en las redes sociales servicios de redes. Específicamente, nuestro modelo híbrido combina un clasificador discriminativo (CRF; Lafferty et al. (2001) y segmentación de palabras no supervisada (NPYLM; Mochihashi et al. (2009)), con un intercambio transparente de información entre estas dos estructuras modelo dentro del marco semisupervisado (JESS-CM; Suzuki e Isozaki ( 2008)). Confirmamos que puede segmentar adecuadamente textos no estándar como los de Twitter y Weibo y que tiene una precisión casi de vanguardia en conjuntos de datos estándar en japonés, chino y tailandés.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Käesolev töö tutvustab uudset hübriidgeneratiivset/diskrimineerivat sõna segmenteerimise mudelit, mis põhineb mitteparameetrilistel bayesia meetoditel. Erinevalt tavalisest diskrimineerivast sõnasegmenteerimisest, mis põhineb ainult märgistatud andmetel, kasutab meie pooljärelevalve all olev mudel ka tohutut hulka märgistamata teksti, et automaatselt õppida uusi sõnu, ning piirab neid veelgi, kasutades märgistatud andmeid mittestandardsete tekstide segmenteerimiseks, nagu sotsiaalvõrgustike teenustes leitavad tekstid. Täpsemalt ühendab meie hübriidmudel diskrimineeriva klassifitseerija (CRF; Lafferty jt. (2001) ja järelevalveta sõnasegmenteerimise (NPYLM; Mochihashi jt. (2009)), läbipaistva teabevahetusega nende kahe mudeli struktuuri vahel pooljärelevalve raames (JESS-CM; Suzuki ja Isozaki (2008)). Me kinnitasime, et see suudab asjakohaselt segmenteerida mittestandardseid tekste, nagu Twitteris ja Weibos, ning on peaaegu tipptasemel täpsusel jaapani, hiina ja tai keeles.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>این کاغذ یک مدل ژنترافی/جدایی جدایی از جمع کردن کلمات بر اساس روش های غیر پارامتریک بیزیان را نشان می دهد. برخلاف جدا کردن کلمه‌های معمولی که تنها بر داده‌های برچسب بستگی دارد، مدل نیمه‌برچسب ما همچنین یک مقدار بزرگی از متن نامزده‌ای برای یادگرفتن کلمه‌های جدید را به خودکار محدودیت می‌کند، و بیشتر آنها را با استفاده از داده‌های برچسب برای جدا کردن متن‌های غیراستاندارد مانند آن‌ها که در خدمات شبکه‌های اج مخصوصاً مدل هیبریدی ما یک کلاسیر جدایی (CRF; Lafferty et al. (۲۰۰۱) و جدایی کلمات غیرقابل تحویل (NPYLM; Mochihashi et al. (۲۰۰۹)، با یک تبادل مشاهده اطلاعات بین این دو ساختار مدل در چهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچهارچ ما تایید کردیم که می‌تواند متن‌های غیر استاندارد را به طور مناسب جدا کند مانند آن‌ها که توئیتر و ویبو هستند و تقریباً دقیقات هنری در مجموعه‌های استاندارد در ژاپن، چینی و تایید دارد.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tässä työssä esitellään uusi hybridi generatiivinen/diskriminatiivinen sanasegmentoinnin malli, joka perustuu ei-parametrisiin bayesilaisiin menetelmiin. Toisin kuin tavallinen syrjivä sanasegmentointi, joka perustuu vain merkittyyn dataan, puolivalvottu mallimme hyödyntää myös valtavia määriä merkitsemätöntä tekstiä oppiakseen automaattisesti uusia sanoja ja rajoittaa niitä entisestään käyttämällä merkittyä dataa segmentoidakseen epästandardeja tekstejä, kuten sosiaalisen median palveluissa. Hybridimallissamme yhdistyvät erityisesti syrjivä luokittelija (CRF; Lafferty et al. (2001) ja valvomaton sanasegmentointi (NPYLM; Mochihashi et al. (2009)), ja näiden kahden mallirakenteen välinen läpinäkyvä tietojenvaihto puolivalvotussa kehyksessä (JESS-CM; Suzuki ja Isozaki (2008)). Vahvistimme, että se pystyy asianmukaisesti segmentoimaan epätavanomaisia tekstejä, kuten Twitterissä ja Weibossa, ja sillä on lähes uusinta tarkkuutta japanin, kiinan ja thain kielissä.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Cet article présente un nouveau modèle hybride génératif/discriminatif de segmentation de mots basé sur des méthodes bayésiennes non paramétriques. Contrairement à la segmentation discriminative de mots ordinaires qui repose uniquement sur des données étiquetées, notre modèle semi-supervisé exploite également d'énormes quantités de texte non étiqueté pour apprendre automatiquement de nouveaux « mots », et les contraint davantage en utilisant des données étiquetées pour segmenter des textes non standard tels que ceux trouvés dans les réseaux sociaux services réseau. Plus précisément, notre modèle hybride combine un classificateur discriminant (CRF ; Lafferty et al. (2001) et une segmentation de mots non supervisée (NPYLM ; Mochihashi et al. (2009)), avec un échange transparent d'informations entre ces deux structures de modèle dans le cadre semi-supervisé (JESS-CM ; Suzuki et Isozaki ( 2008). Nous avons confirmé qu'il peut segmenter de manière appropriée les textes non standard tels que ceux de Twitter et Weibo et qu'il offre une précision presque inégalée sur les ensembles de données standard en japonais, en chinois et en thaï.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Cuireann an páipéar seo i láthair samhail giniúna/idirdhealaitheach hibrideach nua de dheighilt focal bunaithe ar mhodhanna neamhparaiméadracha Bayesian. Murab ionann agus gnáth-dheighilt focal idirdhealaitheach a bhraitheann ar shonraí lipéadaithe amháin, déanann ár múnla leath-mhaoirseachta giaráil freisin ar mhéideanna ollmhóra téacs gan lipéad chun “focail” nua a fhoghlaim go huathoibríoch, agus cuireann sé srian breise orthu trí úsáid a bhaint as sonraí lipéadaithe chun téacsanna neamhchaighdeánacha a dheighilt. iad siúd atá le fáil i seirbhísí líonraithe sóisialta. Go sonrach, comhcheanglaíonn ár múnla hibrideach aicmitheoir idirdhealaitheach (CRF; Lafferty et al. (2001) agus deighilt focal gan mhaoirseacht (NPYLM; Mochihashi et al. (2009))), le malartú trédhearcach faisnéise idir an dá struchtúr mhúnla seo laistigh den leath-struchtúr. creat maoirsithe (JESS-CM; Suzuki agus Isozaki (2008)) Dhearbhaíomar gur féidir léi téacsanna neamhchaighdeánacha mar iad siúd in Twitter agus Weibo a dheighilt go cuí agus go bhfuil cruinneas den scoth aige ar thacair sonraí caighdeánacha sa tSeapáinis agus sa tSínis. , agus Téalainnis.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Wannan takardan na ƙunsa da wani hoton Hybri mai gabatar da/mai yin ɓarna na maganar segmentation a kan non-parametric Bayesian hanyoyi. Di daidaita da rabon maganar da aka inganci na ɗabi'a, yana dõgara kawai kan data na tsari, misalinmu wanda aka yi tsaron da shi na ƙara yana da yawan abu mai girma wa matsayin da ba'anar shi ba dõmin ya sanar da yanzu na yanzu-yanzu, kuma yana ƙudura su da amfani da data na rubutu zuwa raba matsayin na'ura, kamar waɗanda aka samu a cikin tsarin mitandanin jamii. Aka ƙayyade, misalinmu ya koma koma da wani mai rarrabo (CRF; Laffty et al. (2001) da kuma an tsare maganar segmentation (NPYLM; Mokishi et al. (2009)), da an buɗe bayani da bayani da cire-daban laban misalin biyu cikin firam wanda aka yi shekara (JESS-CM; Suzuki da Iszoaki (2006). Mun gaskata cẽwa, za ta raba matsayin waɗanda ba'a daidaita ba kamar waɗanda ke cikin Twitter da Weibo kuma yana da nesten taƙalumi na-sanar a kan daidaita matsayin taƙaita cikin japanen, China da Tai.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>העבודה הזו מציגה מודל חדש גידול היברידי/דיסקרטיבי של סגמנציה מילים מבוסס על שיטות בייזיות לא פרמטריות. בניגוד למחלקת מילים מיוחדת רגילה שמבוססת רק על נתונים מסומנים, המודל שלנו חצי-שולט גם משתמש בכמות עצומות של טקסט לא מסומן כדי ללמוד אוטומטית 'מילים' חדשות, ומגבלת אותם יותר על ידי השימוש של נתונים מסומנים כדי לחלק טקסטים לא סטנדרטיים כמו אלה שנמצאים בשירותים רשת חבר Specifically, our hybrid model combines a discriminative classifier (CRF; Lafferty et al. (2001) and unsupervised word segmentation (NPYLM; Mochihashi et al. (2009)), with a transparent exchange of information between these two model structures within the semi-supervised framework (JESS-CM; Suzuki and Isozaki (2008)). אישרנו שהוא יכול לחלק בהתאם טקסטים לא סטנדרטיים כמו אלה בטוויטר וייבו ויש לו כמעט מדויק חדש במידע בסטנדרטי נתונים ביפני, סיני וטאיילנדי.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>यह पेपर गैर-पैरामीट्रिक बायेसियन विधियों के आधार पर शब्द विभाजन का एक उपन्यास हाइब्रिड जेनरेटर / भेदभावपूर्ण मॉडल प्रस्तुत करता है। सामान्य भेदभावपूर्ण शब्द विभाजन के विपरीत जो केवल लेबल किए गए डेटा पर निर्भर करता है, हमारा अर्ध-पर्यवेक्षित मॉडल स्वचालित रूप से नए "शब्दों" को सीखने के लिए बड़ी मात्रा में बिना लेबल वाले पाठ का लाभ उठाता है, और सोशल नेटवर्किंग सेवाओं में पाए जाने वाले गैर-मानक ग्रंथों को विभाजित करने के लिए लेबल किए गए डेटा का उपयोग करके उन्हें और बाधित करता है। विशेष रूप से, हमारा हाइब्रिड मॉडल एक भेदभावपूर्ण क्लासिफायर (सीआरएफ) को जोड़ता है; Lafferty et al. (2001) और असुरक्षित शब्द विभाजन (NPYLM; Mochihashi et al. (2009)), अर्ध-पर्यवेक्षित ढांचे (JESS-CM) के भीतर इन दो मॉडल संरचनाओं के बीच जानकारी के पारदर्शी आदान-प्रदान के साथ; सुजुकी और इसोज़ाकी (2008)। हमने पुष्टि की है कि यह उचित रूप से ट्विटर और वीबो में उन लोगों की तरह गैर-मानक ग्रंथों को विभाजित कर सकता है और जापानी, चीनी और थाई में मानक डेटासेट पर लगभग अत्याधुनिक सटीकता है।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ovaj papir predstavlja nov hibridni generativni/diskriminacijski model segmentacije riječi na temelju nenaparatnih Bayesijskih metoda. Za razliku od obične diskriminacijske segmentacije riječi koje se oslanjaju samo na označenim podacima, naš polu nadzorni model također utječe na ogromne količine nenabeliranog teksta kako bi automatski naučio nove 'riječi', a dalje ih ograničava koristeći označene podatke za segmentiranje neustandardnih tekstova kao što su pronađeni u socijalnim mrežnim uslugama. Posebno, naš hibridni model kombinira diskriminirajuću klasifikaciju (CRF; Lafferty et al. (2001) i neodređenu segmentaciju riječi (NPYLM; Mochihashi et al. (2009)), s transparentnom razmjenom informacija između tih dva modelnih struktura u polu nadziranom okviru (JESS-CM; Suzuki i Isozaki (2008)). Potvrdili smo da može odgovarajući dijelovati neustandardne tekste poput one na Twitter i Weibo i da ima skoro stanje umjetnosti preciznosti na standardnim podacima na japanskom, kineskom i tajlandskom.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A tanulmány bemutatja a szószegmentáció új hibrid generációs/diszkriminatív modelljét, amely nem parametrikus bayesiai módszereken alapul. A hagyományos diszkriminatív szószegmentációval ellentétben, amely csak a címkézett adatokon alapul, a félig felügyelt modellünk hatalmas mennyiségű, címke nélküli szöveget is felhasznál arra, hogy automatikusan megtanulják az új "szavakat", és tovább korlátozza őket azzal, hogy címkézett adatokat használnak a nem szabványos szövegek szegmentálására, mint például a közösségi hálózati szolgáltatásokban. Különösen, hibrid modellünk egy diszkriminatív osztályozót (CRF; Lafferty et al. (2001) és felügyelet nélküli szegmentációt (NPYLM; Mochihashi et al. (2009)), amely átlátható információcserét biztosít e két modellstruktúra között a félig felügyelt kereten belül (JESS-CM; Suzuki és Isozaki (2008)). Megerősítettük, hogy megfelelően szegmensezheti a nem szabványos szövegeket, mint például a Twitteren és a Weibón, és szinte a legkorszerűbb pontossággal rendelkezik a szabványos adatkészleteken japán, kínai és thai nyelven.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Այս հոդվածը ներկայացնում է բառերի սեգմետրացիայի նոր հիբրիդ սերնդի և խտրականության մոդել, որը հիմնված է ոչ պարամետրիկ բեյզիացի մեթոդների վրա: Unlike ordinary discriminative word segmentation which relies only on labeled data, our semi-supervised model also leverages a huge amounts of unlabeled text to automatically learn new 'words', and further constrains them by using a labeled data to segment non-standard texts such as those found in social networking services. Հիմաստաբար, մեր հիբրիդ մոդելը միավորում է խտրականության դասակարգում (ԿՌՖ, Լաֆերթի և այլն. (2001) և անվերահսկված բառերի սեգմետրացիա (ՆՊՅԼՄ, Մոչիհասի և այլն. (2009) այս երկու մոդելների կառուցվածքների միջև թափանցիկ տեղեկատվության փոխանակում կիսավերահսկված շրջանակում (Յեսս-ԿՄ, Սյուզուկի Մենք հաստատեցինք, որ այն կարող է պատասխանաբար բաժանել ոչ ստանդարտ տեքստերը, ինչպիսիք են Թվիթերի և Վայբոյի տեքստերը, և ունի գրեթե ամենաբարձր ճշգրտություն ստանդարտ տվյալների համակարգերի վրա ճապոներեն, չինարեն և թայլանդերեն:</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kertas ini mempersembahkan model hibrid baru generatif/diskriminatif segmen kata berdasarkan metode Bayesia yang tidak parametrik. Unlike ordinary discriminative word segmentation which relies only on labeled data, our semi-supervised model also leverages a huge amounts of unlabeled text to automatically learn new 'words', and further constrains them by using a labeled data to segment non-standard texts such as those found in social networking services. Secara spesifik, model hibrid kita menggabungkan klasifikasi diskriminatif (CRF; Lafferty et al. (2001) dan segmen kata yang tidak diawasi (NPYLM; Mochihashi et al. (2009)), dengan pertukaran informasi transparan antara dua struktur model ini dalam rangka semi-mengawasi (JESS-CM; Suzuki dan Isozaki (2008)). Kami mengkonfirmasi bahwa dapat segmen teks yang tidak standar seperti di Twitter dan Weibo dan memiliki akurasi hampir state-of-the-art pada set data standar dalam bahasa Jepang, Cina dan Thailand.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Questo articolo presenta un nuovo modello ibrido generativo/discriminatorio di segmentazione delle parole basato su metodi bayesiani non parametrici. A differenza della normale segmentazione discriminatoria delle parole che si basa solo su dati etichettati, il nostro modello semi-supervisionato sfrutta anche un'enorme quantità di testo non etichettato per imparare automaticamente nuove 'parole', e li limita ulteriormente utilizzando dati etichettati per segmentare testi non standard come quelli trovati nei servizi di social networking. Nello specifico, il nostro modello ibrido combina un classificatore discriminante (CRF; Lafferty et al. (2001) e una segmentazione non supervisionata delle parole (NPYLM; Mochihashi et al. (2009)), con uno scambio trasparente di informazioni tra queste due strutture modello all'interno del quadro semi-supervisionato (JESS-CM; Suzuki e Isozaki (2008)). Abbiamo confermato che può segmentare in modo appropriato testi non standard come quelli su Twitter e Weibo e ha una precisione quasi all'avanguardia sui set di dati standard in giapponese, cinese e tailandese.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ノンパラメトリックベイズ法に基づく単語セグメンテーションの新規ハイブリッド生成/識別モデルを提示した。ラベル付けされたデータのみに依存する通常の差別的な単語セグメンテーションとは異なり、私たちの半監督モデルはまた、膨大な量のラベル付けされていないテキストを活用して自動的に新しい「単語」を学習し、ソーシャルネットワーキングサービスに見られるような非標準的なテキストをセグメント化するためにラベル付けされたデータを使用することによって、それらをさらに制約します。具体的には、私たちのハイブリッドモデルは、判別型分類子（ ＣＲＦ ； Ｌａｆｆｅｒｔｙ ｅ ｔ ａ ｌ ． （ ２ ０ ０ １ ） ）と非監視型単語セグメンテーション（ ＮＰＹＬＭ ； Ｍｏｃｈｉｈａｓｈｉ ｅ ｔ ａ ｌ ． （ ２ ０ ０ ９ ） ）を組み合わせ、これら２つのモデル構造間で半監視型フレームワーク内で透明な情報交換を行う（ ＪＥＳＳ － ＣＭ ； Ｓｕｚｕｋｉ ａｎｄ Ｉｓｏｚａｋｉ （ ２ ０ ０ ８ ） ）。TwitterやWeiboなどの非標準テキストを適切にセグメント化でき、日本語、中国語、タイ語の標準データセットにほぼ最新の精度を持つことを確認しました。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>This paper represents a new HyBridge Generative/Diskimiative model of word segmentation supported on nonparametris bayesi method. Genjer-genjer diunting langgar sampeyan kuwi wis dipun ciptaaken sing wis etiket data, kita model sing wis nguasai nyimpen a langgar sampeyan nganggo dolanan sing gak bener Awak dhéwé, pilihan model nyebutaké kelompok kelompok dislikasi (CF; Laffty et al.(2011) lan segmentation awak dhéwé Awak dhéwé wis ngênggunaké karo akeh basa sing gak bener tentang karo Google lan weibo lan saiki karo hal-hal layang-layang sampek awak dhéwé kuwi awak dhéwé kuwi basa sing japané, Cino lan Yulan.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ეს დომენტი ახლა პრომენტიური ჰიბრიდის გენერაციური/დისკრიმინატიური სიტყვების სეგმენტის მოდელი, რომელიც არ პარამეტრიური ბეიზიანური მეცედიების ჩვენი პროგრამიური დისკრიმინატიური სიტყვების სეგმენტის განმავლობაში, რომელიც მხოლოდ მართლად მართლაც მართლაც მართლაც მართლაც მართლად მართლად მონაცემებული მოდელზე, ჩვენი პროგრამიური მართლაც მართლად ახალი 'სიტყვები' მოსწავლად განსაკუთრებულია, ჩვენი ჰიბრიდი მოდელი დისკრიმინატიური კლასიფიკაციატორია (CRF; Lafferty et al. (2001) და არ განსაკუთრებული სიტყვების სეგმენტია (NPYLM; Mochihashi et al. (2009)), ამ ორი მოდელური სტრუქტურების განსაკუთრებული ინფორმაციის გადაცვლა (JESS-CM; Suzuki და Isozaki (2008 ჩვენ დარწმუნეთ, რომ ეს შეუძლია საპირო, ჩინტერვირში და საიბოში სტანდარტური ტექსტების სწორედ სექმენტური სექმენტური სექმენტის მართლაც იქნება და საიბოში სექმენტური</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Бұл қағаз бейезия әдістеріне негізделген романдық гибридтік/дискриминациялық сөздерді сегментациялау үлгісін көрсетеді. Кәдімгі дискриминациялық сөздердің сегментациясы, тек жарлық деректеріне тәуелді, біздің жартық бақылау үлгіміз де жаңа 'сөздер' дегенді автоматты түрде үйрену үшін, жаңа 'сөздер' дегенді үйрену үшін үлкен мәтіндерді шектеп, жарлық деректерді қолдану ү Ескерту үшін, біздің гибрид моделіміз дискриминациялық классификациясы (CRF; Lafferty et al. (2001) және сөздер сегментациясы (NPYLM; Mochihashi et al. (2009)), бұл екі үлгі құрылғылар арасындағы мәліметті біріктіріп, жарты бақылау фреймінде (JESS- CM; Suzuki және Isozaki (2008)). Біз оның Твиттер мен Вайбо секілдерінің стандартты мәтіндері дұрыс емес екенін баптап, жапон, қытайлық және Тайландық стандартты деректер жиындарының стандартты дұрыстығы бар деп ойладық.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>비변수 베일스 방법을 바탕으로 한 혼합 생성/판별 분사 모델을 제시했다.표기 데이터에만 의존하는 일반적인 구분적 단어와 달리 우리의 반감독모델은 대량의 표기되지 않은 텍스트를 이용하여 새로운'단어'를 자동으로 학습하고 표기 데이터를 사용하여 비표준적인 텍스트(예를 들어 소셜네트워크서비스의 텍스트)를 분할함으로써 그것들을 더욱 제한한다.구체적으로 말하자면 우리의 혼합모델은 판별분류기(CRF, Lafferty 등(2001)과 무감독분사(NPYLM, 모치하시 등(2009)와 반감독틀 안의 이 두 모델 구조 간의 투명한 정보 교환(JESS-CM, Suzuki와 Isozaki(2008)을 결합시켰다.트위터와 웨이보 등 비표준 텍스트를 적절하게 분할할 수 있고 일본어, 중국어, 태국어의 표준 데이터 집합에서 가장 선진적인 정확성을 지니고 있음을 확인했다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Šiame dokumente pateikiamas naujas hibridinis ir (arba) diskriminacinis žodžių segmentavimo modelis, grindžiamas ne parametriniais Bayezijos metodais. Priešingai nei įprastas diskriminacinis žodžių segmentavimas, kuris grindžiamas tik pažymėtais duomenimis, mūsų pusiau prižiūrimas modelis taip pat sutelkia didžiulį kiekį nežymėto teksto, kad būtų galima automatiškai išmokti naujų žodžių, ir toliau apriboja juos naudojant pažymėtus duomenis, kad būtų galima segmentuoti nestandartinius tekstus, pvz., socialinių tinklų paslaugų tekstus. Konkrečiai, mūsų hibridinis modelis derina diskriminacinį klasifikatorių (CRF; Lafferty et al. (2001) ir nepastebimą žodžių segmentavimą (NPYLM; Mochihashi et al. (2009)), skaidrų šių dviejų modelių struktūrų keitimąsi informacija pagal pusiau prižiūrimą sistemą (JESS-CM; Suzuki ir Isozaki (2008)). Patvirtinome, kad ji gali tinkamai suskirstyti nestandartinius tekstus, kaip antai tekstus Twitter ir Weibo, ir turi beveik naujausią tikslumą standartinių duomenų rinkinių japonų, kinų ir tailandų kalbomis.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Овој весник претставува нов хибриден генерационален/дискриминативен модел на зборна сегментација базиран на непараметричките бајезиски методи. За разлика од обичната дискриминативна сегментација на зборови која се потпира само на означени податоци, нашиот полунадгледуван модел, исто така, користи огромна количина неозначен текст за автоматски да се научи нови „зборови“, и понатаму ги ограничува со користење означени податоци за сегментирање нестандардни тексти како што се оние Специфично, нашиот хибриден модел комбинира дискриминативен класификатор (ЦРФ; Лаферти и г. (2001) и ненадгледувана словена сегментација (НПЈЛМ; Мочихаши и г. (2009)), со транспарентна размена на информации помеѓу овие две моделни структури во полунадгледуваната рамка (ЈЕСС-ЦМ; Сузуки и Исозаки (2008 Потврдивме дека може соодветно да ги дели нестандардните тексти како оние на Твитер и Вајбо и има скоро најсовремена точност на стандардните податоци на јапонски, кинески и тајландски.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ഈ പത്രത്തില്‍ ഒരു നോവല്‍ ഹൈബ്രിഡിന്റെ ജനററിവ്/വിവേചനയുടെ മോഡല്‍ കാണിക്കുന്നു. പാരാമെറ്റിക് ബെയിസിയന്‍ രീതികളില്‍ അടിസ് സാധാരണ വാക്കുകളുടെ വിഭാഗത്തില്‍ വ്യത്യസ്തമായ വാക്കുകള്‍ വേര്‍തിരിച്ചറിയുന്നതില്‍ മാത്രം വിശ്വസിക്കുന്നു. നമ്മുടെ സെമി-നോട്ട് നിരീക്ഷിക്കപ്പെട്ട മോഡല്‍ സ്വയം പുതിയ വാക്കുകള്‍ പഠ പ്രത്യേകിച്ച്, നമ്മുടെ ഹൈബ്രിഡ് മോഡല്‍ ഒരു വ്യത്യസ്ത വ്യവസ്ഥയെ കൂട്ടിക്കൊണ്ടിരിക്കുന്നു (CRF; Lafferty et al. (2001) പിന്നെ സൂക്ഷിക്കാത്ത വാക്ക് സംഘടിപ്പിക്കുന്നതും (NPYLM; മൊചിഹാഷി et al. (2009)), ഈ രണ്ട് മോഡല്‍ ഘ ഞങ്ങള്‍ ഉറപ്പ് വരുത്തിയിരിക്കുന്നു ഇത് ടൂട്ടരും വെയിബോയിലും സ്ഥാനമില്ലാത്ത പദാവലികള്‍ക്ക് വേര്‍പെടുത്താന്‍ സാധിക്കുന്നു. ജാപ്പാനീസ്, ചൈനീ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Энэ цаас биезийн арга баримтгүй үг загварын шинэ гибрид үүсгэгч/ялгаагүй загварыг харуулдаг. Шинэ үгийг автоматжуулахын тулд бидний хагас удирдлагагүй загвар мөн шинэ үгийг автоматжуулахын тулд маш их хэмжээний хэмжээг ашигладаг. Ялангуяа бидний гибрид загвар нь тархалтын хуваагдагч (CRF; Lafferty et al. (2001) болон бусад үг загвар (NPYLM; Mochihashi et al. (2009)) хоёр загварын байгууллагуудын хоорондын тодорхой мэдээллийг хагас удирдаггүй хэлбэрээр (JESS-CM; Suzuki, Isozaki (2008)-ын хоорондын тодорхой хувьцааны хувьцааны Бид үүнийг Твиттер, Вэйбо хоёр шиг стандарт биш текстүүдийг зөвхөн загварчлах боломжтой гэдгийг баталсан. Япон, Хятад, Тайланд стандарт өгөгдлийн сангийн зөв байдал бараг л байдаг.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kertas ini memperkenalkan model hibrid baru generatif/diskriminatif segmen perkataan berdasarkan kaedah Bayesian bukan parametrik. Tidak seperti segmen perkataan diskriminatif biasa yang hanya bergantung pada data yang ditabel, model setengah-mengawasi kami juga menggunakan jumlah besar teks tidak ditabel untuk secara automatik belajar 'perkataan' baru, dan halang lebih lanjut mereka dengan menggunakan data ditabel untuk segmen teks bukan piawai seperti yang ditemui dalam perkhidmatan rangkaian sosial. Secara khusus, model hibrid kami menggabungkan pengklasifikasi diskriminatif (CRF; Lafferty et al. (2001) dan segmen perkataan tidak diawasi (NPYLM; Mochihashi et al. (2009)), dengan pertukaran maklumat yang jelas antara kedua-dua struktur model ini dalam kerangka setengah diawasi (JESS-CM; Suzuki dan Isozaki (2008)). Kami mengesahkan bahawa ia boleh segmen teks yang tidak piawai seperti dalam Twitter dan Weibo dan mempunyai ketepatan hampir terbaik pada set data piawai dalam bahasa Jepun, Cina dan Thai.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>This paper presents a novel hybrid generative/discriminative model of word segmentation based on nonparametric Bayesian methods. Għall-kuntrarju tas-segmentazzjoni tal-kliem diskriminatorja ordinarja li tiddependi biss fuq dejta ttikkettata, il-mudell nofs superviż tagħna jgħaqqad ukoll ammonti kbar ta’ test mhux ittikkettat biex jitgħallmu awtomatikament ‘kliem’ ġodda, u jkompli jirrestrinġihom billi tuża dejta ttikkettata biex taqsam testi mhux standard bħal dawk misjuba fis-servizzi tan-netwerking soċjali. B’mod speċifiku, il-mudell ibridu tagħna jikkombina klassifikatur diskriminatorju (CRF; Lafferty et al. (2001) u segmentazzjoni tal-kliem mhux sorveljata (NPYLM; Mochihashi et al. (2009)), ma’ skambju trasparenti ta’ informazzjoni bejn dawn iż-żewġ strutturi mudell fi ħdan il-qafas semisorveljat (JESS-CM; Suzuki u Isozaki (2008)). Aħna kkonfermajna li tista' taqsam b'mod xieraq testi mhux standard bħal dawk fuq Twitter u Weibo u għandha kważi l-aktar preċiżjoni avvanzata fuq settijiet ta' dejta standard fil-Ġappuniż, Ċiniż u t-Tajlandiż.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Deze paper presenteert een nieuw hybride generatief/discriminatief model van woordsegmentatie gebaseerd op niet-parametrische Bayesiaanse methoden. In tegenstelling tot gewone discriminerende woordsegmentatie die alleen gebaseerd is op gelabelde gegevens, maakt ons semi-supervised model ook gebruik van een enorme hoeveelheid niet-gelabelde tekst om automatisch nieuwe 'woorden' te leren, en beperkt deze verder door een gelabelde gegevens te gebruiken om niet-standaard teksten zoals die in sociale netwerkdiensten te segmenteren. Specifiek combineert ons hybride model een discriminatieve classificator (CRF; Lafferty et al. (2001) en onbeheerde woordsegmentatie (NPYLM; Mochihashi et al. (2009)), met een transparante uitwisseling van informatie tussen deze twee modelstructuren binnen het semi-supervised framework (JESS-CM; Suzuki en Isozaki (2008)). We hebben bevestigd dat het niet-standaard teksten zoals die in Twitter en Weibo geschikt kan segmenteren en bijna state-of-the-art nauwkeurigheid heeft op standaard datasets in het Japans, Chinees en Thais.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Denne papiret viser ein novel hybrid-generativ/diskrimineriv modell for ordsegmentasjon basert på ikkje-parametriske Bayesianske metodar. I motsetjing til vanleg diskriminasjon av ordsegmentasjon som berre dependerer på merkelige data, vår halvoversikt modellen leverer også ein stor mengd av ikkje merkelige tekst til å automatisk læra nye ord, og framleis begrenser dei ved å bruka eit merkelige data til å segmentera ikkje-standard tekstar, slik som dei funne i sosiale nettverktjenester. Spesielt kombinerer hibridmodellen vårt ein diskriminativ klassifisering (CRF; Lafferty et al. (2001) og uverkjende ordsegmentasjon (NPYLM; Mochihashi et al. (2009)), med ein gjennomsiktig utveksling av informasjon mellom disse to modelle strukturene i semioversikte rammeverket (JESS-CM; Suzuki og Isozaki (2008)). Vi stadfestig at det kan dele ikkje-standardtekstar som dei i Twitter og Weibo og har nesten kunstige nøyaktighet på standard datasett i japansk, kinesisk og Thai.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>W artykule przedstawiono nowy hybrydowy model segmentacji słów generatywnych/dyskryminacyjnych oparty na nieparametrycznych metodach Bayesowskich. W przeciwieństwie do zwykłej segmentacji słów dyskryminacyjnych, która opiera się wyłącznie na danych etykietowanych, nasz model pół-nadzorowany wykorzystuje również ogromne ilości nieetykietowanego tekstu do automatycznego uczenia się nowych "słów" i dodatkowo ogranicza je poprzez wykorzystanie etykietowanych danych do segmentowania niestandardowych tekstów, takich jak te znajdujące się w serwisach społecznościowych. W szczególności nasz model hybrydowy łączy w sobie klasyfikator dyskryminacyjny (CRF; Lafferty i al. (2001) oraz segmentację słów bez nadzoru (NPYLM; Mochihashi i al. (2009)), z przejrzystą wymianą informacji między tymi dwoma strukturami modelowymi w ramach pół-nadzorowanych (JESS-CM; Suzuki i Isozaki (2008)). Potwierdziliśmy, że może odpowiednio segmentować niestandardowe teksty, takie jak te na Twitterze i Weibo oraz posiada niemal najnowocześniejszą dokładność na standardowych zbiorach danych w języku japońskim, chińskim i tajskim.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Este artigo apresenta um novo modelo híbrido generativo/discriminativo de segmentação de palavras baseado em métodos bayesianos não paramétricos. Ao contrário da segmentação discriminativa de palavras comum, que se baseia apenas em dados rotulados, nosso modelo semi-supervisionado também aproveita uma enorme quantidade de texto não rotulado para aprender automaticamente novas “palavras” e as restringe ainda mais usando dados rotulados para segmentar textos não padronizados, como aqueles encontrados em serviços de redes sociais. Especificamente, nosso modelo híbrido combina um classificador discriminativo (CRF; Lafferty et al. (2001) e segmentação de palavras não supervisionada (NPYLM; Mochihashi et al. (2009)), com uma troca transparente de informações entre essas duas estruturas de modelo dentro do semi- estrutura supervisionada (JESS-CM; Suzuki e Isozaki (2008)). Confirmamos que ela pode segmentar adequadamente textos não padronizados como os do Twitter e Weibo e tem precisão quase de última geração em conjuntos de dados padrão em japonês, chinês , e tailandês.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Această lucrare prezintă un nou model generativ/discriminatoriu hibrid de segmentare a cuvintelor bazat pe metode bayesiane non-parametrice. Spre deosebire de segmentarea discriminativă obișnuită a cuvintelor, care se bazează numai pe date etichetate, modelul nostru semi-supravegheat utilizează, de asemenea, o cantitate uriașă de text nelimitat pentru a învăța automat noi "cuvinte", și le constrânge în continuare prin utilizarea unor date etichetate pentru a segmenta texte nestandard, cum ar fi cele găsite în serviciile de rețele sociale. Mai exact, modelul nostru hibrid combină un clasificator discriminatoriu (CRF; Lafferty et al. (2001) și segmentarea cuvintelor nesupravegheată (NPYLM; Mochihashi et al. (2009)), cu un schimb transparent de informații între aceste două structuri de model în cadrul semi-supravegheat (JESS-CM; Suzuki și Isozaki (2008)). Am confirmat că poate segmenta în mod corespunzător texte non-standard precum cele din Twitter și Weibo și are o acuratețe aproape de ultimă oră pe seturile de date standard în japoneză, chineză și thailandeză.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>В данной работе представлена новая гибридная генеративная/дискриминационная модель сегментации слов, основанная на непараметрических байесовских методах. В отличие от обычной дискриминационной сегментации слов, которая опирается только на помеченные данные, наша полунадзорная модель также использует огромное количество немеченного текста для автоматического изучения новых «слов» и дополнительно ограничивает их, используя помеченные данные для сегментации нестандартных текстов, таких как тексты, найденные в социальных сетях. В частности, наша гибридная модель сочетает в себе дискриминационный классификатор (CRF; Lafferty et al. (2001) и неконтролируемую сегментацию слов (NPYLM; Mochihashi et al. (2009)) с прозрачным обменом информацией между этими двумя модельными структурами в рамках полуконтролируемой структуры (JESS-CM; Suzuki and Isozaki (2008)). Мы подтвердили, что он может соответствующим образом сегментировать нестандартные тексты, такие как тексты в Twitter и Weibo, и имеет почти самую современную точность на стандартных наборах данных на японском, китайском и тайском языках.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>මේ පැත්ත පෙන්වන්නේ නොපාරාම්ටරික බේසියාන් විදියට ආධාරිත විදියට නිර්මාණික/විශ්වාසික විදියට ප්‍ර නැත්තම් සාමාන්‍ය විශ්වාසික වචන සැකසුම් වචන සැකසුම් වලින් විතරයි ලේබල් වලින් විතරයි, අපේ සාමාන්‍ය විශ්වාසිත විදියට ප්‍රමාණයක් තියෙන්නේ ලේබල් වලින් ලේබල් වලි විශේෂයෙන්, අපේ හිබ්‍රිඩ් මොඩල් සම්බන්ධ විශ්වාසිත විශේෂකය (CRF; Lafferty et al. (2001) සහ නොසුපෙර්වසිත වචනය (NPYLM; Mochihashi et al. (2009)), සහ පාරදානම් සම්බන්ධ විශේෂකයේ තොරතුරු අතර මෙම් මොඩල් ස අපි සැකසුම් කළා ඒක ට්විටර් සහ වේබෝ වලින් ප්‍රමාණයෙන් නොප්‍රමාණයෙන් පිළිබඳ වෙන්න පුළුවන් කියලා, ජාපාන්, චීනි සහ තායින</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>V prispevku je predstavljen nov hibridni generativni/diskriminativni model segmentacije besed, ki temelji na neparametričnih bajezijskih metodah. Za razliko od običajne diskriminacijske segmentacije besed, ki temelji samo na označenih podatkih, naš pol nadzorovan model uporablja tudi ogromne količine neoznačenega besedila za samodejno učenje novih besed in jih še dodatno omejuje z uporabo označenih podatkov za segmentiranje nestandardnih besedil, kot so besedila, ki jih najdemo v storitvah socialnih omrežij. Natančneje, naš hibridni model združuje diskriminativni klasifikator (CRF; Lafferty et al. (2001) in nenadzorovano segmentacijo besed (NPYLM; Mochihashi et al. (2009)), s pregledno izmenjavo informacij med tema dvema strukturama modela znotraj polnadzorovanega okvira (JESS-CM; Suzuki in Isozaki (2008)). Potrdili smo, da lahko ustrezno segmentira nestandardna besedila, kot sta tista v Twitterju in Weibu, ter ima skoraj najsodobnejšo točnost standardnih naborov podatkov v japonščini, kitajščini in tajščini.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Qoraalkan wuxuu soo saaraa qaab dhaqan/takooris ah oo ku saleysan qaababka ay Bayesian ku qoran yihiin. Kala duwan qayb-takoorista ah oo ku xiran macluumaadka calaamadda oo kaliya, noocyadana halka ka ilaaliyey wuxuu sidoo kale ku fidiyaa warqad badan oo aan la qorin si ay u barato hadal cusub, waxaana sidoo kale ku qasba isticmaalka macluumaad labo ah si ay u kala qeybiso qoraal aan caadi ahayn, sida kuwa laga helay adeegyada shabakadda bulshada. Sida gaar ah, modelheenna hybrid wuxuu isku biiriyaa takooris (CRF; Lafferty et al. (2001) iyo unsupervised word segmentation (NPYLM; Mochihashi et al. (2009)), waxaana la bedelay macluumaad muuqaal ah oo u dhexeeya labadaas dhismaha model hoose-hoose-ilaaliyey (JESS-CM; Suzuki iyo Isozaki (2008). Waxaannu xaqiijinnay inay si saxda ah u qeyb-dhigi karto qoraal aan caadi ahayn sida Twitterka iyo Weibo, waxayna ku leedahay saxda xaaladda farshaxanka ah oo ku saabsan sawirada caadiga ah ee japaniya, Shiino iyo Thai.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ky dokument paraqet një model të ri hibridik gjenerativ/diskriminues të segmentimit të fjalëve bazuar në metodat jo parametrike Bayesian. Unlike ordinary discriminative word segmentation which relies only on labeled data, our semi-supervised model also leverages a huge amounts of unlabeled text to automatically learn new 'words', and further constrains them by using a labeled data to segment non-standard texts such as those found in social networking services. Specifically, our hybrid model combines a discriminative classifier (CRF; Lafferty et al. (2001) and unsupervised word segmentation (NPYLM; Mochihashi et al. (2009)), with a transparent exchange of information between these two model structures within the semi-supervised framework (JESS-CM; Suzuki and Isozaki (2008)). We confirmed that it can appropriately segment non-standard texts like those in Twitter and Weibo and has nearly state-of-the-art accuracy on standard datasets in Japanese, Chinese, and Thai.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ovaj papir predstavlja nov hibridni generativni/diskriminacijski model segmentacije reèi na osnovu neparametričkih Bayesijskih metoda. Za razliku od obične diskriminacijske segmentacije riječi koja se oslanja samo na etiketirane podatke, naš polu nadzorni model takođe utiče na ogromne količine nenabeliranog teksta da automatski nauči nove 'reči', i dalje ih ograničava koristeći etiketirane podatke na segmentirane ne standardne tekste kao što su pronađene u socijalnim mrežnim uslugama. Posebno, naš hibridni model kombinira diskriminativnu klasifikaciju (CRF; Lafferty et al. (2001) i neodređenu segmentaciju riječi (NPYLM; Mochihashi et al. (2009)), sa transparentnom razmjenom informacija između tih dva modelnih struktura u polu nadzornom okviru (JESS-CM; Suzuki i Isozaki (2008)). Potvrdili smo da može odgovarajući segmentirati ne-standardne tekstove poput one na Twitter i Weibo i da ima skoro stanje umjetnosti tačnosti na standardnim setima podataka na japanskom, kineskom i Tajlandu.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Denna uppsats presenterar en ny hybrid generativ/diskriminerande modell av ordsegmentering baserad på icke-parametriska bayesiska metoder. Till skillnad från vanlig diskriminerande ordsegmentering som bara bygger på märkta data, utnyttjar vår halvövervakade modell också enorma mängder omärkt text för att automatiskt lära sig nya "ord", och begränsar dem ytterligare genom att använda en märkt data för att segmentera icke-standardiserade texter som de som finns i sociala nätverkstjänster. Specifikt kombinerar vår hybridmodell en diskriminerande klassificerare (CRF; Lafferty m.fl. (2001) och obevakad ordsegmentering (NPYLM; Mochihashi m.fl. (2009)), med ett transparent informationsutbyte mellan dessa två modellstrukturer inom det halvövervakade ramverket (JESS-CM; Suzuki och Isozaki (2008)). Vi bekräftade att det på lämpligt sätt kan segmentera icke-standardtexter som de i Twitter och Weibo och har nästan toppmodern noggrannhet på standarddataset på japanska, kinesiska och thailändska.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Gazeti hili linaonyesha muundo wa kutengenezwa/ubaguzi wa maneno kwa kutumia mbinu zisizo za kibiashara za Bayesia. Tofauti na utofauti wa neno la kawaida ambalo linategemea tu kwa taarifa zilizowekwa, modeli yetu ya sekondari pia inatumia kiasi kikubwa cha maandishi yasiyopangwa kwa kujifunza kwa kujifunza 'maneno mpya' na pia inawazuia kwa kutumia taarifa zilizoonyesha ili kugawanya maandishi yasiyo ya kawaida kama vile zile zilizopatikana katika huduma za mitandao ya kijamii. Kwa ujumla, modeli yetu ya hybrid inaunganisha mchanganyiko wa tofauti (CRF; Differty et al. (2001) na mchanganyiko wa neno lisilo na uhakika (NPYLM; Mochihashi et al. (2009)), na kubadilishana kwa uwazi kati ya miundo mbili ya miundo mbili ndani ya mfumo ulioangaliwa na semi (JESS-CM; Suzuki na Isozaki (2008). Tulithibitisha kwamba inaweza kutengeneza maandishi yasiyo ya kawaida kama wale kwenye mtandao wa Twita na Weibo na ina karibu sahihi ya hali ya sanaa kuhusu seti za taarifa za kawaida nchini Japani, China na Thai.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>இந்த காகிதத்தின் புதிய ஹைப்ரிட் பொதுவான/வித்தியாசமான வார்த்தை துண்டுதல் மாதிரியை கொடுக்கிறது பயீசியன் முறைமை வழக்கமான வார்த்தை பிரிவு துண்டு மட்டும் குறிப்பிட்ட தகவல் மீது நம்புகிறது, எங்கள் பாமி கண்காணிக்கப்பட்ட மாதிரி ஒரு மிகப் பெரிய எண்ணிக்கையை வழங்குகிறது புதிய 'வார்த்தைகளை தானாகவே கற்று குறிப்பிட்டு, எங்கள் ஹைப்ரிட் மாதிரி ஒரு வித்தியாசமான வகுப்பாட்டாளரை (CRF; Lafferty et al. (2001) மற்றும் பாதுகாப்பாக்கப்படாத வார்த்தை திருத்தல் (NPYLM; Mochihashi et al. (2009)), பெமி கண்காணிக்கப்பட்ட சட்டத்தில் இந்த இரண்டு மாதிர நாங்கள் உறுதிப்படுத்தினோம் அது சரியான நிலையான அல்லாத எழுத்துக்களை துண்டிக்க முடியும் என்பதை நிர்ணயித்துள்ளோம் டூட்டர் மற்றும் வெய்போவி</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bu kagyz Beýeziýanyň döwletlerinde daýanýan hybrid jenerativ/diskriminçy söz segmentasyň nusgasyny görkezýär. Adatça diskriminçy söz segmentasiýasynda diňe etiket edilen maglumatlara güýçlän däldir, hem biziň semi-kontrol modelimiz täze sözleri otomatik bilen öwrenmek üçin ullanmaýan täze bir şekilde täsirleýär we olaryň etiket edilen maglumatlaryny sosyal netek hızmetinde tapylan metinleri bölmek üçin ýüzünde süýtgeder. Adatça, biziň hybrid modelimiz diskriminät klassifikatçisini (CRF; Lafferty et al. (2001) we suýruklanmaýan söz segmentasyny (NPYLM; Mochihashi et al. (2009)), bu iki nusga arasynda semi-kontrol edilen çerçewçiwde bir terjime edip bilen informasiýa çykýar (JESS-CM; Suzuki we Isozaki (2008)). Biz Twitter, Weibo ýaly standart metinleriniň dogry ýagdaýynda taýýarlap biler diýip kabul etdik we ol Japonça, Çin çe we Taýlандa standart veri setirleriniň dogrylygyny hasapladyk.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>This paper presents a new hybrid generative/discriminative model of word segmentation based on nonparametric Bayesian methods. جو صرف لابلیٹ ڈاٹ پر اعتماد ہے، ہماری نصف نظارت والی مدل نے اپنا بہت بڑا مقدار غیر لابلیٹ لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہوا لکھا ہے خاص طور پر، ہمارا ہیبراڈ موڈل ایک تقسیم کلاسیر (CRF; Lafferty et al. (2001) اور غیر قابل تغییر دینے والی کلاسیر (NPYLM; Mochihashi et al. (2009)) کے ساتھ ان دو موڈل ساختاروں کے درمیان نیم-supervised فرمود (JESS-CM; Suzuki اور Isozaki (2008)) کے درمیان مطلوبہ کی تبدیل کی جاتی ہے۔ ہم نے مطمئن کیا کہ یہ ٹویٹر اور ویبو میں ایسے بغیر استاندارڈ ٹیکسٹ کے مطابق قطع کر سکتا ہے اور قریب تھا کہ اسٹارڈ سٹ کے استاندارڈ سٹ پر جاپانی, چینی اور تائیل میں استاندارڈ سٹ کے مطابق صحیح ہے.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bu qogʻoz parametrik Bayesian usulda asoslangan so'z segment modelini yaratadi. Oddiy ajratilgan so'zlar tarkibini faqat notoʻgʻri maʼlumotga ishlatadi, bizning semi-taʼminlovchi modelimiz yangi so'zlarni avtomatik o'rganish uchun juda katta qismi yordam beradi, va ular soʻzlarni avtomatik o'rganish uchun qo'llangan maʼlumot yordamida qo'llangan soʻzlarni boshqa tarmoq xizlarida o'zgartirish mumkin. Ko'rsatilgan, bizning hybrid modelimiz ajratish darajasini (CRF; Lafferty et al. (2001) va xavfsizlanmagan so'zni ajratish (NPYLM; Mochihashi et al. (2009)) bilan bir necha saqlangan jadvaldagi ikki modellar tarkibida maʼlumotni ajratish (JESS-CM; Suzuki va Isozaki (2008). Biz ishonch qildikki, bu Twitter va Weibo kabi oddiy matnlarni o'zgartirish mumkin, va yaponiya, Xitoycha va Tay tilidagi стандарт maʼlumotlar tizimini aniqlash mumkin.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tờ giấy này có một mô hình nhân tạo và phân biệt các từ khác nhau dựa trên các phương pháp không phân đo định người Bayisian. Không giống phân đoạn các từ riêng biệt bình thường chỉ dựa trên các dữ liệu được dán nhãn, mô hình bán giám sát của chúng ta cũng dùng một lượng lớn các chữ chưa được dán vào để tự động học các chữ mới, và giới hạn chúng bằng cách dùng các dữ liệu dán nhãn để phân đoạn các văn bản không tiêu chuẩn như những chữ được tìm thấy trong dịch vụ mạng xã hội. Cụ thể, mô hình lai của chúng ta kết hợp một phân loại riêng biệt (CRF, Lafferty et al. (2001) và phân biệt các từ không giám sát (không riêng (không thể nói: không thể: không thể, Mochihashi et al (2009), với một trao đổi thông tin trong suốt... giữa hai cấu trúc mô hình này trong quá trình giám sát (Jesus-CM; Suzuki và Isozaki (kế thừa) Chúng tôi xác nhận rằng nó có thể phân đoạn các văn bản không tiêu chuẩn như trên Twitter và Weibo và có độ chính xác cao nhất trên các tập tin tiêu chuẩn của Nhật, Trung Quốc và Thái.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>立一本于非参数贝叶斯法者分词混而成/判别模形。 与仅依表数之普通区分性分词不同,吾半监模犹以大未标之文本自习新单词,因用标数对非标准文本(如社交网络服务中文本)细分以约束之。 具体来说,合刑合器(CRF。 Lafferty等(2001)与无监分词(NPYLM。 Mochihashi等(2009)),于半监框架内两样透明易信(JESS-CM。 铃木和矶崎新(2008))。 臣等证之,可以适割非标准本,如Twitter微博中之本,并在日语,中文泰语之数集上有近先进之准确性。</span></div></div><dl><dt>Anthology ID:</dt><dd>Q17-1013</dd><dt>Volume:</dt><dd><a href=/volumes/Q17-1/>Transactions of the Association for Computational Linguistics, Volume 5</a></dd><dt>Month:</dt><dd></dd><dt>Year:</dt><dd>2017</dd><dt>Address:</dt><dd>Cambridge, MA</dd><dt>Venue:</dt><dd><a href=/venues/tacl/>TACL</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>MIT Press</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>179–189</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/Q17-1013>https://aclanthology.org/Q17-1013</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.1162/tacl_a_00054 title="To the current version of the paper by DOI">10.1162/tacl_a_00054</a></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">fujii-etal-2017-nonparametric</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Ryo Fujii, Ryo Domoto, and Daichi Mochihashi. 2017. <a href=https://aclanthology.org/Q17-1013>Nonparametric Bayesian Semi-supervised Word SegmentationBayesian Semi-supervised Word Segmentation</a>. <i>Transactions of the Association for Computational Linguistics</i>, 5:179–189.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/Q17-1013>Nonparametric Bayesian Semi-supervised Word SegmentationBayesian Semi-supervised Word Segmentation</a> (Fujii et al., TACL 2017)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/Q17-1013.pdf>https://aclanthology.org/Q17-1013.pdf</a></dd><dt class=acl-button-row>Video:</dt><dd class=acl-button-row><a href=https://vimeo.com/238235035 class="btn btn-attachment btn-sm"><i class="fas fa-video"></i>&nbsp;https://vimeo.com/238235035</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/Q17-1013.pdf title="Open PDF of 'Nonparametric Bayesian Semi-supervised Word SegmentationBayesian Semi-supervised Word Segmentation'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Nonparametric+Bayesian+Semi-supervised+Word+SegmentationBayesian+Semi-supervised+Word+Segmentation" title="Search for 'Nonparametric Bayesian Semi-supervised Word SegmentationBayesian Semi-supervised Word Segmentation' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'Nonparametric Bayesian Semi-supervised Word SegmentationBayesian Semi-supervised Word Segmentation'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a>
<a class="btn btn-attachment d-flex flex-wrap justify-content-center" href=https://vimeo.com/238235035 title="Open video for 'Nonparametric Bayesian Semi-supervised Word SegmentationBayesian Semi-supervised Word Segmentation'"><span class="align-self-center px-1"><i class="fas fa-video"></i></span>
<span class=px-1>Video</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[Nonparametric Bayesian Semi-supervised Word SegmentationBayesian Semi-supervised Word Segmentation](https://aclanthology.org/Q17-1013) (Fujii et al., TACL 2017)</p><ul class=mt-2><li><a href=https://aclanthology.org/Q17-1013>Nonparametric Bayesian Semi-supervised Word SegmentationBayesian Semi-supervised Word Segmentation</a> (Fujii et al., TACL 2017)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Ryo Fujii, Ryo Domoto, and Daichi Mochihashi. 2017. <a href=https://aclanthology.org/Q17-1013>Nonparametric Bayesian Semi-supervised Word SegmentationBayesian Semi-supervised Word Segmentation</a>. <i>Transactions of the Association for Computational Linguistics</i>, 5:179–189.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>