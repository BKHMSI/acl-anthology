<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Enhancing Answer Boundary Detection for Multilingual Machine Reading Comprehension - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="Enhancing Answer Boundary Detection for Multilingual Machine Reading Comprehension" name=citation_title><meta content="Fei Yuan" name=citation_author><meta content="Linjun Shou" name=citation_author><meta content="Xuanyu Bai" name=citation_author><meta content="Ming Gong" name=citation_author><meta content="Yaobo Liang" name=citation_author><meta content="Nan Duan" name=citation_author><meta content="Yan Fu" name=citation_author><meta content="Daxin Jiang" name=citation_author><meta content="Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics" name=citation_conference_title><meta content="2020/7" name=citation_publication_date><meta content="https://aclanthology.org/2020.acl-main.87.pdf" name=citation_pdf_url><meta content="925" name=citation_firstpage><meta content="934" name=citation_lastpage><meta content="10.18653/v1/2020.acl-main.87" name=citation_doi><meta property="og:title" content="Enhancing Answer Boundary Detection for Multilingual Machine Reading Comprehension"><meta property="og:image" content="https://aclanthology.org/thumb/2020.acl-main.87.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2020.acl-main.87"><meta property="og:description" content="Fei Yuan, Linjun Shou, Xuanyu Bai, Ming Gong, Yaobo Liang, Nan Duan, Yan Fu, Daxin Jiang. Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. 2020."><link rel=canonical href=https://aclanthology.org/2020.acl-main.87></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2020.acl-main.87.pdf>Enhancing Answer Boundary Detection for Multilingual Machine Reading Comprehension</a>
<a id=af_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Verbeter Antwoord Grens Opdekking vir veelvuldige Masjien Lees Kompresie</a>
<a id=am_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>የመልእክት ቀለም</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>تحسين اكتشاف حدود الإجابة لفهم القراءة للآلة متعددة اللغات</a>
<a id=az_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Çoxlu dilli maşın oxunması üçün Cevap Sədini Əlavə Et</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Подобряване на откриването на границите на отговорите за разбиране на многоезичното машинно четене</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>বহুভাষী মেশিন পাঠ করার জন্য উত্তর সীমান্ত সনাক্তি বৃদ্ধি করা হচ্ছে</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>རྒྱབ་སྐྱོར་ཚད་ལྡན་རྩིས་འཁོར་གྱི་ཀློག་འཇུག་བརྟན་པར་མཐུན་མཚམས་བསམ་བྱེད་བཞིན་པ</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Povećavanje ograničenja odgovora za kompresiju čitanja multijezičkih strojeva</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>millorar la detecció de límits de resposta per a la comprensió multilingüe de lectura de màquines</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Zlepšení detekce hranic odpovědi pro vícejazyčné čtení strojů</a>
<a id=da_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Forbedring af detektering af svargrænser for flersproget maskinlæseforståelse</a>
<a id=de_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Verbesserung der Erkennung von Antwortgrenzen für mehrsprachiges maschinelles Leseverständnis</a>
<a id=el_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Ενισχύοντας την ανίχνευση ορίων απάντησης για την πολυγλωσσική κατανόηση ανάγνωσης μηχανών</a>
<a id=es_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Mejora de la detección de límites de respuesta para una comprensión multilingüe de lectura</a>
<a id=et_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Vastuste piiride tuvastamise parandamine mitmekeelse masinlugemise mõistmiseks</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>افزایش پیدا کردن مرز پاسخ برای خواندن ماشین‌های زیادی زبان</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Vastausrajoitusten tunnistuksen parantaminen monikielisen konelukutaidon ymmärtämiseen</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Améliorer la détection des limites de réponse pour la compréhension de la lecture automatique multilingue</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Brath Teorainneacha Freagraí a Fheabhsú le haghaidh Léamhthuiscint Meaisín Ilteangach</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>@ action</a>
<a id=he_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>משפר את גילוי הגבול של תשובות עבור ביטוי קריאת מכונות רבות שפתיים</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>बहुभाषी मशीन पढ़ने की समझ के लिए उत्तर सीमा का पता लगाने को बढ़ाना</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Povećavanje granice otkrivanja odgovora za kompresiju pročitanja višejezičkih strojeva</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>A válaszok határérzékelésének javítása a többnyelvű gépi olvasási értékeléshez</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Enhancing Answer Boundary Detection for Multilingual Machine Reading Comprehension</a>
<a id=id_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Enhancing Answer Boundary Detection for Multilingual Machine Reading Comprehension</a>
<a id=is_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Miglioramento del rilevamento dei limiti delle risposte per la comprensione della lettura automatica multilingue</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>多言語マシン読み取り理解のための回答境界検出の強化</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Ngubah Inggal Buftar</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>მრავალენგური მაქინის კითხვის კომპრენციისთვის პასუხის ბრძანება</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Жауап шегін көп тілдік машинаны оқу құрылғысының шектерін шектеу</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>다국어 기계 읽기 이해 중의 답안 경계 검측 강화</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Padidinti atsakymų ribų nustatymą daugiakalbio mašinų skaitymo kompresijai</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Појачување на детекцијата на границите на одговорот за повеќе јазички компресија за читање машини</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>പല ഭാഷകള്‍ വായിക്കുന്ന യന്ത്രത്തിനുള്ള ഉത്തരം അതിര്‍ത്തിയുടെ കണ്ടുപിടിക്കുന്നു</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Хариулт хязгаарыг олон хэлний машин унших хэмжээний шалгалтыг нэмэгдүүлэх</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Meningkatkan Pengesanan Sempadan Jawapan untuk Pemahaman Pembacaan Mesin Berbahasa</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Titjib fid-Detezzjoni tal-Limitu tar-Rispons għall-Komprensjoni Multilingwi tal-Qari tal-Magni</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Verbetering van de detectie van antwoordgrenzen voor meertalige machineleesbegrippen</a>
<a id=no_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Forstørrar svargrenseoppdaging for fleirspråk lesing av maskinen</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Zwiększenie wykrywania granic odpowiedzi dla zrozumienia wielojęzycznego odczytu maszynowego</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Aprimorando a detecção de limite de resposta para compreensão de leitura de máquina multilíngue</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Îmbunătățirea detectării limitelor de răspuns pentru înțelegerea citirii mașinilor multilingve</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Улучшение определения границ ответов для понимания многоязычного машинного чтения</a>
<a id=si_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>ගොඩක් භාෂාවක් මැෂින් කියවන්න ප්‍රතික්‍රීයාවට ප්‍රතික්‍රියාත්මක සීමාව හොයාගන්න</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Izboljšanje zaznavanja meja odgovorov za razumevanje večjezičnega strojnega branja</a>
<a id=so_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Horumarinta ugu baaraandegista qalabka luuqadaha badan</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Duke përmirësuar zbulimin e kufirit të përgjigjeve për kompresimin e leximit të makinave shumëgjuhëse</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Povećavanje odgovornog ograničenja za kompresiju pročitanja višejezičkih mašina</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Förbättra detekteringen av svarsgränser för flerspråkig maskinläsförståelse</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Kuboresha Utafiti wa Mipaka wa Mashine ya Kilugha ya Kusoma Uwezeshaji</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>பல மொழி இயந்திரத்தை படிக்கும் முடிவுக்கு பதில் வரம்பு கண்டுபிடிப்பு அதிகப்படுத்தல்</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Çoklu dilli maşynyň okamak üçin Jogap Diňliki Aňlamak</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Multilingual Machine Reading Comprehension کے لئے جواب کے محدودیت کا اضافہ کرتا ہے</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Name</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>Phát hiện Kết giới trả lời phát hiện vĩ đại cho máy đọc đa ngôn ngữ</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2020.acl-main.87.pdf>增对案界检测,得多言机器读解</a></h2><p class=lead><a href=/people/f/fei-yuan/>Fei Yuan</a>,
<a href=/people/l/linjun-shou/>Linjun Shou</a>,
<a href=/people/x/xuanyu-bai/>Xuanyu Bai</a>,
<a href=/people/m/ming-gong/>Ming Gong</a>,
<a href=/people/y/yaobo-liang/>Yaobo Liang</a>,
<a href=/people/n/nan-duan/>Nan Duan</a>,
<a href=/people/y/yan-fu/>Yan Fu</a>,
<a href=/people/d/daxin-jiang/>Daxin Jiang</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Multilingual pre-trained models could leverage the training data from a rich source language (such as English) to improve performance on low resource languages. However, the transfer quality for multilingual Machine Reading Comprehension (MRC) is significantly worse than sentence classification tasks mainly due to the requirement of MRC to detect the word level answer boundary. In this paper, we propose two auxiliary tasks in the fine-tuning stage to create additional phrase boundary supervision : (1) A mixed MRC task, which translates the question or passage to other languages and builds cross-lingual question-passage pairs ; (2) A language-agnostic knowledge masking task by leveraging knowledge phrases mined from web. Besides, extensive experiments on two cross-lingual MRC datasets show the effectiveness of our proposed approach.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Veelvuldige voorafgeleerde modele kan die onderwerp data van 'n ryk bron taal (soos Engels) verwyder om uitvoering op lae hulpbron tale te verbeter. Maar die oordrag kwaliteit vir veelvuldige taal Masjien Lees Komprimensie (MRC) is betekeurig beter as soen klasifikasie taak hoofsaaklik vanweë die benodiging van MRC om die woord vlak antwoord grens te beskry. In hierdie papier, voorstel ons twee hulpbron opdragte in die fyn-tuning stadium om ekstra frase grense supervisie te skep: (1) ' n gemengde MRC opdrag, wat die vraag of deurgang na ander tale vertaling en kruistale vraag-wag paar bou; (2) ân Taal-agnostiese kennis wat die taak maskeer deur kennis frase wat uit die web gebruik word. Buiten, uitbreidige eksperimente op twee kruistale MRC-datastelle wys die effektiviteit van ons voorgestelde toegang.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>የፊተኛ ቋንቋ ተማሪ ሞዴላዎች ከሀብታም ምንጭ ቋንቋ (እንደ እንግሊዘኛ) የተጠቃሚ የድምፅ ቋንቋን ለማድረግ ይችላሉ፡፡ ምንም እንኳን ለብዙ ቋንቋዎች መሳሪያዎች መዝገብ ማነብ (MRC) የሚለውጥ ጥያቄ የቃላትን የደረጃ መልስ ዳርቻ ለማግኘት በሚያስፈልገው ከክፍለ መግለጫ ትክክል ነው፡፡ In this paper, we propose two auxiliary tasks in the fine-tuning stage to create additional phrase boundary supervision: (1) A mixed MRC task, which translates the question or passage to other languages and builds cross-lingual question-passage pairs; (2) የቋንቋ-አቀማመጥ እውቀት ማድረግ ከዌብ የተከሰረ የእውቀትን ቃላት በመስጠት በመስጠት ነው፡፡ በተጨማሪም፣ በሁለት የቋንቋ ቋንቋዎች የMRC ዳታ-ሰርቨርስቲ የሥልጣን ሥርዓት ያሳያል፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>يمكن للنماذج متعددة اللغات المدربة مسبقًا الاستفادة من بيانات التدريب من لغة مصدر غنية (مثل اللغة الإنجليزية) لتحسين الأداء في اللغات منخفضة الموارد. ومع ذلك ، فإن جودة النقل لفهم القراءة الآلي متعدد اللغات (MRC) أسوأ بكثير من مهام تصنيف الجملة ويرجع ذلك أساسًا إلى متطلبات MRC لاكتشاف حدود الإجابة على مستوى الكلمة. في هذا البحث ، نقترح مهمتين مساعدتين في مرحلة الضبط الدقيق لإنشاء إشراف إضافي على حدود العبارة: (1) مهمة MRC مختلطة ، والتي تترجم السؤال أو المقطع إلى لغات أخرى وتبني أزواجًا من أسئلة وممرات متعددة اللغات ؛ (2) مهمة إخفاء المعرفة الحيادية اللغة من خلال الاستفادة من عبارات المعرفة المستخرجة من الويب. إلى جانب ذلك ، تُظهر التجارب المكثفة على مجموعتي بيانات MRC متعدد اللغات فعالية نهجنا المقترح.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Çoxlu dil öyrənmiş modellər düşük ressurs dillərində performansını yaxşılaşdırmaq üçün çoxlu təhsil dilindən təhsil verilən məlumatları mümkün edə bilər. Lakin, çoxlu dil maşına oxuyan kompresiya (MRC) üçün tərəfindən cümlələr klasifikasiyasından daha pisdir, çünki sözlər səviyyəsinin cavabı sınırını tanıtmaq üçün MRC ehtiyacı olaraq. Bu kağızda, biz yaxşılıq tərzində iki yardımcı iş təklif edirik ki, əlavə fraz sınır tərzini yaratmaq: (1) Söyləni ya da başqa dillərə çevirir və çox dilli sual-keçiş çift in şa edir. (2) İnternetdən alınan elm ifazlarını silmək üçün dil-agnostik bilgi maskirləşdirir. Əksinə, iki dilli MRC veri qurularında geniş eksperimentlər bizim təklif etdiyimiz metodların etkinlik göstərir.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Многоезичните предварително обучени модели биха могли да използват данните за обучение от богат изходен език (като английски), за да подобрят ефективността на езиците с ниски ресурси. Въпреки това, качеството на прехвърляне за многоезично разбиране за машинно четене (МРК) е значително по-лошо от задачите за класификация на изреченията главно поради изискването на МРК да открива границата на отговора на ниво дума. В настоящата статия предлагаме две допълнителни задачи в етапа на фина настройка за създаване на допълнителен надзор на границите на фразата: (1) смесена задача за ДПС, която превежда въпроса или пасажа на други езици и изгражда междуезични двойки въпрос-пасаж; (2) Задача за маскиране на езиково-агностично знание чрез използване на фрази от знания, извлечени от интернет. Освен това, обширни експерименти с два междуезични масива от данни за МРС показват ефективността на предлагания от нас подход.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>অনেক ভাষায় প্রশিক্ষিত পূর্ববর্তী মডেল সমৃদ্ধ উৎস ভাষা থেকে প্রশিক্ষণের তথ্য প্রদান করতে পারে, যেমন ইংরেজী ভাষায় কম সম্পদ ভাষা তবে বহুভাষায় মেশিন পাঠ করার (এমআরসি) পরিবর্তনের মান বিনিময়ের মান বেশী খারাপ, মূলত এই শব্দের সীমানার সীমানা খুঁজে পাওয়ার জন্য এমআরসির কাজের চেয়ে বিশে এই কাগজটিতে আমরা সুন্দর ভাষায় দুটি কাজের প্রস্তাব করছি যাতে আরো বাক্য সীমানা পর্যবেক্ষণ তৈরি করা যায়: (১) একটি মিশ্রিত এমআরসি কাজ, যা অন্য ভাষায় প্রশ্ন অথবা পাসেজ অনুবাদ করে (২) ওয়েব থেকে মিনিয়ে যাওয়া জ্ঞানের বাক্ষর প্রদান করার মাধ্যমে একটি ভাষার জ্ঞানের জ্ঞান মুখোশ করার কাজ। এছাড়াও, দুই ভাষায় মিআরসি ডাটাসেটের বিস্তারিত পরীক্ষা দেখাচ্ছে আমাদের প্রস্তাবিত পদ্ধতির কার্যকর।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>སྐད་རིགས་ཀྱི་སྔོན་གྲངས་བསླབ་པའི་མིག་གཟུགས་འགྱུར་བའི་སྐད་ཡིག་ཆའི་ནང་ནས་གཙོ་ཆེ་ཤོས་ཡོད་པའི་ཚད་ལུགས་ཤིག་ཡོང་། ཡིན་ནའང་། སྐད་རིགས་ཀྱི་མ་ལག་གླེང་སྒྲུབ་ཀློག་པའི་གསལ་བཤད་ཀྱི་གནས་ཚུལ་མང་ཙམ་ཅིག་ཡིན་པས། འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་འུ་ཅག་གིས་ཕན་ཆེར་གྱི་ལས (2) སྐད་ཡིག་ཆ་དང་ཤེས་པའི་ཆ་འཕྲིན་གྱི་བྱ་འགུལ་ལ་ཉར་འཇུག་བྱེད་ཀྱི་ཡོད། དེ་མིན་ན། སྐད་རིགས་ཆ་མཐོ་འགྱུར་བའི་MRC གནད་སྡུད་ཆ་གྲངས་བརྟན་གྱིས་ང་ཚོའི་སྔོན་སྒྲིག་གི་ཐབས་ལམ་ལ་ལས་སྤྱོད</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mnogjezički predobučeni modeli bi mogli utjecati na podatke obuke sa bogatog jezika izvora (kao što je engleski) kako bi poboljšali učinkovitost na jezicima niskih resursa. Međutim, kvalitet prijenosa multijezičkih kompresija za čitanje mašina (MRC) je značajno gore od zadataka klasifikacije kazne uglavnom zbog zahtjeva MRC-a za otkrivanje granice odgovora na nivou riječi. U ovom papiru predlažemo dvije pomoćne zadatke u fazi finalnog prilagodbe da stvorimo dodatni granični nadzor fraza: (1) mješani zadatak MRC-a, koji prevodi pitanje ili prolaz na drugi jezici i izgradi preko jezika parove preko pitanja; (2) jezik-agnostičko znanje maskirajući zadatak uklanjanjem znanstvenih fraza iz mreže. Osim toga, široki eksperimenti na dva prekogranična MRC podataka pokazuju učinkovitost našeg predloženog pristupa.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Models multilingües de formació previa podrien aprofitar les dades de formació d'un llenguatge de fonts rics (com l'anglès) per millorar el rendiment en llengües de baix recursos. Però la qualitat de transfer ència de la Comprensió Multilingüe de Llegida de màquines (MRC) és significativament pitjor que les tasques de classificació de frases, principalment degut al requisit de la MRC per detectar el límit de resposta del nivell de paraules. En aquest paper, proposem dues tasques auxiliars a l'etapa d'ajustament per crear una supervisió adicional de les fronteres de frases: (1) Una tasca mixta de ressonància magnètica, que traduis la pregunta o el passatge a altres llengües i construeix parelles translingües de ressonància; (2) A language-agnostic knowledge masking task by leveraging knowledge phrases mined from web. A més, experiments extensos en dos conjunts de dades translingües de ressonància magnètica mostren l'eficacia del nostre enfocament proposat.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vícejazyčné předškolené modely by mohly využít data školení z bohatého zdrojového jazyka (například angličtiny), aby zlepšily výkon jazyků s nízkými zdroji. Nicméně kvalita přenosu pro vícejazyčné rozumění strojového čtení (MRC) je výrazně horší než úlohy klasifikace vět hlavně kvůli požadavku MRC detekovat hranici odpovědi na úrovni slova. V tomto článku navrhujeme dva pomocné úkoly ve fázi jemného ladění pro vytvoření dodatečného dohledu nad hranicemi frází: (1) Smíšený MRC úkol, který překládá otázku nebo pasáž do jiných jazyků a vytváří páry mezi jazyky otázkami a pasážemi; (2) Jazykově-agnostický úkol maskování znalostí využitím znalostních frází vytěžených z webu. Kromě toho rozsáhlé experimenty na dvou multilinguálních MRC datových sadách ukazují efektivitu našeho navrhovaného přístupu.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Flersprogede præuddannede modeller kan udnytte træningsdata fra et rigt kildesprog (f.eks. engelsk) for at forbedre ydeevnen på sprog med lave ressourcer. Overførselskvaliteten for flersproget maskinlæseforståelse (MRC) er dog væsentligt dårligere end sætningsklassificeringsopgaver hovedsageligt på grund af kravet om MRC til at detektere svargrænsen på ordniveau. I denne artikel foreslår vi to hjælpeopgaver i finjusteringsfasen for at skabe yderligere sætningsgrænseovervågning: (1) En blandet MRC-opgave, som oversætter spørgsmålet eller passagen til andre sprog og bygger tværsprogede spørgsmål-passage par; (2) En sprogagnostisk vidensmaskeringsopgave ved at udnytte videnssætninger udvundet fra nettet. Desuden viser omfattende eksperimenter på to tværsprogede MRC datasæt effektiviteten af vores foreslåede tilgang.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mehrsprachige vortrainierte Modelle könnten die Trainingsdaten aus einer reichhaltigen Quellsprache (wie Englisch) nutzen, um die Leistung in ressourcenarmen Sprachen zu verbessern. Allerdings ist die Übertragungsqualität für mehrsprachiges Machine Reading Comprehension (MRC) deutlich schlechter als für Satzklassifizierungsaufgaben, hauptsächlich aufgrund der Anforderung von MRC, die Antwortgrenze auf Wortebene zu erkennen. In diesem Beitrag schlagen wir zwei Hilfsaufgaben in der Feinabstimmung-Phase vor, um zusätzliche Phrasengrenzüberwachung zu schaffen: (1) Eine gemischte MRC-Aufgabe, die die Frage oder Passage in andere Sprachen übersetzt und translinguale Frage-Passage-Paare erstellt; (2) Eine sprachunabhängige Wissensmaskierungsaufgabe durch Nutzung von Wissensphrasen aus dem Web. Darüber hinaus zeigen umfangreiche Experimente an zwei translingualen MRC-Datensätzen die Wirksamkeit unseres vorgeschlagenen Ansatzes.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Πολυγλωσσικά προ-εκπαιδευμένα μοντέλα θα μπορούσαν να αξιοποιήσουν τα δεδομένα κατάρτισης από μια πλούσια γλώσσα προέλευσης (όπως τα αγγλικά) για να βελτιώσουν την απόδοση σε γλώσσες χαμηλής περιεκτικότητας. Ωστόσο, η ποιότητα μεταφοράς για την κατανόηση πολυγλωσσικής μηχανικής ανάγνωσης (MRC) είναι σημαντικά χειρότερη από τις εργασίες ταξινόμησης προτάσεων κυρίως λόγω της απαίτησης του MRC να ανιχνεύσει το όριο απαντήσεων επιπέδου λέξεων. Στην παρούσα εργασία, προτείνουμε δύο βοηθητικές εργασίες στο στάδιο του λεπτού συντονισμού για τη δημιουργία πρόσθετης εποπτείας συνόρων φράσεων: (1) Μικτή εργασία που μεταφράζει την ερώτηση ή το πέρασμα σε άλλες γλώσσες και δημιουργεί δίγλωσσα ζεύγη ερωτήσεων-περάσματος. (2) Μια εργασία απόκρυψης γνώσης αγνώστων γλωσσών με χρήση φράσεων γνώσης που εξορύσσονται από το διαδίκτυο. Εξάλλου, εκτεταμένα πειράματα σε δύο γλωσσικά σύνολα δεδομένων δείχνουν την αποτελεσματικότητα της προτεινόμενης προσέγγισής μας.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Los modelos multilingües preentrenados podrían aprovechar los datos de capacitación de un idioma fuente rico (como el inglés) para mejorar el rendimiento en idiomas de bajos recursos. Sin embargo, la calidad de transferencia para la comprensión de lectura automática (MRC) multilingüe es significativamente peor que la de las tareas de clasificación de oraciones, principalmente debido al requisito de MRC de detectar el límite de respuesta a nivel de palabra. En este artículo, proponemos dos tareas auxiliares en la etapa de ajuste fino para crear una supervisión adicional de los límites de la frase: (1) una tarea mixta de MRC, que traduce la pregunta o el pasaje a otros idiomas y crea pares de pasajes de preguntas en varios idiomas; (2) Una tarea de enmascaramiento del conocimiento agnóstico del idioma aprovechando frases de conocimiento extraídas de la web. Además, los extensos experimentos en dos conjuntos de datos de MRC interlingües muestran la eficacia de nuestro enfoque propuesto.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mitmekeelsed eelkoolitud mudelid võiksid kasutada koolitusandmeid rikkalikust lähtekeelest (nt inglise keel), et parandada tulemuslikkust vähese ressursiga keeltes. Kuid mitmekeelse masinlugemise mõistmise (MRC) ülekandmise kvaliteet on oluliselt halvem kui lausete klassifitseerimise ülesannete tõttu peamiselt MRC nõude tõttu tuvastada sõnatasemel vastuse piiri. Käesolevas dokumendis pakume välja kaks abiülesannet peenhäälestuse etapis, et luua täiendav fraasipiiride järelevalve: (1) MRC segaülesanne, mis tõlgib küsimuse või läbipääsu teistesse keeltesse ja ehitab keeleüleseid küsimuste ja läbipääsude paare; (2) Keelega sõltumatute teadmiste varjamise ülesanne, kasutades veebist kaevandatud teadmislauseid. Lisaks näitavad ulatuslikud katsed kahe keeleülese MRC andmekogumiga meie kavandatud lähenemisviisi tõhusust.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>مدلهای پیش آموزش های زیادی زبان می توانند داده های آموزش را از زبان منبع ثروتمند (مثل انگلیسی) برای تأثیر عملکرد روی زبانهای منابع کم تحت تاثیر قرار دهند. ولی کیفیت انتقال ماشین خواندن بسیاری زبان‌های زیادی (MRC) بسیار بدتر از کار‌های جدید کردن جمله‌ها به دلیل نیاز MRC برای شناسایی مرز پاسخ‌های سطح کلمه‌ها است. در این کاغذ، ما دو وظیفه کمک را در مرحله تنظیم کردن برای ایجاد کنترل محدوده‌ی عبارت اضافه پیشنهاد می‌کنیم: (۱) یک وظیفه MRC مختلف، که سوال یا عبور به زبان‌های دیگر را تغییر می‌دهد و جفت سوال‌های مختلف زبان می‌سازد. (2) یک دانش زبان-agnostic ماسک کردن وظیفه با استفاده از عبارت علمی که از وب منتقل شده است. علاوه بر این، آزمایش‌های گسترده در دو مجموعه داده‌های MRC متوسط زبان نشان می‌دهند که فعالیت روش پیشنهاد ما را نشان می‌دهد.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Monikieliset esikoulutetut mallit voisivat hyödyntää monipuolisen lähdekielen (kuten englannin) koulutustietoja parantaakseen suorituskykyä vähävaraisilla kielillä. Monikielisen konelukuymmärryksen (MRC) siirtolaatu on kuitenkin huomattavasti huonompi kuin lauseiden luokittelutehtävät pääasiassa siksi, että MRC vaatii havaitsemaan sanatason vastausrajan. Tässä artikkelissa ehdotamme kahta lisätehtävää hienosäätövaiheessa lauseiden rajavalvonnan luomiseksi: (1) MRC-tehtävä, joka kääntää kysymyksen tai kohdan muille kielille ja rakentaa monikielisiä kysymys-käytäväpareja; (2) Kieliagnostista tietämystä peittävä tehtävä hyödyntämällä tietolauseita verkosta. Lisäksi laajat kokeet kahdesta monikielisestä MRC-aineistosta osoittavat ehdotetun lähestymistavan tehokkuuden.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Les modèles pré-entraînés multilingues peuvent exploiter les données de formation provenant d'une langue source riche (telle que l'anglais) pour améliorer les performances dans les langues à faibles ressources. Cependant, la qualité de transfert pour la compréhension de lecture automatique (MRC) multilingue est nettement inférieure à celle des tâches de classification de phrases, principalement en raison de la nécessité pour MRC de détecter la limite de réponse au niveau du mot. Dans cet article, nous proposons deux tâches auxiliaires dans la phase de mise au point afin de créer une supervision supplémentaire des limites de phrases : (1) une tâche MRC mixte, qui traduit la question ou le passage dans d'autres langues et crée des paires question-passage interlinguistiques ; (2) Une tâche de masquage des connaissances agnostique de la langue en utilisant phrases de connaissances extraites du Web. En outre, des expériences approfondies sur deux ensembles de données MRC multilingues montrent l'efficacité de l'approche que nous proposons.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>D’fhéadfadh samhlacha ilteangacha réamhoilte na sonraí oiliúna a ghiaráil ó theanga foinse shaibhir (amhail Béarla) chun feidhmíocht ar theangacha lagacmhainne a fheabhsú. Mar sin féin, tá an caighdeán aistrithe do Thuiscint Léamh Meaisín ilteangach (MRC) i bhfad níos measa ná tascanna aicmithe abairt go príomha mar gheall ar riachtanas MRC teorainn freagra leibhéal na bhfocal a bhrath. Sa pháipéar seo, molaimid dhá thasc chúnta sa chéim mhionchoigeartaithe chun maoirseacht bhreise teorann frása a chruthú: (1) Tasc measctha MRC, a aistríonn an cheist nó an sliocht go teangacha eile agus a thógann péirí trasteangacha ceist-sleachta; (2) Tasc teanga-agnóiseach a chumhdaíonn eolas trí fhrásaí eolais a bhaintear as an ngréasán a ghiaráil. Ina theannta sin, léiríonn turgnaimh fhairsing ar dhá thacar sonraí tras-teangacha MRC éifeachtacht ár gcur chuige molta.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>@ info: whatsthis Kayya, sifar transfer wa Mashine na Akwai Composition (MRC) na ƙari mafi girma daga aikin mai fassarar maganar, mainli da ƙayyade MRC dõmin ya gane grensa na maganar ajiya. Daga wannan takardan, Munã ƙayyade aikin biyu masu inganci cikin jujjar-tunkuɗawa zuwa ka sami tsarin faɗi: (1) Mai haɗa aikin MRC, wanda ke fassarar da tambayar ko kuma za'a sami nau'in da ke cikin wasu harshe na daban kuma ana sami nau'in-nau'in-nau'i-nau'i; (2) A language-agnostic knowledge masking task by leveraging knowledge phrases mined from web. Babu, jarrabi masu shimfiɗa a kan data-na'ura biyu na tsoron MRC ke nuna aikin hanyarmu da aka buƙata.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>מודלים רבים מאומנים מראש יכולים להשתמש במידע האימוני משפה מקור עשירה (כמו אנגלית) כדי לשפר את ההופעה בשפות משאבים נמוכות. בכל אופן, איכות ההעברה למבנה של קריאת מכונות רבות שפות (MRC) גרועה יותר משימות שיעורי שיעור בעיקר בגלל הדרישה של MRC לגלות את גבול התשובה ברמה המילים. In this paper, we propose two auxiliary tasks in the fine-tuning stage to create additional phrase boundary supervision: (1) A mixed MRC task, which translates the question or passage to other languages and builds cross-lingual question-passage pairs; (2) משימה להסתיר ידע שפה-אגנוסטי על ידי השימוש ביטויים ידע מוכרים מהרשת. חוץ מזה, ניסויים רחבים על שני קבוצות מידע MRC בין שפות מראים את היעילות של הגישה המוצעת שלנו.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>बहुभाषी पूर्व-प्रशिक्षित मॉडल कम संसाधन भाषाओं पर प्रदर्शन में सुधार करने के लिए एक समृद्ध स्रोत भाषा (जैसे अंग्रेजी) से प्रशिक्षण डेटा का लाभ उठा सकते हैं। हालांकि, बहुभाषी मशीन रीडिंग कॉम्प्रिहेंशन (एमआरसी) के लिए स्थानांतरण गुणवत्ता मुख्य रूप से शब्द स्तर की उत्तर सीमा का पता लगाने के लिए एमआरसी की आवश्यकता के कारण वाक्य वर्गीकरण कार्यों की तुलना में काफी खराब है। इस पेपर में, हम अतिरिक्त वाक्यांश सीमा पर्यवेक्षण बनाने के लिए ठीक-ट्यूनिंग चरण में दो सहायक कार्यों का प्रस्ताव करते हैं: (1) एक मिश्रित एमआरसी कार्य, जो अन्य भाषाओं में प्रश्न या मार्ग का अनुवाद करता है और क्रॉस-भाषाई प्रश्न-मार्ग जोड़े बनाता है; (2) वेब से खनन किए गए ज्ञान वाक्यांशों का लाभ उठाकर एक भाषा-अज्ञेयवादी ज्ञान मास्किंग कार्य। इसके अलावा, दो क्रॉस-लिंगुअल एमआरसी डेटासेट पर व्यापक प्रयोग हमारे प्रस्तावित दृष्टिकोण की प्रभावशीलता दिखाते हैं।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mnogi jezički predobučeni modeli mogli bi utjecati na podatke obuke iz bogatog jezika izvora (kao što je engleski) kako bi poboljšali učinkovitost na jezicima niskih resursa. Međutim, kvalitet prijenosa za višejezičku kompresiju čitanja mašine (MRC) značajno je gore od zadataka klasifikacije kazne uglavnom zbog zahtjeva MRC-a za otkrivanje granice odgovora na razini riječi. U ovom papiru predlažemo dvije pomoćne zadatke u fazi ispravnog prilagodbe kako bi stvorili dodatni granični nadzor fraza: (2) zadatak maskiranja jezika-agnostičkih znanja uključivanjem znanstvenih fraza iz mreže. Osim toga, široki eksperimenti na dva prekogranična MRC podataka pokazuju učinkovitost našeg predloženog pristupa.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A többnyelvű, előre képzett modellek kihasználhatják a gazdag forrásnyelvek (például angol) képzési adatait, hogy javítsák a teljesítményt az alacsony forrásnyelvű nyelveken. A többnyelvű gépi olvasási értékelés (MRC) átviteli minősége azonban jelentősen rosszabb, mint a mondatok osztályozási feladatok, elsősorban azért, mert az MRC követelménye a szószintű válaszhatár kimutatására. Jelen tanulmányban két kiegészítő feladatot javasolunk a finomhangolási szakaszban további kifejezési határfelügyelet létrehozására: (1) vegyes MRC feladat, amely lefordítja a kérdést vagy átmenetet más nyelvekre, és többnyelvű kérdés-átmenet párokat épít; (2) Nyelv-agnosztikus tudás maszkolási feladat a webről bányászott tudás kifejezések felhasználásával. Emellett a javasolt megközelítés hatékonyságát két nyelvű MRC adatkészleten végzett kiterjedt kísérletek mutatják.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Բազլեզու նախապատրաստված մոդելները կարող են օգտագործել հարուստ աղբյուր լեզվի (ինչպիսիք են անգլերենը) ուսումնասիրության տվյալները, որպեսզի բարելավեն ցածր ռեսուրսների լեզուների արդյունքները: Այնուամենայնիվ, մեծալեզու մեքենաների ընթերցման ընկալումների (ՄՌԿ) փոխանցման որակը շատ ավելի վատ է, քան նախադասությունների դասակարգման խնդիրները, հիմնականում այն պատճառով, որ ՄՌԿ-ն է պահանջում բառի մակարդակի պատասխանի սահման Այս թղթի մեջ մենք առաջարկում ենք երկու օգնական առաջադրանք բարելավման փուլում, որպեսզի ստեղծենք ավելացված արտահայտությունների սահմանափակ վերահսկողություն: (1) ՄՌԿ-ի խառնված առաջադրանք, որը թարգմանում է հարցը կամ անցումը այլ լեզվով և կառուցում է երկլեզու-լեզու հարց (2) A language-agnostic knowledge masking task by leveraging knowledge phrases mined from web. Ավելին, երկու լեզվային ՄՌԿ տվյալների բազմազան փորձարկումները ցույց են տալիս մեր առաջարկված մոտեցումների արդյունավետությունը:</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Multilingual pre-trained models could leverage the training data from a rich source language (such as English) to improve performance on low resource languages. Namun, kualitas transfer untuk Pemahaman Pembacaan Mesin Multibahasa (MRC) jauh lebih buruk dari tugas klasifikasi kalimat terutama karena keperluan MRC untuk mendeteksi batas jawaban tingkat kata. Dalam kertas ini, kami mengusulkan dua tugas bantuan di tahap penyesuaian untuk menciptakan pengawasan batas frasa tambahan: (1) tugas MRC campuran, yang menerjemahkan pertanyaan atau kalimat ke bahasa lain dan membangun pasangan interbahasa pertanyaan-kalimat; (2) Tugas penutup pengetahuan bahasa-agnostik dengan menggunakan frasa pengetahuan yang dibuang dari web. Selain itu, eksperimen ekstensif pada dua set data MRC saling bahasa menunjukkan efektivitas pendekatan kami yang diusulkan.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Modelli plurilingue pre-formati potrebbero sfruttare i dati di formazione provenienti da una lingua di origine ricca (come l'inglese) per migliorare le prestazioni sulle lingue a basso contenuto di risorse. Tuttavia, la qualità di trasferimento per la comprensione della lettura automatica multilingue (MRC) è significativamente peggiore delle attività di classificazione delle frasi principalmente a causa del requisito di MRC per rilevare il limite di risposta a livello di parola. In questo articolo, proponiamo due compiti ausiliari nella fase di messa a punto per creare un'ulteriore supervisione dei confini delle frasi: (1) Un compito MRC misto, che traduce la domanda o il passaggio in altre lingue e costruisce coppie interlingue domanda-passaggio; (2) Un compito di mascheramento linguistico-agnostico della conoscenza sfruttando frasi di conoscenza estratte dal web. Inoltre, ampi esperimenti su due set di dati MRC cross-lingual dimostrano l'efficacia del nostro approccio proposto.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>多言語の事前トレーニング済みモデルは、豊富なソース言語（英語など）からのトレーニングデータを活用して、低資源言語のパフォーマンスを向上させることができます。しかし、多言語機械読解（ MRC ）の転送品質は、主に単語レベルの回答境界を検出するMRCの要件により、文章分類タスクよりも著しく悪い。この論文では、微調整段階で2つの補助的なタスクを提案して、追加のフレーズ境界監督を作成します。（ 1 ）質問または一節を他の言語に翻訳し、クロスリンガルの質問-一節ペアを構築する混合MRCタスク。（ 2 ）ウェブから得られた知識フレーズを活用して、言語に依存しない知識マスキングタスク。さらに、2つのクロスリンガルMRCデータセットの広範な実験は、提案されたアプローチの有効性を示しています。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Multi-lengkang model sing berangé awakdhéwé nggawe datang nggawe ngubah kang angkang dolanan bangsa (koyo ingkang) sing bisa bantuan nggawe barang langkung bantuan. politenessoffpolite"), and when there is a change ("assertivepoliteness Nang pepulan iki, kita mulai perbudhakan langkung pawar sampeyan kanggo nggawe luwih-luwih dumateng kanggo kewong limian sisan nguasar: 1) Omahmu MPN sing ngesane perusahaan karo pasar kanggo langkung waja sakjane lan nggawe pawar-pasar iki bangsane (2) Ealah-ageostik kesempatan kanggo masalah nggawe ngupakan kelas kuwi tindakan kesempatan minerani nang web. Nanging, dino sing paling-sistem sing paling-sistem kanggo sabanjuré iki bangsane MRC dadi iki bakal sing ngendalikno ning jejaraké awak dhéwé</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>მრავალენგური წინ განაკეთებული მოდელები შეიძლება განაკეთებული მონაცემების მონაცემების გამოყენება ბედნიერი მსოფლიო ენაზე (როგორც ინგლისური) გამოსახულებ მაგრამ, მრავალენგური მაქსინის კომპრენსცია (MRC) უფრო ცოტა უფრო ცოტა უფრო ცოტა, ვიდრე სიტყვების კლასიფიკაციის მოქმედება, უფრო მრავალურად MRC სიტყვების განსაზღვრება ამ დომენტში ჩვენ მხოლოდ ორი დახმარებელი საქმედება სხვა ენაზების შექმნა დამატებელი ფრაზების დამატებით: Name დამატებით, ჩვენი წარმოიდგინეთ პროგრამის ექსპერიმენტები ექსპერიმენტები ორი მრავალური MRC მონაცემების ეფექტიურობა.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Көп тілді алдын- ала оқылған үлгілер ресурс тілдерінің төмен тілдерінде жұмыс істеу үшін баяны көз тілден (ағылшын тілде) оқылған деректерді өзгертуге болады. Бірақ бірнеше тілдік машинаның оқу сәйкестігі (MRC) тапсырмаларды сәйкестіктердің шегін анықтау үшін МRC деңгейінің талап етілген тапсырмалардан артық көп жақсы. Бұл қағазда біз қосымша сөз шектерін қарау үшін қосымша екі көмектесу тапсырмаларын ұсынамыз: (1) Сұрақ немесе басқа тілдерге аудару және бірнеше тілдерге көмектесетін мRC тапсырмасы құрылады. (2) Тілді агностикалық білім тапсырмасын қалқайтын мәлімет сөздерін веб- тағы бойынша көмектеп береді. Қосымша, екі тілді MRC деректер қорларындағы кеңейтілген тәжірибелер қолданылған тәжірибеміздің эффективнігін көрсетеді.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>다중 언어 예비 훈련 모델은 풍부원 언어(예를 들어 영어)에서 온 훈련 데이터를 이용하여 저자원 언어의 성능을 향상시킬 수 있다.그러나 다국어기계독해(MRC)의 이동 품질은 문장 분류 임무보다 현저히 낮다. 이는 주로 MRC가 단어급 답안 경계를 측정해야 하기 때문이다.본고에서 우리는 마이크로 조정 단계에서 두 가지 보조 임무를 제시하여 추가적인 단어 경계 감독을 만들었다. (1) MRC 임무를 혼합하여 문제나 단락을 다른 언어로 번역하고 크로스 언어 문제인 단락 쌍을 구축한다.(2) 인터넷에서 발굴한 지식단어를 이용하여 언어와 무관한 지식 엄폐 임무를 완성한다.또한 두 언어로 구성된 MRC 데이터 세트에서 진행된 수많은 실험은 이 방법의 유효성을 나타냈다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Daugiakalbiai iš anksto parengti modeliai galėtų sutelkti mokymo duomenis iš turtingos šaltinio kalbos (pvz., anglų kalbos) siekiant pagerinti mažų išteklių kalbų veiksmingumą. Tačiau daugiakalbio mašinų skaitymo supratimo (MRC) perdavimo kokybė gerokai blogesnė nei sakinių klasifikavimo užduotys, daugiausia dėl to, kad MRC turi nustatyti žodžio lygio atsakymo ribą. Šiame dokumente siūlome dvi papildomas užduotis patobulinimo etape, siekiant sukurti papildomą frazės ribos priežiūrą: 1) mišrią MRC užduotį, kuri verta klausimą ar perėjimą į kitas kalbas ir kuria tarpkalbines klausimų perėjimų poras; (2) A language-agnostic knowledge masking task by leveraging knowledge phrases mined from web. Be to, išsamūs eksperimentai su dviem tarpkalbiniais MRK duomenų rinkiniais rodo mūsų siūlomo metodo veiksmingumą.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Multilingual pre-trained models could leverage the training data from a rich source language (such as English) to improve performance on low resource languages. Сепак, квалитетот на трансфер за мултијазичното разбирање за читање машина (МРЦ) е значително полош од задачите за класификација на речениците главно поради барањето на МРЦ за детектирање на границата на одговорот на нивото на зборот. Во овој документ, предложуваме две помошни задачи во фазата на финетизирање за создавање дополнителен надзор на границите на фразите: (1) мешана задача на МРЦ, која го преведува прашањето или преминот на други јазици и гради двојки прекујазични прашања-преминови; (2) Работа на маскирање на јазик-агностичко знаење со користење на фразите на знаење кои се минираат од веб-страницата. Покрај тоа, експериментите на две меѓујазични МРЦ податоци покажуваат ефикасност на нашиот предложен пристап.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>കുറഞ്ഞ വിഭവങ്ങളുടെ ഭാഷകളില്‍ നിന്നും മുമ്പ് പരിശീലിക്കപ്പെട്ട മോഡലുകള്‍ പരിശീലിപ്പിക്കുന്നതിനുള്ള വിവരങ്ങള്‍ മുന്‍ക എന്നാലും പല ഭാഷ മെഷീന്‍ വായിക്കുന്നതിനുള്ള മാറ്റങ്ങള്‍ക്കുള്ള സ്വാധീനം വായിച്ചുകേള്‍പ്പിക്കുന്നതിനുള്ള വാക്കിന്റെ ക്ലാസ്ഫിക്ഷന്‍ ജോലി ഈ പത്രത്തില്‍ കൂടുതല്‍ വാക്കിന്റെ അതിര്‍ത്തി നിരീക്ഷിക്കുന്നതിനായി നമ്മള്‍ രണ്ടു കൂടുതല്‍ രണ്ടു പ്രവര്‍ത്തനങ്ങള്‍ പ്രാര്‍ത്ഥിക്കുന്നു: (1) ചോദ്യം ചോദിക്കുന്നതോ മറ (2) A language-agnostic knowledge masking task by leveraging knowledge phrases mined from web. കൂടാതെ, രണ്ട് ക്രിസ്ലിങ്ങ് ഭാഷയുടെ വിശാലമായ പരീക്ഷണങ്ങള്‍ നമ്മുടെ പ്രൊദ്ദേശിക്കപ്പെട്ട സാധ്യതയുടെ പ്ര</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ихэнх хэлний өмнө сургалтын загварууд бага эдийн засгийн хэл дээр ажиллагааг сайжруулахын тулд баян эх үүсвэрийн хэл дээр сургалтын өгөгдлийг ашиглаж чадна. Гэхдээ олон хэлний Машин унших Сургуулийн (MRC) шилжүүлэлтийн квалификаас илүү муу гэдэг үгийн хэмжээний хариулт хязгаарыг олж мэдэх шаардлагатай MRC-ын шаардлагатай ажиллагаас илүү муу. Энэ цаасан дээр бид нэмэлт хэлний хязгаар хязгаар удирдах хоёр тусламжтай ажиллагааг санал болгож байна: (1) МРК-ын төвөгтэй ажиллагаа, асуултыг бусад хэлнүүд рүү орлуулж, олон хэлний асуулт дагуулах хоёрыг бүтээж байна. (2) Холбоо-агностик мэдлэг, мэдлэг хэлбэрүүдийг веб-ээс гаргаж ирсэн мэдлэг хэлбэрүүдийг хадгалах ажил. Үүнээс гадна хоёр хэлний MRC өгөгдлийн сангийн олон шинэ туршилтууд бидний санал өгсөн арга хэмжээний үр дүнг харуулдаг.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Model berlatih-dilatih berbilang bahasa boleh menggunakan data latihan dari bahasa sumber kaya (seperti bahasa Inggeris) untuk meningkatkan prestasi pada bahasa sumber rendah. Namun, kualiti pemindahan untuk Pemahaman Pembacaan Mesin berbilang bahasa (MRC) adalah lebih teruk daripada tugas klasifikasi kalimat terutamanya disebabkan keperluan MRC untuk mengesan sempadan jawapan aras perkataan. Dalam kertas ini, kami cadangkan dua tugas bantuan dalam tahap penyesuaian untuk mencipta pengawasan sempadan frasa tambahan: (1) tugas MRC bercampur, yang menerjemahkan soalan atau laluan ke bahasa lain dan membina pasangan soalan-laluan saling bahasa; (2) Tugas penutup pengetahuan bahasa-agnostik dengan menggunakan frasa pengetahuan yang dibuang dari web. Selain itu, eksperimen luas pada dua set data MRC saling bahasa menunjukkan keefektivitas pendekatan yang kami cadangkan.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mudelli multilingwi mħarrġa minn qabel jistgħu jtejbu d-dejta tat-taħriġ minn lingwa rikka tas-sors (bħall-Ingliż) biex itejbu l-prestazzjoni fuq lingwi b’riżorsi baxxi. Madankollu, il-kwalità tat-trasferiment għall-Komprensjoni Multilingwi tal-Qari tal-Magni (MRC) hija ferm agħar mill-kompiti tal-klassifikazzjoni tas-sentenzi prinċipalment minħabba r-rekwiżit tal-MRC biex tinstab il-limitu tat-tweġiba fil-livell tal-kelma. F’dan id-dokument, qed nipproponu żewġ kompiti awżiljarji fl-istadju ta’ rfinar biex tinħoloq superviżjoni addizzjonali tal-fruntieri tal-frażi: (1) kompitu mħallat tal-MRC, li jittraduċi l-mistoqsija jew il-passaġġ għal lingwi oħra u jibni pari ta’ passaġġ ta’ mistoqsijiet bejn lingwi u lingwi; (2) Kompitu ta' masking tal-għarfien lingwistiku-agnostiku permezz tal-ingranaġġ ta' frażijiet ta' għarfien maħruġa mill-internet. Barra minn hekk, esperimenti estensivi fuq żewġ settijiet ta’ dejta tal-MRC translingwi juru l-effettività tal-approċċ propost tagħna.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Meertalige voorgetrainde modellen kunnen gebruik maken van de trainingsgegevens uit een rijke brontaal (zoals Engels) om de prestaties in talen met weinig resources te verbeteren. De overdrachtskwaliteit voor meertalige Machine Reading Comprehension (MRC) is echter aanzienlijk slechter dan zinnenclassificatietaken, voornamelijk vanwege de eis van MRC om de antwoordgrens op woordniveau te detecteren. In dit artikel stellen we twee ondersteunende taken voor in de fine-tuning fase om extra toezicht op de grens van zinnen te creëren: (1) Een gemengde MRC taak, die de vraag of passage vertaalt naar andere talen en cross-lingual vraag-passage paren bouwt; (2) Een taalagnostische kennismaskertaak door gebruik te maken van kenniszinnen die uit het web zijn gehaald. Daarnaast tonen uitgebreide experimenten op twee meertalige MRC datasets de effectiviteit van onze voorgestelde aanpak aan.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Fleirspråksprøvde modeller kunne levera opplæringsdata frå ein rikt kjeldespråk (som engelsk) for å forbetra utviklinga på låg ressursspråk. Overføringskvaliteten for fleirspråkkmaskinelesingskomprehension (MRC) er imidlertid dørre enn setningsklassifikasjonskvaliteten hovudsakelig på grunn av nødvendigen av MRC for å finna ordnivåsvargrensen. I denne papiret foreslår vi to hjelpeoppgåver i det finnstillingsstaden for å laga fleire frågrenseoversikt: (1) Eit blandet MRC-oppgåve, som omsetjer spørsmålet eller passasjon til andre språk og bygger fleire spørsmål-passasjonar. (2) Eit språk-agnostisk kunnskap som maskerer oppgåve ved å levera kunnskapsfrasar som er minert frå nettet. I tillegg viser ekstra eksperimenter på to krysspråk MRC-dataset effektiviteten av vår foreslått tilnærming.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Wielojęzyczne, wstępnie przeszkolone modele mogłyby wykorzystać dane szkoleniowe z bogatego języka źródłowego (takiego jak angielski), aby poprawić wydajność w językach o niskich zasobach. Jednak jakość transferu dla wielojęzycznego zrozumienia odczytu maszynowego (MRC) jest znacznie gorsza niż zadania klasyfikacji zdań, głównie ze względu na wymóg MRC wykrywania granicy odpowiedzi na poziomie słowa. W niniejszym artykule proponujemy dwa dodatkowe zadania pomocnicze na etapie dostrajania w celu stworzenia dodatkowego nadzoru nad granicami fraz: (1) Mieszane zadanie MRC, które tłumaczy pytanie lub fragment na inne języki i buduje pary pytania-fragment między językami; (2) Zadanie maskowania wiedzy agnostycznej dla języka poprzez wykorzystanie zwrotów wiedzy wydobywanych z sieci. Ponadto obszerne eksperymenty na dwóch wielojęzycznych zbiorach danych MRC pokazują skuteczność proponowanego podejścia.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Modelos pré-treinados multilíngues podem aproveitar os dados de treinamento de um idioma de origem rico (como o inglês) para melhorar o desempenho em idiomas com poucos recursos. No entanto, a qualidade de transferência para a Compreensão de Leitura de Máquina (MRC) multilíngue é significativamente pior do que as tarefas de classificação de frases, principalmente devido à exigência do MRC para detectar o limite de resposta no nível da palavra. Neste artigo, propomos duas tarefas auxiliares no estágio de ajuste fino para criar supervisão de limite de frase adicional: (1) Uma tarefa MRC mista, que traduz a pergunta ou passagem para outros idiomas e constrói pares de pergunta-passagem multilíngues; (2) Uma tarefa de mascaramento de conhecimento independente de linguagem, aproveitando frases de conhecimento extraídas da web. Além disso, extensos experimentos em dois conjuntos de dados MRC multilíngues mostram a eficácia de nossa abordagem proposta.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Modelele multilingve pre-instruite ar putea utiliza datele de formare dintr-o limbă sursă bogată (cum ar fi engleza) pentru a îmbunătăți performanța limbilor cu resurse reduse. Cu toate acestea, calitatea transferului pentru înțelegerea mașinii de citire multilingvă (MRC) este semnificativ mai rea decât sarcinile de clasificare a frazelor, în principal datorită cerinței MRC de a detecta limita răspunsului la nivel de cuvânt. În această lucrare, propunem două sarcini auxiliare în etapa de reglare fină pentru a crea supravegherea suplimentară a limitelor frazelor: (1) O sarcină MRC mixtă, care traduce întrebarea sau pasajul în alte limbi și construiește perechi interlingve întrebare-pasaj; (2) O sarcină lingvistică de mascare a cunoștințelor prin utilizarea frazelor de cunoaștere extrase de pe web. În plus, experimente extinse pe două seturi de date translingve MRC arată eficacitatea abordării propuse.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Многоязычные предварительно подготовленные модели могли бы использовать учебные данные из богатого исходного языка (например, английского) для повышения эффективности работы на языках с низким объемом ресурсов. Тем не менее, качество передачи для многоязычного понимания машинного чтения (MRC) значительно хуже, чем задачи классификации предложений, в основном из-за требования MRC обнаружить границу ответа на уровне слова. В этой статье мы предлагаем две вспомогательные задачи на этапе тонкой настройки для создания дополнительного надзора за границами фраз: (1) смешанная задача MRC, которая переводит вопрос или отрывок на другие языки и строит межъязыковые пары вопросов и проходов; (2) задача маскировки знаний по языку, используя фразы знаний, полученные из сети. Кроме того, обширные эксперименты на двух межъязыковых наборах данных MRC показывают эффективность предлагаемого нами подхода.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ගොඩක් භාෂාවක් ප්‍රධානය කරලා තියෙන්න පුළුවන් ප්‍රධානයක් තියෙන්නේ ප්‍රධානයක් ප්‍රධානය භාෂාවක් ව නමුත්, බොහොම භාෂාවක් පද්ධති කියවන්න යන්ත්‍රය සම්පූර්ණය (MRC) වාක්ෂාවක් පද්ධති වාක්ෂාවක් වඩා ගොඩක් නරකයි වචන වාක්ෂාවක් මේ පැත්තට, අපි ප්‍රශ්නයක් නැති භාෂාවට ප්‍රශ්නයක් නිර්මාණය කරන්න සඳහා ප්‍රශ්නයක් නිර්මාණය කරන්න ප්‍රශ්නයක් දෙකක් ප්‍රශ්නයක් තියෙනවා: (1) අතර භාෂ (2) භාෂාව- අග්නොසික් දන්නවක්, වෙබ් වලින් බිඳින්න තියෙන දැනගන්න ප්‍රශ්නයක් වැඩ කරන්න. ඒ වගේම, විශාල පරීක්ෂණ දෙකක් විශාල භාෂාවක් MRC දත්ත සේට් එක්ක පෙන්වන්නේ අපේ ප්‍රතිචාරිත විද</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Večjezični predhodno usposobljeni modeli bi lahko izkoristili podatke o usposabljanju iz bogatega izvornega jezika (kot je angleščina), da bi izboljšali učinkovitost jezikov z nizkimi viri. Vendar pa je kakovost prenosa za večjezično razumevanje strojnega branja (MRC) bistveno slabša od opravil klasifikacije stavkov, predvsem zaradi zahteve MRC, da zazna mejo odgovora na ravni besed. V prispevku predlagamo dve pomožni nalogi v fazi finega uravnavanja za ustvarjanje dodatnega nadzora meje fraz: (1) mešana naloga MRC, ki prevaja vprašanje ali prehod v druge jezike in gradi medjezične pare vprašanja-prehodov; (2) Zakrivanje jezikovnega agnostičnega znanja z izkoriščanjem znanja, pridobljenih iz spleta. Poleg tega obsežni poskusi na dveh medjezičnih naborih podatkov MRC kažejo učinkovitost našega predlaganega pristopa.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tusaale luuqado badan oo af hore lagu tababariyey waxay ka soo bandhigi kartaa macluumaadka waxbarashada luqada taajirka ah (sida ingiriisi) si uu u hagaajiyo bandhigyada afka hoose ee luqadaha rasmiga ah. Si kastaba ha ahaatee, qiimaha beddelinta ee Masiinka wax akhriska ee luuqadaha kala duduwan (MRC) waa ka sii xunxun tahay shaqada fasaxda ee kaliya sababtoo ah baahida u baahan tahay MRC in uu ogaado xadida jawaabta heerka. Qoraalkan waxaan ku soo jeedaynaa laba shaqooyin oo la mid ah goobta saxda ah si aan u sameyno ilaalinta dheeraad ee xuduudaha: (1) Shaqada MRC oo isku qasan, taasoo ku turjumaya su'aalaha ama baasabka luuqadaha kale, waxaana dhisa laba labo oo ka mid ah su'aalo kala duwan; (2) Aqoonta aqoonta luqada ah oo ku qoran shaqo ku qoran, si uu u dhiibo hadallada aqoonta ee laga mineeyey internetka. Imtixaan dheeraad ah oo ku qoran labada macluumaad oo luqada ah oo MRC ah ayaa tusaya effektada qaababka lagu talo galay.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Modelet shumëgjuhësore të stërvitura paraprake mund të përdorin të dhënat e stërvitjes nga një gjuhë burimi i pasur (si anglisht) për të përmirësuar performancën në gjuhët e ulëta të burimeve. Megjithatë, cilësia e transferit për kompresionin e leximit të makinave shumëgjuhëse (MRC) është ndjeshëm më e keqe se detyrat e klasifikimit të fjalëve kryesisht për shkak të kërkesës së MRC për të zbuluar kufirin e përgjigjes së nivelit të fjalës. In this paper, we propose two auxiliary tasks in the fine-tuning stage to create additional phrase boundary supervision: (1) A mixed MRC task, which translates the question or passage to other languages and builds cross-lingual question-passage pairs; (2) Një detyrë maskimi i njohurive gjuhë-agnostike duke përdorur frazat e njohurive të minave nga rrjeti. Përveç kësaj, eksperimentet e gjerë në dy grupe të dhënash MRC ndërgjuhësore tregojnë efektshmërinë e qasjes sonë të propozuar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mnogi jezički predobučeni modeli mogu uticati na podatke obuke iz bogatog jezika izvora (kao što je engleski) kako bi poboljšali učinkovitost na jezicima niskih resursa. Međutim, kvalitet prijenosa za višejezičku kompresiju čitanja mašine (MRC) je značajno gore od zadataka klasifikacije rečenica uglavnom zbog zahteva MRC-a za otkrivanje granice odgovora na nivou rečenja. U ovom papiru predlažemo dve pomoćne zadatke u fazi finalnog prilagodbe da bi stvorili dodatni granični nadzor fraza: (1) pomiješan zadatak MRC-a, koji prevodi pitanje ili prolaz na drugi jezici i izgradi parove preko jezika pitanja; (2) jezik-agnostičko znanje maskirajući zadatak korištenjem znanja izraženih iz mreže. Osim toga, široki eksperimenti na dva krstojezička MRC podataka pokazuju učinkovitost našeg predloženog pristupa.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Flerspråkiga förberedda modeller skulle kunna utnyttja utbildningsdata från ett rikt källspråk (t.ex. engelska) för att förbättra prestandan på språk med låga resurser. Överföringskvaliteten för flerspråkig maskinläsförståelse (MRC) är dock betydligt sämre än meningsklassificeringsuppgifter främst på grund av kravet på MRC att upptäcka svarsgränsen på ordnivå. I denna uppsats föreslår vi två hjälpuppgifter i finjusteringsstadiet för att skapa ytterligare frasgränsövervakning: (1) En blandad MRC-uppgift, som översätter frågan eller passagen till andra språk och bygger korspråkiga fråge-passagepar; (2) En språkagnostisk kunskapsmaskeringsuppgift genom att utnyttja kunskapsfraser som utvinns från webben. Dessutom visar omfattande experiment på två korspråkiga MRC-datauppsättningar effektiviteten av vårt föreslagna tillvägagångssätt.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mifano mingi ya lugha zilizofunzwa inaweza kutumia taarifa za mafunzo kutoka lugha tajiri (kama vile Kiingereza) ili kuboresha utendaji wa lugha ndogo ya rasilimali. Hata hivyo, kiwango cha uhamishaji kwa mashine ya lugha mbalimbali cha kusoma Ufunguo (MRC) ni mbaya zaidi ya kazi za kutangazwa kwa sentensi hasa kwa sababu ya hitaji la MRC kutambua mpaka wa kiwango cha jibu cha neno. Katika gazeti hili, tunapendekeza kazi mbili za ushirikiano katika jukwaa hili lililotengeneza vizuri ili kutengeneza ufuatiliaji wa ziada wa maneno kwenye mipaka: (1) kazi ya mchanganyiko wa MRC, ambayo inatafsiri swali au upatikanaji wa lugha nyingine na kujenga viwili vya kutangazwa kwa lugha mbalimbali; (2) Tamko la maarifa ya lugha yenye lugha ya kifahamu kwa kutumia maneno ya maarifa yaliyominywa kutoka mtandaoni. Zaidi ya hayo, majaribio mengi kwenye seti mbili za lugha za MRC zinaonyesha ufanisi wa hatua yetu inayopendekezwa.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>முன் பயிற்சிக்கப்பட்ட மாதிரிகள் சிறிய மூலத்தின் மொழியில் இருந்து பயிற்சியின் தகவல்களை மேம்படுத்த முடியும். ஆனால், பல மொழி இயந்திரத்திற்கான மாற்று தரம் (MRC) வாக்கு வகைப்படுத்தல் பணிகளை விட மிகவும் மோசமானது. முக்கியமாக MRC வார்த்தை மட்டும் விட விட்டு வரையறை கண்டற இந்த காகிதத்தில், நாம் நன்றாக துண்டிக்கும் நிலையில் இரண்டு கூட்டுதல் பணிகளை உருவாக்குவதற்கு மேலும் கூடுதல் சொற்றொடர் எல்லை கண்காணிப்பதற்கு பரிந்துரைக்கிறோம்: ( (2) வலைப்பிலிருந்து குறைந்த அறிவிப்பு சொற்றொடர்களை அனுப்பி மொழி அறிவு மூடும் பணி மேலும், இரண்டு மொழி மொழியில் MRC தரவுத்தளங்களின் விரிவான சோதனைகள் தெரியும் நம் பரிந்துரைய செயல்பாட்டின்</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Birnäçe dilli öň-bilim modalary baý çeşme dilinden (iňlisçe ýaly) taýýarlanmak üçin baýramçylyk dilinden üýtgedip bilerdi. Ýöne, köp dilli maşynyň Okamak Derjesi (MRC) sözleriň klasifikasy täbliklerinden has baglanyşygy, iň bellenen MRC sözleriň derejesi çykarmak üçin sözleriň derejesi diýmek üçin ýok bolar. Bu kagyzda, biz esasy çyzgylyň üstünde iki kömek işi teklip edip, esasy çyzgylyň üstünde bir MRC işi çarpýar we bu soragy başga dillere terjime edip, çatlaşyk diller üçin bir soragy çykarýar; (2) Web tarapyndan alan bilim sözlerini çykaryp bilen agnostik bilim maskalaýan zady. Munuň ýagdaýda, iki çarpaz dilli MRC veri setirlerinde möhüm deneyler biziň teklipimiziň etkinliýetimizi görkezýär.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Multilingual pre-trained models can leverage the training data from a rich source language (such as English) to improve performance on low resource languages. However, the transfer quality for multilingual Machine Reading Comprehension (MRC) is significantly worse than sentence classification tasks mainly due to the requirement of MRC to detect the word level answer boundary. اس کاغذ میں ہم دو اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپنا اپن (2) ایک زبان-agnostic علم جو کام کو ماسک کر رہا ہے اس کے ذریعہ سے جہالت کے مطابق ویب سے مٹی ہوئی مطابق۔ اس کے علاوہ دو مختلف زبان MRC ڈیٹسٹ پر بڑے آزمائش دکھاتے ہیں ہماری پیشنهاد کی طریقہ کا اثرات.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bir nechta tillar o'rganilgan modellar yordamida taʼminlovlovchi maʼlumot yordam beradi, maksimal manbaning qisqa manbaning tillarida bajarish mumkin. Lekin bir necha tilda o'qish kompyuterni o'qish (MRC) vazifalarining o'zgartirish qiymati juda qiymati mumkin, asosida so'zlar darajasini aniqlash uchun maxsus darajaga mos keladi. Bu hujjatda, biz bir xil vazifalarni qoʻshimcha imkoniyat chegarasini yaratish uchun boshqa tillarni tarjima qilamiz va boshqa tillarning savol yoki maxfiy soʻzni yaratadi. (2) Veb- dan minglangan ilmiy soʻzlarni yozib olish orqali til-agnostik ilmoga vazifani boshqarish. Ko'pchilik, ikkita tillar uchun MRC maʼlumotlar tarkibida kengaytirish imtiyozlarimizni ko'rsatadi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Các mô hình đa ngôn ngữ được đào tạo có thể dựa trên các dữ liệu đào tạo từ một ngôn ngữ nguồn giàu có (như tiếng Anh) để cải thiện khả năng ngôn ngữ ít tài nguyên. Tuy nhiên, chất lượng chuyển đổi chất lượng đa dạng của máy đọc đa dạng (MRC) còn tệ hơn nhiều việc phân loại phần lớn là do MRX buộc phải phát hiện biên giới đáp cấp từ. Trong tờ giấy này, chúng tôi đề xuất hai nhiệm vụ trợ giúp trong giai đoạn tinh chỉnh cuối để tạo thêm giám sát giới hạn cụm từ: 1) một nhiệm vụ MRX tổng hợp, chuyển câu hỏi hoặc đoạn sang các ngôn ngữ khác và xây dựng các cặp câu hỏi chéo ngôn ngữ; (2) Một nhiệm vụ che giấu kiến thức ngôn ngữ-chẩn bằng cách dùng những từ ngữ từ web. Hơn nữa, các thí nghiệm rộng rãi trên hai bộ dữ liệu MRC chéo cho thấy hiệu quả của phương pháp được đề nghị.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>多言预训模形以自富(如英语)之教数以重低资源言之性。 然多言机器读解(MRC)者传输质明下句类,盖MRC须检测单词级答案界也。 于本文中,微调两佐,以创额外短语界监督:(1)混MRC,以段落翻译成他语立跨语 - 段落对。 (2)因Web发掘短语以掩蔽言事。 又两跨语言MRC数集上之广实验明吾法之有效性。</span></div></div><dl><dt>Anthology ID:</dt><dd>2020.acl-main.87</dd><dt>Volume:</dt><dd><a href=/volumes/2020.acl-main/>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</a></dd><dt>Month:</dt><dd>July</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Online</dd><dt>Venue:</dt><dd><a href=/venues/acl/>ACL</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>925–934</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.acl-main.87>https://aclanthology.org/2020.acl-main.87</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/2020.acl-main.87 title="To the current version of the paper by DOI">10.18653/v1/2020.acl-main.87</a></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">yuan-etal-2020-enhancing</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Fei Yuan, Linjun Shou, Xuanyu Bai, Ming Gong, Yaobo Liang, Nan Duan, Yan Fu, and Daxin Jiang. 2020. <a href=https://aclanthology.org/2020.acl-main.87>Enhancing Answer Boundary Detection for Multilingual Machine Reading Comprehension</a>. In <i>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</i>, pages 925–934, Online. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2020.acl-main.87>Enhancing Answer Boundary Detection for Multilingual Machine Reading Comprehension</a> (Yuan et al., ACL 2020)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2020.acl-main.87.pdf>https://aclanthology.org/2020.acl-main.87.pdf</a></dd><dt class=acl-button-row>Video:</dt><dd class=acl-button-row><a href=http://slideslive.com/38929253 class="btn btn-attachment btn-sm"><i class="fas fa-video"></i>&nbsp;http://slideslive.com/38929253</a></dd><dt>Data</dt><dd><a href=https://paperswithcode.com/dataset/mlqa>MLQA</a>,&nbsp;<a href=https://paperswithcode.com/dataset/squad>SQuAD</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2020.acl-main.87.pdf title="Open PDF of 'Enhancing Answer Boundary Detection for Multilingual Machine Reading Comprehension'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Enhancing+Answer+Boundary+Detection+for+Multilingual+Machine+Reading+Comprehension" title="Search for 'Enhancing Answer Boundary Detection for Multilingual Machine Reading Comprehension' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'Enhancing Answer Boundary Detection for Multilingual Machine Reading Comprehension'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a>
<a class="btn btn-attachment d-flex flex-wrap justify-content-center" href=http://slideslive.com/38929253 title="Open video for 'Enhancing Answer Boundary Detection for Multilingual Machine Reading Comprehension'"><span class="align-self-center px-1"><i class="fas fa-video"></i></span>
<span class=px-1>Video</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[Enhancing Answer Boundary Detection for Multilingual Machine Reading Comprehension](https://aclanthology.org/2020.acl-main.87) (Yuan et al., ACL 2020)</p><ul class=mt-2><li><a href=https://aclanthology.org/2020.acl-main.87>Enhancing Answer Boundary Detection for Multilingual Machine Reading Comprehension</a> (Yuan et al., ACL 2020)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Fei Yuan, Linjun Shou, Xuanyu Bai, Ming Gong, Yaobo Liang, Nan Duan, Yan Fu, and Daxin Jiang. 2020. <a href=https://aclanthology.org/2020.acl-main.87>Enhancing Answer Boundary Detection for Multilingual Machine Reading Comprehension</a>. In <i>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</i>, pages 925–934, Online. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>