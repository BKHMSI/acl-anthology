<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Explanation Regeneration via Multi-Hop ILP Inference over Knowledge BaseILP Inference over Knowledge Base - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="Explanation Regeneration via Multi-Hop ILP Inference over Knowledge BaseILP Inference over Knowledge Base" name=citation_title><meta content="Aayushee Gupta" name=citation_author><meta content="Gopalakrishnan Srinivasaraghavan" name=citation_author><meta content="Proceedings of the Graph-based Methods for Natural Language Processing (TextGraphs)" name=citation_conference_title><meta content="2020/12" name=citation_publication_date><meta content="https://aclanthology.org/2020.textgraphs-1.13.pdf" name=citation_pdf_url><meta content="109" name=citation_firstpage><meta content="114" name=citation_lastpage><meta content="10.18653/v1/2020.textgraphs-1.13" name=citation_doi><meta property="og:title" content="Explanation Regeneration via Multi-Hop ILP Inference over Knowledge BaseILP Inference over Knowledge Base"><meta property="og:image" content="https://aclanthology.org/thumb/2020.textgraphs-1.13.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2020.textgraphs-1.13"><meta property="og:description" content="Aayushee Gupta, Gopalakrishnan Srinivasaraghavan. Proceedings of the Graph-based Methods for Natural Language Processing (TextGraphs). 2020."><link rel=canonical href=https://aclanthology.org/2020.textgraphs-1.13></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Explanation Regeneration via Multi-Hop ILP Inference over Knowledge Base<span class=acl-fixed-case>ILP</span> Inference over Knowledge Base</a>
<a id=af_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Verduideling Regenerasie deur Multi-Hop ILP Inferensie oor kennis Basis</a>
<a id=am_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>ዶሴ `%s'ን ማስፈጠር አልተቻለም፦ %s</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>تجديد التفسير عبر استدلال متعدد المراحل لـ ILP عبر قاعدة المعرفة</a>
<a id=az_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Multi-Hop ILP Inference over Knowledge Base</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Обяснение Регенерация чрез мулти-хоп заключение на ILP над базата знания</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>জ্ঞানের ভিত্তিতে বহুহোপ আইএলপি ইনফারেন্সের মাধ্যমে এক্সপ্লেনেশন রিজেনেশন</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Multi-Hop ILP Inference over Knowledge Base</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Rejeneracija objašnjenja putem multiHop ILP Inferencije nad bazom znanja</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>La regeneració de l'explicació a través de la multiHop ILP Inferència sobre la Base de Conèixements</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Vysvětlení Regenerace pomocí Multi-Hop ILP Inference přes znalostní bázi</a>
<a id=da_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Forklaring Regeneration via Multi-Hop ILP Inference over Knowledge Base</a>
<a id=de_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Erklärung Regeneration mittels Multi-Hop ILP Inference über Knowledge Base</a>
<a id=el_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Εξήγηση Αναγέννηση μέσω Συμπερασμάτων πολλαπλών Hop μέσω της Γνώσης Βάση</a>
<a id=es_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Explicación Regeneración mediante Inferencia de ILP de múltiples saltos sobre la base de conocimientos</a>
<a id=et_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Selgitus Regeneratsioon Multi-Hop ILP järelduse kaudu teabebaasi üle</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>توضيح بازسازي از طريق بيشتر هوپ ILP تأثير بر پايگاه دانش</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Selitys Regeneraatio Multi-Hop ILP inference over Knowledge Base</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Régénération des explications via l'inférence ILP multi-sauts via la base de connaissances</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Míniú Athghiniúint trí Il-Hop ILP Tátail ar Bhonn Eolais</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>KCharselect unicode block name</a>
<a id=he_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>מחדש ההסבר באמצעות אינפרנציה ILP Multi-Hop על בסיס ידע</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>नॉलेज बेस पर मल्टी-हॉप आईएलपी अनुमान के माध्यम से स्पष्टीकरण पुनर्जनन</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Objašnjenje objašnjenja putem multiHop ILP Inferencije nad bazom znanja</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Magyarázat Regeneráció Multi-Hop ILP fertőzéssel a Tudásbázison keresztül</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Հիմացության հիմքի միջոցով բազմահույս ILP ինֆերանսը բացատրելու համար</a>
<a id=id_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Penjelasan Regenerasi melalui Multi-Hop ILP Inference over Knowledge Base</a>
<a id=is_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Rigenerazione tramite inferenza ILP multi-hop su Knowledge Base</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>ナレッジベース上のマルチホップILP推論による説明の再生</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>layer-mode-effects</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>განახსნა რეგენერაცია Multi-Hop ILP ინფერაცია მეცნიერების ბაზაზე</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Білім негізінен көп- хоп ILP инференциясы арқылы түсініктемелер</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>지식 라이브러리 기반의 멀티플렉스 ILP 추리의 해석 재생</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Paaiškinimas Regeneracija naudojant daugiapakopę ILP informaciją apie žinias</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Објаснување на регенерацијата преку Мулти-Hop ILP инференција преку базата на знаење</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Explanation Regeneration via Multi-Hop ILP Inference over Knowledge Base</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Мэдлэг суурь дээрх олон-Hop ILP нэр төрлийн тодорхойлолтыг дахин сэргээх</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Explanation Regeneration via Multi-Hop ILP Inference over Knowledge Base</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Spjegazzjoni Riġenerazzjoni permezz ta’ Inferenza ILP Multi-Hop fuq il-Bażi tal-Għarfien</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Verklaring Regeneratie via Multi-Hop ILP Inference over Knowledge Base</a>
<a id=no_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Uttrykk regenerasjon via fleirhopp ILP-inferens over kunnskapsbasen</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Wyjaśnienie Regeneracja za pomocą Multi-Hop ILP Inference w bazie wiedzy</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Explicação Regeneração via Inferência ILP Multi-Hop sobre Base de Conhecimento</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Explicație Regenerare prin infecția ILP Multi-Hop peste baza de cunoștințe</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Регенерация объяснения с помощью многохопового вывода ILP по сравнению с базой знаний</a>
<a id=si_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Multi-Hop ILP ප්‍රශ්නයක් දැනගන්න ප්‍රශ්නය</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Razlaga Regeneracija prek Multi-Hop ILP sklepanja nad bazo znanja</a>
<a id=so_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Regeneration of Explanation via Multi-Hop ILP Inference over Knowledge Base</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Shpjegimi Rigjenerimi nëpërmjet Inferencës Multi-Hop ILP mbi Bazën e njohurive</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Reģeneracija objašnjenja preko multiHop ILP Inferencije nad bazom znanja</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Förklaring Regenerering via Multi-Hop ILP Inferens över kunskapsbasen</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Kupitia Udhibiti wa Maelezo kupitia Udhibiti wa ILP katika Ufahamu</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>அறிவிப்பு அடிப்படையின் மேல் பல- ஹாப் ILP புகுதித்தல் மூலம் வெளியீட்டு மேலேற்றம்</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Multi-Hop ILP Bilim Basesynda düşündirim</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Multi-Hop ILP Inference over Knowledge Base through Explanation Regeneration</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Name</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>Giải thích cấu trúc qua nhiều ngành truyền thông qua Nhà tri thức</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2020.textgraphs-1.13.pdf>因知识库多跳跃 ILP 推理复生成</a></h2><p class=lead><a href=/people/a/aayushee-gupta/>Aayushee Gupta</a>,
<a href=/people/g/gopalakrishnan-srinivasaraghavan/>Gopalakrishnan Srinivasaraghavan</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Textgraphs 2020 Workshop organized a shared task on &#8216;Explanation Regeneration&#8217; that required reconstructing gold explanations for elementary science questions. This work describes our submission to the task which is based on multiple components : a BERT baseline ranking, an Integer Linear Program (ILP) based re-scoring and a regression model for re-ranking the explanation facts. Our <a href=https://en.wikipedia.org/wiki/System>system</a> achieved a Mean Average Precision score of 0.3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Textgraphs 2020 Workshop het 'n gedeelde taak op 'Verklaring Regenerasie' organiseer wat goud verklaring nodig het vir elementeerde wetenskap vrae herstruiker. Hierdie werk beskryf ons onderskrywing na die taak wat gebaseer is op veelvuldige komponente: 'n BERT baselyn rangering, 'n Heelgetalle Linear Program (ILP) gebaseer herskoring en 'n regresie model vir herrangering van die uitduidelingsfakte. Ons stelsel het 'n Gemiddelde Gemiddelde Gemiddelde Presisie Skaal van 0.3659 bereik.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>የጽሑፍ ግንኙነት 2020 ሰርቨርስቲ ለጥያቄ ሳይንቀሳዊ ጥያቄዎች የወርቅ ትርጓሜዎችን በመሠረት ያስፈልጋል፡፡ ይህ ሥራ በብዛት ክፍሎች ላይ ወደሚገኘው ስራታችንን የሚያሳውቃት ነው፤ BERT መቀመጫው ደረጃ፣ የኢሌም ጉዳይ ፕሮግራም (ILP) የተመሳሳይ የኢትዮጵያ መቆጣጠር እና የግልፅ ውርይይቶችን ለመመለስ እንደተደረገ አስተካክል ሞዴል ነው፡፡ ስርዓታችን የ0.3659 ጥያቄ ነጥብ አግኝቷል፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>نظمت ورشة عمل Textgraphs 2020 مهمة مشتركة حول "Explanation Regeneration" الذي تطلب إعادة بناء تفسيرات الذهب لأسئلة العلوم الأولية. يصف هذا العمل تقديمنا للمهمة التي تستند إلى مكونات متعددة: تصنيف BERT الأساسي ، وإعادة التصنيف المستند إلى البرنامج الخطي الصحيح (ILP) ونموذج الانحدار لإعادة ترتيب حقائق التفسير. حقق نظامنا متوسط درجات الدقة 0.3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Textgraphs 2020 Workshop, ilk elmi sualları üçün altın a çıqlamalarını yenidən inşa etmək lazım olan 'Explanation Regeneration' haqqında paylaşılan bir işi təyin etdi. Bu işlər çoxlu komponentlərə dayanan işlərə təklif etdiyimizi təsdiqləyir: BERT səviyyəsi səviyyəsi, tamamlama Linear Program ı (ILP) təkrar-scoring və a çıq-aydın faktlarını yenidən dəyişdirmək üçün regresiya modeli təsdiqləyir. Sistemimiz orta ədaləti 0.3659 dərəcəsini qəbul etdi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Текстове 2020 Семинарът организира споделена задача на тема "Обяснение за възстановяване", която изисква реконструкция на златни обяснения за елементарните научни въпроси. Тази работа описва нашето подчинение на задачата, която се основава на множество компоненти: базово класиране на базата на Цяла линейна програма (ИЛП) и регресионен модел за повторно класиране на обяснителните факти. Нашата система постигна средна прецизност от 0,3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>টেক্সট্রাফ ২০২০ ওয়ার্ক কর্মশালা 'এক্সপ্ল্যানেশন রিজেনারেশন' নিয়ে একটি শেয়ার কর্মসূচী আয়োজন করেছে, যা পুনরায় সোনার ব্যাখ্যা প্ এই কাজ আমাদের কাজের প্রতি আমাদের আত্মসমর্পণ বর্ণনা করা হয়েছে যা বেশ কয়েকটি উপাদানের ভিত্তিতে ভিত্তিক: বিবেরেট বেসালাইন রেঙ্কিং, একটি গ্রেটার লাইনার প্রোগ আমাদের সিস্টেম মেয়াদ সংখ্যার স্কোর অর্জন করেছে ০. ৩৬৫৯।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Textgraphs 2020 Workshop organized a shared task on `Explanation Regeneration' that required reconstructing gold explanations for elementary science questions. This work describes our submission to the task which is based on multiple components: a BERT baseline ranking, an Integer Linear Program (ILP) based re-scoring and a regression model for re-ranking the explanation facts. ང་ཚོའི་མ་ལག་གིས་རྒྱ་མཚུངས་གྱི་ཚད་རྟགས་པར་ཐག་ཚད་0.3659 ཡིན།</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Textgraphs 2020 Workshop organizirao je zajednički zadatak o "Regeneraciji objašnjenja", koji je zahtijevao rekonstrukciju zlatnih objašnjenja za osnovna naučna pitanja. Ovaj rad opisuje naše podatke na zadatku koji se temelji na višestrukim komponentima: početnoj liniji BERT, početnoj linijskoj programu (ILP) baziranoj ponovno izvlačenju i model regresije za ponovno reagiranje činjenica objašnjenja. Naš sistem je postigao srednju srednju tačnost od 0,3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>El taller Textgraphs 2020 va organitzar una tasca compartida sobre "Regeneració de l'Explicació" que necessitava reconstruir explicacions d'or per a preguntes de ciència elementar. This work describes our submission to the task which is based on multiple components: a BERT baseline ranking, an Integer Linear Program (ILP) based re-scoring and a regression model for re-ranking the explanation facts. El nostre sistema va aconseguir una puntuació mitjana de precisió de 0,3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Textgraphs 2020 Workshop uspořádal společný úkol na "Vysvětlení regenerace", který vyžadoval rekonstrukci zlatých vysvětlení pro základní vědecké otázky. Tato práce popisuje naše podání k úkolu, který je založen na několika komponentách: BERT základním hodnocení, integer lineárním programu (ILP) a regresním modelu pro přehodnocení vysvětlení faktů. Náš systém dosáhl skóre střední průměrné přesnosti 0.3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tekstgrafer 2020 Workshop organiserede en fælles opgave om `Forklaring Regeneration', der krævede rekonstruktion af guld forklaringer til elementære videnskabelige spørgsmål. Dette arbejde beskriver vores indlæg til opgaven, som er baseret på flere komponenter: en BERT-baseline ranking, en Integer Linear Program (ILP) baseret re-scoring og en regressionsmodel til re-rangering af forklaringsfakta. Vores system opnåede en gennemsnitlig præcision score på 0,3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Textgraphs 2020 Workshop organisierte eine gemeinsame Aufgabe zum Thema "Erklärung Regeneration", die die Rekonstruktion goldener Erklärungen für elementarwissenschaftliche Fragen erforderte. Diese Arbeit beschreibt unsere Einreichung zu der Aufgabe, die auf mehreren Komponenten basiert: einem BERT Baseline Ranking, einem Integer Linear Program (ILP) basierenden Re-Scoring und einem Regressionsmodell zum Re-Ranking der Erklärungsfaktoren. Unser System erreichte eine mittlere durchschnittliche Präzision Punktzahl von 0.3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Το εργαστήριο οργάνωσε ένα κοινό έργο με θέμα "Εξήγηση Αναγέννησης" που απαιτούσε την ανακατασκευή χρυσών εξηγήσεων για θέματα στοιχειώδους επιστήμης. Αυτή η εργασία περιγράφει την υποβολή μας στην εργασία η οποία βασίζεται σε πολλαπλά συστατικά: μια κατάταξη βάσης BERT, ένα ακέραιο γραμμικό πρόγραμμα (ILP) βασισμένο σε επαναβαθμολόγηση και ένα μοντέλο παλινδρόμησης για την επανακατάταξη των γεγονότων επεξήγησης. Το σύστημά μας πέτυχε μια μέση βαθμολογία ακρίβειας 0.3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>El taller Textgraphs 2020 organizó una tarea compartida sobre «Regeneración de explicaciones» que requirió la reconstrucción de explicaciones de oro para preguntas de ciencia elemental. Este trabajo describe nuestra sumisión a la tarea, que se basa en múltiples componentes: una clasificación de referencia BERT, una nueva calificación basada en el Programa Lineal de Enteros (ILP) y un modelo de regresión para volver a clasificar los hechos explicativos. Nuestro sistema obtuvo una puntuación de Precisión Media Media de 0.3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tekstid 2020 Töötuba korraldas ühise ülesande teemal "Selgituse taastumine", mis nõudis kuldsete selgituste rekonstrueerimist elementaarteaduse küsimustele. Käesolevas töös kirjeldatakse meie alluvust ülesandele, mis põhineb mitmel komponendil: BERT algtaseme järjestusel, täieliku lineaarse programmi (ILP) alusel põhineval ümberhindamisel ja regressioonimudel selgitavate faktide ümberhindamiseks. Meie süsteem saavutas keskmise täpsuse skoori 0,3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>کارگاه Textgraphs 2020 یک کار مشترک در مورد «توضیح بازسازی» که نیاز به بازسازی توضیح طلا برای سوالات علمی ابتدایی داشت. این کار تسلیم کردن ما به کار که بر پایه بسیاری از بخش‌های متعدد است توصیف می‌کند: صفحه پایین‌خط BERT، برنامه‌ی کلی خط‌شناسی (ILP) بر پایه‌ی بازگرداندن و مدل بازگرداندن برای بازگرداندن حقیقت توضیح‌ها. سیستم ما به یک امتیاز دقیق متوسط 0.3659 رسید.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tekstikuviot 2020 Workshop järjesti yhteisen tehtävän `Selityksen regeneroinnista', joka vaati kultaisten selitysten rekonstruointia alkeistieteellisiin kysymyksiin. Tässä työssä kuvataan tehtävään sitoutumista, joka perustuu useisiin komponentteihin: BERT-perusluokitukseen, kokonaislineaariseen ohjelmaan (ILP) perustuvaan uudelleenpisteytykseen ja regressiomalliin selittävien faktojen uudelleensijoitukseen. Järjestelmämme saavutti keskimääräisen tarkkuuden pisteen 0,3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>L'atelier Textgraphs 2020 a organisé une tâche partagée sur la « régénération des explications » qui nécessitait de reconstruire des explications en or pour des questions de sciences élémentaires. Ce travail décrit notre soumission à la tâche qui est basée sur plusieurs composantes : un classement de base BERT, un re-scoring basé sur un programme linéaire entier (ILP) et un modèle de régression pour reclasser les faits explicatifs. Notre système a obtenu un score de précision moyenne moyenne de 0,3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>D’eagraigh Ceardlann Textgraphs 2020 tasc roinnte ar ‘Athghiniúint Mínithe’ a d’éiligh míniúcháin óir a athchruthú do cheisteanna bunúsacha eolaíochta. Déanann an obair seo cur síos ar ár n-aighneacht don tasc atá bunaithe ar ilchodanna: rangú bonnlíne BERT, athscóráil bunaithe ar Chlár Líneach Slánuimhir (ILP) agus samhail aischéimnithe chun na fíricí mínithe a athrangú. Bhain ár gcóras Meánscór beachtais de 0.3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Textgraphs 2020 Wannan aikin yana bayyana mĩƙa zuwa aikin da aka ƙaddara shi a kan wasu composhi: ranning basin BERT, Shirin Ayuka na Inter Linke (ILP) da aka asa shi a kan re-score kuma wata motel na haramtar da za'a sake ranar da gaskiyar fassarar. Babu'ananmu ya sami wani nau'in Narayi na gaba 0.3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Workshop Textgraphs 2020 ארגן משימה משותפת על "ההסבר מחדש" שדורש שיחזור ביצוע הסברים זהב לשאלות מדע יסודיים. העבודה הזו מתארת את ההעברה שלנו למשימה שמבוססת על מרובות מרכיבים: דירה בסיסית BERT, תוכנית לינרית שלמה (Integer Linear Program, ILP) מבוססת על דירה מחדש ומודל regression כדי לשדרג את העובדות ההסבר. המערכת שלנו השיגה נקודת מדויקת ממוצעת 0.3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>टेक्स्टग्राफ 2020 कार्यशाला ने 'स्पष्टीकरण पुनर्जनन' पर एक साझा कार्य का आयोजन किया, जिसके लिए प्राथमिक विज्ञान के प्रश्नों के लिए सोने के स्पष्टीकरण के पुनर्निर्माण की आवश्यकता थी। यह काम उस कार्य के लिए हमारे सबमिशन का वर्णन करता है जो कई घटकों पर आधारित है: एक BERT बेसलाइन रैंकिंग, एक पूर्णांक रैखिक कार्यक्रम (ILP) आधारित पुन: स्कोरिंग और स्पष्टीकरण तथ्यों को फिर से रैंकिंग करने के लिए एक प्रतिगमन मॉडल। हमारे सिस्टम ने 0.3659 का एक औसत औसत परिशुद्धता स्कोर हासिल किया।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Textgraphs 2020 Workshop organizirao je zajednički zadatak o "Regeneraciji objašnjenja" koji je zahtijevao rekonstrukciju zlatnih objašnjenja za osnovna znanstvena pitanja. Ovaj rad opisuje naše podatke na zadatku koji se temelji na višestrukim komponentima: početnoj liniji BERT, početnoj linijskoj programu (ILP) baziranom ponovnom izvlačenju i model regresije za ponovno reagiranje činjenica objašnjenja. Naš sustav je postigao srednji prosječni rezultat točnosti od 0,3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Textgraphs 2020 Workshop egy közös feladatot szervezett "Magyarázat regeneráció" címmel, amely az alapvető tudományos kérdések arany magyarázatainak rekonstruálására volt szükség. Ez a munka több összetevőn alapuló feladatnak való benyújtásunkat ismerteti: BERT alapszint rangsorolás, ILP alapú újraértékelés és regressziós modell a magyarázat tényeinek újraértékelésére. Rendszerünk 0,3659-es átlagos pontszámot ért el.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Տեքստգրաֆ 2020-ի աշխատասենյակը կազմակերպեց «Պատասխանատվության վերականգնումը» ընդհանուր խնդիր, որը պահանջեց վերականգնել ոսկու բացատրությունները տարրական գիտության հարցերի համար: Այս աշխատանքը նկարագրում է մեր ներկայացումը հանձնարարության վրա, որը հիմնված է բազմաթիվ բաղադրիչների վրա. BER-ի հիմնական դասակարգում, Ամբողջ գծային ծրագիր (ILP) հիմնված վերադասակարգում և վերադասակարգում մոդել բացատրության փաստերի վերադասակարգում: Մեր համակարգը հասավ միջին ճշգրտության 0.3659 գնահատականի:</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Workshop Textgraphs 2020 mengatur tugas berbagi pada `Explanation Regeneration' yang membutuhkan rekonstruksi penjelasan emas untuk pertanyaan ilmu dasar. This work describes our submission to the task which is based on multiple components: a BERT baseline ranking, an Integer Linear Program (ILP) based re-scoring and a regression model for re-ranking the explanation facts. Sistem kita mencapai nilai Precision Utara 0,3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Textgraphs 2020 Workshop ha organizzato un compito condiviso su `Spiegazione Rigenerazione' che richiedeva la ricostruzione di spiegazioni d'oro per questioni scientifiche elementari. Questo lavoro descrive la nostra sottomissione al compito che si basa su più componenti: una classifica di base BERT, un re-scoring basato su un programma lineare intero (ILP) e un modello di regressione per ri-ranking dei fatti di spiegazione. Il nostro sistema ha ottenuto un punteggio medio di precisione di 0,3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>テキストグラフ2020ワークショップでは、基礎科学の質問に対する金の説明の再構築を必要とする「説明の再生」に関する共有タスクを開催しました。この研究では、BERTベースラインランキング、整数線形プログラム（ ILP ）ベースの再スコアリング、および説明事実を再ランク付けするための回帰モデルという複数のコンポーネントに基づいたタスクへの提出について説明します。当社のシステムは、平均精度スコア0.3659を達成しました。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>textgraphs 2020 Workspace 1 Sistem dhéwé éntuk tanggal sing perusahaan kanggo 0.246</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Textgraphs 2020 Workshop organised a shared task on `Explanation Regeneration' that required reconstruction of gold explanations for elementary science questions. ეს სამუშაო აღწერს ჩვენი დამუშაობა რაოდენტის დაბაზეული მრავალ კომპონტენტებზე: BERT ბაზილური რენექციის რენექცია, მუშაობელი რენექციის პროგრამი (ILP) დაბაზეული რესკორცია და რეგრესიის ნაქარა ჟთჟრვმა ეჲჟრигნალა ჟპვენარა ჟპვენარა ოპვეგთე ნა 0,3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Текстграфикалық 2020 жұмыс істемесі бағдарламалық ғылым сұрақтарының алтын түсініктемелерін қайта құру керек 'Түсініктемелер регенерациясы' деген ортақ тапсырманы орындады. Бұл жұмыс бірнеше компоненттерге негізделген тапсырмаға жіберімізді анықтайды: BERT негізгі жолдар, толық сызық бағдарламасы (ILP) негізделген қайта сұрау мен түсініктерді қайта реттеу үшін регрессия моделі. Біздің жүйеміз 0,3659 деген орташа дәрежес нәтижесін жетті.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Textgraphs 2020 세미나는'해석 재생'에 대한 공유 임무를 조직해 기초 과학 문제의 황금 해석을 재건할 것을 요구했다.이 작업은 우리가 임무에 대한 제출을 묘사했다. 이 임무는 여러 가지 구성 부분을 바탕으로 한다. 하나는 버트 기선 랭킹, 하나는 정수선형 계획 (ILP) 을 바탕으로 하는 재평가, 그리고 하나는 사실을 재배열하고 해석하는 데 사용되는 회귀 모델이다.우리 시스템의 평균 정밀도는 0.3659로 나뉜다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>„Textgraphs 2020“ seminare buvo surengta bendra užduotis „Paaiškinimo regeneracija“, pagal kurią reikėjo atkurti aukso paaiškinimus pagrindiniams mokslo klausimams. Šiame darbe apibūdinamas mūsų pristatymas uždaviniui, kuris grindžiamas keliomis sudedamosiomis dalimis: BERT pradiniu reitingu, Integralios linijinės programos (ILP) pakartotiniu reitingu ir regresijos modeliu, skirtu pakartotiniam paaiškinimo faktų reitingui. Mūsų sistema pasiekė vidutinį tikslumą 0,3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Workshop Textgraphs 2020 организираше заедничка задача за „Регенерација на објаснувањето“ која бараше реконструкција на златни објаснувања за прашањата на основната наука. Оваа работа ја опишува нашата поднесувачка на задачата која се базира на повеќе компоненти: рангирање на база на БЕРТ, рерангирање на целосната линијарна програма (ИЛП) и регресен модел за рерангирање на фактите за објаснување. Нашиот систем постигна просечна точност од 0,3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>എക്സ്പ്ലാനേഷന്‍ റിജെനെഷനേഷനില്‍ പങ്കാളിയുള്ള ഒരു ജോലി ഒരുക്കിവെച്ചിരിക്കുന്നു. ആദ്യത്തിലെ ശാസ്ത്ര ശാസ്ത്ര ചോദ്യങ This work describes our submission to the task which is based on multiple components: a BERT baseline ranking, an Integer Linear Program (ILP) based re-scoring and a regression model for re-ranking the explanation facts. നമ്മുടെ സിസ്റ്റത്തിന്റെ മേനസ്ഥാനം 0.3659 പ്രിസിഷന്‍ സ്കോര്‍ എത്തി.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Textgraphs 2020 Workshop нь үндсэн шинжлэх ухааны асуултуудад алт тайлбарыг дахин бүтээх шаардлагатай "Тодорхойлолт дахин сэргээх" талаар хуваалцааг зохион байгуулсан. Энэ ажил бидний олон компонент дээр суурилсан даалгаврыг тайлбарладаг: BERT үндсэн шугам, бүтэн шугам хөтөлбөр (ILP) дээр суурилсан дахин сүлжээ болон тайлбарлалтын үндсэн талаар дахин сүлжээний загвар. Бидний систем 0.3659 дундаж дундаж дундаж тодорхойлолт гарсан.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kerja kerja Textgraphs 2020 mengatur tugas berkongsi pada `Explanation Regeneration' yang memerlukan pembangunan semula penjelasan emas untuk soalan sains asas. Kerja ini menggambarkan penghantaran kami ke tugas yang berdasarkan komponen berbilang: rangkaian dasar BERT, rangkaian semula berdasarkan Program Linar Integer (ILP) dan model regresi untuk rangkaian semula fakta penjelasan. Our system achieved a Mean Average Precision score of 0.3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Il-Workshop tat-Teksti 2020 organizza kompitu komuni dwar “Riġenerazzjoni ta’ Spjegazzjoni” li kien jeħtieġ ir-rikostruzzjoni ta’ spjegazzjonijiet tad-deheb għal kwistjonijiet ta’ xjenza elementari. Dan ix-xogħol jiddeskrivi s-sottomissjoni tagħna għall-kompitu li huwa bbażat fuq komponenti multipli: klassifikazzjoni tal-linja bażi BERT, klassifikazzjoni mill-ġdid ibbażata fuq Programm Linjari Integri (ILP) u mudell ta’ rigressjoni għall-klassifikazzjoni mill-ġdid tal-fatti ta’ spjegazzjoni. Is-sistema tagħna kisbet punteġġ Medju ta’ Preċiżjoni ta’ 0.3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Textgraphs 2020 Workshop organiseerde een gezamenlijke taak over 'Verklaring Regeneratie' die gold verklaringen voor elementaire wetenschappelijke vragen moest reconstrueren. Dit werk beschrijft onze inzending aan de taak die is gebaseerd op meerdere componenten: een BERT baseline ranking, een Integer Linear Program (ILP) gebaseerde re-score en een regressiemodel voor het opnieuw rangschikken van de verklaringsfeiten. Ons systeem behaalde een gemiddelde gemiddelde precisiescore van 0.3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Textgraphs 2020 Workshop organisert ei delt oppgåve på « Explanation Regeneration », som krevst å gjenoppretta gull-forklaringar for elementære vitenskapsførsmål. Dette arbeidet beskriver vår tilføring til oppgåva som er basert på fleire komponentar: ein BERT baselinjer, ein heiltal linjerprogram (ILP) basert på omskoring og ein regresjonsmodul for å gjenoppretta utklaringsfakta. Sistemet vårt oppnådd ein gjennomsnittlig gjennomsnittlig presisjonskort på 0,3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Warsztaty Textgraphs 2020 zorganizowały wspólne zadanie "Regeneracja wyjaśnień", które wymagało rekonstrukcji złotych wyjaśnień dla podstawowych pytań naukowych. W niniejszej pracy opisano naszą zgłoszenie się do zadania, które opiera się na wielu składnikach: rankingu bazowego BERT, całkowitego programu liniowego (ILP) oraz modelu regresji do ponownego rankingu faktów wyjaśniających. Nasz system osiągnął średnią średnią precyzję wyniku 0.3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>O Workshop Textgraphs 2020 organizou uma tarefa compartilhada sobre 'Regeneração de Explicações' que exigia a reconstrução de explicações de ouro para questões científicas elementares. Este trabalho descreve nossa submissão à tarefa que é baseada em múltiplos componentes: um ranking de linha de base do BERT, um rescoring baseado em ILP (Programa Linear Inteiro) e um modelo de regressão para reordenar os fatos explicativos. Nosso sistema alcançou uma pontuação de Precisão Média Média de 0,3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Atelierul de lucru 2020 a organizat o sarcină comună privind "Regenerarea explicațiilor", care a necesitat reconstruirea explicațiilor de aur pentru întrebările științifice elementare. Această lucrare descrie prezentarea noastră la sarcina care se bazează pe mai multe componente: un clasament BERT de bază, un program liniar întreg (ILP) bazat pe re-scoring și un model de regresie pentru re-rangarea faptelor explicative. Sistemul nostru a obținut un scor de precizie medie medie de 0,3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Семинар Textgraphs 2020 организовал совместную задачу по «регенерации объяснений», которая потребовала реконструировать объяснения золота для вопросов элементарной науки. Эта работа описывает наше участие в задаче, которая основана на нескольких компонентах: ранжирование базовой линии BERT, пересчет на основе целочисленной линейной программы (ILP) и регрессионная модель для пересчета объясняющих фактов. Наша система достигла среднего балла прецизионности 0,3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>textGraphs 2020වැඩසටහන් විශ්වාස ප්‍රශ්නය සඳහා සාමාන්‍ය වැඩසටහන් සැකසුම් කරලා තියෙනවා. මේ වැඩේ අපේ ප්‍රතිචාරය විස්තර කරනවා වගේම විශේෂ අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අංක අං අපේ පද්ධතිය පරීක්ෂණය 0.3659 වෙනුවෙන් සාමාන්‍ය විශ්වාසයක් ලැබුනා.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Besedila 2020 Delavnica je organizirala skupno nalogo ‚Razlaganje regeneracije', ki je zahtevala rekonstrukcijo zlatih razlag za osnovna znanstvena vprašanja. To delo opisuje našo predložitev nalogi, ki temelji na več komponentah: osnovni razvrstitvi BERT, ponovni oceni celotnega linearnega programa (ILP) in regresijskem modelu za ponovno razvrstitev pojasnjevalnih dejstev. Naš sistem je dosegel rezultat povprečne natančnosti 0,3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Textgraphs 2020 Workshop wuxuu qabanqaabiyey shuqul la qayb ah oo ku saabsan `Explanation Regeneration' oo u baahan yahay in loo dhiso fasirada dahab ah si ay u dhisto su'aalaha cilmiga hoose. Shaqadan wuxuu ku qoran yahay dhiigga shaqada oo ku saleysan qeybaha kala duduwan: saqafka baseline ee BERT, barnaamijka caadiga Linear (ILP) oo ku saleysan cusboonaysiinta iyo modelka dib u dhigista oo u beddelaysa arrimaha fasaxa. Systemkanagu wuxuu gaadhay qiimaha darajada hore ee 0.3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Workshop Textgraphs 2020 organizoi një detyrë të përbashkët mbi `Shpjegimin Rigjenerim' që kërkonte rindërtimin e shpjegimeve të artë për çështjet e shkencës elementare. Ky punë përshkruan paraqitjen tonë ndaj detyrës që është bazuar në komponente të shumta: një renditje bazë BERT, një renditje bazë Integer Linear Program (ILP) dhe një model regresioni për renditjen e fakteve të shpjegimit. Sistemi ynë arriti një rezultat mesatar të saktësisë 0.3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Textgraphs 2020 Workshop je organizovao zajednički zadatak o «Reģeneraciji objašnjenja» koji je zahtijevao rekonstrukciju zlatnih objašnjenja za osnovna naučna pitanja. Ovaj rad opisuje našu predanost zadatku koji je baziran na višestrukim komponentima: početnoj liniji BERT, početnoj linijskoj programu (ILP) baziranoj ponovno izvlačenju i model regresije za ponovno reagiranje činjenica objašnjenja. Naš sistem je postigao srednju srednju tačnost od 0,3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Textgrafer 2020 Workshop organiserade en gemensam uppgift om "Förklaring Regeneration" som krävde rekonstruktion av guldförklaringar för grundläggande vetenskapliga frågor. Detta arbete beskriver vår inlämning till uppgiften som baseras på flera komponenter: en BERT baslinje ranking, en heltalslinjär program (ILP) baserad omräkning och en regressionsmodell för omräkning av förklaringsfakta. Vårt system uppnådde en genomsnittlig precision poäng på 0,3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Warsha ya Teknolojia 2020 iliandaa kazi ya ushirikiano juu ya “Ujenzi wa Utafiti wa Maelezo” ambayo ilihitaji kujenga maelezo ya dhahabu kwa maswali ya msingi ya sayansi. Kazi hii inaelezea ujumbe wetu wa kazi inayohusiana na vipengele kadhaa: Mpango wa Ujumbe wa BERT unaoandaliwa, Mpango wa Ujumbe wa Linear (ILP) unaoanzishwa kwa upya upya na modeli wa kandamizi kwa ajili ya kutafuta ukweli wa maelezo. Mfumo wetu ulipata kiwango cha wastani cha Uheshima cha 0.3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>'Explanation Regeneration' மீது ஒரு பகிர்ந்த பணியை அமைத்தது பொருள் அறிவியல் கேள்விகளுக்கான தங்கக் விளக்கங்களை மீண்டும் அமைக்க வேண்டும். இந்த வேலை பல பொருள்களை அடிப்படையில் எங்கள் பணிக்கு ஏற்றுமதி குறிப்பிடுகிறது. BERT அடிப்படைக்கோடு வரிசையில், ஒரு முழு கோடு நிரல் (ILP) அடிப்படையில் மீண்டும் மத எங்கள் அமைப்பு 0.3659 சராசரி மதிப்பு மதிப்பெண்ணை அடைந்தது.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Textgraphs 2020 Workshop, elementary bilim soraglary üçin altyn düşündirimlerini täzeden guruldy. Bu işe biziň gönderişimizi birnäçe komponentlere daýan ýan zada tassyklaýar: BERT baseline derejesi, bir Integer Linear Program (ILP) ýene-küýtgetmek we düşündirilmek üçin regresije modeli. Biziň sistemamyz orta orta karanlyk 0.3659 netijesinde çykdy.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Textgraphs 2020 Workshop نے `Explanation Regeneration' کے بارے میں ایک مشترک کام کا سامان کیا تھا جس کے لئے سونے کی توضیح اولی سائنس سؤال کے لئے دوبارہ ساخت کرنے کی ضرورت تھی. یہ کام ہماری اطلاعات کو بہت سی قسمتوں پر بنیاد رکھتا ہے: BERT بنیاد لین رینگ، Integer Linear پروگرام (ILP) بنیاد رکھتا ہے کہ دوبارہ اسکورینگ اور واضح حقیقتوں کو دوبارہ رینگ کرنے کے لئے ریگرس موڈل ہے. ہماری سیستم نے 0.3659 کی میانہ میانہ مضبوط سطح کا امتیاز پہنچا۔</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>2020 Ish stoli `Explanation Regeneration' haqida bir qanday ishni tayyorlaydi. Ilmiy savollari uchun gullni qayta o'rnatish kerak. Bu ishni bir necha komponentlar asosida yaratilgan vazifaning imkoniyatini anglatadi: BERT asosiy satr chegarasi, IP asosida qayta qiymatni qaytadan qo'yish dasturi va faqatlarni qaytadan boshlash uchun boshqarish modeli. Our system achieved a Mean Average Precision score of 0.3659.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Văn bản 2020 Workshop đã tổ chức một nhiệm vụ chia sẻ về "Giải thích cấu trúc" cần làm lại giải thích vàng cho các câu hỏi khoa học cơ bản. Công việc này mô tả sự phục tùng của chúng ta cho nhiệm vụ dựa trên nhiều thành phần: ưu thế hoàn to àn của BERT, một chương trình dây chằng Integer (ILP) dựa vào điểm đánh giá lại và một mô hình hồi quy để xếp lại các dữ liệu giải thích. Hệ thống của chúng tôi đạt được điểm chính xác trung bình</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Textgraphs 2020研讨会说再生之共同任务,重建科学金之说。 其言我于数组件之任:BERT基线之排名,基于整数线性规画(ILP)之重评分及以重名说事者归之。 统之均精,分为0.3659。</span></div></div><dl><dt>Anthology ID:</dt><dd>2020.textgraphs-1.13</dd><dt>Volume:</dt><dd><a href=/volumes/2020.textgraphs-1/>Proceedings of the Graph-based Methods for Natural Language Processing (TextGraphs)</a></dd><dt>Month:</dt><dd>December</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Barcelona, Spain (Online)</dd><dt>Venues:</dt><dd><a href=/venues/coling/>COLING</a>
| <a href=/venues/textgraphs/>TextGraphs</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>109–114</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.textgraphs-1.13>https://aclanthology.org/2020.textgraphs-1.13</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/2020.textgraphs-1.13 title="To the current version of the paper by DOI">10.18653/v1/2020.textgraphs-1.13</a></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">gupta-srinivasaraghavan-2020-explanation</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Aayushee Gupta and Gopalakrishnan Srinivasaraghavan. 2020. <a href=https://aclanthology.org/2020.textgraphs-1.13>Explanation Regeneration via Multi-Hop ILP Inference over Knowledge BaseILP Inference over Knowledge Base</a>. In <i>Proceedings of the Graph-based Methods for Natural Language Processing (TextGraphs)</i>, pages 109–114, Barcelona, Spain (Online). Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2020.textgraphs-1.13>Explanation Regeneration via Multi-Hop ILP Inference over Knowledge BaseILP Inference over Knowledge Base</a> (Gupta & Srinivasaraghavan, TextGraphs 2020)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2020.textgraphs-1.13.pdf>https://aclanthology.org/2020.textgraphs-1.13.pdf</a></dd><dt class=acl-button-row>Optional supplementary material:</dt><dd class=acl-button-row><a href=https://aclanthology.org/attachments/2020.textgraphs-1.13.OptionalSupplementaryMaterial.pdf class="btn btn-attachment btn-sm"><i class="fas fa-file"></i>
&nbsp;2020.textgraphs-1.13.OptionalSupplementaryMaterial.pdf</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2020.textgraphs-1.13.pdf title="Open PDF of 'Explanation Regeneration via Multi-Hop ILP Inference over Knowledge BaseILP Inference over Knowledge Base'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Explanation+Regeneration+via+Multi-Hop+ILP+Inference+over+Knowledge+BaseILP+Inference+over+Knowledge+Base" title="Search for 'Explanation Regeneration via Multi-Hop ILP Inference over Knowledge BaseILP Inference over Knowledge Base' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'Explanation Regeneration via Multi-Hop ILP Inference over Knowledge BaseILP Inference over Knowledge Base'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a>
<a class="btn btn-attachment d-flex flex-wrap justify-content-center" href=https://aclanthology.org/attachments/2020.textgraphs-1.13.OptionalSupplementaryMaterial.pdf title="Open optional supplementary material for 'Explanation Regeneration via Multi-Hop ILP Inference over Knowledge BaseILP Inference over Knowledge Base'"><span class="align-self-center px-1"><i class="fas fa-file"></i></span>
<span class=px-1>Optional supplementary material</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[Explanation Regeneration via Multi-Hop ILP Inference over Knowledge BaseILP Inference over Knowledge Base](https://aclanthology.org/2020.textgraphs-1.13) (Gupta & Srinivasaraghavan, TextGraphs 2020)</p><ul class=mt-2><li><a href=https://aclanthology.org/2020.textgraphs-1.13>Explanation Regeneration via Multi-Hop ILP Inference over Knowledge BaseILP Inference over Knowledge Base</a> (Gupta & Srinivasaraghavan, TextGraphs 2020)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Aayushee Gupta and Gopalakrishnan Srinivasaraghavan. 2020. <a href=https://aclanthology.org/2020.textgraphs-1.13>Explanation Regeneration via Multi-Hop ILP Inference over Knowledge BaseILP Inference over Knowledge Base</a>. In <i>Proceedings of the Graph-based Methods for Natural Language Processing (TextGraphs)</i>, pages 109–114, Barcelona, Spain (Online). Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>