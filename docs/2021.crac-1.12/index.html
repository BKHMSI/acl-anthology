<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>On Generalization in Coreference Resolution - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="On Generalization in Coreference Resolution" name=citation_title><meta content="Shubham Toshniwal" name=citation_author><meta content="Patrick Xia" name=citation_author><meta content="Sam Wiseman" name=citation_author><meta content="Karen Livescu" name=citation_author><meta content="Kevin Gimpel" name=citation_author><meta content="Proceedings of the Fourth Workshop on Computational Models of Reference, Anaphora and Coreference" name=citation_conference_title><meta content="2021/11" name=citation_publication_date><meta content="https://aclanthology.org/2021.crac-1.12.pdf" name=citation_pdf_url><meta content="111" name=citation_firstpage><meta content="120" name=citation_lastpage><meta content="10.18653/v1/2021.crac-1.12" name=citation_doi><meta property="og:title" content="On Generalization in Coreference Resolution"><meta property="og:image" content="https://aclanthology.org/thumb/2021.crac-1.12.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2021.crac-1.12"><meta property="og:description" content="Shubham Toshniwal, Patrick Xia, Sam Wiseman, Karen Livescu, Kevin Gimpel. Proceedings of the Fourth Workshop on Computational Models of Reference, Anaphora and Coreference. 2021."><link rel=canonical href=https://aclanthology.org/2021.crac-1.12></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2021.crac-1.12.pdf>On Generalization in <a href=https://en.wikipedia.org/wiki/Coreference_resolution>Coreference Resolution</a></a>
<a id=af_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Op Generalisasie in Hoofheidsoplossing</a>
<a id=am_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>ምርጫዎች</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>في التعميم في Coreference Resolution</a>
<a id=az_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>캻fad톛 칂칬z칲n칲rl칲y칲nd톛 Generalizasyonda</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Относно обобщението в резолюцията на кореференцията</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>সাধারণ সংস্থা</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>མཐའ་དབྱིབས་གདམ་ཁ་ཚོགས་ནང་དུ་སྤྱིར་བཏང་བ</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>O generalizaciji u rezoluciji korisnosti</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>En la Generalització en la Resolució de Coreferència</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>O obecnění v usnesení společné reference</a>
<a id=da_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Generalisering i Coreference-resolutionen</a>
<a id=de_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Zur Generalisierung in der Coreferenz Resolution</a>
<a id=el_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Για τη γενίκευση στο ψήφισμα της συναδέλφου</a>
<a id=es_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Sobre la generalización en la resolución de correferencias</a>
<a id=et_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Korralduse resolutsiooni üldistamine</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>ШҜШұ ШӘЩҲЩ„ЫҢШҜ ЪҳЩҶШұШ§Щ„ ШҜШұ ШӯЩ„вҖҢШіШ§ШІЫҢ ЩҫЫҢШҙЩҶЩҮШ§ШҜ</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Coreference-päätöslauselman yleistämisestä</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Sur la généralisation dans la résolution de coréférence</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Ar Ghinearálú i Rún Croíthagartha</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>@ action</a>
<a id=he_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>על הגנרליזציה בפתרון הקבוצה</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Coreference संकल्प में सामान्यीकरण पर</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>O generalizaciji u rezoluciji korisnosti</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Általánosítás a Coreferencia-állásfoglalásban</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Կորեֆերանսի լուծումների ընդհանուր հաստատության մասին</a>
<a id=id_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Pada Generalisasi dalam Resolusi Koreference</a>
<a id=is_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Sulla generalizzazione nella risoluzione di Coreferenza</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>コアリファレンス分解能の一般化について</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>iku</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>გენერალიზაციის რეზიოციაში</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Жалпы қасиеттердің Айырымдылығында</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>논공지 소해 중의 범화</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Dėl bendrosios konferencijos rezoliucijos</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>За генерализација во резолуцијата на кореференцијата</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>കോര്‍ഫെന്‍സ് റിപ്പോര്‍ഷനില്‍ ജനറലേഷന്‍ ചെയ്യുമ്പോള്‍</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Хэрэглэгчдийн шийдвэрлэлийн ерөнхийлөгч</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Pada Jeneralisasi dalam Resolusi Coreference</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>On Generalization in Coreference Resolution</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Over generalisering in de resolutie van de Coreferentie</a>
<a id=no_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>På Generalisering i oppløysing av koreferansen</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>W sprawie uogólnienia w rezolucji współpracy</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Sobre Generalização na Resolução de Correferência</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Cu privire la generalizarea în rezoluția Coreferenței</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Об обобщении в ключевом разрешении</a>
<a id=si_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>ප්‍රමාණ විශේෂණයේ සාමාන්‍ය විශේෂණය සඳහා</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>O splošnosti v resoluciji Coreference</a>
<a id=so_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Waxyaabaha guud ee koreference Resolution</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Për gjeneralizimin në rezolutën e Koreferencës</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Na generalizaciji u rezoluciji korisnosti</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Generalisering i Coreference-resolutionen</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Katika Ujumla wa Mazingiro</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>திரைத்திறனில் பொதுவாக்குதலில்</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Däşer Seçenekleri Çaşyrmakda</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>قابل رخصت رخصت میں جرائنالیزی پر</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Name</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>Về việc mời gọi giải quyết</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2021.crac-1.12.pdf>其共推理解析中泛化</a></h2><p class=lead><a href=/people/s/shubham-toshniwal/>Shubham Toshniwal</a>,
<a href=/people/p/patrick-xia/>Patrick Xia</a>,
<a href=/people/s/sam-wiseman/>Sam Wiseman</a>,
<a href=/people/k/karen-livescu/>Karen Livescu</a>,
<a href=/people/k/kevin-gimpel/>Kevin Gimpel</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>While <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> is defined independently of dataset domain, most <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> for performing <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> do not transfer well to unseen domains. We consolidate a set of 8 coreference resolution datasets targeting different domains to evaluate the off-the-shelf performance of <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. We then mix three datasets for training ; even though their domain, annotation guidelines, and <a href=https://en.wikipedia.org/wiki/Metadata>metadata</a> differ, we propose a method for jointly training a single model on this heterogeneous data mixture by using <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> to account for annotation differences and <a href=https://en.wikipedia.org/wiki/Sampling_(statistics)>sampling</a> to balance the data quantities. We find that in a zero-shot setting, <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained on a single dataset transfer poorly while joint training yields improved overall performance, leading to better generalization in coreference resolution models. This work contributes a new <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark</a> for robust coreference resolution and multiple new state-of-the-art results.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Terwyl koreferensieresolusie onveilig van datastel domein gedefinieer is, die meeste modele vir die uitvoer van koreferensieresolusie doen nie goed oordra na onversekende domeine nie. Ons konsoliseer 'n stel van 8 koreferensie oplossing datastelle wat verskillende domeine doen om die af-die-shelf-prestasie van modele te evalueer. Ons het dan drie datastel vir onderwerp gemeng; selfs al is hulle domein, annotasie gidsels, en metadata verskillig, ons voorstel 'n metode vir joint onderwerp van 'n enkele model op hierdie heterogeneese data gemeng deur data vergroot te gebruik om rekening vir annotasie verskillinge en verskillinge te bereik om die data quantiteite te balanse. Ons vind dat in 'n nul-skoot instelling, modele wat op 'n enkele datastel oordrag verkeerd is, terwyl saamste onderwerking vergeet het die hele prestasie verbeter, wat na beter generellisering in koreferensie-oplossing modele lei. Hierdie werk bydra 'n nuwe benchmark vir kragtige koreferensie-oplossing en veelvuldige nuwe staat-van-kuns-resultate.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ምንም እንኳን የኮርፌንቨርስቲ ግንኙነት ከዳታ ሳንተር ብልሃት የተረጋገጠ ሲሆን፣ ብዙዎቹ ምሳሌዎች የኮርፌንሬሽን ማስታወቂያውን ለመፈለግ በመልካም አይለውጡም፡፡ የዓይነቶች አካሄዱን ለማስተካከል የክፍለ ሥርዓት አካባቢ አካባቢ እናደርጋለን፡፡ ከዚያም ሦስት ዳታ ሰርተቶችን ለትምህርት እናጣብቃለን:: ምንም እንኳን አካሄዳቸው፣ ማስታወቂያው መሪ እና ማህተት ቢለዩም እንኳን፣ የዳታ ክፍተቶችን በማስተካከል እና የዳታ ክፍተቶችን ለመቆጣጠር እናሳውቃለን፡፡ በzero-shot ክፍል፣ በአንድ ዳታ-ሰርቨር ማቀናጃ ላይ የተማረ ምሳሌዎች በሙሉ ተማርኮ ይሻላል፡፡ ይህ ሥራ አዲስ የኮርፖስቲካ ማስታወቂያውን እና አዲስ የ-አርእስት ውጤቶች አዲስ አዲስ የአፍሪካ ውጤቶች ያሳያል፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>بينما يتم تحديد دقة المرجع بشكل مستقل عن مجال مجموعة البيانات ، فإن معظم النماذج الخاصة بأداء دقة المرجع لا تنتقل بشكل جيد إلى المجالات غير المرئية. نقوم بدمج مجموعة من 8 مجموعات بيانات ذات دقة مرجعية تستهدف مجالات مختلفة لتقييم الأداء الجاهز للنماذج. ثم نمزج ثلاث مجموعات بيانات للتدريب ؛ على الرغم من اختلاف المجال وإرشادات التعليقات التوضيحية والبيانات الوصفية ، فإننا نقترح طريقة للتدريب المشترك لنموذج واحد على مزيج البيانات غير المتجانسة هذا باستخدام زيادة البيانات لحساب اختلافات التعليقات التوضيحية وأخذ العينات لموازنة كميات البيانات. نجد أنه في إعداد اللقطة الصفرية ، فإن النماذج المدربة على نقل مجموعة بيانات واحدة بشكل سيئ بينما يؤدي التدريب المشترك إلى تحسين الأداء العام ، مما يؤدي إلى تعميم أفضل في نماذج دقة المرجع. يساهم هذا العمل في معيار جديد للقرار المرجعي القوي ونتائج متعددة جديدة على أحدث طراز.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mərhəmətli çözünürlük verilən qurğulu domena bağımsız tərzdə belirlənirsə, çox mərhəmətli çözünürlük etmək üçün modellər gözəl görünməyən domena tərəfindən keçirilməz. Biz 8 rəftar çözünürlük verilənləri birləşdiririk ki, modellərin dəyişikliyini değerləşdirmək üçün müxtəlif domenalar nişanlayırlar. Sonra təhsil üçün üç verilən qurğu karışırıq. Onların domeini, bildirim doğruluqlarını və metadata fərqli olmasına rağmen, biz bu heterogenel veri karışması barəsində bir modeli birlikdə təhsil etmək üçün məlumatları artırmaq və məlumatları müəyyən etmək üçün məlumatları hesablamaq üçün bir modeli təklif edirik. Sıfır-fəsad qurğularında, tək veri qurğularında təhsil edilən modellər pis bir dəyişiklikdə, birlikdə təhsil təhsil ürəklərinin bütün performanslarını daha yaxşı təhsil edir, daha yaxşı generalizasyon modellərdə təhsil edir. Bu işin yeni bir benchmark möhkəm mərhəmət çözünürlərini və çoxlu yeni mərhəmət sonuçlarını sağlar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Докато резолюцията на кореференцията се определя независимо от домейна на набора от данни, повечето модели за извършване на резолюция на кореференцията не се прехвърлят добре към невидими домейни. Консолидираме набор от 8 набора от данни за разделителна способност, насочени към различни области, за да оценим ефективността на моделите. След това смесваме три набора данни за обучение; въпреки че техните области, насоки за анотация и метаданни се различават, ние предлагаме метод за съвместно обучение на един модел за тази хетерогенна смес от данни чрез използване на увеличаване на данните, за да се отчетат разликите в анотацията, и вземане на проби за балансиране на количествата данни. Установяваме, че при нулева обстановка моделите, обучени върху един набор от данни, се пренасят слабо, докато съвместното обучение дава подобрена цялостна производителност, което води до по-добро обобщаване на моделите за резолюция на кореференцията. Тази работа допринася за нов еталон за стабилна резолюция на кореференцията и множество нови най-съвременни резултати.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>যদিও কোরেফেন্সের রিসেশন ডাটাসেট ডোমেইনের স্বাধীনতা নির্ধারণ করা হয়, তবে কোরেফেন্সের সিদ্ধান্ত নির্ধারণের বেশীরভাগ ম মডেলের অফ-শেল্ফ প্রদর্শনের মূল্যের লক্ষ্য করার জন্য আমরা ৮টি কোরেফেন্সের রিলেশন ডাটাসেট সংশ্লিষ্ট করে দেই। তারপর আমরা প্রশিক্ষণের জন্য তিনটি ডাটাসেট মিশ্রণ করি; এমনকি যদিও তাদের ডোমেইন, বিশ্লেষণ নির্দেশ এবং মেটেডাটা বিভিন্ন ভিন্ন ভিন্ন, আমরা একত্রিত তথ্য মিশ্রিত একটি মডেল প্রশিক্ষণের জন্য একটি পদ্ধতি প্রস্তাব করি যেখানে আমরা খুঁজে পেয়েছি যে একটি শূন্য গুলি ব্যবস্থায়, একটি ডাটাসেট ট ট্রান্সফারেশনে মডেল প্রশিক্ষণ করা হয়েছে, যেখানে যৌথ প্রশিক্ষণের ফলে সারাটার প্রয এই কাজটি রোবস্ট কর্ফেন্সের সিদ্ধান্তের জন্য নতুন বেনম্যার্ক এবং নতুন স্টেট-অফ-শিল্পের ফলাফলের জন্য প্রদান করে।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>While coreference resolution is defined independently of dataset domain, most models for performing coreference resolution do not transfer well to unseen domains. ང་ཚོས་སྒྲིག་འཛུགས་གཙང་གཅད་གྱི་མིག་ཐང་གཙང་གཅད་ཀྱི་ཚད་ལྟར་བྱུང་བའི་སྒྲིག་ཡིག འོན་ཀྱང་ང་ཚོས་སློབ་གྲྭར་གྱི་གནད་སྡུད་ཚན་གསུམ་མཉམ་བྱེད་ཀྱི་ཡོད། even though their domain, annotation guidelines, and metadata differ, we propose a method for jointly training a single model on this heterogeneous data mixture by using data augmentation to account for annotation differences and sampling to balance the data quantities. The most important thing is that ང་ཚོས་ཀླད་པའི་སྒྲིག་འགོད་ཀྱི་རྣམ་པ་ཞིག་གིས་མཐུན་རྐྱེན་གྱིས་མིག ལས་ཀ་འདིས་བརྟན་པར་བཟོ་བྱེད་ཀྱི་ཡོད་ཚད་གསར་བ་ཞིག་གིས་མཐུན་བཟོ་བྱེད་ཀྱི་ཡོད།</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Iako je rezolucija dobrote definisana nezavisno od domena podataka, većina modela za provedbu rješenja dobrote ne prenose dobro na nedostajene domene. Konsolidiramo setu podataka o rezoluciji 8 pristojnosti koji ciljaju različite domene da procjenjuju izvanrednu funkciju modela. Onda pomiješamo tri dataseta za obuku; Iako se njihova domena, uputstva za annotaciju i metadatove razlikuju, predlažemo metodu za zajedničku obuku jednog model a o ovoj heterogeneznoj mješavini podataka koristeći povećanje podataka kako bi se računalo o različitim annotacijom i uzorak za ravnotežu količina podataka. Pronašli smo da u nulom snimanju, modeli koji su obučeni na jednom prenošenju podataka loše, dok zajednička obuka donosi poboljšanje ukupnog učinka, koji vodi do boljih generalizacije u modelima rješavanja pristojnosti. Ovaj rad doprinosi novim kriterijom za jaku rezoluciju pristojnosti i više novih rezultata umjetnosti.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mentre que la resolució de coreència es defineix independentment del domini del conjunt de dades, la majoria dels models per a fer la resolució de coreència no es transfereixen bé a dominis invisibles. Consolidem un conjunt de 8 conjunts de dades de resolució de coreferencia que s'apunten a dominis diferents per avaluar el rendiment off-shelf dels models. Ens barregem tres conjunts de dades per a formar-nos; encara que el seu domini, les directrices d'anotació i les metadades difereixin, proposem un mètode per formar conjuntament un únic model sobre aquesta mezcla heterogènia de dades utilitzant l'augmentació de dades per tenir en compte les diferències d'anotació i el recolliment de mostres per equilibrar les quantitats de dades. Trobem que en un entorn de fotografies zero, els models entrenats en un conjunt únic de dades transfereixen malament mentre que l'entrenament conjunt produeix millor rendiment global, portant a una millor generalització en els models de resolució de coreferença. Aquesta feina contribueix a un nou punt de referència per a una solució de coreferencia robusta i múltiples resultats més avançats.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Zatímco rozlišení koreference je definováno nezávisle na doméně datové sady, většina modelů pro provádění koreference se nepřenáší dobře do neviděných domén. Konsolidujeme sadu osmi datových sad s rozlišením koreferencí zaměřených na různé domény, abychom vyhodnotili standardní výkon modelů. Poté smícháme tři datové sady pro školení; I když se jejich doména, anotační směrnice a metadata liší, navrhujeme metodu společného tréninku jediného modelu na této heterogenní datové směsi pomocí rozšíření dat k zohlednění anotačních rozdílů a vzorkování pro vyvážení množství dat. Zjišťujeme, že v nastavení nulového záběru se modely trénované na jedné datové sadě špatně přenášejí, zatímco společný trénink přináší lepší celkový výkon, což vede k lepší zobecnění modelů rozlišení koreferencí. Tato práce přináší nové měřítko pro robustní rozlišení koreferencí a několik nových nejmodernějších výsledků.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mens coreferenceopløsning defineres uafhængigt af datasæt domæne, overføres de fleste modeller til udførelse af coreferenceopløsning ikke godt til usynlige domæner. Vi konsoliderer et sæt af 8 datasæt med coreferenceopløsning målrettet mod forskellige domæner for at evaluere modellernes off-the-shelf ydeevne. Vi blander derefter tre datasæt til uddannelse; Selvom deres domæne, retningslinjer for noteringer og metadata er forskellige, foreslår vi en metode til i fællesskab at træne en enkelt model om denne heterogene datablanding ved at bruge dataforøgelse til at tage højde for annotationsforskelle og prøveudtagning for at balancere datamængderne. Vi finder, at modeller, der trænes på et enkelt datasæt, i en nulskudsindstilling, overføres dårligt, mens fælles træning giver forbedret samlet ydeevne, hvilket fører til bedre generalisering af coreferenceopløsningsmodeller. Dette arbejde bidrager med et nyt benchmark for robust coreferenceopløsning og flere nye state-of-the-art resultater.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Während die Coreferenz-Auflösung unabhängig von der Dataset-Domäne definiert wird, können die meisten Modelle zur Durchführung der Coreferenz-Auflösung nicht gut auf unsichtbare Domänen übertragen werden. Wir konsolidieren einen Satz von 8-Coreferenz-Auflösungsdatensätzen für verschiedene Domänen, um die Standardleistung von Modellen zu bewerten. Anschließend mischen wir drei Datensätze für die Ausbildung; Obwohl ihre Domäne, Annotationsrichtlinien und Metadaten unterschiedlich sind, schlagen wir eine Methode vor, um gemeinsam ein einziges Modell über diese heterogene Datenmischung zu trainieren, indem wir Daten-Augmentation verwenden, um Annotationsunterschiede zu berücksichtigen und Sampling, um die Datenmengen auszugleichen. Wir stellen fest, dass Modelle, die auf einem einzelnen Datensatz trainiert wurden, in einer Null-Schuss-Einstellung schlecht übertragen, während gemeinsames Training eine verbesserte Gesamtleistung liefert, was zu einer besseren Verallgemeinerung in Coreferenz-Auflösungsmodellen führt. Diese Arbeit leistet einen neuen Benchmark für robuste Coreferenzauflösung und mehrere neue State-of-the-Art Ergebnisse.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ενώ η ανάλυση συνάφειας ορίζεται ανεξάρτητα από τον τομέα συνόλου δεδομένων, τα περισσότερα μοντέλα για την εκτέλεση της ανάλυσης συνάφειας δεν μεταφέρονται καλά σε αόρατους τομείς. Ενσωματώνουμε ένα σύνολο 8 συνόλων δεδομένων επίλυσης αλληλοδιαφορών που στοχεύουν σε διαφορετικούς τομείς για να αξιολογήσουμε την απόδοση των μοντέλων. Στη συνέχεια, αναμιγνύουμε τρία σύνολα δεδομένων για την κατάρτιση. Παρόλο που ο τομέας, οι κατευθυντήριες γραμμές σχολιασμού και τα μεταδεδομένα διαφέρουν, προτείνουμε μια μέθοδο για την κοινή εκπαίδευση ενός ενιαίου μοντέλου σε αυτό το ετερογενή μείγμα δεδομένων χρησιμοποιώντας την αύξηση δεδομένων για να υπολογίσουν τις διαφορές σχολιασμού και τη δειγματοληψία για να εξισορροπήσουν τις ποσότητες δεδομένων. Διαπιστώνουμε ότι σε μια ρύθμιση μηδενικής λήψης, μοντέλα εκπαιδευμένα σε ένα μόνο σύνολο δεδομένων μεταφέρονται ανεπαρκώς, ενώ η κοινή εκπαίδευση αποδίδει βελτιωμένη συνολική απόδοση, οδηγώντας σε καλύτερη γενίκευση στα μοντέλα ανάλυσης αλληλοδιαφορών. Η εργασία αυτή συμβάλλει σε ένα νέο σημείο αναφοράς για την εύρωστη ανάλυση της συνάφειας και πολλαπλά νέα αποτελέσματα τελευταίας τεχνολογίας.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Si bien la resolución de correferencia se define independientemente del dominio del conjunto de datos, la mayoría de los modelos para realizar la resolución de correferencias no se transfieren bien a dominios no visibles. Consolidamos un conjunto de 8 conjuntos de datos de resolución de correferencia dirigidos a diferentes dominios para evaluar el rendimiento estándar de los modelos. Luego, mezclamos tres conjuntos de datos para la capacitación; aunque su dominio, las pautas de anotación y los metadatos difieren, proponemos un método para entrenar conjuntamente un solo modelo en esta mezcla de datos heterogénea mediante el uso del aumento de datos para tener en cuenta las diferencias de anotación y el muestreo para equilibrar las cantidades de datos. Encontramos que en un entorno de tiro cero, los modelos entrenados en un solo conjunto de datos transfieren de manera deficiente, mientras que el entrenamiento conjunto produce un mejor rendimiento general, lo que lleva a una mejor generalización en los modelos de resolución de correferencia. Este trabajo aporta un nuevo punto de referencia para una resolución de correferencia sólida y múltiples resultados nuevos de última generación.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kuigi kortereferentsi resolutsioon on määratletud sõltumatult andmekogumi domeenist, ei kandu enamik kortereferentsi resolutsiooni teostamise mudeleid hästi nähtamatutesse domeenidesse. Konsolideerime 8 erinevatele valdkondadele suunatud andmekogumi, et hinnata mudelite kasutusvalmis jõudlust. Seejärel segame koolituseks kolm andmekogumit; Kuigi nende valdkond, annoteerimisjuhised ja metaandmed erinevad, pakume välja meetodi, mille abil koolitada ühiselt üks mudel selle heterogeense andmesegu kohta, kasutades andmete suurendamist annoteerimise erinevuste arvessevõtmiseks ja valimi andmekoguste tasakaalustamiseks. Leiame, et null-shot seadistuses edastavad ühe andmekogumi jaoks koolitatud mudelid halvasti, samas kui ühistreening parandab üldist jõudlust, mis toob kaasa parema üldistamise kordferentsiresolutsiooni mudelites. See töö annab uue võrdlusaluse tugevale kortereferentsi resolutsioonile ja mitmetele uutele kaasaegsetele tulemustele.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>در حالی که راه حل رضایت به طور مستقل از حوزه‌های مجموعه داده‌ها تعریف می‌شود، بیشتر مدل‌ها برای انجام راه حل رضایت رضایت به حوزه‌های غیرقابل تغییر داده نمی‌شوند. ما مجموعه‌ای از 8 تنظیم داده‌های حل‌سازی که هدف‌های دامنه‌های مختلف را برای ارزیابی عملکرد مدل‌های خارج از پناهگاه می‌دهیم. سپس سه مجموعه داده برای تمرین می‌کنیم، با وجود اینکه مدل، رهبری‌های نوشته‌ها و متداده‌ها متفاوت می‌شوند، ما یک روش برای آموزش یک مدل در این ترکیب داده‌های متفاوتی با استفاده از افزایش داده‌ها برای حساب تفاوت‌های نوشته‌ها و نمونه‌هایی برای تعادل اندازه‌های داده‌ها پیشنهاد می‌کنیم. ما فهمیدیم که در یک تنظیمات صفر، مدل‌ها در یک تنظیمات داده‌های بد آموزش یافته‌اند، در حالی که تولید آموزش مشترک اجرات عمومی را بهتر می‌کند، که باعث می‌شود به بهترین تولید عمومی در مدل‌های حل‌کننده‌ای باشد. این کار یک مقدار جدید برای حل شدیدی از ارتباط و نتیجه‌های جدیدی از هنر تولید می‌کند.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vaikka koreferenssin resoluutio määritellään datajoukon toimialueesta riippumatta, useimmat koreferenssin resoluution suorittamismallit eivät siirry hyvin näkymättömiin toimialueisiin. Yhdistämme kahdeksan eri toimialoille suunnatun koreferenssiresoluution datajoukon arvioidaksemme mallien suorituskykyä. Sitten sekoitamme kolme dataa koulutusta varten. Vaikka niiden toimialue, huomautussuunnitelmat ja metatiedot eroavat toisistaan, ehdotamme menetelmää, jolla voidaan yhdessä kouluttaa yksi malli tästä heterogeenisestä tietoseoksesta käyttämällä tietojen lisäystä merkintöjen erojen huomioimiseksi ja näytteenottoa tietomäärien tasapainottamiseksi. Havaitsemme, että nollalaukauksessa yksittäiseen aineistoon koulutetut mallit siirtyvät huonosti, kun taas yhteisharjoittelu parantaa yleistä suorituskykyä, mikä johtaa parempaan yleistymiseen koreferenssiresoluutiomalleissa. Tämä työ antaa uuden vertailukohdan vahvalle koreferenssiresoluutiolle ja useille uusille huippuluokan tuloksille.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Alors que la résolution de coréférence est définie indépendamment du domaine de l'ensemble de données, la plupart des modèles permettant d'effectuer une résolution de coréférence ne sont pas correctement transférés vers des domaines invisibles Nous consolidons un ensemble de 8 ensembles de données de résolution de coréférence ciblant différents domaines afin d'évaluer les performances standard des modèles. Nous mélangeons ensuite trois ensembles de données pour la formation ; même si leur domaine, leurs directives d'annotation et leurs métadonnées diffèrent, nous proposons une méthode pour entraîner conjointement un seul modèle sur ce mélange de données hétérogènes en utilisant l'augmentation des données pour tenir compte des différences d'annotation et l'échantillonnage pour équilibrer les quantités de données. Nous constatons que dans un environnement de tir zéro, les modèles entraînés sur un seul ensemble de données transfèrent mal tandis que l'entraînement conjoint améliore les performances globales, ce qui conduit à une meilleure généralisation dans les modèles de résolution de coréférence. Ce travail constitue une nouvelle référence en matière de résolution de coréférence robuste et de multiples nouveaux résultats de pointe.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Cé go sainmhínítear taifeach croí-chomhdhála go neamhspleách ar fhearann na dtacar sonraí, ní aistrítear go maith go dtí fearainn nach bhfeictear an chuid is mó de na samhlacha chun réiteach croí-chomhdhála a dhéanamh. Comhdhlúthaímid sraith de 8 tacar sonraí réitigh croíchomhdhála a dhíríonn ar fhearainn éagsúla chun feidhmíocht as an tseilf na samhlacha a mheas. Ansin meascaimid trí thacar sonraí le haghaidh oiliúna; cé go bhfuil difríocht idir a bhfearann, treoirlínte anótála, agus meiteashonraí, molaimid modh chun samhail aonair a oiliúint ar an meascán sonraí ilchineálach seo trí úsáid a bhaint as méadú sonraí chun cuntas a thabhairt ar dhifríochtaí anótála agus sampláil chun na cainníochtaí sonraí a chothromú. Feictear dúinn i suíomh nialas lámhaigh, go n-aistríonn múnlaí oilte ar thacar sonraí amháin go dona, agus go mbíonn feabhas ar fheidhmíocht fhoriomlán ag torthaí comhoiliúna, rud a fhágann go mbíonn ginearálú níos fearr i múnlaí réitigh croífhreagartha. Cuireann an obair seo tagarmharc nua le haghaidh réiteach láidir croí-chomhdhála agus torthaí iolracha nua den scoth.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Waka da an bayyana juyin korsference an bayyana shi ɗai'a cikin tsarin database, masu yawa masu motsi wa da za'a aikata juyin shawara cire-bone ba su shige shi da alhẽri zuwa sauyen nan da ba'a sani ba. Tuna ƙara koɓa masu daidaita danna masu motsi na cire 8, don su yi amfani da dukka daban-daban, dõmin su canza tsarin-shelf-don-motsi. Sa'an nan kuma muna haɗa matsayin data uku dõmin wa'anar; Haƙĩƙa, kuma kõ dã shirin ayuka, da shirin ayuka da metadata sun sãɓã, sai mu buɗa wata hanyoyi wa shirin su yi wa shirin haɗi a kan wannan shirin da aka haɗa mutane da data ɗin tsohatarwa, ko da amfani da ƙaramako da data dõmin ya yi amfani da zane-zane-zane-zane ko kuma misali dõmin ya daidaita nau'in data. Muna gane cewa, a cikin tsarin sifiri-sifo, misãlai wanda aka yi wa tunkuɗe a kan transfer ɗin da aka saka bayan bayani, a lokacin da shirin haɗi ya ƙara mafarin aikin jumla, yana ƙara wa mafi kyau a cikin misãlai masu motsi na kure. Wannan aikin yana ƙara wani bangon na buƙata don rabon sararin bangon nan da aka samu mutane da fassarar-state-of-art.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>למרות שהפתרון התאמה מוגדר באופן עצמאי משטח נתונים, רוב הדוגמנים לבצע פתרון התאמה לא מעבירים היטב לשטחים בלתי נראים. אנו קונצנצים קבוצה של 8 קבוצות נתונים של פיתרון קופורנציה שמתכוונים לתחומים שונים כדי להעריך ביצועים מחוץ למדף של דוגמנים. ואז אנחנו מערבבים שלושה קבוצות נתונים לאימון; למרות שהשטח שלהם, המדרגות להציאה, ומטאדאטה שונות, אנו מציעים שיטה לאימון יחד מודל אחד על תערובת הנתונים ההטרוגנית הזאת, על ידי השימוש בתעלות הנתונים כדי לחשבון על הבדלים בהציאה ומדוגמנים כדי לאזן את כמויות הנתונים. We find that in a zero-shot setting, models trained on a single dataset transfer poorly while joint training yields improved overall performance, leading to better generalization in coreference resolution models. העבודה הזו תורמת נקודת רמז חדשה לפתרון חוזק של התאמה ומספר תוצאות חדשות.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>जबकि coreference रिज़ॉल्यूशन डेटासेट डोमेन से स्वतंत्र रूप से परिभाषित किया गया है, coreference resolution करने के लिए अधिकांश मॉडल अनदेखी डोमेन में अच्छी तरह से स्थानांतरित नहीं होते हैं। हम मॉडल के ऑफ-द-शेल्फ प्रदर्शन का मूल्यांकन करने के लिए विभिन्न डोमेन को लक्षित करने वाले 8 कोरफेरेंस रिज़ॉल्यूशन डेटासेट के एक सेट को समेकित करते हैं। फिर हम प्रशिक्षण के लिए तीन डेटासेट मिश्रण करते हैं; भले ही उनके डोमेन, एनोटेशन दिशानिर्देश, और मेटाडेटा अलग-अलग होते हैं, हम डेटा वृद्धि का उपयोग करके इस विषम डेटा मिश्रण पर एक एकल मॉडल को संयुक्त रूप से प्रशिक्षित करने के लिए एक विधि का प्रस्ताव करते हैं एनोटेशन मतभेदों के लिए खाते में और डेटा मात्रा को संतुलित करने के लिए नमूनाकरण। हम पाते हैं कि एक शून्य-शॉट सेटिंग में, एकल डेटासेट हस्तांतरण पर प्रशिक्षित मॉडल खराब रूप से स्थानांतरित होते हैं जबकि संयुक्त प्रशिक्षण पैदावार ने समग्र प्रदर्शन में सुधार किया, जिससे कोरेफेरेंस रिज़ॉल्यूशन मॉडल में बेहतर सामान्यीकरण होता है। यह काम मजबूत coreference संकल्प और कई नए अत्याधुनिक परिणामों के लिए एक नया बेंचमार्क योगदान देता है।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Iako se rješenje liječnosti definira nezavisno od domena podataka, većina modela za provedbu rješenja liječnosti ne prenose dobro u nevidljive domene. Konsolidiramo niz 8 podataka za rješavanje pristojnosti koji ciljaju različite domene za procjenu izvanrednih učinka modela. Onda pomiješamo tri podatke za obuku; Iako se njihova domena, uputstva za annotaciju i metapodatke razlikuju, predlažemo metodu za zajedničku obuku jednog model a o ovoj heterogeneznoj mješavini podataka koristeći povećanje podataka kako bi se računalo o različitim annotacijom i uzorak za ravnotežu količina podataka. Pronašli smo da u nulom snimanju, modeli koji su obučeni na jednom prenošenju podataka loše, dok zajednička obuka donosi poboljšanje ukupnog učinka, dovedeći do bolje generalizacije u modele rješavanja pristojnosti. Ovaj rad doprinosi novim kriterijom za jaku rezoluciju dobrote i više novih rezultata umjetnosti.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Míg a coreferencia felbontást az adatkészlet tartományától függetlenül definiálják, a legtöbb modell a coreferencia felbontás végrehajtásához nem jut jól át láthatatlan tartományokra. A különböző tartományokat célzó 8 coreferencia felbontású adatkészletet konszolidálunk, hogy értékeljük a modellek nem használható teljesítményét. Ezután három adatkészletet keverünk össze a képzéshez; Annak ellenére, hogy tartományuk, jegyzetelési irányelvük és metaadataik eltérnek, javasoljuk egy módszert arra, hogy egyetlen modellt közösen képezzünk erről a heterogén adatkeverékről, adatbővítés alkalmazásával a jegyzetelési különbségek figyelembevételére és az adatmennyiségek kiegyensúlyozására. Úgy találjuk, hogy egy nullás beállításban az egyetlen adatkészletre képzett modellek rosszul továbbítanak, míg a közös képzés javítja az általános teljesítményt, ami a coreferencia felbontási modellek jobb általánosítását eredményezi. Ez a munka új referenciaértéket jelent a robusztus coreferencia felbontás és a több új, korszerű eredmény számára.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Մինչդեռ կորֆերենսի լուծումը սահմանվում է անկախ տվյալների համակարգի տիեզերքից, կորֆերենսի լուծումը կատարելու մոդելների մեծամասնությունը լավ չի փոխանցվում անտեսված տիեզերքին: Մենք կազմակերպում ենք 8 կորեֆերանսի լուծումների տվյալների համակարգ, որոնք նպատակացնում են տարբեր բնագավառների վրա մոդելների արտադրողականությունը գնահատելու համար: We then mix three datasets for training; չնայած դրանց բնագավառին, annoտացիայի ուղղություններին և մետատվյալներին տարբերվում են, մենք առաջարկում ենք մի մեթոդ, որպեսզի միասին վերապատրաստենք մի մոդել տվյալների խառնուրդի մասին օգտագործելով տվյալների աճը annoտացիայի տարբերությունների հաշվի առնելու և նմուշների Մենք հայտնաբերում ենք, որ զրոյական նկարների ընթացքում, մոդելները, որոնք պատրաստված են միակ տվյալների համակարգի փոխանցման վրա, վատ են, մինչդեռ միասին պատրաստման արդյունքները բարելավում են ընդհանուր արդյունքները, ինչը հանգեցնում է ավելի լավ ընդհան Այս աշխատանքը ներդրում է նոր համեմատային արտահայտություն ուժեղ կորֆերենսի լուծումների և նոր բարձրագույն արդյունքների համար:</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Sementara resolusi koreferensi didefinisikan secara independen dari domain set data, kebanyakan model untuk melakukan resolusi koreferensi tidak dipindahkan dengan baik ke domain yang tidak terlihat. Kami mengkonsolidasi set 8 set data resolusi koreferensi yang menargetkan domain yang berbeda untuk mengevaluasi prestasi off-the-shelf model. Kemudian kita campur tiga set data untuk latihan; meskipun domain mereka, arah anotasi, dan metadata berbeda, kami mengusulkan metode untuk bersama-sama melatih model tunggal pada campuran data heterogene ini dengan menggunakan peningkatan data untuk memperhitungkan perbedaan anotasi dan sampel untuk seimbang jumlah data. Kami menemukan bahwa dalam setting zero-shot, model dilatih pada satu set data transfer buruk sementara pelatihan kongsi memberikan prestasi umum yang lebih baik, yang menyebabkan generalisasi lebih baik dalam model resolusi koreferensi. Pekerjaan ini berkontribusi benchmark baru untuk resolusi koreferensi yang kuat dan beberapa hasil baru state-of-the-art.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mentre la risoluzione di coreferenza è definita indipendentemente dal dominio del set di dati, la maggior parte dei modelli per eseguire la risoluzione di coreferenza non si trasferisce bene a domini invisibili. Consolidamo un set di 8 set di dati con risoluzione di coreferenza mirati a diversi domini per valutare le prestazioni off-the-shelf dei modelli. Mescoliamo quindi tre set di dati per la formazione; Anche se il loro dominio, le linee guida di annotazione e i metadati differiscono, proponiamo un metodo per formare congiuntamente un singolo modello su questa miscela eterogenea di dati utilizzando l'aumento dei dati per tenere conto delle differenze di annotazione e il campionamento per bilanciare le quantità di dati. Troviamo che in un'impostazione zero-shot, i modelli addestrati su un singolo set di dati si trasferiscono male mentre l'allenamento congiunto produce prestazioni complessive migliorate, portando a una migliore generalizzazione dei modelli di risoluzione della coreferenza. Questo lavoro contribuisce a un nuovo punto di riferimento per una risoluzione robusta della coreferenza e molteplici nuovi risultati all'avanguardia.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>コアレファレンス分解能は、データセットドメインとは独立して定義されていますが、コアレファレンス分解能を実行するためのほとんどのモデルは、見えないドメインにうまく転送されません。異なるドメインを対象とした8つのコアレファレンス分解能データセットのセットを統合して、モデルの既製のパフォーマンスを評価します。次に、トレーニングのために3つのデータセットを混合します。ドメイン、注釈ガイドライン、およびメタデータが異なるにもかかわらず、注釈の違いを説明するためにデータ拡張を使用し、データ量のバランスを取るためにサンプリングすることによって、この異種データ混合物に関する単一のモデルを共同でトレーニングする方法を提案します。ゼロショット設定では、単一のデータセット転送でトレーニングされたモデルが不十分である一方、共同トレーニングでは全体的なパフォーマンスが向上し、コアレファレンス解像度モデルの一般化が向上することがわかります。この作業は、堅牢なコアリファレンス解決と複数の最新の結果のための新しいベンチマークに貢献します。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>When corefern Resolution is defined separately of dataset domain, all modes for effecting corefern Resolution do not transfer right to unseen domain. 2 Awak dhéwé ngewehi telu dataset kanggo tukang; iki -- [Ctrl-click to open a link in a popup window] and select a new key from the [Ctrl-click] button in the middle of the reference box. Awak dhéwé éntuk kuwi nggawe 0-0 saiki, model sing ditambah akeh nguasai perusahaan dataset sing gak bener, ngono nggawe kudu nggawe barang apik dhéwé, dadi nggawe ngubah Generalizasi model sing apik dhéwé. Ngubah iné kaé gunaké perusahaan kanggo nggawe geranggé hukum sing nggawe geranggap karo hal-hal sing paling-karang mbukak.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>თუმცა კონფერენციის რეზიციო განსაზღვრებულია მონაცემების დემომინისგან განსაზღვრებულია, ბევრი მოდელები კონფერენციის რეზიციოს გავაკეთებელად არ მუშაობს ჩვენ კონსოლიდირებული 8 წინასწორების მონაცემების კონსოლიდირება, რომლებიც განსხვავებული დიომენების მიზეზი, რომ მოდელების გამოკლებული კონსოციენტის შესახებ გადა შემდეგ ჩვენ სამი მონაცემების კონფიგურაციის შესახებ დავწყებთ; მათი დიომინი, ანოტაციის მინუსები და მეტადეტაციის განსხვავებულია, ჩვენ მინუსვთ ერთადერთი მოდელს ამ ჰეტეროგენური მონაცემების შემთხვევაზე ერთადერთი მოდულის შემწყვება, გამოყენებით მონაცემების აგგენტირება ჩვენ აღმოჩნეთ, რომ ნულ სტატის შენახვეში, მოდელები ერთი მონაცემების გადატანისაზე ცოტა, როცა ერთმანეთი განაცემების შესაძლებლობა უფრო უფრო უფრო უფრო უფრო უფრო უფრო უ ეს სამუშაო ახალი ბანქმერტის შესახებ ძალიან წარმოდგენებისთვის და მრავალი ახალი წარმოდგენების შესახებ.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Мұқсаттық айырымдылығы деректер жинақтау доменінен тәуелсіз анықталғанда, мұқсаттық айырымдылығын орындау үшін көпшілігі домендерге жақсы аударылмайды. Біз 8 сәйкестік айырмашылық деректер жиынын консолидациялау үшін басқа домендердің үлгілерін шектеу үшін басқа домендерді оқу үшін. Содан кейін бұл үш деректер жинағын біріктіреміз. Олардың домені, жаңарту бағыттаулары және метадеректері айырмаса да, біз деректердің сандарын баланстыру үшін деректерді көптеу үшін бір үлгісін біріктіру үшін, бір ретерген деректердің араласуын қолдануға арналадық. Біз нөл сүру баптауында бір деректер жиынының алмасуына оқылған үлгілері жалғастырып, біріктірілген оқыту үлгілері жалғастырып жатқан жұмыс істеу үлгілерінде жақсы жасайды. Бұл жұмыс құпты мәселелердің айырмашылығына және бірнеше жаңа күйінің нәтижесін жасайды.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>공지소해는 데이터 집합 영역에서 정의된 것이지만 공지소해를 실행하는 데 사용되는 대부분의 모델은 보이지 않는 영역으로 잘 옮겨지지 않는다.우리는 모델의 기존 성능을 평가하기 위해 서로 다른 분야에 대한 8개의 공지 소해 데이터 집합을 통합했다.그리고 우리는 세 개의 데이터 집합을 혼합하여 훈련을 진행한다.비록 그들의 역, 주석 지침과 메타데이터는 다르지만 우리는 이러한 이구 데이터 혼합에서 단일 모델을 연합하여 훈련하는 방법을 제시했다. 방법은 데이터의 확충을 이용하여 주석의 차이를 해석하고 샘플링을 통해 데이터의 양을 균형 있게 하는 것이다.우리는 영포 설정에서 단일 데이터 집합에서 훈련하는 모델의 전송 효과가 매우 나쁘고 연합 훈련은 전체적인 성능을 향상시켜 공지 소해 모델에서 더욱 좋은 범주화를 실현할 수 있음을 발견했다.이 작업은 안정된 공지 해소와 여러 개의 최신 결과에 새로운 기준을 제공했다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nors koreferencinė rezoliucija apibrėžiama nepriklausomai nuo duomenų rinkinio domeno, dauguma koreferencinės rezoliucijos atlikimo modelių netinka nematoms domenams. Sujungiame 8 duomenų rinkinius, skirtus skirtingoms sritims, kad būtų galima įvertinti modelių eksploatacinius rodiklius. Tada deriname tris mokymo duomenų rinkinius; nors jų sritis, anotacijos gairės ir metaduomenys skiriasi, mes siūlome metodą bendram vieno modelio mokymui šiame heterogeniškame duomenų mišinyje, naudojant duomenų didinimą, kad būtų atsižvelgta į anotacijos skirtumus ir mėginių ėmimą duomenų kiekiams balansuoti. We find that in a zero-shot setting, models trained on a single dataset transfer poorly while joint training yields improved overall performance, leading to better generalization in coreference resolution models. Šis darbas prisideda prie naujo patikimos koreferencijos sprendimo ir kelių naujų naujausių rezultatų lyginamojo rodiklio.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>While coreference resolution is defined independently of dataset domain, most models for performing coreference resolution do not transfer well to unseen domains. Ние консолидираме сет 8 компјутери на податоци за резолуција на кореференција кои се насочени кон различни домени за проценка на изведувањето на моделите надвор од полицата. We then mix three datasets for training; even though their domain, annotation guidelines, and metadata differ, we propose a method for jointly training a single model on this heterogeneous data mixture by using data augmentation to account for annotation differences and sampling to balance the data quantities. Најдовме дека во седиште на нула снимка, моделите обучени за едно пренесување на податоци лошо, додека заедничката обука предизвикува подобрување на целокупната резултатност, што води до подобра генерализација на моделите за резолуција на конференцијата. This work contributes a new benchmark for robust coreference resolution and multiple new state-of-the-art results.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ഡാറ്റാസറ്റ് ഡോമെനിനെ സ്വാതന്ത്രമായി കോര്‍ഫെന്‍സിന്‍റെ റിസ്റ്റല്‍ നിര്‍ണയിക്കുമ്പോള്‍, കോര്‍ഫെന്‍സ് റിസ്റ്റല്‍ പ മോഡലുകളുടെ ഓഫ് ഷെല്‍ഫ് പ്രവര്‍ത്തിപ്പിക്കാന്‍ വ്യത്യസ്തമായ ഡോമീനുകളെ ലക്ഷ്യം വരുത്തുന്ന 8 കോര്‍ഫെന്‍സ് റെല്‍സല്‍ ഡേറ പിന്നീട് പരിശീലനത്തിനായി മൂന്നു ഡാറ്റാസറ്റുകള്‍ കൂട്ടിച്ചേര്‍ക്കുന്നു; അവരുടെ ഡൊമെയിന്‍, അഭിപ്രായശ്ചിത്രത്തിന്റെ വഴികാട്ടികള്‍, മെറ്റേഡാറ്റാ വ്യത്യാസങ്ങള്‍ വ്യത്യസ്തമാണെങ്കിലും ഞങ്ങള്‍ ഒരു മാറ്റം പരിശീലിപ്പിക്കുന്നത് ഈ ഹെറോ ഒരു പൂര്‍ണ്ണമായ വെടിവെക്കുന്ന സെറ്റില്‍, ഒരു ഡാറ്റാസേറ്റ് മാറ്റങ്ങളില്‍ പരിശീലിക്കപ്പെട്ട മോഡലുകള്‍ തെറ്റായി പരിശീലനം നടത്തിയിരിക്ക ഈ ജോലി റോബോസ്റ്റ് കോര്‍ഫെന്‍സ് റിസല്‍മെന്‍സിനുള്ള പുതിയ ബെങ്ക്മാര്‍ക്ക് ചെയ്യുന്നു. പിന്നെ പുതിയ സ്ഥ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Хэдийгээр зөвхөн зөвхөн шийдвэрлэл өгөгдлийн хэлбэрээс ялгаагүй тодорхойлдог ч ихэнх загвар нь зөвхөн тодорхойлдоггүй хэлбэрээр шийдвэрлэлт хийх загварууд сайн харагдахгүй Бид 8 сайхан шийдвэрлэлийн өгөгдлийн сангуудыг удирддаг. Загваруудын ажиллагааг үнэлэхэд өөр загваруудыг зориулдаг. Дараа нь бид 3 өгөгдлийн санг сургалтын тулд цуглуулдаг. Хэдийгээр бид өгөгдлийн хэмжээсүүдийг баланслахын тулд өгөгдлийн нэмэгдүүлэлтийг ашиглаж өгөгдлийн нэмэгдүүлэлтийг ашиглаж өгөгдлийн загвар, мета өгөгдлийн хэмжээсүүдийг баланслахын тулд нэг загвар суралцах боломжтой. Нэг өгөгдлийн сангийн шинжлэх ухаан дээр сургалтын загварууд нь хамтдаа сургалтын үр дүнд бүх үйл ажиллагааг улам сайжруулж, эсрэг шийдвэрлэлтийн загваруудыг илүү ерөнхийлөгчилж чадна. Энэ ажлын хувьд хүчтэй сайхан шийдвэрлэлийн шийдвэрлэлийн шинэ багц болон олон шинэ урлагийн үр дүн үүсгэдэг.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Sementara resolusi rujukan ditakrif secara independen dari domain set data, kebanyakan model untuk melakukan resolusi rujukan tidak dipindahkan dengan baik ke domain yang tidak terlihat. Kami mengkonsolidasi set 8 set data resolusi koreferensi yang menargetkan domain yang berbeza untuk menilai prestasi off-the-shelf model. Kemudian kita campur tiga set data untuk latihan; walaupun domain, arah anotasi, dan metadata mereka berbeza, kami cadangkan satu kaedah untuk melatih bersama model tunggal dalam campuran data heterogene ini dengan menggunakan peningkatan data untuk menganggap perbezaan anotasi dan pengumpulan sampel untuk seimbang kuantiti data. Kami mendapati bahawa dalam seting tembakan sifar, model dilatih pada pemindahan set data tunggal kurang sementara pelatihan kongsi memberikan prestasi umum yang lebih baik, yang membawa kepada generalisasi lebih baik dalam model resolusi koreferensi. Kerja ini menyumbangkan tanda referensi baru untuk resolusi persamaan yang kuat dan pelbagai hasil state-of-the-art baru.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Filwaqt li r-riżoluzzjoni tal-koreferenza hija definita indipendentement mid-dominju tas-sett tad-dejta, il-biċċa l-kbira tal-mudelli għat-twettiq tar-riżoluzzjoni tal-koreferenza ma jittrasferixxux tajjeb għal dominji mhux osservati. Aħna nikkonsolidaw sett ta’ 8 settijiet ta’ dejta dwar ir-riżoluzzjoni tal-koreferenza mmirati lejn dominji differenti biex jevalwaw il-prestazzjoni off-the-shelf tal-mudelli. We then mix three datasets for training; even though their domain, annotation guidelines, and metadata differ, we propose a method for jointly training a single model on this heterogeneous data mixture by using data augmentation to account for annotation differences and sampling to balance the data quantities. Aħna nsibu li f’ambjent b’zero shot, mudelli mħarrġa fuq trasferiment ta’ sett wieħed ta’ dejta b’mod ħa żin filwaqt li taħriġ konġunt jirriżulta f’prestazzjoni globali mtejba, li twassal għal ġeneralizzazzjoni aħjar fil-mudelli ta’ riżoluzzjoni ta’ korreferenza. Dan ix-xogħol jikkontribwixxi għal punt ta’ riferiment ġdid għar-riżoluzzjoni robust a tal-koreferenza u għal diversi riżultati ġodda l-aktar avvanzati.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Hoewel de coreferentie-resolutie onafhankelijk van het datasetdomein wordt gedefinieerd, worden de meeste modellen voor het uitvoeren van coreferentie-resolutie niet goed overgebracht naar onzichtbare domeinen. We consolideren een set van 8 coreference resolutie datasets die gericht zijn op verschillende domeinen om de standaard prestaties van modellen te evalueren. Vervolgens mengen we drie datasets voor training; Hoewel hun domein, annotatierichtlijnen en metadata verschillen, stellen we een methode voor om gezamenlijk één model te trainen op dit heterogene gegevensmengsel door data augmentation te gebruiken om rekening te houden met annotatieverschillen en sampling om de datahoeveelheden in evenwicht te brengen. We merken dat in een zero-shot setting modellen die zijn getraind op een enkele dataset slecht overdragen terwijl gezamenlijke training betere algehele prestaties oplevert, wat leidt tot een betere generalisatie in coreferentie resolutiemodellen. Dit werk draagt bij aan een nieuwe benchmark voor robuuste coreferentie resolutie en meerdere nieuwe state-of-the-art resultaten.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mens koreferanse oppløysing er definert uavhengig av datasettdomene, vil dei fleste modelane for å utføra koreferanse oppløysing ikkje overføra godt til ulike domene. Vi konsoliderer eit sett av 8 datasett for oppløysing av koreferansen som mål på ulike domene for å evaluere utgåva av hjelp av modeller. Vi blander derfor tre datasett for trening. Selv om dei domene, notasjonshjelpelinjene og metadata er forskjellige, foreslår vi ein metode for å kopla opplæring av eit enkelt modell på denne heterogeneske data-mixturen ved å bruka data-augmentasjon for å rekna på forskjeller på annotasjonar og samling for å balansera datakvantitetane. Vi finn at i eit nullsatt innstilling treng modeller på ein enkelt dataset overføring slik dårlig mens samanlig opplæring fører til forbetra overalt utvikling, som fører til bedre generellisering i høgreoppløysingsmodular. Dette arbeidet bidra til ein ny benchmarke for kraftig oppløysing av koreferansen og fleire nye resultat av kunsten.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Chociaż rozdzielczość koreferencji jest definiowana niezależnie od domeny zestawu danych, większość modeli wykonywania rozdzielczości koreferencji nie jest dobrze przenoszona do niewidocznych domen. Konsolidujemy zestaw danych o rozdzielczości ośmiu współdzielczości skierowanych do różnych domen w celu oceny gotowej wydajności modeli. Następnie łączymy trzy zbiory danych dla szkoleń; Chociaż ich domena, wytyczne adnotacyjne i metadane różnią się od siebie, proponujemy metodę wspólnego szkolenia pojedynczego modelu na temat tej heterogenicznej mieszanki danych poprzez wykorzystanie rozszerzenia danych w celu uwzględnienia różnic adnotacyjnych i próbkowania w celu zrównoważenia ilości danych. Stwierdzimy, że w ustawieniach zerowych modele przeszkolone na pojedynczym zbiorze danych są źle przesyłane, podczas gdy wspólne treningi dają poprawę ogólnej wydajności, prowadząc do lepszego uogólnienia modeli rozdzielczości współdzielczej. Praca ta przyczynia się do nowego punktu odniesienia dla solidnej rozdzielczości współdziałania i wielu nowych, najnowocześniejszych wyników.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Embora a resolução de correferência seja definida independentemente do domínio do conjunto de dados, a maioria dos modelos para realizar a resolução de correferência não se transfere bem para domínios não vistos. Consolidamos um conjunto de 8 conjuntos de dados de resolução de correferência direcionados a diferentes domínios para avaliar o desempenho de modelos prontos para uso. Em seguida, misturamos três conjuntos de dados para treinamento; mesmo que seu domínio, diretrizes de anotação e metadados sejam diferentes, propomos um método para treinar em conjunto um único modelo nessa mistura de dados heterogênea usando aumento de dados para levar em conta as diferenças de anotação e amostragem para equilibrar as quantidades de dados. Descobrimos que, em uma configuração de tiro zero, os modelos treinados em um único conjunto de dados transferem mal, enquanto o treinamento conjunto produz um desempenho geral aprimorado, levando a uma melhor generalização em modelos de resolução de correferência. Este trabalho contribui com um novo benchmark para resolução de correferência robusta e vários novos resultados de última geração.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>În timp ce rezoluția coreferenței este definită independent de domeniul setului de date, majoritatea modelelor pentru efectuarea rezoluției coreferenței nu se transferă bine în domeniile nevăzute. Consolidăm un set de 8 seturi de date cu rezoluție de corefență care vizează diferite domenii pentru a evalua performanța off-the-shelf a modelelor. Apoi amestecăm trei seturi de date pentru formare; Chiar dacă domeniul lor, liniile directoare de adnotare și metadatele diferă, propunem o metodă de formare comună a unui singur model pe acest amestec de date eterogen prin utilizarea măririi datelor pentru a lua în considerare diferențele de adnotare și eșantionare pentru a echilibra cantitățile de date. Considerăm că, într-o setare zero-shot, modelele instruite pe un singur set de date transferă slab, în timp ce formarea comună oferă performanțe generale îmbunătățite, ducând la o mai bună generalizare a modelelor de rezoluție coreferență. Această lucrare contribuie la un nou punct de referință pentru rezoluția robustă a corefenței și multiple rezultate noi de ultimă generație.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Хотя разрешение керна определяется независимо от домена набора данных, большинство моделей для выполнения разрешения керна плохо переносятся в невидимые домены. Мы консолидируем набор из 8 наборов данных с разрешением керна, ориентированных на различные области, чтобы оценить стандартную производительность моделей. Затем мы смешиваем три набора данных для обучения; даже несмотря на то, что их область, руководящие принципы аннотирования и метаданные различаются, мы предлагаем метод совместного обучения одной модели на этой неоднородной смеси данных с использованием дополнения данных для учета различий аннотаций и выборки для сбалансирования объемов данных. Мы обнаружили, что в условиях нулевого выстрела модели, обученные передаче одного набора данных, плохо переносятся, в то время как совместное обучение дает улучшенную общую производительность, что приводит к лучшему обобщению в моделях разрешения ядра. Эта работа вносит вклад в новый эталон для надежного разрешения ядра и множественных новых современных результатов.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>කෝරෙෆෙරෙන්ස් රිසෝල්යුෂන් දත්ත සැට් ඩෝමේන් වලින් ස්වයංක්‍රියාවක් විශේෂ කරලා තියෙන්නේ, බොහෝ මොඩේ අපි කොන්සෝලිඩ් කරනවා කෝරෙෆෙරෙෆෙන්ස් රිසෝල්යුෂ් දත්ත සෙට්ටුවක් වෙනස් ඩෝමේන්ස්ට් ලක්ෂණය කරනවා මොඩේ ඊට පස්සේ අපි දත්ත සෙට් තුනක් ප්‍රශ්නයක් වෙනුවෙන්. ඒ වගේම ඔවුන්ගේ ඩෝමේන්, අනුවාර්ථන ප්‍රවේශය, මෙටාඩේටා වෙනස් වෙනස් වුනොත්, අපි ප්‍රවේශයක් සම්බන්ධ වෙනුවෙන් ප්‍රවේශය කරන්න ප්‍රවේශය කරනවා මේ අපිට හොයාගන්න පුළුවන් විදිහට සුන්ධ වෙඩි තියෙන්නේ, මොඩේල් එක්ක දත්ත සැට් එකක් විදිහට පරීක්ෂා කරලා තියෙන්නේ සාමාන්‍ය ප්‍රේෂ මේ වැඩේ අළුත් බෙන්ච්මාර්ක් එකක් සම්බන්ධ විශේෂණය සහ අළුත් ස්ථානය ප්‍රතිචාරයක් සම්බන්ධ වෙන</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Čeprav je ločljivost jedrske reference opredeljena neodvisno od domene nabora podatkov, se večina modelov za izvajanje ločljivosti jedrske reference ne prenaša dobro na nevidne domene. Združujemo nabor osmih naborov podatkov o ločljivosti jedrske reference, ki so usmerjeni v različna področja, da bi ocenili učinkovitost modelov na trgu. Nato združimo tri nabore podatkov za usposabljanje; čeprav se njihova domena, smernice za opombe in metapodatki razlikujejo, predlagamo metodo za skupno usposabljanje enega modela o tej heterogeni mešanici podatkov z uporabo povečanja podatkov za upoštevanje razlik v opombeh in vzorčenje za uravnoteženje količin podatkov. Ugotovili smo, da se v nastavitvi ničelnega strela modeli, usposobljeni za en sam nabor podatkov, slabo prenašajo, medtem ko skupni trening prinaša izboljšano splošno zmogljivost, kar vodi do boljše generalizacije modelov ločljivosti koreference. To delo prispeva novo merilo za robustno ločljivost jedrske reference in več novih najsodobnejših rezultatov.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Inta lagu qorayo go’aanka kaararka oo iskaa u gaar ah gudaha macluumaadka, tusaalooyin badan oo lagu sameeyo qayb-qaadashada kaarka ma bedeli karo meelaha qarsoon. Waxaannu koobnaynaa koox 8 koox oo kala duduwan oo lagu talo galay meelo kala duduwan si aan u qiimeyno sameynta dabeecada. We then mix three datasets for training; xitaa in kastoo ay ku kala duwan yihiin deegaankooda, hagitaanka caafimaadka iyo macluumaadka, waxaynu u soo jeedaynaa qaab ku tababarida wadajirka ah oo ku wada tababarida tusaale isku mid ah oo lagu isku xiriirayo macluumaadkan la isku xiriira marka lagu isticmaalo kordhiska data si loo xisaabiyo kala duwanaansho iyo tusaale ahaan si loo balansiyo qiimaha macluumaadka. Waxaynu heli nahay in qaab nuur ah lagu tababariyo samooyin lagu soo wareejiyo koobashada wadajirka ah ay kordhiso tababar-horumar oo dhan, waxaana ka horumarinaya qaababka ku saabsan qeybta. Shaqadaasu waxay leedahay habka cusub ee ku saabsan heshiiska qofka la isticmaalay iyo arimaha cusub ee farshaxanka.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>While coreference resolution is defined independently of dataset domain, most models for performing coreference resolution do not transfer well to unseen domains. Ne konsolidojmë një sërë 8 të dhënash të rezolutës së korreferencës që synojnë fusha të ndryshme për të vlerësuar performancën jashtë raftit të modeleve. We then mix three datasets for training; edhe pse domenia e tyre, udhëzimet e anotacionit dhe metatë ndryshojnë, ne propozojmë një metodë për trajnimin e përbashkët të një modeli të vetëm në këtë përzierje heterogjene të të dhënave duke përdorur rritjen e të dhënave për të llogaritur ndryshimet e anotacionit dhe marrjen e mostrave për të balancuar sasitë e të dhënave. Ne zbulojmë se në një vendosje zero-shot, modelet e trajnuar në një transferim të vetëm të të dhënave keq ndërsa trajnimi i përbashkët jep përmirësim të performancës së përgjithshme, duke çuar në gjeneralizim më të mirë në modelet e zgjidhjes së korreferencës. Ky punë kontribuon në një pikë të re për zgjidhjen e fortë të korreferencës dhe rezultate të shumta të reja të gjendjes së lartë.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Iako je rezolucija ljubaznosti definisana nezavisno od domena podataka, većina modela za izvršavanje rezolucije ljubaznosti ne prenose dobro u nevidljive domene. Konsolidiramo setu 8 podataka za rezoluciju pristojnosti koji ciljaju različite domene za procjenu izveštaja izveštaja modela. Onda pomiješamo tri seta podataka za obuku; Iako se njihova domena, uputstva za annotaciju i metadatove razlikuju, predlažemo metodu za zajedničku obuku jednog model a o ovoj heterogeneznoj mješavini podataka koristeći povećanje podataka kako bi se računalo za razlike za annotaciju i uzorke za ravnotežu količine podataka. Našli smo da u nulom snimanju, modeli koji su obučeni na jednom prenošenju podataka loše, dok zajednička obuka donosi poboljšanje ukupnog izvođenja, koji vodi do boljih generalizacije u modelima rezolucije. Ovaj rad doprinosi novim kriterijom za jaku rezoluciju pristojnosti i više novih rezultata umjetnosti.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Koreferensupplösningen definieras oberoende av datauppsättningens domän, men de flesta modeller för att utföra coreferensupplösning överförs inte bra till osedda domäner. Vi konsoliderar en uppsättning av 8 datauppsättningar med coreferencelopplösning som riktar sig till olika domäner för att utvärdera modellernas prestanda. Vi blandar sedan tre dataset för utbildning; Även om deras domän, kommenteringsriktlinjer och metadata skiljer sig åt föreslår vi en metod för att gemensamt utbilda en enda modell på denna heterogena datablandning genom att använda dataförstärkning för att ta hänsyn till kommenteringsskillnader och sampling för att balansera datakvantiteterna. Vi finner att modeller som tränats på en enda datauppsättning i en noll-shot inställning överför dåligt medan gemensam träning ger förbättrad övergripande prestanda, vilket leder till bättre generalisering av coreference resolution modeller. Detta arbete bidrar med ett nytt riktmärke för robust coreferencelopplösning och flera nya toppmoderna resultat.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Wakati suluhisho la mafanikio linaelezwa huru ya tovuti ya taarifa, mifano mingi ya kutekeleza suluhisho la msingi hazihamishi vizuri kwenda ndani isiyo fichikana. Tunaweza kuunganisha seti ya taarifa za suluhisho la kompyuta 8 zinazolenga maeneo tofauti ili kutathmini utendaji wa mifano. Kisha tunachanganya seti tatu za taarifa kwa ajili ya mafunzo; even though their domain, annotation guidelines, and metadata differ, we propose a method for jointly training a single model on this heterogeneous data mixture by using data augmentation to account for annotation differences and sampling to balance the data quantities. Tunapata kwamba katika mazingira ya picha sifuri, mifano iliyoendeshwa kwenye usafirishaji wa data moja kwa mbaya wakati mafunzo ya pamoja yanaongeza ufanisi wa jumla, na yanasababisha uzalishaji mzuri katika mifano ya ufumbuzi. Kazi hii inachangia bendera mpya kwa ajili ya suluhisho la mafanikio na matokeo mengi ya hali mpya ya sanaa.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>குறிப்பு தெளிவுத்திறன் தகவல் அமைப்பு களத்தின் தனித்தனாக வரையறுக்கப்பட்டுள்ளது, பெரும்பாலான குறிப்பு தெளிவுத்திறனை ச நாம் மாதிரிகளின் செயல்பாட்டை மதிப்பிட 8 கோரின் தெளிவுத்திறன் தகவல் அமைப்புகளை சேர்க்க வேண்டும். பின்னர் பயிற்சிக்கு மூன்று தரவுத்தளங்களை கலக்குவோம். அவர்களுடைய களம், அறிவிப்பு வழிகாட்டிகள், மற்றும் metadata மாறுபட்டாலும், நாம் ஒரு முறையை ஒன்றாக பயிற்சி செய்ய ஒரு முறையாக, இந்த அடர்ந்த தரவு கலப்பில் ஒரு மாதிரியை பயன் ஒரு சூழ்நிலையான செயல்பாட்டில், ஒரே தரவுத்தளத்தை மாற்றும் மாதிரிகளில் பயிற்சி செய்யப்பட்டுள்ளது, ஒரு சேர்ந்த பயிற்சி மாற்றும் போது சே இந்த வேலை ரோப்ட் குறிப்பு தெளிவுத்திறன் மற்றும் பல புதிய நிலையில் கலை முடிவு</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Karefleksiýa çözümlenme dataset domenyň özgürlügini tanyşdyrylýan halda, karefleksiýa çözümlenme üçin köp nusgalar daşyrmady. Biz 8 sany çekişmeler çözümlerini consolidatýarys. Farklı sahypalary nusgala etmek üçin nusgalar bar. Sonra okuw üçin üç sany veri setirini çaşyrýarys; Hatta onların domeny, duyurarlama düzenleri ve metadata farklı olmasına rağmen biz veri miktarlarını dengelemek için birlikte bir modeli eğitirmek için bir yöntemi teklif ediyoruz. 0-atjyk düzümlerinde, sanlaryň ýeke bir dataseti üýtgetmesinde ýok bir şekilde eğitilenen nusgalary tapýarys. Birleşik okuw taýýarlanmagyň hemme performansyny gowurak getirilýär we çözümler nusgalarynda has gowurak döredilýär. Bu işe güýçli ýüregiň çözümlerini we täze täze bir sanat netijesi üçin täze bir etiket täsirleýär.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>حاﻻنکہ مہربانی رخصت ڈاٹ سٹ ڈومین کے بغیر تعریف کے طور پر تعریف کی جاتی ہے، اکثر مہربانی رخصت کرنے کے لئے مہربانی رخصت کے طور پر اچھی طرح غیب کی ڈومین کو ترغیر نہیں دیتے۔ ہم نے 8 مہربانی ریزیولوسٹ ڈیٹ سٹ کو متصل کیا ہے جو مختلف ڈومین کا موقع رکھتے ہیں کہ مدل کے غیر شالف فعالیت کا ارزش کریں۔ اس کے بعد ہم تین ڈیٹ سٹ کو تمرین کے لئے ملحق کرتے ہیں۔ اگرچہ ان کے دامنی، انٹوریٹ ہدایت لینڈ، اور متڈیٹ ڈیٹ ڈیٹ لینڈ مختلف ہوتے ہیں، ہم ایک طریقہ پیش کرتے ہیں اس طریقہ پر ایک متحدہ ڈیٹ میکسٹ پر ایک مدل کی آموزش کریں، اس طریقہ سے ڈیٹ اضافہ کرنے کے لئے ڈیٹ اضافہ کرنے کے ہم دیکھتے ہیں کہ ایک صفر-شٹ سٹینٹ میں، ایک ڈیٹ سٹ ترنسیٹ پر مطالعہ کیا گیا تھا، حالانکہ joint training yields improved overall performance, leading to better generalization in coreference resolution models. یہ کام ایک نئی بنچم مارک مضبوط مضبوط مضبوط رسولی کے لئے اور بہت سی نئی موقعیت کے نتائج کے لئے اضافہ کرتا ہے.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Name Biz modellarni qiymatish uchun boshqa domenelarni qiymatlash uchun 8 ta ta ta'minlovchi ravishda foydalanuvchimiz. We then mix three datasets for training; Agar ularning domen, taʼminlovchi qoidalari, metadata va taʼlumotlar tarkibini o'zgartirib boʻlishi kerak bo'lsa, biz bu yetarli maʼlumot tarkibida bir modelni birlashtirish usulini talab qilamiz va maʼlumot qiymatlarini o'zgartirish uchun maʼlumot yordamida foydalanish mumkin. Biz shunday o'zgarishni o'rganamiz, bitta maʼlumotlar tarjimasida o'rganish modellari yomon, bir bir xil taʼminlovchisi umumiy amalni bajaradi, va bir xil o'zgarish modellarida yaxshi o'zgartiradi. Name</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mặc dù có phải giải quyết khả năng cao được xác định độc lập với miền tập tin, nhưng hầu hết các mẫu để thực hiện giải quyết hạn mức cao không chuyển tốt đến miền không nhìn thấy. Chúng tôi củng cố một bộ dữ liệu tám khả năng giải quyết nhằm mục tiêu mỗi miền khác nhau để đánh giá hiệu suất của mô- đun. Sau đó chúng ta sẽ kết hợp ba bộ dữ liệu. Dù thuộc lĩnh vực, hướng dẫn ghi chú và siêu dữ liệu có khác nhau, chúng tôi đề xuất một phương pháp để cùng nhau huấn luyện một mô hình duy nhất về hỗn hợp dữ liệu khác nhau này bằng cách sử dụng sự gia tăng dữ liệu để tính to án sự khác nhau và lấy mẫu để cân bằng lượng dữ liệu. Chúng ta thấy các một cách chưa được chảy tới một bộ thống riêng rất xấu, trong khi sự giải trị của một bộ thống của một bộ thống một bộ trí đơn giải và tống tố Công việc này đóng góp một tiêu chuẩn mới cho quyết định khả năng chiến thắng mạnh mẽ và nhiều kết quả mới nhất.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>虽共推理解析独立集域义,然大抵用于行共推理解析之法,不能善传输于未见之域。 整合其异域者 8 共推理解析数集,以质其能。 然后混合三数集。 虽领域、注南与元数不同,然吾建一法,因用数以虑异采样以平数据量,而合练于异构混合物。 吾见零次之设也,单集上之传输不善,而合之以善,因而成之于共分辨率之泛化。 其事强大者共推理分辨率与数新之最先进者给之。</span></div></div><dl><dt>Anthology ID:</dt><dd>2021.crac-1.12</dd><dt>Volume:</dt><dd><a href=/volumes/2021.crac-1/>Proceedings of the Fourth Workshop on Computational Models of Reference, Anaphora and Coreference</a></dd><dt>Month:</dt><dd>November</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Punta Cana, Dominican Republic</dd><dt>Venues:</dt><dd><a href=/venues/crac/>CRAC</a>
| <a href=/venues/emnlp/>EMNLP</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>111–120</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.crac-1.12>https://aclanthology.org/2021.crac-1.12</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/2021.crac-1.12 title="To the current version of the paper by DOI">10.18653/v1/2021.crac-1.12</a></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">toshniwal-etal-2021-generalization</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Shubham Toshniwal, Patrick Xia, Sam Wiseman, Karen Livescu, and Kevin Gimpel. 2021. <a href=https://aclanthology.org/2021.crac-1.12>On Generalization in Coreference Resolution</a>. In <i>Proceedings of the Fourth Workshop on Computational Models of Reference, Anaphora and Coreference</i>, pages 111–120, Punta Cana, Dominican Republic. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2021.crac-1.12>On Generalization in Coreference Resolution</a> (Toshniwal et al., CRAC 2021)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2021.crac-1.12.pdf>https://aclanthology.org/2021.crac-1.12.pdf</a></dd><dt>Code</dt><dd><a href=https://github.com/shtoshni92/fast-coref><i class="fab fa-github"></i>&nbsp;shtoshni92/fast-coref</a></dd><dt>Data</dt><dd><a href=https://paperswithcode.com/dataset/gap-coreference-dataset>GAP Coreference Dataset</a>,&nbsp;<a href=https://paperswithcode.com/dataset/ontogum>OntoGUM</a>,&nbsp;<a href=https://paperswithcode.com/dataset/preco>PreCo</a>,&nbsp;<a href=https://paperswithcode.com/dataset/wsc>WSC</a>,&nbsp;<a href=https://paperswithcode.com/dataset/wikicoref>WikiCoref</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2021.crac-1.12.pdf title="Open PDF of 'On Generalization in Coreference Resolution'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=On+Generalization+in+Coreference+Resolution" title="Search for 'On Generalization in Coreference Resolution' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-secondary d-flex flex-wrap justify-content-center" href="https://paperswithcode.com/paper/?acl=2021.crac-1.12" title="Code for 'On Generalization in Coreference Resolution' on Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-big" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg><span class="pl-sm-2 d-none d-sm-inline">Code</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'On Generalization in Coreference Resolution'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[On Generalization in Coreference Resolution](https://aclanthology.org/2021.crac-1.12) (Toshniwal et al., CRAC 2021)</p><ul class=mt-2><li><a href=https://aclanthology.org/2021.crac-1.12>On Generalization in Coreference Resolution</a> (Toshniwal et al., CRAC 2021)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Shubham Toshniwal, Patrick Xia, Sam Wiseman, Karen Livescu, and Kevin Gimpel. 2021. <a href=https://aclanthology.org/2021.crac-1.12>On Generalization in Coreference Resolution</a>. In <i>Proceedings of the Fourth Workshop on Computational Models of Reference, Anaphora and Coreference</i>, pages 111–120, Punta Cana, Dominican Republic. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>