<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>GILE : A Generalized Input-Label Embedding for Text ClassificationGILE: A Generalized Input-Label Embedding for Text Classification - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="GILE : A Generalized Input-Label Embedding for Text ClassificationGILE: A Generalized Input-Label Embedding for Text Classification" name=citation_title><meta content="Nikolaos Pappas" name=citation_author><meta content="James Henderson" name=citation_author><meta content="Transactions of the Association for Computational Linguistics" name=citation_journal_title><meta content="7" name=citation_volume><meta content="2019" name=citation_publication_date><meta content="https://aclanthology.org/Q19-1009.pdf" name=citation_pdf_url><meta content="139" name=citation_firstpage><meta content="155" name=citation_lastpage><meta content="10.1162/tacl_a_00259" name=citation_doi><meta property="og:title" content="GILE : A Generalized Input-Label Embedding for Text ClassificationGILE: A Generalized Input-Label Embedding for Text Classification"><meta property="og:image" content="https://aclanthology.org/thumb/Q19-1009.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/Q19-1009"><meta property="og:description" content="Nikolaos Pappas, James Henderson. Transactions of the Association for Computational Linguistics, Volume 7. 2019."><link rel=canonical href=https://aclanthology.org/Q19-1009></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/Q19-1009.pdf>GILE : A Generalized Input-Label Embedding for Text Classification<span class=acl-fixed-case>GILE</span>: A Generalized Input-Label Embedding for Text Classification</a>
<a id=af_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>Constellation name (optional)</a>
<a id=am_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>አቀማመጥ</a>
<a id=ar_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: تضمين معمم لتسمية الإدخال لتصنيف النص</a>
<a id=az_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>Constellation name (optional)</a>
<a id=bg_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>ГИЛ: Общо вграждане на входни етикети за класификация на текста</a>
<a id=bn_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: টেক্সট ক্লাসিশনের জন্য একটি সাধারণ ইনপুট- লেবেল এমবেডিং</a>
<a id=bo_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: སྤྱིར་བཏོན་ཡོད་པའི་འཇུག་སྟངས་ཁ་རྟགས་ཀྱི་ཁ་རྟགས་བཙུགས་ཡོད་པ</a>
<a id=bs_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Generalizirani ulazni etiketi za klasifikaciju teksta</a>
<a id=ca_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Una etiqueta d'entrada generalitzada per a classificar text</a>
<a id=cs_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Všeobecné vložení vstupních štítků pro klasifikaci textu</a>
<a id=da_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: En generel indlejring af input-label til tekstklassifikation</a>
<a id=de_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Eine generalisierte Eingabe-Label Einbettung für die Textklassifizierung</a>
<a id=el_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>Μια γενικευμένη ενσωμάτωση ετικετών εισόδου για ταξινόμηση κειμένου</a>
<a id=es_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: una incrustación generalizada de etiquetas de entrada para la clasificación de texto</a>
<a id=et_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Üldine sisendmärgise põimimine teksti klassifitseerimiseks</a>
<a id=fa_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>Constellation name (optional)</a>
<a id=fi_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Yleinen syöttötunnisteen upotus tekstin luokittelua varten</a>
<a id=fl_title style=display:none href=https://aclanthology.org/Q19-1009.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE : intégration généralisée d'étiquettes d'entrée pour la classification de texte</a>
<a id=ga_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Leabú Lipéad Ionchuir Ginearálaithe le haghaidh Aicmiú Téacs</a>
<a id=ha_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: KCharselect unicode block name</a>
<a id=he_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: תווית כניסה גנרליזציה למסגרת טקסט</a>
<a id=hi_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: पाठ वर्गीकरण के लिए एक सामान्यीकृत इनपुट-लेबल एम्बेडिंग</a>
<a id=hr_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Generalizirana uključena etiketa za klasifikaciju teksta</a>
<a id=hu_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Általános bemeneti címke beágyazás a szövegosztályozáshoz</a>
<a id=hy_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>ԳԻԼ. Տեքստի դասակարգման համար ընդհանուր մուտքագրման պիտակ</a>
<a id=id_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: A Generalised Input-Label Embedding for Text Classification</a>
<a id=is_title style=display:none href=https://aclanthology.org/Q19-1009.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Embedding generalizzato di etichette di input per la classificazione del testo</a>
<a id=ja_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE:テキスト分類のための一般化された入力ラベル埋め込み</a>
<a id=jv_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>string" in "context_BAR_stringNew</a>
<a id=ka_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>Constellation name (optional)</a>
<a id=kk_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Мәтін классификациясының жалпы ендіру жарлығы</a>
<a id=ko_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: 텍스트 분류에 사용되는 광범위한 입력 탭 삽입 알고리즘</a>
<a id=lt_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Įterpiamas bendras įėjimo ženklas tekstui klasifikuoti</a>
<a id=mk_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>ГИЛЕ: Генерализирано внесување на ознака за внесување за класификација на текст</a>
<a id=ml_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Text Classification</a>
<a id=mn_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Текст классификацийн нэвтрүүлэлт</a>
<a id=ms_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Penjelmaan Label-Input Umum untuk Klasifikasi Teks</a>
<a id=mt_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Tikketta Ġeneralizzata tal-Input Embedding għall-Klassifikazzjoni tat-Test</a>
<a id=nl_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Een algemene input-label insluiten voor tekstclassificatie</a>
<a id=no_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Ein generelt innskriftsmerkelapp innebygging for tekstklassifikasjon</a>
<a id=pl_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Ogólne osadzanie etykiet wejściowych dla klasyfikacji tekstu</a>
<a id=pt_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Uma incorporação generalizada de rótulo de entrada para classificação de texto</a>
<a id=ro_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: O încorporare generalizată a etichetelor de intrare pentru clasificarea textelor</a>
<a id=ru_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Встраивание обобщённой метки ввода для классификации текста</a>
<a id=si_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>Description</a>
<a id=sk_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Splošna vgradnja nalepk za klasifikacijo besedila</a>
<a id=so_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: A General Input-label Embedding for Text Classification</a>
<a id=sq_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: A Generalized Input-Label Embedding for Text Classification</a>
<a id=sr_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Generalizirani ulazni etiketi za klasifikaciju teksta</a>
<a id=sv_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: En generaliserad inbäddning av inmatningsetikett för textklassificering</a>
<a id=sw_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Label ya Kijumla ya Kuingia kwa ajili ya Makala</a>
<a id=ta_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: உரை வகைப்படுத்தலுக்கான பொதுவான உள்ளீட்டு விளக்கச்சீட்டு உட்பொதி</a>
<a id=tr_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Metin Sınıflandırmak üçin Umumy Girdi-etiket</a>
<a id=uk_title style=display:none href=https://aclanthology.org/Q19-1009.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: ایک عمومی اینپوٹ- لابل پیغام کلاسیفشن کے لئے ایمبڈ</a>
<a id=uz_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Matn klassification uchun umumiy kiritish yorliqi</a>
<a id=vi_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE: Nhúng nhãn tự đặt chung cho hạng mục văn bản</a>
<a id=zh_title style=display:none href=https://aclanthology.org/Q19-1009.pdf>GILE:广义输标嵌</a></h2><p class=lead><a href=/people/n/nikolaos-pappas/>Nikolaos Pappas</a>,
<a href=/people/j/james-henderson/>James Henderson</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Neural text classification models typically treat output labels as <a href=https://en.wikipedia.org/wiki/Categorical_variable>categorical variables</a> that lack description and semantics. This forces their parametrization to be dependent on the label set size, and, hence, they are unable to scale to large label sets and generalize to unseen ones. Existing joint input-label text models overcome these issues by exploiting label descriptions, but they are unable to capture complex label relationships, have rigid parametrization, and their gains on unseen labels happen often at the expense of weak performance on the labels seen during training. In this paper, we propose a new input-label model that generalizes over previous such models, addresses their limitations, and does not compromise performance on seen labels. The model consists of a joint nonlinear input-label embedding with controllable capacity and a joint-space-dependent classification unit that is trained with cross-entropy loss to optimize <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> performance. We evaluate models on full-resource and low- or zero-resource text classification of multilingual news and biomedical text with a large label set. Our model outperforms monolingual and multilingual models that do not leverage label semantics and previous joint input-label space models in both scenarios.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nurale teks klasifikasie modele tipies behandel uitset etikette as kategoriese veranderlikes wat ontbreek beskrywing en semantieke. Hierdie verkrag hulle parametrisasie om afhanklik te wees van die etiket stel grootte, en daarom, hulle is nie moontlik na skaal na groot etiket stel en generelliseer na onversekende. Bestaande joint invoer- label teks modelle oorwin hierdie probleme deur die uitbreiding van etiket beskrywings, maar hulle is nie moontlik om kompleks etiket verhoudings te vang, het rigte parametrisasie, en hulle verskaffings op ongesiende etikette gebeur dikwels op die koste van swak prestasie op die etikette gesien tydens onderriging. In hierdie papier, voorstel ons 'n nuwe invoer- etiket model wat generaliseer oor vorige sodanige modele, adresse hul beperkings, en nie kompromiseer prestasie op gesien etikette nie. Die model bestaan van 'n gemeenskap onlineêre invoer-etiket inbêer met kontroleer kapasiteit en 'n gemeenskap-spasie-afhanklike klasifikasie eenheid wat onderwerp word met kruis-entropie verlies om klasifikasie-prestasie te optimaliseer. Ons evalueer modele op volle- hulpbron en lae- of nul- hulpbron teks klasifikasie van multitaalske nuus en biomediese teks met 'n groot etiket stel. Ons model uitvoer monotale en multitaalse modele wat nie etiket semantiek en vorige joint invoer-etiket spasiemodele in beide scenarios verwyder nie.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>የኩነቶች የጽሑፍ መክፈቻ ሞዴሎች በተለየ የውጤት ምልክቶችን እንደ ክፍተር መለያየት እና መግለጫ የላቸውም ይህ የፋይል ምርጫዎች በlabel መጠን ላይ እንዲታመሙ ይችላል፡፡ የአሁኑ የበይነመረብ-የጽሑፍ ምሳሌዎች እነዚህ ጉዳዮችን በመጠቀም የበረራ ጽሑፎችን አሸንፋሉ፥ ነገር ግን በተጨማሪው የጽሑፍ ግንኙነት መያዝ አይችሉም፣ ጥሩ ማረፊያ አለባቸው፡፡ በዚህ ፕሮግራም፣ የቀድሞው እንደዚህ ዓይነቶች በተለየ አዲስ የinput-label model እናሳልጋለን፣ የግንኙነታቸውን አድራጊ እናደርጋለን፡፡ The model consists of a joint nonlinear input-label containing control capability and a joint-space-dependent classification unit that is trained by cross-entropy loss to optimize classification performance. በሙሉ resource እና በ0-resource ጽሑፍ ጽሑፍ ክፍተቶችን በብዙ ቋንቋዎች ዜና እና የbiomedical ጽሑፍ በታላቅ label እናስመስክራለን፡፡ ሞዴሌያችን በሁለቱ ስናናይኖች ውስጥ የደረጃ ማህበረሰብ እና የብዙ ቋንቋዎች ዓይነቶችን የሚያደርጉ ናቸው፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>عادةً ما تتعامل نماذج تصنيف النص العصبي مع تسميات المخرجات كمتغيرات فئوية تفتقر إلى الوصف والدلالات. هذا يفرض أن تكون معاملاتهم معتمدة على حجم مجموعة الملصقات ، وبالتالي ، فهم غير قادرين على التوسع في مجموعات الملصقات الكبيرة والتعميم على المجموعات غير المرئية. تتغلب نماذج نصوص تسمية الإدخال المشتركة الحالية على هذه المشكلات من خلال استغلال أوصاف الملصقات ، لكنها غير قادرة على التقاط علاقات تسمية معقدة ، ولها معايير صارمة ، ومكاسبها على الملصقات غير المرئية تحدث غالبًا على حساب الأداء الضعيف على الملصقات التي شوهدت أثناء التدريب. في هذه الورقة ، نقترح نموذجًا جديدًا لتسمية الإدخال يعمم على النماذج السابقة ويعالج حدودها ولا يضر بالأداء على الملصقات المرئية. يتكون النموذج من تضمين ملصق إدخال غير خطي مشترك بسعة يمكن التحكم فيها ووحدة تصنيف مشتركة تعتمد على الفضاء يتم تدريبها مع فقدان الانتروبيا لتحسين أداء التصنيف. نقوم بتقييم النماذج على تصنيف نصي كامل الموارد ومنخفض أو معدوم الموارد للأخبار متعددة اللغات والنص الطبي الحيوي مع مجموعة ملصقات كبيرة. يتفوق نموذجنا على النماذج أحادية اللغة ومتعددة اللغات التي لا تستفيد من دلالات الملصقات ونماذج مساحة تسمية الإدخال السابقة المشتركة في كلا السيناريوهين.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nöral metin klasifikasiya modelləri genellikle çıxış etiketlərini tanımlamaq və semantik olmayan kategorikalı dəyişikliklər kimi təhrif edirlər. Bu onların parametrizaqlarını etiket təyin edilmiş böyüklüyündən bağlı olmağa məcbur edir. Buna görə də onlar böyük etiket qurularına dəyişə bilməzlər və görmədikləri etiket qurularına genel dəyişə bilməzlər. Müxtəlif girdi etiketli mətn modelleri etiketli tərzlərini istifadə edərək bu məsələləri üstün edir, amma onlar kompleks etiketli ilişkiləri yakala bilməzlər, qüvvətli parametrizaqları var, və görünməyən etiketlərdə onların qazanışları çox dəfə təhsil etdikdə görünən etiketlərdə zəif performans hesabında olur. Bu kağızda, əvvəlki modellərdə generalizasyon edən yeni girdi etiketli modeli təklif edirik, onların sınırlarını təklif edir və görünülmüş etiketlərdə performansını təklif etməz. Model kontrol edilebilir qabiliyyəti ilə birləşdirilmiş çizgi girdi etiketi və birləşdirilmiş kosmos-bağlı klasifikasiya birimi ilə birləşdirilmiş çoxlu entropi kaybı ilə təhsil edilmiş klasifikasiya performansını optimizləmək üçün təhsil edilən bir nöqtədir. Biz çoxlu dil xəbərlərin və biomedicin mətnlərin tamamlanması və düşük-ya-sıfır-ressurs mətnlərin klasifikasiyasını çəkirik. Bizim modellərimiz hər iki scenarioda etiketli semantik və əvvəlki istifadə etiketi kosmosu modellərini istifadə etməyən monodil və çoxlu dil modellərini göstərir.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Моделите за класификация на неврални текстове обикновено третират изходните етикети като категорични променливи, които нямат описание и семантика. Това принуждава параметризацията им да зависи от размера на набора етикети и следователно те не могат да мащабират до големи набори етикети и да обобщят до невидими такива. Съществуващите съвместни текстови модели за въвеждане и етикет преодоляват тези проблеми чрез използване на описания на етикети, но те не са в състояние да уловят сложни връзки на етикети, имат строга параметризация и печалбите им от невидими етикети често се случват за сметка на слабото представяне на етикетите, наблюдавани по време на обучението. В тази статия предлагаме нов модел на входно-етикет, който обобщава предишните модели, адресира техните ограничения и не компрометира производителността на видимите етикети. Моделът се състои от съединено нелинейно вграждане на входен етикет с контролируем капацитет и съединено-пространствено-зависима класификационна единица, която е обучена с загуба на кръстосана ентропия за оптимизиране на класификационната ефективност. Оценяваме модели за класификация на текста с пълен ресурс и нисък ресурс или нулев ресурс на многоезични новини и биомедицински текстове с голям набор етикети. Нашият модел превъзхожда едноезичните и многоезичните модели, които не използват семантиката на етикетите и предишните съвместни модели на входно-етикетно пространство и в двата сценария.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>নিউরেল টেক্সট ক্লাস্ফিকেশন মডেল সাধারণত আউটপুট লেবেল বিভাগের বিভাগ হিসেবে ব্যবহার করুন, যা বর্ণনা এবং সেমেন এটি তাদের প্যারামিটারিজেশন লেবেল সেটের আকারের উপর নির্ভর করতে বাধ্য করে, আর এর ফলে তারা বিশাল ল লেবেলেট সেটের দিকে আকারে যাত্রা করতে বিদ্যমান যুক্ত ইনপুট-লেবেলের টেক্সট মডেল লেবেল বিবরণ ব্যবহারের মাধ্যমে এই বিষয়গুলোকে বিজয়ী করেছে, কিন্তু তারা কমপ্লেক্স লেবেলেটের সম্পর্ক গ্রহণ করতে পারে না, তাদের প এই কাগজটিতে আমরা একটি নতুন ইনপুট-লেবেল মডেল প্রস্তাব করি যা পূর্বের এই মডেলের উপর জেনারেল করে, তাদের সীমাবদ্ধতা ঠিকানা করে এবং তাদের লেব মোডেলের মধ্যে একটি যৌথ অলাইনিয়ার ইনপুট- লেবেলের মধ্যে রয়েছে যা নিয়ন্ত্রণের ক্ষমতা এবং একটি যৌথ-স্পেস-নির্ভরিত ক্লাস্ফিকেশন ইউনিট যা ক্লাসাফিকেশনের আমরা পুরোপুরি সম্পদ এবং নিম্নলিখিত কিংবা শুধুমাত্র বিশাল লেবেলেটের সংবাদ এবং বায়োমেডিকেল টেক্সটের মূল্যায়ন করি। আমাদের মডেল মোনোলিভাল এবং বহুভাষায় মডেল প্রদর্শন করে যারা দুটো সিনেম্যান্টিক এবং পূর্ববর্তী যোগাযোগ ইনপুট-লেবেল স্থানের</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Neural text classification models typically treat output labels as categorical variables that lack description and semantics. This forces their parametrization to be dependent on the label set size, and, hence, they are unable to scale to large label sets and generalize to unseen ones. Existing joint input-label text models overcome these issues by exploiting label descriptions, but they are unable to capture complex label relationships, have rigid parametrization, and their gains on unseen labels happen often at the expense of weak performance on the labels seen during training. In this paper, we propose a new input-label model that generalizes over previous such models, addresses their limitations, and does not compromise performance on seen labels. The model consists of a joint nonlinear input-label embedding with controllable capacity and a joint-space-dependent classification unit that is trained with cross-entropy loss to optimize classification performance. ང་ཚོས་རྣམ་པ་མང་པོ་དང་མཐོ་རྣམ་པ་མང་པོ་ཞིག་ཡོད་པའི་མིག་གཟུགས་རིས་མང་པོ་ཞིག་དང་། རྣམ་པ་མིག་གཟུགས་རིས Our model outperforms monolingual and multilingual models that do not leverage label semantics and previous joint input-label space models in both scenarios.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Modeli klasifikacije neuronskog teksta obično tretiraju etikete izlaza kao kategorijske varijante koje nedostaju opis i semantike. To primorava njihovu parametrizaciju da zavise od veličine postavljene etikete, i zato oni ne mogu skalirati na velike sete etikete i generalizirati na nevidljive. Postoje zajednički modeli teksta oznake za ulazak prevladaju te probleme iskorištavanjem opisa oznake, ali nisu u mogućnosti da uhvate kompleksne odnose oznake, imaju krute parametrizacije, a njihovi dobiti na nevidljivim etiketama se često dešavaju na troškovi slabe učinke na etiketama viđenim tijekom obuke. U ovom papiru predlažemo novi model ulaznog etiketa koji generalizuje preko prethodnih takvih model a, adresuje njihove ograničenja i ne kompromisuje učinkovitost na viđenim etiketama. Model se sastoji od zajedničkog nelinearnog ulaznog etiketa ugrađenog sa kontrolnom kapacitetom i zajedničkom klasifikacijskom jedinicom ovisnom o svemiru koja je obučena s gubitkom prekretropije kako bi optimizirala klasifikaciju. Procjenjujemo modele o klasifikaciji teksta punog resursa i niskog ili nulog resursa multijezičkih vijesti i biomedicinskog teksta sa velikim namještajem etiketa. Naš model iznosi monojezičke i multijezičke modele koji ne utiču na etikete semantike i prethodne zajedničke svemirske modele za ulazak u obje scenarije.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Neural text classification models typically treat output labels as categorical variables that lack description and semantics. Això obliga la seva parametrització a dependre de la mida del conjunt d'etiquetes, i, per tant, no són capaços d'escalar a grans conjunts d'etiquetes i generalitzar-se a aquells invisibles. Els models de text conjunts d'etiquetes d'entrada superen aquests problemes explotant descripcions d'etiquetes, però no són capaços de capturar relacions complexes d'etiquetes, tenen parametrització rígida, i els seus guanys en etiquetes invisibles aconsegueixen sovint a càrrega del frac rendiment de les etiquetes vistes durant l'entrenament. En aquest paper, proposem un nou model d'etiqueta d'entrada que s'generalitza sobre els models anteriors, aborda les seves limitacions i no compromet el rendiment de les etiquetes vistes. El model consisteix en una etiqueta d'entrada no linear conjunta incorporada amb capacitat controlable i una unitat de classificació dependent de l'espai conjunt que està entrenada amb pèrdua de transentropia per optimitzar el rendiment de la classificació. Evaluam models de classificació de text amb recursos complets i amb recursos baixos o zero de notícies multilingües i text biomèdic amb un gran conjunt d'etiquetes. El nostre model supera els models monolingües i multilingües que no utilitzen l'etiqueta semàntica i els models espacials anteriors d'entrada conjunta en ambdós escenaris.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Neurální klasifikační modely textu obvykle považují výstupní štítky za kategorické proměnné, které postrádají popis a sémantiku. To nutí jejich parametrizaci záviset na velikosti sady štítků, a proto nejsou schopny škálovat na velké sady štítků a zobecnit na neviditelné. Stávající společné textové modely vstupu-štítku tyto problémy překonávají využitím popisů štítků, ale nejsou schopny zachytit složité vztahy štítků, mají pevnou parametrizaci a jejich zisky u neviditelných štítků docházejí často na úkor slabého výkonu štítků viděných během školení. V tomto článku navrhujeme nový model vstupních štítků, který generalizuje předchozí takové modely, řeší jejich omezení a neohrožuje výkon viděných štítků. Model se skládá ze společného nelineárního vložení vstupních štítků s kontrolovatelnou kapacitou a klasifikační jednotky závislé na spojovém prostoru, která je trénována se ztrátou křížové entropie pro optimalizaci klasifikačního výkonu. Hodnotíme modely pro klasifikaci vícejazyčných zpráv a biomedicínského textu s velkou sadou etiket. Náš model překonává monojazyčné a vícejazyčné modely, které nevyužívají sémantiku štítků a předchozí společné modely vstupu-štítků prostoru v obou scénářích.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Neurale tekstklassifikationsmodeller behandler typisk outputetiketter som kategoriske variabler, der mangler beskrivelse og semantik. Dette tvinger deres parametrisering til at være afhængig af etiketsættets størrelse, og derfor er de ikke i stand til at skalere til store etiketsæt og generalisere til usynlige. Eksisterende fælles input-label tekstmodeller løser disse problemer ved at udnytte etiketbeskrivelser, men de er ikke i stand til at indfange komplekse etiketrelationer, har stiv parametrisering, og deres gevinster på usynlige etiketter sker ofte på bekostning af svag ydeevne på etiketterne set under træning. I denne artikel foreslår vi en ny input-label model, der generaliserer over tidligere sådanne modeller, adresserer deres begrænsninger og ikke kompromitterer ydeevnen på set etiketter. Modellen består af en fælles ikke-lineær input-label indlejring med kontrollerbar kapacitet og en fælles-rum-afhængig klassificeringsenhed, der er trænet med cross-entropi tab for at optimere klassificeringens ydeevne. Vi evaluerer modeller for fuld ressource og lav- eller nul-ressource tekst klassificering af flersprogede nyheder og biomedicinsk tekst med et stort labelsæt. Vores model overgår ensprogede og flersprogede modeller, der ikke udnytter etiketsemantik og tidligere fælles input-label rummodeller i begge scenarier.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Neurale Textklassifizierungsmodelle behandeln Ausgabeetiketten typischerweise als kategoriale Variablen, denen es an Beschreibung und Semantik mangelt. Dies zwingt ihre Parametrisierung dazu, von der Größe der Beschriftungssätze abhängig zu sein, weshalb sie nicht in der Lage sind, auf große Beschriftungssätze zu skalieren und auf unsichtbare zu verallgemeinern. Bestehende gemeinsame Eingabe-Label-Textmodelle überwinden diese Probleme, indem sie Beschreibungen von Etiketten ausnutzen, aber sie sind nicht in der Lage, komplexe Beschriftungsbeziehungen zu erfassen, haben eine starre Parametrisierung, und ihre Gewinne bei unsichtbaren Etiketten gehen oft zu Lasten der schwachen Leistung der Etiketten, die während des Trainings beobachtet werden. In diesem Beitrag schlagen wir ein neues Input-Label-Modell vor, das sich gegenüber früheren Modellen verallgemeinert, deren Einschränkungen adressiert und die Leistung auf gesehenen Etiketten nicht beeinträchtigt. Das Modell besteht aus einer gemeinsamen nichtlinearen Input-Label-Einbettung mit steuerbarer Kapazität und einer joint-space-abhängigen Klassifizierungseinheit, die mit Cross-Entropieverlusten trainiert wird, um die Klassifizierungsleistung zu optimieren. Wir evaluieren Modelle zur vollständigen und ressourcenarmen Textklassifizierung von mehrsprachigen Nachrichten und biomedizinischen Texten mit einem großen Etikettenset. Unser Modell übertrifft in beiden Szenarien ein- und mehrsprachige Modelle, die keine Label-Semantik und frühere gemeinsame Eingabe-Label-Raummodelle nutzen.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Τα νεανικά μοντέλα ταξινόμησης κειμένου συνήθως αντιμετωπίζουν τις ετικέτες εξόδου ως κατηγοριακές μεταβλητές που στερούνται περιγραφής και σημασιολογίας. Αυτό αναγκάζει την παραμετροποίηση τους να εξαρτάται από το μέγεθος του συνόλου ετικετών και, ως εκ τούτου, δεν είναι σε θέση να κλιμακωθούν σε μεγάλα σύνολα ετικετών και να γενικεύσουν σε αόρατα. Τα υπάρχοντα κοινά μοντέλα κειμένου εισαγωγής-ετικέτας ξεπερνούν αυτά τα ζητήματα αξιοποιώντας περιγραφές ετικετών, αλλά δεν είναι σε θέση να συλλάβουν πολύπλοκες σχέσεις ετικετών, έχουν άκαμπτη παραμετροποίηση και τα κέρδη τους σε αόρατες ετικέτες συμβαίνουν συχνά σε βάρος της αδύναμης απόδοσης στις ετικέτες που παρατηρούνται κατά τη διάρκεια της εκπαίδευσης. Σε αυτή την εργασία, προτείνουμε ένα νέο μοντέλο εισαγωγής-ετικέτας που γενικεύει σε σχέση με προηγούμενα τέτοια μοντέλα, αντιμετωπίζει τους περιορισμούς τους και δεν θέτει σε κίνδυνο την απόδοση στις ορατές ετικέτες. Το μοντέλο αποτελείται από μια κοινή μη γραμμική ενσωμάτωση ετικετών εισόδου-εισόδου με ελεγχόμενη ικανότητα και μια μονάδα ταξινόμησης που εξαρτάται από το κοινό-χώρο που εκπαιδεύεται με απώλεια διασταυρούμενης εντροπίας για τη βελτιστοποίηση της απόδοσης ταξινόμησης. Αξιολογούμε μοντέλα για την πλήρη και χαμηλή ή μηδενική ταξινόμηση κειμένων πολυγλωσσικών ειδήσεων και βιοϊατρικού κειμένου με μεγάλο σύνολο ετικετών. Το μοντέλο μας ξεπερνά τα μονογλωσσικά και πολυγλωσσικά μοντέλα που δεν αξιοποιούν τη σημασιολογία ετικετών και προηγούμενα κοινά μοντέλα χώρου εισόδου-ετικετών και στα δύο σενάρια.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Los modelos de clasificación de texto neuronal suelen tratar las etiquetas de salida como variables categóricas que carecen de descripción y semántica. Esto obliga a que su parametrización dependa del tamaño del conjunto de etiquetas y, por lo tanto, no pueden escalar a conjuntos de etiquetas grandes y generalizar a juegos invisibles. Los modelos conjuntos de texto de etiquetas de entrada existentes solucionan estos problemas al explotar las descripciones de etiquetas, pero no pueden capturar relaciones de etiquetas complejas, tienen una parametrización rígida y sus ganancias en etiquetas invisibles a menudo se producen a expensas del bajo rendimiento de las etiquetas observadas durante la capacitación. En este artículo, proponemos un nuevo modelo de etiquetas de entrada que generaliza sobre dichos modelos anteriores, aborda sus limitaciones y no compromete el rendimiento de las etiquetas vistas. El modelo consiste en una incrustación de etiquetas de entrada no lineal conjunta con capacidad controlable y una unidad de clasificación dependiente del espacio conjunto que está entrenada con pérdida de entropía cruzada para optimizar el rendimiento de la clasificación. Evaluamos modelos de clasificación de textos de recursos completos y de recursos bajos o nulos de noticias multilingües y textos biomédicos con un juego de etiquetas grande. Nuestro modelo supera a los modelos monolingües y multilingües que no aprovechan la semántica de etiquetas ni los modelos anteriores de espacio de etiquetas de entrada conjunta en ambos escenarios.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Närviteksti klassifitseerimise mudelid käsitlevad väljundsilte tavaliselt kategoorialiste muutujatena, millel puudub kirjeldus ja semantika. See sunnib nende parametriseerimist sõltuma sildikomplekti suurusest ja seetõttu ei saa nad suurte sildikomplektideni skaleerida ja üldistada nähtamatuteks. Olemasolevad ühised sisend-sildi tekstimudelid lahendavad need probleemid sildi kirjelduste kasutamisega, kuid nad ei suuda jäädvustada keerulisi sildi seoseid, neil on jäik parametreerimine ja nende kasu nähtamatute sildide kasutamisel toimub sageli koolituse käigus nähtud sildide nõrga jõudluse arvelt. Käesolevas töös pakume välja uue sisendmärgise mudeli, mis üldistab varasemaid selliseid mudeleid, käsitleb nende piiranguid ja ei ohusta nähtud märgiste jõudlust. Mudel koosneb juhitava võimsusega liigesest mittelineaarsest sisendmärgist ja liigesest-ruumist sõltuvast klassifikatsiooniüksusest, mis on koolitatud ristentroopiakao optimeerimiseks klassifitseerimisjõudluse optimeerimiseks. Hindame mitmekeelsete uudiste ja biomeditsiiniliste tekstide täisressurssiga ja vähese või nulliressurssiga klassifitseerimise mudeleid suure märgistuskomplektiga. Meie mudel ületab ühe- ja mitmekeelseid mudeleid, mis ei kasuta sildi semantikat ega varasemaid ühiseid sisend-sildi ruumimudeleid mõlemas stsenaariumis.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>مدل‌های ویژه‌بندی متن عصبی معمولاً برچسب‌های خروجی را به عنوان متغیر‌های گوناگونی درمان می‌کنند که توصیف و سیمانتیک کم دارند. این باعث می‌شود پارامتریزی آنها به اندازه تنظیم برچسب بستگی داشته باشند، و بنابراین آنها نمی‌توانند به مجموعه‌های بزرگ برچسب مقیاس کنند و به مجموعه‌های غیرقابل مشاهده گردند. مدل‌های متن‌نوشته‌ی ورودی مشترک با استفاده از توضیح‌های نقاشی، این مشکلات را با استفاده از توضیح‌های نقاشی تغییر می‌دهند، ولی آنها نمی‌توانند رابطه‌های نقاشی پیچیده را بگیرند، پارامتریزی سخت داشته باشند، و پیروزی‌هایشان بر نقاشی‌های نابینا ا در این کاغذ، ما یک مدل جدیدی از نقاشی ورودی را پیشنهاد می کنیم که در این مدل های قبلی ژنرالیز می کند، به محدودیت هایشان نشان می دهد، و عملکرد روی نقاشی دیده را تغییر نمی دهد. Model consists of a joint non-linear input-label embedded with controllable capacity and a joint-space-dependent classification unit that is trained with cross-entropy loss to optimize classification performance. ما مدل‌ها را در کلی منابع کامل و تنظیم متن کم یا صفر منابع از خبرهای زیادی زبان و متن بیوپزشکی با یک مجموعه برچسب بزرگ ارزیابی می‌کنیم. مدل ما مدل های یک زبان و چندین زبان را اجرا می کند که مدل های فضایی که در هر دو سناریو نقاشی از نقاشی و نقاشی که با نقاشی از نقاشی و نقاشی که با نقاشی از نقاشی به نقاشی وارد می شود در هر دو سن</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Neurotekstiluokitusmallit käsittelevät tulosmerkintöjä tyypillisesti kategorisina muuttujina, joilla ei ole kuvausta ja semantiikkaa. Tämä pakottaa niiden parametrisoinnin riippumaan etikettijoukon koosta, joten ne eivät pysty skaalaamaan suuriin etikettiryhmiin ja yleistymään näkymättömiin. Nykyiset yhteiset syöttö- ja tarratekstimallit voittavat nämä ongelmat hyödyntämällä tarrakuvauksia, mutta ne eivät kykene kuvaamaan monimutkaisia tarrasuhteita, niiden parametrisointi on jäykkä, ja niiden voitot näkymättömistä etiketeistä tapahtuvat usein koulutuksen aikana havaittujen etikettien heikon suorituskyvyn kustannuksella. Tässä työssä ehdotamme uutta input-label -mallia, joka yleistyy aikaisempiin malleihin verrattuna, käsittelee niiden rajoituksia eikä vaaranna näytettyjen labelien suorituskykyä. Malli koostuu yhdistetystä epälineaarisesta syöttöetiketistä, jolla on hallittavissa oleva kapasiteetti, sekä liitos-avaruudesta riippuvasta luokitusyksiköstä, joka on koulutettu ristientropiahäviöllä luokittelun optimoimiseksi. Arvioimme monikielisten uutisten ja biolääketieteellisten tekstien täysressurssien ja vähäresurssisten tekstien luokittelumalleja suurella etikettisarjalla. Mallimme toimii paremmin kuin yksikieliset ja monikieliset mallit, jotka eivät hyödynnä etiketin semantiikkaa ja aiempia yhteisiä syöte-etiketti-tilamalleja molemmissa skenaarioissa.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Les modèles de classification de texte neuronal traitent généralement les étiquettes de sortie comme des variables catégorielles dépourvues de description et de sémantique. Cela force leur paramétrisation à dépendre de la taille de l'ensemble d'étiquettes et, par conséquent, ils ne peuvent pas être mis à l'échelle à de grands ensembles d'étiquettes et généralisés à des ensembles d'étiquettes invisibles. Les modèles de texte d'entrée et d'étiquette conjoints existants surmontent ces problèmes en exploitant les descriptions d'étiquettes, mais ils sont incapables de saisir des relations d'étiquette complexes, ont une paramétrisation rigide et leurs gains sur les étiquettes invisibles se produisent souvent au détriment de faibles performances sur les étiquettes vues pendant la formation. Dans cet article, nous proposons un nouveau modèle d'étiquette d'entrée qui généralise par rapport aux modèles précédents, aborde leurs limites et ne compromet pas les performances sur les étiquettes vues. Le modèle se compose d'une intégration d'étiquette d'entrée non linéaire conjointe avec une capacité contrôlable et d'une unité de classification dépendante de l'espace articulaire qui est entraînée avec une perte d'entropie croisée afin d'optimiser les performances de classification. Nous évaluons des modèles sur la classification textuelle des ressources complètes et des ressources faibles ou nulles des actualités multilingues et des textes biomédicaux avec un grand ensemble d'étiquettes. Notre modèle surpasse les modèles monolingues et multilingues qui ne tirent pas parti de la sémantique des étiquettes et des modèles d'espace d'entrée et d'étiquette conjoints précédents dans les deux scénarios.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>De ghnáth déileálann samhlacha aicmithe téacs néaracha le lipéid aschuir mar athróga catagóiriúla nach bhfuil cur síos orthu ná an tséimeantaic. Cuireann sé seo iallach ar a bparaiméadracht a bheith ag brath ar mhéid na lipéad, agus, mar sin, níl siad in ann scála a dhéanamh go tacair lipéid mhóra agus ginearálú chuig na cinn nach bhfacthas riamh cheana. Sáraítear na saincheisteanna sin trí thuairiscí lipéid a shaothrú i samhlacha comhpháirteacha téacs lipéid ionchuir, ach ní féidir leo gaolmhaireachtaí casta lipéad a ghabháil, tá paraiméadracht docht acu, agus tarlaíonn a ngnóthachan ar lipéid nach bhfacthas riamh cheana ar chostas lagfheidhmíochta ar na lipéid a fheictear le linn na hoiliúna. Sa pháipéar seo, molaimid múnla lipéad ionchuir nua a dhéanann ginearálú ar shamhlacha dá leithéid roimhe seo, a thugann aghaidh ar a dteorainneacha, agus nach gcuireann isteach ar fheidhmíocht ar lipéid a fheictear. Is éard atá sa tsamhail comhlipéad neamhlíneach ionchuir a neadaíonn cumas inrialaithe agus aonad aicmithe comhspás-spleách atá oilte le caillteanas tras-eantrópachta chun an fheidhmíocht aicmithe a bharrfheabhsú. Déanaimid meastóireacht ar shamhlacha ar aicmiú téacs lán-acmhainne agus acmhainní íseal nó nialasach ar nuacht ilteangach agus ar théacs bithleighis le tacar mór lipéad. Feidhmíonn ár múnla níos fearr ná samhlacha aonteangacha agus ilteangacha nach n-eascraíonn séimeanaic lipéad agus samhlacha spáis comhlipéid ionchuir roimhe seo sa dá chás.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>@ label: listbox Wannan na ƙara parameteriyarsu don a ƙayyade girmar label, kuma bã zã su iya iya fito zuwa matsayin ayuka babba, kuma su samu gaɓõya masu ɓõya. @ label: listbox In this paper, we propose a new input-label model that generalizes over previous such models, addresses their limitations, and does not compromise performance on seen labels. @ info: whatsthis Tuna ƙaddara misãlai kan fasalin matsayin cikakken resource da kasa- ko-nufi, wa'anar lãbãri na mulki-mulki da littãfin da aka daidaita wani label mai girma. MisalinMu na samar da misãlai masu motsi na monoli da mulki-lingui, waɗanda bã su samar wa label semantiki kuma misãlai na farko da ke cikin cikin tsari biyu.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>דוגמנים מסווג טקסט נוירוני בדרך כלל מתייחסים לתוויות יציאה כמשתנים קטגוריים שאין להם תיאור וסמנטיקה. זה מכריח את הפרמטריזציה שלהם להיות תלוי בגודל התווית, ולכן, הם לא מסוגלים להגדיל לתוויות גדולות ולהגדיל לתוויות בלתי נראות. מודלים טקסטים משותפים קיומים של תווית כניסה מתגברים על הנושאים האלה על ידי ניצל תיאורים של תוויות, אבל הם לא יכולים לתפוס מערכות יחסים מסובכות של תוויות, יש פרמטריזציה קשה, והרווחות שלהם על תוויות בלתי נראות קורות לעתים קרובות על חשבון ביצועים חלשים על תוויות שנראות בעיתון הזה, אנו מציעים מודל חדש של תווית כניסה שמתפתח על מודלים כאלה קודמים, מתייחס למגבלותיהם, ולא מפחיד ביצועים על תוויות ראויות. המודל כולל תווית כניסה לא לינרית משותפת עם יכולת שליטה ויחידת קליפורניה משותפת-תלויה בחלל שאומנת עם אובדן אנטרופיה צלב כדי לאופטיזם ביצועי קליפורניה. אנו מעריכים מודלים על מסווג טקסט מלא משאבים נמוכים או אפס של חדשות רבות שפות וטקסט ביומדיקלי עם תווית גדולה. המודל שלנו מוביל מודלים מונושפות ומרבות שפות שלא משתמשים בתווית סמנטיקה ומודלים חלליים משותפים קודמים בשני התקרים.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>तंत्रिका पाठ वर्गीकरण मॉडल आमतौर पर आउटपुट लेबल को स्पष्ट चर के रूप में मानते हैं जिनमें वर्णन और शब्दार्थ की कमी होती है। यह उनके पैरामेट्रिज़ेशन को लेबल सेट आकार पर निर्भर होने के लिए मजबूर करता है, और इसलिए, वे बड़े लेबल सेट को स्केल करने और अनदेखी लोगों को सामान्यीकृत करने में असमर्थ हैं। मौजूदा संयुक्त इनपुट-लेबल टेक्स्ट मॉडल लेबल विवरणों का शोषण करके इन मुद्दों को दूर करते हैं, लेकिन वे जटिल लेबल संबंधों को पकड़ने में असमर्थ हैं, कठोर पैरामेट्राइजेशन करते हैं, और अनदेखी लेबल पर उनके लाभ अक्सर प्रशिक्षण के दौरान देखे गए लेबल पर कमजोर प्रदर्शन की कीमत पर होते हैं। इस पेपर में, हम एक नए इनपुट-लेबल मॉडल का प्रस्ताव करते हैं जो पिछले ऐसे मॉडलों पर सामान्यीकरण करता है, उनकी सीमाओं को संबोधित करता है, और देखे गए लेबल पर प्रदर्शन से समझौता नहीं करता है। मॉडल में नियंत्रणीय क्षमता के साथ एक संयुक्त nonlinear इनपुट-लेबल एम्बेडिंग और एक संयुक्त-अंतरिक्ष-निर्भर वर्गीकरण इकाई होती है जिसे वर्गीकरण प्रदर्शन को अनुकूलित करने के लिए क्रॉस-एन्ट्रॉपी हानि के साथ प्रशिक्षित किया जाता है। हम एक बड़े लेबल सेट के साथ बहुभाषी समाचार और बायोमेडिकल पाठ के पूर्ण-संसाधन और कम-या शून्य-संसाधन पाठ वर्गीकरण पर मॉडल का मूल्यांकन करते हैं। हमारा मॉडल मोनोलिंगुअल और बहुभाषी मॉडल से बेहतर प्रदर्शन करता है जो दोनों परिदृश्यों में लेबल शब्दार्थ और पिछले संयुक्त इनपुट-लेबल स्पेस मॉडल का लाभ नहीं उठाते हैं।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Modeli klasifikacije neuronskog teksta obično tretiraju etikete izlaza kao kategorijske promjene koje nedostaju opis i semantike. To nudi da njihova parametrizacija zavisi od veličine određene etikete, i stoga oni ne mogu skalirati na velike sete etikete i generalizirati na nepoznate. Postoje zajednički modeli teksta oznake za ulazak prevladaju te probleme iskorištavanjem opisa oznake, ali oni ne mogu uhvatiti kompleksne odnose oznake, imaju krute parametrizacije, a njihovi dobiti na nevidljivim etiketama često se događaju na troškovi slabe učinke na etiketama viđenim tijekom obuke. U ovom papiru predlažemo novi model ulaznog etiketa koji generalizira preko prethodnih takvih model a, adresira njihove ograničenja i ne kompromisuje učinkovitost na viđenim etiketama. Model se sastoji od zajedničkog nelinearnog ulaznog etiketa ugrađenog s kontrolnom kapacitetom i zajedničkom klasifikacijskom jedinicom ovisnom o svemiru koja je obučena s gubitkom preko entropije kako bi optimizirala klasifikaciju. Procjenjujemo modele o klasifikaciji teksta punog resursa i niskog ili nulog resursa multijezičkih vijesti i biomedicinskog teksta s velikim oznakem. Naš model iznosi monojezičke i višejezičke modele koji ne utiču na etikete semantike i prethodne zajedničke svemirske modele u obje scenarije.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A neurális szövegosztályozási modellek általában kategorikus változóként kezelik a kimeneti címkéket, amelyek hiányzik a leírás és a szemantika. Ez arra kényszeríti a paraméterezésüket, hogy a címkészlet méretétől függően legyen, így nem tudnak nagy címkészletekre skálázni és általánosítani a láthatatlanokra. A meglévő közös bemeneti-címke szövegmodellek ezeket a problémákat a címke leírásainak kihasználásával oldják meg, de nem képesek összetett címke kapcsolatokat rögzíteni, merev paraméterezéssel rendelkeznek, és a láthatatlan címkéken elért eredményeik gyakran a címkék gyenge teljesítményének rovására fordulnak elő. Ebben a tanulmányban egy új input-label modellt javasolunk, amely általánosítja a korábbi ilyen modelleket, kezeli azok korlátait, és nem veszélyezteti a látható címkék teljesítményét. A modell egy vezérelhető kapacitással rendelkező, közös, nemlineáris bemeneti címke beágyazásból és egy közös térfüggő osztályozási egységből áll, amelyet keresztentrópia veszteséggel képeztek az osztályozási teljesítmény optimalizálására. Többnyelvű hírek és orvosbiológiai szövegek teljes forrású és alacsony vagy nulla forrású szövegosztályozására vonatkozó modelleket értékeljük nagy címkekészlettel. Modellünk mindkét forgatókönyvben felülmúlja az egynyelvű és többnyelvű modelleket, amelyek nem használják a címke szemantikáját és a korábbi közös bemeneti-címke térmodelleket.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Neural text classification models typically treat output labels as categorical variables that lack description and semantics. Սա ստիպում է նրանց պարամետրիզացիան կախված լինել պիտակի սահմանափակումների չափից, և դրանք չեն կարողանում մեծացնել մեծ պիտակի սահմանափակումների և ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ըն Գոյություն ունի միասին ներմուծման-պիտակի տեքստի մոդելներ, որոնք հաղթահարում են այս խնդիրները օգտագործելով պիտակի նկարագրությունները, բայց նրանք չեն կարողանում պատկերացնել բարդ պիտակի հարաբերությունները, ունեն խիստ պարամետրիզացիա, և դրանց շահույթը անտեսանելի պիտակների վրա հաճախ տեղի Այս թղթի մեջ մենք առաջարկում ենք նոր մուտք-պիտակ մոդել, որը ընդհանրացնում է նախորդ մոդելների վերաբերյալ, վերաբերում է նրանց սահմանափակումներին և չի վնասում տեսանելի պիտակների արդյունքը: Մոդելը կազմված է միասին ոչ գծային մուտքագրման պիտակից, որը ներառված է կառավարելի հնարավորության հետ և միասին տարածության կախված դասակարգման միավորից, որը վարժեցվում է խաչը-էնտրոպիայի կորստով որպեսզի օպտիմացվի դասակար Մենք գնահատում ենք բազմալեզու նորությունների և կենսաբժշկական տեքստի ամբողջ ռեսուրսների և ցածր կամ զրոյից ռեսուրսների դասակարգումների մոդելները մեծ պիտակում: Մեր մոդելը արտադրում է միալեզու և բազլեզու մոդելներ, որոնք չեն օգտագործում սեմանտիկայի պիտակները և նախորդ միավոր մուտք-պիտակ տիեզերական մոդելները երկու սցենարներում:</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Model klasifikasi teks saraf biasanya memperlakukan label output sebagai variabel kategori yang kurang deskripsi dan semantik. Ini memaksa parametrisasi mereka untuk bergantung pada ukuran set label, dan, oleh itu, mereka tidak dapat skala ke set label besar dan generalisasi ke yang tidak terlihat. Model teks input-label kongsi yang ada mengatasi isu-isu ini dengan mengeksploitasi deskripsi label, tetapi mereka tidak dapat menangkap hubungan label kompleks, memiliki parametrisasi yang ketat, dan keuntungan mereka pada label yang tidak terlihat sering terjadi pada biaya prestasi lemah pada label yang terlihat selama latihan. Dalam kertas ini, kami mengusulkan model input-label baru yang menyebarkan lebih dari model sebelumnya, mengatasi batasan mereka, dan tidak merusak prestasi pada label yang terlihat. Model ini terdiri dari label input nonlinear kongsi yang memasukkan dengan kapasitas yang dapat dikendalikan dan unit klasifikasi bergantung pada ruang kongsi yang dilatih dengan kehilangan entropi salib untuk optimisasi prestasi klasifikasi. Kami mengevaluasi model pada sumber daya penuh dan klasifikasi teks sumber daya rendah atau nol dari berita multibahasa dan teks biomedis dengan set label besar. Model kita melebihi model monobahasa dan multibahasa yang tidak menggunakan label semantik dan model ruang input-label sebelumnya dalam kedua skenario.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>I modelli di classificazione del testo neurale tipicamente trattano le etichette di output come variabili categoriche prive di descrizione e semantica. Questo costringe la loro parametrizzazione a dipendere dalla dimensione del set di etichette, e, quindi, non sono in grado di scalare a grandi set di etichette e generalizzare a quelli invisibili. I modelli di testo comuni input-label esistenti risolvono questi problemi sfruttando le descrizioni delle etichette, ma non sono in grado di catturare relazioni di etichetta complesse, hanno una parametrizzazione rigida e i loro guadagni su etichette invisibili avvengono spesso a scapito di prestazioni deboli sulle etichette osservate durante la formazione. In questo articolo, proponiamo un nuovo modello di input-label che generalizzi sui modelli precedenti di questo tipo, affronti i loro limiti e non comprometta le prestazioni sulle etichette viste. Il modello consiste in un embedding congiunto non lineare di input-label con capacità controllabile e un'unità di classificazione congiunta-spazio-dipendente che è addestrata con perdita di entropia incrociata per ottimizzare le prestazioni di classificazione. Valutiamo modelli di classificazione dei testi a risorse complete e a risorse basse o zero di notizie multilingue e testi biomedici con un set di etichette di grandi dimensioni. Il nostro modello supera i modelli monolingue e multilingue che non sfruttano la semantica delle etichette e i precedenti modelli comuni di spazio input-label in entrambi gli scenari.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ニューラルテキスト分類モデルは、典型的には、出力ラベルを、記述および意味論を欠く分類変数として扱う。 これにより、パラメータ化はラベルセットのサイズに依存するように強制され、したがって、大きなラベルセットにスケーリングし、見えないものに一般化することはできません。 既存のジョイントインプットラベルテキストモデルは、ラベル記述を利用することによってこれらの問題を克服しますが、複雑なラベル関係をキャプチャすることができず、堅固なパラメータ化を持ち、見えないラベルでの利得は、トレーニング中に見られるラベルのパフォーマンスの低下を犠牲にして発生することがよくあります。 本稿では，これまでのモデルよりも一般化し，限界に対処し，見たラベルのパフォーマンスを損なわない新しいインプットラベルモデルを提案する． モデルは、制御可能な容量を有するジョイント非線形入力ラベル埋め込みと、分類性能を最適化するためにクロスエントロピー損失でトレーニングされたジョイント空間依存分類ユニットで構成されています。 私たちは、多言語ニュースとバイオメディカルテキストのフルリソースと低リソースまたはゼロリソースのテキスト分類に関するモデルを、大きなラベルセットで評価します。 当社のモデルは、両方のシナリオでラベルセマンティクスと以前の共同入力ラベル空間モデルを活用していない単語および多言語モデルを上回っています。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>email-custom-header-Security First letter Joint input-label text model label Genjer Awak dhéwé éntuk model ning komplit-recurs lan basa-perusahaan kelas-perusahaan seneng basa multilanggar lan seneng biasak bantuan kanggo nambah label sing gak dhéwé. modelo sing wis nambah, dadine languangkat lan akeh multilenguang modelo sing ora nggawe etiket sematik lan banjure nggawe modelo input-label space nang saboh sanes.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ნეიროლური ტექსტის კლასიფიკაციის მოდელები ტიპულად გამოყენება ლექტები როგორც კატეგორიალური ცვლილები, რომლებიც გამოყენება და სიმენტიკები არს ეს მათი პარამეტრიზაციას უნდა იყოს ჩატვირთებული ზომიდან დააყენებული, და ამიტომ მათი არ შეუძლებელია დიდი ჩატვირთების ზომიდან მარცხოვრება და გენერალიზაცია არ არსებობს ერთადერთი მონაცემების ტექსტის მოდელები ამ პრობლემების გამოყენებით, მაგრამ ისინი არ შეუძლებელია კომპლექსი ტექსტის შესახებ, არსებობენ კომპლექსი ტექსტის შესახებ, არსებობენ პარამეტრიზაცია და ის ამ დოკუნეში ჩვენ ახალი მონაცემების მოდელს, რომელიც წინ ასეთი მოდელების განმავლობაში გენერალიზება, მისი დროების მისამართება და არ გამოყენებს კომპრომიზებას ჩვენებული eti მოდელის შეფარდება კონტროლიფიკაციის კონტროლიფიკაციის შესახებ და კონტროლიფიკაციის კონტროლიფიკაციის კონტროლიფიკაციის ერთეულისთვის, რომელიც კრესიკოლიფიკაციის კონტროლიფიკაციის გამოსახულებლა ჩვენ მოდელები მულ რესურსის და ცოლ რესურსის ტექსტის კლასიფიკაციაში მრავალენგური ინფორმაციის და ბიომედიციური ტექსტის შესახებ, რომელიც დიდი რესურსის შესა ჩვენი მოდელი მონოლენგური და მრავალენგური მოდელეები გავაკეთებს, რომლებიც არ შეუძლიათ ლებლიკური სიმენტიკები და წინაღალდეგი მრავალური სიმენტიკების მოდელეები ორი</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Нейрондық мәтін классификациялау үлгілері, әдетте шығыс жарлықтарын сипаттамасы мен семантикалық деген категориялық айнымалылар ретінде қалайды. Бұл параметрлерін жарлық орнатылған өлшеміне тәуелді, сондықтан олар үлкен жарлық жиындарына масштабтау және көрсетілмейді. Бар жалпы енгізу жарлығының мәтін үлгілері жарлығының сипаттамасын қолдану арқылы осы мәселелерді көмектеседі, бірақ олар комплекс жарлықтар қатынасын қабылдауға болмайды, дұрыс параметрлерін қабылдауға болады, және олардың көріні Бұл қағаздың жаңа енгізу үлгісін ұсынып, алдыңғы үлгілерді жалғастырып, шектеулерін адрестеп, көрінетін жарлықтардың істеуін көмектеспейді. Бұл үлгі басқару мүмкіндігі мен біріктірілген бос орын тәуелді классификациялық бірлігі, біріктірілген ентропиялық жоғалу үшін біріктірілген жоғалу үшін біріктірілген нелиниялық енгізу жарлығы Біз үлгілерді толық ресурс мен төмен не нөл ресурс мәтінді бірнеше тілдік жаңалықтар және биомедикалық мәтінді үлкен жарлықтарды бағалаймыз. Біздің үлгіміз екі сценарияда бірнеше тілді мен бірнеше тілді үлгілерді өзгертпейді. Бұл белгілерді семантикалық пен алдыңғы келтірілген кеңістік үлгілерді екі сценарияда</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>신경 텍스트 분류 모델은 일반적으로 출력 라벨을 설명과 의미가 부족한 분류 변수로 본다.이 때문에 매개 변수화는 탭 집합의 크기에 의존하기 때문에 대형 탭 집합으로 확장할 수도 없고, 보이지 않는 탭 집합으로 확대할 수도 없다.기존의 연합 입력 라벨 텍스트 모델은 라벨 묘사를 이용하여 이러한 문제점을 극복했지만 복잡한 라벨 관계를 포착하지 못하고 엄격한 매개 변수화를 가지며 보이지 않는 라벨에 대한 수익은 훈련 기간에 보이는 라벨에 좋지 않은 것을 대가로 한다.본고에서 우리는 새로운 입력 라벨 모델을 제시했다. 이 모델은 이전의 입력 라벨 모델을 보급하고 그들의 한계를 해결했으며 SEED 라벨의 성능에 영향을 주지 않았다.이 모델은 용량을 제어할 수 있는 비선형 연합 입력 라벨 삽입과 공간과 관련된 연합 분류 단원으로 구성되어 있으며 이 단원은 교차 엔트로피 손실을 통해 분류 성능을 최적화하기 위해 훈련을 실시한다.우리는 큰 라벨집을 가진 다국어 뉴스와 생물의학 텍스트의 전체 자원과 낮은 자원 또는 제로 자원 텍스트 분류 모델을 평가했다.이 두 가지 상황에서 우리의 모델은 모두 라벨의 의미를 이용하지 않고 이전의 연합 입력 라벨 공간 모델의 단일 언어와 다중 언어 모델보다 우수하다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Neural text classification models typically treat output labels as categorical variables that lack description and semantics. This forces their parametrization to be dependent on the label set size, and, hence, they are unable to scale to large label sets and generalize to unseen ones. Existing joint input-label text models overcome these issues by exploiting label descriptions, but they are unable to capture complex label relationships, have rigid parametrization, and their gains on unseen labels happen often at the expense of weak performance on the labels seen during training. Šiame dokumente siūlome naują įvesties etiketės model į, kuris apibendrina ankstesnius tokius modelius, atsižvelgia į jų apribojimus ir nekelia pavojaus matytiems etiketėms. Modelą sudaro jungtinis nelinijinis įvesties ženklas su kontroliuojamu pajėgumu ir jungtinis nuo erdvės priklausomas klasifikavimo vienetas, kuris mokomas su kryžminiu entropijos praradimu siekiant optimizuoti klasifikavimo charakteristikas. Vertiname daugiakalbių naujienų ir biomedicinio teksto, kuriame pateikiama didelė etiketė, visiškų išteklių ir mažų arba nulinių išteklių teksto klasifikavimo modelius. Our model outperforms monolingual and multilingual models that do not leverage label semantics and previous joint input-label space models in both scenarios.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Моделите за класификација на неуралниот текст обично ги третираат излезните етикети како категорички променливи кои немаат опис и семантика. Ова ја принуди нивната параметризација да зависи од големината на поставената етикета, и затоа тие не можат да се скалираат на големи поставени етикети и да се генерализираат на невидени. Постојаните заеднички текстови модели на вложена етикета ги надминуваат овие прашања со искористување на описите на етикетата, но тие не можат да фатат комплексни односи со етикетата, имаат цврста параметризација, и нивните добивки на невидени етикети честопати се случуваат на трошок на слабата перформанса на етикетите вид Во овој документ, предложуваме нов модел на вложена етикета кој се генерализира во однос на претходните вакви модели, се обраќа на нивните ограничувања и не ја компромитира перформансата на видени етикети. The model consists of a joint nonlinear input-label embedding with controllable capacity and a joint-space-dependent classification unit that is trained with cross-entropy loss to optimize classification performance. Ние ги проценуваме моделите на целосен ресурс и ниско или нула ресурс класификација на текст на мултијазични вести и биомедички текст со голем сет на етикети. Нашиот модел ги надминува монојазичните и мултијазичните модели кои не влијаат на семантиката на етикетата и претходните заеднички вселенски модели на влезот-етикетата во двата сценарија.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>നെയുറല്‍ ടെക്സ്റ്റ് ക്ലാസ്ഫിക്ഷന്‍ മോഡലുകള്‍ സാധാരണ പുറപ്പെടുത്തുന്ന ലേബ്ലുകള്‍ വിശദീകരണവും സെമാന്റിക്സ ലേബ്ലേറ്റിന്റെ വലിപ്പം ആശ്രയിക്കുന്നതിനായി അവയുടെ പാരാമീറ്ററിഷനെ ഇത് പ്രവര്‍ത്തിപ്പിക്കുന്നു. അതിനാല്‍ അവര്‍ക്ക് വലിയ ലേ ലേബിള്‍ വിശദീകരണങ്ങള്‍ ഉപയോഗിക്കുന്നതിനാല്‍ നിലവിലുള്ള സഹജമായ ഇന്‍പുട്ട് ലേബിലേറ്റ് ടെക്സ്റ്റ് മാതൃകങ്ങള്‍ പരിജയപ്പെടുത്തുവാന്‍ അവര്‍ക്ക് കഴിയില്ല, പരിശീലനത്തി ഈ പത്രത്തില്‍, മുമ്പുള്ള ഇങ്ങനെയുള്ള മോഡലുകളില്‍ സാധാരണമാക്കുന്ന ഒരു പുതിയ ഇന്‍പുട്ട് ലേബ് മോഡല്‍ ഞങ്ങള്‍ പ്രായശ്ചിത്തം ചെയ്യുന നിയന്ത്രിക്കാവുന്ന ശക്തിയോടും നിയന്ത്രിക്കാവുന്ന സ്പെയിസ്റ്റ് ആശ്രയിക്കുന്ന ക്ലാസ്പെയിഷനിന്റെ ക്ലാസ്റ്റിഫ്റ്റ് ആശ്രയിക്കുന്ന ഒര ഞങ്ങള്‍ മോഡലുകളെ മുഴുവന്‍ വിഭവങ്ങളിലും കുറഞ്ഞ വിഭവങ്ങളിലും പൂര്‍ണ്ണമായ വിഭവങ്ങളിലും പദാവലിയിലെ വാര്‍ത്തകളിലും ബൈവിയോമിക്കല്‍ വാ നമ്മുടെ മോഡല്‍ മൊണോളില്‍ഭാഷകങ്ങളും പല ഭാഷകങ്ങളും പ്രവര്‍ത്തിപ്പിക്കുന്നു. ലേബറ്റിന്റെ സെമാന്റിക്സും മുമ്പ് യൂട്ട് ഇന്‍പു</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Тархины текст хуваалтын загварууд ихэвчлэн үржүүлэх загваруудыг тайлбарлах болон semantics албагүй категорийн хувьсагчид гэж үздэг. Энэ нь тэдний параметрийг загварын хэмжээнд хамааралтай болгож байна. Тэгэхээр тэд том загварын хэмжээнд хэмжээтэй болж, харагдахгүй зүйлсийг ерөнхийлөгч болгож чадахгүй. Эдгээр асуудлуудыг загварын тодорхойлолтоор ашиглан хамтдаа орж ирсэн бичил загварын загваруудыг давхарлаа. Гэхдээ тэд комплекс загварын харилцаа барьж чадахгүй, хүчтэй параметрийг барьж чадахгүй, харин тэдний шинжлэх загварууд сургалтын үед харагда Энэ цаасан дээр бид өмнө ийм загваруудыг ерөнхийлөгчилж, хязгаарлалтыг удирдаж, харагдаж байгаа загваруудыг тодорхойлж чадахгүй шинэ бичсэн загварын загварыг санал болгож байна. Энэ загвар нь хяналттай чадвартай холбогдсон шулуун биш шулууны оролцоогүй загварын нэгжтэй бөгөөд хамааралтай загварын холбогдолтой хуваалцах нэгжтэй холбогдолтой юм. Бид олон хэлний мэдээллийн, биологийн медицины текстүүдийн бүрэн болон бага эсвэл 0-нүүрстөрөгчийн текстүүдийн хуваалцааны загварыг үнэлдэг. Бидний загвар нь нэг хэл болон олон хэл загваруудыг дамжуулдаг. Эдгээр загварууд хоёр хувилбарт нэг хэл загваруудыг ашиглахгүй.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Model klasifikasi teks saraf biasanya menjaga label output sebagai pembolehubah kategori yang kekurangan keterangan dan semantik. Ini memaksa parametrisasi mereka bergantung pada saiz set label, dan, oleh itu, mereka tidak dapat skala ke set label besar dan umumkan kepada yang tidak terlihat. Model teks input-label kongsi yang wujud mengatasi isu-isu ini dengan mengeksploitasi deskripsi label, tetapi mereka tidak dapat menangkap hubungan label kompleks, mempunyai parametrisasi yang ketat, dan keuntungan mereka pada label yang tidak terlihat sering berlaku pada biaya prestasi lemah pada label yang dilihat semasa latihan. Dalam kertas ini, kami cadangkan model input-label baru yang menyebarkan lebih daripada model sebelumnya, mengarahkan keterangan mereka, dan tidak kompromi prestasi pada label yang dilihat. Model ini terdiri dari label input-bukan linear bersatu yang memasukkan dengan kapasitas yang boleh dikawal dan unit klasifikasi bergantung-ruang bersatu yang dilatih dengan kehilangan entropi salib untuk optimumkan prestasi klasifikasi. Kami menilai model pada kelasukan teks sumber penuh dan sumber rendah atau sifar bagi berita berbilang bahasa dan teks biomedikal dengan set label besar. Model kita melebihi model monobahasa dan berbilang bahasa yang tidak menggunakan label semantik dan model ruang input-label terdahulu dalam kedua-dua skenario.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mudelli ta’ klassifikazzjoni tat-test newrali tipikament jittrattaw it-tikketti tal-output bħala varjabbli kategoriċi li m’għandhomx deskrizzjoni u semantika. Dan iġġiegħel lill-parametrizzazzjoni tagħhom tkun dipendenti fuq id-daqs tas-sett tat-tikketta, u għalhekk ma jistgħux jikbru l-iskala għal settijiet kbar ta’ tikketta u jiġġeneralizzaw għal dawk li ma jidhrux. Il-mudelli tat-test konġunti eżistenti tat-tikketta tal-input jegħlbu dawn il-kwistjonijiet billi jisfruttaw deskrizzjonijiet tat-tikketta, iżda ma jistgħux jaqbdu relazzjonijiet kumplessi tat-tikketta, ikollhom parametrizzazzjoni riġida, u l-kisbiet tagħhom fuq tikketti mhux osservati sikwit iseħħu bi spiża ta’ prestazzjoni dgħajfa fuq it-tikketti li dehru waqt it-taħriġ. F’dan id-dokument, qed nipproponu mudell ġdid ta’ tikketta tal-input li jiġġeneralizza fuq mudelli preċedenti bħal dawn, jindirizza l-limitazzjonijiet tagħhom, u ma jikkompromettix il-prestazzjoni fuq tikketti li jidhru. Il-mudell jikkonsisti f’tikketta tal-input konġunta mhux lineari li tinkorpora b’kapaċità kontrollabbli u unit à ta’ klassifikazzjoni konġunta dipendenti fuq l-ispazju li hija mħarrġa b’telf ta’ entropija trasversali biex tiġi ottimizzata l-prestazzjoni tal-klassifikazzjoni. Aħna jevalwaw mudelli dwar klassifikazzjoni tat-test b’riżorsi sħa ħ u b’riżorsi baxxi jew żero ta’ aħbarijiet multilingwi u test bijomediku b’sett kbir ta’ tikketta. Our model outperforms monolingual and multilingual models that do not leverage label semantics and previous joint input-label space models in both scenarios.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Neurale tekstclassificatiemodellen behandelen uitvoerlabels meestal als categorische variabelen zonder beschrijving en semantiek. Dit dwingt hun parametrisering afhankelijk te zijn van de grootte van de labelset, en daarom zijn ze niet in staat om te schalen naar grote labelsets en te generaliseren naar ongeziene. Bestaande gezamenlijke invoer-label tekstmodellen overwinnen deze problemen door gebruik te maken van labelbeschrijvingen, maar ze zijn niet in staat om complexe labelrelaties vast te leggen, hebben een rigide parametrisering en hun winsten op onzichtbare labels gebeuren vaak ten koste van zwakke prestaties op de labels die tijdens de training worden gezien. In dit artikel stellen we een nieuw input-label model voor dat generaliseert ten opzichte van eerdere dergelijke modellen, hun beperkingen aanpakt en geen afbreuk doet aan de prestaties op zichtbare labels. Het model bestaat uit een gezamenlijke niet-lineaire input-label embedding met controleerbare capaciteit en een joint-space-afhankelijke classificatieeenheid die is getraind met cross-entropieverlies om classificatieprestaties te optimaliseren. We evalueren modellen op full-resource en low- of zero-resource tekstclassificatie van meertalig nieuws en biomedische tekst met een grote labelset. Ons model presteert beter dan eentalige en meertalige modellen die geen gebruik maken van labelsemantiek en eerdere gezamenlijke input-label ruimtemodellen in beide scenario's.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Klassifikasjonsmodeller for neiraltekst behandler vanlegvis utdata- merkelappar som kategoriske variabler som manglar skildring og semantikk. Dette påkraver parametriseringa sine til å vera avhengig av merkelappen sett storleik, og derfor kan dei ikkje skalera til store merkelappane og generellisera til ukjende. Det eksisterande felles tekstmodeller for innskriftsmerkelappen overfører desse problemene ved å bruka merkelappebeskrivelser, men dei kan ikkje henta komplekse merkelappunksjonar, ha sterke parametrisering, og hendinga på ukjende merkelapper skjer ofte på uttrykket av svake uttrykk på merkelappene som ser under opplæring. I denne papiret foreslår vi eit nytt innskriftsmerkelappemodell som genereliserer over førre slike modeller, adresserer grensene sine, og ikkje kompromerer utviklinga på sette merkelapper. Modellen består av ei kopla ikkje-lineær innskriftsmerkelapp innebygd med kontrollbare kapasitet og ei kopla mellomromavhengig klassifikasjonseining som er trent med tap av krysentropi for å optimalisera klassifikasjonsfunksjon. Vi evaluerer modeller på fullstendig ressurs og låg- eller null- ressurstekstklassifikasjon av fleirspråk nyhetar og biomedisk tekst med ein stor merkelapp. Modellen vårt utfører monospråk og fleirspråk modeller som ikkje leverer merkelappen semantikk og førre fleire mellommerkelapper i begge scenarior.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Neuralne modele klasyfikacji tekstu zazwyczaj traktują etykiety wyjściowe jako zmienne kategoryczne, które brakują opisu i semantyki. To zmusza ich parametryzację do uzależnienia od wielkości zestawu etykiet, a zatem nie są w stanie skalować do dużych zestawów etykiet i uogólniać na niewidoczne. Istniejące wspólne modele tekstowe wejścia-etykiety pokonują te problemy poprzez wykorzystanie opisów etykiet, ale nie są w stanie uchwycić złożonych relacji etykiet, mają sztywną parametryzację, a ich zyski na niewidocznych etykietach zdarzają się często kosztem słabej wydajności etykiet widocznych podczas szkolenia. W niniejszym artykule proponujemy nowy model wejściowo-etykietowy, który uogólnia względem poprzednich takich modeli, uwzględnia ich ograniczenia i nie narusza wydajności na widzianych etykietach. Model składa się ze wspólnego nieliniowego osadzenia etykiety wejściowej z kontrolowaną pojemnością i jednostki klasyfikacyjnej zależnej od przestrzeni złączonej, która jest trenowana z utratą entropii krzyżowej w celu optymalizacji wydajności klasyfikacji. Oceniamy modele klasyfikacji tekstów pełnych i niskich lub zerowych, wielojęzycznych wiadomości i tekstów biomedycznych z dużym zestawem etykiet. Nasz model przewyższa modele jednojęzyczne i wielojęzyczne, które nie wykorzystują semantyki etykiet i poprzednich wspólnych modeli przestrzeni wejścia-etykiety w obu scenariuszach.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Os modelos de classificação de texto neural normalmente tratam os rótulos de saída como variáveis categóricas que carecem de descrição e semântica. Isso força sua parametrização a depender do tamanho do conjunto de rótulos e, portanto, eles são incapazes de escalar para conjuntos de rótulos grandes e generalizar para conjuntos não vistos. Os modelos de texto de rótulos de entrada conjuntos existentes superam esses problemas explorando descrições de rótulos, mas são incapazes de capturar relacionamentos de rótulos complexos, têm parametrização rígida e seus ganhos em rótulos não vistos geralmente acontecem às custas de desempenho fraco nos rótulos vistos durante o treinamento. Neste artigo, propomos um novo modelo de rótulo de entrada que generaliza sobre modelos anteriores, aborda suas limitações e não compromete o desempenho em rótulos vistos. O modelo consiste em uma incorporação de rótulo de entrada não linear conjunta com capacidade controlável e uma unidade de classificação dependente do espaço de articulação que é treinada com perda de entropia cruzada para otimizar o desempenho da classificação. Avaliamos modelos de classificação de texto com recursos completos e com poucos ou zero recursos de notícias multilíngues e texto biomédico com um grande conjunto de rótulos. Nosso modelo supera os modelos monolíngues e multilíngues que não aproveitam a semântica de rótulos e os modelos de espaço de entrada-rótulo conjuntos anteriores em ambos os cenários.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Modelele de clasificare a textelor neurale tratează de obicei etichetele de ieșire ca variabile categorice care lipsesc descriere și semantică. Acest lucru forțează parametrizarea lor să fie dependentă de dimensiunea setului de etichete și, prin urmare, ei nu sunt capabili să scaleze la seturi mari de etichete și să generalizeze la cele nevăzute. Modelele text de intrare și etichete comune existente depășesc aceste probleme prin exploatarea descrierilor etichetelor, dar ele nu sunt capabile să capteze relații complexe de etichete, au parametrizare rigidă, iar câștigurile lor pe etichetele nevăzute se întâmplă adesea în detrimentul performanțelor slabe pe etichete observate în timpul antrenamentului. În această lucrare, propunem un nou model de intrare-etichetă care generalizează asupra modelelor anterioare, abordează limitările acestora și nu compromite performanța pe etichetele văzute. Modelul constă dintr-o încorporare neliniară de intrare-etichetă comună cu capacitate controlabilă și o unitate de clasificare dependentă de spațiu comun care este instruită cu pierdere de entropie încrucișată pentru a optimiza performanța clasificării. Evaluăm modele privind clasificarea textelor cu resurse complete și cu resurse reduse sau zero a știrilor multilingve și a textelor biomedicale cu un set mare de etichete. Modelul nostru depășește modelele monolingve și multilingve care nu utilizează semantica etichetelor și modelele anterioare de spațiu de intrare-etichetă comune în ambele scenarii.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Нейронные модели классификации текста обычно рассматривают выходные метки как категориальные переменные, которым не хватает описания и семантики. Это заставляет их параметризацию зависеть от размера набора меток, и, следовательно, они не могут масштабироваться до больших наборов меток и обобщаться до невидимых. Существующие совместные текстовые модели с входными ярлыками преодолевают эти проблемы, используя описания ярлыков, но они не в состоянии фиксировать сложные взаимосвязи ярлыков, имеют жесткую параметризацию, и их достижения на невидимых ярлыках часто происходят в ущерб слабой производительности на ярлыках, наблюдаемых во время обучения. В этой статье мы предлагаем новую модель входной этикетки, которая обобщает предыдущие такие модели, рассматривает их ограничения и не ставит под угрозу производительность на видимых этикетках. Модель состоит из совместного нелинейного вложения входной метки с контролируемой емкостью и блока совместной пространственно-зависимой классификации, который обучается с перекрестными энтропическими потерями для оптимизации производительности классификации. Мы оцениваем модели полноресурсной и малоресурсной или нулевой текстовой классификации многоязычных новостей и биомедицинского текста с большим набором этикеток. Наша модель превосходит одноязычные и многоязычные модели, которые не используют семантику меток и предыдущие модели совместного пространства входных данных и меток в обоих сценариях.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>න්‍යූරාල් පාළුවේ විශේෂණ මොඩල් සාමාන්‍යයෙන්ම ප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිපත්ත මේකෙන් ඔවුන්ගේ ප්‍රමාණිකරණය ලේබුල් සැකසුම් ප්‍රමාණයට අවශ්‍ය වෙන්න පුළුවන්, ඉතින්, ඔවුන් ලේබුල් සැට් වලට වැ Exist shared input-label text Model overnade this challenge by exploding Labels Description, but are inactive to Capture Compressed Labels සම්බන්ධතාවක්, have rigid Paratrizing, and the win on Unseen Labels is oft at the sum of weaker Perfection on the Labels seen in the Training. මේ පැත්තේ අපි අළුත් ඇතුළු ලේබල් මොඩේල් එකක් ප්‍රතිචාර කරනවා ඒ වගේ මොඩේල් වලින් සාමාන්‍ය වෙනුවෙන්, ඔවුන්ගේ සීමාවන මොඩල් එක්ක පාලනය කරන්න පුළුවන් ක්‍රියාත්මක සමග සම්බන්ධ නොලිනියර් ඇතුළු ලබේල් එක්ක සම්බන්ධ වෙන්න පුළුවන් සමග සම්බන්ධ වෙ අපි පූර්ණ- සම්පූර්ණ- සහ අඩු සම්පූර්ණ- සහ ශූර්ණ- සම්පූර්ණ- සම්පූර්ණ- සම්පූර්ණ- සම්පූ අපේ මෝඩල් එක භාෂාවක් සහ ගොඩක් භාෂාවක් මෝඩල් කරන්න පුළුවන් වෙනවා ඒ වගේම ලේබුල් සෙමැන්ටික් සහ කලින් සම්බන්ධ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Modeli razvrščanja živčnih besedil običajno obravnavajo izhodne oznake kot kategorične spremenljivke, ki nimajo opisa in semantike. To prisili, da je njihova parametrizacija odvisna od velikosti nabora oznak, zato jih ni mogoče razširiti na velike nabore oznak in posplošiti na nevidne. Obstoječi skupni vhodni besedilni modeli premagajo te težave z izkoriščanjem opisov oznak, vendar pa ne morejo zajeti kompleksnih odnosov oznak, imajo togo parametrizacijo, njihove koristi pri nevidnih oznakah pa se pogosto zgodijo na račun slabe zmogljivosti oznak, opaženih med usposabljanjem. V prispevku predlagamo nov model vhodne oznake, ki se posploši nad prejšnjimi modeli, obravnava njihove omejitve in ne ogroža zmogljivosti na videnih oznakah. Model je sestavljen iz skupne nelinearne vhodne oznake s krmilljivo zmogljivostjo in skupno-prostorsko odvisne klasifikacijske enote, ki je usposobljena z izgubo navzkrižne entropije za optimizacijo klasifikacijske učinkovitosti. Z velikim naborom oznak ocenjujemo modele za klasifikacijo besedila s polnimi viri in nizkimi ali ničelnimi viri večjezičnih novic in biomedicinskih besedil. Naš model presega enojezične in večjezične modele, ki v obeh scenarijih ne izkoriščajo semantike oznak in prejšnjih skupnih modelov prostora vhodnih oznak.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tusaaladaha tababaridda ee qoraalka naadiga ah sida caadiga ah waxaa loo isticmaalaa alaabta soo baxa oo kala duwan oo aan u baahnayn sawir iyo semantika. Tani waxay ku xiran karaan parameterisadooda, waxayna ku xiran yihiin tirada calaamadda, sababtaas darteed ma awoodi karaan inay kor u qaadaan xarumaha calaamada waaweyn iyo inay u soo bandhigaan meelaha qarsoon. Tusaalooyinka qoraalka ee wadajirka ah ee laga soo qoro qoraalkaas waxay ku adkaan karaan warqadaha calaamada, laakiin way awoodi kari waayaan inay qabtaan xiriirka qalabka adag, waxay leeyihiin mid si adag u isticmaalaya, faa'iidadooda ku baxana baalasha qarsoon waxey marar badan ku dhacaan kharashka tababarka tababarka lagu arag xilliga waxbarashada. Qoraalkan waxaynu soo jeedaynaa model cusub oo laga soo bandhigayo tusaale ahaan hore oo kale, waxaana ku qoraynaa xuduudaha, mana sameynayo tababarka lagu arko alaabta. Tusaalada waxaa ka mid ah mid ka mid ah mid ka mid ah wadajir-aan-linear input-label oo ku qoran awoodda kontroll leh iyo qaybta iskuulka oo wadajir-space-ku xiran, oo lagu baran karo khasaarada korontopy si uu u optimiso fasaxa fasaxa. Tusaalada waxaan ku qiimeynaynaa qoraalka qoraalka hoose-iyo-hoos-ama-zero-resource ee warbixinta luuqadaha kala duduwan iyo qoraalka biomedical ah oo ku qoran calaamad weyn. Tusaale'dayadu wuxuu sameeyaa tusaalooyin luuqado kala duduwan oo aan ku isticmaalin calaamada semantics iyo samooyinka hore oo ka mid ah mid-ka-gala-label-label labadoodaba.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Modelet e klasifikimit të tekstit nervor tipikisht trajtojnë etiketat e daljes si ndryshuesit kategorikë që mungon përshkrimi dhe semantikë. Kjo detyron parametrizimin e tyre të varet nga madhësia e caktuar e etiketës, dhe kështu, ata nuk janë në gjendje të shkallojnë në set të mëdha të etiketës dhe të gjeneralizojnë në të padukshmet. Modelet ekzistuese të përbashkëta të tekstit të etiketave të hyrjes i kapërcejnë këto çështje duke shfrytëzuar përshkrimet e etiketave, por ato nuk janë në gjendje të kapin marrëdhënie komplekse të etiketave, kanë parametrizim të ashpër dhe fitimet e tyre në etiketat e padukshme ndodhin shpesh në dëm të performancës së dobët në etiketat e parë gjatë trajnimit. Në këtë letër, ne propozojmë një model të ri të etiketës së hyrjes që gjeneralizohet mbi modelet e mëparshëm të tilla, trajton kufizimet e tyre dhe nuk kompromiton performancën në etiketat e parë. Modeli përbëhet nga një etiketë e përbashkët jo-lineare të hyrjes me kapacitet të kontrollueshëm dhe një njësi klasifikimi të përbashkët-të varur nga hapësira që është trajnuar me humbje ndër-entropi për të optimizuar performancën e klasifikimit. We evaluate models on full-resource and low- or zero-resource text classification of multilingual news and biomedical text with a large label set. Modeli ynë paraqet modelet monogjuhësore dhe shumëgjuhësore që nuk përdorin etiketën semantike dhe modelet e mëparshme të përbashkëta të hyrjes-etiketës hapësirore në të dy skenarët.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Modeli klasifikacije neuronskog teksta obično tretiraju etikete izlaza kao kategorijske varijante koje nedostaju opis i semantike. To nudi da njihova parametrizacija zavisi od veličine određene etikete, i zato oni ne mogu da skalaju na velike sete etikete i generalizuju na nevidljive. Postoje zajednički modeli teksta oznake za ulazak prevladaju te probleme iskorištavanjem opisa oznake, ali oni nisu u mogućnosti da uhvate kompleksne odnose oznake, imaju krute parametrizacije, a njihove dobitke na nevidljivim etiketama se često dešavaju na troškovi slabe funkcije na etiketama koje su vidjele tokom treninga. U ovom papiru predlažemo novi model ulaznog etiketa koji generalizuje preko prethodnih takvih model a, adresuje njihove ograničenja i ne kompromisuje performancu na viđenim etiketama. Model se sastoji od zajedničkog nelinearnog ulaznog etiketa ugrađenog sa kontrolnom kapacitetom i zajedničkom klasifikacijskom jedinicom ovisnom od svemira koja je obučena sa gubitkom krsno entropije kako bi optimizirala klasifikaciju. Procjenjujemo modele na klasifikaciji teksta punog resursa i niskog ili nulog resursa multijezičkih vijesti i biomedicinskog teksta sa velikim nametom. Naš model iznosi monojezičke i multijezičke modele koji ne utiču na etikete semantike i prethodne zajedničke svemirske modele za ulazak u obje scenarije.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Neurala textklassificeringsmodeller behandlar vanligtvis utmatningsetiketter som kategoriska variabler som saknar beskrivning och semantik. Detta tvingar deras parametrisering att vara beroende av etikettuppsättningens storlek, och därför kan de inte skala till stora etikettuppsättningar och generalisera till osynliga. Befintliga gemensamma textmodeller löser dessa problem genom att utnyttja etikettbeskrivningar, men de kan inte fånga komplexa etikettrelationer, har stel parametrisering, och deras vinster på osynliga etiketter sker ofta på bekostnad av svag prestanda på etiketterna som ses under träning. I denna uppsats föreslår vi en ny inmatningsmodell som generaliserar över tidigare sådana modeller, tar itu med deras begränsningar och inte kompromissar prestanda på sedda etiketter. Modellen består av en gemensam icke-linjär inmatningsmärkning med kontrollerbar kapacitet och en gemensam rymdberoende klassificeringsenhet som utbildas med korsentropiförlust för att optimera klassificeringsprestandan. Vi utvärderar modeller för full- och låg- eller nollresurstextklassificering av flerspråkiga nyheter och biomedicinsk text med en stor etikettuppsättning. Vår modell överträffar enspråkiga och flerspråkiga modeller som inte utnyttjar etikettsemantik och tidigare gemensamma inmatningsmodeller för etiketter i båda scenarierna.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mfano wa usambazaji wa maandishi ya kijasiri mara nyingi hutumia alama za utoaji kama mabadiliko ya kigezo ambazo hazina maelezo na semantika. Hii inawalazimisha ubaguzi wao kutegemea ukubwa wa alama, na kwa hiyo, hawana uwezo wa kuelekea kwenye seti kubwa za alama na kuzuia vifaa vinavyofichikana. Mradi wa maandishi ya viungo vya pamoja unashinda suala hili kwa kutumia maelezo ya alama, lakini hawana uwezo wa kukabiliana na mahusiano magumu, wanachambua vibaya, na mafanikio yao kwenye mabango yasiyofahamika mara nyingi yanatokea kwa gharama kubwa ya utendaji wa mabango yanayoonekana wakati wa mafunzo. Katika karatasi hii, tunapendekeza modeli mpya ya input inayotengeneza zaidi ya mifano kama ilivyopita, hujadili vizuizi vyao, na haijapunguza utendaji wa tabia zilizotazama. The model consists of a joint nonlinear input-label embedding with controllable capacity and a joint-space-dependent classification unit that is trained with cross-entropy loss to optimize classification performance. Tunatathmini mifano ya rasilimali kamili na usambazaji wa maandishi yenye rasilimali ya chini au sifuri ya habari za lugha mbalimbali na ujumbe wa kitabibu kwa seti kubwa. Mfano wetu unaonyesha mifano ya lugha na lugha mbalimbali ambazo hazina mifano ya kiungo na mifano ya anga za kwanza za katika maeneo yote.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>நெருல் உரை வகைப்படுத்தல் மாதிரிகள் வழக்கமாக வெளியீட்டு சிட்டைகளை வகைப்பட்ட மாறிகளாக பயன்படுத்துகிறது. விவரிப்பும இது விளக்கச்சீட்டு அளவு சார்ந்து கொள்ள அளபுருவை செய்ய முடியாது, அதனால் பெரிய விளக்கச் சீட்டு அமைப்புகளுக்கு அளவிட முடியாத தற்போதைய சேரும் உள்ளீட்டு உரை மாதிரிகள் சிட்டை விளக்கங்களை பயன்படுத்தி இந்த விஷயங்களை வெற்றி பெறுகிறது, ஆனால் அவர்களால் சிக்கலான விளக்கச்சீட்டு உறவுகளை பிடிக்க முடியாத இந்த தாளில், நாம் முந்தைய மாதிரியில் புதிய உள்ளீட்டு மாதிரியை பரிந்துரைக்கிறோம். இது முந்தைய மாதிரிகளில் பொதுவாக்கும், அவற இந்த மாதிரியில் உள்ளீடு- விளக்கம் கட்டுப்படுத்தக்கூடிய சக்தியுடன் உட்பொதிந்த ஒரு இணைக்கோடு அல்லாத உள்ளீட்டு விளக்கச்சீட்டு மற்றும் ஒரு joint- space- சா நாம் முழு மூலத்திலும் குறைந்த அல்லது பூஜ்ஜியமான மூலத்திலும் உரை வகைப்பிலும் மாதிரிகளை மதிப்பிடுகிறோம் பல மொழி செய்தியும எங்கள் மாதிரி மொன்மொழி மற்றும் பல மொழி மாதிரி மாதிரிகளை செயல்படுத்துகிறது இவை இரண்டு காட்சிகளிலும் முந்தைய இணைய உள்ளீட்டு வெள</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nöral metin klasifikasyon modelleri genelde çıqtı etiketleri kategorik çarpmalar olarak hasaplar ve semantik yoktur. Bu onların parametriýasyny etiket düzümlerniň ululykna baglanmagy mümkin edýär we bu sebäpli olar uly etiket düzümlerine gollaşdyryp bilmeýär we ony janlaşdyryp bilmeýär. Existen birleşik girdi-etiket metin nusgalary etiket deskriplerini ulanyp bu meseleleri üstüne geçirip bilmeýär emma olar karmaşık etiket baglaýyşlaryny yakalamak başarmaýarlar, hakyky parametrizaýarlar bar we olaryň gaýd edilmegi kän etiketlerde görünýän etiketleriň hasaplamasynda kän bir şekilde başarýarlar. Bu kagyzda, täze bir girdi etiket modelini öňki nusgalaryň üstünde döredilen nusgalary barlaýar we görkezilen etiketlerde etkinleşen täze bir nusga teklip edýäris. Bu nusga kontrol edilebilir kapasitet bilen birleşik gabdaly gaýd etmek üçin çizgi gabdaly gaýd etmek üçin birleşik gabdaly gaýd etmek üçin birleşik gabdaly gaýd etmek üçin birleşik gabdaly etiketlerdir. Biz nusgalary tam-resop we düşük-ýa-da 0-resop metin klasifikasynda çykýarys Biziň nusgamyz hem dilli hem köp dilli nusgalary çykarýar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>نائورل ٹیکسٹ کلاسپیٹ موڈل معمولاً اپوٹ وٹ وٹ لیبل کو کلاسپیٹ ویرئیٹ کے طور پر دکھاتے ہیں جن کی توصیف اور سیمانٹیک نہیں ہے. یہ ان کے پارامیٹریزی کو لابل سٹ کی سائز پر اعتماد کرنے کے لئے مجبور کرتا ہے، اور لہذا وہ بڑے لابل سٹ تک اسکیل نہیں کر سکتے اور غیب کی سائل کو آسان کر سکتے ہیں۔ Existing joint input-label text models overcome these issues by using label descriptions, but they are unable to capture complex label relationships, have rigid parametrization, and their gains on unseen labels often happen at the expense of weak performance on the labels seen during training. اس کاغذ میں ہم ایک نئی اینٹ لیبل موڈل پیشنهاد کرتے ہیں جو پہلے ایسے موڈل پر جرائل کرتا ہے، ان کی محدودیت کو ادرس کرتا ہے، اور دیکھے لیبل پر کامپیوتر کمزور نہیں کرتا۔ Model consists of a joint nonlinear input-label embedding with controllable capacity and a joint-space-dependent classification unit that is trained with cross-entropy loss to optimize classification performance. ہم نے مدلکوں کو پورا-سروسیس اور کم یا صفر-سروسیس ٹیکسٹ کلیسٹ پر مطالعہ کرلیا ہے multilingual news اور biomedical text کے ایک بڑے لیبل سٹ کے ساتھ. ہمارا موڈل ایک زبان اور ملتی زبان کی موڈلیاں کامل کرتا ہے جو لیبل سیمانٹیکوں اور پہلے سے پیدا ہونے والی اینپ لابل فضا موڈلیاں دونوں سینا ریوئیوں میں نہیں لگاتے۔</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Name Bu yerda ularning parametrlarini yorliqning oʻlchamidan ishlatishga ishonchini bajaradi, va shunday qilib ular katta yorliq satrlariga oʻtishi mumkin. Mavjud birinchi qoʻyish yozuv matn modellari yordamida bu muammolarni yozib olish mumkin, lekin ular murakkab yorliq bogʻlamalarini olib tashlab boʻlmaydi, yetarli parametriklashtirish mumkin, yetishmaydigan yorlarning amalni ko'rib chiqish vaqti yordamida ko'rib chiqish tugmasi yordamida yomon. Bu hujjatda, biz oldingi modellardan generalisi yangi input- yorliq modelini talab qilamiz, ularning chegaralarini boshqaradi, va koʻrsatilgan yorliqlarda bajarish imkoniyatini kamaytirilmaydi. Name Biz bir necha tillar news va biotikal matnning butun manbalar va nuqta manbalar matn darajasini qiymatimiz, katta yorliq yordamida. Bizning modelimiz bir necha tillar va bir xil modellarini bajaradi. Bu ikkita scenariosda hech qanday bir bir bir nechta qo'shish mumkin.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mẫu phân loại chữ thần kinh thường coi các nhãn xuất là các biến số không miêu tả và ngữ pháp. Điều này khiến cho thiết bị đo lường của chúng trở nên phụ thuộc vào kích thước của nhãn đặt, và do đó, chúng không thể quy mô với các thiết lập nhãn lớn và tổng hợp thành những cái chưa thấy. Các mô hình văn bản nhãn nhập chung hiện tại giải quyết những vấn đề này bằng cách khai thác các mô tả nhãn, nhưng chúng không thể nắm bắt các mối quan hệ nhãn hiệu phức tạp, thiết kế siêu âm cứng, và lợi nhuận trên nhãn vô hình thường xảy ra vì hiệu suất kém trên nhãn được nhìn thấy trong huấn luyện. Trong tờ giấy này, chúng tôi đề nghị một mô hình nhãn nhập mới tổng hợp hơn các mô hình trước đó, chấp nhận giới hạn của chúng, và không ảnh hưởng đến các nhãn đã thấy. The model consists of a joint non-linear nhập-markings embedding with control capacity and a join-space-dependence classification unit that is educated with cross-entropy loss to tối ưu hoá hoá hoá hoá hoá hoá hoá performance. Chúng tôi đánh giá các mô hình về các tài nguyên đầy đủ và loại văn bản nhỏ hay không chứa nhiều nguồn tin và văn bản sinh học với một bộ nhãn lớn. Trong cả hai kịch bản, mẫu của chúng tôi hoàn thiện ngôn ngữ và ngôn ngữ nhiều loại mà không tác động được ngữ pháp và biểu mẫu chung nhãn nội dung.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>神经文本分模常以输标为少言语义之变量。 是故参数化依于小大,故不能广于大而广于不见也。 今有合输标签者,因其克之,不可得而得者,有严参数化,而其益于不见者,常以死练见者为贱。 凡新输标签,可概前法,以决其局限性,不损所见。 凡模形有可控容者非线性输标签嵌合空间依赖性分类单元成,该单元因交叉熵损训练以优化性能。 评估有大标签集多言新闻与生物医学文本全资、低资源零资源文本分类模型。 吾模优于单语与多言,二者皆无所用语义与前合输空。</span></div></div><dl><dt>Anthology ID:</dt><dd>Q19-1009</dd><dt>Volume:</dt><dd><a href=/volumes/Q19-1/>Transactions of the Association for Computational Linguistics, Volume 7</a></dd><dt>Month:</dt><dd></dd><dt>Year:</dt><dd>2019</dd><dt>Address:</dt><dd>Cambridge, MA</dd><dt>Venue:</dt><dd><a href=/venues/tacl/>TACL</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>MIT Press</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>139–155</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/Q19-1009>https://aclanthology.org/Q19-1009</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.1162/tacl_a_00259 title="To the current version of the paper by DOI">10.1162/tacl_a_00259</a></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">pappas-henderson-2019-gile</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Nikolaos Pappas and James Henderson. 2019. <a href=https://aclanthology.org/Q19-1009>GILE : A Generalized Input-Label Embedding for Text ClassificationGILE: A Generalized Input-Label Embedding for Text Classification</a>. <i>Transactions of the Association for Computational Linguistics</i>, 7:139–155.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/Q19-1009>GILE : A Generalized Input-Label Embedding for Text ClassificationGILE: A Generalized Input-Label Embedding for Text Classification</a> (Pappas & Henderson, TACL 2019)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/Q19-1009.pdf>https://aclanthology.org/Q19-1009.pdf</a></dd><dt>Code</dt><dd><a href=https://github.com/idiap/gile><i class="fab fa-github"></i>&nbsp;idiap/gile</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/Q19-1009.pdf title="Open PDF of 'GILE : A Generalized Input-Label Embedding for Text ClassificationGILE: A Generalized Input-Label Embedding for Text Classification'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=GILE+%3A+A+Generalized+Input-Label+Embedding+for+Text+ClassificationGILE%3A+A+Generalized+Input-Label+Embedding+for+Text+Classification" title="Search for 'GILE : A Generalized Input-Label Embedding for Text ClassificationGILE: A Generalized Input-Label Embedding for Text Classification' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-secondary d-flex flex-wrap justify-content-center" href="https://paperswithcode.com/paper/?acl=Q19-1009" title="Code for 'GILE : A Generalized Input-Label Embedding for Text ClassificationGILE: A Generalized Input-Label Embedding for Text Classification' on Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-big" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg><span class="pl-sm-2 d-none d-sm-inline">Code</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'GILE : A Generalized Input-Label Embedding for Text ClassificationGILE: A Generalized Input-Label Embedding for Text Classification'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[GILE : A Generalized Input-Label Embedding for Text ClassificationGILE: A Generalized Input-Label Embedding for Text Classification](https://aclanthology.org/Q19-1009) (Pappas & Henderson, TACL 2019)</p><ul class=mt-2><li><a href=https://aclanthology.org/Q19-1009>GILE : A Generalized Input-Label Embedding for Text ClassificationGILE: A Generalized Input-Label Embedding for Text Classification</a> (Pappas & Henderson, TACL 2019)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Nikolaos Pappas and James Henderson. 2019. <a href=https://aclanthology.org/Q19-1009>GILE : A Generalized Input-Label Embedding for Text ClassificationGILE: A Generalized Input-Label Embedding for Text Classification</a>. <i>Transactions of the Association for Computational Linguistics</i>, 7:139–155.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>