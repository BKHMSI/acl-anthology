<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Learning Word Representations with Regularization from Prior Knowledge - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="Learning Word Representations with Regularization from Prior Knowledge" name=citation_title><meta content="Yan Song" name=citation_author><meta content="Chia-Jung Lee" name=citation_author><meta content="Fei Xia" name=citation_author><meta content="Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017)" name=citation_conference_title><meta content="2017/8" name=citation_publication_date><meta content="https://aclanthology.org/K17-1016.pdf" name=citation_pdf_url><meta content="143" name=citation_firstpage><meta content="152" name=citation_lastpage><meta content="10.18653/v1/K17-1016" name=citation_doi><meta property="og:title" content="Learning Word Representations with Regularization from Prior Knowledge"><meta property="og:image" content="https://aclanthology.org/thumb/K17-1016.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/K17-1016"><meta property="og:description" content="Yan Song, Chia-Jung Lee, Fei Xia. Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017). 2017."><link rel=canonical href=https://aclanthology.org/K17-1016></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/K17-1016.pdf>Learning Word Representations with Regularization from Prior Knowledge</a>
<a id=af_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Leer woord voorstellings met Regulisering van Vorige kennis</a>
<a id=am_title style=display:none href=https://aclanthology.org/K17-1016.pdf>ምርጫዎች</a>
<a id=ar_title style=display:none href=https://aclanthology.org/K17-1016.pdf>تعلم تمثيلات الكلمات مع التنظيم من المعرفة السابقة</a>
<a id=az_title style=display:none href=https://aclanthology.org/K17-1016.pdf>쿮vv톛lki Bilim t톛rzind톛n d칲zg칲n t톛rzd톛 S칬zl칲kl톛ri 칬yr톛nm톛k</a>
<a id=bg_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Учене на думи с регуляризация от предишни знания</a>
<a id=bn_title style=display:none href=https://aclanthology.org/K17-1016.pdf>প্রাথমিক জ্ঞান থেকে নিয়মিতকরণের সাথে শব্দ প্রতিনিধি শিখা</a>
<a id=bo_title style=display:none href=https://aclanthology.org/K17-1016.pdf>སྔོན་མ་ཤེས་པའི་ལྟ་བུའི་ཡིག་གི་རྣམ་པ་དང་མཉམ་དུ་བསླབས་པའི་ཡིག་གཟུགས་སྟོན་དགོས་པ</a>
<a id=bs_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Naučenje predstavljanja riječi sa regularizacijom iz prije znanja</a>
<a id=ca_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Aprendre representacions de paraules amb regularizació des del coneixement anterior</a>
<a id=cs_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Učení se slovních reprezentací s regularizací z předchozích znalostí</a>
<a id=da_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Læring af ordrepræsentationer med regulering fra tidligere viden</a>
<a id=de_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Lernen von Wortdarstellungen mit Regularisierung aus Vorkenntnissen</a>
<a id=el_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Μάθηση των Αντιπροσωπειών λέξεων με Ρυθμοποίηση από προηγούμενες γνώσεις</a>
<a id=es_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Aprendizaje de representaciones de palabras con regularización a partir de conocimientos previos</a>
<a id=et_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Õppida sõna esindusi regulariseerimisega varasematest teadmistest</a>
<a id=fa_title style=display:none href=https://aclanthology.org/K17-1016.pdf>یاد گرفتن نمایش‌های کلمه با تعیین قانونی از دانش قبلی</a>
<a id=fi_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Sanaedustuksen oppiminen ja säännöstely aiemmasta tiedosta</a>
<a id=fl_title style=display:none href=https://aclanthology.org/K17-1016.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Apprentissage des représentations de mots avec régularisation à partir de connaissances antérieures</a>
<a id=ga_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Ag Foghlaim Léiriúcháin Focal le Rialáil ón Réamheolas</a>
<a id=ha_title style=display:none href=https://aclanthology.org/K17-1016.pdf>KCharselect unicode block name</a>
<a id=he_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Learning Word Representations with Regularization from Prior Knowledge</a>
<a id=hi_title style=display:none href=https://aclanthology.org/K17-1016.pdf>पूर्व ज्ञान से नियमितीकरण के साथ शब्द प्रतिनिधित्व सीखना</a>
<a id=hr_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Naučenje predstavljanja riječi s regularizacijom iz prije znanja</a>
<a id=hu_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Szóreprezentációk tanulása korábbi ismeretekből történő szabályozással</a>
<a id=hy_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Learning Word Representations with Regularization from Prior Knowledge</a>
<a id=id_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Belajar Perwakilan Kata dengan Regularisasi dari Pengetahuan Sebelumnya</a>
<a id=is_title style=display:none href=https://aclanthology.org/K17-1016.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Imparare le rappresentazioni di parole con regolarizzazione da conoscenze precedenti</a>
<a id=ja_title style=display:none href=https://aclanthology.org/K17-1016.pdf>既存の知識から規則化された単語表現を学ぶ</a>
<a id=jv_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Ngubah Keterangkang Pak-Keterangkang karo Regularasyon nang Kelungan Prilikar</a>
<a id=ka_title style=display:none href=https://aclanthology.org/K17-1016.pdf>წინ ვიცნობიდან რეგილარიზაციის სიტყვების გამოსწავლება</a>
<a id=kk_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Алдыңғы білім мәліметінен регулярлау үшін сөздерді таңдау</a>
<a id=ko_title style=display:none href=https://aclanthology.org/K17-1016.pdf>선험지식에 기초한 규칙화 어휘 표징 학습</a>
<a id=lt_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Mokymasis žodžių atstovavimais reguliarizuojant iš ankstesnių žinių</a>
<a id=mk_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Научи претставувања на зборови со регуларизација од претходно знаење</a>
<a id=ml_title style=display:none href=https://aclanthology.org/K17-1016.pdf>പ്രധാനപരിജ്ഞാനത്തില്‍ നിന്നുള്ള വാക്കിന്റെ പ്രതിനിധികള്‍ പഠിക്കുന്നു</a>
<a id=mn_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Өмнөх мэдлэгийнхээ хэмжээний үг төлөөлөлт суралцах</a>
<a id=ms_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Learning Word Representations with Regularization from Prior Knowledge</a>
<a id=mt_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Tagħlim Rappreżentazzjonijiet tal-kliem b’Regolarizzazzjoni minn Għarfien minn Qabel</a>
<a id=nl_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Woordvertegenwoordigingen leren met regulering vanuit voorkennis</a>
<a id=no_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Læring av ordreprezentasjonar med regulering frå førre kjenning</a>
<a id=pl_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Nauka reprezentacji słowa z regularyzacją z wcześniejszej wiedzy</a>
<a id=pt_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Aprendendo Representações de Palavras com Regularização de Conhecimento Prévio</a>
<a id=ro_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Învățarea reprezentărilor Word cu regularizare din cunoștințe anterioare</a>
<a id=ru_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Представления учебных слов с упорядочением на основе предшествующих знаний</a>
<a id=si_title style=display:none href=https://aclanthology.org/K17-1016.pdf>ප්‍රධාන දන්නවයෙන් ප්‍රතිස්ථානය සමග වචන ප්‍රතිස්ථානය ඉගෙන ගන්න</a>
<a id=sk_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Učenje besednih predstavitev z regularizacijo iz predhodnega znanja</a>
<a id=so_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Barista hadal Representations with Regularization from Prior Knowledge</a>
<a id=sq_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Mëso përfaqësime fjalësh me rregullim nga njohuritë e mëparshme</a>
<a id=sr_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Naučenje predstavljanja riječi sa regularizacijom iz priornog znanja</a>
<a id=sv_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Lär dig Word Representationer med regularisering från tidigare kunskap</a>
<a id=sw_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Kujifunza maoni ya neno kwa Utawala kutoka Ujuzi Mkuu</a>
<a id=ta_title style=display:none href=https://aclanthology.org/K17-1016.pdf>முன்னால் அறிவியிலிருந்து வார்த்தையின் பிரதிநிதியுடன் விதிமுறையாக்கம் கற்று</a>
<a id=tr_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Öňki Bilim bilen düzenlemek bilen söz temsilleri öwrenmek</a>
<a id=uk_title style=display:none href=https://aclanthology.org/K17-1016.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/K17-1016.pdf>پہلے علم سے روزنامہ کے ساتھ کلمات روزنامہ کی تعلیم کی جاتی ہے</a>
<a id=uz_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Learning Word Representations with Regularization from Prior Knowledge</a>
<a id=vi_title style=display:none href=https://aclanthology.org/K17-1016.pdf>Học từ miễn trước khi phục hồi từ kiến thức</a>
<a id=zh_title style=display:none href=https://aclanthology.org/K17-1016.pdf>学有正则化于先验者单词</a></h2><p class=lead><a href=/people/y/yan-song/>Yan Song</a>,
<a href=/people/c/chia-jung-lee/>Chia-Jung Lee</a>,
<a href=/people/f/fei-xia/>Fei Xia</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Conventional <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> are trained with specific <a href=https://en.wikipedia.org/wiki/Statistical_parameter>criteria</a> (e.g., based on <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a> or <a href=https://en.wikipedia.org/wiki/Co-occurrence>co-occurrence</a>) inside a single information source, disregarding the opportunity for further calibration using external knowledge. This paper presents a unified framework that leverages pre-learned or external priors, in the form of a <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularizer</a>, for enhancing conventional language model-based embedding learning. We consider two types of <a href=https://en.wikipedia.org/wiki/Regularization_(physics)>regularizers</a>. The first type is derived from topic distribution by running LDA on unlabeled data. The second type is based on <a href=https://en.wikipedia.org/wiki/Dictionary>dictionaries</a> that are created with human annotation efforts. To effectively learn with the <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularizers</a>, we propose a novel <a href=https://en.wikipedia.org/wiki/Data_structure>data structure</a>, trajectory softmax, in this paper. The resulting <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> are evaluated by word similarity and sentiment classification. Experimental results show that our learning framework with <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularization</a> from prior knowledge improves embedding quality across multiple datasets, compared to a diverse collection of baseline methods.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Konvensionale woord inbettings word opgelei met spesifieke kriteriërs (bv. gebaseer op taal modellering of saamvoorkoms) binne 'n enkele inligting bron, onthou die geleentheid vir verdere kalibrering deur eksterne kennis te gebruik. Hierdie papier beveel 'n eenvoudige raamwerk wat voorafleer of eksterne voorafwoordes, in die vorm van 'n regulariseerder, verhoog vir die verbetering van konvensionale taal model gebaseerde inbetering leer. Ons beskou twee tipe regulariseerders. Die eerste tipe is afgeleide van onderwerp verspreiding deur loop LDA op ongeabelde data. Die tweede tipe is gebaseer op woordeboeke wat gemaak word met menslike annotasie versoekte. Om effektief te leer met die regulariseerders, voorstel ons 'n nuwe data struktuur, trajectory softmax in hierdie papier. Die resultateerde inbêdings word deur woord gelykbaarheid en sentiment klasifikasie evalueer. Eksperimentale resultate wys dat ons leer raamwerk met regularisasie van voorheede kennis verbeter inbetering kwaliteit oor veelvuldige datastelle, vergelyk met 'n verskillende versameling van basisline metodes.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Conventional word embeddings are trained with specific criteria (e.g., based on language modeling or co-occurrence) inside a single information source, disregarding the opportunity for further calibration using external knowledge. ይህ ገጽ አስቀድሞ የተማረ ወይም ውጭ የውጭ ቀዳሚዎችን ያሳርፋል፡፡ ሁለት ዓይነቶች አስተዳዳሪዎች እናስባለን ። የመጀመሪያው ዓይነት አዲስ ዶሴ ፍጠር ሁለተኛይቱ ዓይነት በሰው ብሔራዊ ጉዳይ የተፈጠሩ መዝገብ ነው፡፡ በሥርዓት አስተዳሪዎች ጋር ለመማር፣ በዚህ ገጽ የመረጃ ዳታ አካባቢ፣ የግንኙነት ስፍትሕት እናሳውቃለን፡፡ የውጤቱ አካባቢዎች ቃላት በሚመስል እና በሚስማት መግለጫ ያስተካክላሉ፡፡ ፈተና ፍሬዎች ከቀድሞ እውቀታችን ጋር መማር ፍሬማችን በብዛት ዳታተር ጥያቄን እንዲያሳድጋል፣ በተለየ ብዙዎች የጥያቄ ሥርዓት እንዲያሳድግ ያሳያል፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>يتم تدريب عمليات تضمين الكلمات التقليدية وفقًا لمعايير محددة (على سبيل المثال ، استنادًا إلى نمذجة اللغة أو التواجد المشترك) داخل مصدر معلومات واحد ، مع تجاهل الفرصة لمزيد من المعايرة باستخدام المعرفة الخارجية. تقدم هذه الورقة إطارًا موحدًا يستفيد من مقدمات سابقة التعلم أو خارجية ، في شكل منظم ، لتعزيز تعلم التضمين المستند إلى نموذج اللغة التقليدية. نحن نعتبر نوعين من المنظمين. النوع الأول مشتق من توزيع الموضوع عن طريق تشغيل LDA على البيانات غير المسماة. النوع الثاني يعتمد على القواميس التي تم إنشاؤها بجهود التعليقات التوضيحية البشرية. للتعلم بشكل فعال مع المنظمين ، نقترح في هذه الورقة بنية بيانات جديدة ، مسار softmax. يتم تقييم حفلات الزفاف الناتجة عن طريق تشابه الكلمات وتصنيف المشاعر. تُظهر النتائج التجريبية أن إطار التعلم الخاص بنا مع التنظيم من المعرفة السابقة يحسن جودة التضمين عبر مجموعات بيانات متعددة ، مقارنة بمجموعة متنوعة من أساليب خط الأساس.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Yalnız bir məlumat kaynağı içində müəyyən edilən sözlər içərisində müəyyən qiymətlərlə təhsil edilir, daxili bilgi ilə daha çox kalibrləmə fərqli olaraq təhsil edilir. Bu kağıt, əvvəlcə öyrənmiş və ya dış əvvəlkilərin öyrənməsini, düzgün dil modelini yüksəltmək üçün, müxtəlif dil modelini yüksəltən öyrənmək üçün birləşdirilmiş bir framework göstərir. Biz iki növlü düzgün tərzi düşünürük. İlk növ məsələlər dağıtılışından LDA vasitəsilə yazılmış məlumatlardan alındı. İkinci növ insan işarələri ilə yaratdığı sözlərə dayanılır. Bu kağızda yeni məlumat quruluşu, trajectory softmax təklif edirik. Növbəti inşallar sözlərin bənzəriliyi və hisslərin klasifikasiyası ilə değerlənir. Müxtəlif sonuçları, əvvəlki bilgi ilə müəyyən edilən öyrənmə qurğusu ilə, çoxlu veri qurğuları ilə müxtəlif dəyişiklik metodlarının müqayisədə, müxtəlif təhsil qurğusu ilə birləşdirilir.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Конвенционалните вграждания на думи се обучават със специфични критерии (например въз основа на езиково моделиране или съвместно появяване) в рамките на един информационен източник, пренебрегвайки възможността за по-нататъшно калибриране с помощта на външни знания. Тази статия представя единна рамка, която използва предварително научени или външни приоритети под формата на регуляризатор, за подобряване на конвенционалното езиково обучение, базирано на вграждане, базирано на модели. Ние разглеждаме два вида регуляризатори. Първият тип се извлича от тематично разпределение чрез стартиране на LDA върху немаркирани данни. Вторият тип се основава на речници, които са създадени с човешки усилия за анотация. За да се научим ефективно с регуляризаторите, ние предлагаме нова структура на данните, траектория софтмакс, в тази статия. Получените вграждания се оценяват по сходство на думите и класификация на сантименталността. Експерименталните резултати показват, че нашата учебна рамка с регламентиране от предишни знания подобрява качеството на вграждането в множество набори от данни в сравнение с разнообразната колекция от базови методи.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>এক তথ্য উৎসের ভিতরে বিশেষ ক্যালাবেশনের সুযোগ প্রশিক্ষণ প্রদান করা হয় (যেমন ভাষার মডেলিং অথবা একই সাথে সংঘটিত ভিত্তিক ভিত্তিক ভিত্তিক ভিত্তিক) এই পত্রিকাটি একটি একত্রিত ফ্রেম উপস্থাপন করেছে যা পূর্বে শিক্ষা বা বাইরে শিক্ষা প্রাপ্ত বা বিদেশী শিক্ষা প্রদান করা হয়েছে, একটি নিয়মিত শিক্ষা আমরা দুটি ধরনের নিয়মিত বিবেচনা করি। এলডিএ চালিয়ে যাওয়ার মাধ্যমে প্রথম ধরনের বিষয় বিতরণ থেকে উদ্ধার করা হয়েছে অল্প তথ্য চালানোর মাধ্যমে। দ্বিতীয় ধরনের ভিত্তিতে রয়েছে মানুষের প্রচেষ্টার মাধ্যমে যা সৃষ্টি করা হয়েছে। কার্যকরভাবে নিয়ন্ত্রণকারীদের সাথে শিখার জন্য আমরা এই কাগজটিতে একটি উপন্যাস তথ্য কাঠামো প্রস্তাব করি, ট্রাক্টরিক এর ফলে বিভিন্ন বিভিন্ন শব্দের সমতা এবং অনুভূতি বিভাগের মাধ্যমে মূল্যায়ন করা হয়। পরীক্ষার ফলাফল দেখা যাচ্ছে যে আমাদের শিক্ষার কাঠামো পূর্বের জ্ঞান নিয়ন্ত্রণের সাথে বিভিন্ন ধরনের বেসাইলাইন পদ্ধতির তুলনায় বেশ কিছ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Conventional word embeddings are trained with specific criteria (e.g., based on language modeling or co-occurrence) inside a single information source, disregarding the opportunity for further calibration using external knowledge. ཤོག ང་ཚོས་མི་འདྲ་བ་བཟོས་མཁན་གྱི་རྩིས་པ་གཉིས་བསམ་བྱེད་ཀྱི་ཡོད། རིགས་དང་པོ་དེ་ནི་ཁོང་ཡིག་ཆ་མེད་པའི་གནད་དོན་བཤད་ནས་སྤྱོད་པའི་LDA་ནས་ཕན་འབྲས་བ་རེད། དབྱེ་རིགས་གཉིས་པ་དེ་ནི་མིའི་བསྐུལ་ལུགས་ཀྱི་བཟོ་བརྗོད་པའི་འཇིག་རྟེན་དང་མཉམ་དུ་གཞི་རྟེན་ཡོད། དེ་ལྟར་འགྱུར་བ་དང་མཉམ་དུ་གྲངས་སུ་བཏང་ན། ང་ཚོས་ཤོག་བུ་འདིའི་ནང་གི་གསར་འགུལ་གྱི་ཆ་འཕྲིན་དང་། དབྱིབས་ཤུགས་ཀྱི་གནས་ཚུལ་དེ་ཚོར་བ་དང་སྒྲིག་ཚིག་གི་དབྱེ་རིགས་ལ་བསྟུན་ནས་དབྱེ་བ་བཟོས་ཡོད། Experimental results show that our learning framework with regularization from prior knowledge improves embedding quality across multiple datasets, compared with a diverse collection of baseline methods.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Konvencionalni integraciji riječi obučeni su s specifičnim kriterijama (na primjer na temelju modela jezika ili saradnje) unutar jednog izvora informacija, bez obzira na mogućnost daljnje kalibracije koristeći vanjske znanje. Ovaj papir predstavlja ujedinjeni okvir koji utiče na predučenje ili vanjske prethodne, u obliku regularizatora, za unapređenje konvencionalnog jezičkog model a osnovanog učenja ugrađenja. Smatramo dva vrsta regularizatora. Prvi tip je proizveden iz distribucije teme pokrenući LDA na neizbiljnim podacima. Drugi tip je baziran na rečnicima koje su stvorene naporima ljudskih annotacija. Da bi se efikasno naučili sa regularizatorima, predlažemo novu strukturu podataka, trajektoriju softmax, u ovom papiru. Rezultatni integraciji procjenjuju sličnost riječima i klasifikacija osjećaja. Eksperimentalni rezultati pokazuju da naš okvir učenja s regularizacijom iz prethodnog znanja poboljšava integraciju kvalitete na višestrukim podacima u usporedbi s različitim kolekcijom početnih metoda.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Les integracions de paraules convencionals s'entrenen amb criteris específics (per exemple, basats en modelar llengües o coincidència) dins d'una sola font d'informació, ignorant l'oportunitat de seguir calibrant fent servir coneixements externs. Aquest paper presenta un marc unificat que aprofita priors pré-aprenguts o externs, en form a de regularització, per millorar l'aprenentatge integral basat en models de llenguatge convencional. Considerem dos tipus de regularitzadors. El primer tipus es deriva de la distribució temàtica executant LDA en dades sense etiqueta. The second type is based on dictionaries that are created with human annotation efforts. Per aprendre efectivament amb els regularitzadors, proposem una nova estructura de dades, trajectòria softmax, en aquest article. Les integracions resultants s'evaluen segons la similitud de paraules i la classificació del sentiment. Els resultats experimentals mostren que el nostre marc d'aprenentatge amb regularització a partir del coneixement anterior millora l'incorporació de la qualitat a múltiples conjunts de dades, comparat amb una diversa col·lecció de mètodes de base.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Konvenční vkládání slov jsou trénovány podle specifických kritérií (např. založených na jazykovém modelování nebo společném výskytu) uvnitř jednoho informačního zdroje, přičemž se ignoruje možnost další kalibrace pomocí externích znalostí. Tento článek představuje jednotný rámec, který využívá předučené nebo externí předchozí záznamy, ve formě regularizátoru, pro zlepšení konvenčního jazykového modelu založeného na embeddedování. Zvažujeme dva typy regularizátorů. První typ je odvozen z distribuce tématu spuštěním LDA na neoznačených datech. Druhý typ je založen na slovnících, které jsou vytvořeny s lidskými anotacemi. Abychom se efektivně učili s regularizátory, navrhujeme v tomto článku novou datovou strukturu, trajektorii softmax. Výsledné vložení jsou hodnoceny podobností slov a klasifikací sentimentů. Experimentální výsledky ukazují, že náš učební rámec s regularizací z předchozích znalostí zlepšuje kvalitu vložení do více datových sad ve srovnání s různorodou sbírkou základních metod.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Konventionelle ordindlejringer trænes med specifikke kriterier (f.eks. baseret på sprogmodellering eller samtidig forekomst) inde i en enkelt informationskilde, uden at der tages hensyn til muligheden for yderligere kalibrering ved hjælp af ekstern viden. Dette dokument præsenterer en samlet ramme, der udnytter præ-lærte eller eksterne forudsætninger, i form af en regularizer, til at forbedre konventionel sprogmodel baseret indlejring. Vi overvejer to typer regulatorisatorer. Den første type stammer fra emnefordeling ved at køre LDA på ikke-mærkede data. Den anden type er baseret på ordbøger, der er oprettet med menneskelige annoteringsindsatser. For effektivt at lære med regulariserne, foreslår vi en ny datastruktur, traiectory softmax, i denne artikel. De resulterende indlejringer evalueres ved ordlighed og sentiment klassificering. Eksperimentelle resultater viser, at vores læringsramme med regulering fra tidligere viden forbedrer indlejringskvaliteten på tværs af flere datasæt sammenlignet med en varieret samling af basismetoder.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Herkömmliche Worteinbettungen werden mit spezifischen Kriterien (z.B. basierend auf Sprachmodellierung oder Co-Vorkommen) innerhalb einer einzigen Informationsquelle trainiert, wobei die Möglichkeit einer weiteren Kalibrierung mit externem Wissen vernachlässigt wird. Dieser Beitrag stellt ein einheitliches Framework vor, das vorgelernte oder externe Priors in Form eines Regularizers nutzt, um konventionelles sprachmodellbasiertes Einbettungslernen zu verbessern. Wir betrachten zwei Arten von Regularizern. Der erste Typ wird von der Themenverteilung abgeleitet, indem LDA auf nicht beschrifteten Daten ausgeführt wird. Der zweite Typ basiert auf Wörterbüchern, die mit menschlichen Anmerkungen erstellt werden. Um effektiv mit den Regularizern zu lernen, schlagen wir in diesem Beitrag eine neuartige Datenstruktur vor, Trajektorie softmax. Die resultierenden Einbettungen werden nach Wortähnlichkeit und Stimmungsklassifikation bewertet. Experimentelle Ergebnisse zeigen, dass unser Lernframework mit Regularisierung aus Vorkenntnissen die Einbettungsqualität über mehrere Datensätze hinweg verbessert, im Vergleich zu einer Vielzahl von Basismethoden.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Οι συμβατικές ενσωματώσεις λέξεων εκπαιδεύονται με συγκεκριμένα κριτήρια (π.χ. βασισμένα στη γλωσσική μοντελοποίηση ή συνύπαρξη) μέσα σε μια ενιαία πηγή πληροφοριών, αγνοώντας την ευκαιρία για περαιτέρω βαθμονόμηση χρησιμοποιώντας εξωτερικές γνώσεις. Η παρούσα εργασία παρουσιάζει ένα ενοποιημένο πλαίσιο που αξιοποιεί προ-μαθημένα ή εξωτερικά προηγούμενα, με τη μορφή ενός κανονικοποιητή, για την ενίσχυση της συμβατικής εκμάθησης βασισμένης στο μοντέλο γλώσσας. Εξετάζουμε δύο τύπους τακτικών. Ο πρώτος τύπος προέρχεται από τη διανομή θεμάτων με την εκτέλεση σε δεδομένα χωρίς ετικέτα. Ο δεύτερος τύπος βασίζεται σε λεξικά που δημιουργούνται με ανθρώπινες προσπάθειες σχολιασμού. Για να μάθουμε αποτελεσματικά με τους ρυθμιστές, προτείνουμε μια νέα δομή δεδομένων, τροχιά στην παρούσα εργασία. Οι προκύπτουσες ενσωματώσεις αξιολογούνται με βάση την ομοιότητα λέξεων και την ταξινόμηση συναισθημάτων. Τα πειραματικά αποτελέσματα δείχνουν ότι το μαθησιακό μας πλαίσιο με ρύθμιση από προηγούμενες γνώσεις βελτιώνει την ποιότητα ενσωμάτωσης σε πολλαπλά σύνολα δεδομένων, σε σύγκριση με μια ποικιλία μεθόδων βάσης.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Las incrustaciones de palabras convencionales se entrenan con criterios específicos (por ejemplo, basados en el modelado del lenguaje o la coexistencia) dentro de una única fuente de información, sin tener en cuenta la oportunidad de una mayor calibración mediante el uso de conocimientos externos. Este documento presenta un marco unificado que aprovecha los antecedentes preaprendidos o externos, en forma de un regularizador, para mejorar el aprendizaje de incrustación basado en modelos de lenguaje convencional. Consideramos dos tipos de regularizadores. El primer tipo se deriva de la distribución de temas mediante la ejecución de LDA en datos sin etiqueta. El segundo tipo se basa en diccionarios que se crean con esfuerzos de anotación humanos. Para aprender eficazmente con los regularizadores, proponemos en este artículo una estructura de datos novedosa, trayectoria softmax. Las incrustaciones resultantes se evalúan mediante la similitud de palabras y la clasificación de sentimientos. Los resultados experimentales muestran que nuestro marco de aprendizaje con regularización de conocimientos previos mejora la calidad de la integración en múltiples conjuntos de datos, en comparación con una colección diversa de métodos de referencia.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tavapäraseid sõnade manustamist koolitatakse konkreetsete kriteeriumidega (nt keele modelleerimisel või koosesinemisel) ühes teabeallikas, jättes arvesse võimalust edasiseks kalibreerimiseks välisteadmiste abil. Käesolevas dokumendis esitatakse ühtne raamistik, mis võimendab eelõppenud või väliseid prioriteete regulariseerija kujul tavapärase keelemudelil põhineva manustamisõppe parandamiseks. Me kaalume kahte tüüpi regulaatoreid. Esimene tüüp tuletatakse teemajaotusest, käivitades LDA märgistamata andmetel. Teine tüüp põhineb sõnaraamatutel, mis on loodud inimese annoteerimise jõupingutustega. Regulariseerijatega tõhusaks õppimiseks pakume selles töös välja uudse andmestruktuuri, trajektoor softmax. Tulenevaid manustamisi hinnatakse sõna sarnasuse ja sentimentaalse klassifikatsiooni alusel. Eksperimentaalsed tulemused näitavad, et meie õppimisraamistik, mis reguleerib varasemaid teadmisi, parandab mitme andmekogumi manustamise kvaliteeti võrreldes erinevate lähtemeetodite kogumiga.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>درون یک منبع اطلاعات معمولی استفاده می‌کنند که فرصت برای کالیبران بیشتری با استفاده از دانش خارجی استفاده می‌کنند. این کاغذ یک چهارچوب متحده را نشان می دهد که پیش از آموزش یافته یا خارجی را به شکل یک قانونی‌کننده، برای افزایش یادگیری‌های متحده به مدل زبان معمولی تحت تاثیر قرار می‌دهد. ما دو نوع معمولی را در نظر می گیریم. اولین نوع از توزیع موضوع با اجرای LDA در داده‌های نامزدی به دست آورده می‌شود. نوع دوم بر اساس واژه‌هایی است که با تلاش‌های اظهار انسان آفریده می‌شوند. برای موفقیت با معمولی یاد گرفتن با معمولی، ما یک ساختار داده های رمانی را پیشنهاد می کنیم، مسیر نرم ماکس، در این کاغذ. پیوند‌های نتیجه‌ای به عنوان کلمه شبیه‌ای و کلمه‌های احساسات ارزیابی می‌شوند. نتیجه‌های تجربه‌ی ما نشان می‌دهد که چهارچوب یادگیری ما با ساده‌سازی از دانش‌های قبلی در مجموعه‌های داده‌های متعدد، در مقایسه با مجموعه‌های متفاوتی از روش‌های بنیادی بهتر می‌شود.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tavanomaisia sanaupotuksia koulutetaan erityisillä kriteereillä (esim. kielimallinnukseen tai rinnakkaisesiintymiseen) yhden tietolähteen sisällä ottamatta huomioon mahdollisuutta kalibroida edelleen ulkoisen tiedon avulla. Tässä artikkelissa esitellään yhtenäinen viitekehys, joka hyödyntää ennalta opittuja tai ulkoisia prioriteetteja säännöstelijän muodossa perinteisen kielimallipohjaisen upotusoppimisen parantamiseksi. Meillä on kahdenlaisia laillistajia. Ensimmäinen tyyppi johdetaan aihejakaumasta ajamalla LDA:ta merkitsemättömille tiedoille. Toinen tyyppi perustuu sanakirjoihin, jotka on luotu inhimillisillä huomautuksilla. Jotta säännöstelijöiden kanssa voitaisiin oppia tehokkaasti, ehdotamme tässä artikkelissa uutta datarakennetta, trajectory softmax. Tuloksena olevia upotuksia arvioidaan sanojen samankaltaisuuden ja tunteiden luokittelun perusteella. Kokeelliset tulokset osoittavat, että oppimiskehyksemme, jossa on säännönmukainen aikaisemmasta tiedosta, parantaa useiden tietokokonaisuuksien upottamisen laatua verrattuna moniin perusaikataulumenetelmien kokoelmaan.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Les intégrations de mots classiques sont formées avec des critères spécifiques (par exemple, basés sur la modélisation du langage ou la co-occurrence) au sein d'une source d'information unique, sans tenir compte de la possibilité d'un étalonnage supplémentaire à l'aide de connaissances externes. Cet article présente un cadre unifié qui tire parti des antécédents pré-appris ou externes, sous la forme d'un régularisateur, pour améliorer l'apprentissage par intégration basé sur un modèle de langage conventionnel. Nous considérons deux types de régularisateurs. Le premier type est dérivé de la distribution de sujets en exécutant LDA sur des données non étiquetées. Le second type est basé sur des dictionnaires créés avec des efforts d'annotation humaine. Pour apprendre efficacement avec les régularisateurs, nous proposons dans cet article une nouvelle structure de données, la trajectoire softmax. Les intégrations obtenues sont évaluées en fonction de la similitude des mots et de la classification des sentiments. Les résultats expérimentaux montrent que notre cadre d'apprentissage avec régularisation à partir de connaissances antérieures améliore la qualité de l'intégration dans de multiples ensembles de données, par rapport à un ensemble diversifié de méthodes de base.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Cuirtear oiliúint ar ghnáthchaibidlí focal le critéir shonracha (m.sh., bunaithe ar shamhaltú teanga nó comhtharlú) laistigh d’fhoinse amháin faisnéise, agus neamhaird á tabhairt ar an deis le haghaidh calabrú breise ag baint úsáide as eolas seachtrach. Cuireann an páipéar seo i láthair creat aontaithe a ghiaráil tosaíochtaí réamhfhoghlaim nó seachtracha, i bhfoirm rialtatóir, chun feabhas a chur ar ghnáthfhoghlaim teanga bunaithe ar leabú teanga. Breithnímid dhá chineál rialtaitheoirí. Díorthaítear an chéad chineál ó dháileadh topaicí trí LDA a rith ar shonraí neamhlipéadaithe. Tá an dara cineál bunaithe ar fhoclóirí a chruthaítear le hiarrachtaí anótála daonna. Chun foghlaim go héifeachtach leis na rialtaitheoirí, molaimid struchtúr sonraí nua, trajectory softmax, sa pháipéar seo. Déantar na leabú mar thoradh air a mheas trí chosúlacht focal agus aicmiú meon. Léiríonn torthaí turgnamhacha go bhfeabhsaítear ár gcreat foghlama le rialtacht ó réamheolas ar cháilíocht leabú thar il-thacair sonraí, i gcomparáid le bailiúchán éagsúil de mhodhanna bonnlíne.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>An sanar da maganar da ke ƙunsa da kayan ƙayyade masu ƙayyade (misali, a kan motsi da misalin harshe ko da tsohon da ke koma) cikin wani sourcen maɓalli guda, kuma ana ƙyale fursa wa kalarin da ke amfani da ilmi na ƙarƙasan. Wannan takardar na bãyar da wani firam wanda ya haɗu da shi wanda ke ƙara gaba-da-baro ko bakin-gaba, cikin the form of a Rurizor, dõmin ya ƙara wa zane-zane-da-bakin ayuka na ɗabi'a. Tuna ganin wasu nau'i biyu. @ action: button Nau'in na biyu, yana kan karatun dictionaries wanda aka halitta da aikin zartar mutane. To, dõmin a sanar da masu inganci, sai mu buƙata wani matsayin data na yanzu, matsayin hanya, cikin wannan takarda. Ana ƙaddara masu ƙaranci da aka daidaita magana da sifilawa. Matarin da aka jarraba, ya nuna firam masu karanta da jurisdictori daga gabãnin wani ilmi ya improve tsarin faɗi a kowace data-set-daban, kuma a sammeniyar da misãlai masu haɗi ko-jama'a-biyu.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>תוספת מילים מסורתיות מאומנות עם קריטורים ספציפיים (למשל, מבוססים על דוגמנית שפה או התרחשות משותפת) בתוך מקור מידע אחד, מתעלמים מההזדמנות לקליברציה נוספת באמצעות ידע חיצוני. המסמך הזה מציג מסגרת מאוחדת שמשתמשת על קודמות קודמות מלמדות או חיצוניים, בצורה של חוקית, כדי לשפר את הלימוד המבוסס על מודל שפה קונבנציונציאלי. אנחנו שוקלים שני סוגים של חוקים. הטיפוס הראשון מושג מהפיצוץ הנושא על ידי הפעלת LDA על נתונים ללא סימנים. The second type is based on dictionaries that are created with human annotation efforts. כדי ללמוד באופן יעיל עם המפקדים, אנו מציעים מבנה נתונים חדש, מסלול softmax, בעיתון הזה. המערכות הנוצאות מוערכות על ידי דמיון מילים וסימון רגשות. תוצאות ניסויים מראות שמסגרת הלימודים שלנו עם התקנה מידע קודם משפר את הכניסה של איכות בין קבוצות נתונים רבות, בהשוואה לאספת מיוחדת של שיטות בסיסיות.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>पारंपरिक शब्द एम्बेडिंग को एक ही सूचना स्रोत के अंदर विशिष्ट मानदंडों (उदाहरण के लिए, भाषा मॉडलिंग या सह-घटना के आधार पर) के साथ प्रशिक्षित किया जाता है, बाहरी ज्ञान का उपयोग करके आगे के अंशांकन के अवसर की अनदेखी की जाती है। यह पेपर एक एकीकृत रूपरेखा प्रस्तुत करता है जो पारंपरिक भाषा मॉडल-आधारित एम्बेडिंग सीखने को बढ़ाने के लिए, एक नियमितकर्ता के रूप में पूर्व-सीखा या बाहरी प्राथमिकताओं का लाभ उठाता है। हम दो प्रकार के रेगुलराइज़र पर विचार करते हैं। पहला प्रकार बिना लेबल वाले डेटा पर LDA चलाकर विषय वितरण से व्युत्पन्न है. दूसरा प्रकार शब्दकोशों पर आधारित है जो मानव एनोटेशन प्रयासों के साथ बनाए जाते हैं। नियमितकरने वालों के साथ प्रभावी ढंग से जानने के लिए, हम इस पेपर में एक उपन्यास डेटा संरचना, प्रक्षेपवक्र सॉफ्टमैक्स का प्रस्ताव करते हैं। परिणामी एम्बेडिंग का मूल्यांकन शब्द समानता और भावना वर्गीकरण द्वारा किया जाता है। प्रयोगात्मक परिणामों से पता चलता है कि पूर्व ज्ञान से नियमितीकरण के साथ हमारा सीखने का ढांचा बेसलाइन विधियों के विविध संग्रह की तुलना में कई डेटासेट में एम्बेडिंग गुणवत्ता में सुधार करता है।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Uvježbanje konvencionalnih riječi obučeno je s specifičnim kriterijama (na primjer na temelju modeliranja jezika ili saradnje) unutar jednog izvora informacija, bez obzira na mogućnost daljnje kalibracije koristeći vanjske znanje. Ovaj papir predstavlja ujedinjeni okvir koji utječe na predučenje ili vanjske prije, u obliku regularizatora, za poboljšanje konvencionalnog jezičkog model a osnovanog učenja. Smatramo dva vrsta regularizatora. Prvi tip je proizveden iz distribucije teme pokrenući LDA na neizbiljnim podacima. Drugi tip se temelji na riječi koje su stvorene naporima ljudskih annotacija. Da bi se učili s regularizatorima, predlažemo novu strukturu podataka, trajektoriju softmax, u ovom papiru. Rezultativne integracije procjenjuju sličnost riječima i klasifikacija osjećaja. Eksperimentalni rezultati pokazuju da naš okvir učenja s regularizacijom prije znanja poboljšava uključenje kvalitete u više podataka u usporedbi s različitim kolekcijom početnih metoda.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A hagyományos szóbeágyazásokat konkrét kritériumokkal (például nyelvi modellezés vagy együttes előfordulás alapján) képezik egyetlen információforráson belül, figyelmen kívül hagyva a további kalibrálás lehetőségét külső ismeretek felhasználásával. Ez a tanulmány egy olyan egységes keretrendszert mutat be, amely a hagyományos nyelvmodelleken alapuló beágyazási tanulás javításához használja az előre megtanult vagy külső priuszokat, szabályozó formájában. Kétféle szabályozót veszünk figyelembe. Az első típus a témalelosztásból származik, úgy, hogy LDA futtatása címke nélküli adatokon történik. A második típus olyan szótárakra épül, amelyeket emberi jegyzetelési erőfeszítésekkel hoztak létre. A szabályozókkal való hatékony tanulás érdekében ebben a tanulmányban egy új adatszerkezetet, pálya softmax-ot javasolunk. A kapott beágyazásokat szóhasonlóság és hangulatosztályozás alapján értékeljük. Kísérleti eredmények azt mutatják, hogy a korábbi ismeretekből származó szabályozással rendelkező tanulási keretrendszerünk javítja a beágyazás minőségét több adatkészletben, összehasonlítva az alapvető módszerek sokféle gyűjteményével.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Հավանդական բառերի ներդրումը սովորեցվում է հատուկ չափումներով (օրինակ, հիմնված լեզվի մոդելավորման կամ համապատասխանատվության վրա) մեկ տեղեկատվական աղբյուրի մեջ, անտեսելով այն հնարավորությունը, որ ապագայում կալիբրացվի արտաքին գիտելիքների Այս թղթին ներկայացնում է միասնական շրջանակ, որը ազդում է նախկին սովորված կամ արտաքին նախաձեռնություններին, օրինադրողի ձևով, ավանդական լեզվի մոդել հիմնված ուսումնասիրության բարելավման համար: Մենք դիտարկում ենք երկու տեսակի կանոնավորողներ: Առաջին տեսակը ստացվում է թեմայի բաշխման միջոցով, երբ սկսում է աշխատել ԼԴԱ-ն աննշան տվյալների վրա: Երկրորդ տեսակը հիմնված է բառարանների վրա, որոնք ստեղծվում են մարդկային նշումների միջոցով: Այս թղթի մեջ արդյունավետ սովորելու համար մենք առաջարկում ենք նոր տվյալների կառուցվածք, շարժման ծրագիր: Արդյունքում ստացված ներդրումները գնահատվում են բառի նմանության և զգացմունքների դասակարգման միջոցով: Փորձարկվող արդյունքները ցույց են տալիս, որ մեր ուսումնական շրջանակը նախկին գիտելիքներից վերահսկվող կարգավորման հետ բարելավում է բազմաթիվ տվյալների համակարգերի որակը, համեմատած հիմնական մեթոդների բազմաթիվ հավաքածուի</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Pencampuran kata konvensional dilatih dengan kriteria spesifik (contohnya, berdasarkan model bahasa atau korespondensi) di dalam sumber informasi tunggal, mengabaikan kesempatan untuk kalibrasi lanjut menggunakan pengetahuan luar. Kertas ini mempersembahkan rangkaian yang bersatu yang mempengaruhi masa depan pre-belajar atau eksternal, dalam bentuk regulariser, untuk meningkatkan pembelajaran berbasis model bahasa konvensional. Kami mempertimbangkan dua jenis regulariser. Tipe pertama didirikan dari distribusi topik dengan menjalankan LDA pada data tidak ditabel. Jenis kedua berdasarkan kamus yang diciptakan dengan usaha anotasi manusia. Untuk mempelajari secara efektif dengan regularisers, kami mengusulkan struktur data baru, trajektori softmax, di kertas ini. Pencampuran hasilnya diuji dengan persamaan kata dan klasifikasi sentimen. Hasil eksperimen menunjukkan bahwa kerangka belajar kita dengan regularisasi dari pengetahuan sebelumnya meningkatkan kualitas penerbangan di berbagai set data, dibandingkan dengan koleksi berbagai metode dasar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Le incorporazioni convenzionali di parole vengono addestrate con criteri specifici (ad esempio, basati sulla modellazione linguistica o sulla co-occorrenza) all'interno di una singola fonte di informazioni, trascurando l'opportunità di ulteriore calibrazione utilizzando conoscenze esterne. Questo articolo presenta un framework unificato che sfrutta precedenti pre-appresi o esterni, sotto forma di regolarizzazione, per migliorare l'apprendimento basato su modelli linguistici convenzionali. Consideriamo due tipi di regolarizzatori. Il primo tipo deriva dalla distribuzione degli argomenti eseguendo LDA su dati non etichettati. Il secondo tipo si basa su dizionari creati con sforzi umani di annotazione. Per imparare efficacemente con i regolarizzatori, proponiamo una nuova struttura dati, traiectory softmax, in questo articolo. Le incorporazioni risultanti sono valutate per somiglianza di parole e classificazione sentiment. I risultati sperimentali mostrano che il nostro framework di apprendimento con regolarizzazione da conoscenze precedenti migliora la qualità di incorporamento in più set di dati, rispetto a una raccolta diversificata di metodi di base.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>従来の単語埋め込みは、外部知識を使用してさらなる較正を行う機会を無視して、単一の情報源内の特定の基準（例えば、言語モデリングまたは同時発生に基づく）で訓練される。 本稿では，従来の言語モデルに基づく埋め込み学習を強化するための規則化の形で，事前に学習されたまたは外部の前歴を活用する統一されたフレームワークを提示する． 2種類のレギュラー化を検討しています。 最初のタイプは、ラベル付けされていないデータ上でLDAを実行することによってトピック分布から導出されます。 2つ目のタイプは、人間の注釈の努力で作成された辞書に基づいています。 レギュレータで効果的に学習するために、本稿では新規のデータ構造である軌道ソフトマックスを提案する。 結果として生じる埋め込みは、単語の類似性と感情の分類によって評価されます。 実験結果は、既存の知識から規則化された学習フレームワークが、ベースライン法の多様なコレクションと比較して、複数のデータセットにわたる埋め込み品質を向上させることを示しています。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>embedding Perintah iki nggawe akeh nesaturan sing paling-nesaturan sing rumangsa akeh banter, ngono nggawe barang langkung sampek kudu nggawe gerakan ingkang. Awak dhéwé sawetara duwé Tipe tualke kang tanggal Distribusi Tema nang data Gak Bukak Tipe wis digawe sing basa ning diktualisar sing dumadhi karo dolanan sing dadi populer. Awak dhéwé nggambar aturan biasane gagal, kéné ngerasakno dadi nggawe datadir, trajector software, ning basa iki. gambar Reulti sing paling-peringatan nganggep kuwi awak dhéwé sisané awak dhéwé karo sistem sing beraksi kanggo awak dhéwé kuwi tindakan akeh perusahaan karo dataset sing butawak dhéwé, ngrebut karo akeh sampek akeh perusahaan sistem sing sus</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>განსაკუთრებული სიტყვები კრიტირებით (მაგალითად, ენის მოდელირება ან ერთადერთი მოხდება) ერთადერთი ინფორმაციის გამოსახულებაში შემდეგ კალიბრაციის შესაძლებლობა გარეშე გამოიყენება. ეს დაახლოები ახლა ერთადერთი ფრამეტრი, რომელიც წინასწავლის ან გარეშე წინასწავლის ფორმაში, რეგილარიზერის ფორმაში, რომელიც კონტრაციონალური ენის მოდელური მოდელური გარეშე სწ ჩვენ ვფიქრობთ ორი ტიპი რეგილარიზაციელი. პირველი ტიპი ტემების გაყოფილებიდან დაიწყება LDA- ს გადაწყებით, რომელიც არაწერილი მონაცემებზე. მეორე ტიპი ადამიანის წარმოდგენებით შექმნილი სიტყვების დაბაზია. ეფექტიურად დავისწავლოთ რეგილარიზერებთან, ჩვენ პრომენტის მონაცემების სტრუქტურაციას, ტრაექტური softmax, ამ დონეში. შემდეგ შემდეგ სიტყვების სხვადასხვა და სენტიმენტის კლასიფიკაციაზე გაუმუშავება. ექსპერიმენტიური შედეგები ჩვენი სწავლების ფრამეტრის რეგილარიზაციაზე წინასწორედ ცნობილიდან უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უფრო უ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Кәдімгі сөздерді ендіру бір мәлімет көзінде бір түрлі мәлімет көзінде (мысалы, тілдерді моделдеу немесе бір түрлі көзінде негізделген) арнаулы критериялармен ұқытылады, сыртқы білім Бұл қағаз алдын- үйренген немесе сыртқы алдын- ала үйренген бірлікті фреймді, әдетті тіл үлгіні негізінде ендірген оқыту үшін үлгілікті көтеру үшін қолданылады. Біз екі түрлі қадамдастырушылар деп ойлаймыз. Бірінші түрі нақышты үлестіруден LDA- ды келтірілмеген деректерге жегіп шығарылады. Екінші түрі адамдардың жазбалармен құрылған сөздіктеріне негізделген. Үлгілі түрлермен үйрену үшін, бұл қағаздың романдық деректер құрылымын, траекториялық бағдарламалық максимумын таңдаймыз. Сондағы ендірулерді сөздердің ұқсас пен сезімдердің классификациясы бойынша бағалады. Эксперименталдық нәтижелері білім алдындағы мәліметтерден өзгертілген оқыту бағдарламасы бірнеше деректер бағдарламасының салыстыру сапасына салыстырады.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>특정 정보원을 바탕으로 하는 모델링(예를 들어 외부 정보원을 바탕으로 하는 모델링)이나 특정 정보원을 바탕으로 하는 모델링(예를 들어 외부 정보원을 바탕으로 하는 모델링).본고는 통일된 틀을 제시했다. 이 틀은 정규화기의 형식으로 사전 학습이나 외부 선험 지식을 이용하여 전통적인 언어 모델을 바탕으로 하는 삽입 학습을 강화한다.우리는 두 가지 정규화자를 고려한다.첫 번째 유형은 표시되지 않은 데이터에서 LDA를 실행함으로써 테마 분포에서 파생됩니다.두 번째는 인공 주석을 바탕으로 만든 사전이다.정규화기를 효과적으로 사용하여 학습을 하기 위해 본고는 새로운 데이터 구조인 궤적softmax를 제시했다.단어의 싱크로율과 감정 분류를 통해 삽입 결과를 평가한다.실험 결과에 따르면 여러 가지 기선 방법에 비해 선험지식을 바탕으로 하는 정규화 학습 구조는 여러 데이터 집합의 삽입 품질을 향상시켰다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Įprasti žodžių įterpimai rengiami taikant konkrečius kriterijus (pvz., remiantis kalbų modeliavimu arba bendra pasikartojimu) vieno informacijos šaltinio viduje, neatsižvelgiant į galimybę toliau kalibruoti naudojant išorines žinias. Šiame dokumente pateikiama bendra sistema, kuria reguliarizuojamas iš anksto išmokytas ar išorinis ankstesnis mokymasis, siekiant pagerinti tradiciniu kalbų modeliu pagrįstą įterpiamąjį mokymąsi. Mes svarstome dviejų rūšių reguliatorius. Pirmasis tipas gaunamas iš teminio paskirstymo naudojant LDA be žymės duomenis. The second type is based on dictionaries that are created with human annotation efforts. Siekiant veiksmingai mokytis su reguliarizatoriais, šiame dokumente siūlome naują duomenų struktūrą, trajektorijos softmax. Atitinkamos įterptos vertinamos pagal žodžių panašumą ir jausmų klasifikaciją. Eksperimentiniai rezultatai rodo, kad mūsų mokymosi sistema, reguliuojama iš ankstesnių žinių, gerina kokybę įvairiuose duomenų rinkiniuose, palyginti su įvairiais baziniais metodais.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Конвенционалните зборови се обучуваат со специфични критериуми (на пример, базирани на јазичното моделирање или соопштено појавување) во еден извор на информации, отфрлајќи ја можноста за понатамошна калибрација користејќи надворешно знаење. Овој документ претставува унифицирана рамка која влијае на преднаучените или надворешните предходни случаи, во форма на регуларизација, за подобрување на учењето базирано на конвенционалниот јазик модел. Размислуваме за два вида регуларизачи. The first type is derived from topic distribution by running LDA on unlabeled data. Вториот тип се базира на речници кои се создадени со напори за човечка анотација. За ефикасно да научиме со регулаторизаторите, предложуваме нова структура на податоци, траекторија софтмакс, во овој весник. Резултатите на вградувањата се проценуваат со сличност на зборовите и класификација на чувствата. Експерименталните резултати покажуваат дека нашата рамка за учење со регуларизација од претходното знаење го подобрува вклопувањето на квалитетот во повеќе податоци, во споредба со различна колекција на основни методи.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>സാധാരണ വാക്കുകള്‍ പ്രത്യേക പരിശീലിക്കപ്പെടുന്നു This paper presents a unified framework that leverages pre-learned or external priors, in the form of a regularizer, for enhancing conventional language model-based embedding learning. നമ്മള്‍ രണ്ടു തരം നിയന്ത്രണക്കാരെ വിചാരിക്കുന്നു. ലേബല്‍ ചെയ്യാത്ത വിവരങ്ങളില്‍ LDA പ്രവര്‍ത്തിപ്പിക്കുന്നതില്‍ നിന്ന് ആദ്യ തരം ലഭ്യമാക്കുന്നു. രണ്ടാമത്തെ തരം മനുഷ്യരുടെ പ്രശ്നം കൊണ്ട് സൃഷ്ടിക്കപ്പെട്ട നിഘണ്ടികൾ അടിസ്ഥാനമാണ്. നിയന്ത്രണക്കാരുടെ കൂടെ പഠിക്കാന്‍ ഞങ്ങള്‍ ഒരു നോവല്‍ ഡേറ്റാ ഘടനയില്‍, ട്രാക്ടോക്ടറിന്റെ സോഫ്റ്റ്മാക്സ് ഈ പത് അതിന്റെ ഫലങ്ങള്‍ വാക്കിന്റെ തുല്യമാക്കുന്നതിന്റെയും വാക്കിന്റെയും തീരുമാനത്തിന്റെയും ക്ലാസ്ഫി പരീക്ഷണ ഫലങ്ങള്‍ കാണിച്ചു കൊണ്ടിരിക്കുന്നു നമ്മുടെ പഠിക്കുന്ന ഫ്രെയിമ്പില്‍ നിന്നും മുമ്പുള്ള വിജ്ഞാനത്തിന്റെ നിയന്ത്രണ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Нэг мэдээллийн эх үүсвэр дотор тодорхой хэл загвар (жишээ нь хэл загвар болон хамтран үйлдвэрлэх) тодорхой шаардлагатай үг бий болгож, гадаад мэдээллийг ашиглаж дахиад калибр хийх боломжтой боломжтой боломжтой Энэ цаас урьд суралцах эсвэл гадаад суралцагчийн хэлбэрийн загварын сургалтыг улам сайжруулахын тулд нэгтгэлтэй хэлбэрийг харуулдаг. Бид хоёр төрлийн жинхэнэ хэлбэрийг боддог. Эхний төрлийн нь сэдвийн хуваарилалт гаргасан мэдээллээр LDA-г ашиглаж ирсэн юм. Хоёр дахь төрлийн нь хүн төрөлхтний сэтгэл хөдлөл дээр бий болгосон үгсэлтүүд дээр суурилсан. Эцэст нь энгийн хүмүүстэй суралцахын тулд бид энэ цаасан дээр шинэ өгөгдлийн бүтэц, салбарын салбарын максимум гэдгийг санал дэвшүүлнэ. Үүний үр дүнг нь үг төстэй болон сэтгэл хөдлөлийн хуваалцаанд үнэлдэг. Эмчилгээний үр дүнд бидний суралцах үйл ажиллагааны үйл ажиллагааг өмнөх мэдлэгийнхээ хувьд олон өгөгдлийн сангийн хэлбэрээс харьцуулахын тулд бидний суралцах үйл ажиллагааны үйл ажиллагаа</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Pencampuran perkataan konvensional dilatih dengan kriteria khusus (cth., berdasarkan pemodelan bahasa atau kejadian sama) di dalam sumber maklumat tunggal, mengabaikan peluang untuk kalibrasi lanjut menggunakan pengetahuan luaran. Kertas ini memperkenalkan kerangka bersatu yang menggunakan latar belajar awal atau luaran, dalam bentuk pengaturan, untuk meningkatkan pembelajaran berbasis model bahasa konvensional. Kami mempertimbangkan dua jenis pengaturan. Jenis pertama dihimpunkan dari distribusi topik dengan menjalankan LDA pada data tidak ditabel. Jenis kedua berdasarkan kamus yang dicipta dengan usaha anotasi manusia. To effectively learn with the regularizers, we propose a novel data structure, trajectory softmax, in this paper. Pencampuran yang menghasilkan diteliti dengan persamaan perkataan dan klasifikasi perasaan. Hasil percubaan menunjukkan bahawa kerangka pembelajaran kami dengan pengaturan dari pengetahuan terdahulu meningkatkan kualiti penyampaian dalam set data berbilang, dibandingkan dengan koleksi berbeza kaedah dasar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>L-inkorporazzjonijiet konvenzjonali tal-kliem huma mħarrġa b’kriterji speċifiċi (pereżempju, ibbażati fuq mudell tal-lingwa jew kookkorrenza) ġewwa sors wieħed ta’ informazzjoni, filwaqt li tiġi injorata l-opportunità g ħal aktar kalibrazzjoni bl-użu ta’ għarfien estern. Dan id-dokument jippreżenta qafas unifikat li jagħti spinta lill-prijoritajiet ta’ qabel it-tagħlim jew dawk esterni, fil-form a ta’ regolarizzatur, għat-titjib tat-tagħlim inkorporat ibbażat fuq mudell ta’ lingwa konvenzjonali. Aħna nqisu żewġ tipi ta’ regolaturi. L-ewwel tip huwa derivat mid-distribuzzjoni suġġetta billi jitħaddem l-LDA fuq dejta mingħajr tikketta. It-tieni tip huwa bbażat fuq dikjaraturi li jinħolqu bl-isforzi ta’ annotazzjoni umana. Biex nitgħallmu b’mod effettiv mar-regolarizzaturi, qed nipproponu struttura ġdida ta’ dejta, trajettorja softmax, f’dan id-dokument. L-inkorporazzjonijiet li jirriżultaw huma evalwati skont is-similarità tal-kelma u l-klassifikazzjoni tas-sentimenti. Riżultati esperimentali juru li l-qafas tagħna ta’ tagħlim bir-regolarizzazzjoni minn għarfien minn qabel itejjeb l-inkorporazzjoni tal-kwalità f’settijiet ta’ dejta multipli, meta mqabbel ma’ ġbir diversifikat ta’ metodi ta’ bażi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Conventionele woordinsluitingen worden getraind met specifieke criteria (bijvoorbeeld op basis van taalmodellering of co-voorkomen) binnen één enkele informatiebron, waarbij de mogelijkheid tot verdere kalibratie met behulp van externe kennis buiten beschouwing wordt gelaten. Dit document presenteert een uniform raamwerk dat gebruik maakt van vooraf geleerde of externe priors, in de vorm van een regularizer, voor het verbeteren van conventioneel taalmodel gebaseerd embedded learning. We beschouwen twee soorten regularisers. Het eerste type is afgeleid van topic distributie door LDA uit te voeren op gegevens zonder label. Het tweede type is gebaseerd op woordenboeken die zijn gemaakt met menselijke annotatie inspanningen. Om effectief te leren met de regularizers, stellen we in dit artikel een nieuwe datastructuur voor, trajectory softmax. De resulterende embeddings worden geëvalueerd op basis van woordgelijkenis en sentimentclassificatie. Experimentele resultaten tonen aan dat ons leerframework met regularisatie van voorkennis de kwaliteit van het inbedden in meerdere datasets verbetert, in vergelijking met een diverse verzameling basismethoden.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Innbygging av vanleg ord er utlært med spesifikke kriterier (f.eks. basert på språk modellering eller samtidig oppgåve) i ein enkelt informasjonskjelde, utan hending av muligheten for meir kalibrering ved å bruka eksterne kunnskap. Denne papiret viser eit einaste rammeverk som leverer førelærte eller eksterne førehandsvisingar, i form av eit regulært, for å forbetra konvensjonell språk-modell basert innbygging. Vi ser på to typar regulærar. Den første typen er henta frå temafordelinga ved å køyra LDA på ukjende data. Den andre typen er basert på ordbokar som er oppretta med menneske merknader. For å lære effektivt med regulære, foreslår vi eit nytt datastruktur, trajectory softmax i denne papiret. Dette resultatet innbygginga er evaluert etter ordsimilaritet og sentimentklassifikasjon. Eksperimentale resultat viser at læringsrammeverket vår med reguleringa frå førre kunnskap forbetrar innbyggingskvalitet over fleire datasett, sammenlignet med ein ulike samling av baselinjesmetodar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Konwencjonalne osadzenia słów są szkolone według określonych kryteriów (np. w oparciu o modelowanie językowe lub współwystępowanie) wewnątrz jednego źródła informacji, pomijając możliwość dalszej kalibracji z wykorzystaniem wiedzy zewnętrznej. Niniejszy artykuł przedstawia ujednolicone ramy, które wykorzystują wcześniej nauczone lub zewnętrzne priorytety, w postaci regularyzatora, do poprawy konwencjonalnego modelu językowego nauczania się osadzania. Rozważamy dwa rodzaje regulatorów. Pierwszy typ pochodzi z dystrybucji tematów poprzez uruchomienie LDA na danych nieoznakowanych. Drugi typ opiera się na słownikach tworzonych przy użyciu człowieka adnotacji. Aby skutecznie uczyć się z regulatorami, proponujemy w niniejszym artykule nową strukturę danych, trajektorię softmax. Wynikające z nich osadzenia oceniane są według klasyfikacji podobieństwa słów i sentymentów. Wyniki eksperymentalne pokazują, że nasze ramy uczenia się z regularyzacją z wcześniejszej wiedzy poprawiają jakość osadzenia w wielu zbiorach danych, w porównaniu do zróżnicowanego zbioru metod bazowych.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Embeddings de palavras convencionais são treinados com critérios específicos (por exemplo, com base em modelagem de linguagem ou co-ocorrência) dentro de uma única fonte de informação, desconsiderando a oportunidade de calibração adicional usando conhecimento externo. Este artigo apresenta uma estrutura unificada que utiliza prioris pré-aprendidos ou externos, na forma de um regularizador, para aprimorar o aprendizado de incorporação baseado em modelo de linguagem convencional. Consideramos dois tipos de regularizadores. O primeiro tipo é derivado da distribuição de tópicos executando LDA em dados não rotulados. O segundo tipo é baseado em dicionários que são criados com esforços humanos de anotação. Para aprender efetivamente com os regularizadores, propomos uma nova estrutura de dados, trajetória softmax, neste artigo. Os embeddings resultantes são avaliados por similaridade de palavras e classificação de sentimento. Os resultados experimentais mostram que nossa estrutura de aprendizado com regularização de conhecimento prévio melhora a qualidade da incorporação em vários conjuntos de dados, em comparação com uma coleção diversificada de métodos de linha de base.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Încorporările convenționale de cuvinte sunt instruite cu criterii specifice (de exemplu, pe baza modelării limbajului sau a co-apariției) într-o singură sursă de informații, ignorând posibilitatea de calibrare ulterioară utilizând cunoștințe externe. Această lucrare prezintă un cadru unificat care valorifică antecedentele pre-învățate sau externe, sub forma unui regularizator, pentru îmbunătățirea învățării bazate pe modele lingvistice convenționale. Considerăm două tipuri de regularizatori. Primul tip este derivat din distribuția subiectului prin rularea LDA pe date fără etichete. Al doilea tip se bazează pe dicționare care sunt create cu eforturi umane de adnotare. Pentru a învăța eficient cu regularizatorii, propunem o nouă structură de date, traiectoria softmax, în această lucrare. Încorporările rezultate sunt evaluate prin similitudinea cuvintelor și clasificarea sentimentului. Rezultatele experimentale arată că cadrul nostru de învățare cu regularizare din cunoștințe anterioare îmbunătățește calitatea încorporării în mai multe seturi de date, comparativ cu o colecție diversă de metode de bază.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Традиционные вставки слов обучаются с помощью конкретных критериев (например, на основе языкового моделирования или совместного возникновения) внутри одного источника информации, игнорируя возможность дальнейшей калибровки с использованием внешних знаний. В этой статье представлена унифицированная структура, которая использует заранее изученные или внешние притязания в форме регуляризатора для улучшения обучения внедрению на основе моделей обычного языка. Мы рассматриваем два типа регуляризаторов. Первый тип получается из распределения топиков путем запуска LDA на немеченных данных. Второй тип основан на словарях, которые создаются с помощью человеческих аннотаций. Чтобы эффективно учиться с регуляризаторами, мы предлагаем новую структуру данных, траекторию softmax, в этой работе. Полученные вложения оцениваются по сходству слов и классификации настроений. Экспериментальные результаты показывают, что наша система обучения с регуляризацией на основе предшествующих знаний улучшает качество встраивания множества наборов данных по сравнению с разнообразным набором базовых методов.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>සාමාන්‍ය වචන සම්බන්ධ වචන සිද්ධ විශේෂ අවශ්‍ය (උදාහරණය, භාෂාව මොඩේලන් හෝ සම්බන්ධ වෙනුවෙන්) එක්ක තොරතුරු මූල්‍යයක මේ පත්තුව පෙන්වන්නේ සාමාන්‍ය භාෂාව ප්‍රධානය සඳහා ප්‍රධානයක් හෝ ප්‍රධානයක් ප්‍රධානය කරනවා. අපි හිතන්නේ සාමාන්‍ය වැඩකරු දෙකක් වගේ. පළවෙනි වර්ගයක් තේරුම් විතරයෙන් ලිපින්න බැරි දත්තේ LDA දාලා යනවා. දෙවෙනි වර්ගයක් මිනිස්සු ප්‍රශ්නයක් සඳහා නිර්මාණය කරලා තියෙන වචන වචන වලට අධාරිත වෙනව සාමාන්‍ය විදියට ඉගෙන ගන්න, අපි නියම දත්ත සංවිධානයක් ප්‍රයෝජනය කරනවා, මේ පත්තියේ ප්‍රයෝජනයක්. ප්‍රතිචාරය සම්බන්ධතාවක් වචනය සහ විශේෂතාවක් වලින් විශේෂය කරනවා. පරීක්ෂණාත්මක ප්‍රතිචාරයක් පෙන්වනවා අපේ ඉගෙන ගන්න ප්‍රතිචාරය ප්‍රතිචාරයක් ප්‍රතිචාරයෙන් ප්‍රතිචාරයෙන්</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Običajne vgradnje besed se usposabljajo s posebnimi merili (npr. na podlagi jezikovnega modeliranja ali sočasnega pojava) znotraj enega samega vira informacij, pri čemer se ne upošteva možnost nadaljnje kalibracije z uporabo zunanjega znanja. Ta prispevek predstavlja enoten okvir, ki izkorišča vnaprej učene ali zunanje predhodne predhodne naloge v obliki urejevalnika za izboljšanje vključevanja učenja, ki temelji na običajnih jezikovnih modelih. Razmišljamo o dveh vrstah regulatorjev. Prva vrsta je izpeljana iz porazdelitve teme z zagonom LDA na neoznačenih podatkih. Druga vrsta temelji na slovarjih, ki so ustvarjeni s človeškimi pripombami. Za učinkovito učenje z regulatorji v tem prispevku predlagamo novo strukturo podatkov, trajectory softmax. Nastale vdelave so ocenjene s podobnostjo besed in klasifikacijo sentimenta. Eksperimentalni rezultati kažejo, da naš učni okvir z ureditvijo iz predhodnega znanja izboljšuje kakovost vključevanja v več naborov podatkov v primerjavi z raznoliko zbirko osnovnih metod.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Hadalka ku soo socota waxaa lagu baraa kaarar gaar ah (tusaale ahaan tusaale ahaan muuqashada luuqada ama iskaasha ah) marka laga eego fursadda kalibsashada aqoonta dibadda lagu isticmaalo. Qoraalkan waxaa soo saara qoraal isku darsami ah oo horay u sii kordhiya barashada qoraalka afka caadiga ah oo ku qoran horay ama dibadda. Waxaynu ka fiirsanaynaa laba nooc oo xeerarka ah. Nooca ugu horreeya waxaa laga soo saaraa qaybinta madaxa lagu soo dirayo LDA oo ku qoran macluumaad aan la labeyn. Nooca labaad waxaa ku saleysan luqadaha lagu abuuray dhibaatooyinka dadka. Si aad u faa’iido ah u barto xeerarka, waxan warqadan uga soo jeedaynaa dhismo macluumaadka saxda ah, saqafka wadiiqooyinka dhaqdhaqaaqa. Xiriirka sababta ah waxaa lagu qiimeeyaa si siman u eg iyo kalsooni. Experimental results show that our learning framework with regularization from prior knowledge improves embedding quality across multiple datasets, compared to a diverse collection of baseline methods.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Përmbajtja e fjalëve konvencionale është trajnuar me kritere të posaçme (për shembull, bazuar në modelimin gjuhësor apo bashkëndodhjen) brenda një burimi të vetëm informacioni, duke harruar mundësinë për kalibrim të mëtejshëm duke përdorur njohuritë e jashtme. Ky dokument paraqet një kuadër të unifikuar që nxjerr përparësi të mësuara ose të jashtme, në form ën e një rregullatori, për përmirësimin e mësimit të ndërtimit të gjuhës konvencionale bazuar në model in e gjuhës. Ne konsiderojmë dy lloje rregullatorësh. Tipi i parë derivohet nga shpërndarja e temës duke ecur LDA në të dhëna pa etiketë. The second type is based on dictionaries that are created with human annotation efforts. Për të mësuar efektivisht me rregullatorët, ne propozojmë një strukturë të re të të dhënave, trajektori softmax, në këtë letër. Ndërtesat që rezultojnë vlerësohen nga ngjashmëria e fjalës dhe klasifikimi i ndjenjave. Rezultatet eksperimentale tregojnë se kuadri ynë i mësimit me rregullalizim nga njohuritë e mëparshme përmirëson përfshirjen e cilësisë nëpërmjet grupeve të të dhënave të shumta, krahasuar me një koleksion të ndryshëm të metodave bazë.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Konvencionalni integraciji reči obučeni su sa specifičnim kriterijama (na primjer na temelju modela jezika ili saradnje) unutar jednog izvora informacija, bez obzira na mogućnost daljnje kalibracije koristeći spoljno znanje. Ovaj papir predstavlja jedinstven okvir koji utiče na pre-naučene ili vanjske prethodne, u obliku regularizatora, za unapređenje konvencionalnog jezičkog model a osnovanog učenja. Smatramo dva vrsta regularizatora. Prvi tip je proizveden iz distribucije teme pokrenući LDA na neizbiljnim podacima. Drugi tip je baziran na rečnicima koje su stvorene naporima ljudskih annotacija. Da bi se efikasno naučili sa regularizatorima, predlažemo novu strukturu podataka, trajektoriju softmax, u ovom papiru. Rezultativne integracije procjenjuju sliènost rijeèi i klasifikacija sentimenta. Eksperimentalni rezultati pokazuju da naš okvir učenja sa regularizacijom iz prethodnog znanja poboljšava integraciju kvalitete na višestrukim podacima u usporedbi sa različitim kolekcijom početnih metoda.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Konventionella ordinbäddningar utbildas med specifika kriterier (t.ex. baserat på språkmodellering eller samtidig förekomst) inuti en enda informationskälla, bortsett från möjligheten till ytterligare kalibrering med hjälp av extern kunskap. Denna uppsats presenterar ett enhetligt ramverk som utnyttjar förkunna eller externa prioriteringar, i form av en regularizer, för att förbättra konventionellt språkmodellbaserat inbäddande lärande. Vi betraktar två typer av regularisers. Den första typen härleds från ämnesdistribution genom att köra LDA på omärkta data. Den andra typen är baserad på ordböcker som skapas med mänskliga anteckningar ansträngningar. För att effektivt lära sig med regularisers föreslår vi en ny datastruktur, traiectory softmax, i denna uppsats. De resulterande inbäddningarna utvärderas genom ordlikhet och sentimentklassificering. Experimentella resultat visar att vårt lärramverk med regularisering från tidigare kunskap förbättrar inbäddningskvaliteten över flera datauppsättningar, jämfört med en mängd olika baslinjemetoder.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Matambo ya kawaida yanafundishwa na vigezo maalum (kwa mfano, kwa kutumia mifano ya lugha au tukio la pamoja) ndani ya chanzo moja cha habari, wakipuuza fursa ya kupatikana kwa kutumia maarifa ya nje. Gazeti hili linaleta mfumo wa muungano unaoendelea kipaumbele cha kujifunza kabla au nje, kwa namna ya mtaalamu, kwa ajili ya kuongeza mfumo wa lugha ya kawaida wa kujifunza. Tunaona aina mbili ya watengenezaji. Aina ya kwanza inatokana na usambazaji wa mada kwa kufanya LDA kwenye taarifa zisizoeleweka. aina ya pili ni ya lugha ambazo zinatengenezwa na jitihada za kutoa taarifa za binadamu. To effectively learn with the regularizers, we propose a novel data structure, trajectory softmax, in this paper. Matokeo hayo yanavutiwa kwa maneno yanayofanana na hisia. Matokeo ya majaribio yanaonyesha kuwa mfumo wetu wa kujifunza na kudhibiti utaratibu wa maarifa ya kabla huboresha ubora wa kuzalisha katika seti za data mbalimbali, ukilinganisha na mkusanyiko wa njia mbalimbali za msingi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>வழக்கமான வார்த்தை உள்ளிடுதல் குறிப்பிட்ட குறிப்பிட்ட நிறுவனங்களுடன் (உதாரணமாக மொழி மாதிரி வடிவமைப்பு அல்லது ஒரு சேர்ந்த நிகழ்வு) ஒரே தகவல் மூலமு இந்த தாள் ஒரு unified சட்டத்தை குறிப்பிடுகிறது அது முன்னர் கற்றப்பட்டது அல்லது வெளிப்புற முன்னுரிமைகளை வெளியேற்றுகிறது, ஒரு வழக்கமான மொழி மாதி இரண்டு வகையான கட்டுப்பாட்டாளர்களை நாம் கருதுகிறோம். முதல் வகை குறிப்பிடப்படாத தகவலில் LDA இயக்கி தலைப்பு பங்கீட்டிலிருந்து வந்துள்ளது. இரண்டாவது வகை மனித அறிவிப்பு முயற்சிகளுடன் உருவாக்கப்பட்ட அகராதிகளை அடிப்படையாகும். விதிமுறையாளர்களுடன் கற்றுக் கொள்வதற்கு, நாம் இந்த தாளில் ஒரு புதிய தகவல் அமைப்பு, பாதையில் மென்பெரிதாக்கம் பரிந் @ info: whatsthis பரிசோதனை முடிவுகள் காண்பிக்கப்படுகிறது முன்னால் கல்வி சட்டத்திலிருந்து விதிமுறையாக்கத்திலிருந்து கற்றுக்கொள்ளும் அறிவு ம</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Adatça söz integrasy (meselâ, dil modelleýäniň ýa-da bir meňzeşlik çe şmesine daýanýar) bir maglumat çeşmesinde täze bir kalibreleme mümkinçiligi ýok edip bilmeýär. Bu kagyz öňden öňden öwrenmeden ýa daşarydaky öňki öňki döwletlerini düzgün täsirleştirmek üçin birleştirilen bir çerçew görkezýär. Biz düzgün düzgünçiler diýip pikir edýäris. Ilkinji hili ýazmayan maglumaty üzerinde LDA tarapyndan tem daýratyndan çykar. Ikinji hili adam duýdurma çabalary bilen döredilen sözlerne daýanýar. Düzenli adamlar bilen öwrenmek üçin, biz bu kagyzda roman maglumat strukturuny, traktöriň ýokary maksimum teklip edip görýäris. Sonuçta içeri kelime meňzeşlik we duýgular klasifikasyna görä deňlendirilýär. Durmançylyk netijelerimiz öwrenmek framlarymyzyň öňki bilgi bilen düzenli taýýarlanmagy bilen daşary taýýarlanmagynyň köpürleýändigini görkezýär.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ایک اطلاعات سورج کے درمیان (جیسے زبان موڈلینگ یا اتفاق) کے مطابق مخصوص مقداروں کے ساتھ استعمال کئے جاتے ہیں، اور باہر علم کے مطابق اضافہ کلیبرینگ کے فرصت کے ذریعے بغیر منع کئے جاتے ہیں. یہ کاغذ ایک متحدہ فریمیٹ ہے جو پہلے سکھایا جاتا ہے یا خارج سے پہلے، ایک قانون ترکیب کرنے والے کی شکل میں، ایک متحدہ زبان کی مدل پر بنیاد رکھنے کی تعلیم کے لئے استعمال کرتا ہے. ہم نے دو قسم کے معاملہ کرنے والوں کو سمجھ لیا ہے۔ پہلی ٹیپ ٹیپ ڈیٹ پریزینڈر سے لکھا گیا ہے جو LDA کو بغیر پڑھی ہوئی ڈیٹ پر چلتی ہے. دوسری طرح انسان کی اظہار کی کوشش کے ساتھ بنائے ہوئے لکھائی پر بنیاد ہے. ہم نے اس کاغذ میں ایک نئی ڈیٹا ساختار، تراژیکٹری نرم ماکس کی پیشنهاد کرتا ہے۔ نتیجۂ ایمبڈینگ لفظ کے مطابق اور احساسات کلاسیفوں کے ذریعہ ارزش کیا جاتا ہے. Experimental results show that our learning framework with regularization from prior knowledge improves embedding quality in multiple datasets, compared to a diverse collection of baseline methods.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Davom etilgan so'zlar tashqi maʼlumot manbasiga (m. g. tilning modeli yoki bir nechta hodisa asosida) foydalanadi. Bu qogʻoz bir birlashtirilgan freymni koʻrsatiladi. Bu qogʻoz boshqaruvchidan oldin o'rganish yoki tashqi oldin oldin o'rganish yoki tashqi oldin oldin ishlatiladi. Biz ikki tur boshqaruvchilarga o'ylaymiz. @ info: whatsthis Ikkinchi tur inson taʼminlovchi harakat bilan yaratilgan lugʻatlar asosida. Boshqaruvchilar bilan o'rganish uchun, biz bu qogʻozdagi novel maʼlumot tizimi, sakkizning soʻrov dasturi. @ info: whatsthis Tajriba natijalari shunday ko'rsatadi, biz o'rganish frameiyatlarimiz bir necha maʼlumotlar tarkibidagi sonlarning qiymatini ko'paytirish imkoniyatini oshirish mumkin, bir necha maʼlumotlar sonlariga ko'paytirish imkoniyatini ko'rsatadi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Những từ ngữ thông thường được đào tạo với những tiêu chuẩn đặc biệt (v.d., dựa trên cách phát minh ngôn ngữ hay nhập nhau) bên trong một nguồn thông tin đơn lẻ, không để ý cơ hội điều chỉnh thêm dựa trên kiến thức bên ngoài. Tờ giấy này đưa ra một cơ sở thống nhất dùng để thúc đẩy sự hiểu biết trước hay ra ngoài, bằng cách làm chính thức, để phát triển khả năng học thêm ngôn ngữ truyền thống. Chúng tôi xem xét hai loại đều đặn. Loại thứ nhất bắt nguồn từ việc phân phối chủ đề bằng cách chạy LDAP với dữ liệu không tải. Kiểu thứ hai dựa trên các từ điển được tạo ra với các nỗ lực ghi chú con người. Để có hiệu quả học với các nhà hoá học, chúng tôi đề xuất một cấu trúc mới về dữ liệu, đường chuyền bóng đèn, trong tờ giấy này. Kết quả của sự ghép nối được đánh giá bằng cách phân loại từ giống nhau và cảm xúc. Kết quả thí nghiệm cho thấy cơ sở học dựa trên việc theo quy tắc dựa trên kiến thức trước cải thiện việc trộn chất lượng trên nhiều bộ dữ liệu hơn so với một loạt các phương pháp cơ bản khác nhau.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>古词嵌信息源以特定准(,盖言语建模共现)练,忽于外校准也。 本立一框架,当框架以正则化器用预习外先验以强言语模样之旧。 吾思二正则化器。 一曰行未标之数 LDA 从题分生。 二曰人工注字典。 为学正则化器,立新数据结构于本文,即轨迹softmax。 以单词相似性情分质之。 实验结果表明与多样化之基线合,吾之学框架比前知之正则化,增数集之嵌质。</span></div></div><dl><dt>Anthology ID:</dt><dd>K17-1016</dd><dt>Volume:</dt><dd><a href=/volumes/K17-1/>Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017)</a></dd><dt>Month:</dt><dd>August</dd><dt>Year:</dt><dd>2017</dd><dt>Address:</dt><dd>Vancouver, Canada</dd><dt>Venue:</dt><dd><a href=/venues/conll/>CoNLL</a></dd><dt>SIG:</dt><dd><a href=/sigs/signll/>SIGNLL</a></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>143–152</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/K17-1016>https://aclanthology.org/K17-1016</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/K17-1016 title="To the current version of the paper by DOI">10.18653/v1/K17-1016</a></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">song-etal-2017-learning</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Yan Song, Chia-Jung Lee, and Fei Xia. 2017. <a href=https://aclanthology.org/K17-1016>Learning Word Representations with Regularization from Prior Knowledge</a>. In <i>Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017)</i>, pages 143–152, Vancouver, Canada. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/K17-1016>Learning Word Representations with Regularization from Prior Knowledge</a> (Song et al., CoNLL 2017)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/K17-1016.pdf>https://aclanthology.org/K17-1016.pdf</a></dd><dt>Data</dt><dd><a href=https://paperswithcode.com/dataset/imdb-movie-reviews>IMDb Movie Reviews</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/K17-1016.pdf title="Open PDF of 'Learning Word Representations with Regularization from Prior Knowledge'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Learning+Word+Representations+with+Regularization+from+Prior+Knowledge" title="Search for 'Learning Word Representations with Regularization from Prior Knowledge' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'Learning Word Representations with Regularization from Prior Knowledge'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[Learning Word Representations with Regularization from Prior Knowledge](https://aclanthology.org/K17-1016) (Song et al., CoNLL 2017)</p><ul class=mt-2><li><a href=https://aclanthology.org/K17-1016>Learning Word Representations with Regularization from Prior Knowledge</a> (Song et al., CoNLL 2017)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Yan Song, Chia-Jung Lee, and Fei Xia. 2017. <a href=https://aclanthology.org/K17-1016>Learning Word Representations with Regularization from Prior Knowledge</a>. In <i>Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017)</i>, pages 143–152, Vancouver, Canada. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>