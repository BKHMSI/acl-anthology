<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Data Selection with Cluster-Based Language Difference Models and Cynical Selection - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="Data Selection with Cluster-Based Language Difference Models and Cynical Selection" name=citation_title><meta content="Lucía Santamaría" name=citation_author><meta content="Amittai Axelrod" name=citation_author><meta content="Proceedings of the 14th International Conference on Spoken Language Translation" name=citation_conference_title><meta content="2017" name=citation_publication_date><meta content="https://aclanthology.org/2017.iwslt-1.19.pdf" name=citation_pdf_url><meta content="137" name=citation_firstpage><meta content="145" name=citation_lastpage><meta property="og:title" content="Data Selection with Cluster-Based Language Difference Models and Cynical Selection"><meta property="og:image" content="https://aclanthology.org/thumb/2017.iwslt-1.19.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2017.iwslt-1.19"><meta property="og:description" content="Lucía Santamaría, Amittai Axelrod. Proceedings of the 14th International Conference on Spoken Language Translation. 2017."><link rel=canonical href=https://aclanthology.org/2017.iwslt-1.19></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2017.iwslt-1.19.pdf>Data Selection with Cluster-Based Language Difference Models and Cynical Selection</a>
<a id=af_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Data Keuse met Cluster- Based Taal Verskil Modelle en Siniese Keuse</a>
<a id=am_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>የዳታ ምርጫ</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>اختيار البيانات باستخدام نماذج الفروق اللغوية المستندة إلى الكتلة والاختيار المتهكم</a>
<a id=az_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Cluster-Based Dil Farklƒ±lƒ±q Modell…ôri v…ô Sinikal Se√ßimi</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Избор на данни с модели на езикови разлики въз основа на клъстери и цинична селекция</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Name</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Cluster-Based Language Difference Models and Cynical Selection with Data Selection</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Izaber podataka sa modelima razlike jezika na bazi klustera i ciničkim selekcijom</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Selecció de dades amb models de diferència lingüística basats en grups i selecció cínica</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Výběr dat s klastrovými modely jazykových rozdílů a cynickým výběrem</a>
<a id=da_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Datavalg med klyngebaserede sprogforskellmodeller og kynisk valg</a>
<a id=de_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Datenauswahl mit clusterbasierten Sprachdifferenzmodellen und zynischer Selektion</a>
<a id=el_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Επιλογή δεδομένων με μοντέλα γλωσσικής διαφοράς βασισμένα σε σύμπλεγμα και κυνική επιλογή</a>
<a id=es_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Selección de datos con modelos de diferencias lingüísticas basados en clústeres y selección cínica</a>
<a id=et_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Andmete valimine klastripõhiste keeleerinevuste mudelite ja küünilise valikuga</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>انتخاب داده با مدل متفاوت زبان و انتخاب سینیکی پایه‌های کلاستر</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Tietojen valinta klusteripohjaisilla kielieromalleilla ja kyynisellä valinnalla</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Sélection de données avec des modèles de différence de langage basés sur des clusters et une sélection cynétique</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Roghnú Sonraí le Múnlaí Difríochta Teanga Cnuasbhunaithe agus Roghnú Ciniciúil</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>@ action</a>
<a id=he_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>בחירת נתונים עם דוגמני שינויים מבוססים על קבוצות ובחירה סינית</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>क्लस्टर-आधारित भाषा अंतर मॉडल और निंदक चयन के साथ डेटा चयन</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Izabranje podataka sa modelima razlike jezika na bazi klustera i ciničkim izborima</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Adatválasztás klaszter alapú nyelvi különbség modellekkel és cinikus kiválasztással</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Տվյալների ընտրությունը խմբի հիմնված լեզվի տարբերության մոդելներով և սինիկ ընտրությամբ</a>
<a id=id_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Pemilihan Data dengan Model Perbedaan Bahasa Berdasarkan Kelompok dan Pemilihan Sinik</a>
<a id=is_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Selezione dei dati con modelli di differenza linguistica basati su cluster e selezione cinica</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>クラスタベースの言語の違いモデルとシニカルな選択によるデータ選択</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>undo-type</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>მონაცემების არჩევა კლასტერის ბაზის ენის განსხვავების მოდელებით და უნიკალური არჩევა</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Cluster- негіздеген тіл айырмашылық үлгілері мен циникалық таңдау</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>분류된 언어 차이 모델과 분세 질속 선택을 바탕으로 한 데이터 선택</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Duomenų atranka su klasteriniais kalbų skirtumų modeliais ir ciniu atranka</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Data Selection with Cluster-Based Language Difference Models and Cynical Selection</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>ക്ലൌസ്റ്റര്‍ അടിസ്ഥാനമായ ഭാഷ വ്യത്യസ്ത മോഡലുകളും സൈനിക്കല്‍ തെരഞ്ഞെടുക്കുക</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Клустер-сан хэл өөрчлөлт загвар болон Циникийн сонголттай өгөгдлийн сонголт</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Pemilihan Data dengan Model Perbezaan Bahasa Berasas Kelompok dan Pemilihan Sinik</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Għażla tad-dejta b’Mudelli ta’ Differenza Lingwistika bbażati fuq Raggruppamenti u Għażla Ċinika</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Dataselectie met clustergebaseerde taalverschillen en cynische selectie</a>
<a id=no_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Databaseutval med klasterbaserte språk-forskjellingsmodeller og synisk utval</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Wybór danych za pomocą klastrowych modeli różnic językowych i selekcji cynicznej</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Seleção de dados com modelos de diferença de idioma baseados em cluster e seleção cínica</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Selectarea datelor cu modele de diferență lingvistică bazate pe cluster și selecție cinică</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Выбор данных с кластерными моделями различий языков и циничный выбор</a>
<a id=si_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Cluster- ආධාරිත භාෂා වෙනස් මොඩල් සහ සිනිකාල තෝරණය සමග දත්ත තෝරණය</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Izbira podatkov z modeli jezikovnih razlik na podlagi grozdov in cinično izbiro</a>
<a id=so_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Doorashada macluumaadka ee ku qoran luqada kala duwan ee Cluster-Based</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Zgjidhja e të dhënave me modele ndryshimi gjuhësh bazuar në grupe dhe zgjedhje cinike</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Izaber podataka sa modelima razlike jezika na bazi klustera i ciničkim izborima</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Dataval med klusterbaserade språkskillnader modeller och cyniskt urval</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Uchaguzi wa data kwa lugha tofauti na Uchaguzi wa Kireno</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Data Selection with Cluster-Based Language Difference Models and Cynical Selection</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Cluster-Baserden Diller Çeşmeleri we Kinik Saýlaw</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>کلسٹر-بنیادی زبان مختلف موڈل اور سینیک انتخاب کے ساتھ ڈاٹ انتخاب</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Name</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>Chọn độ phân biệt ngôn ngữ với các mẫu liên kết và chọn người máy</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2017.iwslt-1.19.pdf>盖聚类言语差异,与愤世嫉俗之数据选择</a></h2><p class=lead><a href=/people/l/lucia-santamaria/>Lucía Santamaría</a>,
<a href=/people/a/amittai-axelrod/>Amittai Axelrod</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>We present and apply two methods for addressing the problem of selecting relevant training data out of a general pool for use in tasks such as <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. Building on existing work on class-based language difference models [ 1 ], we first introduce a cluster-based method that uses Brown clusters to condense the vocabulary of the corpora. Secondly, we implement the cynical data selection method [ 2 ], which incrementally constructs a training corpus to efficiently model the task corpus. Both the cluster-based and the cynical data selection approaches are used for the first time within a machine translation system, and we perform a head-to-head comparison. Our intrinsic evaluations show that both new methods outperform the standard Moore-Lewis approach (cross-entropy difference), in terms of better perplexity and OOV rates on in-domain data. The cynical approach converges much quicker, covering nearly all of the in-domain vocabulary with 84 % less data than the other methods. Furthermore, the new approaches can be used to select machine translation training data for training better <a href=https://en.wikipedia.org/wiki/System>systems</a>. Our results confirm that class-based selection using Brown clusters is a viable alternative to POS-based class-based methods, and removes the reliance on a <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagger</a>. Additionally, we are able to validate the recently proposed cynical data selection method, showing that its performance in SMT models surpasses that of traditional cross-entropy difference methods and more closely matches the sentence length of the task corpus.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ons voorsien en toewend twee metodes vir die probleem van die kies van relevante onderwerp data uit 'n algemene pool vir gebruik in opdragte soos masjien vertaling. By gebou op bestaande werk op klas-gebaseerde taal verskil modele [1], introduseer ons eerste 'n cluster-gebaseerde metode wat gebruik Brown clusters om die woordeboek van die korpora te kondenseer. Tweede, ons implementeer die siniese data keuse metode [2], wat inkrementeer 'n oefening korpus konstrukteer om effektief die taak korpus te model. Beide die cluster-gebaseerde en die ciniese data-keuse toegang word gebruik vir die eerste keer binne 'n masjien vertalingsstelsel, en ons doen 'n kop-na-kop vergelyking. Ons binneste evaluasies vertoon dat beide nuwe metodes die standaard Moore-Lewis toegang (kruisentropie verskil), in terms van beter perpleksie en OOV rate op in-domein data uitvoer. Die siniese toegang versamel baie vinniger, oordek byna al die in-domein woordeboek met 84% minder data as die ander metodes. Verder kan die nuwe toegang gebruik word om masjien vertaling data te kies vir beter stelsels te oefen. Ons resultate bevestig dat klas-gebaseerde keuse gebruik Brown-clusters 'n bepaalde alternatief is vir POS-gebaseerde klas-gebaseerde metodes, en verwyder die vertrouing op 'n deel-van-woorde-etiket. In addition, we are able to validate the recently proposed cynical data selection method, showing that its performance in SMT models overpasses that of traditional cross-entropy difference methods and more
toe ooreenstem die setlengte van die taak korpus.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>እናሳየዋለን እና ሁለትን ሥርዓት ለመቆጣጠር የግንኙነትን ማህበረሰብ ዳታዎችን ከጠቅላላ ጉዳይ በመምረጥ እናደርጋለን፡፡ በክፍለ ቋንቋ ልዩነት ዓይነቶች ላይ የሚኖረውን ሥራ በመሥራት ላይ (1) በመጀመሪያ የኮርፖርት ቃላትን ለማሳመር የብሮንስ ኮንተር የሚጠቅመውን የኮርፖርት ቃላት ለመጠበቅ የሚጠቅመውን የቅድመ ደረጃ እናስጠጋለን፡፡ በሁለተኛው፣ የስራ ኮርፓስ ትክክል ለማሳመር የጥያቄ ዳታ ምርጫ method (2) እናደርጋለን፡፡ የኮንተር እና የጥያቄ ዳታ ምርጫዎች በመጀመሪያ ጊዜ በመስመር ውስጥ ለመጀመሪያ ይጠቀማሉ፤ እናም የራስ-ራስ ትክክል እናደርጋለን፡፡ የውስጥ ውጤታችን አዲስ ደረጃዎች የሞራ-ሊዊ ቀዳሚ (የድምፅ ግንኙነት የክፍለ ግንኙነት) እና የኦኦቪ ውጤት በዶሜን ዳታዎች ላይ በሚያሳየው ጥያቄ እንዲያሳዩ ያሳያል፡፡ የጥያቄ ሥርዓት ከሌሎቹ ዘዴዎች ይልቅ 84 በመቶ የሚያንስ ዳታ ይለውጣል፡፡ ከዚህም በላይ አዲስ ደረጃዎች ለመምረጥ የመኪን ትርጉም ዳታዎችን ለመምረጥ ይጠቀማሉ፡፡ Our results confirm that class-based selection using Brown clusters is a viable alternative to POS-based class-based methods, and removes the reliance on a part-of-speech tagger. በተጨማሪም፣ የቀኑ የጥያቄ ዳታ ምርጫ method ማረጋገጥ እናስችላለን፣ የSMT ዓይነቶች ፍለጋውን የባሕላዊ cross-entropy ልዩነት ማድረግ እና አብዛኛውን
የስራ ኮርፓስ ግንኙነትን አቅራቢያ ይተካክላል፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>نقدم ونطبق طريقتين لمعالجة مشكلة اختيار بيانات التدريب ذات الصلة من مجموعة عامة لاستخدامها في مهام مثل الترجمة الآلية. بناءً على العمل الحالي على نماذج الفروق اللغوية المستندة إلى الفصل [1] ، نقدم أولاً طريقة قائمة على الكتلة تستخدم مجموعات براون لتكثيف مفردات المجموعة. ثانيًا ، نقوم بتنفيذ طريقة اختيار البيانات المتهكمة [2] ، والتي تبني بشكل تدريجي مجموعة تدريب لنمذجة مجموعة المهام بكفاءة. يتم استخدام كل من نهج اختيار البيانات القائم على الكتلة والنهج الساخر لأول مرة في نظام الترجمة الآلية ، ونقوم بإجراء مقارنة وجهاً لوجه. تُظهر تقييماتنا الجوهرية أن كلتا الطريقتين الجديدتين تتفوقان في الأداء على نهج Moore-Lewis القياسي (اختلاف الانتروبيا المتقاطعة) ، من حيث الارتباك الأفضل ومعدلات OOV على البيانات داخل المجال. يتقارب النهج الساخر بشكل أسرع ، ويغطي تقريبًا كل المفردات في المجال ببيانات أقل بنسبة 84٪ من الطرق الأخرى. علاوة على ذلك ، يمكن استخدام الأساليب الجديدة لتحديد بيانات تدريب الترجمة الآلية لتدريب أنظمة أفضل. تؤكد نتائجنا أن الاختيار المستند إلى الفصل باستخدام مجموعات Brown هو بديل قابل للتطبيق للطرق المستندة إلى فئة POS ، ويزيل الاعتماد على أداة تمييز جزء من الكلام. بالإضافة إلى ذلك ، نحن قادرون على التحقق من صحة طريقة اختيار البيانات المتشائمة المقترحة مؤخرًا ، والتي توضح أن أدائها في نماذج SMT يفوق أداء طرق الاختلاف التقليدية عبر الانتروبيا والمزيد
يتطابق بشكل وثيق مع طول جملة مجموعة المهام.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Biz maşın çevirilməsi kimi işlərdə istifadə etmək üçün çoxlu təhsil məlumatlarını seçmək üçün iki yol göstəririk və istifadə edirik. Sınıf tabanlı dillərin fərqli modellerinin üstündə olan işlərə inşa edirik [1], biz ilk dəfə korporanın sözlərini təsdiqləmək üçün Brown clusters istifadə edən bir cluster tabanlı metodlarını tanıyırıq. İkincisi, biz cinik məlumat seçmə metodunu [2] istifadə edirik ki, işin korpusu təhsil etmək üçün təhsil korpusu təhsil edir. Hər ikisi də pul tabanlı və cinik məlumat seçməsi ilk dəfə maşın çevirim sistemində istifadə edilir. Biz baş ilə baş ilə baş ilə qarşılaşdırırıq. İçindəki değerlendirmələrimiz hər ikisi yeni metodların standart Moore-Lewis yaxınlığını (çox entropi fərqli-fərqli-fərqli-fərqli-fərqli-fərqli-fərqli) ilə daha yaxşı karışıqlıq və OOV dərəcələrini domain verilənlərində daha yax Cinical approach daha hızlı birləşdirir, domain sözlərinin neredeyse bütün məlumatları digər metodlardan 84% az verilən bütün məlumatları örtür. Daha sonra, daha yaxşı sistemləri təhsil etmək üçün maşın təhsil təhsil məlumatlarını seçmək üçün yeni təhsil işlədilir. Bizim sonuçlarımız Sınıf tabanlı seçimlərimiz, Brown clusters vasitəsilə, POS tabanlı sınıf tabanlı metodlarına uyğun bir alternatif olduğunu təsdiqləyir və söz etiketçisinin bir parçasını silər. Daha da, biz yeni təklif edilmiş cinik məlumatlar seçmə metodunu təsdiqləyə bilərik, SMT modellərində onun performansının nəticəli cür entropi fərqli metodlarının və daha çoxluğundan üstün olduğunu göstərək,
işin korpusunun uzunluğuna yaxınlaşır.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Представяме и прилагаме два метода за решаване на проблема с подбора на подходящи данни за обучение от общ пул за използване в задачи като машинен превод. Въз основа на съществуващата работа по модели на езикова разлика, базирани на класове [1], ние първо въвеждаме метод, базиран на клъстери, който използва кафяви клъстери за кондензиране на речника на корпорите. Второ, прилагаме метода на циничен подбор на данни [2], който постепенно изгражда обучителен корпус за ефективно моделиране на корпуса на задачите. За първи път в системата за машинен превод се използват както клъстерно-базираните, така и циничните подходи за подбор на данни и ние извършваме сравнително сравнение. Нашите вътрешни оценки показват, че и двата нови метода превъзхождат стандартния подход на Мур-Луис (разлика между кръстосаната ентропия) по отношение на по-добра перфлексичност и проценти на OOV при вътрешните данни. Циничният подход се сближава много по-бързо, обхващайки почти целия речник в областта с 84% по-малко данни от другите методи. Освен това новите подходи могат да бъдат използвани за подбор на данни за обучение на машинен превод за обучение на по-добри системи. Резултатите ни потвърждават, че подборът на базата на класове с помощта на Браун клъстери е жизнеспособна алтернатива на базираните класове методи и премахва зависимостта от маркер за част от речта. Освен това успяхме да валидираме наскоро предложения метод за циничен подбор на данни, показвайки, че ефективността му в моделите надминава тази на традиционните методи за кръстосана ентропия и др.
Съвпада с дължината на изречението на корпуса на задачите.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>আমরা উপস্থাপন করি এবং দুই পদ্ধতি প্রয়োগ করি মেশিন অনুবাদের মতো কাজে ব্যবহার করার জন্য একটি সাধারণ পুল থেকে প্রশিক্ষণের তথ্য নির্বাচনে ক্লাস ভিত্তিক ভাষার পার্থক্য মডেলের উপর বিদ্যমান কাজ নির্মাণ করা হচ্ছে [১], আমরা প্রথমে একটি ক্লাস্টার ভিত্তিক পদ্ধতি চিহ্নিত করি যা ব্র দ্বিতীয়, আমরা সাইনিকাল ডাটা নির্বাচন পদ্ধতি ব্যবহার করি [২] যা ক্রমাগত কর্পোসের মডেল করার জন্য একটি প্রশিক্ষণ কোর্পাস তৈরি করে। ক্লাস্টার ভিত্তিক এবং সাইকিনাল ডাটা নির্বাচনের ক্ষেত্রে প্রথমবার ব্যবহার করা হয়েছে মেশিন অনুবাদ সিস্টেমের মধ্যে, এবং আমরা মাথা আমাদের অভ্যন্তরীণ পরিস্থিতি দেখা যাচ্ছে যে দুটি নতুন পদ্ধতি মুর-লেউসের স্বাভাবিক প্রতিক্রিয়া (ক্রাস-এন্ট্রোপির পার্থক্য) আর ডোমেইনের ত সাইনিকেল প্রযুক্তি অন্যান্য পদ্ধতির চেয়ে ৮৪% কম তথ্য দ্রুত পরিবর্তন করে। এছাড়াও, মেশিন অনুবাদ প্রশিক্ষণের জন্য নতুন পদ্ধতি ব্যবহার করা যাবে। আমাদের ফলাফল নিশ্চিত করে যে ব্রাউন ক্লাস্টার ব্যবহার করে ব্রাউন ক্লাস্টার ব্যবহার করে ক্লাসের ভিত্তিক নির্বাচনের বিকল্প হলো পোস ভিত্তিক ক ক তাছাড়াও, আমরা সম্প্রতি প্রস্তাবিত সাইনিকাল ডাটা নির্বাচন পদ্ধতি বৈধ করতে পারি, যেখানে দেখাচ্ছি যে এসএমটি মডেলে এর প্রভাব পার্থক্যের পার্থক
closely matches the sentence length of the task corpus.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ང་ཚོས་ལག་ལེན་འཐབ་ཐབས་ལམ་གཉིས་ཀྱི་གནད་དོན་ལ་གནད་དོན་ཡོད་པའི་དཀའ་ངལ་སྤེལ་བའི་གནས ང་ཚོའི་ནང་དུ་ཡོད་པའི་ལས་འགན་སྡེར་བརྟེན་གྱི་སྐད་ཀྱི་ཁྱད་པར་དབྱིབས་ཀྱི་ཐབས་ལམ་ལ་བཟོ་བྱས་པ་དང་པོ་ནས་གསར་བརྗོད་བྱས་པའི་ཐབས་ལམ་ཞིག གཉིས་པ། ང་ཚོས་ཀྱིས་སྤྱི་ཚོགས་གདམ་ཀ་ཐབས་ལམ་དེ་ལས་མཐུན་བཟོ་བྱེད་མཁན་གྱི་དབུགས་རྩིས་ཡོད་པ་ལས་སྦྱོར་གཙོ་བོ་ཞིག་གི་དབ གླིང་མོ་དང་ལྟ་བུའི་གནད་དོན་གཉིས་ཀྱིས་མནར་སྤྲོད་པའི་གནད་དོན་གཉིས་ལས་རང་ཉིད་ཀྱི་གནད་དོན་གཉིས་ཀྱིས་ལག་ལེན་འཐབ་རྒྱུ་ཡི Our intrinsic evaluations show that both new methods outperform the standard Moore-Lewis approach (cross-entropy difference), in terms of better perplexity and OOV rates on in-domain data. སྤྱི་ཚོགས་ཀྱི་ཐབས་ལམ་དེ་འདྲ་མཉམ་དུ་བཏོན་གཏོང་ཐབས་ལམ་གཞན་ལས་བརྩོན་འགྱུར་བ་ཡིན་པའི་ནང་གི་བརྡ་སྤྲོད་ཀྱི་ནང་གི་ཐོག ད་དུང་། ཐབས་ལམ་གསར་བ་ནི་ལག་ལེན་འཐབ་བཏང་ཡོད་པ་ལས་མ་ལག་གི་སྐད་ཡིག ང་ཚོའི་འབྲུག འོན་ཀྱང་། ང་ཚོས་ཉེ་ཆར་གྱིས་སྤྲོད་པའི་ཐབས་ལམ་ལུགས་བདམས་ཟིན་པའི་ཚོར་བ་སྐྱེན་གྱི་ཐབས་ལམ་སྟོན་བྱེད་པར་བྱེད་སྲིད།
དེ་ནི་དུས་ཡུལ་གྱི་ཚིག་རྩིས་འབྲེལ་བ་དང་མཐུན་པོ་ཡོད།</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Predstavljamo i primjenjujemo dvije metode za rješavanje problem a izbora relevantnih podataka obuke iz općeg bazena za upotrebu u zadatkima poput prevoda stroja. Na temelju postojećeg rada na modelima razlike jezika baziranih na klasi [1], prvo predstavljamo metodu baziranu na skupini koji koristi Browne skupine kako bi se kondenzirali rečnik korpore. Drugo, implementiramo metodu selekcije ciničkih podataka [2], koja povećavajući konstruira trening korpus kako bi učinkovito modelirao zadatak korpus. Oba pristupa za izbor ciničkih podataka se koriste prvi put u sustavu prevoda mašine, a mi obavljamo usporedbu glave na glavu. Naše unutrašnje procjene pokazuju da obje nove metode iznose standardni pristup Moore-Lewisa (razlika kroz entropiju), u smislu boljih kompleksnosti i stopa OOV-a na podacima u domenu. Cinički pristup se zbližava mnogo brže, pokrivajući skoro sve riječnike u domenu sa 84% manjim podacima od drugih metoda. Osim toga, nove pristupe se mogu koristiti za odabrati podatke o obuci strojeva za bolji sustav obuke. Naši rezultati potvrđuju da je selekcija bazirana na klasi koristeći Browne skupine održiva alternativa metodi baziranih na klasi na POS-u i uklanja pouzdanost na dijelom govornog značka. Osim toga, mi smo u mogućnosti potvrditi nedavno predloženu metodu izbora ciničkih podataka, pokazujući da njen učinkovit u modelima SMT-a prelazi od tradicionalnih metoda razlike preko entropije i više
blizu odgovara dužini kazne zadatka korpusa.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Presentam i aplicam dos mètodes per abordar el problem a de seleccionar les dades de capacitació pertinents d'un grup general per utilitzar en tasques com la traducció màquina. Construïnt-nos en els models de diferències lingüístices basats en classe [1], vam introduir primer un mètode basat en grups que utilitza grups marrons per condensar el vocabulari de la corpora. En segon lloc, implementam el mètode de selecció de dades cíniques [2], que incrementalment construeix un cos d'entrenament per modelar eficientment el cos de tasques. Tant els enfocaments de selecció de dades basats en grups com cínics s'utilitzen per primera vegada dins un sistema de traducció màquina, i fem una comparació cap a cap. Les nostres evaluacions intrínsecs mostren que ambdós nous mètodes superen l'enfocament Moore-Lewis estándar (diferència entre entropies), en termes de millor perplexitat i índex d'OOV en dades en domini. L'enfocament cínic convergeix molt més ràpid, cobrint gairebé tot el vocabulari en domini amb 84% menys dades que els altres mètodes. A més, es poden utilitzar els nous enfocaments per seleccionar dades d'entrenament de traducció màquina per formar millors sistemes. Els nostres resultats confirmen que la selecció basada en classes utilitzant clusters Brown és una alternativa viable als mètodes basats en classes POS, i elimina la dependència d'un etiquetador de part de la xerrada. A més, podem validar el mètode de selecció de dades cíniques proposat recentment, mostrant que el seu rendiment en models SMT supera el dels mètodes tradicionals de diferència entre entropies i més
coincideix estretament amb la llargada frase del corps de tasca.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Představujeme a aplikujeme dvě metody řešení problému výběru relevantních vzdělávacích dat z obecného fondu pro použití v úkolech, jako je strojový překlad. Na základě existující práce na modelech jazykových rozdílů založených na třídách [1] nejprve představujeme klastrovou metodu, která používá Brown clustery ke zkompenzování slovní zásoby korpusů. Za druhé implementujeme metodu cynického výběru dat [2], která postupně konstruuje tréninkový korpus pro efektivní modelování korpusu úloh. V rámci strojového překladu se poprvé používá klastrový i cynický přístup k výběru dat a provádíme srovnání hlavou k hlavě. Naše vnitřní hodnocení ukazují, že obě nové metody překonávají standardní Moore-Lewisovu přístup (cross-entropie diference), pokud jde o lepší zmatenost a OOV rychlost v doméně dat. Cynický přístup se sbírá mnohem rychleji a pokrývá téměř veškerou slovní zásobu v doméně s 84% méně dat než ostatní metody. Kromě toho lze nové přístupy použít k výběru dat tréninku strojového překladu pro školení lepších systémů. Naše výsledky potvrzují, že výběr založený na třídě pomocí Brown clusterů je životaschopnou alternativou k metodám založeným na POS a odstraňuje spolehlivost na tagger části řeči. Kromě toho jsme schopni ověřit nedávno navrženou metodu cynického výběru dat, která ukazuje, že její výkon v SMT modelech překonává tradiční metody cross-entropie diference a další
úzce odpovídá délce věty korpusu úkolu.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vi præsenterer og anvender to metoder til at løse problemet med at udvælge relevante uddannelsesdata ud af en generel pulje til brug i opgaver som maskinoversættelse. Med udgangspunkt i det eksisterende arbejde med klassebaserede sprogforskellmodeller [1] introducerer vi først en klyngebaseret metode, der bruger brune klynger til at kondensere korporaernes ordforråd. For det andet implementerer vi den kyniske dataudvælgelsesmetode [2], som gradvist konstruerer et træningskorpus til effektivt at modellere opgavekorpset. Både klyngebaserede og kyniske dataudvælgelsesmetoder anvendes for første gang i et maskinoversættelsessystem, og vi foretager en head-to-head sammenligning. Vores iboende evalueringer viser, at begge nye metoder overgår standard Moore-Lewis metoden (cross-entropi difference), hvad angår bedre forvirring og OOV rater på in-domæne data. Den kyniske tilgang konvergerer meget hurtigere og dækker næsten hele domænenes ordforråd med 84% færre data end de andre metoder. Desuden kan de nye fremgangsmåder anvendes til at udvælge maskinoversættelsesdata til uddannelse af bedre systemer. Vores resultater bekræfter, at klassebaseret udvælgelse ved hjælp af brune klynger er et levedygtigt alternativ til POS-baserede klassebaserede metoder, og fjerner afhængigheden af en del-of-tale tagger. Derudover er vi i stand til at validere den nyligt foreslåede kyniske dataudvælgelsesmetode, der viser, at dens ydeevne i SMT modeller overgår traditionelle cross-entropi difference metoder og mere
svarer nøje til sætningslængden af opgavekorpset.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Wir präsentieren und wenden zwei Methoden an, um das Problem der Auswahl relevanter Trainingsdaten aus einem allgemeinen Pool für Aufgaben wie maschinelle Übersetzung anzugehen. Aufbauend auf bestehenden Arbeiten an klassenbasierten Sprachdifferenzmodellen [1] stellen wir zunächst eine clusterbasierte Methode vor, die Brown Cluster verwendet, um das Vokabular der Korpora zu verdichten. Zweitens implementieren wir die zynische Datenauswahl [2], die inkrementell einen Trainingskorpus konstruiert, um den Aufgabenkorpus effizient zu modellieren. Sowohl der clusterbasierte als auch der zynische Datenauswahlansatz werden erstmals innerhalb eines maschinellen Übersetzungssystems eingesetzt und wir führen einen direkten Vergleich durch. Unsere intrinsischen Auswertungen zeigen, dass beide neuen Methoden den Standard-Moore-Lewis-Ansatz (Cross-Entropie Difference) hinsichtlich besserer Verwirrung und OOV-Raten auf In-Domain-Daten übertreffen. Der zynische Ansatz konvergiert viel schneller und deckt fast das gesamte In-Domain Vokabular mit 84% weniger Daten ab als die anderen Methoden. Darüber hinaus können die neuen Ansätze genutzt werden, um Trainingsdaten für maschinelle Übersetzungen auszuwählen, um bessere Systeme zu trainieren. Unsere Ergebnisse bestätigen, dass klassenbasierte Selektion mit Brown Clustern eine praktikable Alternative zu POS-basierten klassenbasierten Methoden ist und die Abhängigkeit von einem Teil-der-Sprache-Tagger beseitigt. Darüber hinaus können wir die kürzlich vorgeschlagene zynische Datenauswahl validieren und zeigen, dass ihre Leistung in SMT-Modellen die von traditionellen Cross-Entropie-Differenzmethoden und mehr übertrifft.
entspricht der Satzlänge des Aufgabenkorpus.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Παρουσιάζουμε και εφαρμόζουμε δύο μεθόδους αντιμετώπισης του προβλήματος επιλογής σχετικών δεδομένων κατάρτισης από μια γενική ομάδα για χρήση σε εργασίες όπως η μηχανική μετάφραση. Βασιζόμενοι στην υπάρχουσα εργασία σε μοντέλα γλωσσικής διαφοράς βάσει τάξεων [1], εισάγουμε πρώτα μια μέθοδο βασισμένη σε ομάδες που χρησιμοποιεί Brown clusters για να συμπυκνώσει το λεξιλόγιο των σωμάτων. Δεύτερον, εφαρμόζουμε τη μέθοδο κυνικής επιλογής δεδομένων [2], η οποία κατασκευάζει σταδιακά ένα εκπαιδευτικό σώμα για να μοντελοποιήσει αποτελεσματικά το σώμα εργασιών. Τόσο η προσέγγιση που βασίζεται σε ομάδες όσο και η κυνική επιλογή δεδομένων χρησιμοποιούνται για πρώτη φορά μέσα σε ένα σύστημα μηχανικής μετάφρασης και διεξάγουμε μια άμεση σύγκριση. Οι εγγενείς αξιολογήσεις μας δείχνουν ότι και οι δύο νέες μέθοδοι ξεπερνούν την τυπική προσέγγιση Moore-Lewis (διαφορά διασταυρούμενης εντροπίας), όσον αφορά την καλύτερη σύγχυση και τους ρυθμούς OOV σε δεδομένα εντός του τομέα. Η κυνική προσέγγιση συγκλίνει πολύ πιο γρήγορα, καλύπτοντας σχεδόν όλο το λεξιλόγιο του τομέα με 84% λιγότερα δεδομένα από τις άλλες μεθόδους. Επιπλέον, οι νέες προσεγγίσεις μπορούν να χρησιμοποιηθούν για την επιλογή δεδομένων κατάρτισης μηχανικής μετάφρασης για την εκπαίδευση καλύτερων συστημάτων. Τα αποτελέσματά μας επιβεβαιώνουν ότι η επιλογή με βάση τις τάξεις με τη χρήση Brown clusters είναι μια βιώσιμη εναλλακτική λύση στις μεθόδους που βασίζονται στις τάξεις και καταργεί την εξάρτηση από μια ετικέτα μερικού λόγου. Επιπλέον, είμαστε σε θέση να επικυρώσουμε την πρόσφατα προτεινόμενη μέθοδο επιλογής κυνικών δεδομένων, δείχνοντας ότι η απόδοσή της στα μοντέλα ξεπερνά αυτή των παραδοσιακών μεθόδων διαφοράς διασταυρούμενης εντροπίας και άλλα
ταιριάζει στενά με το μήκος της πρότασης του σώματος εργασιών.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Presentamos y aplicamos dos métodos para abordar el problema de seleccionar datos de capacitación relevantes de un grupo general para su uso en tareas como la traducción automática. Sobre la base del trabajo existente sobre modelos de diferencias lingüísticas basados en clases [1], primero introducimos un método basado en clústeres que utiliza grupos Brown para condensar el vocabulario de los corpus. En segundo lugar, implementamos el método cínico de selección de datos [2], que construye gradualmente un corpus de entrenamiento para modelar eficientemente el corpus de tareas. Tanto el enfoque basado en clústeres como el de selección cínica de datos se utilizan por primera vez en un sistema de traducción automática, y realizamos una comparación directa. Nuestras evaluaciones intrínsecas muestran que ambos métodos nuevos superan al enfoque estándar de Moore-Lewis (diferencia de entropía cruzada), en términos de mejor perplejidad y tasas de OOV en los datos dentro del dominio. El enfoque cínico converge mucho más rápido, cubriendo casi todo el vocabulario del dominio con un 84% menos de datos que los otros métodos. Además, los nuevos enfoques se pueden utilizar para seleccionar datos de capacitación en traducción automática para entrenar mejores sistemas. Nuestros resultados confirman que la selección basada en clases con clústeres Brown es una alternativa viable a los métodos basados en clases basados en POS, y elimina la dependencia de un etiquetador de parte del discurso. Además, podemos validar el método cínico de selección de datos recientemente propuesto, lo que demuestra que su rendimiento en los modelos SMT supera al de los métodos tradicionales de diferencia de entropía cruzada y más
coincide estrechamente con la longitud de la oración del cuerpo de tareas.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Esitleme ja rakendame kahte meetodit, et lahendada probleemi, mis puudutab asjakohaste koolitusandmete valimist üldisest kogumist selliste ülesannete täitmiseks nagu masintõlge. Tuginedes olemasolevale tööle klassipõhiste keeleliste erinevuste mudelitel [1], tutvustame esmalt klastripõhist meetodit, mis kasutab korpuste sõnavara tihendamiseks pruunide klastrite abil. Teiseks rakendame küünilise andmevaliku meetodit, [2] mis konstrueerib järk-järgult koolituskorpuse ülesandekorpuse efektiivseks modelleerimiseks. Masintõlkesüsteemis kasutatakse esmakordselt nii klastripõhist kui ka küünilist andmete valimise lähenemisviisi ning teostame vastastikuse võrdluse. Meie sisemised hinnangud näitavad, et mõlemad uued meetodid ületavad standardset Moore-Lewise lähenemisviisi (ristentroopia erinevus) parema segaduse ja OOV määra osas domeenisiseste andmete puhul. Küüniline lähenemine läheneb palju kiiremini, hõlmates peaaegu kogu valdkonnasisest sõnavara 84% vähem andmeid kui muud meetodid. Lisaks saab uusi lähenemisviise kasutada masintõlke koolituse andmete valimiseks paremate süsteemide koolitamiseks. Meie tulemused kinnitavad, et klassipõhine valik Browni klastrite abil on elujõuline alternatiiv POS-põhistele klassipõhistele meetoditele ja eemaldab sõltuvuse kõneosa sildistajast. Lisaks on meil võimalik valideerida hiljuti välja pakutud küünilise andmete valimise meetodit, näidates, et selle jõudlus SMT mudelites ületab traditsiooniliste ristentroopia erinevuste meetodite jõudlust.
vastab täpselt ülesandekorpuse karistuse pikkusele.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ما دو روش برای حل مشکل تعلیم مربوط به انتخاب داده های آموزشی مربوط به یک استخراج عمومی برای استفاده از کار مثل ترجمه ماشین را پیشنهاد می کنیم و کاربرد می کنیم. بر روی کار موجود در مورد مدل تفاوت های زبان بر پایه کلاس [1] اولین بار یک روش بر پایه کلاستر معرفی می کنیم که از کلاسترهای براون استفاده می کند تا کلاس های کوپرا را کاندینس کند. دوم، ما روش انتخاب داده های سینیکی [2] را اجرای می کنیم که به طور اضافه یک کورپوس آموزش را برای موثرت مدل کورپوس کار می سازد. هر دو از طریق انتخاب داده های سینیک بر اساس کلاستر برای اولین بار در سیستم ترجمه ماشین استفاده می‌شوند، و ما یک مقایسه سر به سر انجام می‌دهیم. ارزیابی داخلی ما نشان می دهند که هر دو روش جدید از طریق استاندارد مور-لوئیس (تفاوت متوسط انتروپی) در مورد نرخ‌های پرچسبی بهتر و نرخ‌های OOV در داده‌های داخل داخلی انجام می‌دهد. این دستور شینیکی بسیار سریع تر است، که تقریباً تمام کلمه‌های دامنه‌ی دامنه‌ای را با ۸۴ درصد اطلاعات کمتر از روش‌های دیگر پوشانده می‌شود. علاوه بر این، روش‌های جدید برای انتخاب داده‌های ترجمه ماشین برای آموزش سیستم‌های بهتر استفاده می‌شود. نتیجه‌های ما تایید می‌کند که انتخاب بر پایه کلاس با استفاده از کلاس‌های براون جایگزینی قابل قابل قابل قابل قابل استفاده برای روش‌های بر پایه کلاس POS است و اعتماد به یک قسمتی از نقاشی سخنرانی را حذف می‌کند. به اضافه، ما می توانیم روش انتخاب داده های سینیکی را تایید کنیم، که نشان می دهیم که عملکرد آن در مدل های SMT از روش تفاوت های متفاوت متفاوت سنتی و بیشتر
نزدیک به طول مجازات کورپوس کار مشابه دارد.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Esittelemme ja sovellamme kahta menetelmää, joilla ratkaistaan ongelma, joka liittyy koulutustietojen valintaan yleisestä poolista esimerkiksi konekääntämiseen. Luokkapohjaisten kielieromallien [1] pohjalta esittelemme ensin klusteripohjaisen menetelmän, joka tiivistää korpusten sanastoa Brown klustereilla. Toiseksi toteutamme kyynisen tiedonvalintamenetelmän [2], joka rakentaa asteittain koulutuskorpusen tehokkaaksi mallintamiseksi. Konekäännösjärjestelmässä käytetään ensimmäistä kertaa sekä klusteripohjaista että kyynistä tiedonvalintaa, ja teemme vertaisvertailun. Sisäänrakennetut arviointimme osoittavat, että molemmat uudet menetelmät ovat parempia kuin Moore-Lewisin standardi (cross-entropia difference). Kyyninen lähestymistapa lähentyy paljon nopeammin ja kattaa lähes kaiken verkkotunnuksen sanaston 84% vähemmän tietoja kuin muut menetelmät. Lisäksi uusia lähestymistapoja voidaan käyttää konekäännöskoulutuksen tietojen valinnassa parempien järjestelmien kouluttamiseksi. Tuloksemme vahvistavat, että Brown-klustereiden luokkapohjainen valinta on käyttökelpoinen vaihtoehto POS-pohjaisille luokkapohjaisille menetelmille ja poistaa riippuvuuden puheen osatunnisteeseen. Lisäksi pystymme validoimaan hiljattain ehdotetun kyynisen datan valintamenetelmän, joka osoittaa, että sen suorituskyky SMT-malleissa ylittää perinteiset ristientropia-erotusmenetelmät ja enemmän
Vastaa tarkasti tehtäväkorpusen lauseen pituutta.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nous présentons et appliquons deux méthodes pour résoudre le problème de la sélection de données de formation pertinentes à partir d'un pool général à utiliser dans des tâches telles que la traduction automatique. En nous appuyant sur les travaux existants sur les modèles de différence linguistique basés sur les classes [1], nous introduisons d'abord une méthode basée sur les clusters qui utilise des clusters de Brown pour condenser le vocabulaire des corpus. Deuxièmement, nous mettons en œuvre la méthode cyniques de sélection des données [2], qui construit progressivement un corpus de formation pour modéliser efficacement le corpus de tâches. Les approches basées sur les clusters et les approches cyniques de sélection de données sont utilisées pour la première fois dans un système de traduction automatique, et nous effectuons une comparaison directe. Nos évaluations intrinsèques montrent que les deux nouvelles méthodes surpassent l'approche standard de Moore-Lewis (différence d'entropie croisée), en termes de meilleure perplexité et de taux OOV sur les données internes au domaine. L'approche cynique converge beaucoup plus rapidement, couvrant presque tout le vocabulaire du domaine avec 84 % de données en moins que les autres méthodes. En outre, les nouvelles approches peuvent être utilisées pour sélectionner des données de formation en traduction automatique afin de former de meilleurs systèmes. Nos résultats confirment que la sélection basée sur les classes à l'aide de clusters Brown est une alternative viable aux méthodes basées sur les classes basées sur les POS, et supprime la dépendance à un marqueur de partie du discours. De plus, nous sommes en mesure de valider la méthode de sélection de données cyniques récemment proposée, montrant que ses performances dans les modèles SMT dépassent celles des méthodes traditionnelles de différence d'entropie croisée et plus encore
correspond étroitement à la longueur de phrase du corpus de tâches.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Cuirimid i láthair agus cuirimid i bhfeidhm dhá mhodh chun dul i ngleic leis an bhfadhb a bhaineann le sonraí oiliúna ábhartha a roghnú as comhthiomsú ginearálta lena n-úsáid i dtascanna ar nós aistriúchán meaisín. Ag tógáil ar an obair atá ar siúl cheana féin ar mhúnlaí rang-bhunaithe difríochta teanga [1], tugaimid isteach ar dtús modh atá bunaithe ar bhraislí a úsáideann braislí Brown chun foclóir an chorpora a chomhdhlúthú. Ar an dara dul síos, cuirimid i bhfeidhm an modh roghnúcháin sonraí ciniciúil [2], a dhéanann corpas oiliúna de réir a chéile chun an tascchorp a shamhaltú go héifeachtach. Baintear úsáid as na cineálacha cur chuige bunaithe ar bhraisle agus as na cineálacha cur chuige ciniciúil um roghnú sonraí don chéad uair laistigh de chóras aistriúcháin meaisín, agus déanaimid comparáid duine le duine. Léiríonn ár meastóireachtaí intreacha go sáraíonn an dá mhodh nua cur chuige caighdeánach Moore-Lewis (difríocht tras-eantrópachta), i dtéarmaí seachnachta níos fearr agus rátaí OOV ar shonraí in-fearainn. Tagann an cur chuige ciniciúil le chéile i bhfad níos tapúla, ag clúdach beagnach gach ceann de na stór focal in-fearainn le 84% níos lú sonraí ná na modhanna eile. Ina theannta sin, is féidir na cineálacha cur chuige nua a úsáid chun sonraí oiliúna meaisín-aistriúcháin a roghnú chun córais níos fearr a oiliúint. Deimhníonn ár dtorthaí gur rogha inmharthana é roghnú rangbhunaithe ag baint úsáide as braislí Brown ar mhodhanna rangbhunaithe POS, agus go mbaintear an spleáchas ar chlibeálaí cuid de chaint. Ina theannta sin, táimid in ann an modh roghnúcháin sonraí ciniciúil a moladh le déanaí a bhailíochtú, rud a thaispeánann go sáraíonn a fheidhmíocht i samhlacha SMT ná modhanna traidisiúnta difríochta tras-eantrópachta agus go leor eile.
meaitseálann sé go dlúth le fad na habairte sa chorpas taisc.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tuna halatar da su, kuma tuna amfani da shiryoyin biyu dõmin su yi addu'a wa masu jarraba data masu amfani da shi daga wata pool mai amfani da su cikin aikin kama da fassarar mashine. Kana samar da aikin wanda ke samar a kan misãlai masu sãɓa wa harshen fasa[1], za'a gabatar da wata hanyor ta wajen kwamfyuta wanda ke amfani da Brown clubs to run maganar firma. Kijan da, za mu yi amfani da hanyon zaɓanta na kynical data[2], wanda ke samun wata umarni mai amfani da kwamfyuta dõmin ya sami kwamfyutan aikin. @ info: whatsthis Bayanmu da ke ƙari yana nũna cẽwa, hanyoyinMu biyu suna ƙaranci kowanin hanyoyin wata na'urar Mũse-Leusi (tsohon-shiga), a cikin masu tsarin mazaɓa da sauri na kamfani na OOV da sauri kan data masu cikin-Domin. Tsarin kyani na musanya masu kaso da gaggawa, yana rufe taki duk abu na cikin-Domen, da kuma da 84% ƙaranci da data daga wasu shiryoyin. Furan wannan, za'a iya amfani da hanyoyin sãbuwa don a zãɓi data na tsarin translation na mashine dõmin ya yi amfani da tsarin mafiya kyau na'urar system. MatamayinMu na gaskata cewa zaɓen mai fasa da ke amfani da Brown clubs, yana da wata shida mai inganci wa hanyõyin-danne-bane na PSS, kuma yana tafiyar da dõgara a kan wani abu na-faɗi. Ina iya ƙaranci, za'a iya gaskata metoden zaɓallin danne na ƙarani da aka buƙata, kuma za mu nuna cewa aikin kwamfyutan SMT na tsohon hanyoyin tarawa na daban-entropy da waɗancan
na sami sosai da cire tsakiyar aiki.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>אנחנו מציגים ושימושים שתי שיטות להתמודד עם הבעיה של לבחור נתונים אימונים רלוונטיים מבריכה כללית לשימוש במשימות כמו תרגום מכונות. בניין על עבודה קיימת על דוגמני ההבדל בשפה מבוססים בכיתה [1], אנו קודם מכירים שיטה מבוססת על קבוצה שמשתמשת בקבוצות בראון שנית, אנו מפעילים את שיטת הבחירה של נתונים סיניקים [2], שמבנה באופן שלילי קורפוס אימון כדי לדוגמא באופן יעיל את קורפוס המשימה. שני גישות הבחירה של נתונים המבוססים על הקלאסטר והציניות משתמשות בפעם הראשונה בתוך מערכת תרגום מכונת, ואנחנו מבצעים שיוואי ראש לראש. הערכות הפנימיות שלנו מראות ששתי השיטות החדשות מעליפות את הגישה הסטנדרטית של מור-לואיס (הבדל בין אנטרופיה הצלבית), במונחים של בלכות טובה יותר וקצבי OOV על נתונים בתחום. הגישה הצינית מתקרבת הרבה יותר מהר, מכסה כמעט את כל המילים בתחום עם 84% פחות נתונים מהשיטות האחרות. בנוסף, אפשר להשתמש באמצעות הגישות החדשות כדי לבחור נתוני אימון תרגום מכונות לאימון מערכות טובות יותר. התוצאות שלנו מאשרות שבחירה מבוססת בכיתה באמצעות קבוצות בראון היא אלטרנטיבה חיונית לשיטות מבוססת בכיתה POS, ומסירה את תלויה בחלק של טגיר דיבור. Additionally, we are able to validate the recently proposed cynical data selection method, showing that its performance in SMT models surpasses that of traditional cross-entropy difference methods and more
מתאים מקרוב לאורך המשפט של הקורפוס המשימה.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>हम मशीन अनुवाद जैसे कार्यों में उपयोग के लिए एक सामान्य पूल से प्रासंगिक प्रशिक्षण डेटा का चयन करने की समस्या को संबोधित करने के लिए दो विधियों को प्रस्तुत करते हैं और लागू करते हैं। वर्ग-आधारित भाषा अंतर मॉडल [1] पर मौजूदा काम पर निर्माण, हम पहले एक क्लस्टर-आधारित विधि पेश करते हैं जो कॉर्पोरेट की शब्दावली को संघनित करने के लिए ब्राउन क्लस्टर का उपयोग करता है। दूसरे, हम सनकी डेटा चयन विधि [2] को लागू करते हैं, जो कार्य कॉर्पस को कुशलतापूर्वक मॉडल करने के लिए एक प्रशिक्षण कॉर्पस का निर्माण करता है। क्लस्टर-आधारित और निंदक डेटा चयन दृष्टिकोण दोनों का उपयोग पहली बार मशीन अनुवाद प्रणाली के भीतर किया जाता है, और हम एक सिर-से-सिर तुलना करते हैं। हमारे आंतरिक मूल्यांकन से पता चलता है कि दोनों नए तरीके मानक मूर-लुईस दृष्टिकोण (क्रॉस-एन्ट्रॉपी अंतर) से आगे निकलते हैं, इन-डोमेन डेटा पर बेहतर उलझन और ओओवी दरों के संदर्भ में। निंदक दृष्टिकोण बहुत तेज़ी से अभिसरण करता है, अन्य तरीकों की तुलना में 84% कम डेटा के साथ लगभग सभी इन-डोमेन शब्दावली को कवर करता है। इसके अलावा, नए दृष्टिकोणों का उपयोग बेहतर प्रणालियों के प्रशिक्षण के लिए मशीन अनुवाद प्रशिक्षण डेटा का चयन करने के लिए किया जा सकता है। हमारे परिणाम पुष्टि करते हैं कि ब्राउन क्लस्टर का उपयोग करके वर्ग-आधारित चयन पीओएस-आधारित वर्ग-आधारित विधियों के लिए एक व्यवहार्य विकल्प है, और एक भाग-के-भाषण टैगर पर निर्भरता को हटा देता है। इसके अतिरिक्त, हम हाल ही में प्रस्तावित सनकी डेटा चयन विधि को मान्य करने में सक्षम हैं, यह दिखाते हुए कि एसएमटी मॉडल में इसका प्रदर्शन पारंपरिक क्रॉस-एन्ट्रापी अंतर विधियों और अधिक से अधिक है।
बारीकी से कार्य कॉर्पस की वाक्य लंबाई से मेल खाता है।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Predstavljamo i primjenjujemo dvije metode za rješavanje problem a izbora relevantnih podataka obuke iz općeg bazena za upotrebu u zadataka poput prevoda strojeva. Na temelju postojećeg rada na modelima razlike jezika osnovanih na klasi [1], prvo predstavljamo metodu baziranu na skupini koji koristi Brown skupine kako bi se kondenzirali riječ tijela. Drugo, implementiramo metodu izbora ciničkih podataka [2], koja povećavajući konstruira trening korpus kako bi učinkovito modelirao zadatak korpus. Oba pristupa za izbor ciničkih podataka se primjenjuju prvi put u sustavu prevoda strojeva i uspoređujemo glavu na glavu. Naše unutrašnje procjene pokazuju da obje nove metode nadmađuju standardni pristup Moore-Lewisa (razlika kroz entropiju), u smislu boljih kompleksnosti i stopa OOV-a na podacima u domenu. Cinički pristup se zbližava mnogo brže, pokrivajući gotovo sve riječnike u domenu s 84% manjim podacima od drugih metoda. Osim toga, novi pristupi se mogu koristiti za odabrati podatke o obuci strojeva za bolji sustav obuke. Naši rezultati potvrđuju da je izbor baziran na klasi koristeći Browne skupine održiva alternativa metodi baziranih na klasi POS-u i uklanja pouzdanost na dijelom govornog značka. Osim toga, mi smo u mogućnosti potvrditi nedavno predloženu metodu izbora ciničkih podataka, pokazujući da njegova učinka u modelima SMT-a nadmaže tradicionalne metode razlike preko entropije i više
blizu odgovara dužini kazne zadatka korpusa.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Két módszert mutatunk be és alkalmazunk arra, hogy kezeljük a releváns képzési adatokat egy általános készletből kiválasztjuk az olyan feladatokhoz, mint a gépi fordítás. Az osztály alapú nyelvi különbségmodelleken végzett már meglévő munkákra építve [1] először egy klaszter alapú módszert vezetünk be, amely a barna klasztereket használja a testek szókincsének tömörítésére. Másodszor a cinikus adatválasztási módszert [2] alkalmazzuk, amely fokozatosan felépít egy tréningkorpuszt, hogy hatékonyan modellezze a feladatkorpuszt. Mind a klaszter alapú, mind a cinikus adatválasztási megközelítést első alkalommal használjuk egy gépi fordító rendszerben, és fej-fej összehasonlítást végzünk. Belső értékeléseink azt mutatják, hogy mindkét új módszer felülmúlja a Moore-Lewis szabványos megközelítést (cross-entrópia különbség), ami jobb zavaróságot és OOV arányt illeti a domain belüli adatokon. A cinikus megközelítés sokkal gyorsabban konvergál, és a többi módszernél 84%-kal kevesebb adattal fedi le majdnem az egész domain szókincset. Ezenkívül az új megközelítések alkalmazhatók a gépi fordítási képzési adatok kiválasztására a jobb rendszerek képzéséhez. Eredményeink megerősítik, hogy a Brown klasztereket használó osztályalapú kiválasztás életképes alternatívája a POS-alapú osztályalapú módszereknek, és eltávolítja a beszédrészes címkézőre való támaszkodást. Ezenkívül a nemrégiben javasolt cinikus adatválasztási módszer validálására is képesek vagyunk, bizonyítva, hogy az SMT modellek teljesítménye meghaladja a hagyományos keresztentrópiás különbségek módszereit és egyéb módszereket.
szorosan illeszkedik a feladatkorpusz mondathosszához.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Մենք ներկայացնում ենք և կիրառում ենք երկու մեթոդ լուծելու խնդիրը, որը նշանակում է ընտրել նշանակալի ուսումնասիրության տվյալներ ընդհանուր համակարգում օգտագործելու համար, ինչպիսիք են մեքենայի թարգմանությունը: Հիմնվելով գոյություն ունեցող աշխատանքի վրա դասարանի լեզվի տարբերության մոդելների վրա [1] մենք առաջին անգամ ներկայացնում ենք խմբերի հիմնված մեթոդ, որը օգտագործում է Բրաուն խմբերը կոնդենսավորելու համար մարմնի բառարանը: Երկրորդ, մենք կիրառում ենք սինիկ տվյալների ընտրության մեթոդը [2] որը միաժամանակ կառուցում է ուսուցման կորպոս, որպեսզի արդյունավետ մոդելավորի աշխատանքի կորպոսը: Առաջին անգամ մեքենայի թարգմանման համակարգում օգտագործվում են խմբերի և ցինիկ տվյալների ընտրության մոտեցումները, և մենք կատարում ենք գլխավոր առ գլխավոր համեմատություն: Մեր ներքին գնահատումները ցույց են տալիս, որ երկու նոր մեթոդները գերազանցում են ստանդարտ Մուր-Լյուիս մոտեցումը (խաչը-էնտրոպիայի տարբերությունը), ավելի լավ խառնաշփոթի և OOO արագությունների առումով բնագավառի տվյալների վրա: Սինիկ մոտեցումը շատ ավելի արագ է համընկնում, ներառելով գրեթե բոլոր բնագավառի բառարանները 84 տոկոսով ավելի քիչ տվյալներով, քան մյուս մեթոդները: Ավելին, նոր մոտեցումները կարող են օգտագործվել մեքենային թարգմանման ուսուցման տվյալներ ընտրելու համար ավելի լավ համակարգերի ուսուցման համար: Մեր արդյունքները հաստատում են, որ դասի հիմնված ընտրությունը, օգտագործելով Բրաուն կլաստերն, POS-ի հիմնված դասի հիմնված մեթոդների հնարավոր այլընտրանք է և հեռացնում է խոսքի մի մասի վրա կախվածությունը: Ավելին, մենք կարողանում ենք ստուգել վերջերս առաջարկված սինիկ տվյալների ընտրության մեթոդը, ցույց տալով, որ դրա արտադրողությունը SMT մոդելներում գերազանցում է ավանդական փոխէնտրոպիայի տարբերության մեթոդների և ավելի շատ
համապատասխանում է գործի մարմնի նախադասության երկարությանը:</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kami mempersembahkan dan menerapkan dua metode untuk mengatasi masalah memilih data latihan relevan dari kolam umum untuk digunakan dalam tugas seperti terjemahan mesin. Berdasarkan pekerjaan yang ada pada model perbedaan bahasa berdasarkan kelas [1], kami pertama-tama memperkenalkan metode berdasarkan kelompok yang menggunakan kelompok Brown untuk mengkondensasi vokbulari dari korpora. Kedua, kami mengimplementasikan metode pemilihan data cinis [2], yang secara bertambah-turut membangun sebuah korpus latihan untuk memadel korpus tugas secara efisien. Kedua pendekatan pemilihan data berdasarkan klaster dan cinis digunakan untuk pertama kalinya dalam sistem terjemahan mesin, dan kita melakukan perbandingan kepala ke kepala. Evaluasi intrinsik kami menunjukkan bahwa kedua metode baru melebihi pendekatan standar Moore-Lewis (perbedaan interentropi), dalam terma kekacauan yang lebih baik dan kadar OOV pada data dalam domain. pendekatan cinis konvergesi jauh lebih cepat, menutupi hampir semua vokabular dalam domain dengan 84% data kurang dari metode lain. Selain itu, pendekatan baru dapat digunakan untuk memilih data pelatihan terjemahan mesin untuk melatih sistem yang lebih baik. Hasil kami mengkonfirmasi bahwa seleksi berdasarkan kelas menggunakan kelas Brown adalah alternatif yang dapat dihidupkan untuk metode berdasarkan kelas POS, dan menghapus ketergantuan pada bagian dari pembicaraan tagger. Selain itu, kita dapat mengkvalifikasi metode pemilihan data cinis yang baru-baru ini diusulkan, menunjukkan bahwa prestasinya dalam model SMT melebihi metode perbedaan transentropi tradisional dan lebih
sangat cocok dengan panjang kalimat dari task corpus.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Presentiamo e applichiamo due metodi per affrontare il problema della selezione dei dati formativi pertinenti da un pool generale da utilizzare in attività come la traduzione automatica. Basandoci sul lavoro esistente sui modelli di differenza linguistica basati su classi [1], introduciamo per prima cosa un metodo basato su cluster che utilizza i cluster Brown per condensare il vocabolario dei corpora. In secondo luogo, implementiamo il metodo cinico di selezione dei dati [2], che costruisce progressivamente un corpus di formazione per modellare efficacemente il corpus di attività. Sia l'approccio cluster-based che quello cinico della selezione dei dati vengono utilizzati per la prima volta all'interno di un sistema di traduzione automatica, ed eseguiamo un confronto testa a testa. Le nostre valutazioni intrinseche mostrano che entrambi i nuovi metodi superano l'approccio standard Moore-Lewis (differenza tra entropia incrociata), in termini di migliore perplessità e tassi OOV sui dati in-domain. L'approccio cinico converge molto più velocemente, coprendo quasi tutto il vocabolario del dominio con l'84% in meno di dati rispetto agli altri metodi. Inoltre, i nuovi approcci possono essere utilizzati per selezionare i dati di formazione sulla traduzione automatica per formare sistemi migliori. I nostri risultati confermano che la selezione basata su classi utilizzando cluster Brown è una valida alternativa ai metodi basati su classi POS e rimuove la dipendenza da un tag part-of-speech. Inoltre, siamo in grado di convalidare il metodo di selezione cinica dei dati recentemente proposto, dimostrando che le sue prestazioni nei modelli SMT superano quelle dei metodi tradizionali di differenza di entropia incrociata e altro ancora
corrisponde strettamente alla lunghezza della frase del corpus di attività.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>機械翻訳などのタスクで使用するための一般的なプールから関連するトレーニングデータを選択する問題に対処するための2つの方法を提示し、適用します。 クラスベースの言語差異モデル[1]に関する既存の研究に基づいて、まずブラウン・クラスターを使用してコーラの語彙を凝縮するクラスターベースの方法を導入する。 第二に、タスクコーパスを効率的にモデル化するためにトレーニングコーパスを段階的に構築するシニカルなデータ選択方法[2]を実装する。 クラスターベースのデータ選択アプローチとシニカルなデータ選択アプローチの両方が、機械翻訳システム内で初めて使用され、対面比較を行います。 我々の本質的な評価は、両方の新しい方法が、ドメイン内データのより良い困惑性及びＯＯＶ率の点で、標準的なムーア＝ルイスアプローチ（クロスエントロピー差）を上回ることを示している。 皮肉なアプローチの収束ははるかに早く、ドメイン内のほぼすべての語彙を他の方法よりも84 ％少ないデータでカバーします。 さらに、新しいアプローチを使用して、より良いシステムをトレーニングするための機械翻訳トレーニングデータを選択することができます。 私たちの結果は、Brownクラスターを使用したクラスベースの選択が、POSベースのクラスベースの方法に代わる実行可能な代替手段であることを確認し、発話部分タグへの依存を排除しました。 さらに、最近提案された皮肉なデータ選択方法を検証することができ、SMTモデルでのパフォーマンスが従来のクロスエントロピー差分法などを上回ることを示しています。
タスクコーパスの文の長さとよく一致します。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Awak dhéwé nggawe lan aplikasi durung maneh kanggo nambah perbudhakan kanggo nggawe perbudhakan kanggo nggawe data nggawe barang nggawe sistem sing nyimpen kanggo nggawe tarjamahan [1] Sekonder, we install the cisNIC data select method [2] that Includes the design Body to Effectly model the task Body. Sampeyan nganggo sistem itwasi gambar lan nganggo perusahaan dadi dong sing dibutuhe nggo sistem itwasan karo perusahaan, lan kita gewis ngerasakno perusahaan Head-to-Head. We Intinsec assertions show that the new Methods out do the Standard Mure-Lewis method (inter-Entropy contrast), in terms of older perplixty and OOOOOC rate on in-domain data. Dino pernik dadi nggambar luwih-luwih basa, sinau kanggo sabên onh-sabên kelas karo sekondirno karo sekondirno karo pernik-sabên. politenessoffpolite, politenessoffpolite"), and when there is a change ("assertivepoliteness Rejalekan dhéwé nggunakaé punika-punika dipileksi basa kelas nang nggunakaé basa basa basa dunyane mulasar kelas bron Mungkin, kita iso nggambar nggambar kelas sistem sing nyeanye perusahaan data donde, iso nggambar nggawe barang sistem SMT kuwi wis mulasar tentang karo sistem sing perusahaan karo sistem dadi-Entropy sing berarti tambah karo akeh dumadhi;
echoH e l l o space w o r l d periodHelloworldHello world</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ჩვენ ჩვენ აყენებთ და გამოყენებთ ორი მეტი პრობლემას, რომელიც მაქსინური გაგრძელებაში გამოყენებელი მონაცემების გამოყენების პრობლემა. კლასის განსხვავების მოდელზე მუშაობაში მუშაობაში მუშაობაში მუშაობაში [1], ჩვენ პირველად კლასტერის განსხვავებული მეტი დავიყენებთ, რომელიც Brown კლასტერის გამოყენება, რომ კოპორ მეორე, ჩვენ ვამყენებთ უნიკალური მონაცემების მონიშნული მეტი [2], რომელიც კენტიმენტურად კოპუსს შექმნა, რომელიც უფრო ეფექტიურად მოდელურად მონაცემებ კლასტერის და სინიკალური მონაცემების გამოყენება პირველად გამოყენებულია მაქინის გაგრძელების სისტემაში, და ჩვენ გავაკეთებთ თავიდან თავიდან თავიდან თავიდან. ჩვენი ინტერნექტური განსაზღვრებები აჩვენებენ, რომ ორივე ახალი მეტოვები სტანდარტური მოსურ-ლუისის გადასვლა (კრესენტროპური განსხვავება), უკეთესი პროპლექტი და OOV სიმარ უნიკალური პროგორმა უფრო სიჩვენებულია, რომელიც პირდაპირად ყველა დომინური სიტყვებულაზე 84% უფრო ნაკლები მონაცემებით, ვიდრე სხვა მეტირებით. დამატებით, ახალი პროგრამები შეიძლება გამოიყენება მაქსინური განაცვლის მონაცემებისთვის უკეთესი სისტემებისთვის. ჩვენი წარმოდგენები დარწმუნდება, რომ ბრას კლასტრების გამოყენებით კლასტრების გამოყენება POS-დაბათული კლასტური მეტოვებისთვის ცხოვრებელი ალტენტიფიკატია და გამოყენება სიტყვის ტე დამატებით, ჩვენ შეგვიძლია გავაკეთოთ ახლა მხოლოდ უნიკალური მონაცემების მონიშვნის მეტი, რომელიც ჩვენ გავაკეთებთ, რომ მისი მონაცემებში SMT მოდელში გავაკეთება ტრადიციონალ
მხოლოდ მოთავსდება საქმე კორპუსის სიგრძე.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Біз компьютердің аудармасы секілді тапсырмаларда қолдану үшін жалпы бағдарламаларды таңдау мәселесін шешу үшін екі әдістерді көрсету және қолданамыз. Клас негіздеген тіл айырмашылық үлгілерінде барлық жұмыс істеу [1] үшін біріншіден, корпораның сөздігін бағыттау үшін Браун кластерін қолданатын кластердің негіздеген әдісін таңдап берем Екіншіден, біз циникалық деректерді таңдау әдісін [2] іске асырып, тапсырманың корпус үшін оқыту корпус құрылады. Кластер негізінде және циникалық деректерді таңдау кезінде бірінші рет компьютерді аудару жүйесінде қолданылады. Біз басқа-басқа салыстырып тұрмыз. Біздің ішкі оқиғаларымыздың екі жаңа әдістері Муре-Луис стандартты тәртібінен (көпентропиялық айырмашылығы), домен деректерінде жұмыс істеу және OOV жиіліктерінің тең. Киникалық жағдай, домендегі сөздердің барлығын басқа әдістерден 84% дегеннен аз деректерді таңдайды. Қосымша, жүйелерді жақсы оқыту үшін машинаны аудару мәліметін таңдау үшін жаңа арқылы қолданылады. Біздің нәтижелеріміз Браун кластерлерді қолданып класс негізінде таңдау - POS класс негізінде негізінде тұратын әдістерінің альтернативі, және сөйлеу тегтерінің бір бөлігіне сенімдігін өшіруді Сонымен қатар, біз соңғы келтірілген циникалық деректерді таңдау әдісін тексере аламыз. SMT үлгілерінде оның істеу әдістері әдімгі көптеген ентропиялық әдістерін және көптеген
Тапсырма корпусының ұзындығына сәйкес келеді.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>우리는 유니버설 탱크에서 관련 훈련 데이터를 선택하여 기계 번역 등 임무에 사용하는 문제를 해결하기 위해 두 가지 방법을 제시하고 응용한다.기존의 클래스 기반의 언어 차이 모델[1]을 토대로 우리는 먼저 클래스 기반의 방법을 소개했다. 이 방법은 갈색 클래스를 사용하여 어료 라이브러리의 어휘를 압축한다.그 다음에 우리는 세상 물정에 어두운 데이터 선택 방법을 실현했다[2]. 이 방법은 훈련 자료 라이브러리를 증량하여 효과적으로 모델링 임무 자료 라이브러리를 구축한다.기계 번역 시스템에서 처음으로 분류와 질투를 바탕으로 하는 데이터 선택 방법을 사용하고 머리를 맞댔다.우리의 내재적인 평가에 의하면 이 두 가지 새로운 방법은 역내 데이터의 곤혹도와 OOV율 방면에서 모두 표준적인 몰 루이스 방법(교차엔트로피차)보다 우수하다는 것을 알 수 있다.세속에 분개하고 질투하는 방법은 더욱 빨리 수렴되고 거의 모든 분야의 어휘표를 덮으며 데이터량이 다른 방법보다 84% 적다.이 밖에 새로운 방법은 기계 번역 훈련 데이터를 선택하여 시스템을 더욱 잘 훈련할 수 있도록 할 수 있다.우리의 결과에 의하면 브라운 클래스를 사용하는 클래스 기반의 선택은 단어 기반의 클래스 기반의 방법의 실행 가능한 대체 방법이며 단어 표기에 대한 의존을 없앴다.또한 최근에 제기된 불공평한 데이터 선택 방법을 검증하여 SMT 모델에서의 성능이 전통적인 교차 엔트로피 차법 등을 초과했음을 나타낼 수 있다
작업 자료 라이브러리의 문장 길이와 매우 일치합니다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mes pristatome ir taikome du metodus, kuriais sprendžiama problem a, susijusi su atitinkamų mokymo duomenų atranka iš bendros grupės, skirtos tokioms užduotims kaip vertimas mašinomis. Remdamiesi esamais klasės kalbų skirtumų modelių kūrimu [1], pirmiausia įvedame klasteriniu metodu, kuriuo naudojami rudi klasteriai kondensuojant korpros žodyną. Antra, įgyvendiname cininių duomenų atrankos metodą [2], kuris palaipsniui sukuria mokymo korpusą, kad būtų veiksmingai modeliuojamas darbo korpusas. Tiek klasteriniu, tiek cininiu duomenų atrankos metodai pirmą kartą naudojami mašinų vertimo sistemoje, ir mes atliekame palyginimą galva į galvą. Mūsų vidutiniai vertinimai rodo, kad abu nauji metodai viršija standartinį Moore-Lewis metodą (tarpentropinis skirtumas), kiek tai susiję su geresniu perplexumu ir OOV rodikliais srities duomenų atžvilgiu. Cininis požiūris konvergencija gerokai greitesnė, apimanti beveik visą domeno žodyną su 84 % mažiau duomenų nei kiti metodai. Be to, norint rengti geresnes sistemas, gali būti naudojami nauji metodai, kaip pasirinkti mašinų vertimo mokymo duomenis. Mūsų rezultatai patvirtina, kad klasės pasirinkimas naudojant ruduosius klasterius yra gyvybinga alternatyva į POS klasės metodus ir pašalina priklausomybę nuo kalbos dalies žymeklio. Be to, galime patvirtinti neseniai pasiūlytą cininių duomenų atrankos metodą, rodantį, kad jo veiksmingumas SMT modeliuose viršija tradicinių tarpentropinių skirtumų metodų ir daugiau
atidžiai atitinka užduoties korpuso sakinio trukmę.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Презентираме и аплицираме два методи за решавање на проблемот со изборот на релевантни податоци за обука од општиот базен за употреба во задачи како што е машинскиот превод. Користејќи ја постојаната работа на моделите на разлика на јазикот на класа [1], прво воведуваме метод базиран на групи кој користи Браун групи за кондензирање на речникот на капората. Второ, го спроведуваме методот на селекција на цинички податоци [2], кој постојано изградува обукен корпус за ефикасно да го моделира задачниот корпус. И пристапите за селекција на податоци базирани на групи, и циничките се користат за прв пат во системот на машински превод, и ние вршиме споредба глава во глава. Нашите внатрешни проценки покажуваат дека двата нови методи го надминуваат стандардниот пристап Мур-Луис (разлика во крстоентропијата), во поглед на подобра перфектност и стапки ООВ на податоците во доменот. Циничкиот пристап се приближува многу побрзо, покривајќи речиси целиот речник во доменот со 84 отсто помалку податоци од другите методи. Покрај тоа, новите пристапи може да се користат за избор на податоци за обука за машински превод за обука на подобри системи. Нашите резултати потврдуваат дека селекцијата базирана на класата користејќи го Браун кластерите е жива алтернатива на методите базирани на класата на POS, и ја отстранува зависноста од дел од говорот. Покрај тоа, можеме да го потврдиме неодамна предложениот метод за селекција на цинички податоци, покажувајќи дека неговата резултат во СМТ моделите го надминува она на традиционалните методи на разлика во крстоентропијата и повеќе
closely matches the sentence length of the task corpus.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ഒരു പൊതുവായ പൂളില്‍ നിന്നും പരിശീലനത്തിന്റെ പ്രശ്നം തെരഞ്ഞെടുക്കുന്നതിനുള്ള പ്രശ്നത്തിനുള്ള രണ്ടു രീതികള്‍ ഞങ്ങള്‍ ക്ലാസ്സ് അടിസ്ഥാനത്തുള്ള ഭാഷയുടെ വ്യത്യാസമാതൃകങ്ങളില്‍ നിലവിലുള്ള ജോലി നിര്‍മ്മിക്കുന്നതിന്‍റെ [1], ആദ്യം ഞങ്ങള്‍ ഒരു ക്ലാസ്റ്റര്‍ രണ്ടാമതായി, നാം സൈനിക്കല്‍ ഡേറ്റാ തെരഞ്ഞെടുക്കുന്ന രീതി ക്ലാസ്റ്റര്‍ അടിസ്ഥാനമാക്കുന്നതും സൈനിക്കല്‍ ഡേറ്റാ തെരഞ്ഞെടുക്കുന്നതും ആദ്യമായി മെഷീന്‍ പരിഭാഷണ സിസ്റ്റത്തില്‍ ഉപയോഗിക് നമ്മുടെ അകത്തുള്ള വിലാസങ്ങള്‍ കാണിക്കുന്നത് നമ്മുടെ പുതിയ മാര്‍ഗ്ഗങ്ങള്‍ സാധാരണ മൂര്‍-ലീവിസിന്റെ മാര്‍ഗ്ഗങ്ങള്‍ പ്രവര്‍ത്തിപ്പിക്കുന്നത സൈനിക്കല്‍ നടപടി വളരെ വേഗത്തില്‍ മാറുന്നു. കുറച്ച് ഡോമെന്‍ വാക്കുകള്‍ മൂലം മാറ്റുന്നു. മറ്റു രീതികളെക്കാള്‍ 84% കുറഞ്ഞ വ അതിനുശേഷം, മെഷീന്‍ പരിശീലനത്തിനുള്ള പരിശീലന വിവരങ്ങള്‍ തെരഞ്ഞെടുക്കാന്‍ പുതിയ മാറ്റങ്ങള്‍ ഉപയോഗിക് Our results confirm that class-based selection using Brown clusters is a viable alternative to POS-based class-based methods, and removes the reliance on a part-of-speech tagger. കൂടുതല്‍ സൈനിക്കല്‍ ഡേറ്റാ തെരഞ്ഞെടുക്കുന്ന രീതിയില്‍ നമുക്ക് പ്രാപ്തികമായി പരിശോധിക്കാന്‍ കഴിയുന്നു. അതിന്റെ പ്രകടനം SMT മോഡലിലുള്ള
ജോലി കോര്‍പ്പുസിന്റെ വാക്കിന്റെ നീളമായി അടുത്ത് പൊരുതുന്നു.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Бид машины орчуулалт шиг ажилд хэрэглэх боломжтой нийтийн сургалтын өгөгдлийг сонгох асуудлыг олох хоёр арга зам ашиглаж байна. Бид ангид суурилсан хэл ялгаатай загвар дээр суурилсан ажил дээр байгуулсан [1], эхлээд бид Браун кластеруудыг корпораны үгийг зориулахын тулд хэрэглэдэг кластеруудын суурилсан арга загварыг танилцуулдаг. Хоёрдугаарт, бид Циникийн өгөгдлийн сонголтын аргыг [2] хэрэгжүүлдэг. Энэ нь ажлын корпус-г үр ашигтай загварчлахын тулд сургалтын корпус үүсгэдэг. Кластер суурилсан болон циник өгөгдлийн сонголтын тулд машины орчуулах системийн дотор анхны удаа хэрэглэгддэг. Бид толгойд толгойд нь толгойд харьцуулж байна. Бидний дотоод шинэ арга барилга нь Мур-Луисийн стандарт арга барилга (эсрэг энтропийн ялгаа), илүү төвөгтэй байдал болон ООВ-ын тоо барилгын хувьд илүү төвөгтэй гэдгийг харуулдаг. Циникийн арга баримтууд бусад аргаас 84% бага өгөгдлийг илүү хурдан холбогддог. Дараа нь шинэ арга зам нь илүү сайн сургалтын төлөө машины хөгжлийн дасгал өгөгдлийг сонгоход ашиглаж болно. Бидний үр дүнд Браун кластеруудыг ашиглан хичээл дээр суурилсан сонголт нь POS-д суурилсан хичээл дээр суурилсан арга замыг ашиглаж, илтгэлийн нэг хэсэг дээр итгэлтэй байдлыг устгаж байна. Мөн бид саяхан шинэ санал дэвшүүлсэн циник өгөгдлийн сонголтын аргыг шалгаж чадна. Энэ нь SMT загварын үйл ажиллагаа нь уламжлалтай эсрэг энтропийн ялгааны арга болон илүү олон төрлийн арга загваруудыг
ажлын корпусын үгийг ойролцоогоор тэнцүү.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kami mempersembahkan dan melaksanakan dua kaedah untuk mengatasi masalah pemilihan data latihan yang berkaitan dari kolam umum untuk digunakan dalam tugas seperti terjemahan mesin. Membangun pada kerja yang wujud pada model perbezaan bahasa berdasarkan kelas [1], kita pertama-tama memperkenalkan kaedah berdasarkan kelompok yang menggunakan kelompok Brown untuk mengkondensasi vokbulari korpra. Kedua, kita melaksanakan kaedah pemilihan data cinik [2], yang secara bertambah membina sebuah korpus latihan untuk memmodelkan korpus tugas secara efektif. Kedua-dua pendekatan pemilihan data berdasarkan kelompok dan cinik digunakan untuk pertama kalinya dalam sistem terjemahan mesin, dan kita melakukan perbandingan head-to-head. Evaluasi intrinsik kami menunjukkan bahawa kedua-dua kaedah baru melampaui pendekatan Moore-Lewis piawai (perbezaan salib-entropi), dalam terma kekacauan yang lebih baik dan kadar OOV pada data dalam domain. pendekatan cinik berkumpul lebih cepat, meliputi hampir semua vokbulari dalam domain dengan 84% data kurang daripada kaedah lain. Lagipun, pendekatan baru boleh digunakan untuk memilih data latihan terjemahan mesin untuk latihan sistem yang lebih baik. Hasil kami mengesahkan bahawa pemilihan berdasarkan kelas menggunakan kumpulan Brown adalah alternatif yang mudah untuk kaedah berdasarkan kelas berdasarkan POS, dan menghapuskan kepercayaan pada sebahagian-dari-ucapan tag. Selain itu, kita boleh sahkan kaedah pemilihan data cinik yang baru-baru ini diusulkan, menunjukkan bahawa prestasinya dalam model SMT melebihi kaedah perbezaan salib entropi tradisional dan lebih
sepadan dengan panjang kalimat bagi korpus tugas.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Aħna nippreżentaw u napplikaw żewġ metodi biex nindirizzaw il-problem a tal-għa żla tad-dejta rilevanti tat-taħriġ minn ġabra ġenerali għall-użu f’kompiti bħat-traduzzjoni bil-magna. Abbażi tax-xogħol eżistenti fuq mudelli tad-differenzi lingwistiċi bbażati fuq il-klassi [1], l-ewwel a ħna nintroduċu metodu bbażat fuq raggruppament li juża raggruppamenti kannella biex jikkondensaw il-vokabulari tal-korpora. It-tieni nett, nimplimentaw il-metodu ċiniku tal-għa żla tad-dejta [2], li inkrementalment jibni korpus ta’ taħriġ biex jimmudella b’mod effiċjenti l-korpus ta’ ħidma. Kemm l-approċċi tal-għa żla tad-dejta bbażati fuq ir-raggruppament kif ukoll dawk ċiniċi jintużaw għall-ewwel darba fi ħdan sistema ta’ traduzzjoni tal-magna, u nagħmlu paragun minn ras għal oħra. L-evalwazzjonijiet intrinsiċi tagħna juru li ż-żewġ metodi ġodda jaqbżu l-approċċ standard Moore-Lewis (differenza bejn l-entropija), f’termini ta’ perplessità aħjar u rati OOV fuq id-dejta fid-dominju. L-approċċ ċiniku jikkonverġi ħafna aktar malajr, li jkopri kważi l-vokabulari kollha fid-dominju b’84 % inqas dejta mill-metodi l-oħra. Barra minn hekk, l-approċċi l-ġodda jistgħu jintużaw biex tintgħażel id-dejta tat-taħriġ tat-traduzzjoni bil-magna għat-taħriġ ta’ sistemi aħjar. Ir-riżultati tagħna jikkonfermaw li l-għa żla bbażata fuq il-klassi bl-użu ta’ raggruppamenti Brown hija alternattiva vijabbli għal metodi bbażati fuq il-klassi bbażati fuq POS, u tneħħi d-dipendenza fuq tagger ta’ parti mid-diskors. Barra minn hekk, nistgħu nivvalidaw il-metodu ta’ għażla tad-dejta ċinika propost dan l-aħħar, li juri li l-prestazzjoni tiegħu fil-mudelli SMT taqbeż dik tal-metodi tradizzjonali ta’ differenza bejn l-entropija u aktar
jaqbel mill-qrib mat-tul tas-sentenza tal-task corpus.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>We presenteren en passen twee methoden toe om het probleem van het selecteren van relevante trainingsgegevens uit een algemene pool aan te pakken voor taken zoals machinevertaling. Voortbouwend op bestaand werk aan class-based language difference modellen [1], introduceren we eerst een cluster-based methode die Brown clusters gebruikt om de woordenschat van de corpora te verdichten. Ten tweede implementeren we de cynische gegevensselectiemethode [2], die incrementel een trainingscorpus construeert om het taakcorpus efficiënt te modelleren. Zowel de cluster-gebaseerde als de cynische dataselectie benaderingen worden voor het eerst gebruikt binnen een machinevertaalsysteem en we voeren een head-to-head vergelijking uit. Onze intrinsieke evaluaties tonen aan dat beide nieuwe methoden beter presteren dan de standaard Moore-Lewis-benadering (cross-entropieverschil), wat betreft betere verwarring en OOV-percentages op in-domein data. De cynische benadering convergeert veel sneller en bestrijkt bijna alle in-domein woordenschat met 84% minder gegevens dan de andere methoden. Bovendien kunnen de nieuwe benaderingen worden gebruikt om trainingsgegevens voor machinevertaling te selecteren voor het trainen van betere systemen. Onze resultaten bevestigen dat class-based selectie met Brown clusters een haalbaar alternatief is voor POS-gebaseerde class-based methodes, en de afhankelijkheid van een part-of-speech tagger wegneemt. Daarnaast zijn we in staat om de recent voorgestelde cynische gegevensselectiemethode te valideren, waaruit blijkt dat de prestaties in SMT-modellen overtreffen die van traditionele cross-entropieverschilmethoden en meer
komt overeen met de lengte van de zin van het taakcorpus.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vi presenterer og bruker to metodar for å handsama problemet for å velja relevant øvingsdata ut av eit generell pool for bruk i oppgåver som maskineoversettelse. Bygger vi først på eksisterande arbeid på klassebaserte språk-forskjellingsmodeller [1], introduserer vi ein klassebasert metode som brukar Brown-clusters for å kondensera ordboka i korporen. I andre, implementerer vi den cynical datautvalmetoden [2], som inkrementalt konstruerer eit øvingskorpus for å gjere effektivt modell oppgåvekorpusen. Både klosterabaserte og det cynicalske datautvalet blir brukt for første gong i eit maskinsomsetjingssystem, og vi gjer ei sammenligning med hovud-til-hode. Våre interne evalueringar viser at begge nye metodar utfører standardinnstillingane Moore-Lewis (cross-entropy difference), i uttrykket av betre kompleksiteten og OOV-rate på inndomenedata. Cynical approach converges much faster, covering nearly all the in-domain vocabulary with 84% less data than the other methods. I tillegg kan dei nye tilnærmingane brukast for å velja datafor for opplæring av maskineomsetjingar for betre systemer. Resultatet våre stadfestar at klassebasert utval ved bruk av Brown-kluster er ein viktig alternativ for POS-baserte klassebaserte metoder, og fjernar tilbakekallinga på ein del av talemerker. I tillegg kan vi validera den nyleg foreslåde cynical data-utval metoden, som viser at utviklinga i SMT-modeller overpassar den tradisjonelle kryssentropiske forskjellingsmetodane og meir
passar nærare med setninga på oppgåvekorpusen.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Przedstawiamy i stosujemy dwie metody rozwiązania problemu wyboru odpowiednich danych szkoleniowych z ogólnej puli do wykorzystania w zadaniach takich jak tłumaczenie maszynowe. Opierając się na istniejących pracach nad klasowymi modelami różnic językowych [1], wprowadzamy najpierw metodę klastrową, która wykorzystuje klastry brązowe do skondensowania słownictwa korpusów. Po drugie, wdrażamy metodę cynicznej selekcji danych [2], która stopniowo buduje korpus szkoleniowy w celu efektywnego modelowania korpusu zadań. Zarówno klastrowe, jak i cyniczne metody selekcji danych są wykorzystywane po raz pierwszy w systemie tłumaczenia maszynowego i przeprowadzamy porównanie head-to-head. Nasze wewnętrzne oceny pokazują, że obie nowe metody przewyższają standardowe podejście Moore-Lewis (różnica w entropii krzyżowej), pod względem lepszego zdezorientowania i współczynnika OOV na danych wewnątrz domeny. Cyniczne podejście zbiega się znacznie szybciej, obejmując niemal całe słownictwo w domenie z 84% mniejszą ilością danych niż inne metody. Ponadto nowe podejścia mogą być wykorzystane do wyboru danych szkoleniowych z tłumaczenia maszynowego w celu szkolenia lepszych systemów. Nasze wyniki potwierdzają, że selekcja oparta na klasach za pomocą klastrów Brown jest realną alternatywą dla metod opartych na klasach POS i eliminuje zależność od tagera części mowy. Dodatkowo jesteśmy w stanie zweryfikować niedawno zaproponowaną metodę cynicznego selekcji danych, pokazując, że jej wydajność w modelach SMT przewyższa tradycyjne metody różnicy krzyżowej i więcej
ściśle pasuje do długości zdania korpusu zadania.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Apresentamos e aplicamos dois métodos para resolver o problema de selecionar dados de treinamento relevantes de um conjunto geral para uso em tarefas como tradução automática. Com base no trabalho existente sobre modelos de diferenças de linguagem baseados em classes [1], primeiro introduzimos um método baseado em clusters que usa clusters Brown para condensar o vocabulário dos corpora. Em segundo lugar, implementamos o método de seleção de dados cínico [2], que constrói incrementalmente um corpus de treinamento para modelar eficientemente o corpus de tarefas. Ambas as abordagens de seleção de dados baseada em cluster e cínica são usadas pela primeira vez em um sistema de tradução automática, e realizamos uma comparação direta. Nossas avaliações intrínsecas mostram que ambos os novos métodos superam a abordagem padrão de Moore-Lewis (diferença de entropia cruzada), em termos de melhores taxas de perplexidade e OOV em dados no domínio. A abordagem cínica converge muito mais rápido, cobrindo quase todo o vocabulário do domínio com 84% menos dados do que os outros métodos. Além disso, as novas abordagens podem ser usadas para selecionar dados de treinamento de tradução automática para treinar sistemas melhores. Nossos resultados confirmam que a seleção baseada em classe usando clusters Brown é uma alternativa viável aos métodos baseados em classe baseados em POS e remove a dependência de um tagger de parte da fala. Além disso, podemos validar o método de seleção de dados cínicos recentemente proposto, mostrando que seu desempenho em modelos SMT supera o dos métodos tradicionais de diferença de entropia cruzada e mais
corresponde ao comprimento da frase do corpus da tarefa.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Prezentăm și aplicăm două metode pentru abordarea problemei selectării datelor relevante de formare dintr-o bază generală pentru utilizarea în sarcini precum traducerea automată. Bazându-ne pe lucrările existente pe modelele diferențelor de limbă bazate pe clasă [1], introducem mai întâi o metodă bazată pe cluster care utilizează clusterele Brown pentru a condensa vocabularul corporelor. În al doilea rând, implementăm metoda cinică de selecție a datelor [2], care construiește treptat un corpus de instruire pentru a modela eficient corpul de sarcini. Atât abordarea bazată pe cluster, cât și cea cinică a selecției datelor sunt utilizate pentru prima dată în cadrul unui sistem de traducere automată și efectuăm o comparație directă. Evaluările noastre intrinsece arată că ambele metode noi depășesc abordarea standard Moore-Lewis (diferența intropiei încrucișate), în ceea ce privește o mai bună perplexitate și rate OOV pe datele din domeniu. Abordarea cinică converge mult mai rapid, acoperind aproape tot vocabularul din domeniu cu 84% mai puține date decât celelalte metode. În plus, noile abordări pot fi utilizate pentru a selecta datele de instruire în traducerea automată pentru a instrui sisteme mai bune. Rezultatele noastre confirmă faptul că selecția bazată pe clase utilizând clustere Brown este o alternativă viabilă la metodele bazate pe clase POS și elimină dependența de un etichetor part-of-speech. În plus, suntem capabili să validăm metoda recent propusă de selecție cinică a datelor, arătând că performanța sa în modelele SMT depășește cea a metodelor tradiționale de diferență de entropie încrucișată și mai mult
corespunde îndeaproape cu lungimea propoziției corpului de sarcini.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Мы представляем и применяем два метода решения проблемы выбора релевантных обучающих данных из общего пула для использования в таких задачах, как машинный перевод. Опираясь на существующую работу над моделями различий языков на основе классов [1], мы сначала вводим метод на основе кластеров, который использует Брауновские кластеры для уплотнения словарного запаса корпусов. Во-вторых, мы реализуем циничный метод отбора данных [2], который постепенно строит обучающий корпус для эффективного моделирования корпуса задач. Как кластерный, так и циничный подходы к выбору данных используются впервые в системе машинного перевода, и мы выполняем прямое сравнение. Наши внутренние оценки показывают, что оба новых метода превосходят стандартный подход Мура-Льюиса (перекрестная разница энтропии) с точки зрения лучшей недоумения и коэффициентов OOV по внутридоменным данным. Циничный подход сходится гораздо быстрее, охватывая почти весь внутридоменный словарь с на 84% меньше данных, чем другие методы. Кроме того, новые подходы могут быть использованы для выбора данных обучения машинному переводу для обучения лучших систем. Наши результаты подтверждают, что классовый выбор с использованием кластеров Брауна является жизнеспособной альтернативой методам на основе классов на основе POS, и устраняет зависимость от тегера части речи. Кроме того, мы можем подтвердить недавно предложенный циничный метод выбора данных, показывая, что его производительность в моделях SMT превосходит производительность традиционных методов перекрестной энтропии и более
близко соответствует длине предложения корпуса задачи.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>අපි ප්‍රශ්නයක් තියෙන්නේ සමාන්‍ය ප්‍රශ්නයක් තෝරාගන්න ප්‍රශ්නයක් සඳහා ප්‍රශ්නයක් තෝරාගන්න සඳහා ප්‍රශ ප්‍රදේශ භාෂාව වෙනස් මොඩේල් වලින් තියෙන්නේ වැඩේ ඉන්නේ [1], අපි මුලින්ම ප්‍රධාන විදේශයක් ප්‍රවේශ කරනවා බ්‍රාන් ක්ලාස්ට දෙවෙනි විදියට, අපි සිනිකාල දත්ත තෝරණය විදියට ප්‍රවේශනය කරනවා [2], ඒක විශේෂයෙන් ප්‍රවේශනය කර්පස් එකක් හදන්නේ ව මැෂින් වාර්ථාව පද්ධතියක් ඇතුලට පළමුවෙනි වතාවක් පාවිච්චි කරනවා, අපි ඔළුවෙන් ඔළුවෙන් ඔළුවෙන් වාර්ථාව කර අපේ ඇතුළත් අවශ්‍ය විශ්ලේෂණය පෙන්වන්නේ අළුත් විදිහා දෙන්නම මූර්-ලූවිස් ප්‍රමාණය (ක්‍රිස්ටෙන්ට්‍රොපි වෙනස්), හොඳ සං සායිනිකාලික ප්‍රවේශය ගොඩක් වේගයෙන් සම්බන්ධ වෙනවා, අනිත් ප්‍රවේශයෙන් 84% ටිකක් තොරතුරු තොරතුරු තියෙනවා. ඊට පස්සේ, අලුත් විදිහට ප්‍රයෝජනය කරන්න පුළුවන් පද්ධතිය හොඳ පද්ධතියෙන් පරීක්ෂණය කරන්න පද්ධත අපේ ප්‍රතිචාර ප්‍රතිචාරයක් ස්ථානයින් විශ්වාස කරන්න ප්‍රතිචාරයක් ප්‍රයෝජනය කරනවා කියලා ප්‍රතිචාරයක් ප්‍රයෝජනය කරනවා තවත්, අපිට පුළුවන් අවස්ථානයේ සිනිකාල් දත්ත තෝරාගැනීමේ විදියට පරීක්ෂා කරන්න පුළුවන් විදියට, පෙන්වන්නේ SMT මොඩේල
වාර්ථාව කොර්පුස් වලගේ වාක්ය ප්‍රමාණය සම්බන්ධයි.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Predstavljamo in uporabljamo dve metodi za reševanje problema izbire ustreznih podatkov o usposabljanju iz splošnega nabora za uporabo v nalogah, kot je strojno prevajanje. Na podlagi obstoječega dela na modelih jezikovnih razlik, ki temeljijo na razredu [1], smo najprej uvedli metodo, ki temelji na grozdih, ki uporablja rjave grozde za zgoščanje besedišča korpusov. Drugič, izvajamo cinično metodo izbire podatkov [2], ki postopoma konstruira korpus usposabljanja za učinkovito modeliranje korpusa nalog. V sistemu strojnega prevajanja prvič uporabljamo tako grozdni kot cinični pristop za izbiro podatkov, pri čemer izvajamo primerjavo. Naše notranje ocene kažejo, da obe novi metodi presegata standardni Moore-Lewis pristop (razlika med navzkrižno entropijo) v smislu boljše zmedenosti in stopnje OOV na podatkih v domeni. Cinični pristop se veliko hitreje konvergira, saj zajema skoraj celoten domenski besednjak z 84% manj podatkov kot pri drugih metodah. Poleg tega se lahko novi pristopi uporabljajo za izbiro podatkov o usposabljanju strojnega prevajanja za usposabljanje boljših sistemov. Naši rezultati potrjujejo, da je izbira na osnovi razreda z uporabo Brown grozdov izvedljiva alternativa metodam na osnovi razreda na osnovi POS in odpravlja zanašanje na označevalnik dela govora. Poleg tega smo lahko potrdili nedavno predlagano cinično metodo izbire podatkov, ki kaže, da njena učinkovitost pri modelih SMT presega tradicionalne metode navzkrižne entropije in več
tesno se ujema z dolžino kazni v korpusu opravil.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Waxaannu soo wadannaa oo u codsanaynaa laba qaab, si aan u xambaarano dhibaatada doorashada macluumaadka la xiriira laga doorto balliga guud ee lagu isticmaalo shaqooyin tusaale ahaan turjumaadda machine. Bulshada shaqada oo ku qoran noocyada kala duwan luuqada fasalka [1], marka ugu horeysa waxaynu soo bandhignaa qaab ku saleysan luqada oo lagu isticmaalo kooxo Brown si uu u sameeyo warqada shirkadda. Second, waxaynu sameynaa qaababka doorashada macluumaadka habaarka ah[2], taasoo dhisaya koronta waxbarashada si ay u sameyn karto kooxda shaqada si fiican. Inta ugu horraysa waxaa loo isticmaalaa habka turjumaadda machineedka, waxaana sameynaa isbarbardhigga madaxa. Qiimeynta gudaha ah waxay muuqataa in labada qaab cusub ay ka samaystaan qaababka caadiga ah ee Moore-Lewis (kala duduwanka koowaad), si ka fiican muranka iyo qiimaha OOV ee macluumaadka gudaha ku jira. Dhaqdhaqaaqa xiliga ah waxay u bedeshaa si dhaqso u dhaqso, kaas oo ku daboolaya macluumaadka afka gudaha oo dhan, wuxuuna ku qoraa 84% ka yar macluumaadka kale. Intaas waxaa dheer oo loo isticmaali karaa hababka cusub in lagu doorto macluumaadka waxbarashada turjumista machine si loo barayo nidaamka aad u wanaagsan. Fasalkayaga waxay xaqiijiyaan in doorashada fasalka lagu isticmaalo kooxaha Brown waa mid ka bedel kara qaababka fasalka ku saleysan POS, wuxuuna ka ridaa ku tiirsashada qeyb ka mid ah warqadaha hadalka. Sidoo kale waxaynu awoodi karnaa inaannu xaqiijinno qaababka doorashada macluumaadka ee ugu dhowaad ee la soo jeeday, waxaynu tusnaynaa in dhaqdhaqaalaha sameynta SMT ay ka kooban tahay qaababka kala duwan ee caadiga ah ee suuqsinimada
si aad u dhow ayuu u eg yahay dhererka shaqada.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ne paraqesim dhe aplikojmë dy metoda për trajtimin e problemit të zgjedhjes së të dhënave të treinimit të rëndësishme nga një grup i përgjithshëm për përdorim në detyra të tilla si përkthimi i makinave. Duke u mbështetur në punën ekzistuese në modelet e diferencës gjuhësore bazuar në klasë [1], ne së pari futim një metodë bazuar në grupe që përdor grupe kafe për të kondensuar fjalorin e korprës. Secondly, we implement the cynical data selection method [2], which incrementally constructs a training corpus to efficiently model the task corpus. Si metodat e zgjedhjes së të dhënave të bazuara në grupe, ashtu dhe të dhënave cinike përdoren për herë të parë brenda një sistemi përkthimi automatik dhe ne bëjmë një krahasim kokë-kokë. Vlerësimet tona të brendshme tregojnë se të dy metodat e reja tejkalojnë metodën standard Moore-Lewis (ndryshimin ndër-entropi), në lidhje me perplexitet më të mirë dhe normat OOV në të dhënat në domeni. Përqasja cinike konvergon shumë më shpejt, duke mbuluar pothuajse të gjithë fjalorin në domeni me 84% më pak të dhëna se metodat e tjera. Përveç kësaj, qasjet e reja mund të përdoren për të zgjedhur të dhënat e trajnimit të përkthimit të makinave për trajnimin e sistemeve më të mira. Rezultatet tona konfirmojnë se zgjedhja me bazë në klasë duke përdorur klasat Brown është një alternativë e jetueshme ndaj metodave me bazë në klasë POS dhe heq mbështetjen në një pjesë të fjalimit tagger. Përveç kësaj, ne jemi në gjendje të vlerësojmë metodën e zgjedhjes së dhënave cinike të propozuara kohët e fundit, duke treguar se performanca e saj në modelet SMT kalon atë të metodave tradicionale të ndryshimit ndër-entropi dhe më shumë
i përshtatet afër gjatësisë së fjalës së korpusit të detyrës.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Predstavljamo i primjenjujemo dve metode za rješavanje problem a izabranja relevantnih podataka obuke iz općeg bazena za upotrebu u zadataka poput prevoda strojeva. Na temelju postojećeg rada na modelima razlike jezika na klasi [1], prvo predstavljamo metodu na bazi grupa koja koristi Browne skupove kako bi kondenzirali rečnik korpore. Drugo, implementiramo metodu selekcije ciničkih podataka [2], koja povećavajući konstruira trening korpus kako bi efikasno modelio zadatak korpus. Oboje pristupe za izbor ciničkih podataka se koriste za prvi put u sistemu prevoda mašine, a mi obavljamo usporedbu glave na glavu. Naše unutrašnje procjene pokazuju da obe nove metode iznose standardni pristup Moore-Lewisa (krsnoentropijska razlika), u smislu boljih kompleksnosti i stopa OOV-a na podacima u domenu. Cinički pristup se zbližava mnogo brže, pokrivajući skoro sve rečnike u domenu sa 84% manjim podacima od drugih metoda. Osim toga, novi pristupi se mogu iskoristiti za izabranje podataka za obuku automatskih prevoda za bolji sustav obuke. Naši rezultati potvrđuju da je selekcija bazirana na klasi koristeći Browne skupine održiva alternativa za metode bazirane na klasi na POS-u i uklanja pouzdanost na deo govornog značka. Osim toga, mi smo u mogućnosti da potvrdimo nedavno predloženu metodu izbora ciničkih podataka, pokazujući da njegova učinka u modelima SMT-a prelazi tradicionalne metode razlike preko entropije i više
blizu odgovara dužini rečenice poslovnog korpusa.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vi presenterar och tillämpar två metoder för att hantera problemet med att välja relevanta utbildningsdata ur en allmän pool för användning i uppgifter som maskinöversättning. Baserat på befintligt arbete med klassbaserade språkdifferensmodeller [1], introducerar vi först en klusterbaserad metod som använder bruna kluster för att kondensera ordförrådet i korporarna. För det andra implementerar vi den cyniska dataurvalsmetoden [2], som stegvis konstruerar en träningskorpus för att effektivt modellera arbetskorpusen. Både klusterbaserade och cyniska dataval används för första gången inom ett maskinöversättningssystem, och vi gör en head-to-head jämförelse. Våra inneboende utvärderingar visar att de båda nya metoderna överträffar Moore-Lewis standard-metoden (cross-entropi difference), i termer av bättre perplexitet och OOV frekvenser på in-domain data. Det cyniska tillvägagångssättet konvergerar mycket snabbare och täcker nästan hela domänordförrådet med 84% mindre data än de andra metoderna. Dessutom kan de nya metoderna användas för att välja ut utbildningsdata för maskinöversättning för att utbilda bättre system. Våra resultat bekräftar att klassbaserat urval med bruna kluster är ett livskraftigt alternativ till POS-baserade klassbaserade metoder, och tar bort beroende av en del-av-tal taggare. Dessutom kan vi validera den nyligen föreslagna cyniska dataurvalsmetoden, vilket visar att dess prestanda i SMT-modeller överträffar traditionella cross-entropi difference metoder och mer
matchar meningslängden för uppgiftskorpusen.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tunakutana na kutumia mbinu mbili za kutatua tatizo la kuchagua data muhimu za mafunzo kutoka kwenye viwanja jumla kwa ajili ya matumizi katika kazi kama vile tafsiri ya mashine. Kujenga kazi inayopo kwenye mifano ya tofauti ya lugha yenye darasani [1], tunaanzisha kwa mara ya kwanza njia yenye msingi inayotumia viungo vya Brown ili kuendesha maneno ya kampuni hiyo. Pili, tunatekeleza mbinu ya uchaguzi wa taarifa za kawaida[2], ambayo inajenga chombo cha mafunzo kwa ufanisi wa kutengeneza chombo cha kazi. Vyote vinavyoishi na mbinu za uchaguzi wa taarifa za kawaida zimetumika kwa mara ya kwanza ndani ya mfumo wa kutafsiri mashine, na tunafanya ulinganisho mkuu wa juu. Tathmini zetu za ndani zinaonyesha kuwa mbinu mpya zote zinaonyesha mbinu mpya za mwelekeo wa Moore-Lewis (tofauti za kutangazwa kwa watu), kwa sababu ya utata bora na kiwango cha OOV kinachohusu takwimu za ndani. Matokeo ya kawaida yanabadilisha kwa haraka sana, yanayoandika takribani lugha zote za ndani na asilimia 84 chini ya data kuliko njia nyingine. Furthermore, the new approaches can be used to select machine translation training data for training better systems. Matokeo yetu yanathibitisha kuwa uchaguzi wa darasa kwa kutumia viungo vya Brown ni mbadala muhimu wa njia zilizoko kwenye darasa la POS, na kuondoa kutegemea imani kwa sehemu ya alama za hotuba. Kwa nyongeza, tunaweza kuthibitisha njia ya uchaguzi wa takwimu za kiraia za hivi karibuni zinazopendekezwa, zinaonyesha kwamba utendaji wake katika mifano ya SMT unapitisha njia za tofauti za kitamaduni za upatikanaji na zaidi
kwa karibu inafanana na hukumu ya umri wa kazi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>கணினி மொழிபெயர்ப்பு போன்ற பணிகளில் பயன்படுத்துவதற்கான பொதுவான துரிய பயிற்சி தகவலை தேர்ந்தெடுக்கும் பிரச்சனையை நாம வகுப்பு அடிப்படையில் உள்ள மொழி வேறுபாடு மாதிரிகளில் உள்ள வேலை உருவாக்குதல் முதலில் நாம் ஒரு க்ளூஸ்டர் அடிப்படையான முறையை குறிக்கும் ப இரண்டாவது, நாம் சைனிக் தரவு தேர்வு முறைமையை செயல்படுத்துகிறோம் [2], அது வேலை குறியீட்டை வெளிப்படையாக மாதிரியும் பயிற்சி க கணினி மொழிபெயர்ப்பு அமைப்பிற்கு முதல் முறையாக பயன்படுத்தப்படுகிறது, மற்றும் நாம் தலைப்பு தலைப்பு ஒப்பீடு செய்கிறோம். நம்முடைய உள்ளிருக்கும் மதிப்புகள் காண்பிக்கப்பட்டுள்ளது என்றால் இரண்டு புதிய முறைகளும் நிலையான நூர்- லீவிஸ் நெறிமுறையை விட செயல்படுத் சைனிக் செயல்பாடு மிகவும் வேகமாக மாறுகிறது, கிட்டத்தட்ட அனைத்து டோமைன் சொல்வளத்தை மூடுகிறது, மற்ற முறைமைகளை விட 84% கு அதற்கும், புதிய முறைமைகளை பயிற்சி சிறந்த அமைப்புகளுக்கு இயந்திர மொழிபெயர்ப்பு தகவலை தேர்ந்தெடு எங்கள் முடிவுகள் பிரான் கிளாஸ் கிளாஸ்டரை பயன்படுத்தி வகுப்பு தேர்வு உறுதிப்படுத்துகிறது போஸ் அடிப்படையிலான வகுப்பு முறைகளுக்கு ஒரு வி மேலும், நாம் சமீபத்தில் பரிந்துரைக்கப்பட்ட சைனிக்கல் தரவு தேர்வு முறைமையை சரிபார்க்க முடியும், அது SMT மாதிரிகளில் செயல்படுத்தும் பாரம்பர
வேலைக்குறியீட்டின் வாக்கு நீளம் பொருந்தும்.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Maşynyň terjime edilýän işlerde ulanmak üçin uly pool daşarynda nähili eğitim maglumatyny çözmek üçin iki yönden çykýarys we üýtget. Ders tabanly dil üýtgeşmeleri üçin bar işlerine guruldyk [1], başlangyçda kluster tabanly yöntemi korporanyň sözlerini taýýarlamak üçin browny klusterslerden ullanýar. Ikinjisi, kinik maglumaty saýlamak yöntemini ýerine ýetirdik [2], işgärlik korpusyny etkinleýän şekilde üýtgetmek üçin bir bilim korpusyny gurýar. cluster-dan daşarylan we cinik maglumat saýlamasynyň hem ilkinji gezek maşynyň terjime sistemasynda ulanylýar. Biz kellä kellä kellä karşılaştyrylýarys. Bizim iç düşmeklerimiz hem täze yöntemlerimiz standart Moore-Lewis (cross-entropy farklygy), domeniň üstündeki karmaşıklygy we OOV hasaplamalarynyň üstünde çözmesini gösterir. Sinik yaklaşım daha hızlı bir şekilde, domain sözlerinin hepsini 84% daha az veri ile diğer yönlerden kaplıyor. Munuň üçin, täze golaýlar maşynyň terjime etmek üçin gowy sistemlerde okuw etmek üçin ulanyp biler. Biziň netijelerimiz brow sanlaryny ulanan klas tabanly saýlawy POS-dan tabanly klas taýýarlanan yöntemleriň üçin ýeterli bir üýtgedir we güýjüni çykar. Hemmäpli, biz ýakyn teklip eden kinik maglumat saýlawyň yöntemini takyklaşdyryp bileris, SMT nusgalarynda däpli çarpyş-entropi üýtgeşmeleriniň we köp üýtgeşmeleriniň üstünden geçýändigini görkezip bileris.
işiň korpusynyň sözleriň uzunlygyny ýakynlaşýar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ہم نے دو طریقے پیش کیے ہیں اور دو طریقے استعمال کیے ہیں کہ مسئلہ کی تعلیم دادہ کو ایک عمومی پول سے استعمال کریں جیسے ماشین ترجمن کے مطابق استعمال کیے جاتے ہیں۔ کلاس کی بوسیدہ زبان کے متفاوت موڈل پر موجود کام بنانے کے لئے [1] ہم پہلے ایک کلسٹر بنیادی طریقہ کو معلوم کرتے ہیں جو براون کلسٹر کا استعمال کرتا ہے کہ کورپورا کے لکھنے کے لئے کاندنس کرے. دوسرا، ہم نے سینیک ڈیٹا انتخاب طریقہ کو عملہ کر دیا ہے [2], جس نے اضافہ طور پر ایک ٹرینگ کورپوس بنایا ہے تابع کورپوس کی مدل کے لئے. کلسٹر پر بنیاد ہے اور سینیک ڈیٹا انتخاب کے طریقے پہلی بار ایک ماشین ترجمہ سیسٹم کے اندر استعمال کیے جاتے ہیں، اور ہم سر-سر-سر مقایسہ کرتے ہیں. ہماری داخلی تحقیقات دکھاتی ہے کہ دونوں نئی طریقے مور-لوئیس کی طریقہ سے زیادہ استاندارد ہیں (کرس-انٹروپی تفاوت) اچھی پرپرلکتی اور OOV رخصت دامنی پر۔ سینیک طریقہ بہت تیز ترکیب کرتا ہے، قریب ہے کہ دومین میں تمام آواز شناسی کے ساتھ 84% کم ڈیٹا دوسرے طریقے سے چھپاتے ہیں۔ اور اس کے علاوہ، نئی طریقے استعمال کر سکتے ہیں کہ مشین ترینس ترینس ڈیٹا انتخاب کرنے کے لئے بہتر سیستموں کے لئے استعمال کر سکتے ہیں. ہمارے نتیجے مطمئن ہیں کہ براون کلسٹر کے استعمال سے کلاس بنیاد گزینے کا ایک قابل اختیار ہے POS بنیاد کلاس بنیاد رکھے ہوئے طریقے، اور بات ٹیجر کے ایک حصہ پر اعتماد کو ہٹا دیتا ہے. اور اضافہ، ہم نے اچھے سے پیشنهاد کی سینیکی ڈیٹ انتخاب طریقے کی تصدیق کر سکتے ہیں، دکھاتے ہیں کہ اس کی عملکرد SMT موڈلوں میں بہت زیادہ گزر جاتی ہے
تابع کورپوس کے مجلس کی مدت کے مطابق مطابق ہے۔</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Biz hozir qilamiz va mashina tarjima qiladigan vazifalardan foydalanish uchun muhim ta'lim sohasini tanlash uchun ikkita usuldan qoʻllamiz. Faylning birinchi darajadagi tillar o'zgarishga ishni yaratishimiz, birinchi marta, bu kompaniya soʻzni boshqarish uchun Brown clusterlardan foydalanishi mumkin. Ikkinchi so'zda, biz o'sha vazifa kompyuteriga tayyor model qilish uchun foydalanish usulini bajaramiz. Name Bizning ichki qiymatlarimizni ko'rsatishimiz mumkin, yangi usullar bu ikkita oddiy Moore-Lewis usulida (cross-entropy ўзгартиarini) bajaradi va domen maʼlumotlarida yaxshi murakkablik va OOV ratesi. Name Koʻrsatilgan, yangi qoidalar yaxshi tizimni tahrirlash uchun mashina tarjima maʼlumotni tanlash uchun foydalanadi. Bizning natijalarimiz Brown clusterlarni ishlatish uchun sinfning asosida tanlash mumkin, POS asosidagi sinfning asosida o'zgarishga ishonchini olib tashlaydi va gapirish yordamchisining qismini olib tashlash mumkin. Ko'pchilik, biz yaqinda ilova qilingan siniq maʼlumot tanlash usulini bajarishimiz mumkin, bu SMT modelidagi amalni o'xshash o'zgarishga o'zgartiradi va ko'proq o'zgarishni o'zgartiradi.
vazifa qo'shishlarining o'zgarishga murojaat qiladi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Chúng tôi giới thiệu và áp dụng hai phương pháp để giải quyết vấn đề lựa chọn dữ liệu giáo dục liên quan ra khỏi một hồ sơ chung để sử dụng trong các công việc như dịch thuật máy. Dựa trên công trình dựa trên các mô hình ngôn ngữ khác nhau tại lớp[1] Đầu tiên chúng tôi giới thiệu một phương pháp dựa vào cụm thiên văn dùng cụm Trường Nâu để kết hợp các cụm từ của cơ thể. Thứ hai, chúng ta thực hiện phương pháp bí ẩn lựa chọn dữ liệu (2), mà xây dựng dần một tập thể huấn để mô hình hiệu quả tập đoàn các nhiệm vụ. Cả các phương pháp lựa chọn dữ liệu dựa trên cụm và hoài nghi được sử dụng lần đầu tiên trong một hệ thống dịch chuyển máy, và chúng tôi tiến hành so sánh từ đầu tới đầu. Bản đánh giá của chúng tôi cho thấy cả hai phương pháp mới vượt qua tiêu chuẩn Moore-Lewis (khác nhau về phương trình tồn tại khác nhau, về mặt phức tạp hơn và giá OOOV trên dữ liệu nội bộ. Sự hoài nghi của chúng ta hội tụ nhanh hơn nhiều, bao gồm gần hết các từ điển trong miền với 84=.* ít dữ liệu hơn các phương pháp khác. Hơn nữa, các phương pháp mới có thể được dùng để chọn dữ liệu đào tạo dịch chuyển máy để đào tạo hệ thống tốt hơn. Những kết quả của chúng tôi xác nhận việc chọn dựa vào lớp Brown sẽ là một sự thay đổi khả thi cho các phương pháp dựa trên lớp POS, và xóa bỏ sự dựa dẫm vào một phần của câu khẩu phần. Thêm vào đó, chúng tôi có thể xác nhận phương pháp bí ẩn chọn dữ liệu đã được đề nghị gần đây, cho thấy hiệu quả của nó trong mô hình SMT vượt trội so với các phương pháp khác nhau truyền thống và nhiều hơn
Khớp với độ dài của tập đoàn này.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>臣等请用二法以决之,择相关训练,以施机器翻译等事。 盖言语异[1],先引一聚类之法,用Brown聚类压缩语料库之词汇量。 其次,遂愤世嫉俗之数据选择法[2],增量构一练语料库,以效语料库建模。 盖集群愤世嫉俗之数据选择,首用机器翻译统,比之头也。 吾等内评,此二法域内数有佳困惑度与OOV率优于格摩尔-刘易斯法(交熵差)。 愤世嫉俗之法,收敛愈速,几涵盖一切域内词汇,数少于他84%。 此外,新法可于择机器翻译练数,以练善统。 臣等证之,用Brown集群之基于类者,POS之基于类者,可以代方,而消词性器之所恃也。 又验近世愤世嫉俗之数据选择,明SMT形之性过于旧熵差也。
与任语料库句相匹。</span></div></div><dl><dt>Anthology ID:</dt><dd>2017.iwslt-1.19</dd><dt>Volume:</dt><dd><a href=/volumes/2017.iwslt-1/>Proceedings of the 14th International Conference on Spoken Language Translation</a></dd><dt>Month:</dt><dd>December 14-15</dd><dt>Year:</dt><dd>2017</dd><dt>Address:</dt><dd>Tokyo, Japan</dd><dt>Venue:</dt><dd><a href=/venues/iwslt/>IWSLT</a></dd><dt>SIG:</dt><dd><a href=/sigs/sigslt/>SIGSLT</a></dd><dt>Publisher:</dt><dd>International Workshop on Spoken Language Translation</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>137–145</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2017.iwslt-1.19>https://aclanthology.org/2017.iwslt-1.19</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">santamaria-axelrod-2017-data</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Lucía Santamaría and Amittai Axelrod. 2017. <a href=https://aclanthology.org/2017.iwslt-1.19>Data Selection with Cluster-Based Language Difference Models and Cynical Selection</a>. In <i>Proceedings of the 14th International Conference on Spoken Language Translation</i>, pages 137–145, Tokyo, Japan. International Workshop on Spoken Language Translation.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2017.iwslt-1.19>Data Selection with Cluster-Based Language Difference Models and Cynical Selection</a> (Santamaría & Axelrod, IWSLT 2017)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2017.iwslt-1.19.pdf>https://aclanthology.org/2017.iwslt-1.19.pdf</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2017.iwslt-1.19.pdf title="Open PDF of 'Data Selection with Cluster-Based Language Difference Models and Cynical Selection'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Data+Selection+with+Cluster-Based+Language+Difference+Models+and+Cynical+Selection" title="Search for 'Data Selection with Cluster-Based Language Difference Models and Cynical Selection' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'Data Selection with Cluster-Based Language Difference Models and Cynical Selection'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[Data Selection with Cluster-Based Language Difference Models and Cynical Selection](https://aclanthology.org/2017.iwslt-1.19) (Santamaría & Axelrod, IWSLT 2017)</p><ul class=mt-2><li><a href=https://aclanthology.org/2017.iwslt-1.19>Data Selection with Cluster-Based Language Difference Models and Cynical Selection</a> (Santamaría & Axelrod, IWSLT 2017)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Lucía Santamaría and Amittai Axelrod. 2017. <a href=https://aclanthology.org/2017.iwslt-1.19>Data Selection with Cluster-Based Language Difference Models and Cynical Selection</a>. In <i>Proceedings of the 14th International Conference on Spoken Language Translation</i>, pages 137–145, Tokyo, Japan. International Workshop on Spoken Language Translation.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>