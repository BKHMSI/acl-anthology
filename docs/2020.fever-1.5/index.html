<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Language Models as Fact Checkers? - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="Language Models as Fact Checkers?" name=citation_title><meta content="Nayeon Lee" name=citation_author><meta content="Belinda Z. Li" name=citation_author><meta content="Sinong Wang" name=citation_author><meta content="Wen-tau Yih" name=citation_author><meta content="Hao Ma" name=citation_author><meta content="Madian Khabsa" name=citation_author><meta content="Proceedings of the Third Workshop on Fact Extraction and VERification (FEVER)" name=citation_conference_title><meta content="2020/7" name=citation_publication_date><meta content="https://aclanthology.org/2020.fever-1.5.pdf" name=citation_pdf_url><meta content="36" name=citation_firstpage><meta content="41" name=citation_lastpage><meta content="10.18653/v1/2020.fever-1.5" name=citation_doi><meta property="og:title" content="Language Models as Fact Checkers?"><meta property="og:image" content="https://aclanthology.org/thumb/2020.fever-1.5.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2020.fever-1.5"><meta property="og:description" content="Nayeon Lee, Belinda Z. Li, Sinong Wang, Wen-tau Yih, Hao Ma, Madian Khabsa. Proceedings of the Third Workshop on Fact Extraction and VERification (FEVER). 2020."><link rel=canonical href=https://aclanthology.org/2020.fever-1.5></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2020.fever-1.5.pdf>Language Models as Fact Checkers?</a>
<a id=af_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Taal Modelle as Fact Checkers?</a>
<a id=am_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>ቋንቋዎች</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>نماذج اللغة كمدقق للحقائق؟</a>
<a id=az_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Dil modell톛ri Fact Checkers kimi?</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Езикови модели като проверка на фактите?</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>ভাষা মোডেল ফ্যাক্ট চেকার হিসেবে?</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>སྐད་ཡིག་གཟུགས་རིས་དེབ་ལྟ་ཞིབ་བྱེད་བཞིན་པ་ཡིན་ནམ</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Jezikovi modeli kao provjeravači činjenica?</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Models de llenguatgecom a Verificadors de Factes?</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Jazykové modely jako kontrola faktů?</a>
<a id=da_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Sprogmodeller som fakta kontrollere?</a>
<a id=de_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Sprachmodelle als Fact Checker?</a>
<a id=el_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Γλωσσικά μοντέλα ως ελεγκτές γεγονότων;</a>
<a id=es_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>¿Modelos de lenguaje como verificadores de datos?</a>
<a id=et_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Keelemudelid faktide kontrollijana?</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>مدل زباني به عنوان بررسي حقيقت؟</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Kielimallit faktojen tarkistamiseksi?</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Les modèles linguistiques en tant que vérificateurs de faits ?</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Múnlaí Teanga mar Seiceálaithe Fíricí?</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>@ action</a>
<a id=he_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Language Models as Fact Checkers?</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>फैक्ट चेकर्स के रूप में भाषा मॉडल?</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Jezički modeli kao provjeravači činjenica?</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Nyelvi modellek, mint tény ellenőrzők?</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Լեզվի մոդելները՝ փաստերի վերահսկողները:</a>
<a id=id_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Model bahasa sebagai pemeriksa fakta?</a>
<a id=is_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Modelli linguistici come controllori dei fatti?</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>ファクトチェッカーとしての言語モデル？</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Language</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>ენვგური მოდელები როგორც ფაქტის შემოწმება?</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Тіл үлгілері факт тексерушілері ретінде?</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>사실 검증원으로서의 언어 모델?</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Kalbos modeliai kaip faktų tikrintojai?</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Модели на јазик како проверки на факти?</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>ഭാഷ മോഡലുകള്‍ ഫാക്റ്റ് ചെക്കര്‍ എന്നാണോ?</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Холны загваруудыг Фактикийн Шекерүүд гэж үү?</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Model Bahasa sebagai Pemeriksa Fakta?</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Mudelli lingwistiċi bħala Kontrollaturi tal-Fatti?</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Taalmodellen als fact Checkers?</a>
<a id=no_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Språk- modeller som faktisksjekkarar?</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Modele językowe jako sprawdzające fakty?</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Modelos de linguagem como verificadores de fatos?</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Modele lingvistice ca verificători de fapte?</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Языковые модели как средства проверки фактов?</a>
<a id=si_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>භාෂාව ප්‍රමාණය ඇත්ත පරීක්ෂකයෙක් විදියට?</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Jezikovni modeli za preverjanje dejstev?</a>
<a id=so_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Isticmaalka afka sida jardiinooyinka afka?</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Modelet e gjuhës si Kontrollues të Fakteve?</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Jezikovi modeli kao èinjenici?</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Språkmodeller som faktakontroller?</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Modeli za lugha kama Wachunguzi?</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>மொழி மாதிரிகள் உண்மை சரிபார்ப்பார்களாக?</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Diller</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Language Models as facts Checkers?</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Tilning modellari faqat tekshiruvchisi sifatida?</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>Ngôn ngữ mẫu như Dịch vụ Checkers?</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2020.fever-1.5.pdf>语言模为实核查员?</a></h2><p class=lead><a href=/people/n/nayeon-lee/>Nayeon Lee</a>,
<a href=/people/b/belinda-z-li/>Belinda Z. Li</a>,
<a href=/people/s/sinong-wang/>Sinong Wang</a>,
<a href=/people/w/wen-tau-yih/>Wen-tau Yih</a>,
<a href=/people/h/hao-ma/>Hao Ma</a>,
<a href=/people/m/madian-khabsa/>Madian Khabsa</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Recent work has suggested that language models (LMs) store both common-sense and factual knowledge learned from pre-training data. In this paper, we leverage this implicit knowledge to create an effective end-to-end fact checker using a solely a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a>, without any external knowledge or explicit retrieval components. While previous work on extracting knowledge from LMs have focused on the task of open-domain question answering, to the best of our knowledge, this is the first work to examine the use of language models as <a href=https://en.wikipedia.org/wiki/Fact-checking>fact checkers</a>. In a closed-book setting, we show that our zero-shot LM approach outperforms a random baseline on the standard FEVER task, and that our finetuned LM compares favorably with standard baselines. Though we do not ultimately outperform methods which use explicit knowledge bases, we believe our exploration shows that this method is viable and has much room for exploration.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Onlangse werk het voorgestel dat taal modele (LMs) gemeenskap-sens en faktuurlike kennis geleer het van voor-oefening data. In hierdie papier, het ons hierdie inplisite kennis gebruik om 'n effektief end-to-end faktuur toets te skep deur 'n slegs 'n taal model te gebruik, sonder enige eksterne kennis of eksplisiese ontvang komponente. Terwyl die vorige werk op die uitpakking van kennis van LMs gefokus het op die taak van open-domein vraag antwoord, tot die beste van ons kennis, is dit die eerste werk om die gebruik van taal modele as feit kontroleerders te ondersoek. In 'n gesluit boek instelling, wys ons dat ons nul-skoot LM toegang uitvoer 'n willekeurige basisline op die standaard FEVER taak, en dat ons fine LM vergelyk genadig met standaard basisline. Alhoewel ons nie eindelik uitvoer metodes wat eksplisiese kennis bases gebruik nie, glo ons ons uitvoer wys dat hierdie metode beskikbaar is en het baie kamer vir uitvoer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>የቀድሞው ሥራ የቋንቋ ምሳሌዎች (LMs) ከቅድሚያ ተማሪ ዳታዎች የተማረ የውይይት እና የእውቀትን እውቀት ለማስቀመጥ ያሳያል፡፡ በዚህ ካላት፣ በውጭ እውቀት ወይም ግልፅ ማሳየት አንዳች የቋንቋ ምሳሌ ሳይኖር፣ የቋንቋ ምሳሌ መፍጠርን እናደርጋለን፡፡ የቀድሞው የLMs እውቀትን ለመውጣት የሚደረገውን ሥራ ከክፈት ዶሜን ጠያቂዎች መልስ ስራትን ያስተካክሎታል፡፡ በተዘጋጀ መጽሐፍ ውስጥ የኮሌዶችን የLM ሥርዓት የFEVER ሥርዓት ላይ የተለየ የደረጃ መሠረት እንዲያሳየው እናሳየዋለን፤ የተጠቃሚ LM ግን ከዓላማ መቀመጫዎች ጋር ያሳያል፡፡ ምንም እንኳን የግልጽ እውቀት መቀመጫን የሚጠይቁ ሥርዓቶችን ባናደርግም እንምናለን፣ ይህ ሥርዓት የሚቻልበት እና ለመመረመር ብዙ ፋንታ አለበት ብለን እናምናለን፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>اقترح العمل الأخير أن نماذج اللغة (LMs) تخزن كل من الفطرة السليمة والمعرفة الواقعية المستفادة من بيانات ما قبل التدريب. في هذه الورقة ، نستفيد من هذه المعرفة الضمنية لإنشاء مدقق حقائق فعال شامل باستخدام نموذج لغة فقط ، دون أي معرفة خارجية أو مكونات استرجاع صريحة. بينما ركز العمل السابق على استخراج المعرفة من LMs على مهمة الإجابة على أسئلة المجال المفتوح ، على حد علمنا ، هذا هو العمل الأول لفحص استخدام نماذج اللغة كمدقق للحقائق. في إعداد الكتاب المغلق ، نظهر أن نهجنا LM ذي اللقطة الصفرية يتفوق على خط الأساس العشوائي في مهمة FEVER القياسية ، وأن LM المُحسَّن لدينا يُقارن بشكل إيجابي مع خطوط الأساس القياسية. على الرغم من أننا لا نتفوق في النهاية على الأساليب التي تستخدم قواعد المعرفة الواضحة ، إلا أننا نعتقد أن استكشافنا يوضح أن هذه الطريقة قابلة للتطبيق ولديها مجال كبير للاستكشاف.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Son işdə dil modelləri (LMs) öyrəndiklərindən öyrəndiyi həmçinin ortaq anlayışlıq və həmçinin həmçinin həmçinin həmçinin həmçinin həmçinin həmçinin həmçinin həmçinin həmçinin həmçinin həm Bu kağızda, biz bu imkansız bilgi, sadəcə dil modelini istifadə edərək, heç bir dış bilgi və yaxud a çıq bilgi komponentləri olmadan effektiv bir qiyməti təşkil etmək üçün istifadə edirik. LMs elmlərini çıxartmaq üçün əvvəlki işlər açıq-domain sual cavab verməsi üçün, elmlərimizin ən yaxşısına baxmayaraq, bu ilk işlər dil modellərin istifadəsini həqiqət təsdiqçiləri kimi təsdiqlənməkdir. Qapılmış kitab ayarlarında, sıfır-vuruş LM tərəfimizin standart FEVER işində rastgele bir tərəfli çətinlikdən üstün olduğunu göstərdik və bizim gözəl LM standart tərəfli çətinliklərlə yaxşılıq edir. Əlbəttə də biz açıq bilgi üssələrini istifadə edən metodların üstünə çıxmadığımıza inanırıq ki, araşdırmalarımız bu metodların həyat verə biləcəyini və keşif üçün çox yer var.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Последните изследвания показват, че езиковите модели съхраняват както здравия разум, така и фактическите знания, придобити от данни преди обучението. В тази статия ние използваме тези имплицитни знания, за да създадем ефективна проверка на фактите от край до край, използвайки единствено езиков модел, без никакви външни знания или изрични компоненти за извличане. Докато предишната работа по извличане на знания от УМ се фокусира върху задачата за отговор на въпроси с отворен домейн, доколкото знаем, това е първата работа, която изследва използването на езикови модели като проверяващи факти. В затворена книга показваме, че нашият подход с нулев изстрел надминава случайна базова линия при стандартната задача и че нашият фино настроен ЛМ се сравнява благоприятно със стандартните базови линии. Въпреки че в крайна сметка не превъзхождаме методите, които използват изрични бази от знания, ние вярваме, че нашето изследване показва, че този метод е жизнеспособен и има много място за изследване.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Recent work has suggested that language models (LMs) store both common-sense and factual knowledge learned from pre-training data. এই কাগজটিতে আমরা একটি ভাষার মডেল ব্যবহার করে একটি কার্যকর শেষ পরীক্ষক সৃষ্টি করার জন্য এই প্রাপ্ত জ্ঞান প্রদান করি যাতে কোন বাইরে কোন জ্ঞান নেই অথবা পুনর এলএমএস থেকে জ্ঞান বের করার পূর্ববর্তী কাজ যখন উন্মুক্ত ডোমেইন প্রশ্নের উত্তর দিয়ে মনোযোগ প্রদান করেছে, তখন আমাদের জ্ঞানের সর্বোচ্চ কাজের প্রতি এটা হচ্ একটি বন্ধ বই ব্যবস্থায়, আমরা দেখাচ্ছি যে আমাদের শূন্যগুলো এলএম-এর প্রতিযোগিতা স্ট্যান্ডার্ডার ফেভার কাজের উপর একটি বেসালাইন প্রকাশ করে, আর আমাদের সু যদিও আমরা শেষ পর্যন্ত প্রকাশ্য জ্ঞানের বেস ব্যবহার করি না কিন্তু আমরা বিশ্বাস করি আমাদের গবেষণা দেখাচ্ছে যে এই পদ্ধতি ব্যবস্থা এবং অনুসন্</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>འཕྲལ་གསོག་ཀྱི་ལས་འགན་སྤྲོད་དེ་ནི་སྐད་ཡིག་ཆའི་མིག་དཔེ་གཟུགས་རིས་མང་ཙམ་ཉར་ཚགས In this paper, we leverage this implicit knowledge to create an effective end-to-end fact checker using a solely a language model, without any external knowledge or explicit retrieval components. LMs་ལས་སྔོན་གྱི་ལས་འགན་སྤྱད་ནས་མཐུན་རྣམས་ལས་གནད་དོན་གྱིས་open-domain འདྲི་ཚིག་གནད་དོན་ལ་ང་ཚོའི་ཤེས་ཡོད་ཚད་ལྟ་བུ་ཞིབ་འཇུག་པའི་ལས་འགན་བ In a closed-book setting, we show that our zero-shot LM approach outperforms a random baseline on the standard FEVER task, and that our finetuned LM compares favorably with standard baselines. ང་ཚོས་དང་མཐའ་མཇུག་རྫོགས་མ་ཐུབ་པར་ཕྱོགས་སྟོན་པའི་གནས་ཚུལ་གཞི་རྩལ་བ་སྤྱོད་ཐབས་མེད་ཀྱང་། ང་ཚོས་འཚོལ་ཞིབ་བཤེར</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nedavno je rad predložio da jezički modeli (LMs) čuvaju zajedničke smisla i činjenične znanje koje su naučene iz podataka o predobuci. U ovom papiru, iskorištavamo to implicitno znanje da bi stvorili efikasni provjeravač činjenica na kraju koristeći samo jezički model, bez bilo kakvih vanjskih znanja ili eksplicitnih komponenta povlačenja. Iako je prethodni posao o izvlačenju znanja iz LMs-a usredotočen na zadatak odgovora na pitanje otvorenog domena, na najbolje od našeg znanja, to je prvi posao koji je pregledao korištenje jezičkih modela kao provjeravača činjenica. U sklopu zatvorenih knjiga pokazujemo da naš pristup LM-a od nule pucnjave iznosi nasumičnu početnu liniju na standardnom zadatku FEVER-a, i da naš fini LM uspoređuje favoritno sa standardnim osnovnim linijama. Iako na kraju ne izvršavamo metode koje koriste jasne baze znanja, vjerujemo da naša istraživanja pokazuje da je ovaj metod živ i ima mnogo mjesta za istraživanje.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Recent work has suggested that language models (LMs) store both common-sense and factual knowledge learned from pre-training data. En aquest paper, aprofitem aquest coneixement implícit per crear un controlador efectiu de fets de final a final utilitzant només un model de llenguatge, sense cap coneixement extern ni components de recuperació explícita. Mentre que la feina anterior sobre l'extracció del coneixement de les ML s'ha centrat en la tasca de resposta a preguntes de domini obert, pel millor que sabem, aquesta és la primera feina per examinar l'ús de models lingüístics com a verificadors de fets. En un entorn de llibre tancat, demostram que el nostre enfocament de zero-shot LM supera una línia de referència aleatòria en la tasca standard FEVER, i que el nostre LM finat es compara favorablement amb línies de referència standard. Encara que finalment no superem els mètodes que utilitzen bases de coneixement explícites, creiem que la nostra exploració demostra que aquest mètode és viable i té molt espai d'exploració.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nedávné práce naznačují, že jazykové modely (LM) ukládají jak zdravý rozum, tak faktické znalosti získané z předškolených dat. V tomto článku využíváme implicitní znalosti k vytvoření efektivního end-to-end ověřovače faktů pomocí výhradně jazykového modelu, bez jakýchkoli externích znalostí nebo explicitních složek retrievalu. Zatímco předchozí práce na extrahování znalostí z LM se zaměřila na úlohu odpovědi na otázky otevřené domény, podle našich nejlepších znalostí je to první práce, která zkoumá využití jazykových modelů jako kontroly faktů. V nastavení uzavřené knihy ukazujeme, že náš přístup s nulovým výstřelem LM překoná náhodnou základní linii standardního úkolu FEVER a že náš jemně vyladěný LM se příznivě srovnává se standardními základními liniemi. Ačkoli nakonec nepřekonáme metody, které využívají explicitní znalostní báze, věříme, že náš průzkum ukazuje, že tato metoda je životaschopná a má velký prostor pro průzkum.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Det seneste arbejde har antydet, at sprogmodeller gemmer både sund fornuft og faktisk viden fra data før uddannelsen. I denne artikel udnytter vi denne implicitte viden til at skabe en effektiv end-to-end fact checker ved hjælp af en udelukkende sprogmodel, uden ekstern viden eller eksplicitte hentningskomponenter. Mens tidligere arbejde med at udvinde viden fra LM'er har fokuseret på opgaven med open-domæne spørgsmål besvarelse, så vidt vi ved, er dette det første arbejde, der undersøger brugen af sprogmodeller som fact checkers. I en lukket bog-indstilling viser vi, at vores nulskud LM tilgang overgår en tilfældig baseline på standard FEVER opgave, og at vores finjusterede LM sammenligner positivt med standard baselines. Selvom vi ikke i sidste ende overgår metoder, der bruger eksplicitte vidensbaser, mener vi, at vores udforskning viser, at denne metode er levedygtig og har meget plads til udforskning.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Jüngste Arbeiten deuten darauf hin, dass Sprachmodelle (LMs) sowohl gesundes Menschenverstand als auch sachliches Wissen speichern, das aus Daten vor dem Training gelernt wurde. In diesem Beitrag nutzen wir dieses implizite Wissen, um einen effektiven End-to-End Fact Checker zu erstellen, der ausschließlich ein Sprachmodell verwendet, ohne externe Kenntnisse oder explizite Retrieval Komponenten. Während sich frühere Arbeiten zur Extraktion von Wissen aus LMs auf die Aufgabe der offenen Fragebeantwortung konzentrierten, ist dies nach bestem Wissen die erste Arbeit, die den Einsatz von Sprachmodellen als Fact Checker untersucht. In einem geschlossenen Buch zeigen wir, dass unser Zero-Shot-LM-Ansatz eine zufällige Baseline auf der Standard-FEVER-Aufgabe übertrifft und dass unser fein abgestimmtes LM sich günstig mit Standard-Baselines vergleicht. Obwohl wir Methoden, die explizite Wissensgrundlagen verwenden, nicht letztendlich übertreffen, glauben wir, dass unsere Exploration zeigt, dass diese Methode praktikabel ist und viel Raum für Exploration bietet.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Πρόσφατες εργασίες έχουν προτείνει ότι τα γλωσσικά μοντέλα (LM) αποθηκεύουν τόσο την κοινή λογική όσο και τις πραγματικές γνώσεις που αποκτήθηκαν από τα δεδομένα προ-κατάρτισης. Σε αυτή την εργασία, αξιοποιούμε αυτή τη σιωπηρή γνώση για να δημιουργήσουμε έναν αποτελεσματικό ολοκληρωμένο έλεγχο γεγονότων χρησιμοποιώντας ένα μόνο γλωσσικό μοντέλο, χωρίς καμία εξωτερική γνώση ή ρητά συστατικά ανάκτησης. Ενώ οι προηγούμενες εργασίες για την εξαγωγή γνώσεων από LM έχουν επικεντρωθεί στο έργο της απάντησης σε ερωτήσεις ανοικτού τομέα, από όσο γνωρίζουμε, αυτή είναι η πρώτη εργασία που εξετάζει τη χρήση γλωσσικών μοντέλων ως ελεγκτές γεγονότων. Σε μια ρύθμιση κλειστού βιβλίου, δείχνουμε ότι η προσέγγισή μας μηδενικής βολής ξεπερνά μια τυχαία γραμμή βάσης στην τυπική εργασία και ότι η λεπτομέτρησή μας συγκρίνεται ευνοϊκά με τις τυπικές γραμμές βάσης. Αν και τελικά δεν ξεπερνάμε τις μεθόδους που χρησιμοποιούν ρητές βάσεις γνώσης, πιστεύουμε ότι η έρευνά μας δείχνει ότι αυτή η μέθοδος είναι βιώσιμη και έχει πολύ χώρο για εξερεύνηση.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Un trabajo reciente ha sugerido que los modelos de lenguaje (LM) almacenan tanto el conocimiento de sentido común como el conocimiento fáctico aprendido de los datos previos al entrenamiento. En este artículo, aprovechamos este conocimiento implícito para crear un verificador de hechos eficaz de principio a fin utilizando únicamente un modelo de lenguaje, sin ningún conocimiento externo ni componentes de recuperación explícitos. Mientras que el trabajo anterior sobre la extracción de conocimiento de los LM se ha centrado en la tarea de responder a preguntas de dominio abierto, hasta donde sabemos, este es el primer trabajo que examina el uso de modelos de lenguaje como verificadores de hechos. En un entorno a libro cerrado, demostramos que nuestro enfoque de LM de tiro cero supera a una línea de base aleatoria en la tarea FEVER estándar, y que nuestra LM ajustada se compara favorablemente con las líneas de base estándar. Aunque en última instancia no superamos a los métodos que utilizan bases de conocimiento explícitas, creemos que nuestra exploración demuestra que este método es viable y tiene mucho espacio para la exploración.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Hiljutised tööd on näidanud, et keelemudelid säilitavad nii terve mõistuse kui ka faktilisi teadmisi, mis on saadud koolituseelsetest andmetest. Käesolevas dokumendis kasutame neid kaudseid teadmisi, et luua tõhus lõpp-lõpuni faktide kontrollija, kasutades ainult keelemudelit, ilma väliste teadmiste või selgesõnaliste päringukomponentideta. Kuigi varasemad tööd teadmiste väljavõtmiseks LMidest on keskendunud avatud domeenile küsimustele vastamise ülesandele, on see meie parimate teadmiste kohaselt esimene töö, milles uuritakse keelemudelite kasutamist faktikontrollijatena. Suletud raamatu seadetes näitame, et meie null-shot LM lähenemine ületab juhusliku lähtejoone standardülesande FEVER puhul ja et meie täpsustatud LM võrdleb soodsalt standardsete lähtejoontega. Kuigi me ei suuda lõppkokkuvõttes ületada meetodeid, mis kasutavad selgeid teadmistebaase, usume, et meie uurimine näitab, et see meetod on elujõuline ja sellel on palju ruumi uurimiseks.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>کارهای اخیرا پیشنهاد داده است که مدل زبان (LMs) از اطلاعات پیش آموزش یاد گرفته‌اند و دانش معمولی و حقیقی را فروش می‌دهند. در این کاغذ، ما این دانش غیر قابل توجه می‌کنیم تا یک بررسی‌کننده‌ی حقیقت‌های پایان و پایان موثر را با استفاده از یک مدل زبانی استفاده کنیم، بدون هیچ دانش خارجی یا بخش‌های بازیابی مشخص. در حالی که کارهای قبلی در اخراج علم از خانم‌ها روی کار جواب سوال‌های دامنی باز، به بهترین دانش‌های ما تمرکز کرده‌اند، این اولین کاری است که استفاده از مدل‌های زبان را به عنوان بررسی‌کنندگان حقیقت تحقیق می‌کند. در یک تنظیمات کتاب بسته، نشان می دهیم که دستور LM صفر-شلیک ما از یک خط بنیادی تصادفی بر روی کار FEVER استاندارد برتر است، و اینکه LM بی‌نیاز ما به طور مناسب با خط بنیادی استاندارد مقایسه می‌کند. اگرچه در نهایت ما روش‌هایی که استفاده از پایگاه‌های علمی روشن نیستیم، باور می‌کنیم که کشف‌های ما نشان می‌دهند که این روش قابل زندگی است و برای کشف‌ها جای زیادی دارد.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Viimeaikaiset tutkimukset ovat osoittaneet, että kielimallit tallentavat sekä tervettä järkeä että faktatietoa, joka on saatu esiopetuksesta. Tässä artikkelissa hyödynnämme tätä implisiittistä tietoa luodaksemme tehokkaan end-to-end faktatarkistajan käyttäen yksinomaan kielimallia, ilman ulkoista tietoa tai nimenomaisia hakukomponentteja. Vaikka aikaisempi työ tiedon poimimiseksi LM:istä on keskittynyt avoimen verkkotunnuksen kysymyksiin vastaamiseen, parhaamme mukaan tämä on ensimmäinen työ, jossa tarkastellaan kielimallien käyttöä faktojen tarkastajina. Suljetussa kirjassa osoitamme, että nolla-shot LM-lähestymistapamme suoriutuu satunnaisesti tavanomaisessa FEVER-tehtävässä ja että hienosäädetty LM-lähestymistapamme on edullisesti verrattuna tavanomaisiin perusviivoihin. Vaikka emme viime kädessä ylitä menetelmiä, jotka käyttävät eksplisiittistä tietopohjaa, uskomme tutkimuksemme osoittavan, että tämä menetelmä on toteuttamiskelpoinen ja siinä on paljon tilaa tutkia.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Des travaux récents ont suggéré que les modèles linguistiques (LM) stockent à la fois des connaissances de bon sens et des connaissances factuelles apprises à partir des données pré-formation. Dans cet article, nous exploitons ces connaissances implicites pour créer un vérificateur de faits de bout en bout efficace utilisant uniquement un modèle linguistique, sans aucune connaissance externe ni composants de récupération explicites. Alors que les travaux précédents sur l'extraction de connaissances à partir des LM se sont concentrés sur la tâche de répondre à des questions de domaine ouvert, au meilleur de nos connaissances, il s'agit du premier travail à examiner l'utilisation de modèles linguistiques comme vérificateurs de faits. Dans un contexte de livre fermé, nous montrons que notre approche LM à tir zéro surpasse une base aléatoire sur la tâche standard FEVER, et que notre LM affinée se compare favorablement aux lignes de base standard. Bien que nous n'obtenions pas de meilleurs résultats que les méthodes qui utilisent des bases de connaissances explicites, nous pensons que notre exploration montre que cette méthode est viable et qu'il y a beaucoup de place pour l'exploration.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tá sé tugtha le tuiscint in obair a rinneadh le déanaí go stórálann samhlacha teanga (LManna) eolas ciallmhar agus fíorasach a foghlaimíodh ó shonraí réamhoiliúna. Sa pháipéar seo, déanaimid an t-eolas intuigthe seo a ghiaráil chun seiceálaí fíorais éifeachtach ó cheann go ceann a chruthú a úsáideann múnla teanga amháin, gan aon eolas seachtrach ná comhpháirteanna aisghabhála follasacha. Cé gur dhírigh obair a rinneadh roimhe seo ar bhaint eolais ó LManna ar an tasc a bhaineann le ceisteanna oscailte a fhreagairt, chomh fada agus is eol dúinn, is é seo an chéad obair a scrúdaíodh úsáid na múnlaí teanga mar sheiceálaithe fíricí. I suíomh leabhar dúnta, léirímid go n-éiríonn lenár gcur chuige LM náid náid ná bunlíne randamach ar an ngnáth-thasc FEVER, agus go bhfuil comparáid fhabhrach idir ár LM miontiúnta agus bunlínte caighdeánacha. Cé nach n-éiríonn linn níos fearr ar deireadh le modhanna a úsáideann bunáiteanna eolais follasacha, creidimid go léiríonn ár n-iniúchadh go bhfuil an modh seo inmharthana agus go bhfuil go leor spáis ann le haghaidh taiscéalaíochta.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Yin aikin da aka yanzu ya shauri cewa misãlai na harshen (LM) za'a adana duk sanin da aka sanar da su daga data na zaman shawara. Daga wannan takardan, Munã ƙarfafa wannan ilmi wanda ba ta iya sani ba dõmin ka ƙiƙiro wani mai tsaro na ƙarama zuwa ƙarami, yana amfani da wani misali na harshen kawai, ko kuma babu wani ilmi na ƙarƙashin ko da ake samun motsi mai bayyanãwa. Ko da aikin da ya gabata a sami da fitarwa da ilmi daga LM ya fokus wa aikin da za'a karɓa wa masu tambayar buɗe-Domen, zuwa mafi kyaun sani, wannan na farkon aikin ka jarraba amfani da misalin harshen kamar shirin zaɓangare. Daga wani takarda littafin da aka rufe, za mu nuna cewa hanyarmu na LM-da-shekara ba ta samar da ranar bango a kan aikin FEWR na daidaita, kuma da kuma an daidaita LM masu amfani da kwamfyutan bango. Haƙĩƙa, kuma ba mu sami ko ƙarami hanyoyin su da ke amfani da bassi masu bayyani ga ilmi, sai munã ĩmãni cewa misalinmu yana da cẽwa wannan hanyor zai iya amfani da kuma yana da wuri mai yawa ga yin fitina.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>העבודה האחרונה הציעה שדוגמני שפה (LMs) מחסנים גם ידע שפוי וגם ידע עובד שנלמד מידע לפני האימונים. בעיתון הזה, אנו משתמשים בידע מרושע הזה כדי ליצור בדיקת עובדות יעילה סוף-סוף באמצעות מודל שפה בלבד, ללא כל ידע חיצוני או רכיבים חיצוניים. בעוד העבודה הקודמת על החולץ ידע מLMs התמקדו במשימה של עניין לשאלות בתחום פתוח, לטובת הידע שלנו, זו העבודה הראשונה לבדוק את השימוש של דוגמני שפה כמבדקת עובדות. בסיס ספר סגור, אנו מראים שגישת LM אפס-ירייה שלנו מעלית בסיס אקראי במשימת FEVER הסטנדרטית, ושLM המתאים שלנו משווה בצורה טובה עם בסיסים סטנדרטיים. למרות שאנחנו לא בסופו של דבר מתגברים על שיטות אשר משתמשות בסיסי ידע ברורים, אנו מאמינים שהחקירה שלנו מראה כי השיטה הזאת חיה ויש לה הרבה מקום לחקור.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>हाल के काम ने सुझाव दिया है कि भाषा मॉडल (एलएम) पूर्व-प्रशिक्षण डेटा से सीखे गए सामान्य ज्ञान और तथ्यात्मक ज्ञान दोनों को संग्रहीत करते हैं। इस पेपर में, हम किसी भी बाहरी ज्ञान या स्पष्ट पुनर्प्राप्ति घटकों के बिना, पूरी तरह से एक भाषा मॉडल का उपयोग करके एक प्रभावी एंड-टू-एंड फैक्ट चेकर बनाने के लिए इस अंतर्निहित ज्ञान का लाभ उठाते हैं। जबकि एलएम से ज्ञान निकालने पर पिछले काम ने हमारे ज्ञान का सबसे अच्छा जवाब देने के लिए ओपन-डोमेन प्रश्न के उत्तर के कार्य पर ध्यान केंद्रित किया है, यह तथ्य परीक्षकों के रूप में भाषा मॉडल के उपयोग की जांच करने के लिए पहला काम है। एक बंद-पुस्तक सेटिंग में, हम दिखाते हैं कि हमारा शून्य-शॉट एलएम दृष्टिकोण मानक बुखार कार्य पर एक यादृच्छिक आधार रेखा को मात देता है, और यह कि हमारे महीन एलएम मानक बेसलाइन के साथ अनुकूल रूप से तुलना करता है। यद्यपि हम अंततः उन तरीकों से बेहतर प्रदर्शन नहीं करते हैं जो स्पष्ट ज्ञान के आधार का उपयोग करते हैं, हमारा मानना है कि हमारी खोज से पता चलता है कि यह विधि व्यवहार्य है और इसमें अन्वेषण के लिए बहुत जगह है।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nedavno je rad predložio da jezički modeli (LMs) čuvaju zajedničke smisla i činjenične znanje koje su naučene iz podataka prije obuke. U ovom papiru, iskorištavamo to implicitno znanje kako bi stvorili učinkoviti provjeravač činjenica na kraju koristeći samo jezički model, bez bilo kakvih vanjskih znanja ili jasnih komponenata za uzdržavanje. Iako je prethodni rad izvlačenja znanja iz LMs-a usredotočen na zadatak odgovora na pitanje otvorenog domena, na najbolje od našeg znanja, to je prvi rad koji je pregledao korištenje jezičkih modela kao provjeravača činjenica. U sklopu zatvorenih knjiga pokazujemo da naš pristup LM-a od nule pucnjave iznosi nasumičnu početnu liniju na standardnom zadatku FEVER-a, i da naš fin beznačajni LM uspoređuje favoritno sa standardnim osnovnim linijama. Iako na kraju nismo nadmašili metode koje koriste jasne baze znanja, vjerujemo da naša istraživanja pokazuje da je ovaj metod održiv i ima mnogo mjesta za istraživanje.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A közelmúltbeli munkák azt sugallják, hogy a nyelvi modellek mind a józan észt, mind pedig a képzés előtti adatokból származó tényszerű ismereteket tárolják. Ebben a tanulmányban ezt az implicit tudást kihasználjuk egy hatékony end-to-end tény ellenőrző létrehozására, kizárólag egy nyelvi modell használatával, külső ismeretek vagy explicit visszakeresési komponensek nélkül. Míg az LMs-ekből származó tudás kinyerésével kapcsolatos korábbi munka a nyílt domain kérdések megválaszolásának feladatára összpontosított, tudásunk szerint ez az első munka, amely a nyelvi modellek tényellenőrzőként való használatát vizsgálja. Zárt könyvben megmutatjuk, hogy a nulla lövéses LM megközelítésünk felülmúlja a szabványos FEVER feladat véletlenszerű alapját, és hogy a finomhangolt LM kedvezően hasonlít össze a standard alapjaival. Bár végső soron nem teljesítjük túl a kifejezett tudásbázisokat használó módszereket, úgy véljük, hogy feltárásunk azt mutatja, hogy ez a módszer életképes és sok hely van feltárásra.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Վերջին աշխատանքները ցույց են տալիս, որ լեզվի մոդելները պահեն առողջ զգացմունքը և փաստացի գիտելիքները, որոնք սովորել են նախկին ուսումնասիրելու տվյալներից: Այս թղթի մեջ մենք օգտագործում ենք այս ենթարկված գիտելիքը, որպեսզի ստեղծենք արդյունավետ վերջ-վերջ փաստերի ստուգում, օգտագործելով միայն լեզվային մոդել, առանց որևէ արտաքին գիտելիքի կամ բացատրական վերադարձման բաղադրիչների: Մինչդեռ նախորդ աշխատանքները գիտելիքների վերացման վրա կենտրոնացել են բաց բնագավառի հարցերի պատասխանման խնդրի վրա, մեր լավագույն գիտելիքների վրա, սա առաջին աշխատանքն է լեզվի մոդելների օգտագործման որպես փաստերի ստուգում ուսումնասիրելու համար: In a closed-book setting, we show that our zero-shot LM approach outperforms a random baseline on the standard FEVER task, and that our finetuned LM compares favorably with standard baselines. Չնայած մենք վերջ ի վերջո չենք արտադրում մեթոդներ, որոնք օգտագործում են բացահայտ գիտելիքների հիմքերը, մենք հավատում ենք, որ մեր ուսումնասիրությունը ցույց է տալիս, որ այս մեթոդը գոյություն ունի և շատ տեղ ունի ուսումնասիրության համար:</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Pekerjaan baru-baru ini menyarankan bahwa model bahasa (LMs) menyimpan pengetahuan biasa dan faktual yang dipelajari dari data prapelatihan. Dalam kertas ini, kita menggunakan pengetahuan implicit ini untuk menciptakan pemeriksa fakta yang efektif dari akhir ke akhir menggunakan hanya model bahasa, tanpa pengetahuan luar atau komponen penemuan eksplicit. Sementara pekerjaan sebelumnya untuk mengekstraksi pengetahuan dari LMs telah fokus pada tugas menjawab pertanyaan domain terbuka, untuk yang terbaik dari pengetahuan kita, ini adalah pekerjaan pertama untuk memeriksa penggunaan model bahasa sebagai pemeriksa fakta. Dalam pengaturan buku tertutup, kami menunjukkan bahwa pendekatan LM 0-shot kita melebihi dasar acak pada tugas standar FEVER, dan bahwa LM finetuned kita membandingkan dengan baik dengan dasar standar. Meskipun kita tidak akhirnya melebihi metode yang menggunakan dasar pengetahuan eksplicit, kita percaya eksplorasi kita menunjukkan bahwa metode ini bisa hidup dan memiliki banyak ruang untuk eksplorasi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Recenti lavori hanno suggerito che i modelli linguistici (LM) memorizzano sia il buon senso che le conoscenze fattuali apprese dai dati pre-formazione. In questo articolo, sfruttiamo questa conoscenza implicita per creare un efficace controllo dei fatti end-to-end utilizzando un modello esclusivamente linguistico, senza alcuna conoscenza esterna o componenti espliciti di recupero. Mentre i precedenti lavori sull'estrazione della conoscenza da LM si sono concentrati sul compito di rispondere a domande open-domain, per quanto ne sappiamo, questo è il primo lavoro ad esaminare l'uso di modelli linguistici come fact checker. In un'impostazione a libro chiuso, mostriamo che il nostro approccio LM zero-shot supera una linea di base casuale sull'attività FEVER standard e che il nostro LM perfezionato si confronta favorevolmente con le linee di base standard. Anche se alla fine non superiamo i metodi che utilizzano basi di conoscenza esplicite, crediamo che la nostra esplorazione dimostri che questo metodo è praticabile e ha molto spazio per l'esplorazione.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>最近の研究では、言語モデル（ LM ）は、トレーニング前のデータから学んだ常識的知識と事実的知識の両方を保存することが示唆されている。本稿では、この暗黙の知識を活用して、外部知識や明示的な検索コンポーネントなしで、言語モデルのみを使用して効果的なエンドツーエンドのファクトチェッカーを作成する。LMから知識を抽出する以前の作業は、オープンドメインの質問に答える作業に焦点を当てていますが、私たちの知る限りでは、これはファクトチェッカーとしての言語モデルの使用を検討する最初の作業です。クローズドブックの設定では、ゼロショットLMアプローチが標準的な発熱タスクのランダムなベースラインを上回り、微調整されたLMが標準的なベースラインと比較して好ましいことが示されています。明示的な知識ベースを使用する方法を最終的には上回ることはありませんが、私たちの探求は、この方法が実行可能であり、探索の余地が大きいことを示していると信じています。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>text-tool-action Awak dhéwé ngêngé kuwi, ngêngé awak dhéwé nggawe ngerasakno iki banget nggawe barang nggawe ngubah kesempatan kanggo ngubah kesempatan kanggo ngerasakno or a ono ndaftar sêngé awak dhéwé. Nombo kamu arep nggawe kelas bebas nang ngerasahan kelas telu nggawe ing nggawe open-domain question ngomong, kanggo awake sing paling awak dhéwé, iki bukané perusahaan kanggo bisa langkung model kuwi nggawe barang. Nanging kapan-kapan buku, kita ngomong nik sesuk yatak telu-atan LM sing ngendalikne mulai supoyo barang sampek mulalah sing ngendalikne ning daerahé DEBER nggo awak dhéwé, lan saiki ono LM sing paling dhéwé nggawe barang tengahane sampek wae awak dhéwé Genjer-genjer saiki awak dhéwé ora nggawe barang nggawe sistem sing paling awak dhéwé, awak dhéwé ngerasakno kejahatan dhéwé kuwi method sing bisa diagonal iki ngono akeh basa kanggo kejahatan.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ახალი სამუშაო მუშაობა, რომ ენის მოდელები (LMs) სამუშაო სიგრძნე და ფაქტიური ცნობილებები, რომლებიც უნდა იყოს სამუშაო სამუშაო მო ამ დომენტში ჩვენ ამ ინფლიციტური ცნობილების შექმნა ეფექტიურ დასრულებული ფაქტის შემოწმება, რომელიც მხოლოდ ენის მოდელის გამოყენებათ, არსებობით გარეშე ცნობილება ან გარეშე მიღებ თუმცა პირველი სამუშაო მსოფლიოს მოდელეების გამოყენებაზე გახსნა კითხვების დასამართლად, ჩვენი უკეთესი ცნობილებისთვის, ეს არის პირველი სამუშაო, რომელიც ენის მოდელეების გამოყენებას რო ჩვენ დახურებული წიგნის შესაძლებელად ჩვენი ნულ-სურათი LM მიღება სტანდარტული FEVER დავალების გამოსაყენება და ჩვენი წიგნილი LM-ის გამოსაყენება სტანდარტული ფესური ხაზებით. მაგრამ ჩვენ საბოლოოდ არ ვაკეთებთ გავაკეთებული მეტოვები, რომელიც გამოიყენება განსხვავებული ცნობიერების ბაზები, ჩვენ ვფიქრობთ ჩვენი განსხვავება, რომ ეს მეტოვები უფრო ცხ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Жуырдағы жұмыс тіл үлгілері (LMs) алдыңғы оқыту деректерінен үйренген жалпы мәліметтерді және фактикалық мәліметтерді сақтауға мүмкіндік береді. Бұл қағазда біз бұл мәліметті тек тіл үлгісін, сыртқы білім немесе түсінікті алу компоненттері жоқ, ең жақсы аяқтау сәтті тексеру үшін құрамыз. Алдыңғы жұмыс LMs- ден білім тарқату үшін ашық доменге сұрақ жауап беру тапсырмасына, біздің біліміміздің ең жақсы мәліметіне, бұл тіл үлгілерін факты тексеру үшін тексеру үшін бірінші Жабылған кітаптар параметрінде, LM жағдайымыз стандартты FEVER тапсырмасындағы кездейсоқ негізгі жолды жұмыс істейді, және біздің кездейсоқ LM жағдайымыз стандартты негізгі жолдарымен салыстырылады. Біз ең соңында білім мәліметтерді қолданған әдістерді таңдамаймыз, біз зерттеулеріміздің бұл әдісті жақсы болып, зерттеулердің көп жері бар деп ойлаймыз.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>최근 연구에 따르면 언어모델(LMs)에는 훈련 전 데이터에서 배운 상식과 사실 지식이 저장돼 있다.본고에서 우리는 이러한 스텔스 지식을 이용하여 효과적인 끝에서 끝까지의 사실 검사기를 만들고 하나의 언어 모델만 사용하며 외부 지식이나 현식 검색 구성 요소가 필요하지 않다.그동안 LMs에서 지식을 추출하는 작업은 주로 개방 분야 질문에 대한 답변 임무에 집중됐지만, 언어 모델을 팩트 체크 도구로 연구하는 첫 작업으로 알려졌다.폐쇄된 책 환경에서 우리는 우리의 0박자 LM 방법이 표준 발열 임무에서 무작위 기선보다 우수하고 우리의 마이크로스피커 LM이 표준 기선에 비해 더욱 우세하다는 것을 보여 주었다.비록 우리가 최종적으로 현식 지식 라이브러리를 사용하는 방법을 초월하지는 않았지만, 우리는 우리의 탐색이 이러한 방법이 실행 가능하고 매우 큰 탐색 공간이 있음을 나타낸다고 믿는다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Neseniai atliktas darbas parodė, kad kalbų modeliai saugo tiek sveikos proto, tiek faktines žinias, įgytas iš ikimokymo duomenų. Šiame dokumente mes panaudojame šias netiesiogines žinias, kad sukurtume veiksmingą faktų tikrintoją, naudojančią tik kalbos model į, be jokių išorinių žinių ar aiškių surinkimo komponentų. Nors ankstesnis darbas, skirtas žinių gavimui iš LM, buvo sutelktas į užduotį atsakyti į atviros srities klausimus, kiek žinome, tai pirmasis darbas, skirtas kalbų modelių naudojimui kaip faktų tikrintojams išnagrinėti. Uždarytoje knygoje mes parodome, kad mūsų nulinis LM metodas viršija atsitiktinę bazę standartinėje FEVER užduotyje, ir kad mūsų patobulintas LM palyginamas palankiai su standartinėmis bazėmis. Nors galiausiai neatliekame metodų, kurie naudoja aiškias žinių bazes, manome, kad mūsų tyrimas rodo, kad šis metodas yra gyvybingas ir turi daug erdvės tyrimui.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Неодамнешната работа покажа дека јазичките модели (ЛМ) чуваат здраво-смислено и фактично знаење научено од податоците од предобуката. Во овој весник, го искористуваме ова имплицитно знаење за да создадеме ефикасен проверувач на факти од крај до крај, користејќи само јазички модел, без никакво надворешно знаење или експлицитни компоненти за преземање. И покрај тоа што претходната работа за извлекување на знаење од ЛМ се фокусираше на задачата на отворено одговорување на прашања на домен, за најдобро од нашето знаење, ова е првата работа за испитување на употребата на јазичките модели како проверка на факти. Во затворена книга покажуваме дека нашиот пристап со нула снимка на ЛМ го надминува случајниот основен резултат на стандардната ФЕВЕР задача, и дека нашиот финетизиран ЛМ се споредува со стандардните основни резултати. Иако на крајот не ги надминуваме методите кои користат експлицитни бази на знаење, веруваме дека нашето истражување покажува дека овој метод е жив и има многу простор за истражување.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>അടുത്തുതന്നെ ജോലി പരിശീലനത്തിനുമുമ്പ് പഠിച്ച വിവരങ്ങളില്‍ നിന്നും ഭാഷ മോഡലുകള്‍ സൂക്ഷിക്കുന്നതിനായി പരിശോ In this paper, we leverage this implicit knowledge to create an effective end-to-end fact checker using a solely a language model, without any external knowledge or explicit retrieval components. LMs-ല്‍ നിന്നും അറിവ് പുറത്തെടുക്കുന്നതിന്‍റെ മുമ്പുള്ള ജോലി നമ്മുടെ അറിവിന്‍റെ ഉത്തരം തുറന്ന ഡൊമെയിന്‍ ചോദ്യം ഉത്തരം ചെയ്യുന്നതിന്‍റ ഒരു മൂടിയ പുസ്തകത്തിന്റെ സജ്ജീകരണത്തില്‍ ഞങ്ങള്‍ കാണിച്ചുകൊടുക്കുന്നു, നമ്മുടെ പൂജ്യ-ഷോട്ട് എംഎം അടിസ്ഥാനത്തിന്റെ അടിസ്ഥാനത്തില്‍ ഒര പ്രത്യക്ഷമായ അറിവുകളുടെ അടിസ്ഥാനങ്ങള്‍ ഉപയോഗിക്കുന്ന രീതികളില്‍ നമ്മള്‍ ഒടുവില്‍ പ്രവര്‍ത്തിക്കുന്നില്ലെങ്കിലും നമ്മുടെ പരിശോ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Саяхан ажил нь хэл загварууд (LMs) нь аль хэдийн мэдлэг болон үнэндээ мэдлэг аль хэдийн сургалтын мэдээллээс сурсан гэдгийг санал болгож байна. Энэ цаасан дээр бид эдгээр мэдлэгийг эцсийн төгсгөлд нь хэл загварыг ашиглаж, гадаад мэдлэг эсвэл тодорхой алдагдах хэсэгтэй бүтээмж бий болгохын тулд ашигладаг. Хэдийгээр өмнө ажлын ажил ЛХ-ээс мэдлэг гаргах талаар нээлттэй асуулт асуултын хариултыг бидний хамгийн сайн мэдлэгтэй хүмүүст анхны ажил нь хэл загварын хэрэглээ үнэндээ шийдвэрлэгчүүдийг шийдэх анхны ажил юм. Нууцсан номын хэмжээнд бид Нэг шалтгаан LM арга нь стандарт FEVER ажил дээр санамсаргүй үндсэн шугам гаргадаг гэдгийг харуулж байна. Эцэст нь бид тодорхой мэдлэгтэй суурь ашиглаж байгаа арга хэрэглэдэггүй ч, бидний судалгаанд энэ арга нь амьдрах болон судалгаанд маш олон орон байдаг гэдэгт итгэдэг.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kerja baru-baru ini menyarankan bahawa model bahasa (LMs) menyimpan pengetahuan biasa dan fakta yang dipelajari dari data praselatihan. In this paper, we leverage this implicit knowledge to create an effective end-to-end fact checker using a solely a language model, without any external knowledge or explicit retrieval components. Sementara kerja sebelumnya untuk mengekstrak pengetahuan dari LMs telah fokus pada tugas menjawab soalan domain terbuka, untuk yang terbaik dari pengetahuan kita, ini adalah kerja pertama untuk memeriksa penggunaan model bahasa sebagai pemeriksa fakta. Dalam tetapan buku tertutup, kita menunjukkan bahawa pendekatan LM 0-shot kita melampaui dasar rawak pada tugas FEVER piawai, dan bahawa LM yang ditetapkan kita dibandingkan dengan baik dengan garis dasar piawai. Walaupun kita tidak akhirnya melebihi kaedah yang menggunakan dasar pengetahuan secara eksplicit, kita percaya eksplorasi kita menunjukkan bahawa kaedah ini boleh hidup dan mempunyai banyak ruang untuk eksplorasi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Xogħol reċenti ssuġġerixxa li l-mudelli lingwistiċi (LMs) jaħżnu kemm għarfien ta’ sens komuni kif ukoll għarfien fattwali miksub mid-dejta ta’ qabel it-taħriġ. F’dan id-dokument, nagħmlu użu minn dan l-għarfien impliċitu biex noħolqu verifikatur effettiv tal-fatti minn tarf sa tarf bl-użu ta’ mudell lingwistiku biss, mingħajr l-ebda għarfien estern jew komponenti ta’ rkupru espliċitu. Filwaqt li l-ħidma preċedenti dwar l-estrazzjoni tal-għarfien mill-LMs iffukat fuq il-kompitu tat-tweġiba għall-mistoqsijiet b’dominju miftuħ, għall-aħjar għarfien tagħna, din hija l-ewwel ħidma biex jiġi eżaminat l-użu tal-mudelli lingwistiċi bħala verifikanti tal-fatti. F’ambjent ta’ kotba magħluqa, a ħna nuru li l-approċċ tagħna ta’ LM b’ritratt żero jaqbeż linja bażi każwali fuq il-kompitu standard FEVER, u li l-LM irfinat tagħna tqabbel b’mod favorevoli mal-linji bażi standard. Għalkemm fl-aħħar mill-aħħar ma nużawx metodi li jużaw bażijiet ta’ għarfien espliċiti, aħna nemmnu li l-esplorazzjoni tagħna turi li dan il-metodu huwa vijabbli u għandu ħafna spazju għall-esplorazzjoni.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Recent onderzoek heeft gesuggereerd dat taalmodellen (LMs) zowel gezond verstand als feitelijke kennis opslaan die is geleerd uit pre-training data. In dit artikel maken we gebruik van deze impliciete kennis om een effectieve end-to-end fact checker te creëren met een louter taalmodel, zonder enige externe kennis of expliciete retrieval componenten. Terwijl eerdere werkzaamheden over het extraheren van kennis uit LMs zich hebben gericht op de taak van open-domein vragen beantwoorden, is dit voor ons het eerste werk dat het gebruik van taalmodellen als fact checkers onderzoekt. In een gesloten boekinstelling laten we zien dat onze zero-shot LM-benadering beter presteert dan een willekeurige baseline op de standaard FEVER taak, en dat onze verfijnde LM zich gunstig vergelijkt met standaard baselines. Hoewel we uiteindelijk niet beter presteren dan methoden die gebruik maken van expliciete kennisbases, geloven we dat onze exploratie aantoont dat deze methode levensvatbaar is en veel ruimte heeft voor exploratie.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nyleg har arbeidet foreslått at språksmodeller (LMs) lagrar både vanleg og faktisk kunnskap lærte frå føreøvingsdata. I denne papiret leverer vi denne implisitte kunnskapen for å laga ein effektiv ende-til-slutt-faktisk sjekkar med ein berre språk-modell utan nokon eksterne kunnskap eller eksplisitt henting av komponentar. Mens det førre arbeidet på å ekstrahera kunnskap frå LMs har fokusert på oppgåva av oppgåva for å svara på oppgåva av open-domain spørsmål, til det beste av vårt kunnskap, er dette den første arbeidet å undersøke bruken av språk-modeller som faktisk kontrollere. I eit lukka bokinnstilling viser vi at LM-tilnærminga vår null-shot utfører ein tilfeldig grunnlinje på standard FEVER-oppgåva, og at vårt fine LM sammenlignar favoritt med standardsbaselinjer. Selv om vi ikkje finst utfører metodar som bruker eksplisitt kunnskapsbaser, tror vi at utforskinga vår viser at denne metoden er viktig og har mye plass for utforsking.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ostatnie prace sugerują, że modele językowe (LM) przechowują zarówno zdrowy rozsądek, jak i wiedzę faktyczną zdobytą na podstawie danych przedszkoleniowych. W niniejszym artykule wykorzystujemy tę domniemaną wiedzę do stworzenia skutecznego kompleksowego sprawdzania faktów przy użyciu wyłącznie modelu językowego, bez żadnej zewnętrznej wiedzy lub wyraźnych komponentów pobierania. Podczas gdy poprzednie prace nad ekstrakcją wiedzy z LMs koncentrowały się na zadaniu odpowiedzi na pytania otwarte w domenie, według naszej najlepszej wiedzy, jest to pierwsza praca, która zbadała wykorzystanie modeli językowych jako sprawdzaczy faktów. W ustawieniu zamkniętej książki pokazujemy, że nasze podejście zero-shot LM przewyższa losową bazę bazową standardowego zadania FEVER, a nasze precyzyjnie dostrojone LM porównuje się korzystnie ze standardowymi liniami bazowymi. Chociaż ostatecznie nie przewyższamy metod, które wykorzystują wyraźne bazy wiedzy, wierzymy, że nasze badania pokazują, że ta metoda jest opłacalna i ma dużo miejsca do eksploracji.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Trabalhos recentes sugeriram que os modelos de linguagem (LMs) armazenam tanto o senso comum quanto o conhecimento factual aprendido a partir de dados pré-treinamento. Neste artigo, aproveitamos esse conhecimento implícito para criar um verificador de fatos eficaz de ponta a ponta usando apenas um modelo de linguagem, sem nenhum conhecimento externo ou componentes de recuperação explícitos. Embora trabalhos anteriores sobre extração de conhecimento de LMs tenham se concentrado na tarefa de responder a perguntas de domínio aberto, até onde sabemos, este é o primeiro trabalho a examinar o uso de modelos de linguagem como verificadores de fatos. Em um ambiente fechado, mostramos que nossa abordagem LM de tiro zero supera uma linha de base aleatória na tarefa FEVER padrão e que nosso LM ajustado se compara favoravelmente com as linhas de base padrão. Embora, em última análise, não superemos os métodos que usam bases de conhecimento explícitas, acreditamos que nossa exploração mostra que esse método é viável e tem muito espaço para exploração.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Lucrările recente au sugerat că modelele lingvistice (LM) stochează atât cunoștințele de bun simț, cât și cele de fapt învățate din datele pre-formare. În această lucrare, valorificăm aceste cunoștințe implicite pentru a crea un verificator eficient de fapt end-to-end folosind doar un model lingvistic, fără cunoștințe externe sau componente explicite de recuperare. În timp ce lucrările anterioare privind extragerea cunoștințelor din LM s-au concentrat pe sarcina de a răspunde la întrebări pe domeniu deschis, din câte știm, aceasta este prima lucrare care examinează utilizarea modelelor lingvistice ca verificatori de fapt. Într-un cadru de carte închisă, arătăm că abordarea noastră LM zero-shot depășește o linie de referință aleatorie în sarcina standard FEVER și că LM noastră finuțit se compară favorabil cu liniile de referință standard. Deși în cele din urmă nu depășim metodele care utilizează baze de cunoștințe explicite, credem că explorarea noastră arată că această metodă este viabilă și are mult spațiu pentru explorare.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Недавние исследования показали, что в языковых моделях (ЛМ) хранятся как общепринятые, так и фактические знания, полученные на основе данных, полученных до обучения. В этой статье мы используем эти неявные знания для создания эффективной сквозной проверки фактов с использованием исключительно языковой модели без каких-либо внешних знаний или явных компонентов извлечения. В то время как предыдущая работа по извлечению знаний из ЖМ была сосредоточена на задаче ответов на вопросы открытого домена, насколько нам известно, это первая работа по изучению использования языковых моделей для проверки фактов. В закрытой книге мы показываем, что наш подход с нулевым выстрелом LM превосходит случайную базовую линию в стандартной задаче ЛИХОРАДКИ, и что наш тонко настроенный LM выгодно сравнивается со стандартными базовыми линиями. Хотя в конечном счете мы не превосходим методы, которые используют явные базы знаний, мы считаем, что наша разведка показывает, что этот метод является жизнеспособным и имеет много возможностей для разведки.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>අලුත් වැඩේ ප්‍රශ්නය කරලා තියෙන්නේ භාෂාව මොඩේල්ස් (LMs) සාමාන්‍ය අදහස් සහ ඇත්ත දැනගන්න පුළුවන් ප මේ පැත්තේ, අපි මේ අවශ්‍ය දැනගන්න ප්‍රශ්නයක් අවසානයෙන් අවසානයෙන් පරීක්ෂකයක් නිර්මාණය කරන්න භාෂාවක් මොඩේලයක් ප්‍රයෝජන LMs වලින් දැනගන්න ප්‍රශ්න ප්‍රශ්න ප්‍රශ්නයක් ප්‍රතික්‍රියාවට පිළිබඳ වැඩ කරන්න, අපේ දැනගන්න හොඳම වැඩට, මේක තමයි භාෂා මොඩේල්ස වහලා පොත සැකසුම් වලින්, අපි පෙන්වන්නේ අපේ ශූන්ය වෙඩි LM විදියට ප්‍රමාණය FEVER වැඩේ සාමාන්‍ය ප්‍රමාණයක් වලින් විදියට අවසාන ප්‍රමාණය අපි අන්තිම විදියට විශ්වාස කරන විදියට වැඩ කරන්නේ නැහැ නමුත් අපි විශ්වාස කරනවා අපේ පරීක්ෂණය පෙන්වනවා මේ විදියට ප්‍රතික්‍ර</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nedavna dela kažejo, da jezikovni modeli shranjujejo zdravo pamet in dejansko znanje, pridobljeno iz podatkov pred usposabljanjem. V tem prispevku uporabljamo to implicitno znanje za ustvarjanje učinkovitega preverjanja dejstev od konca do konca z uporabo izključno jezikovnega modela, brez zunanjega znanja ali eksplicitnih komponent pridobivanja. Medtem ko je bilo predhodno delo pridobivanja znanja iz LM osredotočeno na nalogo odgovarjanja na vprašanja na odprto domeno, je to po našem najboljšem znanju prvo delo, ki proučuje uporabo jezikovnih modelov kot preverjalcev dejstev. V nastavitvi zaprtih knjig pokažemo, da naš pristop LM brez strela presega naključno osnovo pri standardnem opravilu FEVER in da se naš natančno nastavljen LM primerja s standardnimi osnovnimi črtami. Čeprav na koncu ne presegamo metod, ki uporabljajo eksplicitne baze znanja, verjamemo, da naše raziskovanje kaže, da je ta metoda izvedljiva in ima veliko prostora za raziskovanje.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Shaqoda la soo dhowaaday waxay soo jeedisay in tusaale ahaan luuqada (LMs) lagaga dhigo aqoonta caadiga ah iyo aqoonta runta ah oo laga baray macluumaadka waxbarashada ka horraysa. Warqadan waxaynu ku qornaa aqoontan saamayn ah si a an u sameyno koontarool faa’iido ah ugu dhammaadka ugu dambaysta, si aan u isticmaalno tusaale luuqad oo kaliya, cilmi dibadda ah ama qeybo qaali ah. Intii shaqadii hore oo ku saabsan soo saaridda aqoonta ee LMs waxay focus ugu yeesheen shaqada su'aalaha furan, tan ugu wanaagsan ee aqoonteenna, taasi waa shaqada ugu horeysa si aad u baaritaan isticmaalka modelalka luuqada sida hubsada xaqiiqada ah. Qoraalka qoran oo xidhan, waxaynu tusnaynaa in dhaqdhaqaalahayaga aan nuurka looga dhuftay LM uu ka muujiyo qoraal hoos ah oo ku qoran shaqada caadiga ah ee FEVER, iyo in LM-kaalmeynayo uu si fiican ugu dhigo heerarka caadiga ah. In kastoo aanan ugu dambaysta samayn hababka la soo saaray oo isticmaalaya aasaaska aqoonta cad, waxaynu aaminsanahay baaritaankeenu waxay muuqan tahay in qaabkaasu suurtagal yahay, wuxuuna leeyahay meel aad u baahan karto.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Puna e fundit ka sugjeruar se modelet gjuhësore (LMs) ruajnë njohuri të zakonshme dhe faktike të mësuara nga të dhënat e paratrajnimit. Në këtë letër, ne përdorim këtë njohuri implicit për të krijuar një kontrollues efektiv të fakteve nga fundi në fund duke përdorur vetëm një model gjuhësh, pa ndonjë njohuri të jashtme apo komponente të shprehura. Ndërsa punët e mëparshme mbi nxjerrjen e njohurive nga LMs janë përqëndruar në detyrën e përgjigjes së pyetjeve në domeni të hapur, për më të mirën e njohurive tona, kjo është puna e parë për të shqyrtuar përdorimin e modeleve gjuhësore si kontrollues të fakteve. Në një përcaktim të librit të mbyllur, ne tregojmë se metoda jonë zero-shot LM kryen një bazë të rastësishme në detyrën standard FEVER, dhe se LM jonë të përshtatur krahasohet favorisht me linjat standard bazë. Megjithëse ne nuk bëjmë më së fundi metoda që përdorin baza të njohurive të qarta, ne besojmë se eksplorimi ynë tregon se ky metodë është i jetueshëm dhe ka shumë vend për eksplorim.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Poslednji rad je predložio da jezički modeli (LMs) čuvaju zajedničke smisla i činjenične znanje koje su naučili od podataka pre obuke. U ovom papiru, iskorištavamo to implicitno znanje da bi stvorili efikasni provjernik činjenica na kraju koristeći samo jezički model, bez bilo kakvih spoljnih znanja ili eksplicitnih komponenta za uzdržavanje. Dok je prethodni posao o izvlačenju znanja od LMs fokusiran na zadatak odgovora na pitanje otvorenog domena, na najbolje od našeg znanja, ovo je prvi posao koji je pregledao korištenje jezičkih modela kao provjeravača činjenica. U sklopu zatvorenih knjiga pokazujemo da naš pristup LM-a od nule pucnjave iznosi nasumičnu početnu liniju na standardnom zadatku FEVER-a, i da se naš fin LM uspoređuje favoritno sa standardnim osnovnim linijama. Iako na kraju ne izvršavamo metode koje koriste jasne baze znanja, verujemo da naša istraživanja pokazuje da je ovaj metod održiv i ima mnogo mesta za istraživanje.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nyligen genomförda arbeten har antytt att språkmodeller lagrar både sunt förnuft och sakkunskap som erhållits från data före utbildningen. I denna uppsats utnyttjar vi denna underförstådda kunskap för att skapa en effektiv end-to-end faktakontroll med hjälp av en enbart språkmodell, utan någon extern kunskap eller explicita hämtningskomponenter. Medan tidigare arbete med att utvinna kunskap från LM har fokuserat på uppgiften att besvara frågor med öppen domän, så vitt vi vet, är detta det första arbetet att undersöka användningen av språkmodeller som faktakontroller. I en sluten bokinställning visar vi att vår noll-shot LM-metod överträffar en slumpmässig baslinje på standard FEVER-uppgiften, och att vår finjusterade LM jämför positivt med standard baslinjer. Även om vi i slutändan inte överträffar metoder som använder explicita kunskapsbaser, tror vi att vår utforskning visar att denna metod är livskraftig och har mycket utrymme för utforskning.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kazi ya hivi karibuni imependekeza kuwa mifano ya lugha (LMs) hubeba maarifa ya kawaida na maarifa ya ukweli yaliyojifunza kutoka kwa takwimu za mafunzo ya awali. Katika karatasi hii, tunatumia maarifa haya yenye ufahamu wa kutengeneza utafiti wenye ufanisi wa mwisho wa ukweli wa mwisho kwa kutumia mifano pekee ya lugha, bila ufahamu wa nje au vifaa vya wazi vya kupatikana. Wakati kazi iliyopita kuhusu kuondoa maarifa kutoka kwa LMs wamejikita kwenye kazi ya maswali ya wazi ya ndani ya kujibu, kwa ufahamu wetu bora, hii ni kazi ya kwanza ya kuchunguza matumizi ya mifano ya lugha kama utafiti wa ukweli. In a closed-book setting, we show that our zero-shot LM approach outperforms a random baseline on the standard FEVER task, and that our finetuned LM compares favorably with standard baselines. Ingawa hatufanyi hatua za mwisho zinazotumia misingi ya maarifa ya wazi, tunaamini utafiti wetu unaonyesha kuwa mbinu hii inafaa na ina nafasi nyingi kwa ajili ya uchunguzi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>சமீபத்தில் வேலை மொழி மாதிரிகள் (LMs) பொதுவான உணர்வு மற்றும் உண்மையான அறிவை முன் பயிற்சி தரவிலிருந்து கற்று இந்த காகிதத்தில், வெளிப்புற அறிவு அல்லது வெளிப்படையான பொருள் இல்லாமல் ஒரு மொழி மாதிரி மாதிரியை உருவாக்குவதற்கு ஒரு விருப்பமான முடிவு முட LMs இலிருந்து அறிவை வெளியேற்றும் முந்தைய வேலையில், திறந்த டொமைன் கேள்விக்கு பதில் கவனம் செலுத்தப்பட்டுள்ளது, எங்கள் அறிவின் சிறந்தத்திற் ஒரு மூடிய புத்தகத்தின் அமைப்பில், எங்கள் பூஜ்ஜியமான LM முறைமையை நாம் காண்பிக்கிறோம் என்பது நிலையான FEVER பணியில் ஒரு குறிப்பிட்ட அடிப்படைய Though we do not ultimately outperform methods which use explicit knowledge bases, we believe our exploration shows that this method is viable and has much room for exploration.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ýakynda işleýän zatlar dil nusgalarynyň hem umut duýgulary hem hakyky bilgi hem öňünden öwrenip bilýän bilimleri almagyny maslahat berdi. Bu kagyzda çykyş bilen ýöne bir dil nusgasyny ýöne, ýöne daşarydaky bilim ýöne a çyk komponentleri ýöne täsirli bir netijesi barlamak üçin bu sylagy çykarýarys. LMsden bilim tapmakda öňki işiň açylyk soraglaryň jogabyny açmak üçin üns berilýär. Bilişimiziň iň gowy görä bu dil nusgalarynyň ullanyşyny barlamak üçin ilkinji işidir. Baglanmış kitap düzeninde, biziň nul-atly LM ýazşymyzyň standart FEVER işinde tesadüf üýtgeýän çyzgylygyny görkezýäris we biziň iň kiçiräk LM standart üýtgeýän çyzgymlar bilen gowy görkezýäris. Iň soňunda biz bilim baselerini ulanan yönlerden çykarmaýarys diýip pikir edýäris. Araştyrymyzyň bu yöniň ýagdaýdyr we keşif etmek üçin köp ýer bardyr diýip pikir edýäris.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>اگلے کام نے سفارش کی ہے کہ زبان مدل (LMs) دونوں عام سمجھ اور حقیقی علم کو پہلے آموزش دادہ سے سکھایا گیا ہے. اس کاغذ میں، ہم اس غیر علم کے بغیر کسی خارجی علم یا صاف صاف اٹھانے کے مطابق ایک موجود چکر بنانے کے لئے استعمال کرتے ہیں. حالانکہ پہلے کام لMs سے علم اٹھانے کے لئے کھول دینے والی سوال کے جواب کے کام پر تمرکز کیا گیا ہے، ہمارے علم سے بہترین، یہ سب سے پہلے کام ہے جو زبان مدل کے استعمال کو حقیقت چکروں کے طور پر تحقیق کرنے کے لئے ہے. ہم نے ایک بند کتاب مقرر میں دکھایا کہ ہمارا صفر-شٹ LM تقریبا استاندارد FEVER کے کام پر ناقص بنسبیلئن سے کام لیتا ہے اور ہمارے بہترین LM نے استاندارد بنسبیلئین کے ساتھ مطابق مطابق مقرر کیا ہے. اگرچہ ہم بالاخره طریقے سے کام نہیں لیتے جو صریح علم کی بنیاد استعمال کرتے ہیں، ہم یقین رکھتے ہیں کہ ہماری تحقیق دکھاتا ہے کہ یہ طریقہ قابل ہے اور تحقیق کے لئے بہت سی جگہ ہے.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Recent work has suggested that language models (LMs) store both common-sense and factual knowledge learned from pre-training data. Bu qogʻozda biz faqat tilning modeli yordamida, tashqi bilmagan yoki aniqlash komponentini yordamida qo'llanmiz. LMs'dan olish uchun oldingi ishni o'rganish uchun ochiq domen savol javobga qaramadi, bizning eng yaxshi taʼlumot uchun, bu tilning foydalanishini haqiqiqiy tekshirish uchun birinchi ish. Yopilgan kitob moslamada biz hech narsa yozilgan LM tilimizni andoza FEVER vazifasidagi oddiy asosiy bazasini bajarayotganimizni ko'rsatamiz va bizning yuqori LM andoza asosiy sonlari bilan yaxshi ko'rinadi. Agar biz oxirgi ta'rif asosida foydalanuvchi usullar emas, biz ishlayapmiz, bu usulni ishlab chiqarishimiz mumkin va qidirish uchun juda ko'p joyi bor.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Những nghiên cứu gần đây cho thấy các mô hình ngôn ngữ (LM) lưu trữ cả sự tỉnh táo và sự thật được học từ dữ liệu trước khi đào tạo. Trong tờ giấy này, chúng ta dùng kiến thức ngầm này để tạo ra một hệ thống kiểm tra thực tế hiệu quả dùng một mô hình ngôn ngữ, mà không có kiến thức bên ngoài hay các thành phần trích dẫn rõ ràng. Trong khi những nghiên cứu trước về khai thác kiến thức từ LMs đã tập trung vào nhiệm vụ trả lời câu hỏi mở miền, theo những gì chúng ta biết, đây là công việc đầu tiên để kiểm tra việc dùng các mô hình ngôn ngữ làm người kiểm tra thực tế. Trong một thiết lập kín, chúng tôi cho thấy phương pháp LM "bắn không" của chúng ta thực hiện một đường cơ sở hoàn chỉnh ngẫu nhiên trên nhiệm vụ kiểu FEL chuẩn, và LM tinh chỉnh của chúng ta được so sánh được với những đường hầm chuẩn. Mặc dù chúng ta không hoàn thành các phương pháp sử dụng những căn cứ nhận thức rõ ràng, nhưng chúng ta tin rằng cuộc thám hiểm của chúng ta cho thấy rằng phương pháp này khả thi và có nhiều phòng để thám hiểm.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>近者研明,语言模样(LM)存储从训练前数中学到常识事实。 于本文之中,因隐式以创一效之端,检查器言语模样,而无外显式检组件。 虽前LM取知,皆集开放域问答之务,但据吾所知,此第一项治言语模形以为实核查器也。 夫封闭之书,明吾零次 LM 之法 FEVER 优于随机之基线,而吾之微调 LM 比基线更胜一筹。 虽终无越用显式知识库之术,然吾信吾探索之可也,且有大探索空间。</span></div></div><dl><dt>Anthology ID:</dt><dd>2020.fever-1.5</dd><dt>Volume:</dt><dd><a href=/volumes/2020.fever-1/>Proceedings of the Third Workshop on Fact Extraction and VERification (FEVER)</a></dd><dt>Month:</dt><dd>July</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Online</dd><dt>Venues:</dt><dd><a href=/venues/acl/>ACL</a>
| <a href=/venues/fever/>FEVER</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>36–41</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.fever-1.5>https://aclanthology.org/2020.fever-1.5</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/2020.fever-1.5 title="To the current version of the paper by DOI">10.18653/v1/2020.fever-1.5</a></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">lee-etal-2020-language</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Nayeon Lee, Belinda Z. Li, Sinong Wang, Wen-tau Yih, Hao Ma, and Madian Khabsa. 2020. <a href=https://aclanthology.org/2020.fever-1.5>Language Models as Fact Checkers?</a>. In <i>Proceedings of the Third Workshop on Fact Extraction and VERification (FEVER)</i>, pages 36–41, Online. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2020.fever-1.5>Language Models as Fact Checkers?</a> (Lee et al., FEVER 2020)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2020.fever-1.5.pdf>https://aclanthology.org/2020.fever-1.5.pdf</a></dd><dt class=acl-button-row>Video:</dt><dd class=acl-button-row><a href=http://slideslive.com/38929662 class="btn btn-attachment btn-sm"><i class="fas fa-video"></i>&nbsp;http://slideslive.com/38929662</a></dd><dt>Data</dt><dd><a href=https://paperswithcode.com/dataset/fever>FEVER</a>,&nbsp;<a href=https://paperswithcode.com/dataset/lama>LAMA</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2020.fever-1.5.pdf title="Open PDF of 'Language Models as Fact Checkers?'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Language+Models+as+Fact+Checkers%3F" title="Search for 'Language Models as Fact Checkers?' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'Language Models as Fact Checkers?'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a>
<a class="btn btn-attachment d-flex flex-wrap justify-content-center" href=http://slideslive.com/38929662 title="Open video for 'Language Models as Fact Checkers?'"><span class="align-self-center px-1"><i class="fas fa-video"></i></span>
<span class=px-1>Video</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[Language Models as Fact Checkers?](https://aclanthology.org/2020.fever-1.5) (Lee et al., FEVER 2020)</p><ul class=mt-2><li><a href=https://aclanthology.org/2020.fever-1.5>Language Models as Fact Checkers?</a> (Lee et al., FEVER 2020)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Nayeon Lee, Belinda Z. Li, Sinong Wang, Wen-tau Yih, Hao Ma, and Madian Khabsa. 2020. <a href=https://aclanthology.org/2020.fever-1.5>Language Models as Fact Checkers?</a>. In <i>Proceedings of the Third Workshop on Fact Extraction and VERification (FEVER)</i>, pages 36–41, Online. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>