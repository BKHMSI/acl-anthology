<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Document Level Hierarchical Transformer - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="Document Level Hierarchical Transformer" name=citation_title><meta content="Najam Zaidi" name=citation_author><meta content="Trevor Cohn" name=citation_author><meta content="Gholamreza Haffari" name=citation_author><meta content="Proceedings of the The 19th Annual Workshop of the Australasian Language Technology Association" name=citation_conference_title><meta content="2021/12" name=citation_publication_date><meta content="https://aclanthology.org/2021.alta-1.13.pdf" name=citation_pdf_url><meta content="128" name=citation_firstpage><meta content="137" name=citation_lastpage><meta property="og:title" content="Document Level Hierarchical Transformer"><meta property="og:image" content="https://aclanthology.org/thumb/2021.alta-1.13.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2021.alta-1.13"><meta property="og:description" content="Najam Zaidi, Trevor Cohn, Gholamreza Haffari. Proceedings of the The 19th Annual Workshop of the Australasian Language Technology Association. 2021."><link rel=canonical href=https://aclanthology.org/2021.alta-1.13></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2021.alta-1.13.pdf>Document Level Hierarchical Transformer</a>
<a id=af_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Dokumentvlak Hierariese Transformeerder</a>
<a id=am_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>ሰነድ ደረጃዎች</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>المحولات الهرمية على مستوى الوثيقة</a>
<a id=az_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>D칬k칲m톛t s톛viyy톛si Hierarhikal Transformat칬r칲</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Йерархичен трансформатор на ниво документ</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>ডকুমেন্টের স্তর অতিরিক্ত অনুবাদক</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>ཡིག་གེའི་སྒྲིག་ཡིག་གི་དཔེ་དབྱིབས་སྒྱུར་བ</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Hierarični transformator nivoa dokumenta</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Transformador Hierarquic del Nivel del Document</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Hierarchický transformátor úrovně dokumentu</a>
<a id=da_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Hierarkisk transformator på dokumentniveau</a>
<a id=de_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Hierarchischer Transformator auf Dokumentebene</a>
<a id=el_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Ιεραρχικός μετασχηματιστής επιπέδου εγγράφου</a>
<a id=es_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Transformador jerárquico de documentos</a>
<a id=et_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Dokumenditaseme hierarhiline muundur</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>تغییر سطح سطح سند</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Asiakirjatason hierarkinen muuntaja</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Transformateur hiérarchique au niveau du document</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Trasfhoirmeoir Ordlathach Leibhéal an Doiciméid</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Document Level Hierarchical Transformer</a>
<a id=he_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>מעברת רמת המסמך הייררכית</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>दस्तावेज़ स्तर पदानुक्रमित ट्रांसफॉर्मर</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Hierarični transformator razine dokumenta</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Dokumentumszint hierarchikus transzformátor</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Comment</a>
<a id=id_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Transformer Hierarkis Tingkat Dokumen</a>
<a id=is_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Trasformatore gerarchico a livello di documento</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>ドキュメントレベルの階層トランスフォーマー</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>undo-type</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Comment</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Құжат деңгейі гиерархикалық түрлендіргіші</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>문서 수준 계층 변환기</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Dokumento lygis Hierarchinis transformatorius</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Херархиски трансформирач на ниво на документ</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>രേഖയുടെ നില ഉയര്‍ച്ചയുള്ള വിവരങ്ങള്‍</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Документын түвшин гиерархик шилжүүлэгч</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Penukar Hierarkikal Aras Dokumen</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Trasformatur Ġerarkiku tal-Livell tad-Dokument</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Hierarchische transformatie op documentniveau</a>
<a id=no_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Hierarisk transformering for dokumentnivå</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Transformator hierarchiczny na poziomie dokumentu</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Transformador Hierárquico de Nível de Documento</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Transformator ierarhic la nivel de document</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Иерархический трансформатор уровня документа</a>
<a id=si_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>විස්තාරය ස්තූතිය හියාර්චිකාල ප්‍රවර්තකය</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Hierarhični pretvornik na ravni dokumenta</a>
<a id=so_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Tilmaamaha dukumentiga heerka sare</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Transformues Hierarkik i Nivelit të Dokumentit</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Hierarhički transformator nivoa dokumenta</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Hierarkisk transformator på dokumentnivå</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Transfers</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>ஆவண நிலை உயர்நிலை மாற்றுதல்</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>_Senedler</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Document Level Hierarchical Transformer</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Hujjatning darajasi</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>Dịch biến hình cấp ảnhName</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2021.alta-1.13.pdf>文档级分转换器</a></h2><p class=lead><a href=/people/n/najam-zaidi/>Najam Zaidi</a>,
<a href=/people/t/trevor-cohn/>Trevor Cohn</a>,
<a href=/people/g/gholamreza-haffari/>Gholamreza Haffari</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Generating long and coherent text is an important and challenging task encompassing many application areas such as <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a>, document level machine translation and <a href=https://en.wikipedia.org/wiki/Storytelling>story generation</a>. Despite the success in modeling intra-sentence coherence, existing long text generation models (e.g., BART and GPT-3) still struggle to maintain a coherent event sequence throughout the generated text. We conjecture that this is because of the difficulty for the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to revise, replace, revoke or delete any part that has been generated by the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. In this paper, we present a novel semi-autoregressive document generation model capable of revising and editing the generated text. Building on recent models by (Gu et al., 2019 ; Xu and Carpuat, 2020) we propose document generation as a hierarchical Markov decision process with a two level hierarchy, where the high and low level editing programs. We train our model using imitation learning (Hussein et al., 2017) and introduce roll-in policy such that each <a href=https://en.wikipedia.org/wiki/Policy>policy</a> learns on the output of applying the previous action. Experiments applying the proposed approach sheds various insights on the problems of long text generation using our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>. We suggest various remedies such as using distilled dataset, designing better attention mechanisms and using <a href=https://en.wikipedia.org/wiki/Autoregressive_model>autoregressive models</a> as a <a href=https://en.wikipedia.org/wiki/Low-level_programming_language>low level program</a>.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Skep lank en koerende teks is 'n belangrike en uitgelykbare taak wat versamel baie aansoek gebiede soos opsomming, dokumentvlak masjien vertaling en storie generasie. Terwyl die sukses in die modellering van intra- sentence koherens, bestaande lang teks generasie modele (bv. BART en GPT-3) stoor nog steeds struikel om 'n koherente gebeurtenisvolgorde te hou deur die genereerde teks. Ons verwerp dat dit is vanweë die moeilikheid vir die model om enige deel te hersien, vervang, herhaal of uitvee wat deur die model genereer is. In hierdie papier, voorsien ons 'n roman semi- autoregressiewe dokumentgenerasie model wat moontlik kan hersien en redigeer die genereerde teks. By gebou op onlangse modele deur (Gu et al., 2019; Xu en Carpuat, 2020) voorstel ons dokumentgenerasie as 'n hierarkies Markov besluit proses met 'n twee vlak hierarkie waar die hoë en lae vlak redigeringsprogrammes voorstel. Ons tref ons model deur imitasie leer te gebruik (Hussein et al., 2017) en introduseer rol-in beleid sodat elke beleid leer op die uitvoer van die vorige aksie toepassing. Eksperimente wat die voorgestelde toegang toepassing doen, skep verskeie insigte op die probleme van lang teksgenerasie wat ons model gebruik. Ons stel verskillende herstellings soos die gebruik van verskillende datastel, die ontwerp van beter aandag mekanisme en die gebruik van autoregressiewe modele as 'n lae vlak program.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>የረጅም እና የአካባቢ ጽሑፍ መፍጠር ብዙዎችን ፕሮግራሞች ክፍሎች እንደአቀማመጥ፣ የሰነድ ደረጃዎች መተርጓሜ እና ታሪክ ትውልድ የሚያስጨንቅ እና የሚያስቃወም ስራ ነው፡፡ ምንም እንኳን የድል ግንኙነት ማቀናቀል ቢሆንም፣ ረጅም የጽሑፍ ትውልድ አካባቢዎች (ምሳሌ BART እና GPT-3) በተገኘው ጽሑፍ በሙሉ የተደረገ የግንኙነቱን ድርጊት ለመጠበቅ ይታገላሉ፡፡ We conjecture that this is because of the difficulty for the model to revise, replace, revoke or delete any part that has been generated by the model. በዚህ ገጽ ውስጥ የተፈጠረውን ጽሑፍ ማቀናቀል እና ማስተካክል የሚችል የሰነድ ትውልድ ምሳሌ እናቀርባለን፡፡ አዲስ ዓይነቶች (Gu et al., 2019; Xu እና ካርፉት, 2020) በመሠረት ላይ የሰነድ ትውልድ በሁለት ደረጃዎች ማርኮov ፍርድ ክፍል እና ከፍተኛ እና ታናሹ ፕሮግራሙቶችን ማቀናጃ ፕሮግራም እና ዋናው፡፡ ሞዴሌዎቻችንን በመግለጽ ትምህርት በማድረግ እናስተምረዋለን (Hussein et 2017) እና ሁሉም ፖሊሲ በተቀድሞው ሥራ ለመጠቀም የሚችሉትን የፖሊሲ ውጤት እንዲያስተምረናል፡፡ በተዘጋጀው የጽሑፍ ትውልድ በመጠቀም የረጅም የጽሑፍ ትውልድ ጉዳዮች ላይ የልዩ አሳብ ያሳያል፡፡ የተለየ የዳታ ሰርቨሮች፣ የበለጠ ማስታወቂያውን እና የራሳቸውን ሥልጣን ምሳሌዎችን እንደ ዝቅተኛ ደረጃ ፕሮግራም በመጠቀም እናስባለን፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>يعد إنشاء نص طويل ومتماسك مهمة مهمة وصعبة تشمل العديد من مجالات التطبيق مثل التلخيص والترجمة الآلية على مستوى المستند وإنشاء القصة. على الرغم من النجاح في نمذجة التماسك داخل الجملة ، لا تزال نماذج إنشاء النص الطويل الحالية (على سبيل المثال ، BART و GPT-3) تكافح للحفاظ على تسلسل حدث متماسك في جميع أنحاء النص الذي تم إنشاؤه. نعتقد أن هذا بسبب صعوبة قيام النموذج بمراجعة أو استبدال أو إبطال أو حذف أي جزء تم إنشاؤه بواسطة النموذج. في هذه الورقة ، نقدم نموذجًا جديدًا لإنشاء المستندات شبه الانحدار الذاتي قادر على مراجعة النص الناتج وتحريره. بناءً على النماذج الحديثة من (Gu et al. ، 2019 ؛ Xu and Carpuat ، 2020) نقترح إنشاء المستندات كعملية قرار ماركوف الهرمية مع تسلسل هرمي من مستويين ، حيث برامج التحرير عالية ومنخفضة المستوى. نحن ندرب نموذجنا باستخدام التعلم بالمحاكاة (حسين وآخرون ، 2017) ونقدم سياسة التدرج بحيث تتعلم كل سياسة على مخرجات تطبيق الإجراء السابق. تلقي التجارب التي تطبق النهج المقترح رؤى مختلفة حول مشاكل إنشاء النص الطويل باستخدام نموذجنا. نقترح علاجات مختلفة مثل استخدام مجموعة البيانات المقطرة ، وتصميم آليات انتباه أفضل واستخدام نماذج الانحدار الذاتي كبرنامج منخفض المستوى.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Uzun və müvafiq metinləri yaratmaq möhüm və çətin bir görevdir ki, çoxlu uyğulama bölgeleri, məlumat seviyyəti maşına çevirilməsi və hekayə nəzəriyyəti kimi məlumatdır. İçin cümlələrin birləşməsi modellərində başarılı olmasına rağmen, mövcud uzun mətn nəsli modelləri (bəzisi, BART və GPT-3) yaratdığı mətn boyunca birləşmiş bir vaxt sequencesini qorumaq üçün mübahisə edirlər. Bu modeli yenidən dəyişdirmək, əvəz etmək, təkrar etmək və ya silmək üçün çətindir. Bu kağızda, biz yaratdığı mətn yenidən dəyişdirmək və düzəltmək mümkün olaraq yeni yarı-autoregressiv döküm nəsili modelini göstəririk. Son modellərə inşa edirik (Gu et al., 2019; Xu və Carpuat, 2020; tərəfindən, hörarşik Markov hökmü prosesi olaraq, yüksək və düşük səviyyə düzəltmə proqramları olan iki səviyyə hierarhiyəsi ilə, hörarşik bir Markov hökmü prosesi olaraq). Biz modellərimizi imitasyon öyrənməyi (Hussein et al., 2017) ilə təhsil edirik və hər siyasət əvvəlki eylemlərin istifadə etməsini öyrənir. Önülləşdirilmiş təcrübələrin uygulaması modelimizi istifadə edərək uzun mətn nəsillərinin problemlərinə müxtəlif fikirləri çəkir. Biz destilmiş veri qutusu istifadə etmək, daha yaxşı dikkati mehānismi tasarlamaq və düşük seviyyət program ı olaraq autoregressiv modelləri istifadə etmək kimi müxtəlif dəyişiklikləri təbliğ edirik.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Генерирането на дълъг и съгласуван текст е важна и предизвикателна задача, обхващаща много области на приложение като обобщаване, машинен превод на ниво документи и генериране на истории. Въпреки успеха при моделирането на съгласуваността между изреченията, съществуващите модели за генериране на дълги текстове (напр. BART и GPT-3) все още се борят да поддържат последователност на събитията в целия генериран текст. Предполагаме, че това се дължи на трудността моделът да преразгледа, замени, отмени или изтрие всяка част, която е генерирана от модела. В настоящата статия представяме нов полу-авторегресивен модел за генериране на документи, способен да преразгледа и редактира генерирания текст. Въз основа на последните модели на (Гу и др., 2019; Ксу и Карпуат, 2020) предлагаме генериране на документи като йерархичен процес на вземане на решения на Марков с йерархична йерархия на две нива, където са програмите за редактиране на високо и ниско ниво. Ние обучаваме нашия модел, използвайки имитация на обучение (Хюсеин и др., 2017) и въвеждаме политика на рол-ин, така че всяка политика да се научи за резултатите от прилагането на предишното действие. Експериментите, прилагащи предложения подход, хвърлят различни прозрения за проблемите на дългото генериране на текст, използвайки нашия модел. Предлагаме различни средства за защита, като например използване на дестилиран набор от данни, проектиране на по-добри механизми за внимание и използване на авторегресивни модели като програма на ниско ниво.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Generating long and coherent text is an important and challenging task encompassing many application areas such as summarization, document level machine translation and story generation. প্রজাতির প্রজন্ম মডেল করার সাফল্য সত্ত্বেও বিদীর্ঘ টেক্সট প্রজন্ম মডেল (উদাহরণস্বরূপ বার্টি এবং জিপিটি-৩) সারা জুড়ে তৈরি করা টেক্সটের সাথে আমরা ধারণা করছি যে মডেলের কারণে মডেলের কোন অংশ পরিবর্তন, প্রতিস্থাপন, বাতিল করা অথবা মুছে ফেলার জন্য কঠিন। এই কাগজটিতে আমরা একটি নোভেল স্বয়ংক্রিয়ভাবে স্বয়ংক্রিয়ভাবে নথিপত্রের প্রজন্ম মডেল উপস্থাপন করি যা তৈরি করা লেখা পরি সাম্প্রতিক মডেলে (গু et al., 2019; জু এবং ক্যার্পুয়াট, ২০২০) নির্মাণ করে আমরা নথিপত্রের প্রজন্ম হিয়ারেরাক্কিল মার্কোভ সিদ্ধান্ত নির্মাণের প্রস্তাব করছি যেখ আমরা আমাদের মডেল শিক্ষা প্রশিক্ষণ করি (হুসেন এন্ট ২০১৭) ব্যবহার করে এবং রোল-ইন নীতি পরিচালনা করি যেমন প্রত্যেক নীতি পূর্ববর্তী কাজের আউটপ প্রস্তাবিত পদ্ধতি প্রয়োগ করার পরীক্ষা আমাদের মডেল ব্যবহার করে দীর্ঘ লেখা প্রজন্মের সমস্যার বিভিন্ন দৃষ্টিভ আমরা বিভিন্ন প্রতিক্রিয়া পরামর্শ দিচ্ছি যেমন বিচ্ছিন্ন তথ্য সেট ব্যবহার করে, ভালো মনোযোগ মেকানিস্টেম এবং স্বয়ংক্রিয় স্</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ཉེར་སྤྱོད་རིང དབྱེ་རིམ་འདིའི་ནང་གི་ཚིག ང་ཚོས་མིག་འཆར་བྱས་ན། མ་དབྱིབས་བཟོ་བཅོས་བྱེད་པར་དཀའ་ངལ་པོ་ཞིག་ཡིན་པ་རྟོགས། ང་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་ཚོའི་དུས་ཡིག་ཆ་ལུས་རང་འགུལ་གྱི་ཡིག Building on recent models by (Gu et al., 2019; Xu and Carpuat, 2020) we propose document generation as a hierarchical Markov decision process with a two level hierarchy, where the high and low level editing programs. ང་ཚོའི་མ་དབུགས་ལ་imitation learning་སྤྱད་ནས་ང་ཚོའི་ཐབས་ལམ་སྟོན་བྱེད་ཀྱི་ཡོད། ལག་ལེན་བྱེད་པའི་སྔོན་སྒྲིག་གི་ཐབས་ལམ་ལ་ལག་ལེན་འཐབ་པའི་སྣེ་ཚོགས་རྣམས་ལ་མཐོང་ནུས་མེད་པའི་མིག་རྣམས་ ང་ཚོས་རང་ཉིད་ཀྱི་ཆེད་དུ་བཅུག་ཐབས་མེད་པར། དཔེར་ན་གསལ་བཤད་ཀྱི་གནད་སྡུད་ཇུས་གཏོང་བའི་ཐབས་ལམ་ལ་ཇེ་གསལ་བཀལ་བ་དང</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Proizvodnja dugog i saslušnog teksta je važan i izazovni zadatak koji uključuje mnoge oblasti aplikacije poput sažetke, prevode strojeva na nivou dokumenta i generacije priče. Uprkos uspjehu u modeliranju koherencije unutar rečenice, postojeći modeli generacije dugog teksta (npr. BART i GPT-3) i dalje se bore za održavanje sklonjene sekvence događaja kroz proizvođeni tekst. Pretpostavljamo da je to zbog teškoće modela pregledati, zamijeniti, ukloniti ili izbrisati bilo koji dio koji je stvoren modelom. U ovom papiru predstavljamo nov model generacije polu-autoregresivnog dokumenta sposoban za reviziju i editiranje proizvedenog teksta. Na osnovu nedavnih modela (Gu et al., 2019; Xu i Carpuat, 2020) predlažemo generaciju dokumenta kao proces odluke o hijerarhičkom Markovu sa hijerarhijom dva nivoa, gdje su programi za editiranje visokog i niskog nivoa. Vježbamo svoj model koristeći učenje imitacije (Hussein et al., 2017) i predstavljamo politiku koja se uključuje kako svaka politika uči o izlazu primjene prethodne akcije. Eksperimenti koji primjenjuju predloženi pristup proizvode različite uvide o problemima duge generacije teksta koristeći naš model. Predlažemo raznim sredstvima za opremu poput korištenja destiliranog seta podataka, dizajniranja boljih mehanizma pažnje i korištenja autoregresivnih modela kao program niskog nivoa.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>generar un text llarg i coherent és una tasca important i desafiadora que inclou moltes àrees d'aplicació com la somària, la traducció màquina a nivell de documentos i la generació de històries. Malgrat l'èxit en la modelació de la coherencia intrafrases, els models existents de generació de text llarg (per exemple, BART i GPT-3) encara lluiten per mantenir una seqüència coherent d'eventos a través del text generat. Suposem que això és degut a la dificultat del model de revisar, substituir, revocar o eliminar qualsevol part que ha estat generada pel model. En aquest article presentem un nou model de generació semi-autoregressiu capaç de revisar i editar el text generat. Construïnt en models recents de (Gu et al., 2019; Xu i Carpuat, 2020) proposem la generació de documents com un procés de decisió jeràrquic Markov amb una jerarquia de dos nivells, on els programes d'edició de alt i baix nivell. Ensenyem el nostre model fent servir l'aprenentatge de imitació (Hussein et al., 2017) i introduïm una política d'introducció de tal manera que cada política aprengui sobre el resultat d'aplicar l'acció anterior. Els experiments que aplican l'enfocament proposat revelen diversos aspectes sobre els problemes de la llarga generació de text utilitzant el nostre model. Sugirem diversos recursos, com l'ús de conjunt de dades destilats, el disseny de mecanismes d'atenció millors i l'ús de models autoregressius com un program a de baix nivell.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Generování dlouhého a soudržného textu je důležitým a náročným úkolem zahrnujícím mnoho oblastí aplikace, jako je shrnutí, strojový překlad dokumentů a generování příběhů. Navzdory úspěchu v modelování koherence uvnitř věty stále probíhají existující modely generace dlouhého textu (např. BART a GPT-3) s udržením koherentní sekvence událostí v generovaném textu. Domníváme se, že je to kvůli obtížnosti modelu revidovat, nahradit, zrušit nebo smazat jakoukoliv část, která byla vygenerována modelem. V tomto článku představujeme nový model semi-autoregresivní generace dokumentů schopný revidovat a editovat generovaný text. Na základě nejnovějších modelů (Gu et al., 2019; Xu a Carpuat, 2020) navrhujeme generování dokumentů jako hierarchický Markovský rozhodovací proces se dvouúrovňovou hierarchií, kde editační programy vysoké a nízké úrovně programují. Náš model trénujeme pomocí imitačního učení (Hussein et al., 2017) a zavádíme roll-in politiku tak, aby se každá politika učila o výstupu uplatnění předchozí akce. Experimenty aplikující navržený přístup přinášejí různé pohledy na problémy generování dlouhého textu pomocí našeho modelu. Navrhujeme různé prostředky jako například použití destilované datové sady, navrhování lepších mechanismů pozornosti a použití autoregresivních modelů jako programu nízké úrovně.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Generering af lang og sammenhængende tekst er en vigtig og udfordrende opgave, der omfatter mange anvendelsesområder såsom opsummering, maskinoversættelse på dokumentniveau og historiegenerering. På trods af succesen med at modellere intra-sætning kohærens, eksisterende lange tekstgenereringsmodeller (f.eks. BART og GPT-3) stadig kæmper for at opretholde en sammenhængende begivenhedssekvens i hele den genererede tekst. Vi formoder, at dette skyldes, at modellen har svært ved at revidere, erstatte, tilbagekalde eller slette enhver del, der er genereret af modellen. I denne artikel præsenterer vi en ny semi-autoregressiv dokumentgenerationsmodel, der er i stand til at revidere og redigere den genererede tekst. Med udgangspunkt i de seneste modeller fra (Gu et al., 2019; Xu og Carpuat, 2020) foreslår vi dokumentgenerering som en hierarkisk Markov beslutningsproces med to niveauer hierarki, hvor højt og lavt niveau redigeringsprogrammer. Vi træner vores model ved hjælp af imiteret læring (Hussein et al., 2017) og indfører roll-in politik, således at hver politik lærer om resultatet af anvendelsen af den tidligere handling. Eksperimenter med anvendelse af den foreslåede tilgang giver forskellige indsigter i problemerne med lang tekst generering ved hjælp af vores model. Vi foreslår forskellige løsninger såsom at bruge destilleret datasæt, designe bedre opmærksomhedsmekanismer og bruge autoregressive modeller som et lavt niveau program.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Lange und kohärente Texte zu generieren ist eine wichtige und herausfordernde Aufgabe, die viele Anwendungsbereiche wie Zusammenfassung, maschinelle Übersetzung auf Dokumentenebene und Story-Generierung umfasst. Trotz des Erfolgs bei der Modellierung der Kohärenz innerhalb des Satzes kämpfen bestehende Modelle zur Generierung langer Texte (z.B. BART und GPT-3) immer noch darum, eine kohärente Ereignissequenz im gesamten generierten Text aufrechtzuerhalten. Wir vermuten, dass dies auf die Schwierigkeit des Modells zurückzuführen ist, Teile zu überarbeiten, zu ersetzen, zu widerrufen oder zu löschen, die vom Modell generiert wurden. In diesem Beitrag stellen wir ein neuartiges semi-autoregressives Dokumentengenerationsmodell vor, das in der Lage ist, den generierten Text zu revidieren und zu bearbeiten. Aufbauend auf aktuellen Modellen von (Gu et al., 2019; Xu und Carpuat, 2020) schlagen wir die Dokumentenerzeugung als hierarchischen Markov-Entscheidungsprozess mit einer zweistufigen Hierarchie vor, bei der die Bearbeitung auf hoher und niedriger Ebene erfolgt. Wir trainieren unser Modell anhand von Imitation Learning (Hussein et al., 2017) und führen Roll-in-Politik ein, so dass jede Politik von den Ergebnissen der Anwendung der vorherigen Aktion lernt. Experimente, die den vorgeschlagenen Ansatz anwenden, geben verschiedene Einblicke in die Probleme der langen Textgenerierung mit unserem Modell. Wir schlagen verschiedene Abhilfemaßnahmen vor, wie die Verwendung destillierter Datensätze, die Entwicklung besserer Aufmerksamkeitsmechanismen und die Verwendung autoregressiver Modelle als Low-Level-Programm.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Η δημιουργία μεγάλου και συνεκτικού κειμένου είναι μια σημαντική και προκλητική εργασία που περιλαμβάνει πολλούς τομείς εφαρμογής, όπως η σύνοψη, η μηχανική μετάφραση σε επίπεδο εγγράφων και η δημιουργία ιστοριών. Παρά την επιτυχία στη μοντελοποίηση της συνοχής εντός των προτάσεων, τα υπάρχοντα μοντέλα δημιουργίας μεγάλου μήκους κειμένου (π.χ. και GPT-3) εξακολουθούν να αγωνίζονται να διατηρήσουν μια συνεκτική ακολουθία γεγονότων σε όλο το παραγόμενο κείμενο. Υποθέτουμε ότι αυτό οφείλεται στη δυσκολία για το μοντέλο να αναθεωρήσει, να αντικαταστήσει, να ανακαλέσει ή να διαγράψει οποιοδήποτε μέρος έχει δημιουργηθεί από το μοντέλο. Στην παρούσα εργασία, παρουσιάζουμε ένα νέο μοντέλο ημι-αυτοανακριτικής δημιουργίας εγγράφων ικανό να αναθεωρήσει και να επεξεργαστεί το παραγόμενο κείμενο. Βασιζόμενοι σε πρόσφατα μοντέλα (κ.λ., 2019, και Καρπουάτ, 2020) προτείνουμε τη δημιουργία εγγράφων ως ιεραρχική διαδικασία λήψης αποφάσεων με ιεραρχία δύο επιπέδων, όπου το υψηλό και το χαμηλό επίπεδο προγραμμάτων επεξεργασίας. Εκπαιδεύουμε το μοντέλο μας χρησιμοποιώντας τη μάθηση απομίμησης (κ.α., 2017) και εισάγουμε πολιτική με τέτοιο τρόπο ώστε κάθε πολιτική να μαθαίνει σχετικά με το αποτέλεσμα της εφαρμογής της προηγούμενης δράσης. Τα πειράματα που εφαρμόζουν την προτεινόμενη προσέγγιση ρίχνουν διάφορες απόψεις για τα προβλήματα της μακροχρόνιας δημιουργίας κειμένου χρησιμοποιώντας το μοντέλο μας. Προτείνουμε διάφορες λύσεις όπως η χρήση αποσταγμένων δεδομένων, ο σχεδιασμός καλύτερων μηχανισμών προσοχής και η χρήση αυτοανακριτικών μοντέλων ως χαμηλού επιπέδου πρόγραμμα.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Generar texto largo y coherente es una tarea importante y desafiante que abarca muchas áreas de aplicación, como el resumen, la traducción automática a nivel de documentos y la generación de historias. A pesar del éxito en el modelado de la coherencia entre oraciones, los modelos existentes de generación de texto largo (por ejemplo, BART y GPT-3) siguen teniendo dificultades para mantener una secuencia de eventos coherente en todo el texto generado. Suponemos que esto se debe a la dificultad para que el modelo revise, reemplace, revoque o elimine cualquier parte que haya sido generada por el modelo. En este artículo, presentamos un novedoso modelo de generación de documentos semiautorregresivos capaz de revisar y editar el texto generado. Sobre la base de modelos recientes de (Gu et al., 2019; Xu y Carpuat, 2020) proponemos la generación de documentos como un proceso de decisión jerárquico de Markov con una jerarquía de dos niveles, donde los programas de edición de alto y bajo nivel. Entrenamos nuestro modelo mediante el aprendizaje de imitación (Hussein et al., 2017) e introducimos una política acumulada de manera que cada política aprenda del resultado de la aplicación de la acción anterior. Los experimentos que aplican el enfoque propuesto arrojan varios puntos de vista sobre los problemas de la generación de textos largos utilizando nuestro modelo. Sugerimos varias soluciones, como el uso de datos destilados, el diseño de mejores mecanismos de atención y el uso de modelos autorregresivos como un programa de bajo nivel.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Pika ja sidusa teksti loomine on oluline ja keeruline ülesanne, mis hõlmab paljusid rakendusvaldkondi, nagu kokkuvõte, dokumenditasemel masintõlge ja lugude loomine. Vaatamata lausesisese sidususe modelleerimise edule on olemasolevatel pika teksti genereerimise mudelitel (nt BART ja GPT-3) endiselt raske säilitada ühtne sündmuste jada kogu genereeritud teksti ulatuses. Eeldame, et see on tingitud mudeli raskustest muuta, asendada, tühistada või kustutada mis tahes mudeli loodud osa. Käesolevas töös tutvustame uudset poolaurregressiivset dokumentide genereerimise mudelit, mis suudab genereeritud teksti muuta ja redigeerida. Tuginedes hiljutistele mudelitele (Gu et al., 2019; Xu ja Carpuat, 2020) pakume välja dokumentide genereerimise kui hierarhilise Markovi otsustamisprotsessi kahetasandilise hierarhiaga, kus kõrge ja madala taseme redigeerimisprogrammid. Koolitame oma mudelit imitatsiooniõppe abil (Hussein jt., 2017) ja võtame kasutusele roll-in poliitika nii, et iga poliitika õpib eelmise meetme rakendamise tulemusi. Kavandatud lähenemisviisi rakendamise katsed annavad erinevaid ülevaateid pika teksti genereerimise probleemidest meie mudeli abil. Soovitame erinevaid abinõusid, nagu destilleeritud andmekogumi kasutamine, paremate tähelepanumehhanismide kujundamine ja autoregressiivsete mudelite kasutamine madala taseme programmina.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>پیدا کردن متن طولانی و هماهنگی یک کار مهم و سخت‌گیری است که شامل بسیاری از منطقه‌های کاربرد مانند جمع کردن، ترجمه‌های دستگاه سطح سند و نسل داستان است. با وجود موفقیت در مدل‌سازی هماهنگی داخل جمله، مدل‌های نسل متن طولانی وجود دارد (مثال BART و GPT-3) هنوز برای نگه داشتن یک رده‌ی اتفاق هماهنگی در تمام متن تولید می‌کنند. ما تصور می‌کنیم که این به دلیل مشکلی برای مدل است که هر بخشی که توسط مدل تولید شده است تغییر دهد، جایگزین، باز کند یا پاک کند. در این کاغذ، ما یک مدل نسل سند semi-autoregressive را نشان می دهیم که قادر به تغییر و ویرایش متن تولید شده است. بر روی مدل های اخیر توسط (Gu et al., 2019; Xu and Carpuat, 2020) ما نسل سند را به عنوان یک فرایند تصمیم گرفتن قانونی مارکوف با یک قانونی دو سطح پیشنهاد می‌کنیم که برنامه‌های ویرایش سطح بالا و پایین است. ما مدل خود را با استفاده از یادگیری تصویر (Hussein et al., 2017) آموزش می‌دهیم و سیاست‌های داخلی را معرفی می‌کنیم که هر سیاست در نتیجه کارهای قبلی یاد می‌گیرد. تجربه‌هایی که با استفاده از دستور پیشنهاد می‌گیرند، مشاهده‌های مختلف در مورد مشکلات نسل متن طولانی با استفاده از مدل ما می‌کند. ما پیشنهاد می‌کنیم داروهای متفاوتی مثل استفاده از مجموعه داده‌های متفاوت، طراحی مکانیسم توجه بهتر و استفاده از مدل‌های خودگریزی به عنوان برنامه‌ی سطح پایین استفاده کنیم.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Pitkän ja johdonmukaisen tekstin luominen on tärkeä ja haastava tehtävä, joka kattaa monia sovellusalueita, kuten tiivistelmän, dokumenttitason konekäännöksen ja tarinan tuottamisen. Vaikka lauseidensisäisten koherenssien mallintaminen onnistui, olemassa olevat pitkän tekstintuotannon mallit (esim. BART ja GPT-3) kamppailevat edelleen johdonmukaisen tapahtumajärjestyksen ylläpitämiseksi koko luodussa tekstissä. Arvelemme, että tämä johtuu siitä, että mallin on vaikea tarkistaa, korvata, peruuttaa tai poistaa mitään mallin luomaa osaa. Tässä työssä esitellään uusi puoliautoregressiivinen dokumenttien generointimalli, joka pystyy tarkistamaan ja muokkaamaan luotua tekstiä. Uusien mallien pohjalta (Gu et al., 2019; Xu ja Carpuat, 2020) ehdotamme dokumenttien luomista hierarkkisena Markovin päätöksentekoprosessina kaksitasoisella hierarkialla, jossa korkean ja matalan tason editointiohjelmat. Koulutamme mallimme jäljitelmäoppimisen avulla (Hussein et al., 2017) ja otamme käyttöön roll-in-politiikan siten, että jokainen politiikka oppii aiemman toimen soveltamisen tuotokset. Ehdotettua lähestymistapaa soveltavat kokeilut tuovat erilaisia näkemyksiä pitkän tekstin tuottamisen ongelmista mallimme avulla. Ehdotamme erilaisia korjaustoimenpiteitä, kuten tislatun datajoukon käyttöä, parempien huomiomekanismien suunnittelua ja autoregressiivisten mallien käyttöä matalatasoisena ohjelmana.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>La génération d'un texte long et cohérent est une tâche importante et complexe qui englobe de nombreux domaines d'application tels que la synthèse, la traduction automatique au niveau du document et la génération d'histoires. Malgré le succès de la modélisation de la cohérence intra-phrase, les modèles de génération de texte long existants (par exemple BART et GPT-3) ont encore du mal à maintenir une séquence d'événements cohérente dans le texte généré. Nous supposerons que cela est dû à la difficulté pour le modèle de réviser, remplacer, révoquer ou supprimer toute pièce qui a été générée par le modèle. Dans cet article, nous présentons un nouveau modèle de génération de documents semi-autorégressif capable de réviser et d'éditer le texte généré. En nous appuyant sur des modèles récents de (Gu et al., 2019 ; Xu et Carpuat, 2020), nous proposons la génération de documents en tant que processus de décision hiérarchique de Markov avec une hiérarchie à deux niveaux, où les programmes d'édition de haut et de bas niveau. Nous entraînons notre modèle en utilisant l'apprentissage par imitation (Hussein et al., 2017) et introduisons une politique de roll-in de telle sorte que chaque politique apprenne sur les résultats de l'application de l'action précédente. Les expériences utilisant l'approche proposée apportent divers éclairages sur les problèmes de génération de texte long à l'aide de notre modèle. Nous suggérons divers remèdes tels que l'utilisation de données distillées, la conception de meilleurs mécanismes d'attention et l'utilisation de modèles autorégressifs comme programme de bas niveau.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Is tasc tábhachtach dúshlánach é téacs fada comhleanúnach a ghiniúint a chuimsíonn go leor réimsí feidhmchláir mar achoimre, aistriúchán meaisín ar leibhéal doiciméad agus giniúint scéalta. In ainneoin gur éirigh chomh maith sin le comhleanúnachas in abairt a shamhaltú, tá deacrachtaí fós ag samhlacha giniúna téacs fada atá ann cheana féin (m.sh., BART agus GPT-3) seicheamh comhleanúnach teagmhas a choinneáil ar fud an téacs ginte. Is dóigh linn gurb é seo an chúis leis an deacracht atá ag an múnla aon chuid atá ginte ag an múnla a athbhreithniú, a athsholáthar, a chúlghairm nó a scriosadh. Sa pháipéar seo, cuirimid i láthair samhail giniúna doiciméad leath-uathchéimnitheach úrscéal atá in ann athbhreithniú agus eagarthóireacht a dhéanamh ar an téacs ginte. Ag tógáil ar mhúnlaí le déanaí le (Gu et al., 2019; Xu agus Carpuat, 2020) molaimid giniúint doiciméad mar phróiseas cinnidh ordlathach Markov le hordlathas dhá leibhéal, ina ndéantar na cláir eagarthóireachta ardleibhéil agus ísealleibhéil. Déanaimid ár múnla a thraenáil trí úsáid a bhaint as foghlaim aithrise (Hussein et al., 2017) agus tugtar isteach beartas rollaithe isteach ionas go bhfoghlaimíonn gach beartas ar an aschur ó chur i bhfeidhm an ghnímh roimhe seo. Trí na turgnaimh a bhaineann leis an gcur chuige molta a chur i bhfeidhm, faightear léargais éagsúla ar na fadhbanna a bhaineann le cruthú téacs fada ag baint úsáide as ár múnla. Molaimid réitigh éagsúla ar nós tacar sonraí driogtha a úsáid, meicníochtaí airde níos fearr a dhearadh agus samhlacha uath-aischéimnitheacha a úsáid mar chlár ísealleibhéil.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mai ƙãga matsayin kwanan da aka ƙunsa, yana da wani aikin mai muhimu da mai gaura wanda ke ƙunsa da wasu area na shiryoyin ayuka kamar tsorori, fassarar maɓallin zane da kizafi. Babu da cin nasara a sami-danna-ɗabi'a, yana ƙari motel masu ƙari na matsayi (misali, BArT da GPT-3) don ka sami tsari wani sequence na haɗi cikin matsayin da aka ƙãga. Tuna zaton cewa wannan yana da tsanani wa misali da za'a canza, kuma ka bada, ka sake, ko kuma ka goge wani abu wanda aka gina shi na motel. Ga wannan takardan, muna halatar da wata shekara na takardar da ke iya iya canza kure da taƙaita matsayin da aka ƙãga. Building on recent models by (Gu et al., 2019; Xu and Carpuat, 2020) we propose document generation as a hierarchical Markov decision process with a two level hierarchy, where the high and low level editing programs. Tuna sanar da misalinmu da za'a yi amfani da in karanta surori (Hussein et al., 2017) kuma mu ƙarfafa lissafar rubutu kamar yadda kowane siyafar za'a sani a kan zartar da aikin da ya gabatar. Tajarakin da ke amfani da mazaɓan da aka buƙata, yana nuna masu basĩri masu cikin masu matsayin kiyãyen matsayi tsawo da misalinmu. Tuna shawarar da wasu mutane kamar misãlai da za'a yi amfani da tsarin danne da aka rarraba, ana ƙayyade masu amfani da shiryoyin muhalli masu amfani da shiryoyin ayuka da farat-regressive kamar wata shirin wuri mai ƙas ƙanci.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>יצירת טקסט ארוך ותקביל היא משימה חשובה ומתאגרת שמכילה אזורי שימוש רבים כמו הסכם, תרגום מכונות רמה מסמכים ודור סיפורים. למרות ההצלחה בהדגמה בתוך המשפט, דוגמנים של דוגמנים של דוגמנים של דוגמנים ארוכים (למשל BART וג'י.פי.טי. אנו מניחים שזה בגלל הקשה למודל לשנות, להחליף, לבטל או למחוק כל חלק שנוצר על ידי המודל. בעיתון הזה, אנחנו מציגים מודל דוגמא של דוגמא של דוגמא חצי-אוטורגרסיבי מסוגל לשנות ולהעורר את הטקסט המיוצר. Building on recent models by (Gu et al., 2019; Xu and Carpuat, 2020) we propose document generation as a hierarchical Markov decision process with a two level hierarchy, where the high and low level editing programs. We train our model using imitation learning (Hussein et al., 2017) and introduce roll-in policy such that each policy learns on the output of applying the previous action. ניסויים בהשתמשת הגישה המוצעת משפיעים תובנות שונות על הבעיות של דור טקסט ארוך באמצעות הדוגמא שלנו. We suggest various remedies such as using distilled dataset, designing better attention mechanisms and using autoregressive models as a low level program.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>लंबे और सुसंगत पाठ उत्पन्न करना एक महत्वपूर्ण और चुनौतीपूर्ण कार्य है जिसमें कई अनुप्रयोग क्षेत्रों जैसे सारांश, दस्तावेज़ स्तर की मशीन अनुवाद और कहानी पीढ़ी शामिल हैं। मॉडलिंग इंट्रा-वाक्य सुसंगतता में सफलता के बावजूद, मौजूदा लंबे पाठ पीढ़ी के मॉडल (जैसे, BART और GPT-3) अभी भी उत्पन्न पाठ में एक सुसंगत घटना अनुक्रम बनाए रखने के लिए संघर्ष करते हैं। हम अनुमान लगाते हैं कि यह मॉडल द्वारा उत्पन्न किए गए किसी भी हिस्से को संशोधित करने, बदलने, रद्द करने या हटाने के लिए मॉडल के लिए कठिनाई के कारण है। इस पेपर में, हम एक उपन्यास अर्ध-autoregressive दस्तावेज़ पीढ़ी मॉडल प्रस्तुत करते हैं जो उत्पन्न पाठ को संशोधित और संपादित करने में सक्षम है। द्वारा हाल के मॉडल पर निर्माण (Gu et al., 2019; Xu और Carpuat, 2020) हम दो स्तर पदानुक्रम के साथ एक पदानुक्रमित मार्कोव निर्णय प्रक्रिया के रूप में दस्तावेज़ पीढ़ी का प्रस्ताव करते हैं, जहां उच्च और निम्न स्तर के संपादन कार्यक्रम हैं। हम नकल सीखने (हुसैन एट अल. 2017) का उपयोग करके अपने मॉडल को प्रशिक्षित करते हैं और रोल-इन नीति पेश करते हैं जैसे कि प्रत्येक नीति पिछली कार्रवाई को लागू करने के आउटपुट पर सीखती है। प्रस्तावित दृष्टिकोण को लागू करने वाले प्रयोग हमारे मॉडल का उपयोग करके लंबी पाठ पीढ़ी की समस्याओं पर विभिन्न अंतर्दृष्टि डालते हैं। हम विभिन्न उपचारों का सुझाव देते हैं जैसे कि आसुत डेटासेट का उपयोग करना, बेहतर ध्यान तंत्र डिजाइन करना और निम्न स्तर के कार्यक्रम के रूप में ऑटोरिग्रेसिव मॉडल का उपयोग करना।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Proizvodnja dugog i usklađenog teksta je važan i izazovan zadatak koji uključuje mnoge područje aplikacije poput sažetka, prevoda strojeva na razini dokumenta i generacije priče. Uprkos uspjehu u modeliranju koherencije unutar rečenice, postojeći modeli dugog teksta generacije (npr. BART i GPT-3) i dalje se bore za održavanje sklonjene sekvence događaja kroz proizvođeni tekst. Pretpostavljamo da je to zbog teškoće modela pregledati, zamijeniti, ukloniti ili izbrisati bilo koji dio koji je stvoren modelom. U ovom papiru predstavljamo nov model generacije polu-autoregresivnog dokumenta sposoban za reviziju i uredbu proizvedenog teksta. Na osnovu nedavnih modela (Gu et al., 2019; Xu i Carpuat, 2020) predlažemo generaciju dokumenta kao proces odluke o hijerarhičkom Markovu s hijerarhijom dvije razine, gdje su programi uredbe visoke i niske razine. Vježbamo naš model s učenjem imitacije (Hussein et al., 2017) i uvodimo politiku koja se uključuje kako svaka politika uči o ishodu primjene prethodne akcije. Eksperimenti koji primjenjuju predloženi pristup proizvode različite uvide o problemima duge proizvodnje teksta koristeći naš model. Predlažemo različite lijekove poput korištenja destiliranog seta podataka, dizajniranja boljih mehanizma pažnje i korištenja autoregresivnih modela kao program niskog nivoa.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Hosszú és koherens szöveg létrehozása fontos és kihívást jelentő feladat, amely számos alkalmazási területet magában foglal, mint például az összefoglalás, a dokumentum szintű gépi fordítás és a történetek generálása. A mondatokon belüli koherencia modellezésének sikere ellenére a meglévő hosszú szöveggenerációs modellek (például BART és GPT-3) még mindig küzdenek egy koherens eseménysorozat fenntartásával a generált szövegben. Feltételezzük, hogy ez azért van, mert a modell nehézséget okoz a modell által létrehozott bármely alkatrész felülvizsgálatának, kicserélésének, visszavonásának vagy törlésének. Ebben a tanulmányban egy új, félig-autoregresszív dokumentumgenerációs modellt mutatunk be, amely képes a generált szöveg felülvizsgálatára és szerkesztésére. A legutóbbi modellekre építve (Gu et al., 2019; Xu és Carpuat, 2020) javasoljuk a dokumentum generálását hierarchikus Markov döntési folyamatként, kétszintes hierarchiával, ahol a magas és alacsony szintű szerkesztési programok. Modellünket imitációs tanulással (Hussein et al., 2017) képezzük, és bevezetjük a roll-in politikát úgy, hogy minden politika megismerje az előző intézkedés alkalmazásának eredményeit. A javasolt megközelítést alkalmazó kísérletek különböző betekintéseket nyújtanak a modellünk segítségével a hosszú szöveggenerálás problémáira. Különböző megoldásokat javasolunk, mint például desztillált adatkészlet használata, jobb figyelemmechanizmusok kialakítása és az autoregresszív modellek használata alacsony szintű programként.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Երկար և համապատասխան տեքստի ստեղծելը կարևոր և դժվար խնդիր է, որը ներառում է շատ ծրագրերի ոլորտներ, ինչպիսիք են համառոտագրությունը, փաստաթղթի մակարդակի մեքենային թարգմանությունը և պատմությունների ստեղծ Չնայած ներս նախադասությունների կոնցենսիայի մոդելավորման հաջողությանը, գոյություն ունի երկար տեքստի ստեղծման մոդելներ (օրինակ, BAR և GPT-3), որոնք դեռևս պահպանում են կոնցենսիվ իրադարձությունների հաջորդականությունը ստեղծված Մենք ենթադրում ենք, որ սա այն պատճառով է, որ մոդելը բարդ է վերանայել, փոխարինել, վերանայել կամ ջնջել մոդելի կողմից ստեղծված ցանկացած մասը: Այս թղթի մեջ մենք ներկայացնում ենք մի նոր կիսա-ավտոգրեսիվ փաստաթղթի ստեղծման մոդել, որը կարողանում է վերանայել և խմբագրել ստեղծված տեքստը: Building on recent models by (Gu et al., 2019; Xu and Carpuat, 2020) we propose document generation as a hierarchical Markov decision process with a two level hierarchy, where the high and low level editing programs. Մենք ուսուցանում ենք մեր մոդելը՝ օգտագործելով կրկնօրինակման ուսումնասիրությունը (Հուսեյնը և այլն., 2017 թ․-ը) և ներկայացնում ենք այնպիսի քաղաքականություն, որ յուրաքանչյուր քաղաքականություն սովորի նախորդ գործողության կիրառման Փորձերը, որոնք օգտագործում են նախագծված մոտեցումը, տարբեր տեսանկյուններ են տալիս երկար տեքստի սերունդների խնդիրների մասին, օգտագործելով մեր մոդելը: Մենք առաջարկում ենք տարբեր բուժման միջոցներ, ինչպիսիք են՝ օգտագործելը դիսլիլացված տվյալների համակարգը, ավելի լավ ուշադրության մեխանիզմներ ստեղծելը և օգտագործելը ինքնագրեսիվ մոդելներ որպես ցածր մա</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Menjana teks panjang dan konsisten adalah tugas yang penting dan menantang yang meliputi banyak bidang aplikasi seperti ringkasan, penerjemah mesin tingkat dokumen dan generasi cerita. Meskipun sukses dalam modeling koerensi intra-kalimat, model generasi teks panjang yang ada (contohnya, BART dan GPT-3) masih berjuang untuk mempertahankan urutan peristiwa koerenen sepanjang teks yang dibuat. Kami menduga bahwa ini karena kesulitan bagi model untuk mengubah, mengganti, membatalkan atau menghapus setiap bagian yang telah dihasilkan oleh model. Dalam kertas ini, kami mempersembahkan model generasi dokumen semi-autoregresif yang mampu mengubah dan edit teks yang dihasilkan. Building on recent models by (Gu et al., 2019; Xu and Carpuat, 2020) we propose document generation as a hierarchical Markov decision process with a two level hierarchy, where the high and low level editing programs. Kami melatih model kami menggunakan belajar imitasi (Hussein et al., 2017) dan memperkenalkan kebijakan roll-in sehingga setiap kebijakan belajar tentang hasil dari menerapkan tindakan sebelumnya. Experiments applying the proposed approach sheds various insights on the problems of long text generation using our model. Kami menyarankan berbagai obat seperti menggunakan set data distil, merancang mekanisme perhatian yang lebih baik dan menggunakan model autoregresif sebagai program tingkat rendah.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Generare testo lungo e coerente è un compito importante e impegnativo che comprende molte aree applicative come la sintesi, la traduzione automatica a livello di documento e la generazione di storie. Nonostante il successo nella modellazione della coerenza intra-frase, i modelli esistenti di generazione di testo lungo (ad esempio BART e GPT-3) faticano ancora a mantenere una sequenza di eventi coerente in tutto il testo generato. Supponiamo che ciò sia dovuto alla difficoltà per il modello di rivedere, sostituire, revocare o eliminare qualsiasi parte generata dal modello. In questo articolo, presentiamo un nuovo modello di generazione di documenti semi-autoregressivo in grado di rivedere e modificare il testo generato. Basandoci su modelli recenti di (Gu et al., 2019; Xu e Carpuat, 2020) proponiamo la generazione di documenti come processo decisionale gerarchico Markov con una gerarchia a due livelli, dove i programmi di editing di alto e basso livello. Formiamo il nostro modello utilizzando l'apprendimento imitativo (Hussein et al., 2017) e introduciamo una politica di rollin in modo che ogni politica impari sui risultati dell'applicazione dell'azione precedente. Esperimenti che applicano l'approccio proposto forniscono varie intuizioni sui problemi della generazione di testi lunghi utilizzando il nostro modello. Suggeriamo vari rimedi come l'utilizzo di set di dati distillati, la progettazione di meccanismi di attenzione migliori e l'utilizzo di modelli autoregressivi come programma di basso livello.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>長く一貫したテキストを生成することは、要約、文書レベルの機械翻訳、ストーリー生成などの多くのアプリケーション領域を含む、重要で困難なタスクです。 文章内の一貫性をモデリングすることに成功したにもかかわらず、既存の長いテキスト生成モデル（例えば、ＢＡＲＴ及びＧＰＴ － ３ ）は、生成されたテキスト全体にわたって一貫性のあるイベントシーケンスを維持するために依然として苦労する。 これは、モデルがモデルによって生成された部品を改訂、交換、取り消し、または削除することが困難であるためであると推測します。 本稿では、生成されたテキストの改訂・編集が可能な新規の半自己回帰文書生成モデルを提示する。 (Gu et al., 2019; Xu and Carpuat, 2020)による最近のモデルに基づいて、高レベルと低レベルの編集プログラムを含む2レベルの階層構造を持つ階層的なマルコフ決定プロセスとしてドキュメント生成を提案します。 模倣学習を使用してモデルをトレーニングし（ Hussein et al., 2017 ）、各ポリシーが前のアクションを適用することでアウトプットを学習するように、ロールインポリシーを導入します。 提案されたアプローチを適用する実験は、私たちのモデルを使用した長いテキスト生成の問題に関するさまざまな洞察を提供します。 蒸留データセットの使用、より良い注意メカニズムの設計、低レベルプログラムとしての自己回帰モデルの使用など、さまざまな救済策を提案します。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Jejaring Ngawe ngupakane seneng nglanggar sampeyan ingkang sampeyan-seneng kawelan, model sing langgar teks oleh dumateng (adil. Balt karo Gpta-3) kang isih nguasai nglanggar sampeyan operasi sing berarti secanse sampeyan nggo ndelok teks oluyo. Awak dhéwé ngerasai iki ngono hal-hal susahe kanggo model nggunakake Nang pemilih iki, kita sembaran model sing sembaran autoRegresno dokumen sing bisa ngubah banjure ngubah lan ngubah teks Generation Gu et al, 2011; Xu lan carpuat, 2020) awak dhéwé nggawe dokumen nganggep sistem anu sakjane perbudhakan karo siji-perbudhakan bakal kelas iki sakjane sampek deweke sampek, ndéwé kuwi wis ana sakjane perusahaan mat ambalo sakjane program. Awakdhéwé éntuk model nambah imitasi nggawe sistem imitasi (Herseyen et al, 1997) lan nganggep nggawe dolanan politik sing berarti segala kejahatan winih sing lembane nggawe barang sistem sing lembane nggawe aksi sing berarti. Gebudhakan langkung nggunakaé diangkat nggawe barang sampeyan urip kuwi nggawe pertualangan tentang kanggo nggawe modèl. Awak dhéwé suggerén akeh barêng-barêng lagi koyo gampang dataset wis disenyongno, nggawe mekanimat sing luwih nggawe sistem sing luwih nêmên karo sistem autoRegresor sing model nang program sing di ambang.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>სიგრძელი და შესაძლებელი ტექსტის შექმნა არის მნიშვნელოვანი და შესაძლებელი რაოდენობა, როგორც გამოსახულება, დოკუმენტის დოკუმენტის მაქსინის გადატყვება და ისტორიის მაგრამ მოდელის შემდგომარების შემდგომარეობაში, სხვა დრო ტექსტის შემდგომარების მოდელები (მაგალითად, BART და GPT-3) მუშაობის შემდგომარების შემდგომარების შემდგომარებისთვის მუშ ჩვენ ვფიქრობთ, რომ ეს არის მოდელის რედაქტირება, შეცვლა, გამოცვლა ან წაშლა ყველა ნაწილი, რომელიც მოდელის შექმნა. ამ დოკუმენტში ჩვენ აჩვენებთ პრომენტის ნახევატორეგრესიური დოკუმენტის შექმნა მოდელის რედაქტირება და რედაქტირება. (Gu et al., 2019; Xu და Carpuat, 2020) ჩვენ მივიღეთ დოკუმენტის შექმნა როგორც იერაქტიკური მარковის გადაწყვეტილების პროცესი, რომელიც ორი დონის იერაქტია, სადაც მაღალი და მაღალი დონის რედაქტირების პ ჩვენ ჩვენი მოდელს იმიტაციის სწავლების გამოყენებით (Hussein et al., 2017) და შევცვალოთ პოლიტიკაში, როგორც ყოველ პოლიტიკაში ისწავლის წინა მომხმარების გამოყენება. პრობლემენტების გამოყენება პრობლემენტების განსაზღვრებით განსხვავებული მონაცემების შესახებ ჩვენი მოდელის გამოყენება. ჩვენ შეგიძლიათ განსხვავებული სხვადასხვა სხვადასხვა სხვადასხვა სხვადასხვა სხვადასხვა სხვადასხვა სხვადასხვა მონაცემების გამოყენება, სხვადასხვა სხვადასხვა მონაცე</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Уақыт және тәуелсіз мәтін құру - маңызды және бұл көп қолданбалар аумақтарын, құжаттың деңгейіндегі машинаның аударуы және оқиғаны құру үшін бірнеше қолданба Интернет сөздердің теңдеу моделінің сәттілігіне қарамастан, барлық ұзын мәтін құру үлгілері (мысалы, BART және GPT- 3) жасалған мәтін бойынша теңдеу үшін әлі көмектеседі. Біз үлгісін қайта қарау, алмастыру, қайта алып тастау немесе өшіру үшін бұл үлгісінің қиындығының себебі деп ойлаймыз. Бұл қағазда, жарты авторегрессивні құжатты құру үлгісін көрсетедік, құрылған мәтінді қайта қарау және өзгерту мүмкіндігі болатын. Жуырдағы моделдерге (Gu et al., 2019; Xu және Carpuat, 2020) құжатты құру процесі ретінде екі деңгейіндегі иерархиясы бар, онда жоғары және төмен деңгейіндегі өңдеу бағдарламалары болып, құжатты құру процесі ретін Біз моделімізді түрлендіру үйренімізді (Hussein et al., 2017) қолданып, әрбір ережелер алдыңғы әрекетті қолдану үшін үйренетін саясаттарды келтіреміз. Келтірілген тәжірибені қолдану тәжірибелері үлгі мәтінді құру мәселелерін өзгертеді. Біз бөлек деректер жиынын қолдану, артықшылық механизмтерді құру және авторегрессиялық үлгілерді төмен деңгейіндегі бағдарлама ретінде авторегрессиялық моделдерді қолдану үші</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>성장하고 일관된 텍스트는 중요하고 도전적인 임무로 요약, 문서급 기계 번역과 이야기 생성 등 많은 응용 분야와 관련된다.문장 내 연관 모델링에 성공했지만 기존의 긴 텍스트 생성 모델(예를 들어 BART와 GPT-3)은 생성된 텍스트에서 일관된 이벤트 서열을 유지하기 어렵다.우리는 이것이 모델이 생성한 모든 부분을 수정, 교체, 취소하거나 삭제하기 어려웠기 때문이라고 추측한다.본고에서 우리는 새로운 반자귀환 문서 생성 모델을 제시하여 생성된 텍스트를 수정하고 편집할 수 있다.최근의 모델(Gu 등, 2019년, Xu와 Carpuat, 2020년)을 바탕으로 우리는 문서 생성은 두 가지 차원 구조를 가진 차원 마르코프 결정 과정으로 그 중에서 고급과 저급 편집 프로그램이라고 주장했다.우리는 모방 학습(Hussein et al., 2017)을 사용하여 우리의 모델을 훈련시키고 모든 전략이 이전 동작의 출력을 학습할 수 있도록 스크롤 전략을 도입한다.본고가 제시한 방법을 응용하여 진행한 실험은 우리의 모델을 이용하여 성장하는 텍스트 문제에 대한 여러 가지 견해를 제시했다.우리는 추출한 데이터 집합을 사용하고 더 좋은 주의 메커니즘을 설계하며 자귀환 모델을 저급 프로그램으로 사용하는 등 각종 보완 조치를 제시했다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ilgo ir nuoseklaus teksto kūrimas yra svarbi ir sunki užduotis, apimanti daugelį taikymo sričių, pavyzdžiui, santrauką, dokumentų lygio vertimą mašinomis ir istorijų kūrimą. Nepaisant sėkmės modeliuojant nuoseklumą tarp sakinių, esami ilgų tekstų kūrimo modeliai (pvz., BART ir GPT-3) vis dar stengiasi išlaikyti nuoseklią renginių seką viso parengto teksto metu. Mes darome prielaidą, kad tai yra dėl sunkumų modeliui peržiūrėti, pakeisti, atšaukti ar išbraukti bet kurią modelio sukurtą dalį. Šiame dokumente pristatome naują pusiau autoregresinį dokumentų kūrimo model į, galintį peržiūrėti ir redaguoti sukauptą tekstą. Remdamiesi naujausiais modeliais (Gu et al., 2019; Xu ir Carpuat, 2020 m.), siūlome dokumentų kūrimą kaip hierarchinį Markovo sprendimų priėmimo procesą su dviejų lygių hierarchija, kurioje rengiamos aukšto ir žemo lygio redakcijos programos. Mokome savo model į imituojant mokymąsi (Hussein et al., 2017 m.) ir įgyvendiname įtraukimo politiką, kad kiekviena politika pasimokytų iš ankstesnių veiksmų taikymo rezultatų. Siūlomo požiūrio taikymo eksperimentai rodo įvairias žinias apie ilgos tekstų kūrimo problemas naudojant mūsų model į. Siūlome įvairias taisomąsias priemones, pavyzdžiui, naudoti distiliuotus duomenų rinkinius, kurti geresnius dėmesio mechanizmus ir kaip mažo lygio program ą naudoti autoregresinius modelius.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Генерирањето долг и коеорентен текст е важна и предизвикувачка задача која вклучува многу области на апликациите како што се резултатите, машинскиот превод на ниво на документи и генерацијата на приказни. И покрај успехот во моделирањето на внатрешната кохеренција на речениците, постојните модели на долга генерација на текст (на пример, BART и GPT-3) сé уште се борат за одржување на кохерентна секвенца на настани низ целиот генериран текст. Претпоставуваме дека ова е поради тешкотијата на моделот да го ревидира, замени, повлече или избрише било кој дел кој е генериран од моделот. Во овој весник, претставуваме нов полуавторегресивен модел за генерација на документи способен да го ревидира и уредува генерираниот текст. Поради неодамнешните модели од (Гу и други, 2019; Ху и Карпуат, 2020) предложуваме генерација на документи како хиерархичен процес на одлука на Марков со хиерархија на две нивоа, каде што програмите за уредување на високо и ниско ниво. Ние го обучуваме нашиот модел користејќи имитациско учење (Хусеин и други, 2017) и воведуваме политика за вложување, така што секоја политика ќе научи за резултатот на апликацијата на претходната акција. Експериментите кои го применуваат предложениот пристап даваат различни информации за проблемите на долгата генерација на текст користејќи го нашиот модел. Предлагаме различни лекови, како што е употребата на дестилирани податоци, дизајнирањето подобри механизми на внимание и употребата на авторегресивни модели како програма на ниско ниво.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ഒരുപാട് പ്രയോഗത്തിന്റെ പ്രദേശങ്ങളെ ചുരുക്കം ചെയ്യുന്ന ഒരു പ്രധാനപ്പെട്ട പ്രയോഗത്തിന്റെ പ്രദേശങ്ങള്‍ക്കുള്ള പ്രധാ നിലവിലുള്ള ടെക്സ്റ്റ് തലമുറന്ന മോഡലുകള്‍ (ഉദാ. BART, GPT-3) നിലവിലുള്ള ഒരു സഹജമായ സംഭവത്തിന്റെ സംവിധാനത്തില്‍ സൂക്ഷിക്കുന്നതിനായി പ്രശ മോഡല്‍ ഉണ്ടാക്കിയ ഏതെങ്കിലും ഭാഗം മാറ്റുവാന്‍, പകര്‍ത്തുവാന്‍, വീണ്ടും മാറ്റുക അല്ലെങ്കില്‍ നീക്കം ചെയ്യാന്‍ മാതൃകയുടെ ഈ പത്രത്തില്‍, നമ്മള്‍ ഒരു നോവല്‍ സ്വയമായി രേഖയില്‍ നിര്‍മ്മിക്കുന്ന രേഖയുടെ നിര്‍മ്മാണം മോഡല്‍ നിര്‍മ്മിക്കുന്ന അടുത്തിടെ മോഡലുകളില്‍ നിര്‍മ്മിക്കുന്നത് (Gu et al., 2019; Xu and Carpuat, 2020) ഞങ്ങള്‍ രേഖയുടെ തലമുറയില്‍ നിന്നും രണ്ടു നില മാര്‍ക്കോവിന്റെ തീരുമാന പ്രക്രിയയായി പ ഞങ്ങള്‍ നമ്മുടെ മോഡല്‍ പരിശീലിപ്പിക്കുന്നു. മുമ്പ് പ്രവര്‍ത്തിപ്പിക്കുന്നതിന്‍റെ ഫലം പ്രയോഗിക്കുന്നതിനെപ്പറ്റി എല്ലാ പോളിസി നീണ്ട ട ടെക്സ്റ്റ് തലമുറതലമുറയുടെ പ്രശ്നങ്ങളെക്കുറിച്ച് പ്രായശ്ചിത്തമായ പരീക്ഷണങ്ങള്‍ നമ്മുടെ മോ We suggest various remedies such as using distilled dataset, designing better attention mechanisms and using autoregressive models as a low level program.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Урт, нийгмийн текст бий болгох нь чухал, шаардлагатай ажиллагаа, олон програм хэсгийг тодруулах, баримтын түвшинд машин орчуулах, түүх бий болгох мэт олон хэсгийг тодруулдаг. Интро-өгүүлбэр хоорондоо холбогдолтой модель хийх амжилтыг хүртэл, урт текст үеийн загвар (жишээ нь BART болон GPT-3) үүсгэсэн текст дээр холбогдолтой үйл явдлын дарааллыг хадгалахын тулд тэмцдэг. Бид үүнийг загварын шинэчлэх, орлуулах, сэргээх, эсвэл устгах хэцүү хэсгийг загвараар бүтээсэн хэцүү хэсгийг шинэчлэхэд хэцүү гэж боддог. Энэ цаасан дээр бид бүтээгдэхүүнийг шинэчлэх, өөрчлөх боломжтой, шинэчлэх зохиолын загварыг шинэчлэх, өөрчлөх боломжтой шинэ санааг автоматжуулж байна. Сүүлийн үеийн загварууд дээр (Gu et al., 2019; Xu, Carpuat, 2020) бид баримт бичлэг бүтээхийг 2 түвшинд шийдвэр гаргах процесс болгож, хамгийн өндөр, бага түвшинд зохион бүтээх програм гэж санал болгож байна. Бид загварын загварыг хуурамжлах сургалтыг ашиглан (Хуссейн et al., 2017) суралцаж, өмнөх үйл явдлыг хэрэгжүүлэх үйл явдлыг суралцаж байгаа төлөвлөгөө хийдэг. Өмнөх арга барилгыг ашиглах туршилтууд бидний загварыг ашиглан урт текст үеийн асуудлуудын тухай олон ойлголт өгдөг. Бид өөр өөр төрлийн шинэчлэлүүдийг санал болгож, сайн анхаарал төвлөрүүлэх механизм, авторегрессийн загваруудыг бага түвшин програм болгон ашиглана.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Generating long and coherent text is an important and challenging task encompassing many application areas such as summarization, document level machine translation and story generation. Walaupun berjaya dalam memmodelkan kesehatan dalam kalimat, model generasi teks panjang yang ada (cth., BART dan GPT-3) masih berjuang untuk menjaga urutan peristiwa yang konsisten sepanjang teks yang dijana. Kami menduga bahawa ini adalah kerana kesulitan bagi model untuk mengubah, menggantikan, membatalkan atau padam sebarang bahagian yang telah dijana oleh model. Dalam kertas ini, kami memperkenalkan model generasi dokumen setengah-autoregresif yang mampu mengubah dan edit teks yang dijana. Membangun pada model baru-baru ini oleh (Gu et al., 2019; Xu dan Carpuat, 2020) kami cadangkan generasi dokumen sebagai proses keputusan Markov hierarkik dengan hierarki dua tahap, di mana program penyuntingan tahap tinggi dan rendah. We train our model using imitation learning (Hussein et al., 2017) and introduce roll-in policy such that each policy learns on the output of applying the previous action. Eksperimen yang melaksanakan pendekatan yang diusulkan membuang berbagai pandangan mengenai masalah generasi teks panjang menggunakan model kami. Kami cadangkan berbagai ubat-ubatan seperti menggunakan set data berwarna, merancang mekanisme perhatian yang lebih baik dan menggunakan model autoregresif sebagai program tahap rendah.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Il-ġenerazzjoni ta’ test twil u koerenti hija kompitu importanti u ta’ sfida li jinkludi ħafna oqsma ta’ applikazzjoni bħas-sommarju, it-traduzzjoni tal-magni fil-livell tad-dokumenti u l-ġenerazzjoni tal-istoriji. Minkejja s-suċċess fl-immudellar tal-koerenza bejn is-sentenzi, il-mudelli e żistenti tal-ġenerazzjoni tat-testi twal (pereżempju, il-BART u l-GPT-3) g ħadhom qed jaħdmu biex iżommu sekwenza koerenti ta’ avvenimenti fit-test ġenerat kollu. Aħna nżuru li dan huwa minħabba d-diffikultà għall-mudell biex jirrevedi, jissostitwixxi, jirrevoka jew iħassar kwalunkwe parti li ġiet iġġenerata mill-mudell. In this paper, we present a novel semi-autoregressive document generation model capable of revising and editing the generated text. Filwaqt li nibnu fuq mudelli reċenti minn (Gu et al., 2019; Xu u Carpuat, 2020) nipproponu l-ġenerazzjoni tad-dokumenti bħal a proċess ta’ deċiżjoni ġerarkiku Markov b’ġerarkija ta’ żewġ livelli, fejn il-programmi ta’ edizzjoni ta’ livell għoli u baxx. Aħna nħarrġu l-mudell tagħna bl-użu tat-tagħlim tal-imitazzjoni (Hussein et al., 2017) u nintroduċu politika ta’ introduzzjoni b’tali mod li kull politika titgħallem dwar ir-riżultati tal-applikazzjoni tal-azzjoni preċedenti. L-esperimenti li japplikaw l-approċċ propost jagħtu diversi fehmiet dwar il-problemi tal-ġenerazzjoni ta’ testi twal bl-użu tal-mudell tagħna. Aħna ssuġġerixxu diversi rimedji bħall-użu ta’ sett ta’ dejta distillat, it-tfassil ta’ mekkaniżmi ta’ attenzjoni a ħjar u l-użu ta’ mudelli awtoregressivi bħala programm ta’ livell baxx.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Het genereren van lange en samenhangende tekst is een belangrijke en uitdagende taak die veel toepassingsgebieden omvat, zoals samenvatting, machinevertaling op documentniveau en verhaaltgeneratie. Ondanks het succes in het modelleren van coherentie binnen de zin, hebben bestaande lange tekstgeneratiemodellen (bijv. BART en GPT-3) nog steeds moeite om een coherente gebeurtenissequentie in de gegenereerde tekst te behouden. We veronderstellen dat dit te wijten is aan de moeilijkheid voor het model om elk onderdeel dat door het model is gegenereerd te herzien, vervangen, intrekken of verwijderen. In dit artikel presenteren we een nieuw semi-autoregressief documentgeneratiemodel dat de gegenereerde tekst kan reviseren en bewerken. Voortbouwend op recente modellen van (Gu et al., 2019; Xu en Carpuat, 2020) stellen we documentgeneratie voor als een hiërarchisch Markov beslissingsproces met een twee niveaus hiërarchie, waarbij het hoge en lage niveau bewerkingsprogramma's programmeert. We trainen ons model met imitatie learning (Hussein et al., 2017) en introduceren roll-in beleid zodanig dat elk beleid leert over de output van de toepassing van de vorige actie. Experimenten die de voorgestelde aanpak toepassen, geven verschillende inzichten over de problemen van lange tekstgeneratie met behulp van ons model. We stellen verschillende remedies voor, zoals het gebruik van gedestilleerde dataset, het ontwerpen van betere aandachtsmechanismen en het gebruik van autoregressieve modellen als een laag niveau programma.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Oppretting av lange og koherent tekst er ein viktig og vanskeleg oppgåve som omsluttar mange program-område som samansering, omsetjing av maskinen til dokumentnivå og storleik. Til tross suksess i modellen av samsvar med innsetningar, står det lange tekstgenereringsmodeller (f.eks. BART og GPT-3) fortsatt i bruk til å halda e in samsvarande hendingskombinasjon gjennom den genererte teksten. Vi gjer at dette er på grunn av vanskeligheta for modellen å gjenoppretta, erstatta, tilbakekalla eller sletta alle deler som er laga av modellen. I denne papiret viser vi eit roman semi- autoregressiv dokumentlagmodell som kan gjere om og redigere den genererte teksten. Byggjer vi på nyleg modeller av (Gu et al., 2019; Xu og Carpuat, 2020) vi fører til å laga dokument som eit hierarkisk Markov beslutningsprosess med to nivåhierarki, der høg og låg nivåredigeringsprogram. Vi treng modellen vårt ved å lære imitasjonar (Hussein et al., 2017) og introdusere rolleringspolitikk slik at kvar politikk lærer på utdata av å bruka førre handlinga. Eksperimentar som brukar den foreslåde tilnærminga gjer ulike innsyningar om problema med lang tekstgenerering med modellen vår. Vi foreslår forskjellige rettingar som å bruka destilerte datasett, utforma betre oppmerksmekanisme og bruka autoregressive modeller som eit låg nivåprogram.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Generowanie długiego i spójnego tekstu jest ważnym i wymagającym zadaniem obejmującym wiele obszarów zastosowań, takich jak podsumowanie, tłumaczenie maszynowe na poziomie dokumentów i generowanie historii. Pomimo sukcesu w modelowaniu spójności wewnątrz zdań istniejące długie modele generowania tekstu (np. BART i GPT-3) nadal trudno utrzymać spójną sekwencję zdarzeń w całym wygenerowanym tekście. Domyślamy się, że jest to z powodu trudności dla modelu w zmianie, zastąpieniu, cofnięciu lub usunięciu dowolnej części, która została wygenerowana przez model. W niniejszym artykule przedstawiamy nowatorski model generowania półautoresywnego dokumentu zdolny do rewizji i edycji wygenerowanego tekstu. Opierając się na najnowszych modelach (Gu et al., 2019; Xu i Carpuat, 2020) proponujemy generowanie dokumentów jako hierarchiczny proces decyzji Markova z dwupoziomową hierarchią, gdzie programy edycji wysokiego i niskiego poziomu. Szkolimy nasz model przy użyciu imitacji uczenia się (Hussein et al., 2017) i wprowadzamy politykę roll-in tak, aby każda polityka uczyła się na wynikach zastosowania poprzedniego działania. Eksperymenty stosujące proponowane podejście dają różne spostrzeżenia na problemy generowania długiego tekstu przy użyciu naszego modelu. Proponujemy różne środki zaradcze, takie jak wykorzystanie destylowanego zbioru danych, projektowanie lepszych mechanizmów uwagi i wykorzystanie modeli autoregresywnych jako programu niskiego poziomu.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A geração de texto longo e coerente é uma tarefa importante e desafiadora que abrange muitas áreas de aplicação, como sumarização, tradução automática em nível de documento e geração de histórias. Apesar do sucesso na modelagem da coerência intra-frase, os modelos de geração de texto longo existentes (por exemplo, BART e GPT-3) ainda lutam para manter uma sequência de eventos coerente em todo o texto gerado. Conjecturamos que isso se deve à dificuldade do modelo em revisar, substituir, revogar ou excluir qualquer parte que tenha sido gerada pelo modelo. Neste artigo, apresentamos um novo modelo de geração de documentos semiautoregressivo capaz de revisar e editar o texto gerado. Com base em modelos recentes de (Gu et al., 2019; Xu e Carpuat, 2020) propomos a geração de documentos como um processo de decisão Markov hierárquico com uma hierarquia de dois níveis, onde os programas de edição de alto e baixo nível. Treinamos nosso modelo usando aprendizado por imitação (Hussein et al., 2017) e introduzimos a política de roll-in de modo que cada política aprenda com o resultado da aplicação da ação anterior. Experimentos que aplicam a abordagem proposta lançam vários insights sobre os problemas de geração de texto longo usando nosso modelo. Sugerimos vários remédios, como usar conjuntos de dados destilados, projetar melhores mecanismos de atenção e usar modelos autorregressivos como um programa de baixo nível.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Generarea de text lung și coerent este o sarcină importantă și provocatoare care cuprinde multe domenii de aplicare, cum ar fi rezumarea, traducerea automată la nivel de documente și generarea de povești. În ciuda succesului în modelarea coerenței intra-frază, modelele existente de generare a textului lung (de exemplu, BART și GPT-3) încă se luptă pentru a menține o secvență de evenimente coerente pe tot parcursul textului generat. Presupunem că acest lucru se datorează dificultății modelului de a revizui, înlocui, revoca sau șterge orice parte generată de model. În această lucrare, prezentăm un nou model semi-autoregresiv de generare a documentelor capabil să revizuiască și să editeze textul generat. Bazându-ne pe modele recente până la (Gu et al., 2019; Xu și Carpuat, 2020) propunem generarea documentelor ca proces decizional ierarhic Markov cu o ierarhie de două niveluri, unde programele de editare de nivel înalt și jos. Ne pregătim modelul folosind învățarea imitației (Hussein et al., 2017) și introducem politici roll-in astfel încât fiecare politică să învețe rezultatele aplicării acțiunii anterioare. Experimentele care aplică abordarea propusă oferă diverse perspective asupra problemelor generarii de text lung folosind modelul nostru. Vă sugerăm diverse remedii, cum ar fi utilizarea setului de date distilate, proiectarea unor mecanisme mai bune de atenție și utilizarea modelelor autoregresive ca un program de nivel scăzut.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Формирование длинного и целостного текста является важной и сложной задачей, охватывающей многие области применения, такие как обобщение, машинный перевод на уровне документов и генерация историй. Несмотря на успех в моделировании согласованности внутри предложений, существующие модели генерации длинного текста (например, BART и GPT-3) все еще испытывают трудности с поддержанием последовательности последовательности событий по всему сгенерированному тексту. Мы предполагаем, что это связано с трудностями для модели в пересмотре, замене, отзыве или удалении любой части, которая была создана моделью. В данной работе мы представляем новую полуавторегрессивную модель генерации документов, способную пересматривать и редактировать сгенерированный текст. Основываясь на последних моделях (Gu et al., 2019; Xu and Carpuat, 2020), мы предлагаем генерацию документов как иерархический марковский процесс принятия решений с двухуровневой иерархией, где программы редактирования высокого и низкого уровня. Мы обучаем нашу модель, используя обучение подражанию (Hussein et al., 2017), и внедряем политику внедрения, чтобы каждая политика училась на результатах применения предыдущего действия. Эксперименты с применением предложенного подхода проливают различные идеи по проблемам генерации длинного текста с использованием нашей модели. Мы предлагаем различные средства, такие как использование дистиллированного набора данных, разработка механизмов лучшего внимания и использование авторегрессивных моделей в качестве низкоуровневой программы.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ලොකු සහ සම්බන්ධ පාළුව නිර්මාණය වැදගත් වැදගත් වැදගත් වැදගත් වැදගත් වැදගත් වැදගත් වැදගත් වැඩසටහන් වලින් ව සාමාන්‍ය වාක්ය සංවිධානයක් නිර්මාණය කරලා තියෙන්නේ සාමාන්‍ය විශ්වාස කරලා තියෙන්නේ ලොකු පාළ ප්‍රමාණය (උදාහරණය, BART සහ GPT-3) තාම අපි හිතන්නේ මේක නිර්මාණය වෙනස් කරන්න, ප්‍රතිස්ථාපනය කරන්න, ප්‍රතිස්ථාපනය කරන්න, ප්‍රතිස්ථාපනය කරන්න, ප්‍රතිස්ථ මේ පැත්තට, අපි නිර්මාණය කරපු පාළුවට පරික්ෂා සහ ස්වයංක්‍රියාත්මක විස්තර කරන්න පුළුවන් නිර්මාණය සහ ස (Gu et al., 2019; Xu and Carpuat, 2020යි) අපි ලිපිණිපත් විශාල විශාල විශාල විශාලයක් විදියට පරීක්ෂණය කරනවා මාර්කොව් තීර්ණාපත්ති පරීක්ෂණයක් දෙ අපි අපේ මොඩල් එක ප්‍රයෝජනය කරනවා ප්‍රයෝජනය ඉගෙන ගන්න පුළුවන් විදිහට (හුසේන් ට් ල්., 2017) සහ ප්‍රයෝජනය ප්‍රයෝජනය කරනවා වග පරීක්ෂණය සඳහා ප්‍රවේශනය කරන්න පුළුවන් ප්‍රශ්නයක් අපේ මොඩල් භාවිතා කරන්න පුළුවන් ලොකු පාළුවේ අපි ප්‍රශ්නයක් කරනවා විවිධ ප්‍රශ්නයක් වගේම විශේෂ දත්ත සෙට් වියුතුයි, හොඳ අවධානය සැකසුම් සැකසුම් වි</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ustvarjanje dolgega in koherentnega besedila je pomembna in zahtevna naloga, ki zajema številna področja uporabe, kot so povzetek, strojno prevajanje dokumentov in ustvarjanje zgodb. Kljub uspehu pri modeliranju koherence znotraj stavka obstoječi modeli dolge generacije besedila (npr. BART in GPT-3) še vedno težko ohranjajo skladno zaporedje dogodkov v celotnem ustvarjenem besedilu. Domnevamo, da je to zaradi težav, ki jih model ustvari, spremeni, prekliče ali izbriše. V prispevku predstavljamo nov pol-avtoregresivni model generiranja dokumentov, ki lahko revidira in ureja ustvarjeno besedilo. Na podlagi novejših modelov (Gu et al., 2019; Xu in Carpuat, 2020) predlagamo ustvarjanje dokumentov kot hierarhični Markov proces odločanja z dvostopenjsko hierarhijo, kjer so programi urejanja na visoki in nizki ravni. Naš model usposabljamo z uporabo imitacijskega učenja (Hussein et al., 2017) in uvajamo politiko roll-in, tako da se vsaka politika nauči o rezultatih uporabe prejšnjega ukrepa. Eksperimenti, ki uporabljajo predlagani pristop, dajejo različne vpoglede na probleme dolge oblikovanje besedila z uporabo našega modela. Predlagamo različna sredstva, kot so uporaba destiliranega nabora podatkov, oblikovanje boljših mehanizmov pozornosti in uporaba avtoregresivnih modelov kot nizko raven programa.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Muujinta qoraal dhaadheer iyo isku xiran waa shaqa muhiim ah oo dhibaato leh oo ku wareegsan meelo badan oo codsiga, sida summarinta, turjumidda qoraalka heerka ee muusikada iyo farshaha sheekooyinka. Inkastoo liibaanshaha sameynta halqabsiga interna-sentence, waxaa jira modello dhaadheer oo dhaadheer qoraal ah (tusaale. BART iyo GPT-3) weli waxay u dagaalamayaan inay ilaaliyaan muuqashada isku xiran dhacdooyinka dhashay oo dhan. Waxaynu malaynaynaa in taasi sababtoo ah dhibaatada tusaaleyda ay ku adag tahay in ay ku cusboonayso, beddelo, beddelo ama deleto qeyb kasta oo sameynta sameeyay. Qoraalkan waxaynu ku soo qoraynaa qoraal saxda ah oo u eg qoraal dhaqan ah oo u awoodi kara inuu ka baaraandegiso iyo tahriri karo qoraalka la sameeyay. Dhisidno modello ugu dambeysan (Gu et al., 2019; Xu iyo Carpuat, 2020) waxaynu u soo jeedaynaa sameynta dukumentiga sida go'aanka hierarchical Markov oo leh laba heer hierarchy, halkaas oo ah barnaamijyada hagitaanka heerka sare iyo hoose. Tusaale ahaan waxaynu ku tababarinnaa waxbarashada takhasuska (Hussein et al., 2017) waxaana soo bandhijinaynaa siyaasada qoraalka qoraalka, kaas oo ah in siyaasad kastaa uu ka baranayo dhamaanka codsashada falimaha hore. Imtixaanka lagu sameeyo qaababka la soo jeeday wuxuu muujiyaa aragtida kala duduwan dhibaatooyinka qarniga qoraalka dheer ee isticmaalka modellkayaga. We suggest various remedies such as using distilled dataset, designing better attention mechanisms and using autoregressive models as a low level program.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Gjenerimi i tekstit të gjatë dhe koherent është një detyrë e rëndësishme dhe sfiduese që përfshin shumë fusha aplikimi të tilla si përmbledhje, përkthimi i makinave në nivel të dokumentit dhe gjenerimi i historive. Pavarësisht nga suksesi në modelimin e koherencës brenda fjalëve, modelet ekzistuese të gjata të gjenerimit të tekstit (për shembull, BART dhe GPT-3) ende luftojnë për të mbajtur një sekuencë koherente ngjarjesh gjatë gjithë tekstit të gjeneruar. Ne supozojmë se kjo është për shkak të vështirësisë për modelin për të revizuar, zëvendësuar, revokuar apo eleminuar çdo pjesë që është gjeneruar nga modeli. Në këtë letër, ne paraqesim një model të ri gjysmë-autoregresiv të gjenerimit të dokumenteve të aftë për të revizuar dhe edituar tekstin e gjeneruar. Duke u ndërtuar në modelet e fundit nga (Gu et al., 2019; Xu dhe Carpuat, 2020) ne propozojmë gjenerimin e dokumenteve si një proces vendimi hierarkik Markov me një hierarki dy niveli, ku programet e ndryshimit të nivelit të lartë dhe të ulët. Ne trajnojmë model in tonë duke përdorur imitimin e mësimit (Hussein et al., 2017) dhe futim politikë të vendosur në mënyrë që çdo politikë të mësojë mbi rezultatin e zbatimit të veprimit të mëparshëm. Eksperimentet që zbatojnë qasjen e propozuar hedhin kuptime të ndryshme mbi problemet e gjenerimit të gjatë të tekstit duke përdorur modelin tonë. Ne sugjerojmë mjete të ndryshme të tilla si përdorimi i grupit të dhënash distilluar, dizajnimi i mekanizmave më të mirë të vëmendjes dhe përdorimi i modeleve autoregressive si një program të nivelit të ulët.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Napravljanje dugog i saslušnog teksta je važan i izazovni zadatak koji uključuje mnoge oblasti aplikacije poput sažetanja, prevoda stroja na nivou dokumenta i generacije priče. Uprkos uspjehu u modeliranju koherencije unutar rečenice, postojeći modeli dugog teksta generacije (npr. BART i GPT-3) i dalje se bore za održavanje koherentne sekvence događaja kroz proizvođeni tekst. Pretpostavljamo da je to zbog teškoće modela da pregleda, zameni, ukloni ili izbriše bilo koji deo koji je stvoren modelom. U ovom papiru predstavljamo nov model generacije polu-autoregresivnog dokumenta sposoban za reviziju i editaciju proizvedenog teksta. Na osnovu nedavnih modela (Gu et al., 2019; Xu i Carpuat, 2020) predlažemo generaciju dokumenta kao hijerarhički proces odluke Markov a sa hijerarhijom dva nivoa, gde su programi za editiranje visokog i niskog nivoa. Mi treniramo svoj model koristeći učenje imitacije (Hussein et al., 2017) i predstavljamo politiku koja se uključuje kako svaka politika uči o izlazu primjene prethodne akcije. Eksperimenti koji primjenjuju predloženi pristup imaju različite uvjete o problemima duge generacije teksta koristeći naš model. Predlažemo raznim sredstvima za opremu poput korištenja destiliranog seta podataka, dizajniranja boljih mehanizma pažnje i korištenja autoregresivnih modela kao program niskog nivoa.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Att generera lång och sammanhängande text är en viktig och utmanande uppgift som omfattar många tillämpningsområden såsom sammanfattning, maskinöversättning på dokumentnivå och historiegenerering. Trots framgångarna med modellering av samstämmighet mellan meningar kämpar befintliga modeller för lång textgenerering (t.ex. BART och GPT-3) fortfarande för att upprätthålla en sammanhängande händelsesekvens i hela den genererade texten. Vi antar att detta beror på att modellen har svårt att revidera, ersätta, återkalla eller ta bort någon del som genererats av modellen. I denna uppsats presenterar vi en ny semi-autoregressiv dokumentgenerationsmodell som kan revidera och redigera den genererade texten. Baserat på de senaste modellerna från (Gu et al., 2019; Xu och Carpuat, 2020) föreslår vi dokumentgenerering som en hierarkisk Markov beslutsprocess med två nivåer hierarki, där hög och låg nivå redigeringsprogram. Vi tränar vår modell med hjälp av imitationsinlärning (Hussein m.fl., 2017) och introducerar roll-in-policy så att varje policy lär sig resultatet av att tillämpa den tidigare åtgärden. Experiment med tillämpning av det föreslagna tillvägagångssättet ger olika insikter om problemen med lång textgenerering med hjälp av vår modell. Vi föreslår olika botemedel såsom att använda destillerad dataset, utforma bättre uppmärksamhetsmekanismer och använda autoregressiva modeller som ett lågnivåprogram.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kutengeneza maandishi ya muda mrefu na yenye umuhimu ni jukumu la muhimu na changamoto linalohusu maeneo mengi ya matumizi kama vile muhtasari, tafsiri ya mashine ya nyaraka na kizazi cha habari. Pamoja na mafanikio ya kutengeneza mshikamano wa sentenca, mifano ndefu ya kizazi cha maandishi (kwa mfano, BART na GPT-3) bado wanajitahidi kuendelea kwa mujibu wa tukio la pamoja katika maeneo yote ya maandishi yaliyozaliwa. Tunafikiri kuwa hii ni kwa sababu ya vigumu kwa mtindo wa kurekebisha, kubadilisha, kurudisha au kufuta sehemu yoyote iliyotengenezwa na mtindo. Katika gazeti hili, tunaweka mtandao wa riwaya wa kutengeneza muundo wa nyaraka yenye kudhibiti kujitegemea na uwezo wa kufuatilia na kuhariri ujumbe uliotengenezwa. Kujenga kwenye mifano ya hivi karibuni na (Gu et al., 2019; Xu na Carpuat, 2020) tunapendekeza kizazi cha dokumu kama mchakato wa uamuzi wa Markov wa ngazi mbili, ambapo programu za kuhariri kiwango cha juu na chini za kiwango. Tunamfundisha muundo wetu kwa kutumia kujifunza kwa uchimbaji (Hussein et al., 2017) na kutengeneza sera za ibada kama vile kila sera inajifunza kuhusu matokeo ya kutekeleza hatua zilizopita. Majaribio yanayotumia mbinu zilizopendekezwa yanaonyesha mitazamo mbalimbali kuhusu matatizo ya kizazi chenye maandishi ya ndege kwa kutumia mifano yetu. Tunazipendekeza njia mbalimbali kama vile kutumia seti ya taarifa tofauti, kutengeneza mfumo bora wa kutoa hisia na kutumia mifano ya kujikandamiza kama programu ya chini ya ngazi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>நீண்ட மற்றும் இணைந்த உரையை உருவாக்குதல் ஒரு முக்கியமான மற்றும் சவாலிக்கும் பணியாகும் சுருக்கம், ஆவண நிலை மொழிமாற்றி மற் வெற்றிகரமாக உள்வாக்கி இணைப்பை மாதிரியும் போது, நீண்ட உரை உரை உருவாக்கும் மாதிரிகள் (உதாரணமாக, BART மற்றும் GPT- 3) முழுவதும் உருவாக்கப்பட்ட உரையில மாதிரி உருவாக்கப்பட்ட எந்த பகுதியையும் மாதிரியாக மாற்ற, மாற்ற, மீண்டும், அல்லது நீக்குவதற்கான கடினமாக இது நினைக்கிறது. இந்த காகிதத்தில், நாம் ஒரு புதிய பாதை- தானியங்கி கட்டுப்பாட்டு ஆவணத்தை உருவாக்க முறைமையை கொண்டு வருகிறோம், உருவ சமீபத்தில் உள்ள மாதிரிகளில் (Gu et al., 2019; Xu மற்றும் கார்புவாட், 2020) நாம் ஆவணத்தை உருவாக்குவது ஒரு மேற்பட்ட மார்க்கோவ் தீர்ப்பு செயல்பாட்டில் இரு மட்டத்தின் நாங்கள் எங்கள் மாதிரியை பார்ப்பு கற்றுக்கொள்ள பயிற்சி செய்து முந்தைய செயல்களை பயன்படுத்தும் வெளியீட்டில் ஒவ்வொரு கொள்கைய நீண்ட உரை தலைமுறையின் பிரச்சனைகளை நம் மாதிரியை பயன்படுத்தி முன்னோட்டத்தைக் கொண்டு நீண்ட உரை உருவாக்கு We suggest various remedies such as using distilled dataset, designing better attention mechanisms and using autoregressive models as a low level program.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Uzun we ýerleşikli metin döretmek wajyp we çykyş täblisaň, bellenen uygulamalar meýdançasyny, desktap düzümleri makine terjime we hekaýa döretmäge mejbur edýär. Çözümler birleşmelerini modellendirmek üçin üstünlik gazanyp hem bolan uzun metin döredilmeleri (meselâ, BART we GPT-3) bar we ýene-de üretilen metin içinde kohereket terjimesini saglamak üçin çöpýärler. Biziň pikirimçe nusga görkezilen, üýtgetmek, tertiblemek ýa çykarmak üçin bu nusga üçin kyndygyny çaklaýarys. Bu kagyzda, biz ýarym-otoregressiv sened bejermek üçin janlaşdyrylýan we düzenleyebilir bir romany görkeýäris. Soňky modellere guruldyk (Gu et al., 2019; Xu we Carpuat, 2020) biz sened döredigini iki düýp iýerarhiýasy bilen iki düýp iýerarhiýa bilen, iýokary we düşük düýpüň editleme programleri bilen teklip edip barýarys. Biz nusganymyzy imitaýýa öwrenmegi ulanyp (Hussein et al., 2017) we her politika öňki hereket etmäge öwrenmegi üçin guruldyrys. Öň teklipden gelen ýagdaýyň tapanyşy örän köp metin döredilişiniň kynçylyklaryny nusgasymyzda çykýar. Biz daşary çykan düzümleri ulanmak ýaly düzümleri taýýarlamak, gowy üns meýdançalaryny tassyklamak we awtomatik regressiv nusgalaryny düşük dereje programy ýaly ulanmak teklip edýäris.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>لہروں اور مہربانی پیغام پیدا کرنے کا ایک اہم اور مشکل کام ہے جو بہت سی کاربریوں کے منطقه میں شامل ہوتا ہے جیسے سامنے پیدا کرنا، دفتر لئوی مہینی ترجمہ اور کہانی پیدا کرنا۔ مہربانی کے ساتھ مہربانی کے ساتھ مہربانی کے ساتھ موجود ہونے کے باعث، موجود لگ ٹیکسٹ نسل موڈل (جیسا کہ BART اور GPT-3) یہاں تک بھی پیدا کیا گیا ہے کہ پیدا کیا گیا متن کے درمیان ایک مشکل حادثہ کے سطح حفاظت کرنے کے لئے کوشش کریں ہم خیال کرتے ہیں کہ یہ مدل کی تغییر، بدل، روک یا حذف کرنے کے لئے مشکل ہے جو مدل سے پیدا کیا گیا ہے۔ اس کاغذ میں، ہم نے ایک نئی نصف-autoregressive سند کی نسل مدل پیش کیے جو پیدا کیا گیا ہے اور سمجھنے کے قابل ہے. ہم نے اچھی مدلکوں پر (Gu et al., 2019; Xu اور Carpuat, 2020) دوسری سطح سطح کے ساتھ دو سطح سطح سطح کے مطابق فیصلہ کا پروسس بنایا ہے جہاں اوپر اور نیچے سطح سمجھنے کے پروگراموں کو پیشنهاد کرتے ہیں. ہم نے اپنے مدل کو مثال سیکھنے کے مطابق (Hussein et al., 2017) کی استعمال سے تطالب کرتے ہیں اور اس طرح رول-in پولیس کو معلوم کرتے ہیں جس طرح ہر پولیس پہلے کے کام کے مطابق استعمال کرتا ہے۔ آزمائش کے مطابق پیشنهاد کی تقریبا کے مطابق ہمارے مدل کے مطابق طویل ٹکسٹ نسل کے مشکلوں کے بارے میں مختلف نظر آتا ہے۔ ہم طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح طرح کرتے ہیں جیسے ڈیٹ سٹ استعمال کرتے ہیں، اچھی توجه کے مکانیسم طراحی کرتے ہیں اور اتروگریسٹ موڈل کو کم سطح پروگرام کے طور پر استعمال کرتے ہیں.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>@ info: whatsthis @ info: whatsthis Biz o'ylaymiz, bu model yaratilgan bir qismini o'zgartirish, almashtirish, bekor qilish yoki olib tashlash uchun qiyin sababi. Bu hujjatda, biz yaratilgan matnni oʻzgartirish va tahrirlash imkoniyatini yaratib boʻladigan novel avtomatik raqamli hujjat yaratish modelini koʻrsatimiz. Yaqinda ochilgan modellarda (Gu et al., 2019; Xu va Karpuat, 2020) yaratish uchun, biz hujjat yaratishni ikkita darajadagi hamma darajadagi xabarlarni oʻzgartirish dasturi bilan boshqarishni talab qilamiz. We train our model using imitation learning (Hussein et al., 2017) and introduce roll-in policy such that each policy learns on the output of applying the previous action. Taʼminlovchi usulni qoʻllash uchun imtiyozlar modelmizni yordamida uzun matn generalining muammolari haqida ko'plab keladi. Biz bir necha muammolar bilan bir xil maʼlumotlar tizimini ishlatish, yaxshi paytlarni yaratish va avto-regressiv modellarni kamaytirish dasturi sifatida foydalanishimizni talab qilamiz.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Phát ra một văn bản dài và đồng bộ là một nhiệm vụ quan trọng và đầy thử thách bao gồm nhiều lĩnh vực ứng dụng như là tóm tắt, dịch thuyết trình bằng văn bản và sản xuất câu chuyện. Mặc dù sự thành công trong việc tạo ra sự đồng bộ hạn tù, các mô hình nền văn bản tồn tại (v.d., BART và GPT-3) vẫn đang đấu tranh để duy trì một chuỗi sự kiện liên quan trong suốt đoạn được tạo ra. Chúng tôi cho rằng đây là vì khó khăn cho mô hình để sửa đổi, thay thế, thu hồi hay xóa bất cứ phần nào tạo ra từ mô hình. Trong tờ giấy này, chúng tôi giới thiệu một mẫu tài liệu bán tự động mới có khả năng sửa và sửa đổi văn bản đã tạo ra. Dựa trên các mô hình gần đây của Cố vấn và địa chỉ bây giờ Chúng tôi đề nghị tạo tài liệu như một tiến trình quyết định kiểu Markov cấp hai, nơi các chương trình soạn thảo cấp cao và cấp thấp. Chúng tôi huấn luyện mô hình bằng việc bắt chước học (Hussein et al., tê 7) và đưa ra một chính sách nào đó để cho mỗi chính sách học về kết quả của việc áp dụng hành động trước. Các thử nghiệm áp dụng phương pháp đã đề xuất đưa ra những nghiên cứu khác nhau về vấn đề sản xuất văn bản lâu dài dựa trên phương pháp. Chúng tôi đề nghị phương pháp trị liệu khác nhau như sử dụng bộ dữ liệu chưng cất, thiết kế các cơ chế chăm sóc tốt hơn và sử dụng các mô hình tự vệ như chương trình cấp thấp.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>生长连贯,本一重挑战性,涵盖众应用领域,摘要、文档机器翻译、故事成。 虽一致性建模成功于句,而长文本生模(如 BART 与 GPT-3),难以贯序。 臣测其模形难改,代易,省削模样。 于本文中,新过半自归文档生成模样,当模能改辑成文本。 近模(Gu等,2019。 Xu、Carpuat,2020)文档生成两等层次结构分马尔可夫决策之际,高下辑序。 吾以法学习吾形(Hussein et al., 2017),引入滚策,以学先输。 宜用所法实验示用吾模样生长文本诸见。 臣等条上诸补救措施,如用精炼数据集,设意机制及用自归模形为下程。</span></div></div><dl><dt>Anthology ID:</dt><dd>2021.alta-1.13</dd><dt>Volume:</dt><dd><a href=/volumes/2021.alta-1/>Proceedings of the The 19th Annual Workshop of the Australasian Language Technology Association</a></dd><dt>Month:</dt><dd>December</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Online</dd><dt>Venue:</dt><dd><a href=/venues/alta/>ALTA</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Australasian Language Technology Association</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>128–137</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.alta-1.13>https://aclanthology.org/2021.alta-1.13</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">zaidi-etal-2021-document</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Najam Zaidi, Trevor Cohn, and Gholamreza Haffari. 2021. <a href=https://aclanthology.org/2021.alta-1.13>Document Level Hierarchical Transformer</a>. In <i>Proceedings of the The 19th Annual Workshop of the Australasian Language Technology Association</i>, pages 128–137, Online. Australasian Language Technology Association.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2021.alta-1.13>Document Level Hierarchical Transformer</a> (Zaidi et al., ALTA 2021)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2021.alta-1.13.pdf>https://aclanthology.org/2021.alta-1.13.pdf</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2021.alta-1.13.pdf title="Open PDF of 'Document Level Hierarchical Transformer'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Document+Level+Hierarchical+Transformer" title="Search for 'Document Level Hierarchical Transformer' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'Document Level Hierarchical Transformer'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[Document Level Hierarchical Transformer](https://aclanthology.org/2021.alta-1.13) (Zaidi et al., ALTA 2021)</p><ul class=mt-2><li><a href=https://aclanthology.org/2021.alta-1.13>Document Level Hierarchical Transformer</a> (Zaidi et al., ALTA 2021)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Najam Zaidi, Trevor Cohn, and Gholamreza Haffari. 2021. <a href=https://aclanthology.org/2021.alta-1.13>Document Level Hierarchical Transformer</a>. In <i>Proceedings of the The 19th Annual Workshop of the Australasian Language Technology Association</i>, pages 128–137, Online. Australasian Language Technology Association.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>