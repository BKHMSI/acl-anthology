<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>A Proposal : Interactively Learning to Summarise Timelines by Reinforcement Learning - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="A Proposal : Interactively Learning to Summarise Timelines by Reinforcement Learning" name=citation_title><meta content="Yuxuan Ye" name=citation_author><meta content="Edwin Simpson" name=citation_author><meta content="Proceedings of the First Workshop on Interactive Learning for Natural Language Processing" name=citation_conference_title><meta content="2021/8" name=citation_publication_date><meta content="https://aclanthology.org/2021.internlp-1.4.pdf" name=citation_pdf_url><meta content="25" name=citation_firstpage><meta content="31" name=citation_lastpage><meta content="10.18653/v1/2021.internlp-1.4" name=citation_doi><meta property="og:title" content="A Proposal : Interactively Learning to Summarise Timelines by Reinforcement Learning"><meta property="og:image" content="https://aclanthology.org/thumb/2021.internlp-1.4.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2021.internlp-1.4"><meta property="og:description" content="Yuxuan Ye, Edwin Simpson. Proceedings of the First Workshop on Interactive Learning for Natural Language Processing. 2021."><link rel=canonical href=https://aclanthology.org/2021.internlp-1.4></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2021.internlp-1.4.pdf>A Proposal : Interactively Learning to Summarise Timelines by <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>Reinforcement Learning</a></a>
<a id=af_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>'n Voorskou: Interaktiewe leer na opsomming tydline deur versterking leer</a>
<a id=am_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>A Proposal: Interactive Learn to Summary Timelines by Reinforcement Learn</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>اقتراح: التعلم التفاعلي لتلخيص الجداول الزمنية من خلال التعلم المعزز</a>
<a id=az_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Bir t…ôbliΡü: Ο•yr…ônm…ôk Ο•yr…ônm…ôsi il…ô Ο•yr…ônm…ôk</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Предложение: Взаимно обучение за обобщаване на времевите линии чрез засилване на обучението</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>একটি বৈশিষ্ট্য: সামার্মিজের সময়ের শিক্ষা পুনরায় শিক্ষার্থী</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>ང་ཚོས་བྱ་ཚུལ། སྤྱིར་གཏོང་ཚབ་ལྟར་དུས་ཚོད་དང་བསྟུན་ནས་ཕར་རྒྱས་གཏོང་ཐབས་ཤིག་བྱ།</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Prijedlog: Interaktivno učenje za skupljanje vremenskih linija pojačanjem učenja</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Una proposta: Aprendre interactivament a resumir les línies de temps per reforçar l'aprenentatge</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Návrh: Interaktivní učení shrnout časové osy pomocí posilovacího učení</a>
<a id=da_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Et forslag: Interaktivt læring til at opsummere tidslinjer ved at styrke læring</a>
<a id=de_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Ein Vorschlag: Interaktives Lernen, Zeitrahmen durch Reinforcement Learning zusammenzufassen</a>
<a id=el_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Μια πρόταση: Αλληλέγγυα μάθηση να συνοψίζει χρονοδιαγράμματα με την ενίσχυση της μάθησης</a>
<a id=es_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Una propuesta: aprender de forma interactiva a resumir los plazos mediante el aprendizaje por refuerzo</a>
<a id=et_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Ettepanek: Ajakavade kokkuvõtmise vastastikune õppimine õppimise tugevdamise abil</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>یک پیشنهاد: یادگیری با فعالیت برای جمع کردن خطوط زمانی با یادگیری بیشتری</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Ehdotus: Vuorovaikutteinen oppiminen kokoamaan aikajanoja vahvistamalla oppimista</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Une proposition : Apprentissage interactif pour résumer les délais par l'apprentissage par renforcement</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Togra: Foghlaim go hIdirghníomhach chun Amlínte a Achoimriú trí Fhoghlaim Atreisithe</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>KCharselect unicode block name</a>
<a id=he_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>הצעה: ללמוד באופן אינטראקטיבי לסכם את קווי הזמנים</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>एक प्रस्ताव: इंटरैक्टिव रूप से सुदृढीकरण सीखने द्वारा समयरेखा को संक्षेप में प्रस्तुत करने के लिए सीखना</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Prijedlog: Interaktivno učenje prikupljanja vremenskih linija pojačanjem učenja</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Javaslat: Interaktív tanulás az idővonalak összefoglalására a tanulás megerősítésével</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>A Proposal: Interactively Learning to Summarise Timelines by Reinforcement Learning</a>
<a id=id_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Sebuah cadangan: Belajar secara interaktif untuk mempersingkatkan Jadual Waktu Dengan Penolakan Penyukuran</a>
<a id=is_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Una proposta: Imparare interattivamente per riassumere le tempistiche attraverso il rafforzamento dell'apprendimento</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>提案：強化学習によるタイムラインを要約するためのインタラクティブな学習</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Suasal: Tulung gambar Daftar Taani</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>პროცესი: ინტერქექტიური სწავლება თარიღის ხაზების შესაძლებლობით</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Мәлімет: Тұжырымдық уақыт жолдарын күшейту оқыту арқылы интерактивті оқыту</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>건의: 학습 상호작용 강화를 통해 학습 총결산 시간표</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Pasiūlymas: tarpusavyje mokytis apibendrinti mokymosi sustiprinimu tvarkaraščius</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Предлог: Интерактивно учење да ги сумира временските линии со зајакнување на учењето</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>ഒരു പ്രൊഫോസല്‍: വീണ്ടും പഠിപ്പിക്കുന്നതിനാല്‍ കുരുക്കം നേരിടുന്ന സമയത്തിലേക്ക് പഠിക്കുന്നതിനു</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Өдөр дэвшүүлэл: Хүчирхийллийн суралцлагаар нэмэгдүүлэх цаг хугацааны зураг</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>A Proposal: Interactively Learning to Summary Timelines by Reinforcement Learning</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Proposta: Tagħlim Interattiv biex jinġabru fil-qosor il-Linji taż-Żmien bit-Tagħlim tat-Tisħiħ</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Een voorstel: Interactief Leren Tijdlijnen samenvatten door Reinforcement Learning</a>
<a id=no_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Eit førespurnad: Interaktiv læring for samansering av tidslinjer ved å styrke læring</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Wniosek: Interaktywne uczenie się podsumowywania linii czasowych poprzez uczenie się wzmacniające</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Uma Proposta: Aprendizagem Interativa para Resumir Cronogramas por Aprendizagem por Reforço</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>O propunere: Învățarea interactivă pentru a rezuma termenele prin consolidarea învățării</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Предложение: Интерактивное обучение для обобщения временных рамок посредством обучения подкреплению</a>
<a id=si_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>ප්‍රශ්නයක්: සම්බන්ධ වෙලාව සම්බන්ධ වෙලාවට ඉගෙන ගන්න</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Predlog: Interaktivno učenje povzemanja časovnih okvirov z okrepitvijo učenja</a>
<a id=so_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>A Proposal: Interactively Learning to Summary Updates by Reinforcement Learning</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Një propozim: Mësimi interaktiv për të përmbledhur afatet kohore nga forcimi i Mësimit</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Prijedlog: Interaktivno učenje za skupljanje vremenskih linija pojačanjem učenja</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Ett förslag: Interaktivt lärande för att sammanfatta tidslinjer genom förstärkt lärande</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Tamko: Kujifunza kwa njia za muhtasari na Kufundisha Maendeleo</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>ஒரு குணங்கள்:</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Mazmunlar: Öğrenmek üçin Taýratma Hatlary Taýratma Hatlary öwrenmek</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>ایک پیشنهاد: ہمیشہ استعمال کی تعلیم کے ذریعہ تایمیلین کو جمع کرنے کے لئے اثرات سے سیکھنا</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Name</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>Một đề nghị: học tương tác để tổng hợp dòng thời gian bằng cách tăng cường học hành</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2021.internlp-1.4.pdf>建言:交互式学以强化结时间表</a></h2><p class=lead><a href=/people/y/yuxuan-ye/>Yuxuan Ye</a>,
<a href=/people/e/edwin-simpson/>Edwin Simpson</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Timeline Summarisation (TLS) aims to generate a concise, time-ordered list of events described in sources such as <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a>. However, current <a href=https://en.wikipedia.org/wiki/System>systems</a> do not provide an adequate way to adapt to new domains nor to focus on the aspects of interest to a particular user. Therefore, we propose a method for interactively learning abstractive TLS using Reinforcement Learning (RL). We define a compound reward function and use RL to fine-tune an abstractive Multi-document Summarisation (MDS) model, which avoids the need to train using reference summaries. One of the sub-reward functions will be learned interactively from user feedback to ensure the consistency between users&#8217; demands and the generated <a href=https://en.wikipedia.org/wiki/Timeline>timeline</a>. The other sub-reward functions contribute to topical coherence and linguistic fluency. We plan experiments to evaluate whether our approach could generate accurate and precise <a href=https://en.wikipedia.org/wiki/Timeline>timelines</a> tailored for each user.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tydline Opsomming (TLS) doel doen om 'n sameslys, tydporteerde lys van gebeurtenis in bronne beskrywe soos nuusartikels te genereer. Maar huidige stelsels verskaf nie 'n adequate manier om na nuwe domeine te pas nie of om op die aspekte van belang te fokus a an 'n bepaalde gebruiker te verskaf nie. Daarom, ons voorstel 'n metode vir interaktief abstraktiewe TLS te leer met die gebruik van Versterking Leer (RL). Ons definieer 'n komponente vergelde funksie en gebruik RL om 'n abstraktiewe Multi- dokument Opsomming (MDS) model te fin- tune, wat veroorsaak die benodig om te trein met verwysing opsommings te gebruik. Een van die sub- reward funksies sal interaktief leer word van gebruiker terugkeer om die konsistensie tussen gebruikers se vraagte en die genereerde tydline te verseker. Die ander subvergelde funksies bydra tot onderwerp koherens en lingwisiese fluiditeit. Ons plan eksperimente om te evalueer of ons toegang kan spesifieke en presies tydline vir elke gebruiker genereer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>የአሁኑን ፋይል አስቀምጥ ምንም እንኳን፣ የአሁኑ ስርዓቶች አዲስ ዶሜኖችን ለመቀበል እና የተጠቃሚ ተጠቃሚ ጉዳዮችን ለመጠቀም አይጠቅሙም፡፡ ስለዚህም፣ በሥርዓት ትምህርት (RL) የተጠቃሚ ትምህርት (TLS) ለመማር የሚችሉትን ተቃውሞ እናስፈልጋለን፡፡ የዋጋውን ዋጋ ማድረግ እና RL በመጠቀም እናስቀምጣለን፡፡ ጥያቄ ሌሎቹ የዋጋ ደመወዝ ስርዓቶች ለባሕላዊ ስብስብ እና ለቋንቋዊ ውጤት ያጣቅማሉ፡፡ ሁኔታ ለሁሉም ተጠቃሚዎች የተፈጸመ እና የጊዜውን መስመር መፍጠር እንዲችል ተፈተና እናደርጋለን፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>يهدف تلخيص الجدول الزمني (TLS) إلى إنشاء قائمة موجزة ومرتبة زمنيًا للأحداث الموضحة في المصادر مثل المقالات الإخبارية. ومع ذلك ، لا توفر الأنظمة الحالية طريقة مناسبة للتكيف مع المجالات الجديدة ولا للتركيز على الجوانب التي تهم مستخدم معين. لذلك ، نقترح طريقة للتعلم التفاعلي لطبقة النقل الآمنة التجريدية باستخدام التعلم المعزز (RL). نحدد وظيفة المكافأة المركبة ونستخدم RL لضبط نموذج تلخيص متعدد المستندات (MDS) ، والذي يتجنب الحاجة إلى التدريب باستخدام الملخصات المرجعية. سيتم تعلم إحدى وظائف المكافآت الفرعية بشكل تفاعلي من ملاحظات المستخدم لضمان الاتساق بين طلبات المستخدمين والجدول الزمني الذي تم إنشاؤه. تساهم وظائف المكافآت الفرعية الأخرى في التماسك الموضعي والطلاقة اللغوية. نحن نخطط لإجراء تجارب لتقييم ما إذا كان نهجنا يمكن أن يولد جداول زمنية دقيقة ودقيقة مصممة لكل مستخدم.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Zaman səhifəsi Toplaşdırma (TLS) haqqı məktublar kimi məktublar içində tanımlanmış vaxt sıralanmış vaxt listesini yaratmaq istəyir. Halbuki, a ğımdaki sistemlər yeni domenalara uyğunlaşdırmaq üçün yeterli bir yol verməz və ya müəyyən istifadəçilərə maraqlıq aspektlərinə odaqlanmaq üçün. Buna görə də bizim abstraktiv TLS öyrənmək üçün bir metod təklif edirik. Biz birləşdirilmiş mükafat funksiyasını təyin edirik və RL'i abstraktiv Multi-document Summarisation (MDS) modelini təyin etmək üçün istifadə edirik ki, bu dəyişiklik toplamlarını istifadə etməyə ehtiyacı yoxdur. Üstödüllü funksiyalardan biri istifadəçilərin istəkləri və ürəklənmiş vaxt səhifəsi arasında müəyyən edilməsini təsdiqləmək üçün istifadəçilərin reaksiyasından interaktif olaraq öyrənəcəkdir. Diğer dəyişiklik funksiyaları məsələlərin birləşməsinə və dillərin fəaliyyətinə kömək edir. Biz təcrübələrimizin hər istifadəçi üçün müəyyən edilmiş və müəyyən edilmiş vaxt səhifələrini təşkil etmək üçün təcrübələrimizi təşkil edirik.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Целта на обобщението на времевата линия е да генерира кратък, подреден във времето списък на събитията, описани в източници като новинарски статии. Настоящите системи обаче не осигуряват адекватен начин за адаптиране към нови домейни, нито за фокусиране върху аспектите, които представляват интерес за конкретен потребител. Затова предлагаме метод за интерактивно изучаване на абстрактни ТУС с помощта на подсилващо обучение (РС). Определяме комбинирана функция за възнаграждение и използваме за фина настройка на абстрактен модел за обобщаване на множество документи (МДС), което избягва необходимостта от обучение с помощта на справочни резюмета. Една от функциите за подвъзнаграждение ще се научи интерактивно от обратната връзка на потребителите, за да се гарантира съгласуваността между исканията на потребителите и генерирания времеви график. Другите подвъзнаграждение функции допринасят за актуална съгласуваност и езиково владеене. Планираме експерименти, за да оценим дали нашият подход може да генерира точни и точни времеви линии, съобразени с всеки потребител.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>টাইমেলিন সামার্মিস (টিএলএস) এর লক্ষ্য হচ্ছে সংবাদ প্রবন্ধের মতো সংবাদ প্রবন্ধের মতো বর্ণনা করা হয়েছে একটি সূত্র, সময়-নির্দেশি তবে বর্তমান সিস্টেম নতুন ডোমেইনের সাথে মেনে নেওয়ার জন্য যথেষ্ট উপায় প্রদান করে না এবং কোন বিশেষ ব্যবহারকারীর প্রতি আগ্রহের প্রত তাই আমরা প্রস্তাব করি একটি উপায় যাতে প্রতিষ্ঠান শিক্ষা ব্যবহার করে অস্বাভাবিক টিএলএস শিখতে পারি। আমরা একটি কম্পোনেন্ড পুরস্কারের ফাংশন নির্ধারণ করি এবং RL ব্যবহার করি একটি অস্বাভাবিক মাল্টিক ডকুমেন্ট সামার্সিং মডেল (এমডিএস), যা রেফারেন্স সারিম ব্যবহারকারীদের দাবি এবং উৎপাদন করা সময় লাইনের মধ্যে সাবপুরস্কারের একটি ফাংশন সক্রিয় করে ব্যবহারকারীর ফিডব্যাক থেকে শিখা হবে। অন্যান্য সাব-পুরস্কারের ফাংশন বিষয়বস্তুর সাথে এবং ভাষার ভাষার প্রভাবে অবদান করে। আমরা পরীক্ষার পরীক্ষার পরিকল্পনা করছি যাতে আমাদের প্রতিটি ব্যবহারকারীর জন্য সঠিক এবং পরিমাপের সময় লাইন তৈরি করা যায় কিনা।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>དུས་ཡོད་པའི་ཆ་འཕྲིན་འབྲེལ་བ(TLS)ལ་དམིགས་ཡུལ་ནི་འབྱུང་ཁུངས་ནང་གསལ་བཤད་ཀྱི་དུས་ཚོད་ལྟར་བཤད་ཀྱི་ཐོ་ཡིག་སྐྱེལ་བ ཡིན་ནའང་ད་ལྟོའི་མ་ལག་གི་སྤྱོད་མཁན་པ་ཞིག་ལས་དུས་ཡོད་པའི་འཆར་གཞུང་གིས་དུས་མཐུན་གྱི་ཐབས་ལམ་ལ་དང་མཐུན་སྒྲིག དེར་བརྟེན། ང་ཚོས་རྗེས་སུ་འབྱུང་བའི་TLS ལ་ལམ་ལུགས་གཅིག་གི་སྤྲོད་བྱེད་ཀྱི་ཡོད། We define a compound reward function and use RL to fine-tune an abstractive Multi-document Summarisation (MDS) model, which avoids the need to train using reference summaries. Name Sub-reward ལས་ཕན་འབྲས་ཀྱི་ལས་ཀ་གཅིག་ནི་སྤྱོད་མཁན་གྱི་ངོས་ལངས་ཀྱི་ནང་དུ་སྤྱིར་བཏང་བ་དང་གསར་བསྐྲུན་ཡོད་པའི་དུས Sub-reward་གཞན་པ་འདིས་གནད་དོན་དག་གི་མཉམ་སྦྲགས་དང་སྐད་རིགས་ཀྱི་མཚུངས་སྐོར་དང་། ང་ཚོས་ལག་ལེན་པ་རེ་རེ་བ་མི་དང་འགྲོ་བརྟན་པར་མཐུན་འགྲོ་བ་ཡིན་མིན་ན།</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vremenska sažetka (TLS) cilja je da stvori konkretnu, vremenski naređenu listu događaja opisanih u izvorima poput novinskih članaka. Međutim, trenutni sistemi ne pružaju odgovarajući način da se prilagodi novim domenama niti da se fokusiraju na aspekte interesa određenom korisniku. Stoga predlažemo metodu interaktivnog učenja abstraktivnog TLS koristeći učenje pojačanja (RL). Definiramo funkciju nagrade u kombinaciji i koristimo RL kako bi ispravili abstraktivni model rezervacije višestrukih dokumenta (MDS), koji izbjegava potrebu trenirati s referentnim sažetkama. Jedna od funkcija podnagrade bit će učena interaktivno od povratka korisnika kako bi se osigurala konsekvencija između zahtjeva korisnika i proizvedene vremenske linije. Druge podnagrade doprinose temeljnoj saskašnosti i jezičkoj tekućini. Planiramo eksperimente da procijenimo da li bi naš pristup mogao stvoriti tačne i precizne vremenske linije prilagođene svakom korisniku.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>El resum del calendari (TLS) té l'objectiu de generar una llista concisa i ordenada del temps d'esdeveniments descrits en fonts com els articles de notícies. No obstant això, els sistemes actuals no proporcionen una manera adequada d'adaptar-se a nous dominis ni centrar-se en els aspectes d'interès d'un usuari particular. Therefore, we propose a method for interactively learning abstractive TLS using Reinforcement Learning (RL). Defineixem una funció de recompensa compuesta i utilitzem RL per ajustar un model abstracte de Resume Multidocumental (MDS), que evita la necessitat d'entrenar fent servir resumes de referència. Una de les funcions de subrecompensa es aprendrà interactivament a partir del feedback dels usuaris per assegurar la consistencia entre les exigències dels usuaris i la línia de temps generada. Les altres funcions de subrecompensa contribueixen a la coherencia topical i la fluència lingüística. Planem experiments per avaluar si el nostre enfocament podria generar línies de temps exactes i precisas adaptades a cada usuari.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Shrnutí časové osy (TLS) si klade za cíl vytvořit stručný, časově uspořádaný seznam událostí popsaných ve zdrojích, jako jsou například zpravodajské články. Stávající systémy však neposkytují adekvátní způsob, jak se přizpůsobit novým doménám ani jak se zaměřit na aspekty zájmu konkrétního uživatele. Proto navrhujeme metodu interaktivního učení abstraktivního TLS pomocí Reinforcement Learning (RL). Definujeme složenou funkci odměny a používáme RL k jemnému ladění abstraktivního MDS modelu (Multi-Document Sumlarisation), který se vyhýbá nutnosti trénovat pomocí referenčních souhrnů. Jedna z funkcí sub-odměny se interaktivně naučí ze zpětné vazby uživatelů, aby byla zajištěna konzistence mezi požadavky uživatelů a generovanou časovou osou. Další funkce pododměny přispívají k aktuální soudržnosti a jazykové plynulosti. Plánujeme experimenty, abychom vyhodnotili, zda by náš přístup mohl generovat přesné a přesné časové osy přizpůsobené každému uživateli.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Timeline Summarisation (TLS) har til formål at generere en kortfattet, tidsordnet liste over begivenheder beskrevet i kilder såsom nyhedsartikler. De nuværende systemer giver imidlertid ikke en passende måde at tilpasse sig nye områder på eller fokusere på aspekter af interesse for en bestemt bruger. Derfor foreslår vi en metode til interaktivt at lære abstrakt TLS ved hjælp af Reinforcement Learning (RL). Vi definerer en sammensat belønningsfunktion og bruger RL til at finjustere en abstraktiv MDS-model (Multi-Document Summarisation), hvilket undgår behovet for at træne ved hjælp af referenceresuméer. En af subbelønningsfunktionerne vil blive lært interaktivt fra brugerfeedback for at sikre konsistensen mellem brugernes krav og den genererede tidslinje. De øvrige subbelønningsfunktioner bidrager til aktuel sammenhæng og sproglig flydende. Vi planlægger eksperimenter for at vurdere, om vores tilgang kunne generere nøjagtige og præcise tidslinjer skræddersyet til hver bruger.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Timeline Summarisation (TLS) zielt darauf ab, eine kurze, zeitlich geordnete Liste von Ereignissen zu erstellen, die in Quellen wie Nachrichtenartikeln beschrieben werden. Die derzeitigen Systeme bieten jedoch keine adäquate Möglichkeit, sich an neue Domänen anzupassen oder sich auf die Aspekte zu konzentrieren, die für einen bestimmten Benutzer von Interesse sind. Daher schlagen wir eine Methode vor, um abstraktives TLS interaktiv mit Reinforcement Learning (RL) zu lernen. Wir definieren eine zusammengesetzte Belohnungsfunktion und verwenden RL zur Feinabstimmung eines abstraktiven MDS-Modells (Multi-Document Summarisation). Eine der Unterbelohnungsfunktionen wird interaktiv aus Benutzerfeedback gelernt, um die Konsistenz zwischen den Anforderungen der Benutzer und der generierten Zeitleiste zu gewährleisten. Die anderen Sub-Belohnungsfunktionen tragen zur aktuellen Kohärenz und Sprachflüssigkeit bei. Wir planen Experimente, um zu evaluieren, ob unser Ansatz genaue und präzise Zeitpläne generieren kann, die auf jeden Benutzer zugeschnitten sind.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Η Σύνοψη Χρονικής Γραμμής έχει ως στόχο να δημιουργήσει μια συνοπτική λίστα γεγονότων που περιγράφονται σε πηγές όπως άρθρα ειδήσεων. Ωστόσο, τα σημερινά συστήματα δεν παρέχουν επαρκή τρόπο προσαρμογής σε νέους τομείς ούτε εστίασης στις πτυχές που ενδιαφέρουν έναν συγκεκριμένο χρήστη. Ως εκ τούτου, προτείνουμε μια μέθοδο για διαδραστική εκμάθηση αφηρημένου με τη χρήση της Ενίσχυσης Μάθησης (RL). Καθορίζουμε μια σύνθετη συνάρτηση ανταμοιβής και χρησιμοποιούμε για να τελειοποιήσουμε ένα αφηρημένο μοντέλο Περίληψης πολλαπλών εγγράφων (το οποίο αποφεύγει την ανάγκη κατάρτισης χρησιμοποιώντας περιλήψεις αναφοράς. Μια από τις λειτουργίες υποτροφίας θα διδαχθεί αλληλεπιδραστικά από τα σχόλια των χρηστών για να εξασφαλιστεί η συνέπεια μεταξύ των απαιτήσεων των χρηστών και του παραγόμενου χρονοδιαγράμματος. Οι άλλες λειτουργίες υποτιμίας συμβάλλουν στην τοπική συνοχή και γλωσσική ευχέρεια. Σχεδιάζουμε πειράματα για να αξιολογήσουμε αν η προσέγγισή μας θα μπορούσε να δημιουργήσει ακριβή και ακριβή χρονοδιαγράμματα προσαρμοσμένα για κάθε χρήστη.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Timeline Summarisation (TLS) tiene como objetivo generar una lista concisa y ordenada en el tiempo de los eventos descritos en fuentes como artículos de noticias. Sin embargo, los sistemas actuales no proporcionan una forma adecuada de adaptarse a nuevos dominios ni de centrarse en los aspectos de interés para un usuario en particular. Por lo tanto, proponemos un método para el aprendizaje interactivo de TLS abstractivo mediante el aprendizaje por refuerzo (RL). Definimos una función de recompensa compuesta y utilizamos RL para ajustar un modelo abstractivo de resumen de documentos múltiples (MDS), que evita la necesidad de entrenar con resúmenes de referencia. Una de las funciones de sub-recompensa se aprenderá de forma interactiva a partir de los comentarios de los usuarios para garantizar la coherencia entre las demandas de los usuarios y el cronograma generado. Las otras funciones de sub-recompensa contribuyen a la coherencia temática y la fluidez lingüística. Planificamos experimentos para evaluar si nuestro enfoque podría generar plazos precisos y precisos adaptados a cada usuario.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Timeline Summarisation (TLS) eesmärk on luua lühike ja ajaliselt järjestatud nimekiri sündmustest, mida kirjeldatakse allikates, näiteks uudisteartiklites. Praegused süsteemid ei paku siiski piisavat võimalust kohaneda uute valdkondadega ega keskenduda konkreetsele kasutajale huvi pakkuvatele aspektidele. Seetõttu pakume välja meetodi abstraktse TLS interaktiivseks õppimiseks tugevdusõppe abil. Määratleme komplektfunktsiooni ja kasutame RL-i abstraktse mitme dokumendi kokkuvõtte (MDS) mudeli täpsustamiseks, mis väldib vajadust treenida viitekokkuvõtete abil. Ühte allpreemiafunktsiooni õpitakse interaktiivselt kasutajate tagasisidest, et tagada kasutajate nõudmiste ja loodud ajakava vaheline sidusus. Teised allpreemiafunktsioonid aitavad kaasa aktuaalsele sidususele ja keelelisele sujuvusele. Kavandame katseid, et hinnata, kas meie lähenemisviis suudab luua täpseid ja täpseid ajajooni, mis on kohandatud iga kasutaja jaoks.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>جمع کردن خط زمانی (TLS) هدف می‌گیرد که یک فهرست دقیق، سفارشی زمانی از اتفاقات توصیف شده در منابع مانند مقاله‌های خبری را ایجاد کند. ولی سیستم‌های فعلی راهی مناسب برای adapting to new domains و برای تمرکز روی نقطه‌های علاقه به یک کاربر خاص نمی‌دهند. بنابراین، ما یک روش برای یادگیری TLS abstractive با استفاده از یادگیری افزایش (RL) را پیشنهاد می‌کنیم. ما یک عملکرد پاداش متصل را تعریف می‌کنیم و از RL استفاده می‌کنیم تا یک مدل جمع‌آوری Multi-Document (MDS) را پاداش دهیم که از نیازی استفاده از جمع‌آوری‌های متصل آموزش فرار می‌کند. یکی از عملکرد‌های زیر پاداش از بازگشت کاربر به طور متفاوتی یاد می‌گیرد تا مطمئن شود که هماهنگی بین درخواست‌های کاربر و خط زمانی تولید شده است. کارهای زیر پاداش دیگر به هماهنگی و فعالیت زبان کمک می کنند. ما برنامه‌های آزمایشات را برای ارزیابی که آیا دستور ما می‌تواند خط زمان دقیق و دقیق را برای هر کاربر تغییر داده شود.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Timeline Summarisation (TLS) tavoitteena on luoda tiivis, ajoitettu luettelo tapahtumista, joita kuvataan lähteissä, kuten uutisartikkeleissa. Nykyiset järjestelmät eivät kuitenkaan tarjoa riittävää tapaa sopeutua uusiin toimialoihin eivätkä keskittyä tiettyä käyttäjää kiinnostaviin näkökohtiin. Tämän vuoksi ehdotamme menetelmää abstraktisen TLS:n oppimiseen vuorovaikutteisesti käyttäen Reinforcement Learning (RL) -menetelmää. Määrittelemme yhdistelmäpalkitsemistoiminnon ja hienosäädämme RL:n avulla abstraktiivista Multi-document Summarisation (MDS) -mallia, jolloin ei tarvitse harjoitella viiteyhteenvedoilla. Yksi osapalkkiotoiminnoista opitaan vuorovaikutteisesti käyttäjien palautteesta, jotta varmistetaan käyttäjien vaatimusten ja luotujen aikajanojen välinen johdonmukaisuus. Muut palkitsemistoiminnot edistävät ajankohtaista johdonmukaisuutta ja kielellistä sujuvuutta. Suunnittelemme kokeiluja arvioidaksemme, voisiko lähestymistapamme tuottaa tarkkoja ja tarkkoja aikajanoja kullekin käyttäjälle.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Timeline Summarisation (TLS) vise à générer une liste concise et ordonnée d'événements décrits dans des sources telles que des articles de presse. Cependant, les systèmes actuels ne fournissent pas un moyen adéquat de s'adapter à de nouveaux domaines ni de se concentrer sur les aspects présentant un intérêt pour un utilisateur particulier. C'est pourquoi nous proposons une méthode d'apprentissage interactif du TLS abstrait à l'aide de l'apprentissage par renforcement (RL). Nous définissons une fonction de récompense composée et utilisons RL pour affiner un modèle abstrait de synthèse multi-documents (MDS), ce qui évite d'avoir à former à l'aide de résumés de référence. L'une des fonctions secondaires sera apprise de manière interactive à partir des commentaires des utilisateurs afin d'assurer la cohérence entre les demandes des utilisateurs et le calendrier généré. Les autres fonctions de sous-récompense contribuent à la cohérence thématique et à la maîtrise linguistique. Nous planifions des expériences afin d'évaluer si notre approche peut générer des délais précis et adaptés à chaque utilisateur.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tá sé mar aidhm ag Achoimriú Amlíne (TLS) liosta gonta, am-ordaithe a chruthú d’imeachtaí a gcuirtear síos orthu i bhfoinsí ar nós ailt nuachta. Mar sin féin, ní sholáthraíonn na córais reatha bealach imleor chun oiriúnú d’fhearainn nua ná chun díriú ar ghnéithe ar díol spéise iad d’úsáideoir áirithe. Mar sin, molaimid modh chun TLS teibí a fhoghlaim go hidirghníomhach ag baint úsáide as Foghlaim Neartú (RL). Sainmhínímid feidhm luach saothair iolrach agus úsáidimid RL chun mionchoigeartú a dhéanamh ar shamhail Achoimrithe Ildhoiciméid (MDS) teibí, a sheachnaíonn an gá le hoiliúint a úsáid le hachoimrí tagartha. Foghlaimeofar ceann de na feidhmeanna fo-luaíochta go hidirghníomhach ó aiseolas ó úsáideoirí chun comhsheasmhacht idir éilimh na n-úsáideoirí agus an t-amlíne ginte a chinntiú. Cuireann na feidhmeanna fo-luaíochta eile le comhleanúnachas tráthúla agus líofacht teanga. Déanaimid turgnaimh a phleanáil chun a mheas an bhféadfadh ár gcur chuige amlínte cruinne beachta a chur in oiriúint do gach úsáideoir.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>@ action: button A lokacin da, na'urar da ake kai yanzu ba za'a ƙudura hanya mai daidai wa da za'a haɗi koda, kuma bã ya zura ido kan masu da amfani da wani mai ƙayyade. Saboda haka, Munã buɗa wata usur da za'a sanar da mutane ta kanrakati TLS da amfani da Shirin LUTI (RL). Mu ƙayyade wani aikin ijãrar da aka ƙunsa da kuma Mu yi amfani da RL zuwa a gyare-tun wata misali na takardar mulki-dokuman aiki (MDS), wanda ya ƙẽtare umarni da ke amfani da fassarar tsari. Babu wani abu na ƙara-sakamakon za'a sanar da shi farat ɗaya daga baka mai amfani da mai amfani da, dõmin ya yi yaƙĩni da wata daidaita tsakanin tambayar mai amfani da kuma tare da aka ƙãga wani lokaci. Suna da wasu functionin sub-ijãra yana ƙara wa fassarar samuraci da linguistic. We plan experiments to evaluate whether our approach could generate accurate and precise timelines tailored for each user.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>סדרת קו הזמן (TLS) מתכוונת ליצור רשימה קצרה ומסדרת בזמן של אירועים מתארות במקורים כמו מאמרים חדשות. בכל אופן, מערכות הנוכחיות לא מספקות דרך מתאימה להתאים לתחומים חדשים ולא להתמקד באינטרסים למשתמש מסוים. Therefore, we propose a method for interactively learning abstractive TLS using Reinforcement Learning (RL). אנחנו מגדירים פונקציה של פרס מורכב ושימושים RL כדי לתקן מודל מסמכים רבים אסטרקטיבי (MDS), שממנע את הצורך לאימון באמצעות סדרות התייחסות. אחת התפקידים של הפרס התחתון תלמד באופן אינטראקטיבי ממחזור המשתמש כדי להבטיח את התקבילות בין הדרישות של המשתמשים לקו הזמן הנוצר. התפקידים האחרים של הפרס התחתון תורמים לקשורות נופעית ושלווה שפתית. אנחנו מתכננים ניסויים כדי להעריך אם הגישה שלנו יכולה ליצור קווי זמנים מדויקים ודויקים מתאימים לכל משתמש.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>टाइमलाइन सारांशीकरण (टीएलएस) का उद्देश्य समाचार लेख जैसे स्रोतों में वर्णित घटनाओं की एक संक्षिप्त, समय-क्रमबद्ध सूची उत्पन्न करना है। हालांकि, वर्तमान सिस्टम नए डोमेन के अनुकूल होने का पर्याप्त तरीका प्रदान नहीं करते हैं और न ही किसी विशेष उपयोगकर्ता के लिए रुचि के पहलुओं पर ध्यान केंद्रित करते हैं। इसलिए, हम सुदृढीकरण सीखने (आरएल) का उपयोग करके इंटरैक्टिव रूप से अमूर्त टीएलएस सीखने के लिए एक विधि का प्रस्ताव करते हैं। हम एक यौगिक इनाम समारोह को परिभाषित करते हैं और एक अमूर्त बहु-दस्तावेज़ सारांशीकरण (एमडीएस) मॉडल को ठीक करने के लिए आरएल का उपयोग करते हैं, जो संदर्भ सारांश का उपयोग करके प्रशिक्षित करने की आवश्यकता से बचता है। उप-इनाम कार्यों में से एक को उपयोगकर्ताओं की मांगों और उत्पन्न समयरेखा के बीच स्थिरता सुनिश्चित करने के लिए उपयोगकर्ता प्रतिक्रिया से इंटरैक्टिव रूप से सीखा जाएगा। अन्य उप-इनाम कार्य सामयिक सुसंगतता और भाषाई प्रवाह में योगदान करते हैं। हम यह मूल्यांकन करने के लिए प्रयोगों की योजना बनाते हैं कि क्या हमारा दृष्टिकोण प्रत्येक उपयोगकर्ता के लिए सटीक और सटीक समयरेखा उत्पन्न कर सकता है।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vremenska sažetka (TLS) je cilj proizvesti konkretni, vremenski raspoređeni popis događaja opisanih u izvorima poput novinskih članaka. Međutim, trenutni sustavi ne pružaju odgovarajući način prilagođenja novim domenama niti fokusirati se na aspekte interesa određenom korisniku. Stoga predlažemo metodu interaktivnog učenja abstraktivnog TLS koristeći učenje pojačanja (RL). Definiramo funkciju nagrade kombinacije i koristimo RL kako bi upravljali abstraktivni model rezervacije mnogih dokumenta (MDS), koji izbjegava potrebu trenirati s referentnim sažetkama. Jedna od funkcija podnagrade bit će učena interaktivno od povratka korisnika kako bi se osigurala konsekvencija između zahtjeva korisnika i proizvedene vremenske linije. Druge podnagrade doprinose temeljnoj konsekvenciji i jezičkoj tekućini. Planiramo eksperimente da procijenimo da li bi naš pristup mogao stvoriti tačne i precizne vremenske linije prilagođene svakom korisniku.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A Timeline Summarisation (TLS) célja, hogy tömör, időrendezett listát készítsen a forrásokban, például a hírekben leírt eseményekről. A jelenlegi rendszerek azonban nem biztosítanak megfelelő módot az új területekhez való alkalmazkodásra, sem pedig arra, hogy egy adott felhasználó érdeklődésének szempontjaira összpontosítsanak. Ezért javasoljuk az absztraktív TLS interaktív tanulásának módszerét a Reinforcement Learning (RL) segítségével. Meghatározunk egy összetett jutalomfüggvényt, és RL segítségével finomhangoljuk az absztraktív Multi-Document Summarisation (MDS) modellt, amely elkerüli a referenciaösszefoglalók használatával történő képzés szükségességét. Az egyik részjutalom funkció interaktív módon megtanulható a felhasználói visszajelzésekből, hogy biztosítsa a felhasználók igényei és a generált idővonal közötti összhangot. A többi aljutalom funkció hozzájárul a aktuális koherenciához és a nyelvi folyékonysághoz. Kísérleteket tervezünk annak értékelésére, hogy megközelítésünk képes-e pontos és pontos idővonalakat generálni az egyes felhasználók számára.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ժամանակի համառոտագրությունը (TLS) նպատակով է ստեղծել համընդհանուր, ժամանակի համակարգված ցուցակ իրադարձությունների, որոնք նկարագրվում են այնպիսի աղբյուրներում, ինչպիսիք են նորությունների հոդվածները: Այնուամենայնիվ, ներկայիս համակարգերը բավարար միջոց չեն տրամադրում նոր ոլորտներին հարմարվելու կամ կենտրոնանալ որոշակի օգտագործողի հետաքրքրության ասպեկտների վրա: Այդ պատճառով, մենք առաջարկում ենք ինտերակտիվ ուսումնասիրելու աբստրակտիվ ԹԼՍ-ը օգտագործելով ուժեղացման ուսումնասիրությունը (ՌԼ): Մենք սահմանում ենք համադրված վարձի ֆունկցիան և օգտագործում ենք RL-ը վերաստեղծելու համար բազմաթիվ փաստաթղթերի համառոտագրման (MDS) մոդելը, որը խուսափում է հարցումների համառոտագրման կարիքից: Օգտագործողների արձագանքներից մեկը ինտերակտիվ կսովորվի օգտագործողների պահանջների և ստեղծված ժամանակային գծերի միջև հատուկ լինելու համար: Մյուս ենթավարձի ֆունկցիաները ներդրում են թեմական համապատասխանությունը և լեզվաբանական ճկունությունը: Մենք փորձեր ենք պլանավորում, որպեսզի գնահատենք, արդյոք մեր մոտեցումը կարող է ստեղծել ճշգրիտ և ճշգրիտ ժամանակահատվածներ, որոնք պատրաստված են յուրաքանչյուր օգտագործողի համար:</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Penapisan Garis Waktu (TLS) bermaksud untuk menghasilkan daftar peristiwa singkat, tertib-waktu yang ditetapkan dalam sumber seperti artikel berita. Namun, sistem saat ini tidak menyediakan cara yang tepat untuk beradaptasi ke domain baru atau untuk fokus pada aspek kepentingan bagi pengguna tertentu. Oleh karena itu, kami mengusulkan metode untuk mempelajari secara interaktif TLS abstraktif menggunakan Penjelasan Penyukuran (RL). Kami mendefinisikan fungsi penghargaan komponen dan menggunakan RL untuk memperbaiki model abstraktif Multi-Document Summarization (MDS), yang menghindari kebutuhan untuk berlatih menggunakan ringkasan referensi. One of the sub-reward functions will be learned interactively from user feedback to ensure the consistency between users' demands and the generated timeline. Fungsi sub-hadiah lainnya berkontribusi ke koerensi topik dan keterlaluan bahasa. Kami merencanakan eksperimen untuk mengevaluasi apakah pendekatan kita dapat menghasilkan garis waktu yang tepat dan tepat disesuaikan untuk setiap pengguna.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Timeline Summarisation (TLS) mira a generare un elenco conciso e cronologico di eventi descritti in fonti come articoli di notizie. Tuttavia, i sistemi attuali non forniscono un modo adeguato per adattarsi a nuovi domini né per concentrarsi sugli aspetti di interesse per un determinato utente. Pertanto, proponiamo un metodo per imparare interattivamente TLS astratto utilizzando Reinforcement Learning (RL). Definiamo una funzione di ricompensa composta e utilizziamo RL per ottimizzare un modello astratto di Summarisation Multi-Document (MDS), evitando la necessità di allenarsi utilizzando riassunti di riferimento. Una delle funzioni di sub-ricompensa sarà imparata interattivamente dal feedback degli utenti per garantire la coerenza tra le richieste degli utenti e la timeline generata. Le altre funzioni di sub-ricompensa contribuiscono alla coerenza topica e alla fluidità linguistica. Progettiamo esperimenti per valutare se il nostro approccio possa generare tempistiche accurate e precise su misura per ogni utente.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>タイムラインサマリゼーション（ TLS ）は、ニュース記事などのソースで説明されているイベントの簡潔で時系列のリストを生成することを目的としています。しかしながら、現在のシステムは、新しいドメインに適応するための適切な方法、または特定のユーザーに関心のある態様に焦点を当てるための適切な方法を提供しない。そこで，強化学習（ Reinforcement Learning, RL ）を用いて抽象的なTLSをインタラクティブに学習する方法を提案する．複合報酬関数を定義し、RLを使用して抽象的なマルチドキュメント要約（ MDS ）モデルを微調整します。これにより、参照要約を使用してトレーニングする必要がなくなります。サブリワード機能の1つは、ユーザーの要求と生成されたタイムラインとの間の一貫性を確保するために、ユーザーのフィードバックから対話的に学習されます。他の副次的な機能は、話題の一貫性と言語の流暢性に寄与します。私たちは、私たちのアプローチが各ユーザーに合わせた正確で正確なタイムラインを生成できるかどうかを評価するための実験を計画しています。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ukuntaha Tarjamahan (TIL) kang disimpen nggawe sampek, aku-disimpen oleh dadi pawaran kanggo nggawe tarjamahan karo penjelongkapan kanggo Artis Perintah politenessoffpolite"), and when there is a change ("assertivepoliteness Kaya, kéné gunakake sistem kanggo nggambar aksi tarjamahan kanggo nggambar RL kuwi nggawe Rayforcement Learning (RL). Awakdhéwé Define 1 Omah sing mbubuti Layaran Pangan Sub-Rayakno sing mengko perusahaan nganggep bantuan kanggo sabên bakal terusahan karo pawaran ingkang. Awak dhéwé éntukno éntukang nggawe baléné, mengko iso nggawe layang kanggo ngono nggawe layang kanggo nggawe Perintah kanggo nguasai nggo sabên pengguna.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>დრო ხაზის კონფიგურაცია (TLS) მიზეზია, რომ წარმოიდგინოთ, დროს დაწყენებული მოვლენების სია, როგორც ახალგაზონის статьები. მაგრამ, მიმდინარე სისტემები არ ახალ დიომენთან აეპტიფიკაციის შესაძლებელი გზა, არა ინტერესტის აპექტიკურება განსაკუთრებული მომხმარებისთვის. ამიტომ, ჩვენ მინდა ინტერექტიგურად აბსტრაქტიგური TLS სწავლისთვის, რომელიც გამოყენებული აბსტრაქტიგური სწავლისთვის (RL). ჩვენ განსაზღვრებით შეცდომების ფუნქცია და გამოყენებით RL, რომ აბსტრაქტიური მრავალე დოკუმენტის კომპერაციაცია (MDS) მოდელს, რომელიც გამოცდილობს რეფერაციის კომპერ ერთი სამუშაო ფუნქციებიდან ინტერექტიგურად მომხმარებლის გადასწავლა, რომ მომხმარებლის მოთხოვრების და შექმნილი სამუშაო ხაზის განმავლობას დასწავლათ. სხვა სამუშაო ფუნქციები მიიღებენ ტემატიური კონექერენციას და ენგურისტიური ფუნქციას. ჩვენ ვფიქრობთ ექსპერიმენტები, რომელიც განსაზღვრება თუ ჩვენი პროგრამა შეიძლება წარმოიქმნა მარტივი და წარმოადგილი დრო ხაზები, რომელიც ყო</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Уақыт жолының тұжырымдамасы (TLS) жаңалық мақалалар секілді көзінде таңдалған оқиғалар тізімін құру мақсаты болады. Бірақ назардағы жүйелер жаңа доменге адаптау үшін және осы пайдаланушыға қызықтық аспектеріне көңіл бермейді. Сондықтан, біз интерактивті түрде абстрактивті TLS оқыту әдісін қолданамыз (RL). Біз компоненттің жоғары функциясын анықтап, RL дегенді абстрактивті көптеген құжаттардың тұжырымдамасын (MDS) баптау үшін қолданамыз. Бұл сілтемелер тұжырымдамасын қолдану керектігін шектеп Пайдаланушылардың талаптарының және құрылған уақыт жолының тәуелсіздігін тексеру үшін қолданушылардың қайтару арқылы интерактивті түрде үйреніледі. Басқа төмендеу функциялары нақышты согластық және лингвистикалық жылдамдығына көмектеседі. Біз әрбір пайдаланушыға дұрыс және дұрыс уақыт жолдарын құрастыру үшін тәжірибелерді бағалау үшін тәжірибелерді жоспарлаймыз.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>타임라인 요약(TLS)은 뉴스 기사와 같은 출처에서 기술한 이벤트의 간단명료하고 시간순으로 목록을 만들기 위한 것이다.그러나 현재의 시스템은 새로운 분야에 적응하는 적당한 방식을 제공하지 않고 특정 사용자가 흥미를 느끼는 부분에 중점을 두지 않는다.따라서 우리는 강화학습(RL)을 사용하여 추상적인 TLS를 상호작용으로 학습하는 방법을 제시했다.우리는 복합 보상 함수를 정의하고 RL을 사용하여 추상적인 다중 문서 요약(MDS) 모델을 미세하게 조정하여 참고 요약을 사용하여 교육을 진행하는 수요를 피했다.그 중 하나의 차급 보상 기능은 사용자의 피드백에서 상호작용을 통해 사용자의 수요와 생성된 시간선 간의 일치성을 확보할 것이다.기타 하위 보상 기능은 주제의 일관성과 언어의 유창성에 도움이 된다.우리는 우리의 방법이 모든 사용자에게 정확한 시간선을 생성할 수 있는지를 평가하기 위해 실험을 진행할 계획이다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Laikotarpio santraukos tikslas – sudaryti trumpą, laiku tvarkomą įvykių, aprašytų šaltiniuose, pavyzdžiui, naujienų straipsniuose, sąrašą. Tačiau dabartinės sistemos nesuteikia tinkamo būdo prisitaikyti prie naujų sričių ir sutelkti dėmesio į konkrečiam vartotojui svarbius aspektus. Todėl siūlome metodą interaktyviai mokytis abstraktyvios TLS naudojant sustiprintą mokymąsi. We define a compound reward function and use RL to fine-tune an abstractive Multi-document Summarisation (MDS) model, which avoids the need to train using reference summaries. Viena iš papildomo atlyginimo funkcijų bus interaktyviai mokoma iš vartotojų atsiliepimų, kad būtų užtikrintas vartotojų poreikių ir sukauptų terminų nuoseklumas. Kitos subatlyginimo funkcijos prisideda prie aktualios nuoseklumo ir kalbų lankstumo. Planuojame eksperimentus, kad įvertintume, ar mūsų metodas galėtų sukurti tikslias ir tikslias kiekvienam naudotojui pritaikytas grafikas.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Timeline Summarisation (TLS) aims to generate a concise, time-ordered list of events described in sources such as news articles. However, current systems do not provide an adequate way to adapt to new domains nor to focus on the aspects of interest to a particular user. Затоа предложуваме метод за интерактивно учење апстрактивен ТЛС користејќи го Научувањето на зајакнување (РЛ). Ние дефинираме комплексна функција на награда и користиме RL за финетизирање на апстрактивен модел на Мултидокументарна резултатација (МДС), кој ја избегнува потребата за обука користејќи референтни резултати. Една од функциите на поднаградата ќе биде научена интерактивно од корисничките реакции за да се осигури константноста помеѓу барањата на корисниците и генерираната временска линија. Другите функции на поднаграда придонесуваат за точната кохеренција и јазичната течност. Планираме експерименти за да процениме дали нашиот пристап може да генерира точни и прецизни временски линии соодветни за секој корисник.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>വാര്‍ത്തകള്‍ പോലെ വിവരിച്ചിരിക്കുന്ന സംഭവങ്ങളുടെ നിര്‍ദ്ദേശങ്ങളുടെ പട്ടിക ഉണ്ടാക്കുവാന്‍ ടൈമെലിന്‍ ചുരുക്കം(TLS) എന്നാലും ഇപ്പോഴത്തെ സിസ്റ്റത്തില്‍ പുതിയ ഡൊമെന്‍സിലേക്ക് ചേര്‍ക്കാനും പ്രത്യേകിച്ചുള്ള ഉപയോക്താവിന് താല്പര്യ അതുകൊണ്ട്, നമ്മള്‍ വീണ്ടും പ്രവര്‍ത്തിപ്പിക്കുന്ന വിദ്യാഭ്യാസ പഠിക്കുന്നതിനുള്ള ഒരു രീതിയെടുക്കുന്നു. ഞങ്ങള്‍ ഒരു കൂട്ടത്തിലെ പ്രതിഫല ഫങ്ഷന്‍ നിര്‍ണ്ണയിക്കുന്നു. RL ഉപയോഗിക്കുന്നത് ഒരു അസാധ്യതയില്ലാത്ത പല രേഖയുടെ ചുരുക്കം മോഡലിലേക്ക് ഉപയ ഉപയോക്താവിന്റെ ആവശ്യങ്ങള്‍ക്കും സൃഷ്ടിക്കുന്ന സമയലൈനുമിടയിലുള്ള അവസ്ഥ ഉറപ്പുവരുത്തുന്നതിനും ഉപയോക്താവിന്റെ ഫിബിബിബാക മറ്റുള്ള ഉപപ്രതിഫല പ്രവര്‍ത്തനങ്ങള്‍ പ്രധാനപൂര്‍ണ്ണമായ സഹജയത്തിലും ഭാഷക്കാരുടെ ഫ്ലൈന്‍സിക്കും സഹായിക് നമ്മുടെ പരീക്ഷണങ്ങള്‍ പരിശോധിക്കുന്നത് ഓരോ ഉപയോക്താവിനും വേണ്ടി നിര്‍ണ്ണയിക്കപ്പെട്ട സമയത്തിന്റെയും കൃത്യമ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Цаг хугацааны уулзалт (TLS) нь мэдээллийн баримтууд шиг эх үүсвэрт тайлбарлан тодорхой, цаг хугацааны дарааллын жагсаалтыг бүтээх зорилго юм. Гэхдээ одоогийн системүүд шинэ хэсэгт адилтгах боломжтой арга замаар хангадаггүй, эсвэл тодорхой хэрэглэгчид сонирхолтой асуудлыг анхаарлаа хангадаггүй. Тиймээс бид интерактив суралцах арга замыг нэмэгдүүлэх (RL) суралцах арга зам өгдөг. Бид холбоотой шагналын функцийг тодорхойлож, RL-г ашиглаж, харьцангуй олон баримт нийлүүлэлтийн (MDS) загварыг сайжруулахын тулд ашигладаг. Энэ нь хариултын нийлүүлэлтийг ашиглан суралцах хэрэгтэй. Хэрэглэгчдийн хэрэглэгчдийн талаар болон үүсгэсэн цаг хугацааны хоорондын харилцааны харилцааны харилцааны нэг нь интерактив байдлаар суралцагдана. Бусад шагналын функцүүд сэдэв хамааралтай, хэлний шингэнд тусалдаг. Бид туршилтуудыг хэрэглэгчид бүрт тодорхой, тодорхой цаг хугацааны шугам бий болгож чадах эсэхийг тодорхойлдохын тулд төлөвлөгдөг.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Penapisan Garis Masa (TLS) bermaksud untuk menghasilkan senarai peristiwa yang tersusun dan tersusun-masa yang diterangkan dalam sumber seperti artikel berita. However, current systems do not provide an adequate way to adapt to new domains nor to focus on the aspects of interest to a particular user. Therefore, we propose a method for interactively learning abstractive TLS using Reinforcement Learning (RL). Kami takrifkan fungsi hadiah gabungan dan gunakan RL untuk menyesuaikan model Penapisan Berberapa Dokumen (MDS) abstraktif, yang mengelakkan perlukan latihan menggunakan ringkasan rujukan. Salah satu fungsi sub-hadiah akan belajar secara interaktif dari balas balik pengguna untuk memastikan konsistensi antara permintaan pengguna dan garis masa yang dijana. Fungsi sub-hadiah lain berkontribusi kepada ketepatan topik dan ketepatan bahasa. Kami merancang eksperimen untuk menilai sama ada pendekatan kita boleh menghasilkan garis masa yang tepat dan tepat yang disesuaikan untuk setiap pengguna.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Is-Sommarju taż-Żmien (TLS) għandu l-għan li jiġġenera list a konċiża u ordnata skont iż-żmien ta’ avvenimenti deskritti f’sorsi bħal artikoli tal-a ħbarijiet. Madankollu, is-sistemi attwali ma jipprovdux mod adegwat biex jadattaw għal dominji ġodda u lanqas biex jiffokaw fuq l-aspetti ta’ interess għal utent partikolari. Għalhekk, qed nipproponu metodu għat-tagħlim interattiv tat-TLS astrattiv bl-użu tat-Tagħlim ta’ Rinforzament (RL). Aħna niddefinixxu funzjoni komposta ta’ premju u nużaw RL biex nidfinaw mudell astrattiv ta’ Sommarju Multi-Dokumenti (MDS), li jevita l-ħtieġa li nħarrġu bl-użu ta’ sommarji ta’ referenza. One of the sub-reward functions will be learned interactively from user feedback to ensure the consistency between users' demands and the generated timeline. Il-funzjonijiet l-oħra ta’ sottopremju jikkontribwixxu għal koerenza topika u fluwenza lingwistika. Aħna ppjanaw esperimenti biex jivvalutaw jekk l-approċċ tagħna jistax jiġġenera skedi ta’ żmien preċiżi u preċiżi mfassla għal kull utent.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Timeline Summarisation (TLS) heeft als doel een beknopte, tijdgeordende lijst te genereren van gebeurtenissen beschreven in bronnen zoals nieuwsberichten. De huidige systemen bieden echter geen adequate manier om zich aan te passen aan nieuwe domeinen of om te focussen op de aspecten die voor een bepaalde gebruiker interessant zijn. Daarom stellen we een methode voor om interactief abstractief TLS te leren met behulp van Reinforcement Learning (RL). We definiëren een samengestelde beloningsfunctie en gebruiken RL om een abstractief MDS-model (Multi-Document Summarisation) te finetunen, waardoor het niet nodig is om te trainen met behulp van referentiesamenvattingen. Een van de sub-beloningsfuncties wordt interactief geleerd van gebruikersfeedback om de consistentie tussen de eisen van gebruikers en de gegenereerde tijdlijn te verzekeren. De andere sub-beloningsfuncties dragen bij aan actuele samenhang en taalbeheersing. We plannen experimenten om te evalueren of onze aanpak nauwkeurige en nauwkeurige tijdlijnen kan genereren op maat van elke gebruiker.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tidlinjesamandringa (TLS) måtar å laga ei konklus, tidsredigt liste over hendingar som er beskriven i kjelder som nyhetsarklar. Det gjeldande systemet gjev imidlertid ikkje noko passande måte å tilpassa nye domene eller fokusera på aspektane av interesse til ein bestemt brukar. Derfor fører vi ein metode for interaktivt læring av abstraktive TLS ved hjelp av reinforcementlæring (RL). Vi definerer ein komponent rentefunksjon og bruker RL for å finne opp ein abstraktiv multidokumentsamandrag (MDS) modell, som unngår behov for å trenja med referanssamandrag. Ein av underløpsfunksjonane vil bli lært interaktivt frå tilbakemeldinga til brukaren for å sikra at konsistens mellom brukaren krev og den genererte tidslinja. Den andre underløpsfunksjonane bidrar til temaske koherens og språkstiske fluktens. Vi planlegger eksperimenter for å evaluera om tilnærminga vårt kan laga nøyaktig og nøyaktig tidslinjer som er tilpassa for kvar brukar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Podsumowanie linii czasu (TLS) ma na celu stworzenie zwięzłej, uporządkowanej w czasie listy zdarzeń opisanych w źródłach, takich jak artykuły wiadomościowe. Obecne systemy nie zapewniają jednak odpowiedniego sposobu dostosowania się do nowych domen ani skupienia się na aspektach interesujących konkretnego użytkownika. Dlatego proponujemy metodę interaktywnego uczenia się abstrakcyjnego TLS z wykorzystaniem Reinforcement Learning (RL). Definiujemy złożoną funkcję nagrody i używamy RL do dostrojenia abstrakcyjnego modelu podsumowania wielu dokumentów (MDS), co unika konieczności treningu za pomocą podsumowań referencyjnych. Jedna z funkcji sub-nagrody zostanie nauczona interaktywnie z opinii użytkowników, aby zapewnić spójność między wymaganiami użytkowników a generowaną linią czasu. Inne funkcje sub-nagrody przyczyniają się do aktualnej spójności i płynności językowej. Planujemy eksperymenty, aby ocenić, czy nasze podejście może generować dokładne i precyzyjne linie czasu dostosowane do każdego użytkownika.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A sumarização da linha do tempo (TLS) visa gerar uma lista concisa e ordenada de eventos descritos em fontes como artigos de notícias. No entanto, os sistemas atuais não fornecem uma maneira adequada de se adaptar a novos domínios nem de se concentrar nos aspectos de interesse de um determinado usuário. Portanto, propomos um método para aprender interativamente TLS abstrativo usando Reinforcement Learning (RL). Definimos uma função de recompensa composta e usamos RL para ajustar um modelo abstrativo de sumarização de vários documentos (MDS), o que evita a necessidade de treinar usando resumos de referência. Uma das funções de sub-recompensa será aprendida interativamente a partir do feedback do usuário para garantir a consistência entre as demandas dos usuários e o cronograma gerado. As outras funções de sub-recompensa contribuem para a coerência tópica e a fluência linguística. Planejamos experimentos para avaliar se nossa abordagem pode gerar cronogramas precisos e precisos sob medida para cada usuário.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Timeline Summarisation (TLS) își propune să genereze o listă concisă, ordonată în timp, a evenimentelor descrise în surse precum articole de știri. Cu toate acestea, sistemele actuale nu oferă o modalitate adecvată de adaptare la noile domenii și nici de concentrare asupra aspectelor de interes pentru un anumit utilizator. Prin urmare, propunem o metodă de învățare interactivă a TLS abstractivă folosind Reinforcement Learning (RL). Definim o funcție de recompensă compusă și folosim RL pentru a regla fin un model abstractiv Multi-Document Summarisation (MDS), care evită nevoia de a instrui folosind rezumate de referință. Una dintre funcțiile de subrecompensă va fi învățată interactiv din feedback-ul utilizatorilor pentru a asigura coerența între cerințele utilizatorilor și calendarul generat. Celelalte funcții sub-recompensare contribuie la coerența actuală și fluența lingvistică. Planificăm experimente pentru a evalua dacă abordarea noastră ar putea genera cronologii precise și precise adaptate fiecărui utilizator.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Сводка временной шкалы (TLS) направлена на создание краткого, упорядоченного по времени списка событий, описанных в таких источниках, как новостные статьи. Однако нынешние системы не обеспечивают адекватного способа адаптации к новым областям или сосредоточения внимания на аспектах, представляющих интерес для конкретного пользователя. Поэтому мы предлагаем метод интерактивного обучения абстрактному TLS с использованием обучения подкреплению (RL). Мы определяем сложную функцию вознаграждения и используем RL для тонкой настройки абстрактной модели суммирования нескольких документов (MDS), которая позволяет избежать необходимости тренировки с использованием справочных сводок. Одна из функций субпоощрения будет изучаться в интерактивном режиме на основе обратной связи с пользователями, с тем чтобы обеспечить согласованность между запросами пользователей и составленными сроками. Другие функции суб-награды способствуют тематической согласованности и лингвистической беглости. Мы планируем эксперименты, чтобы оценить, может ли наш подход генерировать точные и точные временные рамки, адаптированные для каждого пользователя.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>වෙලාව සම්පූර්ණය (TLS) අදහස් කරනවා සම්පූර්ණය, වෙලාව සම්පූර්ණය සඳහා වාර්තාවක් ලැයිස්තුවක් නිර්මාණය කරන නමුත්, ප්‍රස්ථාන පද්ධතිය අළුත් ඩෝමේන් වලට සම්බන්ධ වෙන්න හැබැයි විශේෂ ප්‍රයෝජකයෙක්ට ප්‍රශ්නයක් ඉතින්, අපි ප්‍රයෝජනය කරන්නේ ප්‍රයෝජනයක් ප්‍රයෝජනය කරන්නේ ප්‍රයෝජනය සඳහා ප්‍රයෝජනය සඳහා ප්‍රයෝජනය සඳ අපි සම්පූර්ණ ප්‍රයෝජනයක් විශ්වාස කරන්න සහ RL විශ්වාස කරන්න සම්පූර්ණ විශ්වාස කරන්න සම්පූර්ණ විශ්වාස (MDS) මොඩේල් එක පාවිච්චි ප්‍රයෝජනය සහ නිර්මාණය වෙනුවෙන් ප්‍රයෝජනය ප්‍රයෝජනයෙන් ප්‍රයෝජනයෙන් ප්‍රයෝජනයෙන් ප්‍රයෝ අනිත් ප්‍රතිචාර ප්‍රයෝජනය සහ භාෂාත්මක ප්‍රයෝජනය සම්බන්ධ වෙන්න පුළුවන්. අපි පරීක්ෂණය සැලසුම් කරනවා අපේ පරීක්ෂණය සිද්ධ වෙන්න පුළුවන් කියලා හැම පාවිච්චිකරුවෙක්ම සැකස</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Cilj povzetka časovne linije (TLS) je ustvariti jedrnat, časovno urejen seznam dogodkov, opisanih v virih, kot so novinarski članki. Vendar sedanji sistemi ne zagotavljajo ustreznega načina prilagajanja novim področjem niti osredotočanja na vidike, ki zanimajo določenega uporabnika. Zato predlagamo metodo interaktivnega učenja abstraktivnega TLS z uporabo ojačevalnega učenja (RL). Določimo sestavljeno funkcijo nagrajevanja in uporabljamo RL za natančno nastavitev abstraktivnega modela večdokumentnega povzetka (MDS), s čimer se izognemo treningu z uporabo referenčnih povzetkov. Ena od funkcij podnagrade se bo interaktivno naučila iz povratnih informacij uporabnikov, da se zagotovi skladnost med zahtevami uporabnikov in ustvarjenim časovnim okvirom. Druge funkcije podnagrade prispevajo k aktualni skladnosti in jezikovni tekočosti. Načrtujemo poskuse, s katerimi ocenimo, ali lahko naš pristop ustvari natančne in natančne časovne linije, prilagojene vsakemu uporabniku.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Summariska waqtiga (TLS) waxaa loola jeedaa inuu sameeyo liiska dhacdooyinka oo lagu qoray sida warqadaha habari. Si kastaba ha ahaatee nidaamka joogtada ah ma bixiyaan hab ku filan in lagu beddelo deegaanka cusub ama uu ku kalsoonaado arrimaha xiisaha ee isticmaalaha gaar ah. Sidaas darteed waxaynu soo jeedaynaa qaab aan si iskuul ah u barano TLS oo la isticmaalayo waxbarashada Reinforcement (RL). Waxaynu u qoraynaa shaqo mushaar ah oo ka mid ah RL si a an u sameyno sameyn sameynta dhamaadka qoraalka kala duduwan (MDS), kaasoo diida in loo baahdo waxbarashada isticmaalka summarinta reference. Mid ka mid ah waxqabadka sub-mushaarka waxaa si firfircoon looga bartaa feedbacka isticmaalaha si uu u xaqiijiyo isku xiriirka u dhexeeya baahida isticmaalayaasha iyo xilliga la soo saaray. Shaqooyinka kale ee sub-mushaarku waxay ku caawinaysaa isku xiriir iyo luqada. Waxaan qorsheynaa baaritaanka si aan u qiimeynayno in qaababkayagu uu u sameyn karo saxda iyo saxda xilliyada ee loo qoray isticmaalaha kasta.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Përshkrimi i afatit të kohës (TLS) synon të gjenerojë një list ë të shkurtër dhe të caktuar me kohë të ngjarjeve të përshkruara në burime të tilla si artikujt e lajmeve. Megjithatë, sistemet aktuale nuk ofrojnë një mënyrë të përshtatshme për t'u përshtatur në fusha të reja dhe as për t'u përqëndruar në aspektet e interesit për një përdorues të veçantë. Prandaj, ne propozojmë një metodë për të mësuar interaktivisht TLS abstraktiv duke përdorur Mësimin e Përforcimit (RL). Ne përcaktojmë një funksion shpërblimi të përbashkët dhe përdorim RL për të përshtatur një model abstraktiv të Summarization Multi-Document (MDS), i cili shmanget nevojës për trajnimin duke përdorur përmbledhjet e referimit. Një nga funksionet e nënshpërblimit do të mësohet interaktivisht nga përgjigjet e përdoruesve për të siguruar konsistencën midis kërkesave e përdoruesve dhe vijës kohore të gjeneruar. Funksionet e tjera të nënshpërblimit kontribuojnë për koherencën aktuale dhe fluencën gjuhësore. Ne planifikojmë eksperimente për të vlerësuar nëse qasja jonë mund të gjenerojë vija kohore të sakta dhe të sakta të përshtatshme për çdo përdorues.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vremenska sažetka (TLS) je cilj da stvori konkretnu, vremenski naređenu listu događaja opisanih u izvorima poput novinskih članaka. Međutim, trenutni sistemi ne pružaju odgovarajući način da se prilagodi novim domenama niti da se fokusiraju na aspekte interesa određenom korisniku. Stoga predlažemo metodu interaktivnog učenja abstraktivnog TLS koristeći učenje pojačanja (RL). Definiramo funkciju kompleksnog nagrade i koristimo RL za finaliziranje apstraktivnog model a rezervacije mnogih dokumenta (MDS), koji izbjegava potrebu treniranja korištenjem referentnih sažetaka. Jedna od funkcija podnagrade biće učena interaktivno od povratka korisnika kako bi se osigurala konsekvencija između zahteva korisnika i proizvedenih vremenskih linija. Druge podnagrade doprinose temalnoj koherenciji i jezičkoj tekućini. Planiramo eksperimente da procenimo da li bi naš pristup mogao stvoriti tačne i precizne vremenske linije ispravljene za svakog korisnika.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Timeline Summarisation (TLS) syftar till att skapa en kortfattad, tidsordnad lista över händelser som beskrivs i källor som nyhetsartiklar. Nuvarande system ger dock inte ett lämpligt sätt att anpassa sig till nya domäner eller att fokusera på aspekter av intresse för en viss användare. Därför föreslår vi en metod för interaktivt lärande av abstrakt TLS med hjälp av Reinforcement Learning (RL). Vi definierar en sammansatt belöningsfunktion och använder RL för att finjustera en abstraktiv MDS-modell (Multi-Document Summarisation), vilket undviker behovet av att träna med referenssammanfattningar. En av delbelöningsfunktionerna kommer att läras interaktivt från användarfeedback för att säkerställa samstämmigheten mellan användarnas krav och den genererade tidslinjen. De andra delbelöningsfunktionerna bidrar till aktuell samstämmighet och språklig flytning. Vi planerar experiment för att utvärdera om vårt tillvägagångssätt kan generera exakta och exakta tidslinjer anpassade för varje användare.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Uhitimisho wa muda mfupi (TLS) unalenga kutengeneza orodha ya matukio yanayoamrishwa kwa muda unaoandikwa katika vyanzo kama vile makala za habari. Hata hivyo, mifumo ya sasa hazina njia ya kutosha ya kubadilishana na maeneo mapya wala kuyatazama masuala ya maslahi kwa mtumiaji fulani. Kwa hiyo, tunapendekeza njia ya kujifunza kwa njia za kujitegemea TLS zenye ubora kwa kutumia mafunzo ya Maendeleo (RL). Tunaweza kufafanua kazi ya malipo ya pamoja na kutumia RL kwa ajili ya kuunganisha mfumo wa Mkutano wa nyaraka kadhaa (MDS), ambao unajitenga na haja ya kufundisha kwa kutumia muhtasari wa maandishi. Moja ya kazi za malipo ya subira itajifunza kwa namna moja kwa moja kutokana na mwitikio wa mtumiaji ili kuhakikisha umuhimu kati ya mahitaji ya watumiaji na simu zilizotengenezwa. Shughuli nyingine za malipo ya subira zinachangia ushirikiano wa mada na ufanisi wa lugha. We plan experiments to evaluate whether our approach could generate accurate and precise timelines tailored for each user.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Timeline Summarisation (TLS) aims to generate a concise, time-ordered list of events described in sources such as news articles. ஆயினும், தற்போதைய கணினிகள் புதிய களங்களுக்கு ஒப்பிட போதுமான வழியைக் கொடுக்கவில்லை அல்லது குறிப்பிட்ட பயனருக்கு த ஆகையால், நாம் ஒரு முறையை திரும்பச் செயல்படுத்த வேண்டிய TLS கற்றுக்கொள்ள ஒரு முறையை பரிந்துரைக்கிறோம். நாம் ஒரு கூட்டு கூலி செயல்கூறை வரையறுக்கிறோம் மற்றும் RL பயன்படுத்தி ஒரு செயல்படுத்தப்பட்ட பல்ஆவண சுருக்கம் (MDS) மாதிரியை பயன்படுத்துகிறோம், அது துணை பூர்த்தி செயல்பாடுகளில் ஒன்று பயனர் செயல்பாடுகளின் செயல்பாடுகளிலிருந்து செயல்படுத்தப்படும் பயனர் தேவைகள் மற்றும் உருவா மற்ற துணை பூர்த்தி செயல்பாடுகள் தலைப்பு ஒன்றிணைப்புகளுக்கும் மொழியில் தெளிவான விளைவுகளுக்கும் ஒவ்வொரு பயனருக்கும் சரியான மற்றும் சரியான நேர வரிகளை உருவாக்க முடியுமா என்று பரிசோதிப்போம்.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Zaman hatlary Toplaýyşy Ýöne häzirki sistemler täze sahypa üýtgetmek üçin ýeterli ýoly saýlamaýarlar, we munyň wajyp ullanyşyň nähili gyzyklanmagyny üçin üns bermeýärler. Şol sebäpli, abstraktiwny TLS öwrenmegi üçin bir täze teklip edip görýäris. Biz birleşik täsirli fonksiýany tanyşdyrýarys we soňra bir çoklu-sened jemgyýeti düzenlemek üçin RL'i ulanýarys we bu şekilde çykyş sumlaryny ulanmakdan uzaklaşdyrylýar. Ullançylaryň talaplarynyň we üretilen wagtlyk hatlaryň barlygyny garaşdyrmak üçin alt-täsirli fonksiýalarynyň biri aktiw olara öwrenip biler. Başga üýtgetmeli işlemler meýdança bir ýerleşmeligine we dil ýerleşmeligine kömekleýär. Biz özümiziň ýaryşymyzyň dogry we dogry zamanlyk çykarylyklaryň her Ulaşçy üçin üýtgedilýändigini çözmek üçin deneyleri planlaýarys.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Timeline Summarisation (TLS) کا ارادہ یہ ہے کہ سورجوں میں واضح ہونے والی حادثوں کی ایک قطعہ، زمان سفارش کی لکھ پیدا کرے۔ لیکن موجود سیستموں نے نئی ڈومین کے ساتھ اچھی طرح نہیں دی ہے اور نہ کسی خاص کاربر کے علاقے پر تمرکز کرنا ہے. لہٰذا، ہم ایک طریقہ پیشنهاد کرتے ہیں کہ آب تراکٹیو TLS کی استعمال کریں (RL) کے مطابق ایک طریقہ سکھائیں۔ ہم ایک متصلہ اجرت کا فرقہ مقرر کرتے ہیں اور RL کو استعمال کرتے ہیں کہ ایک مثبت multi-document Summarisation (MDS) موڈل (مثبت) کو مثبت کر سکیں، جو مرتبہ جمع کے مطابق تطالب کرنے کی ضرورت سے روکتی ہے۔ سوب-پاداش کا ایک فنکٹ یوسف یوسف فیڈبک سے پیدا کیا جائے گا تاکہ کارساز کی خواہشوں اور پیدا کیے ہوئے تایملین کے درمیان اتصال کرے۔ اور دوسری کمائی کے فناوروں نے ٹوپائیل کی ملکیت اور زبان کی ملکیت میں اضافہ کیا ہے۔ ہم آزمائش کی تدبیروں کی تدبیر کریں گے کہ ہمارا طریقہ دقیق اور دقیق تایملین پیدا کرے جو ہر کاربر کے لئے تدبیر کی گئی ہے۔</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>@ info: whatsthis Lekin, joriy tizim yangi domen bilan moslash uchun yetarli usulni koʻrsatilmaydi va foydalanuvchiga foydalanuvchi qiymatlariga foydalanish uchun foydalanuvchini foydalanishi mumkin. Shunday qilib, biz Reinforcement o'rganish (RL) yordamida avto'g'ri bo'lgan TLS o'rganish usulini tahlil qilamiz. Biz bir kompyuterning muvaffaqiyatlarni aniqlash va RL'ni ajratish uchun katta hujjat hisobotini (MDS) modeliga foydalanamiz. Bu muammolar hisobotidan foydalanish kerak emas. Name Boshqa sub-payt funksiyalari mavjud birlashtirish va tillarda foydalanadi. Biz bir foydalanuvchiga tayyorlangan taymaviy va taymaviy vaqtlarni yaratish uchun imtiyozlarni qiymatga qaramamiz.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Lát nữa sẽ có buổi khai đại (TLS) nhằm tạo ra một danh sách các sự kiện ngắn gọn, được đặt ra theo thời gian diễn tả trong các nguồn tin như bản tin. Tuy nhiên, hệ thống hiện tại không cung cấp một cách thích hợp để thích nghi với lĩnh vực mới hay tập trung vào các khía cạnh quan tâm đối với một người dùng cụ thể. Do đó, chúng tôi đề xuất phương pháp học tập trừu tượng TLS bằng cách tiếp cận học tủy sống (RL). Chúng tôi xác định một hàm phần thưởng phức tạp và dùng RL để chỉnh sửa một kiểu tổ chức đa tài liệu trừu tượng (MDS) để tránh việc huấn luyện bằng các bản tóm tắt tham khảo. Một trong các chức năng phần thưởng sẽ được học tương tác từ phản hồi của người dùng để đảm bảo sự đồng nhất giữa yêu cầu của người dùng và dòng thời gian đã tạo ra. Các chức năng tiền thưởng khác đóng góp cho sự đồng bộ thời sự kiên trì. Chúng tôi lên kế hoạch thử nghiệm để xem phương pháp của chúng ta có thể tạo ra dòng thời gian chính xác cho mỗi người dùng không.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>时间轴摘要(TLS)旨在生成新闻文章等事简明,以时序列。 然目前之统,未有适特定用户之宜也。 故吾言强化学(RL)交学抽象TLS之道也。 吾义了一复合奖函数,并用 RL 微抽象之多文档摘要 (MDS) 模样,以免参考摘要训练之用。 其一奖励功能,将以交互方式学于用户反馈,以保用户成之时间表一致性。 其他次级奖功有助于主题连贯性语言流利性。 吾计实验之,以估吾法为用户量身定确之时间表。</span></div></div><dl><dt>Anthology ID:</dt><dd>2021.internlp-1.4</dd><dt>Volume:</dt><dd><a href=/volumes/2021.internlp-1/>Proceedings of the First Workshop on Interactive Learning for Natural Language Processing</a></dd><dt>Month:</dt><dd>August</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Online</dd><dt>Venues:</dt><dd><a href=/venues/acl/>ACL</a>
| <a href=/venues/ijcnlp/>IJCNLP</a>
| <a href=/venues/internlp/>InterNLP</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>25–31</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.internlp-1.4>https://aclanthology.org/2021.internlp-1.4</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/2021.internlp-1.4 title="To the current version of the paper by DOI">10.18653/v1/2021.internlp-1.4</a></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">ye-simpson-2021-proposal</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Yuxuan Ye and Edwin Simpson. 2021. <a href=https://aclanthology.org/2021.internlp-1.4>A Proposal : Interactively Learning to Summarise Timelines by Reinforcement Learning</a>. In <i>Proceedings of the First Workshop on Interactive Learning for Natural Language Processing</i>, pages 25–31, Online. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2021.internlp-1.4>A Proposal : Interactively Learning to Summarise Timelines by Reinforcement Learning</a> (Ye & Simpson, InterNLP 2021)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2021.internlp-1.4.pdf>https://aclanthology.org/2021.internlp-1.4.pdf</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2021.internlp-1.4.pdf title="Open PDF of 'A Proposal : Interactively Learning to Summarise Timelines by Reinforcement Learning'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=A+Proposal+%3A+Interactively+Learning+to+Summarise+Timelines+by+Reinforcement+Learning" title="Search for 'A Proposal : Interactively Learning to Summarise Timelines by Reinforcement Learning' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'A Proposal : Interactively Learning to Summarise Timelines by Reinforcement Learning'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[A Proposal : Interactively Learning to Summarise Timelines by Reinforcement Learning](https://aclanthology.org/2021.internlp-1.4) (Ye & Simpson, InterNLP 2021)</p><ul class=mt-2><li><a href=https://aclanthology.org/2021.internlp-1.4>A Proposal : Interactively Learning to Summarise Timelines by Reinforcement Learning</a> (Ye & Simpson, InterNLP 2021)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Yuxuan Ye and Edwin Simpson. 2021. <a href=https://aclanthology.org/2021.internlp-1.4>A Proposal : Interactively Learning to Summarise Timelines by Reinforcement Learning</a>. In <i>Proceedings of the First Workshop on Interactive Learning for Natural Language Processing</i>, pages 25–31, Online. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>