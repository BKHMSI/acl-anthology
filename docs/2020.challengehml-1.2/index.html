<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>A Multi-modal Approach to Fine-grained Opinion Mining on Video Reviews - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="A Multi-modal Approach to Fine-grained Opinion Mining on Video Reviews" name=citation_title><meta content="Edison Marrese-Taylor" name=citation_author><meta content="Cristian Rodriguez" name=citation_author><meta content="Jorge Balazs" name=citation_author><meta content="Stephen Gould" name=citation_author><meta content="Yutaka Matsuo" name=citation_author><meta content="Second Grand-Challenge and Workshop on Multimodal Language (Challenge-HML)" name=citation_conference_title><meta content="2020/7" name=citation_publication_date><meta content="https://aclanthology.org/2020.challengehml-1.2.pdf" name=citation_pdf_url><meta content="8" name=citation_firstpage><meta content="18" name=citation_lastpage><meta content="10.18653/v1/2020.challengehml-1.2" name=citation_doi><meta property="og:title" content="A Multi-modal Approach to Fine-grained Opinion Mining on Video Reviews"><meta property="og:image" content="https://aclanthology.org/thumb/2020.challengehml-1.2.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2020.challengehml-1.2"><meta property="og:description" content="Edison Marrese-Taylor, Cristian Rodriguez, Jorge Balazs, Stephen Gould, Yutaka Matsuo. Second Grand-Challenge and Workshop on Multimodal Language (Challenge-HML). 2020."><link rel=canonical href=https://aclanthology.org/2020.challengehml-1.2></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2020.challengehml-1.2.pdf>A Multi-modal Approach to Fine-grained Opinion Mining on Video Reviews</a>
<a id=af_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>'n Multimodale toegang tot Fine-grained Opinion Mining op Video Review</a>
<a id=am_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>view-action</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>نهج متعدد الوسائط لتعدين الرأي الدقيق في مراجعات الفيديو</a>
<a id=az_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Video Gözləri haqqında çoxlu modal Yaxınlıq</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Многомодален подход към фино-зърнестото извличане на мнения по видео рецензии</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Name</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>A Multi-modal Approach to Fine-grained Opinion Mining on Video Reviews</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Multimodalni pristup rudarstvu mišljenja o snimkama</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Un enfocament multimodal a la mineria d'opinió fines sobre revisions de vídeo</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Multimodální přístup k jemnozrnnému dolování názorů na video recenze</a>
<a id=da_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>En multimodal tilgang til finkornet opinion minedrift på videoanmeldelser</a>
<a id=de_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Ein multimodaler Ansatz zum feinkörnigen Meinungsbau auf Video-Reviews</a>
<a id=el_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Μια πολυμορφική προσέγγιση για την εξόρυξη λεπτόκοκκων γνωμοδοτήσεων σχετικά με τις αναθεωρήσεις βίντεο</a>
<a id=es_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Un enfoque multimodal para la minería de opinión detallada en las reseñas de vídeo</a>
<a id=et_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Mitmeliigiline lähenemisviis peeneteralisele arvamuse kaevandamisele videoülevaatete teemal</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>یک دسترسی بسیاری از مدل برای ذخیره کردن نظریه‌های نیکو در مورد تحقیقات ویدئو</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Monimuotoinen lähestymistapa hienorakeiseen lausuntojen louhintaan videoarvioinneista</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Une approche multimodale de l'exploration fine des opinions dans les revues vidéo</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Cur Chuige Ilmhódúil maidir le Mianadóireacht Thuairimíochta Mhionchúiseach ar Léirmheasanna Físeáin</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>KCharselect unicode block name</a>
<a id=he_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>גישה רבה-מודלית למכרת דעת מוצקה על שיקולי וידאו</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>वीडियो समीक्षा पर ठीक दानेदार राय खनन के लिए एक बहु-मोडल दृष्टिकोण</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Multimodalni pristup rudarstvu mišljenja o snimkama</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>A finomszemű véleménybányászat multimodális megközelítése videóértékelések alapján</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Տեսագրությունների վերաբերյալ բազմամոդալ մոտեցումը</a>
<a id=id_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>A Multi-modal Approach to Fine-grained Opinion Mining on Video Reviews</a>
<a id=is_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Un approccio multimodale all'estrazione di opinioni a grana fine su video recensioni</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>動画レビューにおける細かい意見の採掘に関する多元的なアプローチ</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>A Multi modal Access to Fine-granted Resolution Minng on Video Resolutions</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Multi modal Approach to Fine-grained Opinion Mining on Video Review</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Видео редакцияларының көптеген модалдық қатынау</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>영상 평론에서 세립도 의견을 발굴하는 다중모드 방법</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Daugiarūšis požiūris į smulkiai apdorotą nuomonę dėl vaizdo apžvalgų kasybos</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Мултимодален пристап до фино растепано мислење за минирање на видео ревизии</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>വീഡിയോ കാഴ്ചകളില്‍ കിട്ടിയ ഓഫിനിയന്‍ മിനിങ്ങിലേക്കുള്ള ഒരു പല-മോഡല്‍ സമീപത്തിലേക്കു്</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Бичлэгийн шалгалтын тухай олон моделийн ойлголт</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Name</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Approċċ multimodali għall-Opinjoni dwar il-Minjieri b'Ħruġ Irfinat dwar ir-Reviżjonijiet tal-Vidjo</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Een multimodale aanpak voor fijnkorrelige opiniemining op video reviews</a>
<a id=no_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Name</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Multimodalne podejście do drobnoziarnistego wydobywania opinii na temat recenzji wideo</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Uma abordagem multimodal para mineração de opinião refinada em análises de vídeo</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>O abordare multimodală a mineritului de opinie cu granule fine pe recenzii video</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Мультимодальный подход к тонкому выяснению мнений по видеообзорам</a>
<a id=si_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>A Multi-Model approach to Fine-Graned oping on Video Revising</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Večmodalni pristop k drobnozrnatem pridobivanju mnenj o video pregledih</a>
<a id=so_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>A Multi-modal Approach to Fine-grained Opinion Mining on Video Reviews</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Një metodë multimodale ndaj minierës së opinionit me kokrra të holla mbi shqyrtimet e videove</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Multimodalni pristup rudarstvu mišljenja o video pregledima</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>En multimodal strategi för finkornig opinionsutvinning på videoomdömen</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Utafiti wa Video unaoendelea kuchukuliwa vizuri</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Name</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>A Multi modal Approach to Fine-grained Opinion Mining on Video Reviews</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>ویڈیو رسانیوں کے بارے میں بہت سی موڈال تقرب</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Name</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>Cách tiếp cận đa phương tiện cho kết quả ổn định</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2020.challengehml-1.2.pdf>视频论中细粒度议所发掘多模式</a></h2><p class=lead><a href=/people/e/edison-marrese-taylor/>Edison Marrese-Taylor</a>,
<a href=/people/c/cristian-rodriguez/>Cristian Rodriguez</a>,
<a href=/people/j/jorge-balazs/>Jorge Balazs</a>,
<a href=/people/s/stephen-gould/>Stephen Gould</a>,
<a href=/people/y/yutaka-matsuo/>Yutaka Matsuo</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Despite the recent advances in <a href=https://en.wikipedia.org/wiki/Opinion_mining>opinion mining</a> for written reviews, few works have tackled the <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> on other sources of reviews. In light of this issue, we propose a multi-modal approach for mining fine-grained opinions from video reviews that is able to determine the aspects of the item under review that are being discussed and the sentiment orientation towards them. Our approach works at the sentence level without the need for time annotations and uses features derived from the audio, video and language transcriptions of its contents. We evaluate our approach on two datasets and show that leveraging the video and audio modalities consistently provides increased performance over text-only baselines, providing evidence these extra modalities are key in better understanding video reviews.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Terwyl die onlangse avansies in die opiëmining vir geskryfde hersienings, het sommige werke die probleem op ander bronne van hersienings gehandel. In die lig van hierdie probleem, voorstel ons 'n multimodaal toegang vir die mining van fyn-graan besonderhede van video hersiening wat kan bepaal die aspekte van die item onder hersiening wat bespreek word en die sentimentorientasie teenoor hulle. Ons toegang werk by die setvlak sonder die benodig vir tyd annotasie en gebruik funksies wat van die oudio, video en taal oordra van sy inhoud afgeleide is. Ons evalueer ons toegang op twee datastelle en wys dat die verwysing van die video en oudiomodaliteite konsistentlik die verhoog van uitvoerings oor slegs teks-baselyne verskaf, en die bevestiging van hierdie ekstra modaliteite is sleutel in beter verstanding van video hersiening.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ከቅርብ ዘመን ጀምሮ የጽሕፈት ጉዳይ መቆጣጠር ምንም እንኳ፣ ጥቂቶች ሥራዎች በሌላ መልዕክቶች ላይ ጉዳዩን ተቃውሞአል፡፡ ከዚህም ጉዳይ በተመለከተው ውይይት የሚታወቁትን እና የሚታወቁትን የጉዳዩን ጉዳይ ማረጋገጥ የሚችሉትን የቪዲዮ መልዕክቶች ለመዘጋጀት የሚቻለውን የብዙ ዓይነት አካባቢ አካሄድን እናስባለን፡፡ የድምፅ፣ የቪዲዮ እና የቋንቋ ጽሑፎችን ለማስፈልጋት የጊዜው ማሰቃየት ሳይያስፈልጋቸው የፍርድ ደረጃን ይሠራል፡፡ በሁለት ዳታተሮች ላይ ያሉትን ሥርዓታችንን እናሳውቃለን፤ የቪዲዮ እና የድምፅ ዓይነቶችን በመስጠት በጽሑፍ-ብቻ መቀመጫዎች ላይ የሚጨመር የድምፅ ሥርዓት እንዲሰጥ እናሳያቸዋለን፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>على الرغم من التطورات الأخيرة في التنقيب عن الرأي للمراجعات المكتوبة ، إلا أن القليل من الأعمال تناولت المشكلة في مصادر أخرى للمراجعات. في ضوء هذه المشكلة ، نقترح نهجًا متعدد الوسائط لاستخراج الآراء الدقيقة من مراجعات الفيديو القادرة على تحديد جوانب العنصر قيد المراجعة التي تتم مناقشتها والتوجه العاطفي تجاهها. يعمل نهجنا على مستوى الجملة دون الحاجة إلى التعليقات التوضيحية الزمنية ويستخدم الميزات المستمدة من نسخ الصوت والفيديو واللغة لمحتوياتها. نقوم بتقييم نهجنا على مجموعتي بيانات ونبين أن الاستفادة من طرائق الفيديو والصوت توفر باستمرار أداءً متزايدًا أكثر من خطوط أساس نصية فقط ، تقدم أدلة على أن هذه الأساليب الإضافية أساسية في فهم مراجعات الفيديو بشكل أفضل.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Yazı xəbərlər üçün qeyri-qiymətlərin məhsullarında qeyri-qiymətlərin gəlib çatmasına rağmen, bəzi işlər başqa xəbərlər üzərində problemi çəkdilər. Bu məsələnin aydınlığında, biz video görüşmələrindən çoxlu modal fikirləri dağıtmaq üçün təklif edirik ki, görüşməkdə olanların aspektlərini və onların tərəfindən hiss göstərilməsini təsdiqləyə bilər. Bizim yaxınlığımız cümlənin səviyyəsində vaxtın məlumatlarının istifadəsi olmadan və səsindən, video və dillərin məlumatlarının istifadəsi olmadan istifadə edir. Biz iki verilən qurğu ilə yaxınlığımızı değerləşdiririk və video və audi modüllərini sürəklə daha yaxşı anlamaq üçün göstəririk.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Въпреки скорошния напредък в търсенето на мнения за писмени рецензии, малко произведения са решили проблема с други източници на рецензии. В светлината на този въпрос предлагаме мултимодален подход за извличане на фини мнения от видео рецензии, който може да определи аспектите на разглежданата тема, които се обсъждат, и ориентацията към тях. Нашият подход работи на ниво изречение без необходимост от времеви анотации и използва функции, получени от аудио, видео и езикови транскрипции на съдържанието му. Ние оценяваме нашия подход върху два набора от данни и показваме, че използването на видео и аудио модификациите последователно осигурява по-висока производителност спрямо базовите линии само за текст, като предоставя доказателства, че тези допълнителни модификации са ключови за по-доброто разбиране на видео ревютата.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>সাম্প্রতিক ভাবে লিখিত পর্যবেক্ষণের জন্য মন্তব্যের খনির উন্নয়ন সত্ত্বেও, অন্যান্য পুনরাবৃত্তির ব্যাপারে কয়েকটি কাজ এই সমস্ এই বিষয়ের আলোকচিত্রে আমরা ভিডিও পর্যবেক্ষণ থেকে ভিডিও পর্যবেক্ষণের জন্য একটি বহুমাত্র মডেল চিন্তা করার প্রস্তাব করছি যা বিষয়টি পর্যবেক্ষণ করা হচ্ছে এবং তাদের প্রতি অনু আমাদের প্রতিযোগিতা সময়ের বিষয়বস্তুর বিষয়বস্তুর অডিও, ভিডিও এবং ভাষা রিপোর্টের প্রয়োজন ছাড়া কাজ করে। আমরা দুই ডাটাসেটে আমাদের পদ্ধতিকে মূল্যায়ন করি এবং দেখাচ্ছি যে ভিডিও এবং অডিও মোডিয়েট বাড়িয়ে দেওয়া ভিডিও এবং শুধুমাত্র লেখার মাধ্যমে বৃদ্ধি প্রদর্</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>བྲིས་ཡིག་གི་ལྟ་ཞིབ་འཇུག དེ་ལྟ་བུའི་དོན་ལྟར། ང་ཚོས་རྣམ་གྲངས་མེད་པའི་མཐུན་སྣུམ་གྱི་བཟོ་རྣམ་པ་ཞིག་བཤད་ཀྱི་ཡོད། ང་ཚོའི་གནད་དོན་འདི་ཚིག་ཡིག་གི་སྐོར ང་ཚོས་རང་གི་ཐབས་ལམ་གནད་གནད་གནད་སྡུད་ཚན་གཉིས་ཀྱི་བཟོ་བཅོས་བྱེད་ཀྱི་ཡོད་ཚད་རྩོལ་བསྐྱེད་བྱས་ནས་བརྙན་གཟུགས་རིས་ཐབས་ལམ་ནང་ལས་སྐྱོན་རྐྱེ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Uprkos nedavnim napredovima rudarstva za pisane preglede, nekoliko radova riješilo je problem na drugim izvorima pregleda. S obzirom na to pitanje, predlažemo multimodalni pristup rudarstvu zgodnih mišljenja iz video pregleda koji može odrediti aspekte predviđenog predmeta koji se raspravljaju i orijentaciju osjećaja prema njima. Naš pristup radi na razini rečenice bez potrebe za vremenskim annotacijom i koristi karakteristike iz audio, video i jezičkih prepisama sadržaja. Procjenjujemo naš pristup na dvije baze podataka i pokazujemo da je uvećanje video i audio modaliteta stalno pružanje povećane učinkovitosti na osnovnim linijama samo teksta, osiguranje dokaza da su ovi dodatni modaliteti ključni u boljem razumijevanju video pregleda.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Malgrat els avanços recents en la mineria d'opinió per a revisions escrites, poces obres han abordat el problema en altres fonts de revisions. A la llum d'aquesta qüestió, proposem un enfocament multi modal per a minerar opinions fines a partir de revisions de vídeo que pugui determinar els aspectes del tema en examen que està debatint i l'orientació del sentiment cap a ells. El nostre enfocament funciona a nivell de frases sense la necessitat d'anotacions temporals i utilitza característiques derivades de les transcripcions d'àudio, vídeo i llenguatge del seu contingut. Evaluam el nostre enfocament en dos conjunts de dades i demostrem que aprofitar les modalitats de vídeo i àudio proporciona consistentment un rendiment més gran sobre les línies de base de només text, proporcionant evidències que aquestes modalitats extra són clau per a entendre millor les revisions de vídeo.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Navzdory nedávnému pokroku v těžbě mínění pro písemné recenze, málo děl řešilo problém na jiných zdrojích recenzí. S ohledem na tuto problematiku navrhujeme multimodální přístup k těžbě jemnozrnných názorů z videorecenzí, který je schopen určit aspekty hodnocené položky, které jsou diskutovány, a orientaci sentimentu k nim. Náš přístup pracuje na úrovni věty bez nutnosti časových anotací a využívá funkce odvozené z audio, video a jazykových přepisů jeho obsahu. Hodnotíme náš přístup na dvou datových sadách a ukážeme, že využití videa a audio modalit důsledně poskytuje zvýšený výkon oproti textovým základním liniím, což poskytuje důkaz, že tyto extra modality jsou klíčové pro lepší porozumění recenzím videa.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>På trods af de seneste fremskridt i opinion mining for skriftlige anmeldelser, har få værker tacklet problemet på andre kilder til anmeldelser. I lyset af dette spørgsmål foreslår vi en multimodal tilgang til udvinding af finkornede meninger fra videoanmeldelser, der er i stand til at bestemme de aspekter af det gennemgåede emne, der drøftes, og følelsesorienteringen over for dem. Vores tilgang fungerer på sætningsniveau uden behov for tidsnoteringer og bruger funktioner afledt af lyd-, video- og sprogtranskriptioner af indholdet. Vi evaluerer vores tilgang på to datasæt og viser, at udnyttelse af video- og lydmodaliteterne konsekvent giver øget ydeevne i forhold til tekstbaserede basislinjer, hvilket beviser, at disse ekstra modaliteter er afgørende for bedre forståelse af videoanmeldelser.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Trotz der jüngsten Fortschritte beim Meinungsbau für schriftliche Rezensionen haben sich nur wenige Arbeiten mit dem Problem anderer Quellen von Rezensionen befasst. Vor diesem Hintergrund schlagen wir einen multimodalen Ansatz für das Mining feinkörniger Meinungen aus Videorezensionen vor, der in der Lage ist, die Aspekte des zu diskutierenden Artikels und die Stimmungsorientierung zu diesen zu bestimmen. Unser Ansatz arbeitet auf Satzebene ohne Zeitannotationen und verwendet Funktionen, die aus den Audio-, Video- und Sprachtranskriptionen des Inhalts abgeleitet werden. Wir evaluieren unseren Ansatz auf zwei Datensätzen und zeigen, dass die Nutzung der Video- und Audiomodalitäten konsistent eine höhere Leistung gegenüber reinen Textbaselines bietet, was beweist, dass diese zusätzlichen Modalitäten der Schlüssel zum besseren Verständnis von Videorezensionen sind.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Παρά τις πρόσφατες εξελίξεις στην εξόρυξη γνώμης για γραπτές κριτικές, λίγα έργα έχουν αντιμετωπίσει το πρόβλημα σε άλλες πηγές κριτικών. Υπό το πρίσμα αυτού του ζητήματος, προτείνουμε μια πολυμορφική προσέγγιση για την εξόρυξη λεπτόκοκκων απόψεων από βιντεοσκοπήσεις, η οποία είναι σε θέση να καθορίσει τις πτυχές του υπό εξέταση θέματος που συζητούνται και τον προσανατολισμό συναισθημάτων προς αυτά. Η προσέγγισή μας λειτουργεί σε επίπεδο προτάσεων χωρίς την ανάγκη για χρονοσχολιασμούς και χρησιμοποιεί χαρακτηριστικά που προέρχονται από τις ηχογραφήσεις, βίντεο και γλωσσικές μεταγραφές του περιεχομένου της. Αξιολογούμε την προσέγγισή μας σε δύο σύνολα δεδομένων και καταδεικνύουμε ότι η αξιοποίηση των μεθόδων βίντεο και ήχου παρέχει σταθερά αυξημένη απόδοση σε σχέση με τις γραμμές βάσης μόνο κειμένου, παρέχοντας αποδεικτικά στοιχεία ότι αυτές οι επιπλέον λεπτομέρειες είναι καθοριστικές για την καλύτερη κατανόηση των αναθεωρήσεων βίντεο.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A pesar de los recientes avances en la minería de opiniones para las revisiones escritas, pocos trabajos han abordado el problema en otras fuentes de reseñas. A la luz de este tema, proponemos un enfoque multimodal para extraer opiniones detalladas de las reseñas de videos que sea capaz de determinar los aspectos del tema en revisión que se están discutiendo y la orientación de los sentimientos hacia ellos. Nuestro enfoque funciona a nivel de oración sin necesidad de anotaciones de tiempo y utiliza características derivadas de las transcripciones de audio, video e idioma de su contenido. Evaluamos nuestro enfoque en dos conjuntos de datos y demostramos que aprovechar las modalidades de video y audio de manera consistente proporciona un mayor rendimiento sobre líneas de base de solo texto, proporcionando evidencia de que estas modalidades adicionales son clave para comprender mejor las reseñas de videos.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vaatamata hiljutistele edusammudele arvamuse kaevandamisel kirjalike arvustuste jaoks, on vähesed tööd lahendanud probleemi teistes arvustusallikates. Seda küsimust silmas pidades pakume välja multimodaalse lähenemisviisi videoülevaatest põhjalike arvamuste kaevandamiseks, mis suudab kindlaks määrata arutatava teema aspektid ja nende suhtes suunatud tunded. Meie lähenemine töötab lausetasemel ilma ajamärgistuste vajaduseta ning kasutab selle sisu audio-, video- ja keeletranskriptsioonidest tulenevaid funktsioone. Hindame oma lähenemisviisi kahe andmekogumi põhjal ja näitame, et video- ja helirežiimide kasutamine tagab järjekindlalt suurema jõudluse ainult tekstipõhiste lähtejoontega võrreldes, tõestades, et need lisarežiimid on videoülevaatete parema mõistmise võtmeks.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>با وجود پیشرفتهای اخیر در نظر خرید کردن برای تحقیقات نوشته، چند کاری در منابع دیگر تحقیقات مشکل را حل کردند. در نور این مسئله، ما پیشنهاد می‌کنیم یک روش متفاوتی برای خریدن نظریه‌های دانه‌های پاکیزه از بازرسی‌های ویدئویی که می‌تواند نقطه‌های بررسی‌کننده‌ای که در موردشان بحث می‌شوند و رهبری احساسات به سویشان تعیین کند. دسترسی ما در سطح جمله بدون نیازی به نوشتن زمانی و از ویدئو، ویدئو و زبان استفاده از ویدئو و ترجمه‌های محتویاتش استفاده می‌کند. ما روش خودمان را بر دو مجموعه داده ارزیابی می‌کنیم و نشان می‌دهیم که تحت تأثیر روش ویدئو و صدا عملکرد بیشتری بر روی خطوط‌های پایین فقط متن می‌دهد، و مدرک‌ها را پیشنهاد می‌دهیم که این روش‌های اضافه‌ای در درک‌های ویدئ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Huolimatta viimeaikaisesta edistyksestä mielipidevaikunnassa kirjallisia arvosteluja varten, harvat teokset ovat käsitelleet ongelmaa muissa arvostelulähteissä. Tämän kysymyksen valossa ehdotamme multimodaalista lähestymistapaa hienojakoisten mielipiteiden louhimiseen videoarvosteluista, jolla voidaan määrittää tarkasteltavana olevan kohteen näkökohdat, joista keskustellaan, ja tunteiden suuntautuminen niitä kohtaan. Lähestymistapamme toimii lausetasolla ilman aikamerkintöjä ja käyttää sisällönsä ääni-, video- ja kielitranskriptioista johdettuja ominaisuuksia. Arvioimme lähestymistapaamme kahden datajoukon perusteella ja osoitamme, että video- ja audiomuotojen hyödyntäminen tarjoaa johdonmukaisesti paremman suorituskyvyn kuin vain tekstiä sisältävien perusviivojen, mikä osoittaa, että nämä ylimääräiset menetelmät ovat avainasemassa videoarvosteluiden ymmärtämisessä.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Malgré les récents progrès réalisés dans la recherche d'opinions pour les revues écrites, peu d'ouvrages ont abordé le problème sur d'autres sources d'avis. À la lumière de ce problème, nous proposons une approche multimodale pour extraire des opinions précises à partir de critiques vidéo, capable de déterminer les aspects de l'élément examiné qui sont discutés et l'orientation du sentiment à leur égard. Notre approche fonctionne au niveau de la phrase sans avoir besoin d'annotations temporelles et utilise des fonctionnalités dérivées des transcriptions audio, vidéo et linguistiques de son contenu.Nous évaluons notre approche sur deux ensembles de données et montrons que l'exploitation des modalités vidéo et audio permet d'améliorer constamment les performances sur des bases textuelles uniquement, fournir des preuves que ces modalités supplémentaires sont essentielles pour mieux comprendre les critiques vidéo.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In ainneoin an dul chun cinn le déanaí i mianadóireacht tuairimí le haghaidh léirmheasanna scríofa, is beag saothar atá tar éis dul i ngleic leis an bhfadhb ar fhoinsí athbhreithnithe eile. I bhfianaise na ceiste seo, molaimid cur chuige ilmhódúil chun tuairimí míne ó léirmheasanna físe a mhianadóireacht a bheidh in ann na gnéithe den mhír faoi athbhreithniú atá á bplé agus an treo meon ina leith a chinneadh. Oibríonn ár gcur chuige ag leibhéal na habairte gan gá le nótaí ama agus úsáideann sé gnéithe a dhíorthaítear ó thras-scríbhinní fuaime, físe agus teanga a bhfuil ann. bunlínte téacs-amháin, ag soláthar fianaise tá na módúlachtaí breise seo ríthábhachtach maidir le tuiscint níos fearr a fháil ar léirmheasanna físe.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bayan da taki masu ƙaranci a cikin kunnuwa na rubutu, aiki kaɗan sun samu matsayin masu kansala masu kansalar matsayin. Yana da haske ga wannan masu al'amarin, Munã buɗa wata hanyoyi wa masu ƙaranci ga hanyoyin abin da aka riƙe masu farin ciki daga matsayin video wanda yake iya iya ƙayyade gafakan abun da ake nuna da su, da juyi zuwa gare su. Mataimakinmu yana aiki da daraja ga hukuma, bã da buƙata wa zartar da lokaci kuma yana amfani da wasu mistakardar da aka samu daga sauti, video da harshen wanda ke cikin shi. Tuna ƙaddara hanyoyinmu a kan daidaita biyu na database kuma Muke nuna cewa idan a iya samar da video da zanen saudi daidai yana da gyarata mai girma a kan rubutun-bango kawai, kuma idan ana bãyar da shaidar ayuka masu ƙaranci, za'a zama maɓalli cikin mafarin mafiya hankalin video.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>למרות התקדמות האחרונות במכרות דעות עבור ביקורות כתובות, מעט עבודות התמודדו עם הבעיה על מקורות אחרים של ביקורות. בהתחשב בנושא הזה, אנו מציעים גישה רבת-מודלית למכרה דעות עצומות מהביקורות וידאו שיכולות לקבוע את היבטים של הנקודה הנבחרת הגישה שלנו עובדת ברמת המשפט ללא הצורך להציעות זמן ומשתמשים בכישורים שנוצרו מתוכנתו של הקולנוע, הוידאו והשפה. אנו מעריכים את הגישה שלנו על שני קבוצות נתונים ולהראות כי השימוש במונדליות וידאו והאודיו באופן קבוע מספק ביצועים גדולים מעל קווי הבסיס טקסט בלבד, לספק ראיות שהמודליות הנוספות האלה הם מפתח בהבנה טובה יותר ביקורות</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>लिखित समीक्षाओं के लिए राय खनन में हाल ही में हुई प्रगति के बावजूद, कुछ कार्यों ने समीक्षाओं के अन्य स्रोतों पर समस्या से निपटा है। इस मुद्दे के प्रकाश में, हम वीडियो समीक्षाओं से ठीक-ठीक राय के खनन के लिए एक बहु-मोडल दृष्टिकोण का प्रस्ताव करते हैं जो समीक्षा के तहत आइटम के पहलुओं को निर्धारित करने में सक्षम है जिस पर चर्चा की जा रही है और उनके प्रति भावना अभिविन्यास। हमारा दृष्टिकोण समय एनोटेशन की आवश्यकता के बिना वाक्य स्तर पर काम करता है और इसकी सामग्री के ऑडियो, वीडियो और भाषा प्रतिलेखन से प्राप्त सुविधाओं का उपयोग करता है। हम दो डेटासेट पर हमारे दृष्टिकोण का मूल्यांकन करते हैं और दिखाते हैं कि वीडियो और ऑडियो तौर-तरीकों का लाभ उठाना लगातार केवल पाठ-केवल बेसलाइन पर प्रदर्शन में वृद्धि प्रदान करता है, सबूत प्रदान करता है कि ये अतिरिक्त तौर-तरीके वीडियो समीक्षाओं को बेहतर ढंग से समझने में महत्वपूर्ण हैं।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Uprkos nedavnim napredovima rudarstva za pisane preglede, nekoliko radova riješilo je problem s drugim izvorima pregleda. S obzirom na to pitanje, predlažemo višemodalni pristup rudarstvu zgodnih mišljenja iz video pregleda koji može utvrditi aspekte predmeta koji se raspravljaju i usmjerenje osjećaja prema njima. Naš pristup radi na razini rečenice bez potrebe za vremenskim annotacijom i koristiti karakteristike iz zvuka, video i jezičkih prepisama sadržaja. Procjenjujemo naš pristup na dvije baze podataka i pokazujemo da je uključenje video i audio modaliteta stalno pružalo povećanu učinku samo na osnovnim linijama teksta, osiguravajući dokaze da su ovi dodatni modaliteti ključni u boljem razumijevanju video pregleda.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Annak ellenére, hogy a közelmúltban előrehaladtak az írásbeli értékelések véleménybányászatában, kevés mű kezelte a problémát más értékelési forrásokkal kapcsolatban. E kérdés fényében multimodális megközelítést javasolunk a videokritikákból származó finomszemcsés vélemények kitermelésére, amelyek képesek meghatározni a vizsgált téma megvitatott aspektusait és az irányuló érzelmi orientációt. Megközelítésünk mondatszinten működik időjegyzések nélkül, és tartalmának hang-, videó- és nyelvi átirataiból származó funkciókat használ. Két adatkészleten értékeljük megközelítésünket, és megmutatjuk, hogy a videó és audio módszerek következetesen nagyobb teljesítményt biztosítanak a csak szöveges alapvonalakhoz képest, bizonyítva, hogy ezek az extra módszerek kulcsfontosságúak a videóértékelések jobb megértéséhez.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Չնայած կարծիքների վերջին զարգացումներին գրավոր վերլուծումների համար, քիչ աշխատանքներ են լուծել խնդիրը վերաբերյալ վերլուծումների այլ աղբյուրներին: Հետևաբար, մենք առաջարկում ենք մի բազմամոդալ մոտեցում, որպեսզի հանդիսանանք տեսագրություններից պատրաստված գեղեցիկ կարծիքներ, որոնք կարողանում են որոշել քննարկվող առարկանի ասպեկտները և զգացմունքների ուղղությունը նրանց նկատմամբ: Մեր մոտեցումը աշխատում է նախադասության մակարդակում առանց ժամանակային նշումների կարիքի և օգտագործում է իր պարունակության ձայնային, տեսագրական և լեզվային հատկությունները: Մենք գնահատում ենք մեր մոտեցումը երկու տվյալների համակարգերի վրա և ցույց ենք տալիս, որ տեսահոլովակի և ձայնային միջոցների օգտագործումը մշտապես տալիս է ավելացված արտադրողականությունը միայն տեքստի հիմնական գծերի վրա, ապացույցնելով, որ այս ավելացյա</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Meskipun kemajuan baru-baru ini dalam penambangan pendapat untuk penelitian tertulis, beberapa pekerjaan telah mengatasi masalah pada sumber penelitian lain. Dalam cahaya isu ini, kami mengusulkan pendekatan multi-modal untuk penambangan pendapat gandum dari ulasan video yang mampu menentukan aspek dari item yang sedang didiskusikan dan orientasi sentimen terhadap mereka. pendekatan kita bekerja di tingkat kalimat tanpa membutuhkan annotasi waktu dan menggunakan ciri-ciri yang berasal dari transkripsi audio, video dan bahasa kandungannya. Kami mengevaluasi pendekatan kami pada dua set data dan menunjukkan bahwa penggunaan modalitas video dan audio secara konsisten menyediakan penambahan prestasi di atas garis dasar teks-hanya, menyediakan bukti bahwa modalitas ekstra ini adalah kunci dalam memahami lebih baik penelitian video.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nonostante i recenti progressi nell'opinion mining per le recensioni scritte, pochi lavori hanno affrontato il problema su altre fonti di recensioni. Alla luce di questo tema, proponiamo un approccio multimodale per estrarre opinioni a grana fine da video recensioni in grado di determinare gli aspetti del punto in esame che sono in discussione e l'orientamento sentimentale verso di essi. Il nostro approccio funziona a livello di frase senza la necessità di annotazioni temporali e utilizza funzionalità derivate dalle trascrizioni audio, video e linguistiche dei suoi contenuti. Valutiamo il nostro approccio su due set di dati e mostriamo che sfruttando le modalità video e audio costantemente fornisce prestazioni migliori rispetto alle linee di base solo testuali, fornendo prove che queste modalità aggiuntive sono fondamentali per una migliore comprensione delle recensioni video.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>書面によるレビューのためのオピニオンマイニングの最近の進歩にもかかわらず、他のレビューのソースでこの問題に取り組んだ作品はほとんどありません。この課題を踏まえ、議論されている審査項目の側面とそれらに対する感情指向を決定することができる、ビデオレビューから細かい意見をマイニングするためのマルチモーダルアプローチを提案します。私たちのアプローチは、時間の注釈を必要とせずに文章レベルで機能し、その内容の音声、ビデオ、および言語の文字起こしに由来する機能を使用します。2つのデータセットに関する私たちのアプローチを評価し、ビデオとオーディオのモダリティを活用することで、テキストのみのベースラインよりも一貫してパフォーマンスが向上することを示し、これらの追加のモダリティがビデオレビューをよりよく理解するための鍵となる証拠を提供します。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>@item:checkbox Genjer-genjer saiki nglakoni cara iki, kita supoyo akeh modal kanggo ngerasah luwih dumadhi winih sing dibutuhke tarjamahan video sing bisa nguasai perusahaan karo perusahaan langgar sampek winih sing berarti ambekan karo perusahaan pentar nggo masalah Awakdhéwé éntuk dhéwé nggawe aturan kanggo nggawe tarjamahan kanggo nakong nggawe tarjamahan lan gunaké peringatan video lan luwih nggawe barang-dilangan. Awak dhéwé éntukno dhéwé nggawe dataset iki dadi lan ngono nggawe barang video karo modalité sing ditambah kuwi nggawe barang kotak dhéwé, njaluké awak dhéwé modalité sing luwih apik lan tambah kuwi nggawe sistem sing luwih apik dhéwé.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>მაგრამ ახალი პროგრესის წარმოდგენების წარმოდგენების მინდომის მინდომის წარმოდგენებისთვის, რამდენიმე სამუშაო პრობლემა სხვა წარმოდგენების ამ პრობლემას განსაზღვრებით, ჩვენ მრავალ მოდიალური პრობლემა ვიდეო განსაზღვრებისთვის, რომელიც შეუძლებელია განსაზღვრებული ელემენტის არსებების განსაზღვრება, რომლებიც განსაზღვრებულიან და მათგანი სენტი ჩვენი წარმოდგენა წარმოდგენის დონეში მუშაობა, რომელიც საჭირო წარმოდგენება და გამოიყენება ფუნქციები, ვიდეო და ენის ტრანქპრების შესახებ. ჩვენ ჩვენი მიღება ორი მონაცემების კონფიგურაციაში და გამოჩვენებთ, რომ ვიდეო და ასეთო მოდიალიტების გამოყენება მხოლოდ ტექსტის მხოლოდ გამოყენება, რომელიც გამოყენება, რომ ეს მეტად მოდიალიტებ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Жазбалардың сұхбаттауларының жаңа жағдайларына қарай, басқа сұхбаттау көзінің мәселесін басқа көзінде шешуге болады. Бұл мәселе бойынша, біз бейне редакцияларының аспекттерін анықтай алатын, және олардың көптеген көптеген мәселелерді бақылау үшін көптеген модельдік тәсілдерді қолданамыз. Біздің тәсіліміміз сөйлеме деңгейінде уақыт жазбаларын керек болмаса және оның мазмұнының аудио, видео және тіл транскриптерінің қасиеттерін қолданады. Біз екі деректер қорларындағы тәсілімізді бағалап, видео және аудио әдістерін тек мәтін негізгі жолдарындағы жұмыс істеу үшін көмектеседі. Бұл қосымша тәсіліктерді білеу үшін көмектес</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>비록 최근 서면 평론의 의견 발굴에 약간의 진전을 거두었지만, 다른 평론 원천에서 이 문제를 해결하는 연구는 매우 드물다.이 문제를 감안하여 우리는 영상 평론에서 세립도 의견을 발굴하는 다중모드 방법을 제시했다. 이 방법은 토론 중인 프로젝트의 각 방면과 이런 방면에 대한 감정 취향을 확정할 수 있다.우리의 방법은 문장 차원에서 작업하기 때문에 주석할 시간이 필요 없고 그 내용의 오디오, 영상과 언어 기록에서 얻은 기능을 사용한다.우리는 두 데이터 집합에서 우리의 방법을 평가한 결과 순수한 텍스트 기선에 비해 영상과 오디오 모델을 이용하여 일치된 성능을 제공했고 이러한 추가 모델이 영상 평론을 더욱 잘 이해하는 데 중요하다는 증거를 제공했다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nepaisant pastarųjų nuomonės gavybos pažangos rašytinėms peržiūroms, keli darbai išspręsė problem ą, susijusią su kitais peržiūros šaltiniais. Atsižvelgdami į šį klausimą siūlome daugiarūšį požiūrį į smulkių grūdų kasybos nuomones iš vaizdo apžvalgų, kad būtų galima nustatyti svarstomo klausimo aspektus ir jų požiūrį. Mūsų požiūris veikia sakinių lygiu, nereikalaujant laiko anotacijų ir naudojant savybes, gautas iš jo turinio garso, vaizdo ir kalbos transkripcijų. Vertiname savo požiūrį į du duomenų rinkinius ir rodome, kad vaizdo ir garso būdų sverto naudojimas nuosekliai užtikrina didesnius rezultatus, palyginti su tik teksto bazinėmis linijomis, ir pateikiame įrodymus, kad šios papildomos sąlygos yra svarbiausios siekiant geriau suprasti vaizdo peržiūras.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>И покрај неодамнешните напредоци во рударството на мислењето за пишувани рецензии, неколку дела го решија проблемот со другите извори на рецензии. Со оглед на ова прашање, предложуваме мултимодален пристап за рудање на фино-растени мислења од видео рецензии кои можат да ги одредат аспектите на предметот кој се разговара и орентацијата на чувствата кон нив. Нашиот пристап функционира на нивото на речениците без потреба од временски анотации и користи карактеристики изведени од аудио, видео и јазички преписи на содржината. Ние го проценуваме нашиот пристап на два датотеки и покажуваме дека употребата на видео и аудио модијалитетите константно обезбедува зголемена резултат над основните линии кои се само текст, обезбедувајќи докази дека овие дополнителни модијалитети се клучни за</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>എഴുതിയ കാര്യങ്ങള്‍ക്കുള്ള അഭിപ്രായത്തില്‍ ഏറ്റവും അടുത്ത മുന്‍ഗണങ്ങള്‍ വരുത്തിയിട്ടുണ്ടെങ്കിലും കുറച്ചു പ്രവര്‍ത്തനങ ഈ പ്രശ്നത്തിന്റെ പ്രകാശത്തില്‍, വീഡിയോ പരിശോധനകളില്‍ നിന്നും നല്ല കൈപ്പിടിക്കപ്പെട്ടിരിക്കുന്ന ആശയങ്ങള്‍ കുറച്ച് കുഴിച്ചുകൊടുക്കാന്‍ ഞങ്ങള്‍ ഒരു പല മ നമ്മുടെ സമ്പ്രദായം വാക്ക് നില്‍ക്കുന്നതിന് സമയത്തെ അഭിനയിക്കുന്നതിന് ആവശ്യമില്ലാതെ പ്രവര്‍ത്തിക്കുന്നു. അതിന്റെ ഉള്ളടക രണ്ടു ഡാറ്റാസറ്റുകളില്‍ നമ്മുടെ നടപടിയെ വിലയിച്ച് കാണിക്കുന്നു. വീഡിയോ ഓഡിയോ രീതികളും കൊടുക്കുന്നത് മാത്രം ടെക്സ്റ്റ് മാത്രം ബേസ്റ്റെലൈ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Сүүлийн үеийн санааны хөгжлийн хөгжлийн үр дүнд хэд хэдэн ажил бусад шалгалтын эх үүсвэрээс асуудлыг зориулсан. Энэ асуудлын ачаар бид бичлэгийн шалгалтын тухай ярилцаж байгаа зүйлсийн асуудлыг тодорхойлох боломжтой олон загварын арга зам өгдөг. Бидний арга баримтууд өгүүлбэрийн түвшинд цаг хугацааны илтгэл шаардлагагүйгээр ажилладаг. Үүний бичлэг, видео болон хэл хэлний дүрсийг ашигладаг. Бид хоёр өгөгдлийн сангийн аргыг үнэлж, бичлэг болон үндэслэлийн арга зам нь текст зөвхөн суурь шугам дээр нэмэгдүүлэхийг харуулж, эдгээр нэмэлт арга зам нь бичлэгийн шинжлэх ухаанд илүү чухал гэдгийг харуулж байна.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Walaupun kemajuan baru-baru ini dalam penambangan pendapat untuk ulasan tertulis, beberapa kerja telah mengatasi masalah pada sumber ulasan lain. Dalam cahaya isu ini, kami cadangkan pendekatan berbilang-modal untuk mengembangkan pendapat-pendapat yang sempurna dari ulasan video yang mampu menentukan aspek item yang sedang diselesaikan dan orientasi perasaan terhadap mereka. pendekatan kita berfungsi pada tahap kalimat tanpa perlukan anotasi masa dan menggunakan ciri-ciri yang berasal dari transkripsi audio, video dan bahasa kandungannya. Kami menilai pendekatan kami pada dua set data dan menunjukkan bahawa penggunaan modaliti video dan audio secara konsisten menyediakan prestasi meningkat atas garis dasar teks-sahaja, menyediakan bukti modaliti tambahan ini adalah kunci dalam memahami lebih baik ulasan video.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Minkejja l-avvanzi reċenti fil-minjieri tal-opinjonijiet għal reviżjonijiet bil-miktub, ftit xogħlijiet indirizzaw il-problema fuq sorsi oħra ta’ reviżjonijiet. Fid-dawl ta’ din il-kwistjoni, qed nipproponu approċċ multimodali għat-tħaffir ta’ opinjonijiet minuri minn reviżjonijiet tal-vidjo li jkun jista’ jiddetermina l-aspetti tal-punt li qed jiġi diskuss u l-orjentazzjoni tas-sensazzjoni lejn dawn. L-approċċ tagħna jaħdem fil-livell tas-sentenza mingħajr il-ħtieġa għal annotazzjonijiet fil-ħin u juża karatteristiċi derivati mit-traskrizzjonijiet awdjo, vidjo u lingwistiċi tal-kontenut tiegħu. Aħna jevalwaw l-approċċ tagħna fuq żewġ settijiet ta’ dejta u nuru li l-ingranaġġ tal-modalitajiet tal-vidjo u l-awdjo b’mod konsistenti jipprovdi prestazzjoni akbar fuq linji bażi tat-test biss, billi nipprovdu evidenza li dawn il-modalitajiet addizzjonali huma kruċjali biex nifhmu aħjar ir-reviżjonijiet tal-vidjo.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ondanks de recente vooruitgang in opinion mining voor geschreven reviews, hebben weinig werken het probleem op andere bronnen van beoordelingen aangepakt. In het licht van dit vraagstuk stellen we een multimodale aanpak voor het ontginnen van fijngranige meningen uit videoreviews voor, die in staat is om de aspecten van het onderwerp te bepalen die worden besproken en de sentimentoriëntatie daartoe. Onze aanpak werkt op zinsniveau zonder de noodzaak van tijdannotaties en maakt gebruik van functies afgeleid van de audio-, video- en taaltranscripties van de inhoud. We evalueren onze aanpak op twee datasets en laten zien dat het gebruik van de video- en audiomodaliteiten consistent betere prestaties biedt dan alleen tekstbaselines, wat aantoont dat deze extra modaliteiten essentieel zijn voor een beter begrip van videoreviews.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Til tross av dei siste avanserte utviklingane i gjennomsnittet for skrivne gjennomsnitt, har få arbeidar løyst problemet på andre kjelder for gjennomsnittet. I gjennomsikt av dette problemet foreslår vi ein fleire modal tilnærming for å minne fine-grained opinionar frå videogjennomsikt som kan bestemme aspektane til elementet under gjennomsikt som vert diskutert og sentimentorientasjonen mot dei. Nærminga vårt fungerer på setningsnivået utan nødvendighet for tidsinnotasjonar og brukar funksjonar ut frå innhaldet til lyd, video og språk. Vi evaluerer tilnærminga vårt på to datasett og viser at å levera videomodulene og lydsmodulene konsistent tilbyr økt utviklingar over bare tekstbaselinjer, og tilbyr beviser at desse ekstra modulene er nøkkelen i betre forståelse av videogjennomgang.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Pomimo ostatnich postępów w eksploracji opinii w poszukiwaniu pisemnych recenzji, niewiele prac poradziło sobie z problemem innych źródeł recenzji. W świetle tej kwestii proponujemy multimodalne podejście do wydobywania precyzyjnych opinii z recenzji wideo, które jest w stanie określić aspekty omawianej pozycji oraz orientację sentymentu wobec nich. Nasze podejście działa na poziomie zdań bez konieczności stosowania adnotacji czasowych i wykorzystuje funkcje pochodzące z transkrypcji audio, wideo i językowych jego treści. Oceniamy nasze podejście na podstawie dwóch zbiorów danych i pokazujemy, że wykorzystanie metod wideo i audio konsekwentnie zapewnia zwiększoną wydajność w porównaniu z liniami bazowymi wyłącznie tekstowymi, dostarczając dowodów, że te dodatkowe metody są kluczowe do lepszego zrozumienia recenzji wideo.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Apesar dos avanços recentes na mineração de opinião para resenhas escritas, poucos trabalhos abordaram o problema em outras fontes de resenhas. À luz desta questão, propomos uma abordagem multimodal para mineração de opiniões refinadas de revisões de vídeo que seja capaz de determinar os aspectos do item sob revisão que estão sendo discutidos e a orientação do sentimento em relação a eles. Nossa abordagem funciona no nível da frase sem a necessidade de anotações de tempo e usa recursos derivados das transcrições de áudio, vídeo e linguagem de seu conteúdo. linhas de base somente de texto, fornecendo evidências de que essas modalidades extras são essenciais para entender melhor as revisões de vídeo.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>În ciuda progreselor recente în opinia mining pentru recenzii scrise, puține lucrări au abordat problema altor surse de recenzii. Având în vedere această problemă, propunem o abordare multimodală pentru extragerea de opinii fine din recenzii video, care să poată determina aspectele subiectului examinat care sunt discutate și orientarea sentimentală față de acestea. Abordarea noastră funcționează la nivelul propozițiilor fără a fi nevoie de adnotări de timp și utilizează caracteristici derivate din transcrierile audio, video și lingvistice ale conținutului său. Evaluăm abordarea noastră pe două seturi de date și arătăm că utilizarea modalităților video și audio oferă în mod constant performanță sporită față de liniile de referință numai text, oferind dovezi că aceste modalități suplimentare sunt esențiale pentru o mai bună înțelegere a recenziilor video.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Несмотря на недавние достижения в области изучения общественного мнения для письменных обзоров, лишь немногие работы были посвящены этой проблеме из других источников обзоров. В свете этого вопроса мы предлагаем мультимодальный подход к майнингу мелкозернистых мнений из видео обзоров, который способен определить аспекты рассматриваемого пункта, которые обсуждаются, и ориентацию настроений на них. Наш подход работает на уровне предложений без необходимости временных аннотаций и использует функции, полученные из аудио-, видео- и языковых транскрипций его содержимого. Мы оцениваем наш подход на двух наборах данных и показываем, что использование видео- и аудиомодулей последовательно обеспечивает повышенную производительность по сравнению с базовыми линиями только для текста, предоставляя доказательства того, что эти дополнительные модальности являются ключевыми для лучшего понимания видеообзоров.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ලියපු පරීක්ෂණය සඳහා අලුත් ප්‍රධානයක් තියෙනවා නමුත්, වැඩ කිහිපයක් අනිත් පරීක්ෂණයේ ප්‍රශ්නයක් විසිද මේ ප්‍රශ්නයේ ලයිට්, අපි ප්‍රශ්නයක් කරනවා වීඩියෝ පරීක්ෂණයෙන් ප්‍රශ්නයක් සඳහා විද්‍යාප්‍රශ්නයක් ප්‍රශ්නයක් වෙනුවෙන් විද්‍යාප්‍රශ් අපේ වාර්තාව වාර්තාවට වැඩ කරන්නේ වාර්තාවට අවශ්‍ය නැති වෙලාවක් නැති වෙලාවක් විතරයි, ඔඩියෝ, වීඩියෝ සහ භාෂ අපි දත්ත සටහන් දෙකක් විදිහට අපේ විදිහට පරීක්ෂා කරනවා ඒ වගේම වීඩියෝ සහ ඔඩියෝ සාධාරණය සාමාන්‍ය විතරයි පාළුවන් විතරයි, පාළුව</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kljub nedavnemu napredku pri iskanju mnenj za pisne recenzije se je težavo lotilo le malo del drugih virov recenzij. Glede na to vprašanje predlagamo multimodalni pristop k izkopavanju drobnozrnatih mnenj iz video pregledov, ki lahko določi vidike pregledane točke, o katerih razpravljamo, in sentimentalno usmerjenost do njih. Naš pristop deluje na nivoju stavka brez potrebe po časovnih opombah in uporablja funkcije, ki izhajajo iz avdio, video in jezikovnih transkripcij vsebine. Naš pristop ocenjujemo na podlagi dveh naborov podatkov in pokažemo, da izkoriščanje video in zvočnih načinov dosledno zagotavlja večjo zmogljivost v primerjavi z osnovnimi vrsticami samo besedila, kar dokazuje, da so te dodatne načine ključnega pomena za boljše razumevanje video pregledov.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Inta kastoo uu horumarintii ugu dambeeyey ee lagu qorayo qoraal baaritaanka aragtida, shaqaalaha yar ayaa dhibaatada ka baaraandegay meelaha kale ee laga fiiriyo. Marka la soo jeedo arinkan, waxaan soo jeedaynaa qaabab kala duduwan oo aan ka soo qaadano fiidiyowga fiidiyowga aragtida oo wanaagsan oo awoodi karo inuu go'aano dhinaca arrimaha laga soo baaraandegayo islamarkaasna aan u soo jeedin aragtida. Dhaqdhaqaalkayagu wuxuu ka shaqeeyaa heerka garsooridda, iyadoon u baahnayn waqtiga la wareejiyo iyo isticmaalka warqadaha ku jira codsiga, fiidiyowga iyo luuqadda. Waxaynu qiimeynaynaa qaababkayaga labada kooban ee macluumaadka, waxaana tusnaa in la soo dirayo fiidiyowga iyo qaababka codowga si joogto ah u sii kordhiso bandhigyada qoraalka oo kaliya, oo lagu siiyo cadeynta qaababkan dheeraadka ah waa muhiim u ah baaritaanka fiidiyowga oo ka wanaagsan.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Megjithë përparimet e fundit në minierën e opinionit për shqyrtimet e shkruara, pak punë kanë trajtuar problem in në burime të tjera të shqyrtimeve. In light of this issue, we propose a multi-modal approach for mining fine-grained opinions from video reviews that is able to determine the aspects of the item under review that are being discussed and the sentiment orientation towards them. Përqasja jonë funksionon në nivelin e fjalëve pa nevojën për anotacione kohore dhe përdor karakteristika të nxjerra nga transkriptimet audio, video dhe gjuhësh të përmbajtjes së saj. We evaluate our approach on two datasets and show that leveraging the video and audio modalities consistently provides increased performance over text-only baselines, providing evidence these extra modalities are key in better understanding video reviews.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Uprkos nedavnim napredovima rudarstva za napisane preglede, nekoliko radova je riješilo problem na drugim izvorima pregleda. S obzirom na to pitanje, predlažemo multimodalni pristup rudarstvu zgodnih mišljenja iz video pregleda koji može odrediti aspekte predviđenog predmeta koji se raspravljaju i orijentaciju sentiment a prema njima. Naš pristup radi na nivou rečenice bez potrebe za vremenskim annotacijom i koristi karakteristike iz zvuka, video i jezičkih prepisa njegovog sadržaja. Procjenjujemo naš pristup na dva podataka i pokazujemo da je uvećanje video i audio modaliteta stalno pružanje povećane funkcije samo na osnovnim linijama teksta, pružanje dokaza da su ovi dodatni modaliteti ključni u boljem razumijevanju video pregleda.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Trots de senaste framstegen inom opinionsutvinning för skriftliga recensioner, har få verk tagit itu med problemet på andra källor till recensioner. Mot bakgrund av denna fråga föreslår vi ett multimodalt tillvägagångssätt för utvinning av finkorniga åsikter från videorecensioner som kan avgöra de aspekter av den granskade punkten som diskuteras och sentimentorienteringen mot dem. Vårt tillvägagångssätt fungerar på meningsnivå utan tidsanteckningar och använder funktioner som härrör från ljud-, video- och språktranskriptioner av innehållet. Vi utvärderar vårt tillvägagångssätt på två datauppsättningar och visar att utnyttjandet av video- och ljudmodaliteterna konsekvent ger ökad prestanda jämfört med textbaserade baslinjer, vilket ger bevis för att dessa extra modaliteter är avgörande för att bättre förstå videorecensioner.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Pamoja na maendeleo ya hivi karibuni katika uchimbaji wa maoni kwa ajili ya matokeo ya kuandika, kazi chache zimechukua tatizo hilo kwenye vyanzo vingine vya maoni. Kwa mujibu wa suala hili, tunapendekeza mbinu za namna mbalimbali za kuchimba maoni yenye vizuri kutoka kwenye mtazamo wa video ambao unaweza kuamua mambo ya suala hili chini ya utafiti ambao unajadiliwa na mitazamo yanayoelekea kwao. Our approach works at the sentence level without the need for time annotations and uses features derived from the audio, video and language transcriptions of its contents. Tutathmini hatua yetu kwenye seti mbili za takwimu na kuonyesha kuwa kutuma video na namna za sauti kwa ujumla huwa inatoa ufanisi wa kuongezeka zaidi ya misingi ya maandishi pekee, na kutoa ushahidi wa namna hizi za ziada ni muhimu kwa kutathmini video bora zaidi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>எழுத்து முடிவுகளுக்கான கருத்து குழந்தையில் சமீபத்தில் முன்னேறுதல் இருந்தாலும், சில வேலை செய்திகள் மற்ற முடிவுகளி இந்த பிரச்சனையின் ஒளியில், நாம் வீடியோ பரிசோதனையில் இருந்து நன்றாக பிடிக்கப்பட்ட கருத்துக்களை குறைக்க ஒரு பல மாற்று வழியை பரிந்துரைக்கிறோம். இது பிரச நேரம் அறிவிப்புகளுக்கு தேவையில்லாமல் எங்கள் அணுகல் வாக்கி மட்டத்தில் வேலை செய்கிறது மற்றும் அதன் உள்ளடக்கங்களின் ஒலி, வீடிய நாம் இரண்டு தரவுத்தளங்களில் எங்கள் செயல்பாட்டை மதிப்பிடுகிறோம் மற்றும் வீடியோ மற்றும் ஒலி வகைகளை வழங்குவதை காட்டுகிறோம் என்று காட்டுகிறோம் என</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ýakynda ýazylan çykyşlar üçin pikir eden täzeliklerde has ýöne birnäçe iş başga çykyşlaryň meseläni çözdi. Bu meseleň ýakynlaşynda, video reviewlerinden gowy görünümleri taýýarlamak üçin köp modal bir yaklaşma teklif edip bilýäris. Bu tema hakynda gürrüňleşen zadyň aspektlerini we olaryň yönünde duýgulanma orjentasyny çözebilir. Biziň ýaryşymyz sözlem derejesinde wagt duýdurmanlary gerek bolmadyk we ses, wideo we dil terjimelerinden gelen özellikleri ulanýar. Biz öz ýaryşymyzy iki datajyk düzümlerinde deňleýäris we video we ses modaliteleriniň düzümlenmesini diňe tekst diňe baseçinlerinde ýokarylýandygyny görkezýäris we bu extra modalitleriň video reviewlerini gowylaşdyrmak üçin has möhümdigini görkezýäris.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>نوشتہ رسانیوں کے لئے اخیر پیشرفتوں کے بغیر، بہت کم کاموں نے دوسرے رسانیوں کے سراسر مشکل کو حل کیا ہے. اس مسئلہ کی روشنی میں ہم نے ویڈیو رسانیوں سے بہت سی موڈال طریقے کی پیشنهاد کرتا ہے جو ان کے بارے میں بحث کیا جاتا ہے اور ان کے بارے میں احساس کی روشنی کا اختیار کرسکتا ہے. ہمارا طریقہ مجلس سطح پر کام کرتا ہے بغیر زمانہ کے اظہار کے اور آڈیو, ویڈیو اور زبان کے منصوبات کی ترنسکرپٹوں سے پھیرے ہوئے فرصت استعمال کرتا ہے. ہم دو ڈاٹ سٹ پر اپنے طریقے کا ارزش کرتے ہیں اور دکھاتے ہیں کہ ویڈیو اور آڈیو موڈلیٹ کو اضافہ کرنا صرف پایس لینوں پر زیادہ فعالیت دیتا ہے، اور یہ اضافہ موڈلیٹ کو دکھاتے ہیں کہ ویڈیو رسی کو اچھی سمجھ میں بہتر ہے.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Yaqinda ochilgan ta ľminlovchi ta ľminlovchi so Ľzlar ro Ľyxati ro Ľy berilganda, boshqa tashqaruv manbalarda bir nechta ishlar muammolarni ko'rib chiqaradi. In light of this issue, we propose a multi-modal approach for mining fine-grained opinions from video reviews that is able to determine the aspects of the item under review that are being discussed and the sentiment orientation towards them. Bizning qismlarimiz gapir darajada ishlaydi, vaqt ta ľminlovchilar kerak emas va tarkibini audio, video va tillar tarkibini ishlatish kerak emas. Biz ikkita ma ľlumotlar tarkibidagi fikrimizni qiymatimiz va video va audio usullarni yozib olishni davom etishimiz mumkin va bu ko Ľproq usullarni faqat matn asosiy satrlaridan foydalanishimizni ko'paytirish mumkin.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mặc dù đã có tiến triển gần đây trong lĩnh vực đào tạo cho các bài kiểm tra viết, ít công việc đã giải quyết vấn đề về các nguồn đánh giá khác. Dựa trên vấn đề này, chúng tôi đề xuất một phương pháp đa chiều để khai thác các ý kiến chi tiết theo cách khác nhau từ các cuốn băng video được xác định các khía cạnh của vấn đề đang được thảo luận và hướng dẫn cảm xúc về nó. Cách tiếp cận của chúng ta có tác dụng ở mức độ án mà không cần ghi chú thời gian và sử dụng các tính năng từ ghi chép âm, video và ngôn ngữ của nó. Chúng tôi đánh giá phương pháp của chúng tôi trên hai bộ dữ liệu và cho thấy nhờ dùng các phương thức video và âm thanh luôn tăng hiệu suất trên những đường cơ bản chỉ có văn bản, cung cấp bằng chứng những phương thức phụ này là chìa khóa để hiểu tốt các bài phê bình video.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>虽近于书面论议,鲜有作者于他论。 凡此诸法,施于视频论掘细粒度,定其正论及情取向。 吾法在句级,无暇注释,并用其音频,视频语转录中使生之功。 吾于两数集上质吾法,而明用视频与音频式始终于纯文本基线之性,证明额外之式,视频论之要也。</span></div></div><dl><dt>Anthology ID:</dt><dd>2020.challengehml-1.2</dd><dt>Volume:</dt><dd><a href=/volumes/2020.challengehml-1/>Second Grand-Challenge and Workshop on Multimodal Language (Challenge-HML)</a></dd><dt>Month:</dt><dd>July</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Seattle, USA</dd><dt>Venues:</dt><dd><a href=/venues/acl/>ACL</a>
| <a href=/venues/challengehml/>Challenge-HML</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>8–18</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.challengehml-1.2>https://aclanthology.org/2020.challengehml-1.2</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/2020.challengehml-1.2 title="To the current version of the paper by DOI">10.18653/v1/2020.challengehml-1.2</a></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">marrese-taylor-etal-2020-multi</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Edison Marrese-Taylor, Cristian Rodriguez, Jorge Balazs, Stephen Gould, and Yutaka Matsuo. 2020. <a href=https://aclanthology.org/2020.challengehml-1.2>A Multi-modal Approach to Fine-grained Opinion Mining on Video Reviews</a>. In <i>Second Grand-Challenge and Workshop on Multimodal Language (Challenge-HML)</i>, pages 8–18, Seattle, USA. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2020.challengehml-1.2>A Multi-modal Approach to Fine-grained Opinion Mining on Video Reviews</a> (Marrese-Taylor et al., Challenge-HML 2020)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2020.challengehml-1.2.pdf>https://aclanthology.org/2020.challengehml-1.2.pdf</a></dd><dt class=acl-button-row>Video:</dt><dd class=acl-button-row><a href=http://slideslive.com/38931259 class="btn btn-attachment btn-sm"><i class="fas fa-video"></i>&nbsp;http://slideslive.com/38931259</a></dd><dt>Data</dt><dd><a href=https://paperswithcode.com/dataset/youtubean>Youtubean</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2020.challengehml-1.2.pdf title="Open PDF of 'A Multi-modal Approach to Fine-grained Opinion Mining on Video Reviews'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=A+Multi-modal+Approach+to+Fine-grained+Opinion+Mining+on+Video+Reviews" title="Search for 'A Multi-modal Approach to Fine-grained Opinion Mining on Video Reviews' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'A Multi-modal Approach to Fine-grained Opinion Mining on Video Reviews'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a>
<a class="btn btn-attachment d-flex flex-wrap justify-content-center" href=http://slideslive.com/38931259 title="Open video for 'A Multi-modal Approach to Fine-grained Opinion Mining on Video Reviews'"><span class="align-self-center px-1"><i class="fas fa-video"></i></span>
<span class=px-1>Video</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[A Multi-modal Approach to Fine-grained Opinion Mining on Video Reviews](https://aclanthology.org/2020.challengehml-1.2) (Marrese-Taylor et al., Challenge-HML 2020)</p><ul class=mt-2><li><a href=https://aclanthology.org/2020.challengehml-1.2>A Multi-modal Approach to Fine-grained Opinion Mining on Video Reviews</a> (Marrese-Taylor et al., Challenge-HML 2020)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Edison Marrese-Taylor, Cristian Rodriguez, Jorge Balazs, Stephen Gould, and Yutaka Matsuo. 2020. <a href=https://aclanthology.org/2020.challengehml-1.2>A Multi-modal Approach to Fine-grained Opinion Mining on Video Reviews</a>. In <i>Second Grand-Challenge and Workshop on Multimodal Language (Challenge-HML)</i>, pages 8–18, Seattle, USA. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>