<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Generalization to Mitigate Synonym Substitution Attacks - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="Generalization to Mitigate Synonym Substitution Attacks" name=citation_title><meta content="Basemah Alshemali" name=citation_author><meta content="Jugal Kalita" name=citation_author><meta content="Proceedings of Deep Learning Inside Out (DeeLIO): The First Workshop on Knowledge Extraction and Integration for Deep Learning Architectures" name=citation_conference_title><meta content="2020/11" name=citation_publication_date><meta content="https://aclanthology.org/2020.deelio-1.3.pdf" name=citation_pdf_url><meta content="20" name=citation_firstpage><meta content="28" name=citation_lastpage><meta content="10.18653/v1/2020.deelio-1.3" name=citation_doi><meta property="og:title" content="Generalization to Mitigate Synonym Substitution Attacks"><meta property="og:image" content="https://aclanthology.org/thumb/2020.deelio-1.3.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2020.deelio-1.3"><meta property="og:description" content="Basemah Alshemali, Jugal Kalita. Proceedings of Deep Learning Inside Out (DeeLIO): The First Workshop on Knowledge Extraction and Integration for Deep Learning Architectures. 2020."><link rel=canonical href=https://aclanthology.org/2020.deelio-1.3></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2020.deelio-1.3.pdf>Generalization to Mitigate Synonym Substitution Attacks</a>
<a id=af_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Generalisasie na verklein sinoniem substitusie aanhegsels</a>
<a id=am_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>ምስሉን በሌላ ስም አስቀምጥ</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>التعميم للتخفيف من هجمات استبدال المرادفات</a>
<a id=az_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Sinonim 쿮lav톛 쿮lav톛l톛rini Q캼d캼rmaq 칲칞칲n Generalizasyon</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Обобщение за смекчаване на атаките за заместване на синонимите</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>সিনোনিম সাবস্টিউটেশন আক্রমণের জন্য সাধারণ</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>ཆ་མཚོན་རྟགས་ལ་ཚབ་སྒྲིག་མཐུད་སྒྲིག་འགོད་བྱེད་པར་བཟོ་བཅོས</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Generalizacija za uključivanje sinonima zamjene napada</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Generalització per mitigar els atacs de substitució de sinònims</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Všeobecnění pro zmírnění synonymních náhradních útoků</a>
<a id=da_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Generalisering til at mindske synonym substitutionsangreb</a>
<a id=de_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Generalisierung zur Abschwächung von Angriffen auf Synonyme-Substitution</a>
<a id=el_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Γενικοποίηση για την άμβλυνση των επιθέσεων υποκατάστασης συνονόμων</a>
<a id=es_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Generalización para mitigar los ataques de sustitución de sinónimos</a>
<a id=et_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Üldine sünonüümi asendamise rünnakute leevendamine</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>ژنرال برای تغییر حمله‌های همگانی</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Yleistäminen synonyymien korvaavien hyökkäysten lieventämiseksi</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Généralisation pour atténuer les attaques par substitution de synonymes</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Ginearálú chun Ionsaithe Ionadaithe Comhchiallacha a Mhaolú</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>@ action</a>
<a id=he_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>הגנרליזציה כדי להקל תקיפות תחליפות סינונים</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>समानार्थी प्रतिस्थापन हमलों को कम करने के लिए सामान्यीकरण</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Generalizacija za uključivanje napada za zamjenu sinonima</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Általánosítás a szinonim helyettesítő támadások enyhítésére</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Comment</a>
<a id=id_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Generalisasi untuk Mitigasi Serangan Substitusi Sinonim</a>
<a id=is_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Generalizzazione per mitigare gli attacchi di sostituzione sinonimi</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>代名詞置換攻撃を軽減するための一般化</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>structural navigation</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>სინონიმის გადაყენება დაკავშირებებისთვის გენერალაცია</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Синонимді алмастыру тіркемелерін шектеу үшін жасау</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>공통화하여 동의어 교체 공격을 경감시키다</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Generalizacija siekiant sumažinti sinonimų pakeitimo atakus</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Generalization to Mitigate Synonym Substitution Attacks</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>സങ്കീര്‍ണ്ണത്തിന്റെ അടിസ്ഥാനത്തിന്റെ പൊതുവാക്കുക</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Хэрэглэгчийн хамгаалалтын хамгаалалтуудыг багасгах</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Jeneralisasi untuk Melawankan Serangan Ganti Sinonim</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Ġeneralizzazzjoni biex jittaffew attakki ta’ sostituzzjoni tas-Sinonimu</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Generalisering om synoniem vervangingsaanvallen te verminderen</a>
<a id=no_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Generalisering for å gjennomføra synonymisk substitusjonsvedlegg</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Uogólnienie w celu ograniczenia ataków zastępczych synonimów</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Generalização para mitigar ataques de substituição de sinônimos</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Generalizarea pentru atenuarea atacurilor de substituție sinonime</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Обобщение для минимизации атак подстановки синонимов</a>
<a id=si_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>සාමාන්‍ය වෙනුවෙන් සමාන්‍ය වෙනුවෙන් සමාන්‍ය වෙනුවෙන් සැකසුම</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Generalizacija za ublažitev napadov nadomestitve sinonimov</a>
<a id=so_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Jaamar u sameeya</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Gjeneralizimi për të lehtësuar sulmet e zëvendësimit të sinonimit</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Generalizacija za ukljuèivanje sinonièkih napada za zamjenu</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Generalisering för att mildra synonym substitutionsattacker</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Umoja wa kushambuliwa kwa Uunganishaji</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>ஒத்திசைப்படுத்தல் அடிக்குகளை கலக்கு செய்</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Synonym Gaýd Edilmelerini Azdyrmak üçin döredilme</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Synonym Substitution Attacks</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Name</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>Chế độ giết người Thần thoại</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2020.deelio-1.3.pdf>泛化以轻同义词代攻</a></h2><p class=lead><a href=/people/b/basemah-alshemali/>Basemah Alshemali</a>,
<a href=/people/j/jugal-kalita/>Jugal Kalita</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Studies have shown that deep neural networks (DNNs) are vulnerable to adversarial examples perturbed inputs that cause DNN-based models to produce incorrect results. One robust adversarial attack in the NLP domain is the synonym substitution. In attacks of this variety, the adversary substitutes words with <a href=https://en.wikipedia.org/wiki/Synonym>synonyms</a>. Since synonym substitution perturbations aim to satisfy all lexical, grammatical, and semantic constraints, they are difficult to detect with automatic syntax check as well as by humans. In this paper, we propose a structure-free defensive method that is capable of improving the performance of DNN-based models with both clean and adversarial data. Our findings show that replacing the embeddings of the important words in the input samples with the average of their synonyms&#8217; embeddings can significantly improve the generalization of DNN-based classifiers. By doing so, we reduce <a href=https://en.wikipedia.org/wiki/Sensitivity_and_specificity>model sensitivity</a> to particular words in the input samples. Our results indicate that the proposed defense is not only capable of defending against adversarial attacks, but is also capable of improving the performance of DNN-based models when tested on benign data. On average, the proposed defense improved the classification accuracy of the CNN and Bi-LSTM models by 41.30 % and 55.66 %, respectively, when tested under adversarial attacks. Extended investigation shows that our defensive method can improve the robustness of nonneural models, achieving an average of 17.62 % and 22.93 % classification accuracy increase on the SVM and XGBoost models, respectively. The proposed defensive method has also shown an average of 26.60 % <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification accuracy</a> improvement when tested with the infamous BERT model.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>klasifikasie-presies vergroot op die SVM en XGBoost-modele, respektief. Die voorgestelde verdedingsmetode het ook 'n gemiddelde van 26. 60% klassifikasie presies verbetering vertoon wanneer deur die verstandige BERT model te testeer. Ons algoritme is generiek genoeg om in enige NLP domein te gebruik en aan enige model wat op enige natuurlike taal opgelei word.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>የኩነቶች መረጃዎች የተዘጋጀው የጠበቀ ሥርዓት በተፈተናው ጊዜ የBERT ሞዴል በተፈተና ጊዜ በቁጥጥር 26.60 በመቶ ክፍተቱን የሚያሳየው፡፡ አሌጎራይማችን በNLP ዶሜን እና በአካባቢው ቋንቋ ማንኛውም ሞዴል ለመጠቀም ይበቃል፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>أظهرت الدراسات أن الشبكات العصبية العميقة (DNNs) معرضة لأمثلة متعارضة - مدخلات مضطربة تتسبب في إنتاج النماذج المستندة إلى DNN لنتائج غير صحيحة. أحد الهجمات العدائية القوية في مجال البرمجة اللغوية العصبية هو استبدال المرادف. في هجمات من هذا النوع ، يستبدل الخصم الكلمات بمرادفات. نظرًا لأن اضطرابات استبدال المرادفات تهدف إلى تلبية جميع القيود المعجمية والنحوية والدلالية ، فمن الصعب اكتشافها من خلال التحقق التلقائي من بناء الجملة وكذلك من قبل البشر. في هذه الورقة ، نقترح طريقة دفاعية خالية من البنية قادرة على تحسين أداء النماذج المستندة إلى DNN مع كل من البيانات النظيفة والمتعارضة. تظهر النتائج التي توصلنا إليها أن استبدال تضمين الكلمات المهمة في عينات الإدخال بمتوسط زخارف مرادفاتها يمكن أن يحسن بشكل كبير تعميم المصنفات المستندة إلى DNN. من خلال القيام بذلك ، نقوم بتقليل حساسية النموذج لكلمات معينة في عينات الإدخال. تشير نتائجنا إلى أن الدفاع المقترح ليس فقط قادرًا على الدفاع ضد الهجمات العدائية ، ولكنه قادر أيضًا على تحسين أداء النماذج المستندة إلى DNN عند اختبارها على بيانات حميدة. في المتوسط ، حسّن الدفاع المقترح دقة التصنيف لنماذج CNN و Bi-LSTM بنسبة 41.30٪ و 55.66٪ على التوالي ، عند اختباره في ظل هجمات معادية. يُظهر التحقيق الموسع أن طريقتنا الدفاعية يمكن أن تحسن متانة النماذج غير العصبية ، محققة متوسط 17.62٪ و 22.93٪
زيادة دقة التصنيف في طرازي SVM و XGBoost ، على التوالي. أظهرت الطريقة الدفاعية المقترحة أيضًا تحسنًا في دقة التصنيف بمعدل 26.60٪ عند اختبارها باستخدام نموذج BERT سيئ السمعة. تعد الخوارزمية الخاصة بنا عامة بما يكفي ليتم تطبيقها في أي مجال من مجالات البرمجة اللغوية العصبية وعلى أي نموذج يتم تدريبه على أي لغة طبيعية.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>SVM və XGBoost modellərində klasifikasiya doğruluğu artır. Bu təbliğ edilən müdafiə metodu, həmçinin sınaqlarında BERT modeli ilə imtahana çəkildikdə ortalama 26,60% klasifikasiya doğruluğunun düzəltməsini göstərdi. Algoritimiz hər NLP domeində və hər təbiətli dildə təhsil edilən modellərə kifayət qədər generikdir.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>повишаване на точността на класификацията при моделите съответно SVM и XGBoost. Предложеният отбранителен метод също показва средно 26,60% подобрение на точността на класификацията при тестване с скандалния модел. Нашият алгоритъм е достатъчно генеричен, за да се прилага във всяка област на НЛП и във всеки модел, обучен на всеки естествен език.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>SVM এবং XGBoost মডেলগুলোতে শ্রেণীকরণের সঠিকভাবে বৃদ্ধি করা হয়েছে। প্রস্তাবিত প্রতিরক্ষার পদ্ধতি ২৬. আমাদের অ্যালগরিদম এনএলপি ডোমেইনে প্রয়োগ করার জন্য যথেষ্ট সৌন্দর্য এবং প্রাকৃতিক ভাষায় যে কোন মডেল প্রশিক্ষণ করা হয় ত</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Studies have shown that deep neural networks (DNNs) are vulnerable to adversarial examples – perturbed inputs that cause DNN-based models to produce incorrect results. NLP domain ནང་དུ་སྤྱི་ཚོགས་པའི་གནད་དོན་ཡུལ་གྱི་འགའ་བ་གཅིག་ནི་synonym substitution རེད། གདོང་རིས་འདིའི་དབྱེ་བ་ནང་གི་བརྗོད་མཁན་གྱི་གཞས་ཚིག་དང་འདྲ་མི་མཚོན་པ་ཚོ་ཚབ་བཅུག་གི་ཡོད། Since synonym substitution perturbations aim to satisfy all lexical, grammatical, and semantic constraints, they are difficult to detect with automatic syntax check as well as by humans. འུ་ཅག་གིས་ཤོག་བྱང་འདིའི་ནང་དུ་རང་དབང་གི་སྒྲིག་འགོད་མིན་ཐང་བའི་ཐབས་ལམ་ཞིག་སྔར་སྤྲོད་ཡོད། དེ་ནི་DNN གཙང་དག་དང་གདོང་ཉེ ང་ཚོའི་findings show that replacing the embeddings of the important words in the input samples with the average of their synonyms' embeddings can significantly improve the generalization of DNN-based classifiers. བྱས་ཙང་བྱས་ན་འོད་ཀྱིས་དབྱིབས་མཐུན་རྐྱེན་བྱས་པར་ངེས་པར་དབྱིབས་ ང་ཚོའི་འབྲུག སྤྱིར་བཏང་བའི་ཉེན་ཁ་བརྗོད་ཀྱིས་རྒྱབ་སྐྱོར་གྱི་དབྱིབས་ཆོས་ཉིད་དེ་གོང་ཡར་རྒྱས་གཏོང་། extended investigation shows that our defensive method can improve the robustness of non-neural models, achieving an average of 17.62% and 22.93%
SVM དང་XGBoost མིག་དཔེ་དབྱིབས་བདེ་སྟངས་ལ་ཆེ་རུ་གཏོང་བ། དམིགས་འཛུགས་ཀྱི་སྲུང་སྐྱོབ་ཐབས་ལམ་ལ་ཞིབ་པས་(BERT)མིག་དཔྱད་དང་བརྟག ང་ཚོའི་སྒྲིག་སྟངས་རྒྱལ་ཁབ་ཡིན་ན་NLP domain་གང་རུང་ནང་དུ་སྤྱོད་བཏང་ན་ཕན་འབྲས་ཡོད་པ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>povećanje točnosti klasifikacije na modele SVM i XGBoost, odnosno. Predložena odbrambena metoda je također pokazala prosječan poboljšanje tačnosti klasifikacije 26,60% kada je testirano s nepoznatim BERT modelom. Naš algoritam je dovoljno generičan da se primjenjuje u bilo kojem domenu NLP-a i na bilo koji model obučen na bilo kojem prirodnom jeziku.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>augmenta la precisió de classificació dels models SVM i XGBoost, respectivament. El mètode defensiu proposat també ha demostrat una mitjana de 26,60% de millora de la precisió de la classificació quan s'ha provat amb el famós model BERT. El nostre algoritme és prou genèric per aplicar-se en qualsevol domini NLP i en qualsevol model entrenat en qualsevol llenguatge natural.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Zvýšení přesnosti klasifikace u modelů SVM a XGBoost. Navržená obranná metoda rovněž prokázala průměrné zlepšení přesnosti klasifikace 26,60% při testování s nechvalně proslulým modelem BERT. Náš algoritmus je dostatečně obecný, aby byl aplikován v jakékoliv NLP doméně a na jakýkoliv model trénovaný na libovolném přirozeném jazyce.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>klassificeringsnøjagtighed stigning på henholdsvis SVM- og XGBoost-modellerne. Den foreslåede defensive metode har også vist en gennemsnitlig forbedring af klassificeringsnøjagtigheden på 26,60%, når den testes med den berygtede BERT-model. Vores algoritme er generisk nok til at blive anvendt i ethvert NLP domæne og til enhver model trænet i ethvert naturligt sprog.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Zunahme der Klassifikationsgenauigkeit bei den Modellen SVM und XGBoost. Die vorgeschlagene defensive Methode hat auch eine durchschnittliche Verbesserung der Klassifikationsgenauigkeit von 26,60% gezeigt, wenn sie mit dem berüchtigten BERT-Modell getestet wurde. Unser Algorithmus ist generisch genug, um in jeder NLP-Domäne und auf jedem Modell angewendet zu werden, das auf jeder natürlichen Sprache trainiert ist.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Αύξηση της ακρίβειας ταξινόμησης στα μοντέλα SVM και XGBoost αντίστοιχα. Η προτεινόμενη αμυντική μέθοδος έχει επίσης δείξει μια μέση βελτίωση της ακρίβειας ταξινόμησης 26,60% όταν δοκιμαστεί με το διαβόητο μοντέλο BERT. Ο αλγόριθμος μας είναι αρκετά γενικός ώστε να εφαρμοστεί σε οποιοδήποτε τομέα και σε οποιοδήποτε μοντέλο εκπαιδευμένο σε οποιαδήποτε φυσική γλώσσα.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Los estudios han demostrado que las redes neuronales profundas (DNN) son vulnerables a ejemplos contradictorios, entradas perturbadas que hacen que los modelos basados en DNN produzcan resultados incorrectos. Un ataque contundente de confrontación en el dominio de la PNL es la sustitución de sinónimos. En ataques de esta variedad, el adversario sustituye palabras por sinónimos. Dado que las perturbaciones de sustitución de sinónimos tienen como objetivo satisfacer todas las restricciones léxicas, gramaticales y semánticas, son difíciles de detectar con la verificación automática de la sintaxis, así como por parte de los humanos. En este artículo, proponemos un método defensivo sin estructura que es capaz de mejorar el rendimiento de los modelos basados en DNN con datos limpios y contradictorios. Nuestros hallazgos muestran que reemplazar las incrustaciones de las palabras importantes en las muestras de entrada con el promedio de incrustaciones de sus sinónimos puede mejorar significativamente la generalización de los clasificadores basados en DNN. Al hacerlo, reducimos la sensibilidad del modelo a palabras particulares en las muestras de entrada. Nuestros resultados indican que la defensa propuesta no solo es capaz de defenderse de ataques adversarios, sino que también es capaz de mejorar el rendimiento de los modelos basados en DNN cuando se prueban con datos benignos. En promedio, la defensa propuesta mejoró la precisión de clasificación de los modelos CNN y Bi-LSTM en un 41,30% y 55,66%, respectivamente, cuando se probó bajo ataques adversarios. La investigación extendida muestra que nuestro método defensivo puede mejorar la robustez de los modelos no neuronales, logrando un promedio de 17,62% y 22,93%
aumento de la precisión de la clasificación en los modelos SVM y XGBoost, respectivamente. El método defensivo propuesto también ha mostrado una mejora promedio de la precisión de la clasificación del 26.60% cuando se prueba con el infame modelo BERT. Nuestro algoritmo es lo suficientemente genérico como para ser aplicado en cualquier dominio de la PNL y en cualquier modelo entrenado en cualquier lenguaje natural.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Klassifikatsioonitäpsus suureneb vastavalt SVM ja XGBoost mudelitel. Kavandatud kaitsemeetod on näidanud ka keskmiselt 26,60% klassifikatsioonitäpsuse paranemist kurikuulsa BERT mudeliga testimisel. Meie algoritm on piisavalt üldine, et seda rakendada mis tahes NLP domeenis ja mis tahes mudelile, mis on koolitatud mis tahes looduskeeles.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>دقیقات classification increase on the SVM and XGBoost models respectively. این روش دفاع پیشنهاد همچنین در حالی که با مدل بدبخت BERT آزمایش می‌شود، در میانگین دفاع دفاع دفاع ۲۶.۶۰ درصد را نشان داده است. الگوریتم ما به اندازه کافی معمولی است که در هر دامنی NLP و به هر مدل که روی هر زبان طبیعی آموزش داده شده است.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>SVM- ja XGBoost-malleissa luokitustarkkuus paranee. Ehdotettu puolustusmenetelmä on myös osoittanut keskimääräisen 26,60%:n parannuksen luokituksen tarkkuudelle, kun sitä on testattu pahamaineisella BERT-mallilla. Algoritmimme on riittävän yleinen käytettäväksi missä tahansa NLP-alueella ja missä tahansa luonnollisella kielellä koulutetussa mallissa.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Des études ont montré que les réseaux neuronaux profonds (DNN) sont vulnérables aux exemples contradictoires, c'est-à-dire aux entrées perturbées qui font que les modèles basés sur les DNN produisent des résultats incorrects. Une attaque contradictoire robuste dans le domaine de la PNL est la substitution de synonymes. Dans les attaques de cette variété, l'adversaire substitue des mots par des synonymes. Puisque les perturbations de substitution de synonymes visent à satisfaire toutes les contraintes lexicales, grammaticales et sémantiques, elles sont difficiles à détecter avec la vérification syntaxique automatique ainsi que par les humains. Dans cet article, nous proposons une méthode défensive sans structure capable d'améliorer les performances des modèles basés sur DNN avec des données propres et contradictoires. Nos résultats montrent que le remplacement des intégrations des mots importants dans les échantillons d'entrée par la moyenne des intégrations de leurs synonymes peut améliorer considérablement la généralisation des classificateurs basés sur DNN. Ce faisant, nous réduisons la sensibilité du modèle à des mots particuliers dans les échantillons d'entrée. Nos résultats indiquent que la défense proposée est non seulement capable de se défendre contre les attaques contradictoires, mais qu'elle est également capable d'améliorer les performances des modèles basés sur le DNN lorsqu'ils sont testés sur des données bénignes. En moyenne, la défense proposée a amélioré la précision de classification des modèles CNN et Bi-LSTM de 41,30 % et 55,66 %, respectivement, lorsqu'ils ont été testés dans le cadre d'attaques contradictoires. Une étude approfondie montre que notre méthode défensive peut améliorer la robustesse des modèles non neuronaux, atteignant une moyenne de 17,62 % et 22,93 %
augmentation de la précision de classification sur les modèles SVM et XGBoost, respectivement. La méthode défensive proposée a également montré une amélioration moyenne de 26,60 % de la précision de classification lorsqu'elle a été testée avec le fameux modèle BERT. Notre algorithme est suffisamment générique pour être appliqué dans n'importe quel domaine de la PNL et à n'importe quel modèle formé sur n'importe quel langage naturel.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tá sé léirithe ag staidéir go bhfuil líonraí néaracha doimhne (DNNanna) i mbaol samplaí sáraíochta - ionchuir suaite a fhágann go mbíonn torthaí míchearta ag samhlacha DNN-bhunaithe. Ionsaí sáraíochta láidir amháin san fhearann NLP is ea an t-ionadú comhchiallach. In ionsaithe den éagsúlacht seo, ionadaíonn an namhaid focail le comhchiallaigh. Ós rud é go bhfuil sé mar aidhm ag suaitheadh ar ionadú comhchiallach gach srian foclóireachta, gramadaí agus séimeantach a shásamh, is deacair iad a bhrath le seiceáil comhréire uathoibríoch agus ag daoine freisin. Sa pháipéar seo, molaimid modh cosanta saor ó struchtúir atá in ann feidhmíocht samhlacha atá bunaithe ar DNN a fheabhsú le sonraí glan agus sáraíochta araon. Léiríonn ár dtorthaí gur féidir feabhas suntasach a chur ar ghinearálú na n-aicmitheoirí atá bunaithe ar DNN trí mheán leabaithe a gcomhchiallaigh a chur in ionad leabú na bhfocal tábhachtach sna samplaí ionchuir. Trí sin a dhéanamh, laghdaítear íogaireacht na samhla i leith focail ar leith sna samplaí ionchuir. Tugann ár dtorthaí le fios go bhfuil an chosaint atá beartaithe ní hamháin in ann cosaint a dhéanamh ar ionsaithe sáraíochta, ach go bhfuil sé in ann freisin feidhmíocht na samhlacha atá bunaithe ar DNN a fheabhsú nuair a dhéantar tástáil ar shonraí neamhurchóideacha. Ar an meán, d'fheabhsaigh an chosaint bheartaithe cruinneas aicmithe na samhlacha CNN agus Bi-LSTM 41.30% agus 55.66%, faoi seach, nuair a tástáladh faoi ionsaithe sáraíochta. Léiríonn imscrúdú leathnaithe gur féidir lenár modh cosanta feabhas a chur ar stóinseacht na múnlaí neamhneuracha, ag baint amach meán de 17.62% agus 22.93%
méadú ar chruinneas aicmithe ar na samhlacha SVM agus XGBoost, faoi seach. Tá sé léirithe ag an modh cosanta atá beartaithe freisin go raibh feabhas ar chruinneas aicmithe 26.60% ar an meán nuair a thástáiltear é leis an tsamhail BERT míchlúiteach. Tá ár n-algartam cineálach go leor le cur i bhfeidhm in aon fhearann NLP agus le haon mhúnla atá oilte ar aon teanga nádúrtha.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Haƙĩƙa, akadi sun nuna cewa zanen tarakin neural (DNNs) sun kasance masu haske a kan misãlai masu motsi - perturated inputi da ke saba da misãlai na DNN-da za'a zartar da matsalan makosa. Babu wani shawarar motsi da aka yi kuskure a cikin NLP's Domen na musanya sunonim. Daga shawarar wannan daban, mai motsi yana musanya magana da sunonim. Tana da musanya surori na synonim don ya yi nufin ya cika duk taurãri, grammati da kuma na sakanti, sai ya yi nau'i a gane su da checkin kowace farat ɗaya da kuma mutum. Ga wannan takardan, Munã buɗa wata shirin tsari wanda ba ta koma ba da komai ba, wanda yana iya iya ƙaranci cikakken misãlai-danne-danne na DNN da duk masu tsari da motsi. FayiyinMu na nuna cewa musanya masu muhimma cikin misãlai da aka shigar a cikin shirin ayuka, yana iya ƙaranci ƙidãya da suka samu'anta na sammakon da suka samu'anta. Kayya, ko da haka, za mu ƙara masu saniya ga misãlai da ke cikin shirin ayuka. Our results indicate that the proposed defense is not only capable of defending against adversarial attacks, but is also capable of improving the performance of DNN-based models when tested on benign data. Gansa da kamma, tsarin da aka gozartar da shi, ya improve tsari ga sifilafin na CNN da Bi-LSM da shekara 41.30% da 55.66%, a lokacin da aka jarraba wajen aikin bayani. Ana nuna cewa, hanyoyinmu na tsari yana iya ƙara tufãfin misalin misalin na'ura, kuma yana sãmu a tsakanin 17,65% da 22,93
QScriptBreakpointsModel Tsarin tsari da aka rufe shi, ya nuna mai tsakanin daraja na 26,60% sifikanci da aka jarraba shi da misalin BERT. Algorityinmu yana da kawaici wanda za'a amfani da shi cikin duk wuyan NLP da zuwa wani misali wanda aka sanar da shi kan wani harshe na asili.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>מחקרים הראו כי רשתות עצביות עמוקות (DNN) פגיעות לדוגמאות נוגדיות – כניסות מופרעות שגורמות לדוגמאות מבוססות על DNN לייצר תוצאות לא נכונות. התקפה יריבית חזקה אחת בתחום NLP היא ההחלפה הסינונימית. In attacks of this variety, the adversary substitutes words with synonyms. Since synonym substitution perturbations aim to satisfy all lexical, grammatical, and semantic constraints, they are difficult to detect with automatic syntax check as well as by humans. בעיתון הזה, אנו מציעים שיטה הגנה ללא מבנה שיכולה לשפר את ההופעה של דוגמנים מבוססים בדנ.אן.אן עם נתונים נקיים ויריבים. הממצאים שלנו מראים שהתחליף של המילים החשובות בדגימות הכניסה עם הממוצע של ההתחליפות של הסינונימים שלהם יכול לשפר באופן משמעותי את הגנרליזציה של מסמכים מבוססים על DNN. על ידי כך, אנחנו מפחידים את רגישות המודל למילים מסויימות בדגימות הכניסה. התוצאות שלנו מצביעות שההגנה המוצעת לא רק מסוגלת להגן נגד תקיפות יריבות, אלא גם מסוגלת לשפר את ההפעלה של דוגמנים מבוססים בדנ"א כשנבחנים על נתונים טובים. בממוצע, ההגנה המוצעת שידרה את מדויקת הסיווג של דוגמני CNN ובי-LSTM ב-41.30% ו-55.66%, בהתאם, כאשר ניסו תחת התקפים יריביים. חקירה מורחבת מראה ששיטת ההגנה שלנו יכולה לשפר את החזקה של דוגמנים לא עצביים, להשיג ממוצע של 17.62% ו-22.93%
הגידול בדיקת הסווג על דוגמנים SVM ו XGBoost, בהתאם. שיטת ההגנה המוצעת הראה גם ממוצע של 26.60% שיפור מדויק מסווג כאשר נבחן עם מודל BERT המפורסם. האלגוריתם שלנו הוא מספיק גנרני כדי שימשיך בכל תחום NLP וכל מודל מאומן על כל שפה טבעית.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>अध्ययनों से पता चला है कि गहरे तंत्रिका नेटवर्क (डीएनएन) प्रतिकूल उदाहरणों के लिए कमजोर हैं - परेशान इनपुट जो डीएनएन-आधारित मॉडल को गलत परिणाम उत्पन्न करने का कारण बनते हैं। एनएलपी डोमेन में एक मजबूत प्रतिकूल हमला समानार्थी प्रतिस्थापन है। इस किस्म के हमलों में, विरोधी शब्दों को पर्यायवाची शब्दों के साथ प्रतिस्थापित करता है। चूंकि पर्यायवाची प्रतिस्थापन का उद्देश्य सभी लेक्सिकल, व्याकरणिक और शब्दार्थ बाधाओं को संतुष्ट करना है, इसलिए उन्हें स्वचालित वाक्यविन्यास जांच के साथ-साथ मनुष्यों द्वारा भी पता लगाना मुश्किल है। इस पेपर में, हम एक संरचना-मुक्त रक्षात्मक विधि का प्रस्ताव करते हैं जो स्वच्छ और प्रतिकूल डेटा दोनों के साथ डीएनएन-आधारित मॉडल के प्रदर्शन में सुधार करने में सक्षम है। हमारे निष्कर्ष ों से पता चलता है कि इनपुट नमूनों में महत्वपूर्ण शब्दों के एम्बेडिंग को उनके पर्यायवाची शब्दों के एम्बेडिंग के औसत के साथ बदलने से डीएनएन-आधारित क्लासिफायरके सामान्यीकरण में काफी सुधार हो सकता है। ऐसा करने से, हम इनपुट नमूनों में विशेष शब्दों के लिए मॉडल संवेदनशीलता को कम करते हैं। हमारे परिणामों से संकेत मिलता है कि प्रस्तावित रक्षा न केवल प्रतिकूल हमलों के खिलाफ बचाव करने में सक्षम है, बल्कि सौम्य डेटा पर परीक्षण किए जाने पर डीएनएन-आधारित मॉडल के प्रदर्शन में सुधार करने में भी सक्षम है। औसतन, प्रस्तावित रक्षा ने सीएनएन और बी-एलएसटीएम मॉडल की वर्गीकरण सटीकता में क्रमशः 41.30% और 55.66% तक सुधार किया, जब प्रतिकूल हमलों के तहत परीक्षण किया गया। विस्तारित जांच से पता चलता है कि हमारी रक्षात्मक विधि गैर-तंत्रिका मॉडल की मजबूती में सुधार कर सकती है, 17.62% और 22.93% की औसत प्राप्त कर सकती है।
वर्गीकरण सटीकता क्रमशः SVM और XGBoost मॉडल पर वृद्धि. प्रस्तावित रक्षात्मक विधि ने कुख्यात BERT मॉडल के साथ परीक्षण किए जाने पर 26.60% वर्गीकरण सटीकता सुधार का औसत भी दिखाया है। हमारा एल्गोरिथ्म किसी भी एनएलपी डोमेन में और किसी भी प्राकृतिक भाषा पर प्रशिक्षित किसी भी मॉडल पर लागू होने के लिए पर्याप्त सामान्य है।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>povećanje točnosti klasifikacije na modele SVM i XGBoost, odnosno. Predložena odbrambena metoda također pokazala je prosječan poboljšanje točnosti klasifikacije 26,60% kada se testira s nepoznatim BERT modelom. Naš algoritam je dovoljno generičan da se primjenjuje u bilo kojem domenu NLP-a i na bilo koji model obučen na bilo kojem prirodnom jeziku.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Az SVM és XGBoost modellek osztályozási pontosságának növekedése. A javasolt védekezési módszer átlagosan 26,60%-os osztályozási pontosságot mutatott a hírhedt BERT modellel történő tesztelés során. Algoritmusunk elég általános ahhoz, hogy bármilyen NLP tartományban és bármilyen természetes nyelven képzett modellre alkalmazhassuk.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>դասակարգման ճշգրիտության աճը համեմատաբար ՎԻՄ-ի և XԳԲուստ-ի մոդելների վրա: Պատրաստված պաշտպանական մեթոդը ցույց է տալիս նաև 26.60 տոկոսի միջին դասակարգման ճշգրտության բարելավումը, երբ փորձարկվում է հայտնի BER մոդելի օգնությամբ: Մեր ալգորիթմը բավականաչափ ընդհանուր է, որպեսզի կիրառվի ցանկացած ՆԼՊ ոլորտում և ցանկացած բնական լեզվի վրա վարժեցված մոդելի վրա:</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>peningkatan akurasi klasifikasi pada model SVM dan XGBoost, respektif. Metode pertahanan yang diusulkan juga menunjukkan rata-rata dari 26,60% peningkatan akurasi klasifikasi ketika diuji dengan model BERT terkenal. Algoritma kita cukup generik untuk dipakai dalam domain NLP apapun dan pada model apapun yang dilatih dalam bahasa alami apapun.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>aumento della precisione di classificazione sui modelli SVM e XGBoost, rispettivamente. Il metodo difensivo proposto ha anche mostrato un miglioramento medio dell'accuratezza della classificazione del 26,60% se testato con il famigerato modello BERT. Il nostro algoritmo è abbastanza generico da essere applicato in qualsiasi dominio NLP e a qualsiasi modello addestrato su qualsiasi linguaggio naturale.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>研究によると、深層ニューラルネットワーク（ DNN ）は、DNNベースのモデルが誤った結果を生み出す原因となる摂動的な入力の対立例に脆弱であることが示されています。 NLPドメインにおける堅牢な対抗攻撃の1つは、代名詞置換である。 この種の攻撃では、敵対者は単語を代名詞に置き換えます。 代名詞置換摂動は、すべての語彙的、文法的、および意味的制約を満たすことを目的としているため、人間だけでなく自動構文チェックでも検出することは困難である。 本稿では、クリーンデータと対抗データの両方でDNNベースのモデルのパフォーマンスを向上させることができる構造フリーの防御方法を提案する。 我々の調査結果は、入力サンプル内の重要な単語の埋め込みを同義語の埋め込みの平均に置き換えることで、DNNベースの分類子の一般化を大幅に改善できることを示しています。 これにより、入力サンプルの特定の単語に対するモデル感度を低下させます。 我々の結果は、提案された防御は、敵対的な攻撃から防御することができるだけでなく、良性データでテストされたときにDNNベースのモデルのパフォーマンスを向上させることができることを示しています。 平均して、提案された防御は、対抗攻撃下で試験された場合、CNNモデルとBi - LSTMモデルの分類精度をそれぞれ41.30%と55.66%改善した。 拡張調査では、当社の防御方法は非神経モデルの堅牢性を向上させることができ、平均17.62 ％および22.93 ％を達成することが示されています。
sVMモデルとXGBoostモデルでそれぞれ分類精度が向上します。提案された防御方法はまた、悪名高いBERTモデルで試験した場合、平均26.60 ％の分類精度向上を示しています。当社のアルゴリズムは、あらゆるNLPドメインおよびあらゆる自然言語でトレーニングされたあらゆるモデルに適用できるほど一般的です。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Iwurung wis nambah karo hal-hal nganggep didalat seneng pisan Neral One bot hostary effect in the NLP domain is the sinanym replaced. Nanging panganan karo perkara-perkara iki, pakan-pakan iki bakal terusah pawaran karo sinanan. Taning Nang kuwi iki, kita supoyo sistem-perusahaan uwis wis dianggap banjure nggawe barang nggawe modèl dadi DNN sing basa dadi wis dianggap karo perusahaan karo perusahaan karo paké. Find and find out that Ngawe Perintah pengguna perusahaan Sensitif kanggo Kemerdekaan kuwi model nang sampulan input Rejalaké awak dhéwé ngerngerti barang nggawe aturan aturan dipunangé ora iso ngubah perusahaan winih kanggo atak omongé, macem iso ngubah dhéwé ngerasakno perusahaan model sing isiné DNN-usul kanggo bisa teka data bendhuwur. Tanggal, supoyo nggunakake perusahaan kanggo ngerasakno dadi angan kelas nang dadi MT karo model bi-LTT, gawe lan 10.30% lan 5.6%, mengko iso disenyakake sak pangan negoro atake opo-terasi. Awakdhéwé éntuk perusahaan anyar tentang dipunangé awak dhéwé iso nggawe barang nggawe model sing gak ngéwé, sampeyan ngono kalaayéh sabên tanggal 18.00% lan 22.9%
--strikethrough Wis Algorithm dhéwé bukane kadaterangan tanggal kanggo aplikasi ning sakjane NLP lan sakjane model sing ditambah ning saben lenggal pribadi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>SVM და XGBoost მოდელში კლასიფიკაციის წესიერება გაზრდება. პროგრამის შესაძლებელი გამოყენება ასევე 26.60% კლასიფიკაციის კონფიკაციის წარმოდგენება, როდესაც გამოცნობა ბერტის მოდელზე. ჩვენი ალგორიტიმ უფრო დინარიფური იქნება, რომელიც NLP დომინში და ყველა მოდელში, რომელიც მორცემულია ნებისმიერი ნაირადი ენაზე.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>SVM және XGBoost үлгілерінде классификациялық дұрыстығын өзгерту. Келтірілген қорғау әдісі сондай-ақ BERT үлгісімен тексергенде орташа 26,60% классификациялық дұрыстығын жақсарту көрсетілді. Алгоритміз NLP доменінде және кез-келген табиғи тілде оқылған кез-келген үлгі үлгілеріне қолданылатын жалпы.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>SVM과 XGBoost 모델의 분류 정밀도가 각각 향상되었습니다.악명 높은 베르토 모형을 사용하여 테스트를 진행할 때 제시된 방어 방법도 평균 26.60%의 분류 정밀도가 높아진 것으로 나타났다.우리의 알고리즘은 모든 NLP 분야와 자연 언어 훈련의 모델에 적용될 수 있는 충분한 통용성을 가지고 있다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>SVM ir XGBoost modelių klasifikacijos tikslumo padidėjimas. Siūlomas gynybos metodas taip pat parodė 26,60 % klasifikacijos tikslumo pagerėjimą, kai bandoma naudojant žymią BERT model į. Mūsų algoritmas yra pakankamai generinis, kad jis būtų taikomas bet kurioje NLP srityse ir bet kuriam modeliui, mokomam bet kokia natūralia kalba.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>зголемување на точноста на класификацијата на моделите SVM и XGBoost, односно. Предложениот одбранбен метод, исто така, покажа просечно подобрување на прецизноста на класификацијата од 26,60 отсто кога се тестира со познатиот модел БЕРТ. Нашиот алгоритм е доволно генеричен за да се примени во било кој домен на НЛП и во било кој модел обучен на било кој природен јазик.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>എസ്‌വിഎം, എക്സ്‌ജിബൂസ്റ്റ് മോഡലുകളിലും ക്ലാസ്ഫിക്കല്‍ ക്ലാസ്റ്റിഫിക്കല്‍ തെളിഞ്ഞിട്ടുണ പ്രൊദ്ദേശിക്കപ്പെട്ട പ്രതിരോധ രീതിയും 26.60% ക്ലാസ്ഫിക്കല്‍ കൃത്രിമ മ മെച്ചപ്പോള്‍ പരീക്ഷിക്കപ്പെട്ട ബെര്‍ട്ടി മ നമ്മുടെ ആല്‍ഗോരിതം സാധാരണ പ്രയോഗപ്പെടുത്താന്‍ പോകുന്നത് എംഎല്‍പി ഡൊമെയിനിലും സ്വാഭാവിക ഭാഷയില്‍ പഠിപ്പിക</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>SVM болон XGBoost загварын тодорхойлолт нь нэмэгддэг. Өөрчлөлтийн хамгаалах арга нь мөн хэмжээний БЕРТ загвартай шалгаж буй үед дундаж 26.60% хувь хуваалцааны тодорхойлолтын тодорхойлолтыг харуулсан байна. Бидний алгоритм нь ямар ч NLP холбоонд, ямар ч байгалийн хэл дээр сургалтын загварт хэрэглэгдэхэд хангалттай ерөнхий хэлбэртэй.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>peningkatan ketepatan klasifikasi pada model SVM dan XGBoost, sama ada. Kaedah pertahanan yang diusulkan juga menunjukkan rata-rata 26.60% peningkatan ketepatan klasifikasi apabila diuji dengan model BERT yang terkenal. Algoritma kita cukup generik untuk dilaksanakan dalam mana-mana domain NLP dan kepada mana-mana model yang dilatih dalam mana-mana bahasa alam.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>żieda fil-preċiżjoni tal-klassifikazzjoni fuq il-mudelli SVM u XGBoost, rispettivament. Il-metodu difensiv propost wera wkoll medja ta’ titjib fil-preċiżjoni tal-klassifikazzjoni ta’ 26.60% meta ttestjat bil-mudell magħruf BERT. L-algoritmu tagħna huwa ġeneriku biżżejjed biex jiġi applikat fi kwalunkwe qasam NLP u għal kwalunkwe mudell imħarreġ fuq kwalunkwe lingwa naturali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>De classificatienauwkeurigheid wordt verhoogd op respectievelijk de SVM- en XGBoost-modellen. De voorgestelde defensieve methode heeft ook een gemiddelde verbetering van 26,60% classificatie nauwkeurigheid aangetoond wanneer getest met het beruchte BERT model. Ons algoritme is generiek genoeg om toegepast te worden in elk NLP domein en op elk model getraind op elke natuurlijke taal.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>øk klassifikasjons akkurat på SVM- og XGBoost- modellen, respectivt. Den foreslåde defensivmetoden har også vist gjennomsnittlig forbedring av klassifikasjonsnøyaktighet på 26,60 % når testet er med den infamous BERT-modellen. Algoritmen vårt er generelt nok for å bruka i alle NLP- domene og i alle modelane som treng på alle naturspråk.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Zwiększenie dokładności klasyfikacji odpowiednio w modelach SVM i XGBoost. Proponowana metoda obronna wykazała również średnią poprawę dokładności klasyfikacji 26,60% podczas testowania z niesławnym modelem BERT. Nasz algorytm jest wystarczająco ogólny, aby być stosowany w dowolnej domenie NLP i w każdym modelu przeszkolonym na dowolnym języku naturalnym.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Estudos mostraram que redes neurais profundas (DNNs) são vulneráveis a exemplos adversários – entradas perturbadas que fazem com que modelos baseados em DNN produzam resultados incorretos. Um ataque adversário robusto no domínio da PNL é a substituição de sinônimos. Em ataques dessa variedade, o adversário substitui palavras por sinônimos. Como as perturbações de substituição de sinônimos visam satisfazer todas as restrições lexicais, gramaticais e semânticas, elas são difíceis de detectar com verificação automática de sintaxe, bem como por humanos. Neste artigo, propomos um método defensivo sem estrutura capaz de melhorar o desempenho de modelos baseados em DNN com dados limpos e adversários. Nossas descobertas mostram que substituir os embeddings das palavras importantes nas amostras de entrada pela média dos embeddings de seus sinônimos pode melhorar significativamente a generalização de classificadores baseados em DNN. Ao fazer isso, reduzimos a sensibilidade do modelo a palavras específicas nas amostras de entrada. Nossos resultados indicam que a defesa proposta não é apenas capaz de se defender contra ataques adversários, mas também é capaz de melhorar o desempenho de modelos baseados em DNN quando testados em dados benignos. Em média, a defesa proposta melhorou a precisão de classificação dos modelos CNN e Bi-LSTM em 41,30% e 55,66%, respectivamente, quando testados sob ataques adversários. Investigação estendida mostra que nosso método defensivo pode melhorar a robustez de modelos não neurais, alcançando uma média de 17,62% e 22,93%
aumento da precisão de classificação nos modelos SVM e XGBoost, respectivamente. O método defensivo proposto também mostrou uma melhoria média de 26,60% na precisão da classificação quando testado com o infame modelo BERT. Nosso algoritmo é genérico o suficiente para ser aplicado em qualquer domínio de PNL e em qualquer modelo treinado em qualquer linguagem natural.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>creșterea preciziei clasificării pe modelele SVM și, respectiv, XGBoost. Metoda defensivă propusă a arătat, de asemenea, o îmbunătățire medie de 26,60% a preciziei clasificării atunci când a fost testată cu infamul model BERT. Algoritmul nostru este suficient de generic pentru a fi aplicat în orice domeniu NLP și oricărui model instruit pe orice limbă naturală.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Исследования показали, что глубокие нейронные сети (ГНС) уязвимы к враждебным примерам – возмущенным входным данным, которые приводят к тому, что модели, основанные на ГНС, дают неверные результаты. Одной из надежных сопернических атак в домене NLP является подмена синонима. В атаках этого рода противник заменяет слова синонимами. Поскольку синонимные замещающие возмущения имеют целью удовлетворить все лексические, грамматические и семантические ограничения, их трудно обнаружить с помощью автоматической проверки синтаксиса, а также людьми. В этой статье мы предлагаем безструктурный защитный метод, который способен улучшить производительность моделей на основе DNN как с чистыми, так и с соперничающими данными. Наши результаты показывают, что замена вложений важных слов во входных образцах на средние значения вложений их синонимов может значительно улучшить обобщение классификаторов на основе DNN. Таким образом, мы уменьшаем чувствительность модели к определенным словам во входных выборках. Наши результаты показывают, что предлагаемая защита не только способна защитить от сопернических атак, но и способна улучшить производительность моделей на основе DNN при тестировании на доброкачественных данных. В среднем предлагаемая защита улучшила точность классификации моделей CNN и Bi-LSTM на 41,30% и 55,66%, соответственно, при тестировании в условиях сопернических атак. Расширенное исследование показывает, что наш защитный метод может повысить устойчивость ненейронных моделей, достигнув в среднем 17,62% и 22,93%
повышение точности классификации на моделях SVM и XGBoost соответственно. Предлагаемый защитный метод также показал среднее улучшение точности классификации на 26,60% при испытании с использованием печально известной модели BERT. Наш алгоритм является достаточно общим для применения в любом домене NLP и к любой модели, обученной любому естественному языку.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>@ info: whatsthis පරීක්ෂණය කරන්න පුළුවන් ආරක්ෂා විධානය පෙන්වන්න පුළුවන් විධානයක් 26.60% විශේෂණ විශේෂණය සමාන්‍ය විශ අපේ ඇල්ගෝරිතම් සාමාන්‍ය භාෂාවට ඇතුලත් ඇති NLP ඩෝමින් වලට ඇතුලත් වෙන්න පුළුවන් ඇති.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Študije so pokazale, da so globoka nevronska omrežja (DNN) občutljiva na kontradikcijske primere – motene vhode, ki povzročajo, da modeli, ki temeljijo na DNN, proizvajajo napačne rezultate. En robustni kontradikcijski napad v domeni NLP je sinonimska nadomestitev. V napadih te sorte nasprotnik nadomesti besede s sinonimi. Ker je namen motenj zamenjave sinonimov zadovoljiti vse leksikalne, slovnične in semantične omejitve, jih je težko zaznati s samodejnim preverjanjem sintakse in tudi s strani ljudi. V prispevku predlagamo obrambno metodo brez strukture, ki je sposobna izboljšati zmogljivost modelov, ki temeljijo na DNN, tako s čistimi kot kontrastnimi podatki. Naše ugotovitve kažejo, da lahko zamenjava vdelav pomembnih besed v vhodnih vzorcih s povprečjem vdelav njihovih sinonimov bistveno izboljša generalizacijo klasifikatorjev na osnovi DNN. S tem zmanjšamo občutljivost modela na določene besede v vhodnih vzorcih. Naši rezultati kažejo, da predlagana obramba ni sposobna samo braniti pred kontradikcijskimi napadi, temveč je sposobna tudi izboljšati učinkovitost modelov, ki temeljijo na DNN, pri testiranju na benignih podatkih. Predlagana obramba je v povprečju izboljšala klasifikacijsko natančnost modelov CNN in Bi-LSTM za 41,30% oziroma 55,66%, ko je bila testirana pod kontrastnimi napadi. Razširjena raziskava kaže, da lahko naša obrambna metoda izboljša robustnost nevronskih modelov in doseže povprečno 17,62% in 22,93%.
Povečanje natančnosti klasifikacije pri modelih SVM oziroma XGBoost. Predlagana obrambna metoda je pokazala tudi povprečno 26,60% izboljšanje natančnosti klasifikacije pri testiranju z zloglasnim BERT modelom. Naš algoritem je dovolj generičen za uporabo v kateri koli domeni NLP in v katerem koli modelu, usposobljenem za kateri koli naravni jezik.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tilmaamaha SVM iyo XGBoost waxaa ku kordhiya fasax rasmi ah. Midabka defence ee la soo jeeday wuxuu sidoo kale tusay abbaaraha 26.60% oo fasax kordhin koritaanka saxda ah marka lagu imtixaamo modelka BERT ee la yaqaan. Algoritnagu waa wax caadi ah oo ku filan in lagu codsado deegaan kasta oo NLP ah iyo tusaale kasta oo lagu baro luqad dabiiciga ah.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>rritja e saktësisë së klasifikimit në modelet SVM dhe XGBoost respektivisht. Metoda e propozuar mbrojtëse ka treguar gjithashtu një përmirësim mesatar prej 26.60% të saktësisë së klasifikimit kur është testuar me modelin e famshëm BERT. Algoritmi ynë është mjaft gjenerik për t'u aplikuar në çdo domeni NLP dhe në çdo model të trajnuar në çdo gjuhë natyrore.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>povećanje točnosti klasifikacije na modele SVM i XGBoost, odnosno. Predložena odbrambena metoda je takođe pokazala prosječno poboljšanje tačnosti klasifikacije 26,60% kada se testira sa nepoznatim BERT modelom. Naš algoritam je dovoljno generičan da se primjenjuje u bilo kojem domenu NLP-a i na bilo koji model obučen na bilo kojem prirodnom jeziku.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Klassificeringsnoggrannheten ökar på SVM- respektive XGBoost-modellerna. Den föreslagna defensiva metoden har också visat en genomsnittlig förbättring av klassificeringsnoggrannheten på 26,60% när den testas med den ökända BERT-modellen. Vår algoritm är tillräckligt generisk för att användas i alla NLP-domäner och för alla modeller som är utbildade på något naturligt språk.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>kuongezeka kwa uhakika wa usawa katika mifano ya SVM na XGBoost, kwa namna fulani. Utawala wa ulinzi unapendekezwa pia umeonyesha wastani wa asilimia 26.60 ya kutangaza maendeleo ya sahihi pale yalipojaribiwa kwa mtindo maarufu wa BERT. Ualgorithi wetu ni wa kawaida wa kutosha kutumika katika maeneo yoyote ya NLP na kwa mtindo wowote wa mafunzo katika lugha yoyote ya asili.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>SVM மற்றும் XGBoost மாதிரிகளில் வகுப்பு சரியான திட்டம் அதிகரிக்கும். பரிந்துரைக்கப்பட்ட பிரெட் மாதிரியால் சராசரி 26.60% வகுப்பு சரியான மேம்படுத்தலை காட்டியுள்ளது. எங்கள் ஆல்gorithm பொதுவான போதுமானது எந்த NLP தளத்திலும் எந்த இயற்கை மொழியிலும் பயிற்சிக்கப்பட்ட மாதிரி</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Sınıfta derejesi SVM we XGBoost nusgalarynda artýar. Önerlenen savunmasyn yöntemi hem 26.60% klasifikasyň derejesi ýüze bardygynda test edilen BERT nusga bilen ortalamasyny görkezildi. Biziň algoritmimiz NLP domaýynda we her täbiň dilinde bilinmeli bir nusga ýeterlik ýagdaýdyr.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>SVM اور XGBoost موڈلوں پر کلاسپیٹ دقیق اضافہ ہوتا ہے۔ پیغمبر کی محافظت طریقہ نے 26.60% کلاسپیٹ کی دقیقیت کے متوسط سفارش کو بھی دکھایا ہے جب کمزور BERT موڈل کے ساتھ آزمائش کی جاتی ہے۔ ہمارا الگوریٹم ہر NLP ڈومین میں اور ہر طبیعی زبان پر آموزش کی مدل پر کافی عمدہ ہے۔</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>@ info: whatsthis Name Bizning algoritmiz - NLP domenni qo'llashga yetarli narsa va tabiiy tilda ta'minlovchi modelga.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Độ chính xác phân loại tăng liên quan đến mẫu SVM và XGBust. Cách phòng thủ đề nghị cũng cho thấy mức độ chính xác trung bình 26.60 khi được thử nghiệm với mô hình BERT nổi tiếng. Thuật to án của chúng tôi đủ đa dạng để được áp dụng trong bất kỳ miền Njala hay bất cứ mẫu nào được đào tạo trên bất kỳ ngôn ngữ tự nhiên.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>论深神经网络(DNN)易对抗性示例,对抗性示例生于DNN。 NLP域中一强对抗性攻者,同义词代也。 凡此诸攻,敌以同义词易单词。 以同义词代扰足词汇、语法、语义约束,难以自语法检查和人工检之。 本文中,设无结构守御之法,所以崇DNN之性,洁对抗性之数也。 臣等考结果表明,将输样本要单词者嵌替为其同义词嵌者平均值可以显DNN分类器之泛化。 因此,我们降了模样对输入样本中特定单词的敏感性。 吾之的结果表明,非徒能守御对抗性攻也,且试之良性数,犹足以崇DNN之性也。 平均言之,对抗性攻而试之,所谓守御将CNN与Bi-LSTM模形之类准确性各崇41.30%55.66%。 广之以明,吾守以崇非神经模之鲁棒性,均致17.62%和22.93%
SVM 与 XGBoost 形之分益高。 所陈守御之法犹见,当试以臭名昭着BERT,类准确性均升26.60%。 算法足以通用,可以NLP域,可以练自然语言。</span></div></div><dl><dt>Anthology ID:</dt><dd>2020.deelio-1.3</dd><dt>Volume:</dt><dd><a href=/volumes/2020.deelio-1/>Proceedings of Deep Learning Inside Out (DeeLIO): The First Workshop on Knowledge Extraction and Integration for Deep Learning Architectures</a></dd><dt>Month:</dt><dd>November</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Online</dd><dt>Venues:</dt><dd><a href=/venues/deelio/>DeeLIO</a>
| <a href=/venues/emnlp/>EMNLP</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>20–28</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.deelio-1.3>https://aclanthology.org/2020.deelio-1.3</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/2020.deelio-1.3 title="To the current version of the paper by DOI">10.18653/v1/2020.deelio-1.3</a></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">alshemali-kalita-2020-generalization</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Basemah Alshemali and Jugal Kalita. 2020. <a href=https://aclanthology.org/2020.deelio-1.3>Generalization to Mitigate Synonym Substitution Attacks</a>. In <i>Proceedings of Deep Learning Inside Out (DeeLIO): The First Workshop on Knowledge Extraction and Integration for Deep Learning Architectures</i>, pages 20–28, Online. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2020.deelio-1.3>Generalization to Mitigate Synonym Substitution Attacks</a> (Alshemali & Kalita, DeeLIO 2020)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2020.deelio-1.3.pdf>https://aclanthology.org/2020.deelio-1.3.pdf</a></dd><dt class=acl-button-row>Video:</dt><dd class=acl-button-row><a href=https://slideslive.com/38939726 class="btn btn-attachment btn-sm"><i class="fas fa-video"></i>&nbsp;https://slideslive.com/38939726</a></dd><dt>Data</dt><dd><a href=https://paperswithcode.com/dataset/imdb-movie-reviews>IMDb Movie Reviews</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2020.deelio-1.3.pdf title="Open PDF of 'Generalization to Mitigate Synonym Substitution Attacks'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Generalization+to+Mitigate+Synonym+Substitution+Attacks" title="Search for 'Generalization to Mitigate Synonym Substitution Attacks' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'Generalization to Mitigate Synonym Substitution Attacks'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a>
<a class="btn btn-attachment d-flex flex-wrap justify-content-center" href=https://slideslive.com/38939726 title="Open video for 'Generalization to Mitigate Synonym Substitution Attacks'"><span class="align-self-center px-1"><i class="fas fa-video"></i></span>
<span class=px-1>Video</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[Generalization to Mitigate Synonym Substitution Attacks](https://aclanthology.org/2020.deelio-1.3) (Alshemali & Kalita, DeeLIO 2020)</p><ul class=mt-2><li><a href=https://aclanthology.org/2020.deelio-1.3>Generalization to Mitigate Synonym Substitution Attacks</a> (Alshemali & Kalita, DeeLIO 2020)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Basemah Alshemali and Jugal Kalita. 2020. <a href=https://aclanthology.org/2020.deelio-1.3>Generalization to Mitigate Synonym Substitution Attacks</a>. In <i>Proceedings of Deep Learning Inside Out (DeeLIO): The First Workshop on Knowledge Extraction and Integration for Deep Learning Architectures</i>, pages 20–28, Online. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>