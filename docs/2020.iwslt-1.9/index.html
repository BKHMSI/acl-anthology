<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>SRPOL’s System for the IWSLT 2020 End-to-End Speech Translation TaskSRPOL’s System for the IWSLT 2020 End-to-End Speech Translation Task - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="SRPOL’s System for the IWSLT 2020 End-to-End Speech Translation TaskSRPOL’s System for the IWSLT 2020 End-to-End Speech Translation Task" name=citation_title><meta content="Tomasz Potapczyk" name=citation_author><meta content="Paweł Przybysz" name=citation_author><meta content="Proceedings of the 17th International Conference on Spoken Language Translation" name=citation_conference_title><meta content="2020/7" name=citation_publication_date><meta content="https://aclanthology.org/2020.iwslt-1.9.pdf" name=citation_pdf_url><meta content="89" name=citation_firstpage><meta content="94" name=citation_lastpage><meta content="10.18653/v1/2020.iwslt-1.9" name=citation_doi><meta property="og:title" content="SRPOL’s System for the IWSLT 2020 End-to-End Speech Translation TaskSRPOL’s System for the IWSLT 2020 End-to-End Speech Translation Task"><meta property="og:image" content="https://aclanthology.org/thumb/2020.iwslt-1.9.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2020.iwslt-1.9"><meta property="og:description" content="Tomasz Potapczyk, Pawel Przybysz. Proceedings of the 17th International Conference on Spoken Language Translation. 2020."><link rel=canonical href=https://aclanthology.org/2020.iwslt-1.9></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL’s System for the IWSLT 2020 End-to-End Speech Translation Task<span class=acl-fixed-case>SRPOL</span>’s System for the <span class=acl-fixed-case>IWSLT</span> 2020 End-to-End Speech Translation Task</a>
<a id=af_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL se Stelsel vir die IWSLT 2020 End- to- End Speech Translation Task</a>
<a id=am_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL's System for the IWSLT 2020 End-to-End Speech Translation Task</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>نظام SRPOL لمهمة ترجمة الكلام من البداية إلى النهاية IWSLT 2020</a>
<a id=az_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL's System for the IWSLT 2020 End-to-End Speech Translation Task</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>Системата на СРПОЛ за задачата за превод на реч от край до край</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>IWSLT ২০২০ শেষ- থেকে শেষ- পর্যন্ত ভাষণ অনুবাদের কাজের জন্য SRPOL সিস্টেম</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL's System for the IWSLT 2020 End-to-End Speech Translation Task</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL-ov sustav za zadatak prevoda govora IWSLT 2020.</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>El Sistema SRPOL per a la tasca de traducció de la llengua final a final IWSLT 2020</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>Systém SRPOL pro komplexní překlad řeči IWSLT 2020</a>
<a id=da_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL's system til IWSLT 2020 End-to-End Tale Oversættelse Opgave</a>
<a id=de_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL's System für die IWSLT 2020 End-to-End Sprachübersetzung</a>
<a id=el_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>Το σύστημα της SRPOL για το έργο ολοκληρωμένης μετάφρασης ομιλίας του IWSLT 2020</a>
<a id=es_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>Sistema de SRPOL para la tarea de traducción de voz de extremo a extremo de IWSLT 2020</a>
<a id=et_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOLi süsteem IWSLT 2020 lõppkõne tõlke ülesandeks</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>سیستم SRPOL برای تاریخ ترجمه سخنرانی IWSLT 2020</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL:n järjestelmä IWSLT 2020:n puhekääntämistehtävään</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>Le système de SRPOL pour la tâche de traduction vocale de bout en bout IWSLT 2020</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>Córas SRPOL do Thasc Aistriúcháin Ó Dheireadh go Deireadh IWSLT 2020</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>@ action</a>
<a id=he_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>מערכת SRPOL למשימה של IWSLT 2020</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>IWSLT 2020 एंड-टू-एंड वाक् अनुवाद कार्य के लिए SRPOL की प्रणाली</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL-ov sustav za IWSLT 2020. zadatak za kraj do kraja prevoda govora</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>Az SRPOL rendszere az IWSLT 2020 teljes beszédfordítási feladatához</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>IwPLT 2020 թվականի վերջ-վերջ խոսքի թարգմանման հանձնարարությունը</a>
<a id=id_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>Sistem SRPOL untuk Tugas Terjemahan Bicara Akhir-Akhir IWSLT 2020</a>
<a id=is_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>Sistema SRPOL per la traduzione vocale end-to-end di IWSLT 2020</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>IWSLT 2020エンドツーエンドの音声翻訳タスクのためのSRPOLのシステム</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>paper size</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL- ის სისტემა IWSLT 2020 ბოლოდან ბოლოდან დასრულებული სიტყვების გასაგრძელება</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL жүйесі IWSLT 2020 End- to End Speech Translation Task</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL의 IWSLT 2020 엔드-투-엔드 음성 번역 임무 시스템</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL strategijos „IWSLT 2020“ vertimo žodžiu užduotis</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>Системот на СРПОЛ за задачата за преведување на говорот од крај до крај на IWSLT 2020</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>IWSLT 2020 അവസാനിക്കുന്നതിനുള്ള SRPOL സിസ്റ്റം</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL's System for the IWSLT 2020 End-to-End Speech Translation Task</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL's System for the IWSLT 2020 End-to-End Speech Translation Task</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>Is-Sistema tal-SRPOL għall-kompitu tat-traduzzjoni tal-kelma mill-aħħar sal-aħħar tal-IWSLT 2020</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL's systeem voor de IWSLT 2020 End-to-End spraakvertaaltaak</a>
<a id=no_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL- systemet for IWSLT 2020 End- to- End Speech Translation Task</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>System SRPOL do kompleksowego tłumaczenia mowy IWSLT 2020</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>Sistema do SRPOL para a tarefa de tradução de fala de ponta a ponta do IWSLT 2020</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>Sistemul SRPOL pentru sarcina de traducere vocală finală IWSLT 2020</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL 's System for the IWSLT 2020 End-to-End Speech Translation Task (Система SRPOL для задачи комплексного перевода речи IWSLT 2020)</a>
<a id=si_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL' s System for the IWSLT 2020End- to- End Talk translation Job</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>Sistem SRPOL za nalogo prevajanja govora od konca do konca IWSLT 2020</a>
<a id=so_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL's system for the IWSLT 2020 End-to-End Speech Translation Task</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>Sistemi i SRPOL për IWSLT 2020</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL-ov sistem za IWSLT 2020. zadatak za kraj do kraja prevoda govora</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL:s system för IWSLT 2020 End-to-End Speech Translation Task</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>Mfumo wa SRPOL kwa ajili ya Task la Tafsiri ya Utafiti</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>IWSLT 2020 முடிவு- முடிவு பேச்சு மொழிபெயர்ப்பு பணிக்கான SRPOL அமைப்பு</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL'iň IWSLT 2020'iň End-to-End Sözi Terjime Görevi</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>IWSLT 2020 End-to-End Speech Translation Task کے لئے SRPOL سیسٹم</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>@ info: whatsthis</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>Hệ thống âm thanh AROL for the IWSLT 2020 End-to-End chuyện Translation Task</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2020.iwslt-1.9.pdf>SRPOL 用 IWSLT 2020 端到端语音译职之统</a></h2><p class=lead><a href=/people/t/tomasz-potapczyk/>Tomasz Potapczyk</a>,
<a href=/people/p/pawel-przybysz/>Pawel Przybysz</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>We took part in the offline End-to-End English to German TED lectures translation task. We based our <a href=https://en.wikipedia.org/wiki/Solution>solution</a> on our last year&#8217;s submission. We used a slightly altered Transformer architecture with ResNet-like convolutional layer preparing the audio input to Transformer encoder. To improve the model&#8217;s quality of translation we introduced two regularization techniques and trained on machine translated Librispeech corpus in addition to iwslt-corpus, TEDLIUM2 andMust_C corpora. Our best <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> scored almost 3 BLEU higher than last year&#8217;s model. To segment 2020 test set we used exactly the same procedure as last year.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ons het deel in die offline End-to-End Engels na Duitse TED-leksies vertaling taak geneem. Ons gebaseer on s oplossing op ons laaste jaar se onderwerp. Ons gebruik 'n bietjie verander Transformer Arkitektuur met ResNet- like konvolusionele laag wat die oudio invoer na Transformer enkoder berei het. Om die model se kwaliteit van vertaling te verbeter, het on s twee regularisasie teknike ingevoer en op masjien vertaling Librispeech corpus in byvoeg by iwslt-corpus, TEDLIUM2 en Must_C corpora. Ons beste model het amper 3 BLES hoër as die laaste jaar se model getel. To segment 2020 test set we used exactly the same procedure as last year.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ወደ አርንሳይ የመጨረሻ-ወደ-መጨረሻ እንግሊዘኛ ወደ ጀርመን ቴድ ትርጓሜዎችን ትርጉም አድራሻ ተጋርተናል፡፡ የቀድሞው ዓመታት ስልጣን ላይ መፍትረታችንን አቀረብን፡፡ የድምፅ ድምፅ አቀማመጥ ወደ ተርጓሚው ኮድ ማዘጋጀት በResNet የሚመስል አካውንት የተለወጠውን የፍጥረት መሠረት አቀራጠልን፡፡ በይslt-corpus፣ TEDLIUM2 እና ሙሉ_C ኮፖርት በቀር ሁለት የሥርዓት አስተዳደር ቴክኖቶችን እና በመሣሪያዎች ላይ የተዘጋጀን የሊብሪፓክ ኮፕስ እና የተማረርን የሞዴል ጥያቄን ለማድረግ ነው፡፡ የቀድሞው ዓመት በ3 ቢልዩን የበለጠ ሞዴል ተቃውሞ ነበር፡፡ በ2020 ፈተና ለመክፈት እንደገና ባለፈው ዓመታት አንድ ሥርዓት ተጠቃሚ ነበር፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>شاركنا في مهمة ترجمة محاضرات TED من الإنجليزية إلى الألمانية من البداية إلى النهاية. لقد استندنا في حلنا إلى تقديمنا العام الماضي. استخدمنا بنية محول معدلة قليلاً مع طبقة تلافيفية تشبه ResNet لتحضير إدخال الصوت إلى ترميز المحولات. لتحسين جودة الترجمة في النموذج ، أدخلنا تقنيتين للتنظيم ودربنا على مجموعة Librispeech المترجمة آليًا بالإضافة إلى iwslt-corpus و TEDLIUM2 و Must_C corpora. أفضل طراز لدينا سجل 3 BLEU أعلى من طراز العام الماضي. لتقسيم مجموعة الاختبار لعام 2020 ، استخدمنا نفس الإجراء تمامًا كما في العام الماضي.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Biz "End-to-End" İngilizce dilində Almanca TED leksiyalarının çevirilməsinə bölüşdük. Biz s on il müs əlmanlarımızın çətinliklərinə dayandıq. Biz ResNet kimi konvolucional səviyyə ilə biraz dəyişdirilmiş Transformer arhitektarını kullandıq. Transformer kodlayıcısına audio girişini hazırlamaq üçün. Modelin tərcümünün keyfiyyətini yaxşılaşdırmaq üçün iki düzgünlük tekniklərini təyin etdik və maşına Librispeech korpusu iwslt-corpus, TEDLIUM2 və Must_C korporasını təhsil etdik. Bizim ən yaxşı modellərimiz son il modelindən az qala 3 BLEU yüksək dəyişdi. 2020-ci segment test təyin etdik ki, biz dünən il ilə həqiqətən də eyni proqramı kullandıq.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Участвахме в офлайн задачата за превод на лекции от английски до немски език. Основахме решението си на представянето от последната година. Използвахме леко променена архитектура на трансформатора с конволюционен слой, подобен на ResNet, подготвящ аудио входа към трансформатора. За да подобрим качеството на превода на модела, въведохме две техники за регулировка и обучихме машинно преведен корпус в допълнение към корпусите. Най-добрият ни модел отбеляза почти 3 по-висока оценка от миналата година. За сегмент 2020 тест комплект използвахме точно същата процедура като миналата година.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>আমরা অফ-লাইন শেষ-থেকে ইংরেজিতে জার্মান টেড ভাষণের অনুবাদ কাজে অংশ নিয়েছি। আমরা গত বছরের আত্মসমর্পণের উপর আমাদের সমাধান ভিত্তি করেছি। আমরা রেসেন্টের মতো বিশ্বাসী স্তরের সাথে একটি সামান্য পরিবর্তনের পরিবর্তন কাঠামো ব্যবহার করেছি ট্রান্সফার্নার এনকোডারে অডিও এই মডেলের অনুবাদের মান উন্নত করার জন্য আমরা দুটি নিয়ন্ত্রণ প্রযুক্তি তুলে ধরেছি এবং ইইজসল-কোর্পাস, টেডিলিউম্২ এবং মেশিন অনুবাদ করা লিব্রিস্পেচ কোর্পাসের আমাদের সর্বোচ্চ মডেল গত বছরের মডেল থেকে প্রায় ৩ বিলিউ বেশি। ২০২০ পরীক্ষা বিভাগের জন্য আমরা গত বছর পর্যন্ত একই প্রক্রিয়া ব্যবহার করেছিলাম।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ང་ཚོས་དྲ་རྒྱའི་ནང་དུ་End-to-End དབྱིན་ཡིག ང་ཚོས་རྗེས་མའི་ལོ་ངོ་མའི་བསམ་བློ་གཏོང་བའི་ཐབས་ཤེས་དེ་གཞི་རྟེན་བྱེད་ཀྱི་ཡོད། We used a slightly altered Transformer architecture with ResNet-like convolutional layer preparing the audio input to Transformer encoder. ང་ཚོའི་མ་དབྱིབས་གྱི་དཔེ་དབྱིབས་ལ་སྒྲིག་འགོད་ཀྱི་རིམ་པ་སྒྲིག ང་ཚོའི་མ་དབྱིབས་འདས་པའི་ལོ་རྣམ་གྲངས་སྔོན་གྱི་མ་དབྱིབས་ཉུང་བའི་ཚད་ལྡན་གྲངས་ཀ་འདི་ཉེ་བར་གསུ ལོ་གྲངས་སྔོན་2020་ཡི་བརྟག་ཞིབ་ཚད་ལ་རྗེས་སུ་ང་ཚོས་དུས་མཐུན་གྱི་ཐབས་ལམ་ལ་མཚུངས་པ་ཡིན།</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Pridružili smo se poslu za prevod na njemačkim TED predavanjima. Na osnovu našeg rješenja na posljednjoj godini podnošenja. Koristili smo malu izmjenjenu arhitekturu transformera sa konvolucionalnim slojem poput ResNet a, pripremajući audio ulaz u koder transformera. Da bi poboljšali kvalitet prevoda modela, predstavili smo dvije regularizacijske tehnike i obučene na mašini prevedeno Librispeech corpus osim iwslt-corpus, TEDLIUM2 i Must_C corpora. Naš najbolji model je skoro 3 BLEU viši od prošlogodišnjeg modela. Za snimanje testa za segment 2020, koristili smo tačno iste procedure kao i prošle godine.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vam participar en la tasca de traducció del final al final de l'anglès a les conferències alemanes TED. Vam basar la nostra solució en la presentació de l'any passat. Vam utilitzar una arquitectura Transformer una mica canviada amb capa convolucionada com ResNet preparant l'entrada d'àudio al codificador Transformer. Per millorar la qualitat de la traducció del model vam introduir dues tècniques de regularizació i vam entrenar en Librispeech corpus traduit per màquina a més d'iwslt-corpus, TEDLIUM2 i Must_C corpora. El nostre millor model va marcar gairebé 3 BLEU més alts que el model de l'any passat. Per al conjunt de tests del segment 2020 vam utilitzar exactament el mateix procediment que l'any passat.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Zúčastnili jsme se offline překladu TED přednášek z angličtiny do němčiny End-to-End. Naše řešení jsme založili na loňském předložení. Použili jsme mírně změněnou architekturu Transformeru s konvoluční vrstvou podobnou ResNet připravující zvukový vstup do snímače Transformeru. Pro zlepšení kvality překladu modelu jsme představili dvě regularizační techniky a trénovali na strojově přeloženém korpusu Librispeech kromě korpusů iwslt-corpus, TEDLIUM2 a Must_C. Náš nejlepší model dosáhl téměř o tři BLEU vyšší než loňský model. Pro segment 2020 testovací sady jsme použili přesně stejný postup jako loni.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vi deltog i offline end-to-end engelsk til tysk TED foredrag oversættelse opgave. Vi baserede vores løsning på vores sidste års indsendelse. Vi brugte en lidt ændret Transformer arkitektur med ResNet-lignende konvulutionslag forberedelse af lydindgangen til Transformer encoder. For at forbedre modellens oversættelseskvalitet introducerede vi to reguleringsteknikker og trænede i maskinoversat Librispeech corpus ud over iwslt-corpus, TEDLIUM2 og Must_C corpora. Vores bedste model scorede næsten 3 BLEU højere end sidste års model. For at segmentere 2020 testsæt brugte vi nøjagtig samme procedure som sidste år.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Wir haben an der Offline-End-Übersetzungsaufgabe für TED-Vorträge teilgenommen. Unsere Lösung stützten wir auf die Vorlage des Vorjahres. Wir verwendeten eine leicht veränderte Transformer-Architektur mit ResNet-ähnlicher Faltungsschicht, die den Audioeingang zum Transformer-Encoder vorbereitete. Um die Übersetzungsqualität des Modells zu verbessern, führten wir zwei Regularisierungstechniken ein und trainierten zusätzlich zu iwslt-corpus, TEDLIUM2 und Must_C Korpora am maschinell übersetzten Librispeech Korpus. Unser bestes Modell erzielte fast drei BLEU höher als das Vorjahresmodell. Für das Segment 2020-Testset haben wir genau das gleiche Verfahren wie im Vorjahr verwendet.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Πήραμε μέρος στο έργο μετάφρασης διαλέξεων από αγγλικά σε γερμανικά. Βασίσαμε τη λύση μας στην περσινή υποβολή μας. Χρησιμοποιήσαμε μια ελαφρώς τροποποιημένη αρχιτεκτονική μετασχηματιστή με ένα στρώμα που μοιάζει με ResNet προετοιμάζοντας την είσοδο ήχου στον κωδικοποιητή μετασχηματιστή. Για να βελτιώσουμε την ποιότητα της μετάφρασης του μοντέλου εισαγάγαμε δύο τεχνικές κανονικοποίησης και εκπαιδεύσαμε σε μηχανικά μεταφρασμένο σώμα εκτός από τα σώματα iwslt-corpus, TEDLIUM2 και Must_C. Το καλύτερό μας μοντέλο πέτυχε σχεδόν τρία υψηλότερα από το περσινό μοντέλο. Για το τμήμα 2020 σετ δοκιμών χρησιμοποιήσαμε ακριβώς την ίδια διαδικασία με πέρυσι.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Participamos en la tarea de traducción de conferencias TED de inglés a alemán de principio a fin fuera de línea. Basamos nuestra solución en la presentación del año pasado. Utilizamos una arquitectura Transformer ligeramente alterada con una capa convolucional similar a Resnet que prepara la entrada de audio al codificador Transformer. Para mejorar la calidad de la traducción del modelo, introdujimos dos técnicas de regularización y nos capacitamos en corpus Librispeech traducidos automáticamente, además de los corpora iwslt-corpus, TEDLIUM2 y MUST_C. Nuestro mejor modelo obtuvo casi 3 BLEU más que el modelo del año pasado. Para segmentar el conjunto de pruebas de 2020 utilizamos exactamente el mismo procedimiento que el año pasado.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Osalesime võrguühenduseta inglise keele-saksa TED loengute tõlkimise ülesandes. Me põhinesime oma lahendusel eelmisel aastal esitatud pakkumisel. Kasutasime veidi muudetud Transformeri arhitektuuri ResNeti sarnase konvolutsioonikihiga, mis valmistas helisisendi Transformeri kodeerijaks ette. Mudeli tõlkekvaliteedi parandamiseks tutvustasime lisaks iwslt-korpusele, TEDLIUM2 ja Must_C korpusele ka masintõlgitud Librispeech korpusega. Meie parim mudel sai peaaegu 3 BLEU kõrgema kui eelmisel aastal. Segmendi 2020 testikomplekti jaoks kasutasime täpselt sama protseduuri kui eelmisel aastal.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ما در کار ترجمه‌های TED به انگلیسی End-to-End شرکت کردیم. ما راه حل خود را بر اساس تسلیم سال گذشته‌مان بنیاد می‌دهیم. ما از یک معماری تغییر تبدیل کننده کوچک استفاده کردیم با طبقه متغییر مانند ResNet برای آماده کردن ورودهای صوتی به رمندۀ تغییر دهنده. برای بهتر کردن کیفیت ترجمه مدل، دو تکنیک قانونی را معرفی کردیم و بر ماشین ترجمه شده‌ایم Librispeech corpus در addition to iwslt-corpus, TEDLIUM2 و Must_C corpora. بهترین مدل ما تقریباً سه بلوپ بالاتر از مدل سال گذشته بود. برای برقطه آزمایش ۲۰۰۲، ما دقیقاً همان روش را با سال گذشته استفاده کردیم.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Osallistuimme offline End-to-End English to German TED luentojen kääntämiseen. Perustimme ratkaisumme viime vuoden toimitukseen. Käytimme hieman muunneltua Transformer-arkkitehtuuria ResNetin kaltaisella konvolutionaalisella kerroksella, joka valmisti äänituloa Transformer-kooderiin. Mallin kääntämisen laadun parantamiseksi otimme käyttöön kaksi laillistustekniikkaa ja koulutimme konekäännettyä Librispeech-korpusta iwslt-korpusen, TEDLIUM2- ja Must_C-korpusten lisäksi. Paras mallimme sai lähes 3 BLEU enemmän kuin viime vuoden malli. Segmentin 2020 testisarjaan käytimme täsmälleen samaa menettelyä kuin viime vuonna.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nous avons participé à la tâche de traduction hors ligne de bout en bout des conférences TED de l'anglais vers l'allemand. Nous avons basé notre solution sur la base de notre soumission de l'année dernière. Nous avons utilisé une architecture Transformer légèrement modifiée avec une couche convolutionnelle de type Resnet préparant l'entrée audio de l'encodeur Transformer. Pour améliorer la qualité de traduction du modèle, nous avons introduit deux techniques de régularisation et nous nous sommes formés au corpus Librispeech traduit automatiquement en plus des corpus iwslt-corpus, TEDLIUM2 et MUST_C. Notre meilleur modèle a obtenu près de 3 points de plus que le modèle de l'année dernière. Pour segmenter le jeu de test 2020, nous avons utilisé exactement la même procédure que l'année dernière.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ghlacamar páirt i dtasc aistriúcháin léachtaí TED ó Bhéarla go Gearmáinis ó cheann go ceann as líne. Bhunaíomar ár réiteach ar ár n-aighneacht anuraidh. D'úsáideamar ailtireacht Trasfhoirmeora a athraíodh de bheagán agus ciseal conbhlóideach cosúil le ResNet ag ullmhú an ionchur fuaime chuig an ionchódóir Transformer. Chun cáilíocht aistriúcháin an mhúnla a fheabhsú thugamar isteach dhá theicníc rialtachta agus chuireamar oiliúint ar corpas meaisín-aistrithe Librispeech chomh maith le iwslt-corpus, TEDLIUM2 agus Must_C corpora. Scóráil ár múnla is fearr beagnach 3 BLEU níos airde ná samhail na bliana seo caite. Chun tacair tástála 2020 a dheighilt, d'úsáideamar go díreach an nós imeachta céanna agus a bhí anuraidh.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>@ info: whatsthis Mun ƙaddara suluyinmu a kan Musuluncin shekara ta shida. We used a slightly altered Transformer architecture with ResNet-like convolutional layer preparing the audio input to Transformer encoder. To improve tsarin motel'in fassarar, we introduce technical biyu masu tsaro kuma an sanar da shi a kan mashine ta fassar Librispech Cornas, addition to iwslt-Corbas, TeDLIUM2 and Must_C Corpo. Babu misalinmu na ƙari takin BLEU ya fi girma daga misalin shekara ta shida. Ga rabin jarrabi 2020, mun yi amfani da daidai jarrabo kamar shekara ta shida.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>השתתפנו בתפקיד התרגום של "סוף עד סוף" לאנגלית לרצאות TED הגרמניות. הבססנו את הפתרון שלנו על ההכנעה שלנו בשנה שעברה. השתמשנו בארכיטקטורה מעט משתנה עם שכבה משתנה דומה לרסנט שמכינה את הכניסה של הקולנוע לקודר. כדי לשפר את איכות התרגום של המודל הכרנו שתי טכניקות רגילות ואימנו על מכונת התרגם Librispeech corpus בנוסף ל iwslt-corpus, TEDLIUM2 ו Must_C corpora. המודל הטוב ביותר שלנו קיבל כמעט 3 BLEU גבוה יותר מהמודל של שנה שעברה. To segment 2020 test set we used exactly the same procedure as last year.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>हमने ऑफ़लाइन एंड-टू-एंड अंग्रेजी से जर्मन टेड व्याख्यान अनुवाद कार्य में भाग लिया। हम अपने पिछले साल के सबमिशन पर हमारे समाधान के आधार पर. हम ResNet के साथ एक थोड़ा बदल ट्रांसफॉर्मर वास्तुकला का इस्तेमाल किया-जैसे convolutional परत ट्रांसफॉर्मर एन्कोडर के लिए ऑडियो इनपुट तैयार. अनुवाद के मॉडल की गुणवत्ता में सुधार करने के लिए हमने दो नियमितीकरण तकनीकों को पेश किया और मशीन अनुवादित लिब्रिसपीच कॉर्पस पर प्रशिक्षित किया, इसके अलावा iwslt-corpus, TEDLIUM2 andMust_C corpora। हमारे सबसे अच्छे मॉडल ने पिछले साल के मॉडल की तुलना में लगभग 3 BLEU अधिक स्कोर किया। सेगमेंट 2020 परीक्षण सेट के लिए हमने पिछले साल की तरह ही प्रक्रिया का उपयोग किया।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Pridružili smo se poslu za prevod na njemačkim TED predavanjima. Započeli smo našu rješenje na podnošenju prošle godine. Koristili smo malu izmijenjenu arhitekturu transformera sa konvolucionalnim slojem poput ResNet a pripremajući audio ulaz za koder transformera. Da bi poboljšali kvalitet prevoda modela, predstavili smo dvije regularizacijske tehnike i obučene na strojevima prevedeno Librispeech corpus, osim iwslt-corpus, TEDLIUM2 i Must_C corpora. Naš najbolji model rezultirao je skoro 3 BLEU viši od prošlogodišnjeg modela. Za snimanje testa za segment 2020, koristili smo tačno isti postupak kao i prošle godine.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Részt vettünk az offline End-to-End angol-német TED előadások fordítási feladatában. Megoldásunkat a tavalyi beadványunkra alapoztuk. Egy kissé módosított Transformer architektúrát használtunk ResNet-szerű konvolúciós réteggel, amely előkészítette az audio bemenetet a Transformer kódolóhoz. A modell fordítási minőségének javítása érdekében két szabályozási technikát vezettünk be, és az iwslt-corpus, a TEDLIUM2 és a Must_C corpora mellett gépi lefordítású Librispeech corpus képzésére készültünk. A legjobb modellünk majdnem 3 BLEU-t ért el a tavalyi modellnél. A 2020-as tesztkészlethez pontosan ugyanazt az eljárást használtuk, mint tavaly.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Մենք մասնակցեցինք անգլերենի վերջ-վերջ անգլերենի և գերմանացի TED-ի դասընթացների թարգմանման գործին: Մենք հիմնեցինք մեր լուծումը անցյալ տարվա ներկայացման վրա: We used a slightly altered Transformer architecture with ResNet-like convolutional layer preparing the audio input to Transformer encoder. Մոդելի թարգմանման որակը բարելավելու համար մենք ներկայացրեցինք երկու ռեգուլարիզացիոն տեխնիկա և ուսուցանում էինք մեքենայի թարգմանված գրադարձ կորպոս, ավելացնելով iսթ-կորպոս, TEDլիում2 և Մուստ_C կորպորա Մեր լավագույն մոդելը գնահատել է մոտ երեք բլեուզ ավելի բարձր, քան անցյալ տարվա մոդելը: To segment 2020 test set we used exactly the same procedure as last year.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kami mengambil bagian dalam tugas terjemahan dari Bahasa Inggris akhir ke akhir ke kursus TED Jerman. Kami mendasarkan solusi kami pada penyerahan tahun lalu kami. Kami menggunakan arsitektur Transformer yang sedikit berubah dengan lapisan konvolusi seperti ResNet mempersiapkan input audio ke pengekode Transformer. Untuk meningkatkan kualitas terjemahan model kami memperkenalkan dua teknik regularisasi dan dilatih di mesin terjemahan Librispeech corpus tambah iwslt-corpus, TEDLIUM2 dan Must_C corpora. Model terbaik kami skor hampir 3 BLEU lebih tinggi dari model tahun lalu. Untuk set tes segmen 2020 kami menggunakan prosedur yang sama seperti tahun lalu.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Abbiamo preso parte al compito offline di traduzione delle lezioni TED dall'inglese al tedesco. Abbiamo basato la nostra soluzione sulla presentazione dell'ultimo anno. Abbiamo usato un'architettura Transformer leggermente modificata con un livello convoluzionale simile a ResNet per preparare l'ingresso audio al codificatore Transformer. Per migliorare la qualità della traduzione del modello abbiamo introdotto due tecniche di regolarizzazione e addestrato sul corpus Librispeech tradotto automaticamente oltre a iwslt-corpus, TEDLIUM2 e Must_C corpora. Il nostro miglior modello ha ottenuto quasi 3 BLEU in più rispetto al modello dello scorso anno. Per segmentare il set di test 2020 abbiamo utilizzato esattamente la stessa procedura dell'anno scorso.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>オフラインのエンドツーエンドの英語からドイツ語へのTED講義翻訳タスクに参加しました。昨年の提出書類に基づいてソリューションを作成しました。私たちは、ResNetのような畳み込みレイヤーを備えた少し変更されたトランスフォーマーアーキテクチャを使用して、トランスフォーマーエンコーダへのオーディオ入力を準備しました。モデルの翻訳品質を向上させるために、2つの正規化技術を導入し、iwslt - corpus、TEDLIUM 2、およびMust_C corporaに加えて機械翻訳Librispeechコーパスのトレーニングを行いました。当社の最高のモデルは、昨年のモデルよりもほぼ3 BLEUのスコアを獲得しました。2020年のテストセットをセグメント化するために、昨年とまったく同じ手順を使用しました。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Awak dh챕w챕 wis ak챔h n챗m챗n ning "End-to-End" -Inggris kanggo nganggo barang alaman kanggo tarjamahan "Tom". Awakdh챕w챕 ngerti perusahaan dh챕w챕 nang kana dh챕w챕 We used a little change Transformer architecture with Resnet-like convolution layer Reading the sound input to Transformer koder. Mbak penting nggawe kalitas model kebebasan itoleh dumadhi, awak dh챕w챕 ngerasai t챕kno sing berarti ujak karo perusahaan dibutuhke "Library" sing berarti itoleh bantuan, lan ujak-ujak i "Iwakken telu" lan "Must_C" Rasan챕 sing paling dh챕w챕, ditambah sing kator 3 BEL kuwi model sing paling tau. Genjer-genjer saiki gerang t챔st 2020 sampeyan, kita ngaweh penggunan ngono cah-cah dumadhi tau.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ჩვენ დავიწყეთ "End-to-End" ინგლისური დაწყვეტილების დაწყვეტილებელი TED ლექციების დაწყვეტილებელი საქმე. ჩვენ წინა წლის შემდეგ ჩვენი გარეშე დავიბაზეთ. ჩვენ გამოყენეთ ცოტა შეცვლელი ტრანფორმების აქტიქტიქტიკური რესნეტების მსგავსი კონტროლუციონალური ჩატვირთვის, როგორც რესნეტების მსგავ ჩვენ მოდელის გასაგრძელებლად ორი რეგილარიზაციის ტექნოგიების გასაგრძელებლად შევცვალოთ და მაქინის გასაგრძელებლად Librispeech corpus-ს დამატებით iwslt-corpus, TEDLIUM2 და Must_C corpora-ს დამატებით. ჩვენი ყველაზე საუკეთესო მოდელი დაიწყო დამატებით 3 BLEU-ს უფრო მეტი წლის მოდელზე. 2020 წლის სეგენტის ტესტისთვის ჩვენ გამოყენეთ ისეთი პროცესია როგორც წინა.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Біз "End-to-End" ағылшыншасына неміс TED лекцияларының аудару тапсырмасына бөлікті. Біз соңғы жылдың келтірімізге шешімізді негіздеп тұрмыз. Біз ResNet секілді конверсиялық қабатты аудио енгізуін түрлендіру кодеріне дайындау үшін бірнеше өзгертілген түрлендіру архитектурасын қолдандық. Үлгінің аудармасының сапатын жақсарту үшін, біз екі үлгі түрлендіру техникасын және компьютердің аудармағындағы Librispeech корпус iwslt-corpus, TEDLIUM2 және Must_C корпорасына қосымша үйрендік. Біздің ең жақсы моделіміз өткен жылдың үлгісінен артық 3 BLEU болды. 2020 жыл сегментінің сынақтарына біз өткен жылдың бір процедурасын қолдандық.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>우리는 오프라인에서 끝까지 영어부터 독일어 TED 강좌 번역 임무에 참가했다.우리는 작년에 제출한 해결 방안을 바탕으로 한다.우리는 ResNet과 비슷한 볼륨층을 가지고 변환기 인코더를 위해 오디오 입력을 준비하는 약간 바뀐 변환기 구조를 사용했다.모델의 번역 품질을 향상시키기 위해 iwslt 자료 라이브러리, TEDLIUM2와Must C 자료 라이브러리 외에 두 가지 정규화 기술을 도입하고 기계 번역의Librispeech 자료 라이브러리에서 훈련을 실시했다.우리의 가장 좋은 차종의 득점은 작년 차종보다 3개의 BLEU 가까이 높다.2020 테스트집을 분할하기 위해 작년과 똑같은 프로그램을 사용했다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mes dalyvavome anglų kalbos vertimo darbe iš eilės į vokiečių TED pamokas. Mūs ų sprendimas grindžiamas praėjusių metų pareiškimu. Naudojome šiek tiek pakeistą Transformer architektūrą su panašu į ResNet konvoliuciniu sluoksniu, ruošiant garso įvedimą į Transformer kodatorių. Siekdami pagerinti modelio vertimo kokybę, įdiegėme du reguliarizavimo metodus ir apmokėme mašin ų vertimo Librispeech corpus, be iwslt-corpus, TEDLIUM2 ir Must_C corpora. Mūs ų geriausias modelis buvo beveik 3 BLEU didesnis už praėjusių metų model į. To segment 2020 test set we used exactly the same procedure as last year.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>We took part in the offline End-to-End English to German TED lectures translation task. Го базиравме нашето решение на минатата година. Користевме малку променета трансформарна архитектура со конволуционален слој како Ресенет кој го подготвува аудио внесот во трансформарниот кодер. За да го подобриме квалитетот на преводот на моделот, воведовме две техники за регуларизација и трениравме на машински превод Librispeech corpus, покрај iwslt-corpus, TEDLIUM2 и Must_C corpora. Нашиот најдобар модел постигна скоро 3 БЛЕ повисоки од минатогодишниот модел. To segment 2020 test set we used exactly the same procedure as last year.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ഞങ്ങള്‍ ഓഫ്‌ലൈന്‍ ആന്‍ഡ് മുഴുവന്‍ ഇംഗ്ലീഷില്‍ പങ്കുചേര്‍ത്ത് ജര്‍മ്മന്‍ ടെഡി ലേക്ഷര്‍ പരിഭാഷണത്തിന്‍റെ നമ്മുടെ കഴിഞ്ഞ വര്‍ഷത്തെ കീഴ്പ്പെടുത്തിയിട്ട് നമ്മുടെ പരിഹാരം അടിസ്ഥാനമാക്കി. We used a slightly altered Transformer architecture with ResNet-like convolutional layer preparing the audio input to Transformer encoder. ഈ മോഡലിന്റെ വിഭാഷത്തിന്റെ ഗുണപൂര്‍ണ്ണമാക്കാന്‍ ഞങ്ങള്‍ രണ്ടു നിയന്ത്രണത്തിന്റെ സാങ്കേതികവിദ്യകളെ പരിശീലിപ്പിച്ച് ലിബ്രിസ്പീച് കോര്‍പ്പുസിനെ നമ്മുടെ ഏറ്റവും നല്ല മോഡല്‍ കഴിഞ്ഞ വര്‍ഷത്തെ മോഡലിനെക്കാള്‍ മൂന്നു ബിലിയുവിനെക്കാള്‍ ഉയര്‍ത്തി. 2020 ടെസ്റ്റ് സെറ്റ് ചെയ്യാന്‍ കഴിഞ്ഞ വര്‍ഷം നമ്മള്‍ അതേ പ്രക്രിയയാണ് ഉപയോഗിച്ചത്.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Бид "End-to-End" хэлний англи хэлний төгсгөлд Германы TED лекцийн хөгжлийн даалгавраанд оролцсон. Өнгөрсөн жилийн дараа бидний шийдвэрийг үндсэн. Бид ResNet шиг бага зэрэг өөрчлөгдсөн Трансфер архитектурыг ашигласан. Аудио орлуудыг Трансфер кодер руу бэлдэж байна. Тиймээс бид загварын хөгжүүлэх чадварыг сайжруулахын тулд хоёр шууд шинжлэх ухааны техник, машины хөгжүүлэх Librispeech корпус болон iwslt-corpus, TEDLIUM2 болон Must_C корпора дамжуулагдсан. Бидний хамгийн сайн загвар өнгөрсөн жилийн загвараас бараг 3 БЛУ өндөр байсан. 2020 оны шалгалтын хувьд бид өнгөрсөн жилтэй адилхан процедурыг ашигласан.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>We took part in the offline End-to-End English to German TED lectures translation task. Kita berdasarkan penyelesaian kita pada penghantaran tahun lepas. Kami menggunakan arkitektur Transformer yang sedikit diubah dengan lapisan konvolusi seperti ResNet menyediakan input audio ke pengekod Transformer. Untuk meningkatkan kualiti terjemahan model kami memperkenalkan dua teknik pengaturan dan dilatih pada Librispeech corpus terjemahan mesin selain iwslt-corpus, TEDLIUM2 dan Must_C corpora. Our best model scored almost 3 BLEU higher than last year's model. Untuk set ujian segmen 2020 kami menggunakan prosedur yang sama dengan tahun lepas.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>We took part in the offline End-to-End English to German TED lectures translation task. We based our solution on our last year's submission. Użajna arkitettura Transformer kemmxejn mibdula b’saff konvoluzzjonali simili għal ResNet li jipprepara l-input awdjo għall-kodifikatur Transformer. Biex tittejjeb il-kwalità tat-traduzzjoni tal-mudell introduċejna żewġ tekniki ta’ regolarizzazzjoni u mħarrġa fuq Librispeech corpus tradott bil-magna flimkien ma’ iwslt-corpus, TEDLIUM2 u Must_C corpora. L-aħjar mudell tagħna kellu kważi 3 BLEU ogħla mill-mudell tas-sena l-oħra. Għas-sett tat-test tas-segment 2020 użajna eżattament l-istess proċedura bħas-sena l-oħra.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>We namen deel aan de offline End-to-End Engels naar Duits TED lezingen vertaaltaak. We baseerden onze oplossing op onze inzending van vorig jaar. We gebruikten een licht gewijzigde Transformer architectuur met ResNet-achtige convolutionele laag die de audio-ingang naar Transformer encoder voorbereidde. Om de kwaliteit van de vertaling van het model te verbeteren hebben we twee regularisatietechnieken geïntroduceerd en getraind op machinaal vertaalde Librispeech corpus naast iwslt-corpus, TEDLIUM2 en Must_C corpora. Ons beste model scoorde bijna drie BLEU hoger dan vorig jaar. Voor het segmenteren van 2020 testset hebben we exact dezelfde procedure gebruikt als vorig jaar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vi har delt i den fråkopla ende-til-slutt engelsk til tysk TED-leksjonsoppgåva. Vi baserer løsningen vårt på løsningen vårt siste år. Vi brukte ein liten endra transformeringsarkitektur med konvolusjonell lag som ResNet-liknar som forbereder lyd-inndata til Transformeringskodar. For å forbetra omsetjingskvaliteten til modellen, introdusere vi to reguleringsteknikk og trenga på maskina omsette Librispeech corpus i tillegg til iwslt-corpus, TEDLIUM2 og Must_C corpora. Det beste modellet vårt oppretta nesten 3 BLEU høgare enn siste årsmodellen. For segment 2020-testen brukte vi nøyaktig det samme prosedyren som siste år.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Braliśmy udział w zadaniu tłumaczenia wykładów TED z języka angielskiego na niemiecki offline. Nasze rozwiązanie opieraliśmy na zeszłorocznej zgłoszeniu. Zastosowaliśmy nieco zmienioną architekturę Transformera z warstwą konwolucyjną ResNet przygotowującą wejście audio do kodera Transformera. Aby poprawić jakość tłumaczenia modelu, wprowadziliśmy dwie techniki regularyzacji oraz trenowaliśmy korpus Librispeech przetłumaczony maszynowo oprócz korpusów iwslt-corpus, TEDLIUM2 i Must_C. Nasz najlepszy model zdobył niemal 3-BLEU wyższy niż ubiegłoroczny model. Do segmentu zestawu testowego 2020 zastosowaliśmy dokładnie taką samą procedurę jak w zeszłym roku.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Participamos da tarefa de tradução de palestras TED de inglês para alemão de ponta a ponta offline. Baseamos nossa solução na apresentação do ano passado. Usamos uma arquitetura Transformer ligeiramente alterada com camada convolucional do tipo ResNet preparando a entrada de áudio para o codificador Transformer. Para melhorar a qualidade da tradução do modelo, introduzimos duas técnicas de regularização e treinamos em Librispeech corpus traduzido por máquina, além de iwslt-corpus, TEDLIUM2 e Must_C corpora. Nosso melhor modelo obteve quase 3 BLEU a mais do que o modelo do ano passado. Para segmentar o conjunto de testes de 2020, usamos exatamente o mesmo procedimento do ano passado.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Am luat parte la sarcina offline de traducere a prelegerilor TED din engleză în germană. Am bazat soluția noastră pe depunerea noastră de anul trecut. Am folosit o arhitectură Transformer ușor modificată cu strat convoluțional asemănător ResNet pregătind intrarea audio la encoder Transformer. Pentru a îmbunătăți calitatea traducerii modelului am introdus două tehnici de regularizare și am instruit pe corpus Librispeech tradus automat în plus față de iwslt-corpus, TEDLIUM2 și Must_C corpora. Cel mai bun model al nostru a obținut aproape 3 BLEU mai mult decât modelul de anul trecut. Pentru segmentarea setului de testare 2020 am folosit exact aceeași procedură ca și anul trecut.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Мы приняли участие в офлайн-задаче по переводу с английского на немецкий лекций TED. Наше решение было основано на нашем прошлогоднем представлении. Мы использовали слегка измененную архитектуру Трансформатора со сверточным слоем, подобным ResNet, подготавливающим аудио вход для кодировщика Трансформатора. Для улучшения качества перевода модели мы внедрили две методики регуляризации и обучили машинному переводу Librispeech corpus в дополнение к iwslt-corpus, TEDLIUM2 иMust_C corpa. Наша лучшая модель набрала почти на 3 БЛЮ больше, чем модель прошлого года. Для сегментации тестового набора 2020 года мы использовали точно такую же процедуру, как и в прошлом году.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>අපි ඉංග්‍රීසියට අන්තිම විදියට ජර්මන් TED ප්‍රශ්න විදියට භාවිතා කරනවා. අපි අන්තිම අවුරුද්දේ පිළිගන්නේ අපේ විසරණය. අපි ResNet-වගේ සම්පූර්ණ ස්ථානයක් සමග වෙනස් වෙන්න වෙනස් වෙන්න ස්ථානයක් පාවිච්චි කරනවා අඩියෝජිත ඇත මොඩල් එකේ වාර්ථාවේ කුළුවත් වැඩි කරන්න අපි නියමික විද්‍යාපිත විද්‍යාපිත විද්‍යාපිත විද්‍යාපිත විද්‍යාපිත විද්‍යාපිත විද්‍යාපිත ව අපේ හොඳම මෝඩේල් එක ගිය අවුරුද්දේ මෝඩේල් එකට වඩා බ්ලෝයුස් 3ක් වඩා වැඩියි. අපි පරීක්ෂණාවට පරීක්ෂණාවට පස්සේ අවුරුද්දේ වගේ සිද්ධ විධානය පාවිච්චි කරනවා.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Sodelovali smo pri prevajanju TED predavanj iz angleščine do nemščine brez povezave. Našo rešitev smo temeljili na lanskem predložitvi. Uporabili smo rahlo spremenjeno arhitekturo transformatorjev s konvolucijskim slojem, podobnim ResNetu, ki je pripravil avdio vhod v kodirnik transformatorjev. Za izboljšanje kakovosti prevajanja modela smo poleg iwslt-korpusa, TEDLIUM2 in Must_C korpusa uvedli dve tehniki regularizacije in usposabljali strojno prevedenega Librispeech korpusa. Naš najboljši model je ocenil skoraj 3 BLEU višje od lanskega modela. Za segment test set 2020 smo uporabili popolnoma enak postopek kot lani.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Waxaannu ka qeybqaadanay shabakadda End-to-End Ingiriis-da German TED lectures translation mission. waxaynu ku aasaasnay xalaalka dhamaadka sanadkii. Waxaynu isticmaalnay dhismaha turjumista ee wax yar oo beddelan oo la mid ah ResNet darajada adag oo u diyaarinaya sawirka codka ee turjumista. Si loo hagaajiyo takhasuska turjumista, waxaan soo bandhigay laba qaabilaad oo la soodajiyo oo lagu tababariyey mashiinka lagu turjumay librispeech korpus ka sokow iwslt-corpus, TEDLIUM2 iyo Must_C corpora. Our best model scored almost 3 BLEU higher than last year's model. qeybinta 2020 ee baaritaanka waxaynu u isticmaalnay si isku mid ah xiliga sanadkii hore.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ne morëm pjesë në detyrën e përkthimit të lezioneve të TED-it nga fundi në fund. Ne bazuam zgjidhjen tonë në dorëzimin tonë të vitit të kaluar. Ne përdorëm një arkitekturë pak të ndryshuar Transformer me shtresë konvolutive si ResNet duke përgatitur hyrjen audio në koduesin Transformer. Për të përmirësuar cilës in ë e përkthimit të modelit ne futëm dy teknika rregulluese dhe stërvitëm në Librispeech corpus përkthyer nga makina përveç iwslt-corpus, TEDLIUM2 dhe Must_C corpora. Our best model scored almost 3 BLEU higher than last year's model. Për testin e segmentit 2020 kemi përdorur saktësisht të njëjtën procedurë si vitin e kaluar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Pridružili smo se poslu za prevod na njemačkim TED predavanjima. Na osnovu našeg rješenja na poslednjoj predanosti. Koristili smo malu izmjenjenu arhitekturu transformera sa konvolucionalnim slojem poput ResNet a, pripremajući audio unos za koder transformera. Da bi poboljšali kvalitet prevoda modela, predstavili smo dve regularizacijske tehnike i obučene na mašini prevedeno Librispeech corpus, osim iwslt-corpus, TEDLIUM2 i Must_C corpora. Naš najbolji model je dobio skoro 3 BLEU viši od prošlogodišnjeg modela. Za snimanje testa 2020. koristili smo tačno iste procedure kao i prošle godine.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vi deltog i översättningsuppgiften offline från engelska till tyska TED-föreläsningar. Vi baserade vår lösning på vårt förra års inlämning. Vi använde en något förändrad Transformer arkitektur med ResNet-liknande konvulutionslager för att förbereda ljudingången till Transformer encoder. För att förbättra modellens kvalitet på översättning introducerade vi två regulariseringstekniker och tränade på maskinöversatt Librispeech corpus utöver iwslt-corpus, TEDLIUM2 och Must_C corpora. Vår bästa modell fick nästan 3 BLEU högre än förra årets modell. För att segmentera 2020 testset använde vi exakt samma procedur som förra året.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tumeshiriki katika kazi ya tafsiri ya TED katika mtandao wa mwisho-to-End English hadi Ujerumani. We based our solution on our last year's submission. Tulitumia jengo lililobadilishwa kidogo la Transformer na kiwango kinachofanana na ResNet ambacho kiliandaa matokeo ya sauti kwenye kodi la Transformer. Kuboresha ubora wa utafsiri wa mifano tulianzisha mbinu mbili za kudhibiti na kufundishwa kwenye mashine yanayotafsiriwa Librispeech pamoja na iwslt-corpus, TEDLIUM2 na Must_C. Mfano wetu bora uliorodhesha takribani BLEU 3 zaidi ya mtindo wa mwaka jana. Katika sehemu ya jaribio la 2020 tulitumia utaratibu huo sawa kama mwaka jana.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>We took part in the offline End-to-End English to German TED lectures translation task. நாங்கள் கடந்த வருடத்தின் கட்டளையை அடிப்படையாக எங்கள் தீர்வு. நாங்கள் ஒரு சிறிய மாற்றப்பட்ட மாற்று அமைப்பை பயன்படுத்தினோம் ரெஸ்நெட் போன்ற சாதாரண அடுக்கு மாற்றும் குறியீட்டிற்க மாதிரியின் மொழிபெயர்ப்பின் தரம் மாற்ற நாங்கள் இரண்டு கட்டுப்பாட்டு தொழில்நுட்பத்தை முன்னேற்றி இயந்திரத்தில் பயிற்சி மொழிபெயர்ப்பு லிப்ரிச்ப எங்கள் சிறந்த மாதிரி கடந்த வருடத்தின் மாதிரியை விட மூன்று பிலியு உயர்ந்தது. 2020 சோதனையை பிரிக்க நாம் கடந்த வருடத்தில் அதே செயல்பாட்டை பயன்படுத்தினோம்.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Biz offline End-to-End Iňlisçe nemesçe TED sanlarynyň terjime täbligine böldik. Biz geçen ýylymyzyň teslim etmäge çözümüzü daýadyk. ResNet'e görkezilen bir şekilde üýtgeden bir Transformer arhitektegi ullandık. Ses girişini Transformer ködere taýýarlanýar. Modeliniň terjime kalitesini geliştirmek üçin biz 2 düzenlemek tekniklerini we makine terjime edilen Librispeech corpus iwslt-corpus, TEDLIUM2 we Must_C corpora dahil edildi. Biziň iň gowy nusgymyz geçen ýylyň nusgasyndan 3 BLEU köp sany boldy. 2020-nji ýyl barlamak üçin biz geçen ýyl ýaly edil bir prosedyny ulandyk.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ہم نے آف لین End-to-End انگلیسی میں جرمانی TED لکتروں کی ترجمہ کا کام بنایا۔ ہم نے اگلے سال کے مسلمانوں پر ہمارا حل بنیاد رکھا ہے۔ ہم نے ایک تھوڑا بدل تغییر تغییر تغییر دینے والے معماری استعمال کیا ہے جو رس نیٹ جیسی کنوولیوشن لائر کے ساتھ آڈیو اپن ایمپ ترنسفور کوڈر کے لئے تیار کر رہے ہیں. ہم نے مدل کی تعلیم کی کیفیت کو اچھی طرح پہنچایا اور ماشین کی تعلیم لیبرائیسپیچ کورپوس کے علاوہ دوسری قانونی تکنیک کو پہنچایا۔ ہمارے سب سے بہترین نمونڈل گئی سال کی نمونڈل سے تقریباً تین بلیوس سے بلند تھا۔ سال ۲۰۰۲ کے سپٹ ٹیسٹ کے لئے ہم نے پچھلی سال کے مطابق اسی طرح استعمال کیا۔</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Biz ofline End to- End ingliz tilidagi ingliz tilida o'rganishni Olmoncha TED tahrirlash vazifasiga ega qildik. Biz yetgi yil qanday qilishga qaror qilamiz. Biz ResNet sifatida bir qisqa o'zgarishga o'zgarishga ishlatdik va Transformer kodlash uchun audio input tayyorligini tayyorlash. @ info Bizning eng yaxshi modelimiz past yil modelidagi 3 BLEU ko'p edi. 2020 ta'limni ajratish uchun biz past yil huddi bir xil vazifalarni ishlatdik.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Chúng tôi tham gia vào cuộc dịch thuật bằng tiếng Anh giữa kết thúc và cuối cùng của Đức. Chúng ta đã dựa trên giải pháp của mình từ năm ngoái. Chúng tôi sử dụng một cấu trúc biến hình có chút thay đổi với lớp xoắn ốc giống hệt ResNet để chuẩn bị âm thanh nhập vào bộ mã hóa biến hình. Để nâng cao chất lượng bản dịch của mô hình chúng tôi đã nhập vào hai kỹ thuật hoá học và được đào tạo trên tập đoàn LibRispeech (Văn bản) được dịch ra trên máy tính, thêm cả hợp chất lỏng lẻo, định vị và phải hạ C. Mô hình tốt nhất của chúng ta đã đạt đến ba nguyên tắc cao hơn mẫu năm ngoái. Về phần kiểm tra 2020 chúng tôi đã dùng đúng thủ tục y chang năm ngoái.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>与离线端到端英语德语TED讲座译事。 我们的解决方案基于去年提交的文件。 吾用少变之 Transformer 架构,有类 ResNet 之卷积层,以备 Transformer 编码器之音频输。 为重译质,引入二正则化,教习于机器翻译之Librispeech语料库及iwslt-corpus,TEDLIUM2 andMust_C语料库。 最佳得分比去年模出近3 BLEU。 为分2020年试集,用与去年同。</span></div></div><dl><dt>Anthology ID:</dt><dd>2020.iwslt-1.9</dd><dt>Volume:</dt><dd><a href=/volumes/2020.iwslt-1/>Proceedings of the 17th International Conference on Spoken Language Translation</a></dd><dt>Month:</dt><dd>July</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Online</dd><dt>Venues:</dt><dd><a href=/venues/acl/>ACL</a>
| <a href=/venues/iwslt/>IWSLT</a></dd><dt>SIG:</dt><dd><a href=/sigs/sigslt/>SIGSLT</a></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>89–94</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.iwslt-1.9>https://aclanthology.org/2020.iwslt-1.9</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/2020.iwslt-1.9 title="To the current version of the paper by DOI">10.18653/v1/2020.iwslt-1.9</a></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">potapczyk-przybysz-2020-srpols</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Tomasz Potapczyk and Pawel Przybysz. 2020. <a href=https://aclanthology.org/2020.iwslt-1.9>SRPOL’s System for the IWSLT 2020 End-to-End Speech Translation TaskSRPOL’s System for the IWSLT 2020 End-to-End Speech Translation Task</a>. In <i>Proceedings of the 17th International Conference on Spoken Language Translation</i>, pages 89–94, Online. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2020.iwslt-1.9>SRPOL’s System for the IWSLT 2020 End-to-End Speech Translation TaskSRPOL’s System for the IWSLT 2020 End-to-End Speech Translation Task</a> (Potapczyk & Przybysz, IWSLT 2020)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2020.iwslt-1.9.pdf>https://aclanthology.org/2020.iwslt-1.9.pdf</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2020.iwslt-1.9.pdf title="Open PDF of 'SRPOL’s System for the IWSLT 2020 End-to-End Speech Translation TaskSRPOL’s System for the IWSLT 2020 End-to-End Speech Translation Task'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=SRPOL%E2%80%99s+System+for+the+IWSLT+2020+End-to-End+Speech+Translation+TaskSRPOL%E2%80%99s+System+for+the+IWSLT+2020+End-to-End+Speech+Translation+Task" title="Search for 'SRPOL’s System for the IWSLT 2020 End-to-End Speech Translation TaskSRPOL’s System for the IWSLT 2020 End-to-End Speech Translation Task' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'SRPOL’s System for the IWSLT 2020 End-to-End Speech Translation TaskSRPOL’s System for the IWSLT 2020 End-to-End Speech Translation Task'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[SRPOL’s System for the IWSLT 2020 End-to-End Speech Translation TaskSRPOL’s System for the IWSLT 2020 End-to-End Speech Translation Task](https://aclanthology.org/2020.iwslt-1.9) (Potapczyk & Przybysz, IWSLT 2020)</p><ul class=mt-2><li><a href=https://aclanthology.org/2020.iwslt-1.9>SRPOL’s System for the IWSLT 2020 End-to-End Speech Translation TaskSRPOL’s System for the IWSLT 2020 End-to-End Speech Translation Task</a> (Potapczyk & Przybysz, IWSLT 2020)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Tomasz Potapczyk and Pawel Przybysz. 2020. <a href=https://aclanthology.org/2020.iwslt-1.9>SRPOL’s System for the IWSLT 2020 End-to-End Speech Translation TaskSRPOL’s System for the IWSLT 2020 End-to-End Speech Translation Task</a>. In <i>Proceedings of the 17th International Conference on Spoken Language Translation</i>, pages 89–94, Online. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>