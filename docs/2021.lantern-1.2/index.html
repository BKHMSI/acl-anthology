<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Visual Grounding Strategies for Text-Only Natural Language Processing - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="Visual Grounding Strategies for Text-Only Natural Language Processing" name=citation_title><meta content="Damien Sileo" name=citation_author><meta content="Proceedings of the Third Workshop on Beyond Vision and LANguage: inTEgrating Real-world kNowledge (LANTERN)" name=citation_conference_title><meta content="2021/4" name=citation_publication_date><meta content="https://aclanthology.org/2021.lantern-1.2.pdf" name=citation_pdf_url><meta content="19" name=citation_firstpage><meta content="29" name=citation_lastpage><meta property="og:title" content="Visual Grounding Strategies for Text-Only Natural Language Processing"><meta property="og:image" content="https://aclanthology.org/thumb/2021.lantern-1.2.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2021.lantern-1.2"><meta property="og:description" content="Damien Sileo. Proceedings of the Third Workshop on Beyond Vision and LANguage: inTEgrating Real-world kNowledge (LANTERN). 2021."><link rel=canonical href=https://aclanthology.org/2021.lantern-1.2></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2021.lantern-1.2.pdf>Visual Grounding Strategies for Text-Only Natural Language Processing</a>
<a id=af_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Visuele Grounding Strategies vir Slegs Natuurlike Taal Verwerking</a>
<a id=am_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>ምርጫዎች</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>استراتيجيات التأريض البصري لمعالجة النص فقط باللغة الطبيعية</a>
<a id=az_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Sadəcə Təbiətli Dil İşləməsi üçün Görünürlü Əlavə Strateji</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Визуални стратегии за заземяване на текста за обработка на естествен език</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>টেক্সট- শুধুমাত্র স্বাভাবিক ভাষা প্রক্রিয়ার জন্য দৃশ্যমান গ্রুউন্ডিং স্ট্যাটেক্ট</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>མཐོང་ནུས་མེད་པའི་སྐད་རིགས་ལ་རང་རུང་བའི་སྒྲིག་འགོད།</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Vizualne strategije osnova samo prirodnog jezika</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Estrategies visuals per a processar llenguatges naturals només amb text</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Strategie vizuálního uzemnění pro zpracování pouze textového přirozeného jazyka</a>
<a id=da_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Visuelle jordbaserede strategier for tekstbehandling af naturligt sprog</a>
<a id=de_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Visuelle Erdungsstrategien für die Textverarbeitung natürlicher Sprache</a>
<a id=el_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Στρατηγικές οπτικής γείωσης για την επεξεργασία φυσικής γλώσσας μόνο με κείμενο</a>
<a id=es_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Estrategias de base visual para el procesamiento del lenguaje natural solo de texto</a>
<a id=et_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Visuaalsed maandusstrateegiad ainult teksti loomuliku keele töötlemiseks</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>استراتژی‌های بنیادی بینایی برای پرداخت زبان طبیعی تنها متن</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Visuaaliset pohjautumisstrategiat vain tekstin luonnollisen kielen käsittelyyn</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Stratégies de mise à la terre visuelle pour le traitement du langage naturel en mode texte</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Straitéisí Amharcbhunaithe le haghaidh Próiseáil Teanga Nádúrtha Téacs amháin</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>KCharselect unicode block name</a>
<a id=he_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>אסטרטגיות קרקעיות חזותיות לעבודת שפת טבעית טקסטית בלבד</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>पाठ-केवल प्राकृतिक भाषा प्रसंस्करण के लिए दृश्य ग्राउंडिंग रणनीतियाँ</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Vizualne strategije osnova samo prirodnog jezika</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Vizuális alapozási stratégiák a csak szöveges természetes nyelv feldolgozásához</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Տեսական հիմնական ռազմավարությունները միայն տեքստի բնական լեզուների վերաբերյալ</a>
<a id=id_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Strategi Pemasangan Visual untuk Proses Bahasa Alami Teks-Hanya</a>
<a id=is_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Strategie di messa a terra visiva per l'elaborazione del linguaggio naturale solo testuale</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>テキストのみの自然言語処理のためのビジュアルグラウンディング戦略</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Visual Gruonding Siasat kanggo Perusahaan langgambar Text-Only</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>მხოლოდ ტექსტის ნაირადი ენის პროცესისთვის ვიზუალური გასაღების სტრატიგიები</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Тек мәтін- тек негізгі тіл процессорындағы көрінетін негізгі стратегиялар</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>순수한 텍스트 자연 언어 처리의 시각적 기초 전략</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Vaizdo pagrindo strategijos, skirtos tik tekstui skirtam natūralaus kalbų apdorojimui</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Визуелни стратегии за процес на природен јазик само за текст</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>പദാവലി മാത്രം സ്വാഭാവികമായ ഭാഷ പ്രവര്‍ത്തിപ്പിക്കുന്നതിനുള്ള കാഴ്ചയുള്ള ഗ്രൂണ്ടിങ് സ്ട്</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Зөвхөн Текст-Зөвхөн Байгалийн хэл Процессорын үзэж буй үндсэн стратеги</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Strategi Pemasangan Visual untuk Pemprosesan Bahasa Alami Teks-Hanya</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Visual Grounding Strategies for Text-Only Natural Language Processing</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Visuele aardingsstrategieën voor tekstverwerking van natuurlijke taal</a>
<a id=no_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Visuelle grunnleggingsstrategiar for berre naturleg språk</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Strategie uziemienia wizualnego dla przetwarzania języka naturalnego tylko tekstowego</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Estratégias de aterramento visual para processamento de linguagem natural somente texto</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Strategii de împământare vizuală pentru procesarea limbajului natural numai pentru text</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Стратегии визуального заземления для обработки только текста на естественном языке</a>
<a id=si_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>පාළ- ප්‍රතිභාවික භාෂාව ප්‍රස්ථාපනය සඳහා ප්‍රදේශ විශ්වාසීය විධානය</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Vizualne strategije ozemljitve za obdelavo naravnega jezika samo besedilo</a>
<a id=so_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Visual Grounding Strategies for Text-Only Natural Language Processing</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Strategjitë vizuale të themeluara për procesimin e gjuhës natyrore vetëm teksti</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Визуална стратегија подкрепа за процесс само природног езика текста</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Visual Grounding Strategier för textbaserad behandling av naturligt språk</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Mikakati ya Makundi ya Utaratibu</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Visual Grounding Strategies for Text-Only Natural Language Processing</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Diňe-täb diller işlemek üçin Görnöşi Açmak Strategiýasy</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>صرف پیغام کی طبیعی زبان پرسس کے لئے دکھائی گرونڈنگ استراتژی</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>Name</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>KCharselect unicode block name</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2021.lantern-1.2.pdf>纯文本自然语言视之大略也</a></h2><p class=lead><a href=/people/d/damien-sileo/>Damien Sileo</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Visual grounding is a promising path toward more robust and accurate Natural Language Processing (NLP) models. Many multimodal extensions of BERT (e.g., VideoBERT, LXMERT, VL-BERT) allow a joint modeling of texts and images that lead to state-of-the-art results on multimodal tasks such as Visual Question Answering. Here, we leverage multimodal modeling for purely textual tasks (language modeling and classification) with the expectation that the multimodal pretraining provides a grounding that can improve text processing accuracy. We propose possible <a href=https://en.wikipedia.org/wiki/Strategy_(game_theory)>strategies</a> in this respect. A first type of strategy, referred to as transferred grounding consists in applying multimodal models to text-only tasks using a <a href=https://en.wikipedia.org/wiki/Placeholder_name>placeholder</a> to replace image input. The second one, which we call associative grounding, harnesses <a href=https://en.wikipedia.org/wiki/Image_retrieval>image retrieval</a> to match texts with related images during both pretraining and text-only downstream tasks. We draw further distinctions into both strategies and then compare them according to their impact on <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a> and commonsense-related downstream tasks, showing improvement over text-only baselines.<i>transferred grounding</i> consists in applying multimodal models to text-only tasks using a placeholder to replace image input. The second one, which we call <i>associative grounding</i>, harnesses image retrieval to match texts with related images during both pretraining and text-only downstream tasks. We draw further distinctions into both strategies and then compare them according to their impact on language modeling and commonsense-related downstream tasks, showing improvement over text-only baselines.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Visuele agtergrond is 'n beloftende pad na meer kragtige en presies Natuurlike Taal Prosessering (NLP) modele. Baie multimodal e uitbreidings van BERT (bv. VideoBERT, LXMERT, VL- BERT) toelaat 'n koppelige modellering van teks en beelde wat lei na status- of- the- art resultate op multimodale opdragte soos Visuele Fraag Antwoord. Hier, ons maak multimodaal modellering vir pur tekstuule opdragte (taal modellering en klasifikasie) met die verwaging dat die multimodaal voorstreking verskaf 'n agtergrond wat teks verwerking presies kan verbeter. Ons voorstel moontlik strategies in hierdie respek. 'n Eerste tipe strategie wat as oordra agtergrond bepaal word, bestaan in die toepassing van multimodale modele na slegs teks- opdragte wat gebruik 'n plekhouer om beeldinvoer te vervang. Die tweede een, wat ons geassosieerde agtergrond noem, laat beeld herhaal om te ooreenstem met verwante beelde tydens beide voortreëning en slegs teks onderstreem taak. Ons trek verdere verskilte in beide strategies en vergelyk hulle volgens hulle invloek op taal modellering en gemeenskap verwante onderstreemde taak, wys verbetering oor slegs teks-basisline.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>የራእይ ጉዳይ የጠቅላላ ቋንቋ ማቀናጃ (NLP) ሞዴል ነው፡፡ BERT (e.g., VideoBERT, LXMERT, VL-BERT) የጽሑፎች እና ምስሎችን በብዙ ጥያቄ ጥያቄዎች እንደሚያሳየው የፊደል ጥያቄዎችን በሚያሳዩ ጥያቄ መልስ በሚያሳየው ብሎሜዶል ስርዓቶች ላይ የሚያሳየው የጽሑፎች እና ምስሎች ተሳትተዋል፡፡ ወደዚህ፣ የቋንቋ ምሳሌ እና ክፍለ ሥርዓት (የቋንቋ ምሳሌ እና ክፍልፍል) በተስፋት የብዙኃን የዝናብ ዝናብ የጽሑፍ ማቀናቀል እርግጠኛ ማድረግ የሚችል የጽሑፍ ማቀናቀል የሚችል ክፍል እናደርጋለን፡፡ በዚህ ላይ የሚቻልበትን strategie እናሳውቃለን፡፡ የተለወጠው የክፍለ ቅርጽ ምርጫዎች ሁለተኛይቱ የአካባቢ ጉድጓድ እና የጽሑፉን ምስሎች በተገኘው ጽሑፎች እና የጽሑፍ ማድረግ ብቻ በሚያሳድሩ ስራቶች ጋር ለመቀላቀል እናስባለን፡፡ በቋንቋ ምሳሌ እና የድምፅ አካባቢ ሥርዓት ላይ የሚደረገውን የጽሑፍ ብቻ መሠረት ማሳየት እናሳያል፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>التأريض البصري هو مسار واعد نحو نماذج معالجة لغة طبيعية (NLP) أكثر قوة ودقة. تسمح العديد من الامتدادات متعددة الوسائط لـ BERT (على سبيل المثال ، VideoBERT و LXMERT و VL-BERT) بنمذجة مشتركة للنصوص والصور التي تؤدي إلى أحدث النتائج في المهام متعددة الوسائط مثل الإجابة على الأسئلة المرئية. هنا ، نستفيد من النمذجة متعددة الوسائط للمهام النصية البحتة (نمذجة اللغة وتصنيفها) مع توقع أن يوفر التدريب المسبق متعدد الوسائط أساسًا يمكنه تحسين دقة معالجة النص. نقترح الاستراتيجيات الممكنة في هذا الصدد. يتمثل النوع الأول من الإستراتيجية ، المشار إليه باسم التأريض المنقولة ، في تطبيق نماذج متعددة الوسائط على المهام النصية فقط باستخدام عنصر نائب لاستبدال إدخال الصورة. الثاني ، الذي نسميه التأريض الترابطي ، يسخر استرجاع الصور لمطابقة النصوص مع الصور ذات الصلة أثناء كل من مهام التدريب المسبق والمهام النصية فقط. نرسم مزيدًا من الفروق في كلتا الاستراتيجيتين ثم نقارنها وفقًا لتأثيرها على نمذجة اللغة والمهام النهائية ذات الصلة بالمنطق المنطقي ، مما يُظهر تحسنًا على خطوط الأساس النصية فقط.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Görünürlü tərzdə daha qüvvətli və daha doğru Təbiq Dil İşləməsi (NLP) modellerinə tələb edən bir yoldur. BERT'nin çox modal uzaqlaşdırmaları (bəzisi, VideoBERT, LXMERT, VL-BERT) bir çox məlumat və suratların birlikdə modelləşdirməsinə izin verir ki, bəzisi sual cavab verməsi kimi çoxlu modal işlərdə mövcuddur. Burada, çoxlu modal modelləri təmiz mətn işləri (dil modelləri və klasifikasyonu) ilə müəyyən edirik ki, çoxlu modal pretraining mətn işləri doğruluğunu yaxşılaşdıra bilər. Bu haqda mümkün stratejilər təklif edirik. Əvvəlki tərəfindən daşınmış tərəfindən nazil edilən ilk növ strateji görüntü girişini əvəz etmək üçün tərəfindən istifadə etmək üçün çoxlu modal modellərə istifadə etməkdir. İkincisi, ortaq yerləşdirmək adlandırdığımız şəkillərin görüntüləri hər ikisini təkrar və təkrar-təkrar işləri ilə eşidən şəkillər ilə istifadə edir. Biz hər iki strateji ilə daha çox fərqli çəkirik və sonra onları dil modelliklərinə və sıradan-sıradan düşən işlərə görə salıyırıq, mətn yalnız baseline üstündə yaxşılıqları göstərir.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Визуалното заземяване е обещаващ път към по-здрави и точни модели за обработка на естествения език (НЛП). Много мултимодални разширения на BERT (например ВидеоBERT, LXMERT, VL-BERT) позволяват съвместно моделиране на текстове и изображения, което води до най-съвременни резултати при мултимодални задачи като визуално отговаряне на въпроси. Тук използваме мултимодалното моделиране за чисто текстови задачи (езиково моделиране и класификация) с очакването, че мултимодалното предварително обучение осигурява основа, която може да подобри точността на текстовата обработка. Предлагаме възможни стратегии в това отношение. Първият тип стратегия, наричана прехвърлено заземяване, се състои в прилагането на мултимодални модели за задачи само с текст, като се използва контейнер за заместване на входа на изображението. Вторият, който наричаме асоциативно заземяване, използва извличането на изображения, за да съответства на текстовете със съответните изображения по време както на задачите за предварително обучение, така и само за текст надолу по веригата. Правим допълнителни разграничения в двете стратегии и след това ги сравняваме според тяхното въздействие върху езиковото моделиране и свързаните с общия разум задачи надолу по веригата, показвайки подобрение спрямо базовите линии само с текст.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Visual grounding is a promising path toward more robust and accurate Natural Language Processing (NLP) models. বিরেটের অনেক মাল্টিমোডাল এক্সটেনশন (উদাহরণস্বরূপ ভিডিওবের্ট, LXMERT, VL-BERT) লেখা এবং ছবির একটি যৌথ মডেলের অনুমতি দিয়েছে যা দৃশ্য প্রশ্নের উত্তরের মতো দৃশ্যমান কাজের উপর প্ এখানে আমরা একেবারেই টেক্সটুল কাজের জন্য মাল্টিমোডাল মডেল দেখাচ্ছি (ভাষা মডেলিং এবং ক্লাসাফিকেশন) প্রত্যাশা করছি যে মাল্টিমোডাল বৃষ্টি একটি গ আমরা এই সম্ভাব্য কৌশল প্রস্তাব করি। একটি প্রথম ধরনের কৌশল, যার মানে পরিবর্তিত গ্রুউন্ড হিসেবে উল্লেখ করা হয়, তার মধ্যে রয়েছে ছবি ইনপুটের প্রতিস্থাপনের জন্য মাল্টিমোডাল দ্বিতীয়, যেটাকে আমরা একত্রিক গ্রুউন্ডিং বলি, সেখানে সংশ্লিষ্ট ছবি পুনরুদ্ধার করার জন্য চিত্র পুনরুদ্ধারের প্রতি মিলিয়ে দেয়া হয় আমরা উভয় কৌশলের মধ্যে আরো পার্থক্য আঁকছি এবং তারপর তাদের ভাষার মডেলিং এবং কমিউনিসেন্সের সংক্রান্ত নীচের কাজের প্রভাব অনুযায়ী তুলনা করি, য</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>མཐོང་ནུས་ཀྱི་རྨང་གཞི་ནི་ལྟ་བུའི་འགྲུལ་ལམ་ཞིག་ཏུ་གཏོང་མཁན་དགོས་པ་ཞིག་རེད། BERT (དཔེར་ན། VideoBERT, LXMERT, VL-BERT) ཡི་སྣ་མང་ཆེ་རྣམ་གྲངས་ཀྱི་རྣམ་པ་དང་བརྙན་རིས་མཐུན་སྒྲིག་ཡིག་དང་བརྙན་རིས་མང་ཙམ་སྟོན་ཐུབ་པའི་གནས འོན་ཀྱང་། ང་ཚོའི་ནང་དུ་ཡིག་ཆ་དབྱིབས་སྟངས་དང་དབྱེ་སྟངས་ལ་ཆུང་བའི་རྣམ་པ་ཚོར་ལག་ལེན་འཐབ་རྒྱུ་དང་། འུ་ཅག་གིས་བྱ་རིམ་འདིའི་ནང་གི་གྲོས་འཆར་སྤྲོད་ཡོད། སྐྱེས་འདྲེན་ཡོད་པའི་རྒྱབ་ལྗོངས་ཀྱི་དབྱེ་རིགས་དང་པོ་ཞིག་འདུག འདི་གཉིས་པ་དེ་ནི་ང་ཚོས་asociative རྒྱབ་ལྗོངས་དང་མཉམ་དུ་བརྙན་རིས་ཀྱི་ནང་དུ་འཇུག་རིས་མཐུན་པའི་ཡིག ང་ཚོས་གཞུང་ཕྱོགས་གཉིས་པ་དང་ཁྱད་པར་དབྱེ་བ་གཉིས་དབྱེ་བ་དང་བསྟུན་ནས་སྐད་རིགས་མིན་འདུག</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Visualno osnovanje je obećavajući put ka robnijim i preciznijim modelima procesa prirodnog jezika (NLP). Mnoge multimodalne proširenje BERT (npr. VideoBERT, LXMERT, VL-BERT) omogućavaju zajedničku modelizaciju teksta i slika koje dovode do rezultata umjetnosti na multimodalne zadatke poput odgovora na vizuelno pitanje. Ovdje, uključujemo multimodalnu modelizaciju čisto tekstualnih zadataka (jezička modelizacija i klasifikacija) sa očekivanjem da multimodalna pretkivanja pruža osnovu koja može poboljšati preciznost obrade teksta. Predlažemo moguće strategije u ovom pogledu. Prva vrsta strategije koja se zove prebacena zemlja sastoji od primjene multimodalnih modela na samo tekstualne zadatke koristeći placeholder za zamjenu unosa slika. Drugi, koji zovemo asocijativno područje, koristi prikupljanje slika kako bi odgovarali tekstima sa povezanim slikama tijekom zadataka koji se pretvaraju i samo snimaju tekst. Nacrtajemo daljnje razlike u oba strategija i onda ih uspoređujemo u skladu s njihovim utjecajem na modeliranje jezika i spuštanje zadataka povezanih sa zajedničkim smisluma, pokazujući poboljšanje samo teksta.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>El fonament visual és un camí prometedor cap a models més robustos i precisos de processament de llenguatges naturals (NLP). Many multimodal extensions of BERT (e.g., VideoBERT, LXMERT, VL-BERT) allow a joint modeling of texts and images that lead to state-of-the-art results on multimodal tasks such as Visual Question Answering. Aquí aprofitem la modelació multimodal per a tasques purament textuals (modelació de llenguatges i classificació) amb l'esperança que la pré-capacitació multimodal proporcioni una base que pugui millorar la precisió del processament de text. Proposem possible estratègies en aquest sentit. Un primer tipus d'estratègia, anomenat fonament transferit, consisteix en aplicar models multimodals a tasques només de text utilitzant un sostituïdor per substituir l'entrada d'imatge. La segona, que anomenem fundament associatiu, utilitza la recuperació d'imatges per ajustar els textos amb imatges relacionades durant les tasques de pré-formació i de text-sols a avall. Fem més distincions en ambdues estratègies i després les comparem segons l'impacte que tenen en la modelació lingüística i en les tasques downstream relacionades amb la sensació comú, mostrant millora sobre les línies de base només de text.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vizuální uzemnění je slibná cesta k robustnějším a přesnějším modelům NLP (Natural Language Processing). Mnoho multimodálních rozšíření BERT (např. VideoBERT, LXMERT, VL-BERT) umožňuje společné modelování textů a obrázků, které vedou k nejmodernějším výsledkům u multimodálních úloh, jako je vizuální odpověď na otázky. Zde využíváme multimodální modelování pro čistě textové úlohy (jazykové modelování a klasifikace) s očekáváním, že multimodální předškolení poskytne uzemnění, které může zlepšit přesnost zpracování textu. V tomto ohledu navrhujeme možné strategie. První typ strategie, označovaný jako přenášené uzemnění, spočívá v aplikaci multimodálních modelů na úlohy pouze textu pomocí zástupného symbolu nahrazujícího vstup obrázku. Druhý, kterému říkáme asociativní uzemnění, využívá vyhledávání obrázků k porovnání textů s souvisejícími obrázky během předškolení i textových následných úloh. Do obou strategií dále rozlišujeme a porovnáváme je podle jejich vlivu na jazykové modelování a následné úlohy související se zdravým rozumem, což ukazuje zlepšení oproti textovým základním liniím.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Visual grounding er en lovende vej mod mere robuste og nøjagtige Natural Language Processing (NLP) modeller. Mange multimodale udvidelser af BERT (f.eks. VideoBERT, LXMERT, VL-BERT) muliggør en fælles modellering af tekster og billeder, der fører til state-of-the-art resultater på multimodale opgaver som visuel spørgsmål besvarelse. Her udnytter vi multimodal modellering til rent tekstopgaver (sprogmodellering og klassifikation) med forventning om, at multimodal foruddannelse giver en grundlægning, der kan forbedre tekstbehandlingens nøjagtighed. Vi foreslår mulige strategier i denne henseende. En første type strategi, kaldet overført jording, består i at anvende multimodale modeller på tekstbeskyttede opgaver ved hjælp af en pladsholder til at erstatte billedinput. Den anden, som vi kalder associativ grounding, udnytter billedhentning til at matche tekster med relaterede billeder under både forudgående og tekstkun downstream opgaver. Vi trækker yderligere skelner i begge strategier og sammenligner dem derefter i forhold til deres indflydelse på sprogmodellering og almindelig fornuftsrelaterede downstream opgaver, hvilket viser forbedringer i forhold til tekstbaserede basislinjer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Visuelle Erdung ist ein vielversprechender Weg zu robusteren und genaueren Natural Language Processing (NLP)-Modellen. Viele multimodale Erweiterungen von BERT (z.B. VideoBERT, LXMERT, VL-BERT) ermöglichen eine gemeinsame Modellierung von Texten und Bildern, die zu aktuellen Ergebnissen bei multimodalen Aufgaben wie Visual Question Answering führen. Hier nutzen wir multimodale Modellierung für rein textuelle Aufgaben (Sprachmodellierung und Klassifizierung) mit der Erwartung, dass das multimodale Vortraining eine Grundlage bietet, die die Genauigkeit der Textverarbeitung verbessern kann. Wir schlagen diesbezüglich mögliche Strategien vor. Eine erste Art von Strategie, die als übertragene Erdung bezeichnet wird, besteht darin, multimodale Modelle auf reine Textaufgaben anzuwenden, indem ein Platzhalter verwendet wird, um die Bildeingabe zu ersetzen. Die zweite Methode, die wir assoziative Erdung nennen, nutzt die Bildwiederholung, um Texte mit verwandten Bildern zu verknüpfen, sowohl während des Vortrainings als auch bei textbasierten Folgeaufgaben. Wir unterscheiden beide Strategien weiter und vergleichen sie nach ihrem Einfluss auf Sprachmodellierung und Commonsense-bezogene Downstream-Aufgaben und zeigen Verbesserungen gegenüber reinen Textbaselines.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Η οπτική γείωση είναι μια ελπιδοφόρα πορεία προς πιο ισχυρά και ακριβή μοντέλα επεξεργασίας φυσικής γλώσσας. Πολλές πολυεπίπεδες επεκτάσεις του επιτρέπουν μια κοινή μοντελοποίηση κειμένων και εικόνων που οδηγούν σε αποτελέσματα τελευταίας τεχνολογίας σε πολυμορφικές εργασίες, όπως η οπτική απάντηση ερωτήσεων. Εδώ, αξιοποιούμε την πολυμορφική μοντελοποίηση για καθαρά γραπτές εργασίες (μοντελοποίηση και ταξινόμηση γλωσσών) με την προσδοκία ότι η πολυμορφική προεπιλογή παρέχει μια γείωση που μπορεί να βελτιώσει την ακρίβεια επεξεργασίας κειμένου. Προτείνουμε πιθανές στρατηγικές από την άποψη αυτή. Ένας πρώτος τύπος στρατηγικής, που αναφέρεται ως μεταφερόμενη γείωση, συνίσταται στην εφαρμογή πολυμορφικών μοντέλων σε εργασίες μόνο κειμένου χρησιμοποιώντας ένα σύμβολο κράτησης θέσης για την αντικατάσταση της εισαγωγής εικόνας. Το δεύτερο, που ονομάζουμε συσχετιστική γείωση, αξιοποιεί την ανάκτηση εικόνων για να ταιριάξει κείμενα με σχετικές εικόνες τόσο κατά την προεπιλογή όσο και κατά τη διάρκεια εργασιών μόνο κειμένου. Κάνουμε περαιτέρω διακρίσεις και στις δύο στρατηγικές και στη συνέχεια τις συγκρίνουμε ανάλογα με τον αντίκτυπο τους στη γλωσσική μοντελοποίηση και στις μεταγενέστερες εργασίες που σχετίζονται με την κοινή λογική, δείχνοντας βελτίωση σε σχέση με τις γραμμές βάσης μόνο κειμένου.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>La base visual es un camino prometedor hacia modelos de procesamiento del lenguaje natural (NLP) más sólidos y precisos. Muchas extensiones multimodales de BERT (por ejemplo, VideoBERT, LXMERT, VL-BERT) permiten un modelado conjunto de textos e imágenes que conducen a resultados de vanguardia en tareas multimodales, como la respuesta visual a preguntas. Aquí, aprovechamos el modelado multimodal para tareas puramente textuales (modelado y clasificación del lenguaje) con la expectativa de que el preentrenamiento multimodal proporcione una base que pueda mejorar la precisión del procesamiento de textos. Proponemos posibles estrategias en este sentido. Un primer tipo de estrategia, conocida como puesta a tierra transferida, consiste en aplicar modelos multimodales a tareas de solo texto mediante un marcador de posición para reemplazar la entrada de imágenes. La segunda, que llamamos conexión a tierra asociativa, aprovecha la recuperación de imágenes para hacer coincidir los textos con las imágenes relacionadas durante las tareas posteriores de preentrenamiento y solo texto. Hacemos distinciones adicionales en ambas estrategias y luego las comparamos de acuerdo con su impacto en el modelado del lenguaje y las tareas posteriores relacionadas con el sentido común, lo que demuestra una mejora con respecto a las líneas de base solo de texto.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Visuaalne maandus on paljulubav tee tugevamate ja täpsemate looduskeele töötlemise mudelite suunas. Paljud BERTi multimodaalsed laiendused (nt VideoBERT, LXMERT, VL-BERT) võimaldavad ühiselt modelleerida tekste ja pilte, mis viivad kaasaegsete tulemusteni multimodaalsete ülesannete, näiteks visuaalse küsimustele vastamise puhul. Siin kasutame mitmeliigilist modelleerimist puhtalt tekstiülesannete jaoks (keele modelleerimine ja klassifitseerimine), eeldades, et mitmeliigiline eelõpetamine annab aluse, mis võib parandada teksti töötlemise täpsust. Me pakume selles suhtes välja võimalikud strateegiad. Esimene strateegia, mida nimetatakse ülekantavaks maandamiseks, seisneb mitmeliigiliste mudelite rakendamises ainult tekstiga ülesannetele, kasutades pildisisendi asendamiseks kohatäidet. Teine, mida me nimetame assotsiatsiooniliseks maandamiseks, rakendab pilditõmbe, et sobitada tekste seotud piltidega nii eeltreeningu kui ka ainult tekstiga alljärgnevate ülesannete käigus. Me tõmbame mõlemasse strateegiasse täiendavaid eristusi ja seejärel võrdleme neid vastavalt nende mõjule keele modelleerimisele ja üldise mõttega seotud alljärgnevatele ülesannetele, näidates paranemist ainult tekstiga võrreldes.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>زمینه‌های بینایی یک مسیر قوی به سمت مدل‌های قوی‌تر و دقیق‌ترین پردازش زبان طبیعی (NLP) است. بسیاری از گسترش‌های متوسطی BERT (مثل: VideoBERT, LXMERT, VL-BERT) اجازه می‌دهد که یک نمودار متن و تصاویر مشترک را اجازه می‌دهد که به نتیجه‌های حالت هنری روی کار های متوسطی مثل پاسخ پرسیدن سوال‌های بینایی رخ می‌دهد. در اینجا، ما مدل‌سازی چندmodal برای کار‌های پاکیزه‌ای (مدل‌سازی و گروهی‌سازی زبان) را با انتظار می‌گیریم که مدل‌سازی چندmodal یک پایه‌سازی می‌دهد که می‌تواند دقیق‌سازی‌سازی متن را بهتر کند. ما در این مورد استراتژی‌های ممکن پیشنهاد می‌کنیم. یک نوع اولین استراتژی که به عنوان زمینه انتقال داده می‌شود در کاربرد مدل‌های چندین مدل به کار‌های تنها متن استفاده از یک جایگزینی برای جایگزینی ورودی تصویر است. دومین، که ما به اسم زمینه‌های همکاری می‌گوییم، تصویر را برای بازیابی با متن‌های ارتباط با تصویر‌های ارتباط در زمان تکلیف و تکلیف‌های پایین پایین استفاده می‌کند. ما تفاوت‌های بیشتری را به هر دو استراتژی می‌کشیم و سپس آنها را بر طبق تاثیر آنها بر مدل‌سازی زبان و کار‌های پایین‌ترین رابطه‌های معمولی مقایسه می‌کنیم، و بر طبق خطوط‌های پایین‌ترین متن بهترین</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Visuaalinen maadoitus on lupaava tie kohti vankempia ja tarkempia Natural Language Processing (NLP) -malleja. Monet BERT:n multimodaaliset laajennukset (esim. VideoBERT, LXMERT, VL-BERT) mahdollistavat tekstien ja kuvien yhteisen mallintamisen, joka johtaa uusimpiin tuloksiin multimodaalisissa tehtävissä, kuten Visual Question Answering. Tässä hyödynnämme multimodaalista mallinnusta puhtaasti tekstitehtävissä (kielimallinnus ja luokittelu) olettaen, että multimodaalinen esikoulutus tarjoaa perustan, joka voi parantaa tekstin käsittelyn tarkkuutta. Ehdotamme tässä suhteessa mahdollisia strategioita. Ensimmäinen strategia, jota kutsutaan siirretyksi maadoitukseksi, koostuu multimodaalisten mallien soveltamisesta vain tekstiä sisältäviin tehtäviin käyttämällä paikkamerkkiä kuvan syötön korvaamiseksi. Toinen, jota kutsumme assosiatiiviseksi maadoitukseksi, valjastaa kuvanhaun vastaamaan tekstejä toisiinsa liittyviin kuviin sekä esikoulutuksessa että vain tekstejä sisältävissä jatkotehtävissä. Haemme lisää eroja molempiin strategioihin ja vertaamme niitä sen mukaan, miten ne vaikuttavat kielimallinnukseen ja järjettömyyteen liittyviin loppupään tehtäviin.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>La mise à la terre visuelle est une voie prometteuse vers des modèles de traitement du langage naturel (NLP) plus robustes et plus précis. De nombreuses extensions multimodales de BERT (par exemple, VideoBERT, LXMERT, VL-BERT) permettent une modélisation conjointe de textes et d'images qui mènent à des résultats de pointe sur des tâches multimodales telles que la réponse visuelle aux questions. Ici, nous tirons parti de la modélisation multimodale pour des tâches purement textuelles (modélisation et classification du langage) dans l'espoir que la pré-formation multimodale fournit une base qui peut améliorer la précision du traitement de texte. Nous proposons des stratégies possibles à cet égard. Un premier type de stratégie, appelé mise à la terre transférée, consiste à appliquer des modèles multimodaux à des tâches de texte uniquement à l'aide d'un espace réservé pour remplacer la saisie d'image. Le second, que nous appelons la mise à la terre associative, exploite la récupération d'images pour faire correspondre des textes avec des images associées pendant les tâches de pré-apprentissage et les tâches en aval contenant uniquement du texte. Nous établissons des distinctions supplémentaires entre les deux stratégies, puis nous les comparons en fonction de leur impact sur la modélisation du langage et les tâches en aval liées au bon sens, ce qui montre une amélioration par rapport aux lignes de base uniquement textuelles.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Is cosán dóchasach é an bunús amhairc i dtreo múnlaí Próiseála Teanga Nádúrtha (NLP) níos láidre agus níos cruinne. Ligeann go leor síntí ilmhódacha ar BERT (m.sh., VideoBERT, LXMERT, VL-BERT) comhshamhaltú téacsanna agus íomhánna as a dtagann torthaí úrscothacha ar thascanna ilmhódacha ar nós Amharc-Fhreagraí. Anseo, déanaimid samhaltú ilmhódach a ghiaráil le haghaidh tascanna atá ina n-ábhar téacs amháin (samhaltú agus aicmiú teanga) agus muid ag súil go gcuirfidh an réamhoiliúint ilmhódach bonn ar fáil a fhéadfaidh cruinneas próiseála téacs a fheabhsú. Molaimid straitéisí féideartha ina leith seo. Is éard atá sa chéad chineál straitéise, dá ngairtear bunús aistrithe, samhlacha ilmhódacha a chur i bhfeidhm ar thascanna téacs-amháin ag baint úsáide as coimeádán áit chun ionchur íomhá a ionadú. Baineann an dara ceann, ar a dtugaimid bunús comhthiomsaitheach, leas as aisghabháil íomhá chun téacsanna a mheaitseáil le híomhánna gaolmhara le linn réamhoiliúint agus tascanna iartheachtacha téacs amháin. Déanaimid tuilleadh idirdhealaithe sa dá straitéis agus ansin déanaimid comparáid idir iad de réir a dtionchar ar shamhaltú teanga agus ar thascanna iartheachtacha a bhaineann le tuiscint coiteann, rud a léiríonn feabhas ar bhunlínte téacs-amháin.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kunna da gane shi wata hanya ne mai yi wa'adi zuwa misalin Jarayi na Fassarar Farawa (NLP). Babu yawa masu motsi na BERT (misali, video BERT, LXMERT, vL-BERT) don ka yarda wani shirin motsi na littattafai da zane waɗand a ke ƙara wa fassaran-art a kan aikin multi-multiodal kamar jibin tambayar Gani. Hiki, Munã samun misãlai masu multi-multiodal wa aikin littafi masu tsari (misalin harshe da classifori) da matumain cẽwa, girgije na multi-multi zai bãyar da wani jami wanda yake iya ƙara wa aikin matsayi na tsari. Tuna goyya da ikon takwai cikin wannan. Nau'i na farko na yi amfani da wani wurin da aka canza komai cikin ƙungiyoyi da aka transforma na komai yana cikin shirin ayuka masu motsi na multi-multi zuwa aikin matsayi kawai, don ya yi amfani da wani wurin da za'a bada tsarin zane. Kijan na biyu, wanda Muke kiran musamman da komai, yana samun zane da ake sami zuwa matsayin da zane masu husũma da zane-zane masu husũma a lokacin da za'a yi amfani da aikin rubutu da na-rubutu kawai. Munã fizge kodi cikin takilaikin biyu, sa'an nan kuma Mu sami su kamar yadda suka yi wa matsayin misalin harshen da masu husũma da manyan aiki na ƙarƙashin ruwa, kuma Muke nuna mafiya kyau a kan rubutun-rubutu kawai.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>קרקע חזותי הוא דרך מבטיחה לכיוון דוגמנים יותר חזקים ומדויקים של תהליך שפת טבעית (NLP). הרווחים המולטומודליים רבים של BERT (למשל VideoBERT, LXMERT, VL-BERT) מאפשרים דגם משותף של טקסטים ותמונות שמובילים לתוצאות מוקדמות על משימות מולטומודליות כמו תשובות על שאלות ויזואליות. כאן, אנו משתמשים במודילים רבים למשימות טהורות טקסטיות (דוגמניות שפות וסיפור) עם הצפייה שהמתאמנים רבים מספקים קרקע שיכול לשפר את מדויקת העבודה טקסטית. אנחנו מציעים אסטרטגיות אפשריות בנוגע לזה. סוג ראשון של אסטרטגיה, שנקרא "קרקע מועבר" כולל באימוץ מודלים multimodal למשימות טקסט בלבד באמצעות מחזיק מקום להחליף הכניסה של תמונה. השנייה, שאנחנו קוראים לה קרקע חברתי, משתמשת בחזרה של תמונות כדי להתאים טקסטים עם תמונות קשורות במהלך משימות מראש וגם טקסט-בלבד. We draw further distinctions into both strategies and then compare them according to their impact on language modeling and commonsense-related downstream tasks, showing improvement over text-only baselines.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>दृश्य ग्राउंडिंग अधिक मजबूत और सटीक प्राकृतिक भाषा प्रसंस्करण (एनएलपी) मॉडल की ओर एक आशाजनक पथ है। BERT के कई बहुआयामी एक्सटेंशन (उदाहरण के लिए, VideoBERT, LXMERT, VL-BERT) ग्रंथों और छवियों के एक संयुक्त मॉडलिंग की अनुमति देते हैं जो दृश्य प्रश्न उत्तर जैसे बहुआयामी कार्यों पर अत्याधुनिक परिणामों की ओर ले जाते हैं। यहां, हम विशुद्ध रूप से पाठ्य कार्यों (भाषा मॉडलिंग और वर्गीकरण) के लिए मल्टीमॉडल मॉडलिंग का लाभ उठाते हैं, इस उम्मीद के साथ कि मल्टीमॉडल प्रीट्रेनिंग एक ग्राउंडिंग प्रदान करता है जो पाठ प्रसंस्करण सटीकता में सुधार कर सकता है। हम इस संबंध में संभावित रणनीतियों का प्रस्ताव करते हैं। पहले प्रकार की रणनीति, जिसे स्थानांतरित ग्राउंडिंग के रूप में जाना जाता है, में छवि इनपुट को बदलने के लिए प्लेसहोल्डर का उपयोग करके केवल पाठ कार्यों के लिए मल्टीमॉडल मॉडल लागू करना शामिल है। दूसरा एक, जिसे हम साहचर्य ग्राउंडिंग कहते हैं, प्रीट्रेनिंग और टेक्स्ट-ओनली डाउनस्ट्रीम कार्यों दोनों के दौरान संबंधित छवियों के साथ ग्रंथों से मेल खाने के लिए छवि पुनर्प्राप्ति का उपयोग करता है। हम दोनों रणनीतियों में आगे के अंतर को आकर्षित करते हैं और फिर भाषा मॉडलिंग और कॉमनसेंस से संबंधित डाउनस्ट्रीम कार्यों पर उनके प्रभाव के अनुसार उनकी तुलना करते हैं, जो केवल पाठ-केवल बेसलाइन पर सुधार दिखाते हैं।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Visualno osnovanje je obećavajući put prema robnijim i preciznijim modelima procesa prirodnog jezika (NLP). Mnoge multimodalne proširenje BERT (npr. VideoBERT, LXMERT, VL-BERT) omogućavaju zajedničku modelizaciju teksta i slika koji dovode do rezultata umjetnosti na multimodalne zadatke poput odgovora na vizuelno pitanje. Ovdje, uključujemo multimodalnu modelizaciju čisto tekstualnih zadataka (jezička modelizacija i klasifikacija) s očekivanjem da multimodalna pretkivanja pruža temelj koji može poboljšati preciznost obrade teksta. Predlažemo moguće strategije u ovom pogledu. Prva vrsta strategije koja se zove prebacena područja sastoji u primjeni multimodalnih modela samo na tekstualne zadatke koristeći placeholder za zamjenu ulaza slike. Drugi, koji zovemo asocijativno područje, koristi prikupljanje slika kako bi odgovarali tekstima s povezanim slikama tijekom zadataka koji se pretvaraju i samo tekst donosi. Nacrtajemo daljnje razlike u oba strategija i onda ih uspoređujemo u skladu s njihovim utjecajem na modeliranje jezika i spuštanje zadataka povezanih sa zajedničkim osjećajima, pokazujući poboljšanje samo na osnovnim linijama teksta.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A vizuális földelés ígéretes út a robusztusabb és pontosabb Natural Language Processing (NLP) modellek felé. A BERT számos multimodális kiterjesztése (pl. VideoBERT, LXMERT, VL-BERT) lehetővé teszi a szövegek és képek közös modellezését, amelyek a multimodális feladatok, például a vizuális kérdések megválaszolása során a legkorszerűbb eredményekhez vezetnek. Itt kihasználjuk a multimodális modellezést tisztán szöveges feladatokhoz (nyelvmodellezés és osztályozás) azzal a reménnyel, hogy a multimodális előkészítés olyan alapozást biztosít, amely javíthatja a szövegfeldolgozás pontosságát. E tekintetben lehetséges stratégiákat javasolunk. Az átvitt földelésnek nevezett első típusa a multimodális modellek alkalmazása a csak szöveges feladatokra, helyőrző segítségével a kép bevitele helyett. A második, amelyet asszociatív földelésnek nevezünk, a képkeresést arra használja, hogy a szövegekhez kapcsolódó képekhez illeszkedjen mind az előkészítés, mind pedig a szövegcsak downstream feladatok során. További megkülönböztetéseket vonunk mindkét stratégiába, majd összehasonlítjuk azokat a nyelvi modellezésre és a közérzethez kapcsolódó downstream feladatokra gyakorolt hatásuk alapján, amelyek javulást mutatnak a csak szöveges alapvonalakhoz képest.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Տեսական հիմքը խոստացնող ճանապարհ է ավելի ուժեղ և ճշգրիտ բնական լեզվի մշակույթի (ՆԼՊ) մոդելների ուղղությամբ: BERT-ի բազմաթիվ բազմաթիվ ընդլայնումները (օրինակ ՎիդեոBERT-ը, LXմեRT-ը, VL-BERT-ը) թույլ են տալիս համընդհանուր մոդելավորել տեքստներ և պատկերներ, որոնք հանգեցնում են բարձր արդյունքներին բազմաթիվ առաջադրանքների, ինչպիսիք են Վիդեոլ հարցե Այստեղ մենք օգտագործում ենք բազմամոդելային մոդելներ մաքուր տեքստային առաջադրանքների համար (լեզվի մոդելներ և դասակարգում) այն ակնկալությամբ, որ բազմամոդելային նախադասությունը տալիս է հիմք, որը կարող է բարելավել տեքստի վերամշակման ճշգրտու Մենք առաջարկում ենք հնարավոր ռազմավարություններ այս հարցում: Առաջին ռազմավարության տեսակը, որը կոչվում է փոխանցված հոսանքներ, կազմում է կիրառելով բազմամոդալ մոդելներ միայն տեքստի առաջադրանքների վրա՝ օգտագործելով տեղաշարժիչ պատկերի ներմուծման փոխարինելու համար: Երկրորդը, որը մենք անվանում ենք ասոցատիվ հիմնադրամ, օգտագործում է պատկերի վերադարձումը, որպեսզի համընկնի տեքստները հարաբերվող պատկերների հետ նախադասության և միայն տեքստի ընթացքում: Մենք երկու ռազմավարությունների վերաբերյալ ավելի շատ տարբերակներ ենք կատարում և համեմատում դրանք ըստ նրանց ազդեցության լեզվի մոդելավորման և ընդհանուր զգացմունքով կապված հետագա խնդիրների, որոնք ցույց են տալիս զարգացում միայն տեքստի հիմն</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Pemasangan visual adalah jalan yang berjanji menuju model proses bahasa alam (NLP) yang lebih kuat dan akurat. Banyak ekstensi multimodal BERT (contohnya, VideoBERT, LXMERT, VL-BERT) memungkinkan sebuah model kongsi dari teks dan gambar yang membawa ke hasil terbaik dalam tugas multimodal seperti Jawaban Pertanyaan Visual. Di sini, kita menggunakan model multimodal untuk tugas pura-pura tekstual (model bahasa dan klasifikasi) dengan harapan bahwa pretraining multimodal menyediakan dasar yang dapat meningkatkan akurasi proses teks. Kami mengusulkan strategi yang mungkin dalam hal ini. Tipe pertama strategi, yang disebut sebagai grounding yang dipindahkan terdiri dalam aplikasi model multimodal untuk tugas teks-hanya menggunakan pemegang tempat untuk menggantikan input gambar. Yang kedua, yang kita sebut grounding asosiatif, menggunakan retrieval gambar untuk cocok teks dengan gambar yang berhubungan selama kedua latihan dan tugas turun teks-sahaja. Kami menarik perbedaan lanjut ke dalam kedua strategi dan kemudian membandingkan mereka berdasarkan dampak mereka pada model bahasa dan tugas turun terkait umum, menunjukkan peningkatan atas garis dasar hanya teks.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>La messa a terra visiva è un percorso promettente verso modelli di elaborazione del linguaggio naturale (NLP) più robusti e accurati. Molte estensioni multimodali di BERT (ad esempio VideoBERT, LXMERT, VL-BERT) consentono una modellazione congiunta di testi e immagini che portano a risultati all'avanguardia su attività multimodali come Visual Question Answering. Qui, sfruttiamo la modellazione multimodale per attività puramente testuali (modellazione e classificazione del linguaggio) con l'aspettativa che il pretraining multimodale fornisca una base in grado di migliorare l'accuratezza dell'elaborazione del testo. Proponiamo possibili strategie in questo senso. Un primo tipo di strategia, denominato trasferimento a terra, consiste nell'applicare modelli multimodali alle attività di solo testo utilizzando un segnaposto per sostituire l'input dell'immagine. Il secondo, che chiamiamo messa a terra associativa, sfrutta il recupero delle immagini per abbinare i testi con le immagini correlate sia durante le attività a valle di pretraining che solo testo. Trattiamo ulteriori distinzioni in entrambe le strategie e poi le confrontiamo in base al loro impatto sulla modellazione linguistica e sulle attività downstream correlate al senso comune, mostrando miglioramenti rispetto alle linee di base solo testuali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>視覚的接地は、より堅牢で正確な自然言語処理（ NLP ）モデルへの有望なパスです。 BERTの多くのマルチモーダルエクステンション（例えば、VideoBERT、LXMERT、VL - BERT ）は、テキストと画像の共同モデリングを可能にし、視覚的質問応答などのマルチモーダルタスクの最先端の結果につながる。 ここでは、純粋なテキストタスク（言語モデリングと分類）のためのマルチモーダルモデリングを活用し、マルチモーダルプレトレーニングがテキスト処理の精度を向上させることができるグラウンディングを提供することを期待しています。 この点については、可能な戦略を提案します。 転送グラウンディングと呼ばれる第１のタイプの戦略は、画像入力を置き換えるためにプレースホルダを使用してテキストのみのタスクにマルチモーダルモデルを適用することである。 2つ目は、連想接地と呼ばれ、事前トレーニングとテキストのみのダウンストリームタスクの両方で、テキストと関連する画像を一致させるために画像取得を利用します。 両方の戦略にさらに区別を加え、言語モデリングと共通感覚に関連する下流タスクへの影響に応じて比較し、テキストのみのベースラインよりも改善されていることを示します。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Visual grunding is a perbudhakan langkung rawuh akeh sistem gak stabil karo akeh pakan langkung (NLP). politenessoffpolite"), and when there is a change ("assertivepoliteness string" in "context_BAR_stringLink Awak dhéwé ngerti perusahaan pancen kanggo nggawe iki. A first type of policy, listed as transfer background Digawe Awak dhéwé nglanggar luwih-luwih dumateng lan padha sampek nggawe gerakan karo perusahaan langkung model lan basa sing ngregani layar, iso nggawe luwih-luwih basa sing menehi iki.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ვიზუალური ფორმაცია არის უფრო ძალიან და უფრო წესიერი სახელის პროცესი (NLP) მოდელებისთვის. BERT- ის მულტიმოდიალური გაფართლებები (მაგალითად, VideoBERT, LXMERT, VL- BERT) შესაძლებელია ტექსტის და გამოსახულების ერთადერთი მოდელირება, რომელიც მულტიმოდიალური დავალებების შესახებ, როგორც ვიზუალური კითხვების გასაგრძელება. აქ, ჩვენ მულტიმოდიალური მოდელირებას მხოლოდ ტექსტულური დავალებებისთვის (ენის მოდელირება და კლასიფიკაცია) გავაკეთებთ, რომ მულტიმოდიალური მოდელირება შეუძლიათ ტექსტულის პროცესის წესის გაუფ ჩვენ შესაძლებელი სტრატიგიების შესახებ ამ შესახებ. პირველი სტრატიგიის ტიპი, რომელიც გადატანსტრებულია ფონტაქტის გამოყენებაში მულტიმოდელური მოდელების გამოყენებაში მხოლოდ ტექსტიური დავალებების გამოყენებაში, გამოყენებ მეორე, რომელსაც ჩვენ ვუხედავთ აცისოციენტიური ფონტირება, გამოიყენება სურათის მიღება ტექსტის შესაბამისთვის შესაბამისთვის გამოსაბამისთვის გამოსაბამისთვის, რომე ჩვენ უფრო მეტი განსხვავებები ორივე სტრატეგიაში და შემდეგ ისინი განსხვავებენ ენის მოდელეციის და საერთო სიგრძნობის დაკავშირებული დავალებების შემდეგ, რომელიც ტექსტის მხოლოდ ფ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Көрінетін түсіндіру - күшті және дұрыс тіл процессорының (NLP) моделдеріне қатынау жолы. BERT көптеген көптеген кеңейтулер (мысалы, VideoBERT, LXMERT, VL- BERT) мәтін мен кескіндердің біріктіру үшін көптеген мәтіндер мен кескіндерді моделдеу мүмкіндігін мүмкіндік береді. Көрінетін сұрақ жауап беру секілді көптеген тап Мұнда біз текстік тапсырмалар (тіл моделі және классификациясы) үшін көптеген көптеген модель модельдерді күту үшін көмектесеміз. Мәтін өңдеу дұрыстығын өзгертуге болады. Бұл үшін мүмкін стратегияларды таңдаймыз. Кескінді алмастыру үшін орындаушы қолдану үшін тек мәтін- тапсырмаларына көп модель үлгілерін қолдану үшін бірінші стратегия түрі. Екіншіден, біз қосымша түрлі түрлі деп аталамыз, кескінді түрлендіру және тек мәтін түрлендіру тапсырмаларына сәйкес кескіндермен сәйкес келеді. Екі стратегияларға қосымша бөліктерді салыстырып, оларды тілдерді моделдеу және көпшілік сезімдеріне қатысты тапсырмаларды салыстырып, тек мәтін негізгі сызықтардың жақсартуы</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>시각적 기초는 더욱 건장하고 정확한 자연언어처리(NLP) 모델을 실현하는 희망적인 경로이다.BERT의 많은 다중모드 확장(예를 들어 VideoBERT, LXMERT, VL-BERT)은 텍스트와 이미지를 연합하여 모델링할 수 있어 시각 퀴즈 등 다중모드 작업에서 가장 선진적인 결과를 낼 수 있다.여기서 우리는 다중모드 모델링을 이용하여 순수한 텍스트 작업(언어 모델링과 분류)을 완성하고 다중모드 예비 훈련이 텍스트 처리의 정밀도를 향상시키는 데 기반을 마련할 수 있기를 기대한다.우리는 이 방면에서 가능한 전략을 제시했다.첫 번째 정책은 이미지 입력 대신 자리 표시자를 사용하고 다중모드 모델을 순수한 텍스트 작업에 응용하는 것을 포함한다.두 번째 방법은 연상 접지라고 하는데 이미지 검색을 이용하여 훈련 전과 텍스트만 하는 하위 임무에서 텍스트를 관련 이미지와 일치시킨다.우리는 이 두 가지 전략을 한층 더 구분한 다음에 언어 모델링과 상식과 관련된 하위 임무에 대한 영향을 비교한 결과 순수한 텍스트 기선보다 개선되었다는 것을 알 수 있다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vizualinis pagrindas yra perspektyvus kelias siekiant patikimesnių ir tikslesnių gamtos kalbų apdorojimo (NLP) modelių. Daugelis įvairiarūšio pobūdžio BERT išplėtimų (pvz., VideoBERT, LXMERT, VL-BERT) leidžia bendrai modeliuoti tekstus ir vaizdus, kurie duoda naujausių rezultatų daugiarūšio pobūdžio uždaviniuose, pavyzdžiui, atsakymuose į vizualiuosius klausimus. Čia naudojame daugiarūšio modeliavimo modeliavimą vien tekstinėms užduotims (kalbų modeliavimas ir klasifikavimas) tikėdamiesi, kad daugiarūšio išankstinio mokymo pagrindas gali pagerinti teksto apdorojimo tikslumą. Šiuo atžvilgiu siūlome galimas strategijas. Pirmą strategijos rūšį, vadinamą perduotu antžeminiu pagrindu, sudaro daugiarūšio pobūdžio modelių taikymas tik teksto užduotims, naudojant vietos turėtoją vaizdo įvedimui pakeisti. The second one, which we call associative grounding, harnesses image retrieval to match texts with related images during both pretraining and text-only downstream tasks. Toliau atskiriame abi strategijas ir palyginame jas atsižvelgiant į jų poveikį kalbų modeliavimui ir su bendrąja prasme susijusias tolesnes užduotis, rodančias pagerėjimą, palyginti su tik teksto bazėmis.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Визуелното основање е ветувачки пат кон појаки и прецизни модели за процес на природен јазик (NLP). Многу мултимодилни проширувања на BERT (на пример, VideoBERT, LXMERT, VL-BERT) овозможуваат заедничко моделирање на текстови и слики кои водат до најсовремени резултати на мултимодилните задачи како што е Визуелно одговорување на прашањата. Овде, ние го користиме мултимодилниот модел за чисто текстуални задачи (јазички модел и класификација) со очекувањата дека мултимодилниот претренинг обезбедува основа која може да ја подобри прецизноста на текстовите процеси. Предложуваме можни стратегии во врска со ова. Првиот тип на стратегија, наречен префрлено основање, се состои од апликација на мултимодилни модели на задачи само за текст, користејќи место за замена на влогот на слика. Вториот, кој го нарекуваме асоцијативно основање, го искористува преземањето на слики за да се совпаѓа текстот со поврзаните слики за време на претренирањето и само текстот на долните задачи. Навлекуваме понатамошни разлики во двете стратегии и потоа ги споредуваме во согласност со нивното влијание на јазичното моделирање и заедничките задачи поврзани со сензијата, покажувајќи подобрување во однос на основните линии само за текст.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>കാഴ്ചയുള്ള ഗ്രൂണിങ്ങ് കൂടുതല്‍ കൂടുതല്‍ റോബ്സ്റ്റും കൃത്യമായ സ്വാഭാവിക ഭാഷ പ്രവര്‍ത്തനങ്ങളുടെ (NLP) മോഡലുകളി BERT (ഉദാഹരണമായ വിഡിയോബെര്‍ട്ടി, LXMERT, VL- BERT) പാഠങ്ങളുടെയും ചിത്രങ്ങളുടെയും കൂടുതല്‍ മൊഡലിങ്ങ് അനുവദിക്കുന്നു. കാഴ്ചയുള്ള ചോദ്യങ്ങള്‍ ഇവിടെ ഞങ്ങള്‍ ടെക്സ്കൂള്‍ ജോലികളുടെ (ഭാഷ മാതൃകയും ക്ലാസ്ഫിക്ഷനും) മുഴുവന്‍ മഴ പ്രചരിപ്പിക്കുന്ന ഒരു ഗ്രൂണിങ്ങ് നല്‍കുന്നു. ടെക്സ്റ്റ് പ്രോ We propose possible strategies in this respect. മാറ്റിമാറ്റുന്ന ഗ്രൂണിങ്ങിനെപ്പറ്റി വിളിക്കുന്ന ഒരു ആദ്യത്തെ തരത്തിലുള്ള ഒരു പ്ലാസ്റ്റെഹോര്‍ട്ടര്‍ ഇമേജ് ഇന്‍പുട്ട് മാ രണ്ടാമത്തെ രണ്ടാമത്തേത്, നമ്മള്‍ സംഘത്തെ വിളിക്കുന്നത് സംബന്ധിച്ച ചിത്രങ്ങളോടൊപ്പം പദാവലികള്‍ പൊരുതാന്‍ വേണ്ടി ചിത്രം വീണ് നമ്മള്‍ രണ്ടുപേര്‍ക്കും വ്യത്യാസങ്ങളിലേക്ക് വേര്‍പെടുത്തുന്നു. പിന്നീട് അവയെ ഭാഷ മോഡലിങ്ങിന്‍റെയും കമോണ്‍സണ്‍സെന്‍സിന്‍റെയും നദി</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Харин харагдах зүйл бол илүү хүчтэй, тодорхой Байгалийн хэл Процессор (NLP) загварын загвар юм. БЕРТ-ын олон модуль дэвшилт (жишээ нь Видео-Берт, LXMERT, VL-BERT) нь хариултын асуулт хариулт гэх мэт олон модуль үйл ажиллагааны төвшин урлагийн үр дүнд хүргэж чадна. Энд бид олон загварын загвар (хэл загвар болон хуваалцах) загваруудыг олон загварын загвар ашигладаг. Мэдээллийн загвар нь текст үйлдвэрлэлийн зөв байдлыг сайжруулж чадна. Бид үүнд боломжтой стратегийг санал болгож байна. Эхний төрлийн стратеги, шилжүүлэгдсэн шалтгаан гэж нэрлэгдэх олон моделийн загваруудыг текст зөвхөн даалгаваруудыг ашиглан зураг орлуулахын тулд хэрэглэдэг. Хоёрдугаарт бид холбоотой суурь гэж нэрлэдэг, зураг авах нь холбоотой зурагтай холбоотой зурагтай холбоотой юм. Бид стратегийг хоёр дахин өөрчлөгдөж, дараа нь хэл загварчлалын, нийтлэг мэдрэмжтэй доорх үйл ажиллагааны нөлөөтэй харьцуулж, текст зөвхөн суурь шугам дээр сайжруулж байна.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Pemasangan visual adalah laluan yang berjanji menuju ke model Pemprosesan Bahasa Alami (NLP) yang lebih kuat dan tepat. Banyak sambungan multimodal BERT (cth., VideoBERT, LXMERT, VL-BERT) membenarkan pemodelan bersama teks dan imej yang membawa kepada keputusan-state-of-the-art pada tugas multimodal seperti Jawapan soalan Visual. Di sini, kita menggunakan pemodelan multimodal untuk tugas pura-pura teks (pemodelan bahasa dan klasifikasi) dengan jangkaan bahawa pralatihan multimodal menyediakan pendaratan yang boleh meningkatkan ketepatan pemprosesan teks. Kami cadangkan strategi yang mungkin dalam hal ini. Jenis pertama strategi, yang disebut sebagai grounding dipindahkan terdiri dalam melaksanakan model multimodal kepada tugas teks-sahaja menggunakan pemegang ganti untuk menggantikan input imej. Yang kedua, yang kita panggil grounding asosiatif, menggunakan pemulihan imej untuk padan teks dengan imej berkaitan semasa kedua-dua latihan dan tugas bawah teks-sahaja. Kita lukiskan perbezaan lebih lanjut ke dalam kedua-dua strategi dan kemudian membandingkannya mengikut kesan mereka pada model bahasa dan tugas turun berkaitan dengan umum, menunjukkan peningkatan atas garis dasar teks-sahaja.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Il-bażi viżwali hija triq promettenti lejn mudelli aktar robusti u preċiżi tal-ipproċessar tal-lingwi naturali (NLP). Many multimodal extensions of BERT (e.g., VideoBERT, LXMERT, VL-BERT) allow a joint modeling of texts and images that lead to state-of-the-art results on multimodal tasks such as Visual Question Answering. Hawnhekk, nagħmlu użu minn mudell multimodali għal kompiti purament testwali (mudell tal-lingwi u klassifikazzjoni) bl-istennija li t-taħriġ minn qabel multimodali jipprovdi bażi li tista’ ttejjeb il-preċiżjoni tal-ipproċessar tat-test. Nipproponu strateġiji possibbli f'dan ir-rigward. L-ewwel tip ta’ strateġija, imsejjaħ “grounding” trasferit tikkonsisti fl-applikazzjoni ta’ mudelli multimodali għal kompiti tat-test biss bl-użu ta’ detentur ta’ post biex jissostitwixxi l-input tal-immaġni. It-tieni wieħed, li jissejjaħ grounding assoċjattiv, juża l-irkupru tal-immaġni biex jaqbel mat-testi ma’ immaġni relatati kemm waqt it-taħriġ minn qabel kif ukoll waqt il-kompiti downstream tat-test biss. We draw further distinctions into both strategies and then compare them according to their impact on language modeling and commonsense-related downstream tasks, showing improvement over text-only baselines.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Visuele aarding is een veelbelovend pad naar robuustere en nauwkeurigere Natural Language Processing (NLP)-modellen. Veel multimodale uitbreidingen van BERT (bijv. VideoBERT, LXMERT, VL-BERT) maken een gezamenlijke modellering van teksten en afbeeldingen mogelijk die leiden tot state-of-the-art resultaten bij multimodale taken zoals Visual Question Answering. Hier maken we gebruik van multimodale modellering voor puur tekstuele taken (taalmodellering en classificatie) met de verwachting dat de multimodale pretraining een basis biedt die de nauwkeurigheid van tekstverwerking kan verbeteren. Wij stellen hiervoor mogelijke strategieën voor. Een eerste type strategie, aangeduid als overgedragen aarding, bestaat uit het toepassen van multimodale modellen op alleen tekst-taken met behulp van een tijdelijke aanduiding om beeldinvoer te vervangen. De tweede, die we associatieve aarding noemen, maakt gebruik van beeldterugwinning om teksten te matchen met gerelateerde afbeeldingen tijdens zowel pretraining als tekst-only downstream taken. We maken verder onderscheid in beide strategieën en vergelijken ze vervolgens op basis van hun impact op taalmodellering en gezond verstand gerelateerde downstreamtaken, wat verbeteringen aantoont ten opzichte van alleen tekst baselines.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Visuelt grunnlegging er ein promessant bane mot meir sterkt og nøyaktig naturspråk-handlingsmodular (NLP). Mange fleire modular utvidingar av BERT (f.eks. VideoBERT, LXMERT, VL-BERT) tillèt ei saman modellering av tekstar og bilete som fører til tilstanden av kunsten til fleire oppgåver slik som Visuelt spørsmålssvar. Her leverer vi multimodal modellering for pur tekstoppgåver (språk modellering og klassifikasjon) med forventinga at multimodal trekking tilbyr ein grunnlegging som kan forbetra tekstprosesserings nøyaktighet. Vi foreslår moglege strategiar i denne hendinga. Eit første type strategi som er referert til overførte bakgrunn inneheld i bruk av multimodal modeller til berre tekstoppgåver med eit plasshaldar for å erstatta inndata av bilete. Den andre, som vi kallar asosiativ bakgrunnen, brukar biletet til å henta til tekst med relaterte bilete under både trekking og berre nedstrekkoppgåver med tekst. Vi tegnar meir forskjellingar i både strategier og så samanliknar dei etter sine påvirkning på språk modellering og fellesskapslinjerelaterte nedtrekkoppgåver, viser forbetringa over berre tekstbaselinjer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Uziemienie wizualne jest obiecującą drogą do bardziej solidnych i dokładnych modeli przetwarzania języka naturalnego (NLP). Wiele multimodalnych rozszerzeń BERT (np. VideoBERT, LXMERT, VL-BERT) umożliwia wspólne modelowanie tekstów i obrazów, co prowadzi do najnowocześniejszych wyników w zadaniach multimodalnych, takich jak Visual Question Respwering. Tutaj wykorzystujemy modelowanie multimodalne do czysto tekstowych zadań (modelowanie językowe i klasyfikacja) z oczekiwaniem, że multimodalne wstępne szkolenie zapewni uziemienie, które może poprawić dokładność przetwarzania tekstu. Proponujemy możliwe strategie w tym zakresie. Pierwszy rodzaj strategii, określany jako uziemienie transferowe polega na zastosowaniu modeli multimodalnych do zadań tekstowych za pomocą symbolu zastępczego w celu zastąpienia wejścia obrazu. Drugi, który nazywamy uziemieniem asocjacyjnym, wykorzystuje odzyskiwanie obrazów do dopasowywania tekstów do powiązanych obrazów zarówno podczas zadań wstępnego szkolenia, jak i tylko tekstowego. Wyróżniamy obie strategie, a następnie porównujemy je w zależności od ich wpływu na modelowanie językowe i zadania związane ze zdrowym rozsądkiem, pokazując poprawę nad liniami bazowymi wyłącznie tekstowymi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>O aterramento visual é um caminho promissor para modelos de processamento de linguagem natural (NLP) mais robustos e precisos. Muitas extensões multimodais do BERT (por exemplo, VideoBERT, LXMERT, VL-BERT) permitem uma modelagem conjunta de textos e imagens que levam a resultados de última geração em tarefas multimodais, como o Visual Question Answering. Aqui, aproveitamos a modelagem multimodal para tarefas puramente textuais (modelagem e classificação de linguagem) com a expectativa de que o pré-treinamento multimodal forneça uma base que possa melhorar a precisão do processamento de texto. Propomos estratégias possíveis a este respeito. Um primeiro tipo de estratégia, conhecido como aterramento transferido, consiste em aplicar modelos multimodais a tarefas somente de texto usando um espaço reservado para substituir a entrada de imagem. O segundo, que chamamos de aterramento associativo, aproveita a recuperação de imagens para combinar textos com imagens relacionadas durante as tarefas de pré-treinamento e somente texto. Traçamos mais distinções em ambas as estratégias e as comparamos de acordo com seu impacto na modelagem de linguagem e nas tarefas downstream relacionadas ao senso comum, mostrando melhorias em relação às linhas de base somente de texto.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Împământarea vizuală este o cale promițătoare către modele mai robuste și mai precise de procesare a limbajului natural (NLP). Multe extensii multimodale ale BERT (de exemplu, VideoBERT, LXMERT, VL-BERT) permit o modelare comună a textelor și imaginilor care duc la rezultate de ultimă generație în sarcini multimodale, cum ar fi răspunsul la întrebări vizuale. Aici, utilizăm modelarea multimodală pentru sarcini pur textuale (modelarea și clasificarea limbii) cu așteptarea că pretraining multimodal oferă o bază care poate îmbunătăți acuratețea procesării textului. Propunem strategii posibile în acest sens. Un prim tip de strategie, denumit împământare transferată, constă în aplicarea modelelor multimodale la activitățile numai text utilizând un substituent pentru a înlocui introducerea imaginii. Al doilea, pe care noi îl numim fundamentare asociativă, valorifică recuperarea imaginilor pentru a potrivi textele cu imaginile asociate atât în timpul activităților de pregătire, cât și în timpul activităților din aval numai text. Tragem distincții suplimentare în ambele strategii și apoi le comparăm în funcție de impactul lor asupra modelării limbajului și a sarcinilor din aval legate de bunul sens, arătând îmbunătățiri față de liniile de bază doar text.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Визуальное заземление - это перспективный путь к более надежным и точным моделям обработки естественного языка (NLP). Многие мультимодальные расширения BERT (например, VideoBERT, LXMERT, VL-BERT) позволяют совместно моделировать тексты и изображения, которые приводят к самым современным результатам в мультимодальных задачах, таких как визуальный ответ на вопросы. Здесь мы используем мультимодальное моделирование для чисто текстовых задач (языковое моделирование и классификация) с ожиданием, что мультимодальное предварительное обучение обеспечивает заземление, которое может улучшить точность обработки текста. В этой связи мы предлагаем возможные стратегии. Первый тип стратегии, называемый переданным заземлением, заключается в применении мультимодальных моделей к задачам только с текстом, используя местозаполнитель для замены ввода изображения. Второй, который мы называем ассоциативным заземлением, использует извлечение изображений для сопоставления текстов с соответствующими изображениями как во время предварительного обучения, так и только в текстовых задачах. Мы проводим дальнейшие различия в обеих стратегиях, а затем сравниваем их в соответствии с их влиянием на моделирование языка и задачи, связанные с общим смыслом, показывая улучшение по сравнению с базовыми линиями только для текста.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ප්‍රශ්න භාෂාව ප්‍රශ්නයක් තමයි තරම් ශක්තිමත් සහ සාමාන්‍ය භාෂාව ප්‍රශ්නය (NLP) මොඩේල් වලට ප්‍ර BERT (උදාහරණයෙන්, Video BERT, LXMERT, VL-BERT) ගොඩක් විශාල ප්‍රතිබිත්තුවක් සම්පූර්ණය සහ පිළිබඳ ප්‍රතිබිත්තුවක් සම්පූර්ණය කරන්න සම්පූර්ණය සඳහා ප්‍රතිබ මෙතන, අපි විශේෂ විශේෂ විශේෂය (භාෂාව විශේෂණය සහ විශේෂණය) ගොඩක් මොඩිමෝඩාල් මොඩිල් මොඩිල් මොඩිල් විශේෂණය කරනවා මොඩි අපි මේ ගෞරවයට පුළුවන් සැලසුම් කරනවා. පින්තූර ඇතුලට පළමු ප්‍රමාණයක් විතරයි, පින්තූර ඇතුලට ප්‍රතියෝජනයක් භාවිත කරන්න ස්ථානය සඳහා පින්තූර ඇතුලට දෙවෙනි එක, අපි සම්බන්ධ පුළුවන් කියලා කියලා, පින්තූර පුළුවන් පුළුවන් පුළුවන් පින්තූරය සමග සම්බන්ධ පින අපි තව ප්‍රතිශේෂණ දෙන්නම් ප්‍රතිශේෂණ දෙන්නම් ප්‍රතිශේෂණය කරනවා, ඊට පස්සේ ඔවුන්ගේ භාෂාව මොඩිලින් සහ සාමාන්‍ය අ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vizualna ozemljitev je obetavna pot k robustnejšim in natančnejšim modelom obdelave naravnega jezika (NLP). Številne multimodalne razširitve BERT (npr. VideoBERT, LXMERT, VL-BERT) omogočajo skupno modeliranje besedil in slik, ki vodijo do najsodobnejših rezultatov pri multimodalnih nalogah, kot je vizualno odgovarjanje na vprašanja. Pri tem izkoristimo multimodalno modeliranje za izključno besedilna opravila (jezikovno modeliranje in klasifikacija) s pričakovanjem, da multimodalno predurjenje zagotavlja utemeljitev, ki lahko izboljša natančnost obdelave besedila. V zvezi s tem predlagamo možne strategije. Prva vrsta strategije, imenovana prenesena ozemljitev, je uporaba multimodalnih modelov za opravila samo z besedilom z označbo mesta za nadomestitev vnosa slike. Drugi, ki ga imenujemo asociativno ozemljanje, izkorišča pridobivanje slik, da se besedila ujemajo s sorodnimi slikami tako pri predurjenju kot tudi pri nadaljnjih opravilih samo besedila. V obeh strategijah črpamo nadaljnje razlike in jih nato primerjamo glede na njihov vpliv na jezikovno modeliranje in z dobrim smislom povezana nadaljnja opravila, kar kaže izboljšanje v primerjavi z osnovnimi črtami samo besedila.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kooxa aragnimadu waa wado loo ballanqaaday oo u jeeda qaababka lagu soo bandhigayo afka asalka ah oo si saxda ah (NLP). BERT (e.g., VideoBERT, LXMERT, VL-BERT) waxaa la ogolaa tusaale wadajir ah sameynta qoraal iyo sawirro oo ka keena resultada-of-the-art shaqooyin badan, tusaale ahaan jawaabta su'aalaha aragtida. Here, we leverage multimodal modeling for purely textual tasks (language modeling and classification) with the expectation that the multimodal pretraining provides a grounding that can improve text processing accuracy. Waxaynu soo jeedaynaa qoraal suurtagal ah ee arinkan. Qoraalka kooxa ugu horeeya ee lagu magacaabay kooxa la wareejiyo waxaa ka mid ah codsashada tusaalayaal kala duduwan oo loo isticmaalayo shaqooyinka qoraalka oo kaliya si loo beddelo sawirka. Mida labaad ee aan ugu magacaabno kooxo wadajir ah, waxay leedahay sawir la soo celin karo si ay u dhigto qoraal la xiriira sawirro xilliga sameynta tababarka iyo shaqooyinka hoose-hoose oo kaliya. Sida waafaqsan saameynta ku saabsan sameynta afka iyo hawlaha hoose ee ku saabsan sameynta qoraalka oo kaliya ee ku saabsan sameynta luuqadda, waxaana tusnaa hagaajinta qorshaha qoraalka oo kaliya.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Fundimi vizual është një rrugë premtuese drejt modeleve më të forta dhe më të sakta të Procesimit të Gjuhave Natyrore (NLP). Shumë zgjerime multimodal e të BERT (për shembull, VideoBERT, LXMERT, VL-BERT) lejojnë një modelim të përbashkët të teksteve dhe imazheve që shpien në rezultate më të larta në detyra multimodale të tilla si përgjigjet vizuale të pyetjeve. Here, we leverage multimodal modeling for purely textual tasks (language modeling and classification) with the expectation that the multimodal pretraining provides a grounding that can improve text processing accuracy. Ne propozojmë strategji të mundshme në këtë lidhje. A first type of strategy, referred to as transferred grounding consists in applying multimodal models to text-only tasks using a placeholder to replace image input. I dyti, i cili ne e quajmë bazim shoqëror, përdorë marrjen e imazhit për të përputhur tekstet me imazhet e lidhura gjatë detyrave të parastërvitjes dhe vetëm tekstit në vazhdim. Ne tërheqim dallime të mëtejshme në të dy strategjitë dhe pastaj i krahasojmë ato sipas ndikimit të tyre në modelimin gjuhësor dhe detyrat e përbashkëta të lidhura me ndjekjen poshtë, duke treguar përmirësim mbi linjat bazë të vetëm tekstit.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Visualno osnovanje je obećavajući put ka robnijim i tačnijim modelima procesa prirodnog jezika (NLP). Mnoge multimodalne proširenje BERT (npr. VideoBERT, LXMERT, VL-BERT) omogućavaju zajedničku modelizaciju teksta i slika koje dovode do rezultata umjetnosti na multimodalne zadatke poput odgovora na vizuelno pitanje. Ovdje, uključujemo multimodalnu modelizaciju čisto tekstualnih zadataka (jezička modelizacija i klasifikacija) sa očekivanjem da multimodalna pretkivanja pruža osnovu koja može poboljšati tačnost obrade teksta. Predlažemo moguće strategije u ovom pogledu. Prva vrsta strategije koja se zove prebacena zemlja sastoji od primjene multimodalnih modela na samo tekstualne zadatke koristeći placeholder za zamjenu unosa slika. Drugi, koji zovemo asocijativno područje, koristi povratak slika kako bi odgovarali tekstima sa povezanim slikama tijekom zadataka koji se pretvaraju, i samo tekstualno spuštaju. Nacrtajemo daljnje razlike u oba strategija i onda ih uspoređujemo u skladu s njihovim utjecajem na modeliranje jezika i spuštanje zadataka povezanih sa zajedničkim smisluma, pokazujući poboljšanje samo tekstskih osnovnih linija.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Visuell jordning är en lovande väg mot mer robusta och exakta Natural Language Processing (NLP)-modeller. Många multimodala tillägg av BERT (t.ex. VideoBERT, LXMERT, VL-BERT) möjliggör en gemensam modellering av texter och bilder som leder till toppmoderna resultat på multimodala uppgifter som Visual Question Answering. Här utnyttjar vi multimodal modellering för rent textmässiga uppgifter (språkmodellering och klassificering) med förväntan om att multimodal förbehandling ger en grundning som kan förbättra textbearbetningens noggrannhet. Vi föreslår möjliga strategier i detta avseende. En första typ av strategi, kallad överförd jordning, består i att tillämpa multimodala modeller på textbara uppgifter med hjälp av en platshållare för att ersätta bildinmatning. Den andra, som vi kallar associativ grounding, utnyttjar bildhämtning för att matcha texter med relaterade bilder under både förberedande och textbara nedströmsuppgifter. Vi gör ytterligare åtskillnader i båda strategierna och jämför dem sedan utifrån deras inverkan på språkmodellering och allmännyttiga nedströmsuppgifter, vilket visar förbättringar jämfört med textbaserade baslinjer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kundi la kuona ni njia inayoahidiwa kuelekea mifano ya Utafiti wa Lugha za asili na sahihi (NLP). Mpango mkubwa wa BERT (kwa mfano VideoBERT, LXMERT, VL-BERT) unaruhusu muundo wa pamoja wa maandishi na picha zinazosababisha matokeo ya sanaa kwenye kazi nyingine kama vile swali la Visual. Hapa, tunatumia mifano mingi kwa ajili ya kazi za msingi tu (mifano ya lugha na usambazaji wa lugha) kwa matumaini kwamba mvua mbalimbali unatoa kundi ambalo linaweza kuboresha uhakika wa upasuaji wa teknolojia. Tunazipendekeza mikakati inayowezekana katika heshima hii. a in a ya kwanza ya mkakati, inayoitwa kama makundi yanayohamishwa inahusisha kutumia mifano mingi kwa kazi za maandishi pekee kwa kutumia placeholder ili kubadilisha input wa picha. Kila pili, ambacho tunaiita makundi ya ushirikiano, inatumia picha ya kupambana na maandishi yanayohusiana na picha zinazohusiana wakati wa kujificha na kazi za kuandika kwa kutumia mitandao pekee. We draw further distinctions into both strategies and then compare them according to their impact on language modeling and commonsense-related downstream tasks, showing improvement over text-only baselines.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>பார்வையான குழுக்கம் அதிகமாக மாறுதல் மற்றும் சரியான இயல்பான மொழி செயல்பாடு (NLP) மாதிரி Many multimodal extensions of BERT (e.g., VideoBERT, LXMERT, VL-BERT) allow a joint modeling of texts and images that lead to state-of-the-art results on multimodal tasks such as Visual Question Answering. இங்கே நாம் மெய்யாகவே உரை பணிகளுக்கு பல்முறைமையான மாதிரிமாதிரியை வழங்குகிறோம் (மொழி மாதிரி மற்றும் வகைப்படுத்தல்) பலமுறையான மாதிரியில் மா இந்த மதிப்பில் சாத்தியமான திட்டங்களை நாம் பரிந்துரைக்கிறோம். மாற்றப்பட்ட குழு என்று குறிப்பிடப்பட்ட முதல் வகையான திட்டத்தில் உள்ளது பிம்பத்தின் உள்ளீட்டை மாற்ற ஒரு இடப்பெட்டி மட்டும் உரையில இரண்டாவது ஒன்று, நாம் இணைப்பு குழுவை அழைக்கும் பிம்பத்தை மீட்டெடுக்கும் போது தொடர்புடைய உருவங்களுடன் பொருத்தும் உரையை மட்டும நாம் இரண்டு திட்டங்களுக்கும் மேலும் வேறுபாடுகளை வரைகிறோம் பின்னர் அவை மொழி மாதிரி மாதிரியில் ஒப்பிடுகிறது மற்றும் தொழில்நுட்</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Görnüş ýerleşmek dogry we dogry Dil işlemegi (NLP) nusgalaryna gollaýan bir söz ýoldur. BERT'yň köp modal eklentisi (meselâ, VideoBERT, LXMERT, VL-BERT) g örnüş sorag jogaplama ýaly multimodal işlerinde meňzeş modal eserler modellerine mümkin edýär Bu ýerde, metin işlerini düzeltmek üçin multimodal modellendirmek üçin (diller modellendirmek we klasifikasyon) multimodal süýtgetmek üçin bir ýer gabdalyk saýlayar. Biz bu barada mümkin strategiýalary teklip edýäris. Transfer edilen ýerleri diňe metin-täblisaň üçin ullanýan ilkinji tür strategiýa. Ikinjisi, asosyýat ýerleşdirim diýip atlandyrýan täzeliklerde hem tekst-diňe aşak täzeliklerde metinler bilen meňzeşleýän suratlary taýýarlaýar. Biz her iki stratejiýa daşary çykarýarys we soňra olary dil modelleýäniň we daşary duýgunlaryň daşary täsirlerine görä çykarýarys, diňe tekst diňe basehatlaryň üstünde gelişmeleri görkez.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Visual grounding is a promising path to more robust and accurate Natural Language Processing (NLP) models. BERT کی بہت سی موڈال اضافہ (جیسے ویڈیوBERT, LXMERT, VL-BERT) ایک متن اور تصاویروں کے جوڑے موڈلینگ کی اجازت دیتی ہے جو بہت سی موڈال کاموں پر موجود رہتے ہیں جیسے Visual Question Answering. یہاں، ہم بہت سی موڈلیل موڈلینگ (زبان موڈلینگ اور کلاسیک) کی امید رکھتے ہیں کہ multimodal pretraining ایک گرانڈی پیدا کرتا ہے جو ٹیکسٹ پرسینگ دقیقیت کو بہتر کر سکتا ہے۔ ہم اس کے بارے میں ممکن استراتژی پیشنهاد کرتے ہیں۔ ایک پہلی طریقہ استراتژی، جو منتقل ہوئی زمین کی نام سے منتقل ہوئی موڈل کو متعدم موڈل کے لئے لکھنے کے لئے صرف ایک پلیس هولڈر کے مطابق استعمال کرتا ہے۔ دوسرا، جسے ہم مشترک زمین بناتے ہیں، تصویر پھیرنے کے لئے متعلق تصویروں کے ساتھ ملنے کے لئے استعمال کرتا ہے، صرف ڈونٹریٹریٹ کے کاموں میں اور متعلق کے بارے میں. ہم ان دونوں استراتژی میں اضافہ کریں گے اور پھر ان کی تاثیر کے مطابق ان کی زبان مدلینگ اور عادت کے معاملہ کے نیچے مسائل کی تاثیر کے مطابق ان کی تاثیر کے مطابق ان کی تاثیر کریں گے، یہاں تک کہ متن کے</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Name Name Bu yerda biz bir multimodalar modelini faqat matn vazifalar (tillar modellash va classifikasi) uchun ishlab chiqaramiz. Ko'pchilik davomida o'zgarishni tasavvur qilishi mumkin. Matn jarayonlarining tashkilotni aniqlash imkoniyatini oshirish mumkin. Bu haqida biz imkoniyatli strategiya qilamiz. Transfer qilingan guruhning birinchi turi rasm kiritish uchun multimodal modellarini faqat matn vazifalari bilan ishlatish mumkin. Ikkinchi marta, biz buni birinchi bog'liq guruh deb ataymiz, rasmlarni olib tashlashni tasavvur qilish va faqat tahrirlash vazifalari bilan bog'liq rasmlar bilan bog'liq boʻlgan matnlarni o'zgartirish mumkin. Biz ikkita strategiyani koʻproq o'zgarishni chiqaramiz va keyin ularni tilning modeli va kommunikasi bilan bog'liq vazifalarga kamaytirimiz va faqat matn asosiy sonlaridan yaxshi ko'rsatish mumkin.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nhìn ngắm là một con đường hứa hẹn để đạt trình độ phát triển ngôn ngữ tự nhiên mạnh mẽ và chính xác hơn. Nhiều sự mở rộng đa phương pháp của BERT (v.d., VideoBERT, LXMENT, VL-BERT) cho phép kết hợp tạo mẫu văn bản và ảnh dẫn đến kết quả hiện đại về các công việc đa chiều như câu hỏi ảo. Ở đây, chúng ta dựa trên mô hình đa phương cho các công việc văn bản thuần túy (tạo mẫu ngôn ngữ và phân loại) với sự mong đợi rằng tính toán tiền trước đa phương cung cấp một nền tảng có thể cải thiện độ chính xác xử lý văn bản. Chúng tôi đề xuất các phương pháp có thể. Một kiểu chiến lược đầu tiên, được gọi là sự khởi động đã được chuyển đến là áp dụng các mô hình đa phương để thực hiện các công việc chỉ văn bản, dùng người giữ chỗ thay thế ảnh. Cái thứ hai, mà chúng tôi gọi là nền hỗ trợ, khai thác ảnh để khớp với các văn bản với các ảnh tương ứng trong khi chụp trước và chỉ đọc xuôi dòng. Chúng tôi phân biệt sâu hơn cả hai chiến lược và sau đó so sánh họ dựa trên tác động của họ về việc tạo mẫu ngôn ngữ và các công việc theo dòng chảy liên tục, cho thấy cải tiến trên nền văn bản.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>视基者,所以通强大,正自然语言处 (NLP) 形者也。 BERT者多模态广(如VideoBERT,LXMERT,VL-BERT)许合建模于文本与图像,以多模态之务(视)最先进也。 多模态建模于纯文本(言建模类),期于多模态预训练可以崇准确性基。 吾等于此有可言之略。 一曰移(接地)用占位符易象于纯文本。 其二,谓之关联接地,以像检练纯文本下流,以文本配之。 二者分别,然后因其言语建模与常识相关,以见出对纯文本基线之改。</span></div></div><dl><dt>Anthology ID:</dt><dd>2021.lantern-1.2</dd><dt>Volume:</dt><dd><a href=/volumes/2021.lantern-1/>Proceedings of the Third Workshop on Beyond Vision and LANguage: inTEgrating Real-world kNowledge (LANTERN)</a></dd><dt>Month:</dt><dd>April</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Kyiv, Ukraine</dd><dt>Venues:</dt><dd><a href=/venues/eacl/>EACL</a>
| <a href=/venues/lantern/>LANTERN</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>19–29</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.lantern-1.2>https://aclanthology.org/2021.lantern-1.2</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">sileo-2021-visual</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Damien Sileo. 2021. <a href=https://aclanthology.org/2021.lantern-1.2>Visual Grounding Strategies for Text-Only Natural Language Processing</a>. In <i>Proceedings of the Third Workshop on Beyond Vision and LANguage: inTEgrating Real-world kNowledge (LANTERN)</i>, pages 19–29, Kyiv, Ukraine. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2021.lantern-1.2>Visual Grounding Strategies for Text-Only Natural Language Processing</a> (Sileo, LANTERN 2021)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2021.lantern-1.2.pdf>https://aclanthology.org/2021.lantern-1.2.pdf</a></dd><dt>Data</dt><dd><a href=https://paperswithcode.com/dataset/bookcorpus>BookCorpus</a>,&nbsp;<a href=https://paperswithcode.com/dataset/coco>COCO</a>,&nbsp;<a href=https://paperswithcode.com/dataset/imagenet>ImageNet</a>,&nbsp;<a href=https://paperswithcode.com/dataset/superglue>SuperGLUE</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2021.lantern-1.2.pdf title="Open PDF of 'Visual Grounding Strategies for Text-Only Natural Language Processing'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Visual+Grounding+Strategies+for+Text-Only+Natural+Language+Processing" title="Search for 'Visual Grounding Strategies for Text-Only Natural Language Processing' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'Visual Grounding Strategies for Text-Only Natural Language Processing'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[Visual Grounding Strategies for Text-Only Natural Language Processing](https://aclanthology.org/2021.lantern-1.2) (Sileo, LANTERN 2021)</p><ul class=mt-2><li><a href=https://aclanthology.org/2021.lantern-1.2>Visual Grounding Strategies for Text-Only Natural Language Processing</a> (Sileo, LANTERN 2021)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Damien Sileo. 2021. <a href=https://aclanthology.org/2021.lantern-1.2>Visual Grounding Strategies for Text-Only Natural Language Processing</a>. In <i>Proceedings of the Third Workshop on Beyond Vision and LANguage: inTEgrating Real-world kNowledge (LANTERN)</i>, pages 19–29, Kyiv, Ukraine. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>