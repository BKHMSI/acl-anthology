<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>What to Learn, and How: Toward Effective Learning from Rationales - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="What to Learn, and How: Toward Effective Learning from Rationales" name=citation_title><meta content="Samuel Carton" name=citation_author><meta content="Surya Kanoria" name=citation_author><meta content="Chenhao Tan" name=citation_author><meta content="Findings of the Association for Computational Linguistics: ACL 2022" name=citation_conference_title><meta content="2022/5" name=citation_publication_date><meta content="https://aclanthology.org/2022.findings-acl.86.pdf" name=citation_pdf_url><meta content="1075" name=citation_firstpage><meta content="1088" name=citation_lastpage><meta property="og:title" content="What to Learn, and How: Toward Effective Learning from Rationales"><meta property="og:image" content="https://aclanthology.org/thumb/2022.findings-acl.86.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2022.findings-acl.86"><meta property="og:description" content="Samuel Carton, Surya Kanoria, Chenhao Tan. Findings of the Association for Computational Linguistics: ACL 2022. 2022."><link rel=canonical href=https://aclanthology.org/2022.findings-acl.86></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2022.findings-acl.86.pdf>What to Learn, and How: <span class=acl-fixed-case>T</span>oward Effective Learning from Rationales</a>
<a id=af_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Analiseer Dinamiese Adversariale Oefening Data in die Grens</a>
<a id=am_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>dialogs-action</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>تحليل بيانات التدريب الديناميكي العدائي في الحد</a>
<a id=az_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Sınırda Dynamik Adversarial Training Data Analyzing</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Анализиране на динамичните данни за неблагоприятно обучение в границите</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>সীমান্তে ডাইনামিক প্রশিক্ষণ তথ্য বিশ্লেষণ করা হচ্ছে</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>ཚད་འཛིན་ནང་གི་སྤྱིར་གཏོང་གི་Adversarial Training Data་ཞིབ་དཔྱད་བྱེད་བཞིན་པ</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Analiziranje dinamičkih naprednih podataka za obuku u granici</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Analitzar les dades dinàmiques d'entrenament adversari al límit</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Analýza dat dynamického nepřátelského tréninku v limitu</a>
<a id=da_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Analyse af dynamiske negative træningsdata i grænsen</a>
<a id=de_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Analyse dynamischer Adversarial Trainingsdaten im Limit</a>
<a id=el_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Ανάλυση δυναμικών αρνητικών δεδομένων εκπαίδευσης στο όριο</a>
<a id=es_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Análisis de datos dinámicos de entrenamiento contradictorio en el límite</a>
<a id=et_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Dünaamiliste kõrvaltoimete koolituse andmete analüüsimine piirides</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>تحلیل داده‌های آموزش تحقیقات دینامیک در محدوده</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Dynaamisten haittaharjoitustietojen analysointi rajassa</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Analyser les données dynamiques d'entraînement contradictoire dans les limites</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Anailís a dhéanamh ar Shonraí Oiliúna Sáraíochta Dinimiciúla sa Teorainn</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Ana analyza data na Training na Dama cikin Limit</a>
<a id=he_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>ניתוח נתוני אימון נוגדי דינמי בגבול</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>सीमा में डायनेमिक प्रतिकूल प्रशिक्षण डेटा का विश्लेषण करना</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Analiziranje dinamičkih poremećajnih podataka obuke u granici</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Dinamikus negatív edzési adatok elemzése a határon belül</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Դինամական հակառակ վարժման տվյալների վերլուծությունը սահմանափակում</a>
<a id=id_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Analisasi Data Pelatihan Atas Dinamik dalam Batas</a>
<a id=is_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Analisi dei dati di allenamento avversi dinamici nel limite</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>限界内の動的対抗トレーニングデータの分析</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Language</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Name</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Динамикалық конверсариялық оқыту деректерін шектеу</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>극한 상태에서 동적 대항 훈련 데이터 분석</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Dinaminių nepalankiojo mokymo duomenų analizė riboje</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Анализирање на динамските податоци за непријатно обука во границата</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>സീമിറ്റില്‍ ഡിനാനിക്കല്‍ പരിശീലന വിവരങ്ങള്‍ അന്വേഷിക്കുന്നു</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Хязгаарт шинжлэх ухааны дасгал хөдөлгөөн өгөгдлийг шинжилгээ</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Menganalisis Data Latihan Melawan Dinamik dalam Had</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Analiżi ta’ Dejta Dinamika ta’ Taħriġ Adversarju fil-Limitu</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Dynamic Adversarial Training Data in the Limit analyseren</a>
<a id=no_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Analiserer dynamiske rekursarialske treningsdata i grensen</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Analiza dynamicznych danych treningowych przeciwników w granicy</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Analisando Dados de Treinamento Dinâmico Adversarial no Limite</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Analiza datelor de antrenament adversar dinamic în limita</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Анализ данных динамического обучения соперников в лимите</a>
<a id=si_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Name</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Analiza dinamičnih podatkov o neželenem treningu v meji</a>
<a id=so_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Analyzerka macluumaadka waxbarashada ee cilmiga</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Analizimi i të dhënave dinamike të trajnimit kundërshtar në kufi</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Analiziranje dinamičkih naprednih podataka za obuku u granici</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Analysera dynamiska negativa träningsdata i gränsen</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Anachambua taarifa za mafunzo ya kidynamic katika Mipaka</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>எல்லையில் Dynamic முன்னேற்றம் பயிற்சி தகவல்களை ஆய்வு செய்கிறது</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Dinamik Ullanyş Taýramçylyk Maglumaty Çözümleme</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>محدودیت میں داینامیکی اڈورسٹرین ٹرینینگ ڈاٹا تحلیل کیا جا رہا ہے</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Name</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>Phân tích dữ liệu về tình trạng chờ tế bào</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2022.findings-acl.86.pdf>于限内分析动度</a></h2><p class=lead><a href=/people/s/samuel-carton/>Samuel Carton</a>,
<a href=/people/s/surya-kanoria/>Surya Kanoria</a>,
<a href=/people/c/chenhao-tan/>Chenhao Tan</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Learning from rationales seeks to augment model prediction accuracy using human-annotated rationales (i.e. subsets of input tokens) that justify their chosen labels, often in the form of intermediate or multitask supervision. While intuitive, this idea has proven elusive in practice. We make two observations about human rationales via empirical analyses:1) maximizing rationale supervision accuracy is not necessarily the optimal objective for improving model accuracy; 2) human rationales vary in whether they provide sufficient information for the model to exploit for prediction.Building on these insights, we propose several novel loss functions and learning strategies, and evaluate their effectiveness on three datasets with human rationales. Our results demonstrate consistent improvements over baselines in both label and rationale accuracy, including a 3% accuracy improvement on MultiRC. Our work highlights the importance of understanding properties of human explanations and exploiting them accordingly in model training.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Om modele te skep wat sterk is deur 'n wyse reek van toets inputs, moet onderwerp datastelle verskeie voorbeelde insluit wat veelvuldige fenomene uitbrei. Dinamiese texantariese data versameling (DADC), waar annotators byvoorbeelde verwerp wat voorspoedings wat voortgaan voortgaan voortgaan wat voortgaan voortgaan verbeter modele, hou belofte as 'n toegang vir die genereer van sodanige verskeie onderwerp stelle. Vorige werk het vertoon dat loop DADC oor 1- 3 ronde kan hulp modele help om sommige fout tipes te reg, maar dit doen nie noodsaaklik lei na beter generalisering buite adversariale toets data. Ons argumenteer dat die hardloop van DADC oor baie ronde maksimeer sy oefening-tyd voordeel, want die verskillende ronde kan saam baie van die taak-relevante fenomene oordeel. Ons stel die eerste studie van langer-term DADC waar ons 20 ronde van NLI voorbeelde versamel vir 'n klein stel van premise paragraaf, met beide teenstandaarlike en nie-teenstandaarlike toegang. Models onderwerp op DADC voorbeelde maak 26\% minder foute op ons ekspertiefasteerde toets stel vergelyk met modele onderwerp op nie- adversariale data. Ons analisie vertoon dat DADC voorbeelde wat moeilik is, meer leksik en sintaktisies verskeie, en bevat minder annotasie kunstenaars in vergelyking met nie-adversariale voorbeelde.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>በዙሪያው ፈተና ጥያቄዎች ላይ የሚነጥቁትን ምሳሌዎች ለመፍጠር፣ የዳታ ማህበረሰብ ብዙዎችን አካባቢ ምሳሌዎች እንዲያስተካክሉ ይገባዋል፡፡ የዲያኖሚክ ተቃዋሚዎች ዳታ ሰብስብ (DADC), where annotators craft ምሳሌs ሁልጊዜ በመጠቀም ሞዴሎችን የሚያቃልሉ ምሳሌዎች፣ እንደዚህ ልዩ ልዩ ተማሪ መስመር ማቀናጃ ለመፍጠር ለመስጠት ተስፋ ያደርጋል፡፡ የቀድሞው ስራ ከ1-3 ክፍል በላይ DADC ሊሮጥ የስህተት ዓይነቶችን ሊረዳ የሚችል እንደሆነ አስታውቆታል፤ ነገር ግን በተቃዋሚ ፈተና ዳታዎችን በማሻል አያስፈልግም። ብዙ አካባቢዎች ላይ DADC የሚሮጥ የግንኙነቱን የጊዜው ጥቅሞችን በማድረግ እናዋጋለን፡፡ የረጅም ቀን ዲዲ ሲ የመጀመሪያውን ትምህርት እናቀርባታለን፣ በዚያው 20 የNLI ውጤቶች ምሳሌዎችን ለመቆጣጠር እናስቀድዳለን፡፡ በDADC ምሳሌዎች ላይ የተጠቃሚ ሞዴል 26\1 በመቶ ስህተት በሚያነሳው በተቃዋሚ ዳታዎች ላይ በተማመሩ ሞዴላዎች ይደረጋሉ፡፡ ትምህርታችን DADC ከጭንቅ፣ ሌክሲካዊ እና በተለየ ልዩ ልዩ ምሳሌዎችን ያሳየዋል፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>لإنشاء نماذج قوية عبر مجموعة واسعة من مدخلات الاختبار ، يجب أن تتضمن مجموعات بيانات التدريب أمثلة متنوعة تغطي العديد من الظواهر. جمع البيانات الديناميكية العدائية (DADC) ، حيث يصنع المعلقون أمثلة تتحدى النماذج التي تتحسن باستمرار ، يبشر بالخير كنهج لتوليد مثل هذه المجموعات التدريبية المتنوعة. أظهر العمل السابق أن تشغيل DADC على مدى 1-3 جولات يمكن أن يساعد النماذج في إصلاح بعض أنواع الأخطاء ، لكنه لا يؤدي بالضرورة إلى تعميم أفضل يتجاوز بيانات الاختبار العدائية. نجادل بأن تشغيل DADC على عدة جولات يزيد من فوائد وقت التدريب ، حيث يمكن للجولات المختلفة أن تغطي معًا العديد من الظواهر ذات الصلة بالمهام. نقدم الدراسة الأولى لـ DADC على المدى الطويل ، حيث نجمع 20 جولة من أمثلة NLI لمجموعة صغيرة من الفقرات الافتتاحية ، مع كل من المناهج العدائية وغير العدائية. النماذج المدربة على أمثلة DADC تجعل الأخطاء أقل بنسبة 26٪ في مجموعة الاختبار المنسقة من الخبراء لدينا مقارنة بالنماذج المدربة على البيانات غير العدائية. يُظهر تحليلنا أن DADC ينتج أمثلة أكثر صعوبة وأكثر تنوعًا معجميًا وتركيبيًا ، وتحتوي على عدد أقل من القطع الأثرية مقارنة بالأمثلة غير العدائية.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Müxtəlif məlumatlar arasında möhkəm modellər yaratmaq üçün, təhsil verilənlər təhsil etmək üçün çoxlu məlumatlar genişlənir. Dynamic adversarial data collection (DADC), where annotators craft examples that challenge continuously improving models, holds promise as a approach for generating such different training sets. Əvvəlki işin 1-3 səviyyədə DADC çalışması modellərin bəzi xəta növlərini düzəltməsinə kömək edə biləcəyini göstərdi, amma bu, əleyhinə sınamaq məlumatından daha yaxşı generalizasiya yol verməz. Biz mübahisə edirik ki, DADC çalışması çox çətinliklərdə təhsil vaxtının faydalarını artırar, çünki fərqli çətinliklərdən çoxlarını birləşdirə bilər. Daha uzun müddətli DADC təhsilinin ilk təhsilini göstərdik, ki, buna görə də düşmənçilik və düşmənçilik olmayan NLI məsəllərini 20 runda toplayırıq. DADC nümunələrində təhsil edilən modellər ekspertlərimiz təhsil edilmiş sınamamızda 26\% daha az xəta verir. Bizim analizimiz DADC'nin daha çətin, daha hekayətli və sintaktik olaraq müxtəlif məsəllərini göstərir və düşmənçilik olmayan məsəllərlə qarşılaşdırmaq üçün daha az danışmaq məsəllərini daxil edir.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>За да се създадат модели, които са здрави в широк спектър от входящи тестове, наборите от данни за обучение трябва да включват разнообразни примери, които обхващат множество явления. Динамично събиране на противоречиви данни (ДАДК), където анотаторите изработват примери, които предизвикват непрекъснато подобряващите се модели, е обещаващо като подход за генериране на такива разнообразни набори от обучение. Предишна работа е показала, че стартирането на ДАД в рамките на 1-3 кръга може да помогне на моделите да коригират някои типове грешки, но не е задължително да доведе до по-добро обобщаване извън данните от теста. Ние твърдим, че управлението на ДАДК в много кръгове увеличава ползите от времето на обучение, тъй като различните кръгове могат заедно да обхванат много от свързаните със задачата явления. Представяме първото проучване на по-дългосрочния ДАДК, където събираме 20 кръга примери от НЛИ за малък набор от параграфи от предпоставки, както с противоречиви, така и с непротиворечиви подходи. Моделите, обучени по примери правят 26\% по-малко грешки в нашия експертен набор от тестове в сравнение с моделите, обучени по неконкурентни данни. Анализът ни показва, че дава примери, които са по-трудни, по-лексично и синтактично разнообразни и съдържат по-малко анотационни артефакти в сравнение с неконкурентните примери.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>To create models that are robust across a wide range of test inputs, training datasets should include diverse examples that span numerous phenomena. যেখানে বিভিন্ন প্রশিক্ষণ নির্মাণের জন্য বিভিন্ন প্রশিক্ষণ সেট তৈরি করার প্রতিশ্রুতি প্রদান করা হয়েছে। প্রাথমিক কাজ প্রদর্শন করা হয়েছে যে ১-৩ রাউন্ড চালানো DADC কিছু ত্রুটি ধরনের মোডেল ঠিক করতে সাহায্য করতে পারে, কিন্তু এটি বিরোধী পরীক্ষা ত আমরা যুক্তি দিচ্ছি যে অনেক রাউন্ডে ডিএডিসি চালানো হচ্ছে তার প্রশিক্ষণ-সময়ের সুবিধা বৃদ্ধি করে, কারণ বিভিন্ন রাউন্ডের বিভিন্ন আমরা দীর্ঘমেয়াদী ডিডিসির প্রথম গবেষণা উপস্থাপন করেছি, যেখানে আমরা ২০ রাউন্ড এনলির উদাহরণ সংগ্রহ করেছি একটি ছোট প্রাথমিক প্যাপারেসের জন্য, যা ডিডিসি উদাহরণে প্রশিক্ষিত মডেল ২৬\শতাংশ ভুল করে আমাদের বিশেষজ্ঞ-কার্ডের পরীক্ষার সেটের তুলনায় আমাদের বিরোধী তথ্যে প্ আমাদের বিশ্লেষণ দেখাচ্ছে যে ডিএডিসি এর উদাহরণ দেখিয়েছে যা আরো কঠিন, আরো লেক্সিক্সিক এবং সিন্টাক্সিক ভাবে বিভিন্ন ভিন্ন, আর তার মধ্য</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>དཔེ་དབྱེ་བ་དག་གི་ནང་དུ་བརྟག་དཔེ་དབྱིབས་ཡོད་པའི་མིག Dynamic adversarial data collection (DADC), where annotators craft examples that challenge continuously improving models, holds a promise as an approach for generating such a diverse training sets. Prior work has shown that running DADC over 1-3 rounds can help models fix some error types, but it does not necessarily lead to better generalization beyond adversarial test data. ང་ཚོས་DADC་འཁོར་སྐྱོད་བྱས་ནས་སྐབས་ཆར་གྱི་དོན་ལས་ཕན་ཚུལ་ཆེ་ཤོས་བསྐྱེད་ཚད་མང་ཤོས་ཏེ། ང་ཚོས་DADC བརྟག་ཞིབ་འཇུག་རྒྱུ་དང་པོ་དེ་ལྟ་བུ་བཏོན་པའི་གནད་དོན་ཐེངས་ཀྱི་དཔེར་བརྗོད་ཆོག Models trained on DADC examples make 26\% fewer errors on our expert-curated test set compared to models trained on non-adversarial data. Our analysis shows that DADC yields examples that are more difficult, more lexically and syntactically diverse, and contain fewer annotation artifacts compared to non-adversarial examples.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Da bi stvorili modele koji su snažni u širokom nizu testnih ulaganja, podaci obuke trebali bi uključiti različite primjere koje šire brojne fenomene. Dinamička kolekcija neprijateljskih podataka (DADC), gdje annotatori navode primjere koji izazivaju stalno poboljšavanje modela, obećava se kao pristup stvaranju takvih različitih seta obuke. Prije posla pokazala je da vodeći DADC preko 1-3 runde može pomoći modelima da popravi neke vrste greške, ali ne mora da dovede do bolje generalizacije izvan podataka o negativnim testiranjima. Tvrdimo da trčanje DADC tokom mnogih runda maksimalizuje svoju korist za trening, jer različite runde zajedno mogu pokriti mnoge od fenomena vezanih za zadatak. Predstavljamo prvo ispitivanje dugoročnog DADC-a, gdje skupljamo 20 rundi primjera NLI-a za mali skup premijskih paragrafa, sa objektivnim i ne-adversarnim pristupima. Modeli obučeni na primjerima DADC-a čine 26\% manje greške na našem testu u usporedbi s modelima obučenim na neprijateljskim podacima. Naša analiza pokazuje da DADC daje primjere koje su teže, leksičkije i sintaktički različite, i sadrže manje artifakta annotacije u usporedbi s neadversarnim primjerima.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Per crear models robustos a través d'una amplia gama d'entrades de prova, els conjunts de dades d'entrenament haurien d'incloure diversos exemples que abarcan molts fenomens. La col·lecció dinàmica de dades adversaries (DADC), on els anotators fan exemples que desafian els models de millora continua, té promesa com un enfocament per generar aquests conjunts de formació tan diversos. La feina anterior ha demostrat que executar DADC durant 1-3 rondes pot ajudar els models a arreglar alguns tipus d'errors, però no necessariament porta a una millor generalització més enllà de les dades de prova adversaria. Argumentem que executar el DADC durant moltes rondes maximitza els beneficis del temps d'entrenament, com les diferents rondes poden cobrir molts dels fenomens pertinents a la tasca. Presentam el primer estudi de DADC a llarg termini, on recollim 20 rondes d'exemples de NLI per un petit conjunt de paràgrafs premises, amb abords adversaris i no adversaris. Els models entrenats en exemples DADC fan un 26\% menys errors en el nostre conjunt d'exàmens curat per experts en comparació amb models entrenats en dades no adversaries. La nostra anàlisi mostra que el DADC produeix exemples que són més difícils, més lexicament i sinàcticament diversos, i contenen menys artefactes d'anotació comparats amb exemples no adversaris.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Chcete-li vytvořit modely robustní napříč širokou škálou testovacích vstupů, měly by tréninkové datové sady obsahovat různé příklady, které zahrnují řadu jevů. Dynamický adversariální sběr dat (DADC), kde anotátoři vytvářejí příklady, které zpochybňují neustále zlepšující se modely, má slibný přístup k generování tak rozmanitých tréninkových sad. Předchozí práce ukázaly, že spuštění DADC přes 1-3 kola může pomoci modelům opravit některé typy chyb, ale nemusí nutně vést k lepší zobecnění nad rámec kontroverzních testovacích dat. Tvrdíme, že běh DADC v mnoha kolech maximalizuje jeho výhody v době tréninku, protože různá kola mohou společně pokrýt mnoho jevů relevantních pro úkoly. Představujeme první studii dlouhodobějšího DADC, kde shromažďujeme dvacet kol NLI příkladů pro malý soubor premisních odstavců, s nepřátelskými i nepřátelskými přístupy. Modely trénované na příkladech DADC způsobují 26\% méně chyb v naší zkušební sadě vytvořené experty ve srovnání s modely trénovanými na nepřátelských datech. Naše analýza ukazuje, že DADC přináší příklady, které jsou složitější, lexicky a syntakticky různorodější a obsahují méně anotačních artefaktů ve srovnání s nepřátelskými příklady.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>For at skabe modeller, der er robuste på tværs af en lang række testinput, bør træningsdatasæt indeholde forskellige eksempler, der spænder over talrige fænomener. Dynamisk adversarial data collection (DADC), hvor kommentatorer laver eksempler, der udfordrer løbende forbedrede modeller, er lovende som en tilgang til at generere så forskelligartede træningssæt. Tidligere arbejde har vist, at kørsel af DADC over 1-3 runder kan hjælpe modeller med at rette nogle fejltyper, men det fører ikke nødvendigvis til bedre generalisering ud over modstridende testdata. Vi hævder, at kørsel af DADC over mange runder maksimerer dets træningstidsfordele, da de forskellige runder sammen kan dække mange af de opgaverelevante fænomener. Vi præsenterer den første undersøgelse af længerevarende DADC, hvor vi samler 20 runder af NLI eksempler til et lille sæt præmisser afsnit, med både modstridende og ikke-modstridende tilgange. Modeller, der er trænet i DADC eksempler, gør 26% færre fejl på vores ekspertgrupperede testsæt sammenlignet med modeller, der er trænet på ikke-modstandsdata. Vores analyse viser, at DADC giver eksempler, der er mere vanskelige, mere leksikologisk og syntaktisk forskelligartede og indeholder færre annotationsartefakter sammenlignet med ikke-modstridende eksempler.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Um Modelle zu erstellen, die über ein breites Spektrum von Testeingaben hinweg robust sind, sollten Trainingsdatensätze vielfältige Beispiele enthalten, die zahlreiche Phänomene umfassen. Dynamische adversariale Datenerfassung (DADC), bei der Annotatoren Beispiele anfertigen, die kontinuierlich verbesserte Modelle herausfordern, ist ein vielversprechender Ansatz, um solch vielfältige Trainingssets zu generieren. Frühere Arbeiten haben gezeigt, dass das Ausführen von DADC über 1-3-Runden Modellen helfen kann, einige Fehlertypen zu beheben, aber es führt nicht notwendigerweise zu einer besseren Verallgemeinerung jenseits von kontroversen Testdaten. Wir argumentieren, dass das Führen von DADC über viele Runden die Vorteile der Trainingszeit maximiert, da die verschiedenen Runden zusammen viele der aufgabenrelevanten Phänomene abdecken können. Wir präsentieren die erste Studie des längerfristigen DADC, in der wir 20-Runden von NLI-Beispielen für einen kleinen Satz von Prämisse-Absätzen sammeln, mit sowohl kontradisorischen als auch nicht-kontradisorischen Ansätzen. Modelle, die auf DADC-Beispielen trainiert werden, machen 26\% weniger Fehler in unserem von Experten kuratierten Testset im Vergleich zu Modellen, die auf nicht-gegnerischen Daten trainiert wurden. Unsere Analyse zeigt, dass DADC Beispiele liefert, die schwieriger, lexikalisch und syntaktisch vielfältiger sind und weniger Annotationsartefakte enthalten als nicht-kontroverse Beispiele.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Για τη δημιουργία μοντέλων που είναι ανθεκτικά σε ένα ευρύ φάσμα εισροών δοκιμών, τα σύνολα δεδομένων κατάρτισης θα πρέπει να περιλαμβάνουν διάφορα παραδείγματα που καλύπτουν πολλά φαινόμενα. Η δυναμική συλλογή δεδομένων αντιδιαστάσεων (όπου σχολιαστές δημιουργούν παραδείγματα που αμφισβητούν τη συνεχή βελτίωση των μοντέλων, αποτελεί υπόσχεση ως προσέγγιση για τη δημιουργία τέτοιων διαφορετικών εκπαιδευτικών συνόλων. Προηγουμένες εργασίες έχουν δείξει ότι η εκτέλεση σε κύκλους 1-3 μπορεί να βοηθήσει τα μοντέλα να διορθώσουν ορισμένους τύπους σφαλμάτων, αλλά δεν οδηγεί απαραίτητα σε καλύτερη γενίκευση πέρα από τα αντικρουόμενα δεδομένα δοκιμής. Υποστηρίζουμε ότι η εκτέλεση σε πολλούς γύρους μεγιστοποιεί τα οφέλη του χρόνου κατάρτισης, καθώς οι διάφοροι γύροι μπορούν να καλύψουν μαζί πολλά από τα σχετικά με την εργασία φαινόμενα. Παρουσιάζουμε την πρώτη μελέτη του μακροπρόθεσμου DADC, όπου συγκεντρώνουμε είκοσι γύρους παραδειγμάτων για ένα μικρό σύνολο παραγράφων προϋποθέσεων, με αντιφατικές και μη αντιφατικές προσεγγίσεις. Τα μοντέλα που εκπαιδεύονται βάσει παραδειγμάτων κάνουν 26\% λιγότερα λάθη στο σετ δοκιμών που επιμελούνται από εμπειρογνώμονες σε σύγκριση με τα μοντέλα που εκπαιδεύονται σε μη αντίπαλα δεδομένα. Η ανάλυσή μας δείχνει ότι η DADC αποδίδει παραδείγματα που είναι πιο δύσκολα, πιο λεξικά και συντακτικά διαφορετικά, και περιέχουν λιγότερα τεχνουργήματα σχολιασμού σε σύγκριση με μη αντιπαραβαλλόμενα παραδείγματα.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Para crear modelos que sean sólidos en una amplia gama de entradas de prueba, los conjuntos de datos de entrenamiento deben incluir diversos ejemplos que abarquen numerosos fenómenos. La recopilación dinámica de datos contradictorios (DADC), en la que los anotadores crean ejemplos que desafían los modelos que mejoran continuamente, es prometedora como enfoque para generar conjuntos de entrenamiento tan diversos. Trabajos anteriores han demostrado que ejecutar DADC durante 1 a 3 rondas puede ayudar a los modelos a corregir algunos tipos de error, pero no necesariamente conduce a una mejor generalización más allá de los datos de prueba contradictorios. Sostenemos que ejecutar DADC durante muchas rondas maximiza sus beneficios de tiempo de entrenamiento, ya que las diferentes rondas juntas pueden cubrir muchos de los fenómenos relevantes para la tarea. Presentamos el primer estudio de DADC a largo plazo, donde recopilamos 20 rondas de ejemplos de NLI para un pequeño conjunto de párrafos de premisas, con enfoques contradictorios y no contradictorios. Los modelos entrenados en ejemplos de DADC cometen 26\% menos errores en nuestro conjunto de pruebas seleccionadas por expertos en comparación con los modelos entrenados en datos no contradictorios. Nuestro análisis muestra que el DADC produce ejemplos que son más difíciles, más diversos desde el punto de vista léxico y sintáctico, y que contienen menos artefactos de anotación en comparación con los ejemplos no contradictorios.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Selleks et luua mudelid, mis on tugevad mitmesuguste katsesisendite puhul, peaksid koolitusandmekogumid sisaldama mitmesuguseid näiteid, mis hõlmavad paljusid nähtusi. Dünaamiline konkurentsiandmete kogumine (DADC), kus annotatorid valmistavad välja näiteid, mis väljakutsevad pidevalt täiustavaid mudeleid, on nii mitmekesiste koolituskomplektide loomisel lubaduslik lähenemisviis. Varasem töö on näidanud, et DADC käivitamine 1–3 vooru jooksul võib aidata mudelitel parandada mõningaid veatüüpe, kuid see ei pruugi tingimata kaasa tuua paremat üldistamist väljaspool vastaseid katseandmeid. Väidame, et DADC-i kasutamine paljude voorude jooksul maksimeerib selle koolitusaja eeliseid, sest erinevad voorud võivad koos katta paljusid ülesandega seotud nähtusi. Esitleme esimese pikaajalise DADC uuringu, kus kogume 20 vooru NLI näiteid väikeste eelduslõigete kogumi jaoks, nii vastandlike kui ka mittevastavate lähenemisviisidega. DADC näidete põhjal koolitatud mudelid teevad meie ekspertkureeritud testikomplektis 26% vähem vigu võrreldes mittevastavate andmete põhjal koolitatud mudelitega. Meie analüüs näitab, et DADC toob näiteid, mis on keerulisemad, leksikaalselt ja süntaktiliselt mitmekesisemad ning sisaldavad vähem annotatsiooniartefakte võrreldes mittevastavate näidetega.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>برای ایجاد مدل‌هایی که در مجموعه‌ی وسیع وارد آزمایش‌ها قدرتمند هستند، مجموعه‌های داده‌های آموزش باید مثال‌های مختلف را شامل کنند که رویداده‌های زیادی را گسترش می‌دهند. جمع داده های دینامیک دشمنی (DADC) جایی که مثالهایی که مدل‌ها را به طور دائمی بهتر کردن چالش می‌دهند، برای تولید چنین مجموعه‌های آموزش مختلف قول می‌دهد. کارهای پیشینی نشان داده است که اجرای DADC بیش از ۱- ۳ راند می‌تواند مدل‌ها کمک کند تا برخی نوع خطا را تعمیر کند، ولی لازم نیست که آن به بهترین ترکیب عمومی بیش از داده‌های آزمایش دشمنی رخ دهد. ما بحث می‌کنیم که اجرای DADC در طول بسیاری از دوره‌ها سود آموزش زمان خود را maximize می‌کند، زیرا دوره‌های مختلف می‌توانند با هم بسیاری از اتفاقات مربوط به کار را حفظ کنند. ما اولین مطالعه‌ای از DADC مدت طولانی را پیشنهاد می‌کنیم، جایی که ما ۲۰ راند مثال NLI را برای یک مجموعه‌ی نقطه‌های کوچک، با همچنین نزدیک‌های دشمنی و غیر دشمنی جمع می‌کنیم. Models trained on DADC examples make 26\% fewer errors on our expert-curated test set compared to models trained on non-adversarial data. تحلیل ما نشان می دهد که DADC مثالهایی که سخت تر، زبان‌شناسی‌تر و متفاوت‌تر هستند، و در مقایسه با مثالهایی که غیر دشمنی هستند، آهنگ‌شناسی کمتر وجود دارد.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Jotta voidaan luoda malleja, jotka ovat vankkoja useilla eri testisyötteillä, koulutustietojen tulisi sisältää erilaisia esimerkkejä, jotka kattavat lukuisia ilmiöitä. Dynaaminen kontrastariaalinen tiedonkeruu (DADC), jossa kommentaattorit laativat esimerkkejä, jotka haastavat jatkuvasti kehittyviä malleja, on lupaava tapa luoda näin erilaisia koulutuskokonaisuuksia. Aikaisemmat tutkimukset ovat osoittaneet, että DADC:n ajaminen 1-3 kierroksella voi auttaa malleja korjaamaan joitakin virhetyyppejä, mutta se ei välttämättä johda parempaan yleistymiseen kuin vastakkaiset testitiedot. Väitämme, että DADC:n ajaminen monilla kierroksilla maksimoi harjoitteluajan edut, sillä eri kierroksilla voidaan yhdessä kattaa monia tehtävään liittyviä ilmiöitä. Esitämme ensimmäisen pitkän aikavälin DADC:n tutkimuksen, jossa keräämme 20 kierrosta NLI-esimerkkejä pienille lähtökohtille sekä kontradikaalisilla että ei-kontradikaalisilla lähestymistavoilla. DADC-esimerkkeihin koulutetut mallit tekevät 26\% vähemmän virheitä asiantuntijakuratoidussa testisarjassamme verrattuna malleihin, jotka on koulutettu ei-vastakkaisella datalla. Analyysimme osoittaa, että DADC tuottaa esimerkkejä, jotka ovat vaikeampia, lexikaalisesti ja syntaktisesti monimuotoisempia ja sisältävät vähemmän merkintäartefakteja kuin ei-adversariaaliset esimerkit.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Pour créer des modèles robustes pour un large éventail d'entrées de test, les ensembles de données d'entraînement doivent inclure divers exemples couvrant de nombreux phénomènes. La collecte dynamique de données contradictoires (DADC), dans laquelle les annotateurs créent des exemples qui remettent en question l'amélioration continue des modèles, est prometteuse en tant qu'approche pour générer des ensembles de formation aussi divers. Des travaux antérieurs ont montré que l'exécution du DADC sur 1 à 3 cycles peut aider les modèles à corriger certains types d'erreurs, mais cela ne conduit pas nécessairement à une meilleure généralisation au-delà des données de test contradictoires. Nous soutenons que l'exécution du DADC sur de nombreux cycles maximise ses avantages en termes de temps d'entraînement, car les différents cycles peuvent couvrir de nombreux phénomènes liés à la tâche. Nous présentons la première étude sur le DADC à plus long terme, dans laquelle nous recueillons 20 séries d'exemples NLI pour un petit ensemble de paragraphes de prémisse, avec des approches contradictoires et non contradictoires. Les modèles formés sur des exemples DADC génèrent 26 \ % d'erreurs en moins sur notre ensemble de tests sélectionnés par des experts par rapport aux modèles formés sur des données non contradictoires. Notre analyse montre que le DADC fournit des exemples plus difficiles, plus diversifiés du point de vue lexical et syntaxique, et contiennent moins d'artefacts d'annotation que les exemples non contradictoires.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Chun samhlacha a chruthú atá láidir thar raon leathan ionchuir tástála, ba cheart go n-áireodh tacair sonraí oiliúna samplaí éagsúla a chuimsíonn feiniméin iomadúla. Tá gealltanas ag bailiú sonraí sáraíochta dinimiciúla (DADC), áit a ndéanann anótálaithe samplaí a chruthú a thugann dúshlán do mhúnlaí a fheabhsú go leanúnach, mar chur chuige chun tacair oiliúna chomh héagsúil sin a ghiniúint. Léiríodh le réamhobair gur féidir le reáchtáil DADC thar 1-3 bhabhta cabhrú le samhlacha roinnt cineálacha earráide a shocrú, ach ní gá go n-eascródh ginearálú níos fearr as sonraí tástála sáraíochta. Áitímid go n-uasmhéadaíonn reáchtáil DADC thar go leor babhtaí na tairbhí a bhaineann leis maidir le ham oiliúna, toisc gur féidir leis na babhtaí éagsúla le chéile go leor de na feiniméin a bhaineann le tascanna a chlúdach. Cuirimid an chéad staidéar ar DADC níos fadtéarmaí i láthair, áit a mbailímid 20 babhta de shamplaí LNÉ do thacar beag de mhíreanna bonn, le cineálacha cur chuige sáraíochta agus neamhsháraíochta araon. Déanann samhlacha atá oilte ar shamplaí DADC 26 \% níos lú earráidí ar ár dtacar tástála coimeádta ag saineolaithe i gcomparáid le samhlacha atá oilte ar shonraí neamhsháraíochta. Léiríonn ár n-anailís go dtugann DADC samplaí atá níos deacra, níos éagsúla ó thaobh foclóireachta agus comhréire, agus a bhfuil níos lú déantúsáin nótaí iontu i gcomparáid le samplaí neamhsháraíochta.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>To, ka ƙiƙira misãlai waɗanda aka kife su cikin cikin wasu matsayi mai tsawo, za'a ƙunsa da tsarin mutane masu amfani da wasu misãlai da za'a spana abu mai yawa. Juyin data na motsi da za'a motsi (DADC), a inda misãlai na sanitacce masu motsi wanda ke tsõratar da misãlai masu yin amfani da daidai a ci-daidai, yana yi wa'adi kamar hanyor ya sami tsari masu yin amfani da waɗancan. Kayan aikin na gaba ya nuna cewa tafiyar da DADC kan rundunta 1-3, yana iya amfani da misãlai su daidaita wasu nau'i masu ɓarna, kuma amma ba ya lazimta ta ta ƙara tsarin mai kyau bisa data na motsi. Tuna faɗa da cẽwa, tafiyar da DADC a kan runduniya masu yawa yana faɗaɗa amfani da wa'adin mai aikin, kamar da rundunõnin dabam-dabam suke iya haɗuwa da wasu na'anar aiki da ke da muhimmi. Tuna halatar da farkon karatun na DADC, inda Muke sami misãlai 20 na NLI, wa'anar ƙarami na fassarar farko, da duk masu motsi da kuma bã-motsi. @ info: whatsthis AnalyyinMu yana nũna DADC ya fitar misãlai waɗanda suke mafi tsananin masu adadi, masu cikin littafa da tarayya, kuma yana da masu kashẽwa kaɗan da misãlai masu motsi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>כדי ליצור דוגמנים חזקים ברחבי מגוון רחב של תוצאות מבחן, קבוצות נתונים אימונים צריכות לכלול דוגמאות מגוונות שמרחבות תופעות רבות. אוסף נתונים נוגדים דינמיים (DADC), שבו המכתבים יוצרים דוגמאות שמתאתגרים בשיפור ממשיך של דוגמאות, מחזיק הבטחה כגישה לייצור קבוצות אימונים מגוונים כאלה. העבודה הקודמת הראה שהפעלת DADC במהלך 1-3 סיבובים יכולה לעזור לדוגמנים לתקן סוגי שגיאות מסויימים, אך זה לא בהכרח מוביל לגנרליזציה טובה יותר מעבר למידע מבחן יריבי. אנחנו מתווכחים שהפעלת DADC במהלך סיבובים רבים מקסימום את היתרונות של הזמן האימוני שלה, כיוון שהסיבובים השונים יכולים יחד לכסות הרבה מהתופעות רלוונטיות למשימה. אנו מציגים את המחקר הראשון של DADC לטווח ארוך יותר, שבו אנו אוספים 20 סיבובים של דוגמאות NLI עבור קבוצה קטנה של פראגמים משמעותיים, עם גישות נוגדיות וגם לא נוגדיות. דוגמאות מאומנות על דוגמאות DADC עושות 26% פחות שגיאות על קבוצת המבחנים המומחיות שלנו בהשוואה לדוגמאות מאומנות על נתונים לא יריביים. הניתוח שלנו מראה כי DADC מציג דוגמאות יותר קשות, יותר לקסית ומגוונים באופן סינטאקטי, ומכילים פחות חפצי ציונים בהשוואה לדוגמאות לא נוגדיות.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>मॉडल बनाने के लिए जो परीक्षण इनपुट की एक विस्तृत श्रृंखला में मजबूत हैं, प्रशिक्षण डेटासेट में विविध उदाहरण शामिल होने चाहिए जो कई घटनाओं को फैलाते हैं। गतिशील प्रतिकूल डेटा संग्रह (डीएडीसी), जहां एनोटेटर उदाहरणों को शिल्प करते हैं जो लगातार मॉडल में सुधार को चुनौती देते हैं, इस तरह के विविध प्रशिक्षण सेट उत्पन्न करने के लिए एक दृष्टिकोण के रूप में वादा करते हैं। पहले के काम से पता चला है कि 1-3 राउंड पर डीएडीसी चलाने से मॉडल को कुछ त्रुटि प्रकारों को ठीक करने में मदद मिल सकती है, लेकिन यह जरूरी नहीं कि प्रतिकूल परीक्षण डेटा से परे बेहतर सामान्यीकरण का कारण बने। हम तर्क देते हैं कि कई दौरों में डीएडीसी चलाने से इसके प्रशिक्षण-समय लाभों को अधिकतम किया जाता है, क्योंकि विभिन्न राउंड एक साथ कई कार्य-प्रासंगिक घटनाओं को कवर कर सकते हैं। हम लंबी अवधि के DADC का पहला अध्ययन प्रस्तुत करते हैं, जहां हम प्रतिकूल और गैर-प्रतिकूल दृष्टिकोण दोनों के साथ, आधार पैराग्राफ के एक छोटे से सेट के लिए एनएलआई उदाहरणों के 20 राउंड एकत्र करते हैं। डीएडीसी उदाहरणों पर प्रशिक्षित मॉडल गैर-प्रतिकूल डेटा पर प्रशिक्षित मॉडल की तुलना में हमारे विशेषज्ञ-क्यूरेटेड परीक्षण सेट पर 26\ % कम त्रुटियां करते हैं। हमारे विश्लेषण से पता चलता है कि डीएडीसी ऐसे उदाहरण देता है जो अधिक कठिन, अधिक लेक्सिकल और वाक्यात्मक रूप से विविध हैं, और गैर-प्रतिकूल उदाहरणों की तुलना में कम एनोटेशन कलाकृतियां हैं।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Da bi stvorili modele koji su snažni u širokom nizu testnih ulaganja, obuka podataka trebala bi uključiti različite primjere koje šire brojne fenomene. Dinamička kolekcija negativnih podataka (DADC), gdje annotatori navode primjere koji izazivaju stalno poboljšavanje modela, obećava se kao pristup stvaranju takvih različitih obuka. Prije posla pokazala je da vodeći DADC preko 1-3 runde može pomoći modelima da popravi neke vrste greške, ali ne mora dovesti do boljih generalizacija izvan podataka o negativnim testiranjima. Tvrdimo da trčanje DADC u mnogim rundima maksimalizira svoja korist za trening, jer različite runde zajedno mogu pokriti mnoge od fenomena relevantnih zadataka. Predstavljamo prvo ispitivanje dugoročnog DADC-a, gdje skupljamo 20 krugova primjera NLI-a za mali skup premijskih paragrafa, uz neprijateljske i neprijateljske pristupe. Modeli obučeni na primjerima DADC-a čine 26\% manje grešaka na našim testovima koji su zaključeni stručnjacima u usporedbi s modelima obučenim na neprijateljskim podacima. Naša analiza pokazuje da DADC daje primjere koje su teže, leksičkije i sintaktički različite, i sadrže manje artifakta annotacije u usporedbi s neadversarnim primjerima.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Annak érdekében, hogy a vizsgálati bemenetek széles skáláján robusztus modelleket hozzon létre, a képzési adatoknak számos jelenséget átfogó példát kell tartalmazniuk. A dinamikus ellenséges adatgyűjtés (DADC), ahol a kommentátorok olyan példákat készítenek, amelyek kihívást jelentenek a folyamatosan fejlődő modellek, ígéretes megközelítést nyújtanak az ilyen sokféle képzési készletek létrehozásához. Korábbi munkák azt mutatták, hogy a DADC 1-3 fordulóban történő futtatása segíthet a modellek kijavítani bizonyos hibatípusokat, de ez nem feltétlenül vezet jobb általánosításhoz az ellenséges tesztadatokon túl. Azzal érvelünk, hogy a DADC több fordulón keresztül történő futtatása maximalizálja edzési idő előnyeit, mivel a különböző fordulók együttesen lefedhetik a feladat-releváns jelenségek számát. Bemutatjuk a hosszabb távú DADC első tanulmányát, ahol 20 forduló NLI példát gyűjtünk egy kis előzetes bekezdéshez, ellenséges és nem ellenséges megközelítésekkel. A DADC példákra képzett modellek 26\%-kal kevesebb hibát okoznak a szakértői által kiválasztott tesztkészletünkön, mint a nem ellentétes adatokra képzett modellek. Elemzésünk azt mutatja, hogy a DADC nehezebb, lexikailag és szintaktikailag sokszínűbb példákat hoz létre, és kevesebb jegyzetelési leletet tartalmaz a nem ellentétes példákhoz képest.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Որպեսզի ստեղծենք մոդելներ, որոնք ուժեղ են թեստերի տարբեր ներմուծների ընթացքում, տեղեկատվական համակարգերը պետք է ներառեն բազմաթիվ օրինակներ, որոնք ընդգրկում են բազմաթիվ երևույթներ: Դինամական հակառակորդական տվյալների հավաքածուն (DADԿ), որտեղ annoտորները օրինակներ են ստեղծում, որոնք անընդհատ բարելավում են մոդելները, խոստանում է որպես այդպիսի բազմազան ուսուցման համակարգեր ստեղծելու մոտեցում: Prior work has shown that running DADC over 1-3 rounds can help models fix some error types, but it does not necessarily lead to better generalization beyond adversarial test data. Մենք փաստարկում ենք, որ DADԿ-ի աշխատանքը շատ շրջանների ընթացքում մեծացնում է իր ուսուցման-ժամանակի առավելությունները, քանի որ տարբեր շրջանները միասին կարող են ծածկել խնդիրների հետ կապված երևույթները: Մենք ներկայացնում ենք երկարաժամկետ DADԿ-ի առաջին ուսումնասիրությունը, որտեղ մենք հավաքում ենք քսան շրջանակներ ՆԼԻ օրինակների մի փոքրիկ պարբերակների համար, ինչպես հակառակորդ և ոչ հակառակորդ մոտեցումների միջոցով: DADC օրինակների վրա սովորեցված մոդելները մեր փորձարկումների համակարգում ավելի քիչ սխալներ են անում, քան ոչ հակառակորդական տվյալների վրա սովորեցված մոդելները: Մեր վերլուծությունը ցույց է տալիս, որ DADԿ-ն առաջացնում է օրինակներ, որոնք ավելի դժվար են, լեքսիկական և սինտակտիկապես բազմազան, և պարունակում են ավելի քիչ annoտացիոն արտերֆեկտներ, համեմատած ոչ հակառակորդ օրինակների հետ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Untuk menciptakan model yang kuat melalui jangkauan luas masukan tes, set data pelatihan harus mengandung contoh-contoh berbeda yang meliputi banyak fenomena. Dinamik koleksi data musuh (DADC), di mana annotator membuat contoh yang menantang terus-menerus meningkatkan model, memegang janji sebagai pendekatan untuk menghasilkan set latihan yang berbeda seperti ini. Pekerjaan sebelumnya menunjukkan bahwa menjalankan DADC selama 1-3 putaran dapat membantu model memperbaiki beberapa tipe kesalahan, tetapi tidak perlu memimpin ke generalisasi yang lebih baik diluar data ujian musuh. Kami berdebat bahwa menjalankan DADC selama banyak pusingan maksimalkan keuntungan latihan-waktu, karena pusingan yang berbeda bisa bersama-sama menutupi banyak fenomena yang relevan tugas. Kami mempersembahkan penelitian pertama dari DADC jangka panjang, di mana kami mengumpulkan 20 ronde contoh NLI untuk set kecil paragraf premise, dengan kedua pendekatan musuh dan bukan musuh. Model yang dilatih pada contoh DADC membuat 26\% kurang kesalahan pada set tes kami yang dikurasikan oleh ahli dibandingkan dengan model yang dilatih pada data bukan musuh. Analisis kami menunjukkan bahwa DADC memberikan contoh yang lebih sulit, lebih leksikal dan sintaksi berbeda, dan mengandung lebih sedikit artefak anotasi dibandingkan contoh-contoh yang tidak bertentangan.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Per creare modelli robusti in un'ampia gamma di input di test, i set di dati di formazione dovrebbero includere esempi diversi che coprono numerosi fenomeni. La raccolta dinamica dei dati avversi (DADC), in cui gli annotatori creano esempi che sfidano modelli in continuo miglioramento, è un approccio promettente per generare set di formazione così diversi. Il lavoro precedente ha dimostrato che l'esecuzione di DADC su 1-3 turni può aiutare i modelli a correggere alcuni tipi di errore, ma non porta necessariamente a una migliore generalizzazione oltre i dati di test avversi. Sosteniamo che l'esecuzione di DADC su molti turni massimizza i suoi benefici di allenamento-tempo, in quanto i diversi turni possono coprire insieme molti dei fenomeni rilevanti per il compito. Presentiamo il primo studio del DADC a lungo termine, dove raccogliamo 20 round di esempi NLI per un piccolo set di paragrafi preminenti, con approcci sia avversari che non avversari. I modelli formati su esempi DADC producono il 26% di errori in meno sul nostro set di test curato da esperti rispetto ai modelli formati su dati non avversi. La nostra analisi mostra che DADC produce esempi che sono più difficili, più lessicamente e sintatticamente diversi e contengono meno artefatti di annotazione rispetto ad esempi non avversari.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>幅広いテスト入力にわたって堅牢なモデルを作成するには、トレーニングデータセットに、多数の現象にわたる多様な例を含める必要があります。 注釈者が継続的にモデルを改善することに挑戦する例を作成する動的対抗データ収集（ DADC ）は、そのような多様なトレーニングセットを生成するためのアプローチとして約束を持っています。 以前の研究では、DADCを1〜3ラウンドにわたって実行することで、モデルがいくつかのエラータイプを修正するのに役立つことが示されていますが、対抗テストデータを超えてより良い一般化につながるとは限りません。 DADCを多くのラウンドにわたって実行することは、異なるラウンドが一緒にタスクに関連する現象の多くをカバーすることができるため、トレーニング時間の利点を最大化すると主張している。 私たちは、長期的なDADCの最初の研究を提示します。ここでは、対立的アプローチと非対立的アプローチの両方を使用して、少数の前提パラグラフのための20ラウンドのNLIの例を収集します。 DADCの例でトレーニングされたモデルは、非対抗データでトレーニングされたモデルと比較して、専門家がキュレーションしたテストセットのエラーが26 \%少なくなります。 我々の分析は、DADCが、非対立的な例と比較して、より困難であり、より語彙的および構文的に多様であり、より少ない注釈アーチファクトを含む例をもたらすことを示している。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Jejaring Name politenessoffpolite"), and when there is a change ("assertivepoliteness Awak dhéwé sawian karo sistem sing dibutuhke Awak dhéwé éntuk perusahaan urip nggambar luwih-luwih DaD Name Panjenenganipun dhéwé menehi bakal sing nyimpen dadi, dadi sing luwih apik lan kelakipun sing sampeyan karo hal-hal sing gak dhéwé, akeh lanjut sing gak adhil karo hal-hal sing paling dhéwé.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>მოდელების შექმნა, რომლებიც ძალიან ძალიან განსხვავებული ტესტის მონაცემების გარეშე, განსწავლების მონაცემები უნდა შექმნა განსხვავებული მაგალითები, რომლებიც მრავალ დინამიკური ანტორიალური მონაცემების კოლექცია (DADC), სადაც ანტოტორიების მაგალითები, რომელიც მუშაობაც მოდელების გაუკეთებას წარმოადგენს, გვეყვებს, როგორც ასეთი განსხვავებული პირველი სამუშაო მუშაობა ჩვენება, რომ DADC 1- 3 პუნდზე გადაწყება შესაძლებელია მოდელების დახმარება, მაგრამ ეს არ უნდა უფრო უკეთესი გენერალიზაცია განსაზღვრებული ტესტი ჩვენ ვაკეთებთ, რომ DADC-ის გადაწყვეტილება მრავალ პრონეტებში მაქსიმიკურებს მისი სამყარო სამყარო სამყარო გამოსახულება, რადგან განსხვავებული პრონეტები შეუძლი ჩვენ დავიწყებთ პირველი კვლევა DADC-ის უკვე სიმართლეში, სადაც ჩვენ შევძლებთ NLI მაგალითების 20 კონდის მაგალითების მაგალითების მაგალითი პრემიზის ნაწილი, რომლებიც ორივე განსაცემებული და არ DADC მაგალითად განსწავლებული მოდელები 26\% უფრო ცოტა ჩვენი ექსპერტის კურვილი ტესტის შეცდომის შედგომა, რომლებიც არ განსწავლებელი მოდელთან განსწავლებული მოდელთან. ჩვენი ანალიზია, რომ DADC იქნება მაგალითები, რომლებიც უფრო რთული, ლექსიკურად და სინტაქტიკურად განსხვავებულია, და უფრო ცოტა ანალიზაციის არტაკტებები, რომლებიც არ განს</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Көптеген сынақтар келтірілген үлгілерді құру үшін, бақылау деректер жиындары көптеген мәселелерді көптеген түрлі мысалдар болуы тиіс. Динамикалық негатриялық деректер жинақтауы (DADC), бұл жерде моделдерді жақсарту үшін белгілер үлгілерді жасайтын мәселелер жасайды, бұл әртүрлі оқыту бағдарламаларын құру үшін әлемді Алдыңғы жұмыс істеген DADC 1- 3 тұлбадан орындалуда кейбір қатенің түрлерін түзетуге көмектеседі, бірақ бұл қатенің түрлерін түзетуге көмектеседі, бірақ қарсы сынақтар деректерінен ар Біз DADC жұмыс істеу көпшілігін көптеген жұмыс істеу үшін оның бақылау уақыттың мүмкіндіктерін көптеген, себебі әртүрлі жұмыс істеу үшін тапсырмалардың көптег Біз DADC ұзындық уақытты бірінші зерттеуді таңдаймыз. Бұл жерде NLI пішімдерінің 20 мәселелерін кішкентай премия параграфиялар үшін, негатриялық және негатриялық емес жағдайларды біріктіреміз. DADC мысалдарында оқылған үлгілер эксперттердің өзгертілген сынақтарымыздың 26\% деген қателерін негізгі деректер үлгілерімен салыстыру үлгілеріне сәйкес келеді. Біздің анализиямыз, DADC деген мәселелерді қатты, лексикалық және синтактикалық түрлі түрлі мәселелерді көрсетеді. Олардың негізгі мәселелерімен салыстырылған жазбалардың артефакттары аз.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>각종 테스트 입력에서 노봉성을 가진 모델을 만들기 위해 훈련 데이터 집합은 다양한 현상을 뛰어넘는 각종 예시를 포함해야 한다.동적 대항적 데이터 수집(DADC)은 이처럼 다양한 훈련 집합을 만드는 방법으로 주석자가 DADC에서 도전의 끊임없는 개선 모델을 만들 수 있는 예이다.이전의 작업에서 1-3라운드에서 DADC를 운행하면 모델이 일부 오류 유형을 복구하는 데 도움을 줄 수 있다고 밝혔지만 이것은 반드시 대항적인 테스트 데이터를 초월하는 더 좋은 범위화를 초래하는 것은 아니다.우리는 여러 바퀴가 DADC를 운행하면 훈련 시간 효율을 최대한 높일 수 있다고 생각한다. 왜냐하면 서로 다른 바퀴는 임무와 관련된 많은 현상을 함께 커버할 수 있기 때문이다.우리는 첫 번째 장기 DADC 연구를 소개했는데 그 중에서 우리는 20차례의 NLI 예시를 수집하여 대항성과 비대항성 방법을 포함한 일부 전제 단락에 사용했다.DADC 예제 훈련 기반 모델은 비대항적 데이터 트레이닝 기반 모델에 비해 전문가가 기획한 테스트 세트에서 오류가 26% 감소했다.우리의 분석에 따르면 DADC가 생성하는 예는 비대항적인 예에 비해 더욱 어렵고 어휘와 문법적으로 다양하며 주석 부품이 더 적게 포함된 것으로 나타났다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>To create models that are robust across a wide range of test inputs, training datasets should include diverse examples that span numerous phenomena. Dinaminis priešingų duomenų rinkimas (DADC), kuriame anotatoriai rengia pavyzdžius, kurie nuolat kelia prieštaravimų modeliams tobulinti, yra pažadus, kad toks įvairių mokymo rinkinių kūrimo metodas. Ankstesnis darbas parodė, kad DADC veikimas per 1–3 raundus gali padėti modeliams ištaisyti kai kuriuos klaidų tipus, tačiau nebūtinai lemia geresnę generalizaciją nei priešingų bandymų duomenys. Mes teigiame, kad daugeliu apskritimų vykdant DADC maksimaliai padidina mokymo trukmę, nes skirtingi apskritimai kartu gali apimti daugelį su užduotimis susijusių reiškinių. We present the first study of longer-term DADC, where we collect 20 rounds of NLI examples for a small set of premise paragraphs, with both adversarial and non-adversarial approaches. Models trained on DADC examples make 26\% fewer errors on our expert-curated test set compared to models trained on non-adversarial data. Our analysis shows that DADC yields examples that are more difficult, more lexically and syntactically diverse, and contain fewer annotation artifacts compared to non-adversarial examples.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>За да се создадат модели кои се силни низ широк опсег на тестирани внесувања, обуките на податоци треба да вклучат различни примери кои ги опфаќаат бројните феномени. Dynamic adversarial data collection (DADC), where annotators craft examples that challenge continually improving models, holds promise as an approach for generating such diverse training sets. Prior work has shown that running DADC over 1-3 rounds can help models fix some error types, but it does not necessarily lead to better generalization beyond adversarial test data. We argue that running DADC over many rounds maximizes its training-time benefits, as the different rounds can together cover many of the task-relevant phenomena. We present the first study of longer-term DADC, where we collect 20 rounds of NLI examples for a small set of premise paragraphs, with both adversarial and non-adversarial approaches. Models trained on DADC examples make 26\% fewer errors on our expert-curated test set compared to models trained on non-adversarial data. Our analysis shows that DADC yields examples that are more difficult, more lexically and syntactically diverse, and contain fewer annotation artifacts compared to non-adversarial examples.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>വിശാലമായ പരീക്ഷണ ഇന്‍പുട്ടുകളിലൂടെ കൊണ്ടുപോകുന്ന മോഡലുകള്‍ ഉണ്ടാക്കുവാന്‍ വേണ്ടി, പരിശീലനത്തിന്റെ ഡാറ്റാസറ്റു ഡൈനാമിക്ക് വിരോധമായ വിവരങ്ങള്‍ സംഘടിപ്പിക്കുന്നത് (DADC), അവിടെ വിവിധ വിവരങ്ങളുടെ പ്രവര്‍ത്തനങ്ങള്‍ എപ്പോഴും മോഡലുകള്‍ മുന്‍കൂട്ടു 1-3 റൌണ്ടില്‍ നിന്നും കൂടുതല്‍ ഡിഡിസിയെ പ്രവര്‍ത്തിപ്പിക്കുന്നത് കാണിച്ചിരിക്കുന്നുവെങ്കില്‍ ചില തെറ്റുകളുടെ തരത്തില്‍ മോഡല നമ്മള്‍ വാദിക്കുന്നത് ഡിഡിസിയെ പല റൌണ്ടുകള്‍ക്കും മേല്‍ ഓടിക്കൊണ്ടിരിക്കുന്നത് അതിന്‍റെ ട്രെയിനിങ്ങ് സമയം ഉപകാരം ഏറ്റവും നീണ്ട കാലം ഡിഡിസിയുടെ ആദ്യത്തെ പഠനം ഞങ്ങള്‍ കൂട്ടിക്കൊണ്ടിരിക്കുന്നു. അവിടെ നമ്മള്‍ 20 റൗണ്ട് NLI ഉദാഹരണങ്ങള്‍ സംഘടിക്കുന്നു. ഒരു ചെ DADC ഉദാഹരണങ്ങളില്‍ പരിശീലിക്കപ്പെട്ട മോഡലുകള്‍ 26\% കുറച്ച് പിശകുകളാക്കുന്നു. നമ്മുടെ പരീക്ഷണത്തില്‍ പരീക്ഷണത്തിന്റെ പരിശോ നമ്മുടെ അന്വേഷണം കാണിക്കുന്നത് ഡിഡിസി കൂടുതല്‍ കഠിനമായ ഉദാഹരണങ്ങള്‍ ഉണ്ടാക്കുന്നു, കൂടുതല്‍ ലെക്സിക്സിക്കല്‍ വ്യത്യസ്ത വ്യത്യസ്തമാ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Мөн олон шалгалтын өгөгдлийн хэмжээнд хүчтэй моделуудыг бий болгохын тулд сургалтын өгөгдлийн сангууд олон үзэгдлийг тооцоолж байгаа олон жишээг нэмэгдүүлэх хэрэгтэй. Динамикийн эсрэг өгөгдлийн цуглуулалт (DADC) гэдэг нь загваруудыг сайжруулахын тулд зорилгодог загваруудын жишээ бий болгож, ийм олон төрлийн сургалтын сургалтыг бүтээх арга хэмжээтэй байдаг. Өмнөх ажил нь ДАДК-г 1-3 дахин гүйцэтгэх нь загваруудын зарим алдаа төрлүүдийг засах боломжтой гэдгийг харуулсан байна. Гэхдээ энэ нь эсрэг шалгалтын мэдээллээс илүү сайн ерөнхийлөгчилгээ хүргэхгүй. Бид ДАДК-г олон хэсэгт дасгал хөдөлгөөн нь дасгал хөдөлгөөн цаг хугацааны хэрэгцээг нэмэгдүүлдэг гэдгийг хэлж байна. Яагаад гэвэл өөр хэсэг нь ажлын холбоотой олон үйл явдалыг хамтдаа Бид урт хугацааны ДАДК-ын анхны судалгааг үзүүлнэ. Бид НЛИ-ийн жижиг хэсэг хэсэг хэсэг дээр 20 давхар жишээг цуглуулдаг. DADC жишээ дээр сургалтын загварууд бидний мэргэжилтнүүд дээр сургалтын шалгалтын хэмжээнд 26\% бага алдаа гаргадаг. Бидний шинжилгээнд ДАДК илүү хэцүү, илүү лексикийн, синтактикийн төрлийн жишээг гаргаж, эсрэг биш жишээтэй харьцуулахад бага анзааралтын урлагийн жишээг бий болгож байна.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Untuk mencipta model yang kuat melalui julat luas input ujian, set data latihan sepatutnya mengandungi contoh-contoh berbeza yang meliputi banyak fenomena. Dynamic adversarial data collection (DADC), where annotators craft examples that challenge continually improving models, holds promise as an approach for generating such diverse training sets. Prior work has shown that running DADC over 1-3 rounds can help models fix some error types, but it does not necessarily lead to better generalization beyond adversarial test data. We argue that running DADC over many rounds maximizes its training-time benefits, as the different rounds can together cover many of the task-relevant phenomena. We present the first study of longer-term DADC, where we collect 20 rounds of NLI examples for a small set of premise paragraphs, with both adversarial and non-adversarial approaches. Model yang dilatih pada contoh DADC membuat 26\% kurang ralat pada set ujian yang dikurasikan oleh ahli kita dibandingkan dengan model yang dilatih pada data bukan musuh. Our analysis shows that DADC yields examples that are more difficult, more lexically and syntactically diverse, and contain fewer annotation artifacts compared to non-adversarial examples.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Biex jinħolqu mudelli b’saħħithom f’firxa wiesgħa ta’ inputs tat-testijiet, settijiet ta’ dejta tat-taħriġ għandhom jinkludu eżempji varji li jkopru bosta fenomeni. Il-ġbir dinamiku tad-dejta avversarja (DADC), fejn l-annotaturi jfasslu eżempji li jikkontestaw it-titjib kontinwu tal-mudelli, għandu wegħda bħala approċċ għall-ġenerazzjoni ta’ settijiet ta’ taħriġ differenti bħal dawn. Prior work has shown that running DADC over 1-3 rounds can help models fix some error types, but it does not necessarily lead to better generalization beyond adversarial test data. We argue that running DADC over many rounds maximizes its training-time benefits, as the different rounds can together cover many of the task-relevant phenomena. Aħna nippreżentaw l-ewwel studju tad-DADC fit-tul, fejn niġbru 20 ċiklu ta’ eżempji tal-NLI għal sett żgħir ta’ paragrafi premessa, b’approċċi kemm avversarji kif ukoll mhux avversarji. Il-mudelli mħarrġa fuq eżempji tad-DADC jagħmlu 26\% inqas żbalji fis-sett tat-test ikkurat mill-esperti tagħna meta mqabbel ma’ mudelli mħarrġa fuq dejta mhux avversarja. L-analiżi tagħna turi li d-DADC jagħti eżempji li huma aktar diffiċli, aktar lexikament u sintetikament differenti, u li fihom inqas artifatti ta’ annotazzjoni meta mqabbla ma’ eżempji mhux avversarji.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Om modellen te maken die robuust zijn voor een breed scala aan testinputs, moeten trainingsdatasets diverse voorbeelden bevatten die talrijke fenomenen bestrijken. Dynamic adversarian data collection (DADC), waar annotators voorbeelden maken die voortdurend verbeteren van modellen uitdagen, is veelbelovend als een benadering voor het genereren van dergelijke uiteenlopende trainingssets. Eerder onderzoek heeft aangetoond dat het uitvoeren van DADC over 1-3 rondes modellen kan helpen bepaalde fouttypen op te lossen, maar het hoeft niet noodzakelijkerwijs te leiden tot een betere generalisatie dan tegenstrijdige testgegevens. We argumenteren dat het uitvoeren van DADC over vele rondes de voordelen van de trainingstijd maximaliseert, omdat de verschillende rondes samen veel van de taak-relevante fenomenen kunnen behandelen. We presenteren de eerste studie van DADC op langere termijn, waarin we 20-ronden NLI voorbeelden verzamelen voor een kleine set premise paragrafen, met zowel tegenstrijdige als niet-tegenstrijdige benaderingen. Modellen die zijn getraind op DADC voorbeelden maken 26\% minder fouten in onze door experts geselecteerde testset in vergelijking met modellen die zijn getraind op niet-tegenstrijdige gegevens. Uit onze analyse blijkt dat DADC voorbeelden levert die moeilijker, lexicaal en syntactisch diverser zijn en minder annotatieartefacten bevatten in vergelijking met niet-tegenstrijdige voorbeelden.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>For å laga modeller som er sterkt i eit brett rekkje av testinndata, må opplæringsdatasett inkludere ulike eksemplar som gjer mange fenomenar. Dynamisk datasamling (DADC), der annotatorar arbeider eksemplar som utfordrer kontinuerleg forbedring av modeller, har lov som ein tilnærming for å laga slike ulike opplæringssett. Førre arbeid har vist at køyring av DADC over 1- 3 rundar kan hjelpa til modeller å retta nokre feiltypar, men det fører ikkje nødvendig til bedre generalisering enn negativ test data. Vi argumenterer at køyring av DADC over mange rundar maksimerer uttrykkingstidsfordelene sine, sidan dei ulike rundane kan dekke saman mange av oppgåvelege fenomena. Vi presenterer den første studien av langsiktige DADC, der vi samler 20 runda av NLI-eksemplar for ein liten set av premise avsnitt, med både negativ og ikkje-negativ tilnærmingar. Modellar trengte på DADC-eksemplar gjer at 26\% feil på vårt ekspertkurert test sett i sammenligning med modeller trengte på ikkje-adversariske data. Analysen vårt viser at DADC gjev eksemplar som er vanskeleg, mer leksisk og syntaksisk forskjellige, og inneheld mindre artifaktar for annotasjonar sammenlignet med ikkje-adversariske eksemplar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Aby stworzyć modele solidne w szerokim zakresie wejść do testów, zestawy danych szkoleniowych powinny zawierać różne przykłady obejmujące liczne zjawiska. Dynamiczne gromadzenie danych przeciwnych (DADC), gdzie adnotatorzy tworzą przykłady, które stawiają czoła ciągłemu ulepszaniu modeli, ma obiecujące podejście do generowania tak zróżnicowanych zestawów szkoleniowych. Wcześniejsze prace wykazały, że uruchomienie DADC w rundach 1-3 może pomóc modelom naprawić niektóre typy błędów, ale niekoniecznie prowadzi do lepszego uogólnienia poza przeciwnymi danymi testowymi. Twierdzimy, że prowadzenie DADC przez wiele rund maksymalizuje korzyści z czasu treningu, ponieważ różne rundy mogą razem obejmować wiele zjawisk związanych z zadaniem. Przedstawiamy pierwsze badanie długoterminowego DADC, w którym zbieramy 20-rundy przykładów NLI dla małego zestawu akapitów założeniowych, z podejściem zarówno przeciwnym, jak i nieprzeciwnym. Modele przeszkolone na przykładach DADC powodują 26\% mniejszą liczbę błędów w naszym zestawie testów kuracjonowanych przez ekspertów w porównaniu z modelami przeszkolonymi na danych nieprzeciwnych. Nasza analiza pokazuje, że DADC daje przykłady, które są trudniejsze, bardziej zróżnicowane leksycznie i składniowo oraz zawierają mniej artefaktów adnotacyjnych w porównaniu z przykładami nieprzeciwnymi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Para criar modelos robustos em uma ampla variedade de entradas de teste, os conjuntos de dados de treinamento devem incluir diversos exemplos que abrangem vários fenômenos. A coleta dinâmica de dados adversários (DADC), em que os anotadores criam exemplos que desafiam modelos de melhoria contínua, é promissora como uma abordagem para gerar conjuntos de treinamento tão diversos. Trabalhos anteriores mostraram que a execução do DADC em 1-3 rodadas pode ajudar os modelos a corrigir alguns tipos de erro, mas não necessariamente leva a uma melhor generalização além dos dados de teste adversários. Argumentamos que executar o DADC em muitas rodadas maximiza seus benefícios de tempo de treinamento, pois as diferentes rodadas podem, juntas, cobrir muitos dos fenômenos relevantes para a tarefa. Apresentamos o primeiro estudo de DADC de longo prazo, onde coletamos 20 rodadas de exemplos de NLI para um pequeno conjunto de parágrafos de premissa, com abordagens adversas e não adversas. Modelos treinados em exemplos de DADC cometem 26\% menos erros em nosso conjunto de testes com curadoria de especialistas em comparação com modelos treinados em dados não adversários. Nossa análise mostra que o DADC produz exemplos que são mais difíceis, mais lexicalmente e sintaticamente diversos e contêm menos artefatos de anotação em comparação com exemplos não adversários.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Pentru a crea modele robuste într-o gamă largă de intrări de testare, seturile de date de formare ar trebui să includă exemple diverse care cuprind numeroase fenomene. Colectarea dinamică a datelor adversariale (DADC), în care adnotatorii creează exemple care provoacă îmbunătățirea continuă a modelelor, ține promisiunea ca o abordare pentru generarea unor seturi de formare atât de diverse. Lucrările anterioare au arătat că rularea DADC peste 1-3 runde poate ajuta modelele să remedieze anumite tipuri de erori, dar nu duce neapărat la o mai bună generalizare dincolo de datele adversare ale testelor. Susținem că rularea DADC pe mai multe runde maximizează beneficiile sale de antrenament-timp, deoarece diferitele runde pot acoperi împreună multe dintre fenomenele relevante pentru sarcini. Prezentăm primul studiu al DADC pe termen lung, unde colectăm 20 de runde de exemple NLI pentru un set mic de paragrafe premise, atât cu abordări adversare, cât și non-adversare. Modelele instruite pe exemple DADC fac cu 26\% mai puține erori în setul nostru de testare curatat de experți comparativ cu modelele instruite pe date non-adversare. Analiza noastră arată că DADC oferă exemple care sunt mai dificile, mai diverse din punct de vedere lexical și sintactic și conțin mai puține artefacte de adnotare comparativ cu exemplele non-adversare.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Для создания надежных моделей с широким диапазоном входных тестовых данных обучающие наборы данных должны включать разнообразные примеры, охватывающие множество явлений. Динамический сбор состязательных данных (DADC), где аннотаторы создают примеры, которые бросают вызов постоянно улучшающимся моделям, является многообещающим подходом для создания таких разнообразных обучающих наборов. Предыдущая работа показала, что запуск DADC в течение 1-3 раундов может помочь моделям исправить некоторые типы ошибок, но это не обязательно приводит к лучшему обобщению помимо сопернических тестовых данных. Мы утверждаем, что выполнение DADC на протяжении многих раундов максимизирует его преимущества во времени обучения, поскольку различные раунды могут вместе охватывать многие из связанных с задачами явлений. Мы представляем первое исследование долгосрочного DADC, где мы собираем 20 раундов примеров NLI для небольшого набора абзацев предпосылок, как с состязательным, так и с несостязательным подходом. Модели, обученные на примерах DADC, на 26\% меньше ошибок в нашем экспертном наборе тестов по сравнению с моделями, обученными на несопернических данных. Наш анализ показывает, что DADC дает примеры, которые являются более сложными, более лексически и синтаксически разнообразными и содержат меньше артефактов аннотации по сравнению с несостязательными примерами.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>පරීක්ෂණ ප්‍රවේශයක් විශාල විශාල ප්‍රවේශයක් නිර්මාණය කරන්න, පරීක්ෂණ දත්ත සේට් වලින් විවිධ උදාහරණ උදාහ සාමාන්‍ය විරුද්ධ විරුද්ධ දත්ත සංග්රහනය (DADC), කොහේද අනතුරු ක්‍රියාත්මක විදිහට ප්‍රශ්නයක් තියෙන්නේ මොඩේල්ස් වලට ස මුලින් වැඩේ පෙන්වන්නේ DADC 1- 3 කුණු වලින් වැඩ කරන්න පුළුවන් විදිහට වැරදි වර්ගයක් නිර්මාණය කරන්න, ඒත් ඒක විරෝධ පරීක්ෂණ අපි ප්‍රශ්නයක් කරනවා DADC කිරීම ගොඩක් ප්‍රශ්නයක් වෙනුවෙන් එයාගේ ප්‍රශ්නයක් වෙලාවට ප්‍රයෝජනයක් වැඩි වෙනුවෙන් ප්‍ර අපි ලොකු වාර්තාවේ DADC ගේ පළමු අධ්‍යානය පෙන්වන්නම්, එතන අපි NLI උදාහරණ 20 ක් සම්බන්ධ කරනවා ප්‍රධාන ප්‍රධාන ප්‍රධාන ප්‍රධානයක් සම DADC උදාහරණ වලින් ප්‍රධානය කරලා තියෙන මොඩල් 26\% අඩු වැරැද්දක් අපේ විශ්වාසිත විශ්වාසිය පරීක්ෂණය සඳහා ප්‍රධානය අපේ විශ්ලේෂණය පෙන්වන්නේ DADC විශ්ලේෂණය තමයි වඩා අමාරුයි, වඩා ලෙක්සිකාරික සහ සංවිධානයෙන් වෙනස් විදියට වඩා විදියට ප</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Za ustvarjanje modelov, ki so robustni v širokem naboru preskusnih vhodov, bi morali nabori podatkov o usposabljanju vključevati različne primere, ki zajemajo številne pojave. Dinamično kontradikcijsko zbiranje podatkov (DADC), kjer opozorilci oblikujejo primere, ki izzivajo stalno izboljšujoče modele, je obetaven pristop k ustvarjanju tako raznolikih naborov usposabljanja. Predhodno delo je pokazalo, da lahko izvajanje DADC v 1-3 krogih modelom pomaga odpraviti nekatere vrste napak, vendar to ne vodi nujno do boljše posploševanje preko kontrastnih preskusnih podatkov. Trdimo, da vodenje DADC v številnih krogih maksimira njegove koristi v času treninga, saj lahko različni krogi skupaj pokrivajo številne pojave, pomembne za nalogo. Predstavljamo prvo študijo dolgoročnejšega DADC, kjer zbiramo 20 krogov primerov NLI za majhen sklop premičnih odstavkov, tako kontradiktorskih kot tudi ne kontradiktorskih pristopov. Modeli, usposobljeni na podlagi primerov DADC, naredijo 26% manj napak v našem strokovnem naboru preskusov v primerjavi z modeli, usposobljenimi na podlagi podatkov, ki niso konkurenčni. Naša analiza kaže, da DADC prinaša primere, ki so težji, bolj leksikološko in sintaktično raznoliki in vsebujejo manj artefaktov za označevanje v primerjavi z nekontraralnimi primeri.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Si aad u sameyso tusaalooyin lagu isticmaalo samooyin imtixaan badan oo kala duduwan, waxaa laga yaabaa in lagu sameeyo tusaalooyin kala duduwan oo ku dhaqdhaqaaqaya waxyaabo badan. Duumarinta macluumaadka cadaawayaasha ah (DADC), meesha ay tusaalayaasha qalabka dhibaatooyinka ay ku qasbi karaan horumarinta modellada oo joogtada ah, waxay ballanqaadaan qaab u sameynta koorasyada waxbarashada kala duduwan. Shaqo hore wuxuu tusay in dhaqdhaqaaqa DADC oo ka badan 1-3 wadooyin waxay caawin karaan tusaalayaasha inay hagaajiyaan noocyo khalad ah, laakiin laguma baahna in lagu sameeyo wax ka wanaagsan sameynta danbiyada cadaawayaasha ah. Waxaynu ka sheekaynaynaa in dhaqdhaqaaqa DADC uu ugu badiyaa manfacyada waqtiga waxbarashada, sababtoo ah wadooyin kala duduwan waxay wada dabooli karaan waxyaabo badan oo la xiriira shaqada. Waxbarashada ugu horeeyay ee DADC ee waqtiga dheer, halkaas oo aynu soo ururinaa 20 wareegg oo NLI ah, tusaalayaal ka mid ah qeybo yar oo ka mid ah kooxaha hore iyo labada qaabab ka gees ah iyo ka gees ah. Tusaalada DADC lagu baranayo waxay ka dhigaan 26\% khalad yar oo ku saabsan imtixaanka aqoonteenna la koobay, barbarta modelalka lagu tababaray macluumaadka aan cadaawayaasha ka dhigin. Analyskayagu wuxuu muujiyaa in DADC soo saaraa tusaalooyin ay ka adag yihiin, oo ay ka badan yihiin dhibaatooyin, si qalloocan ah oo ay u kala duwan yihiin, waxayna ku jiraan arrimaha wax yar oo la xiriira tusaalayaal aan ka gees ahayn.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Për të krijuar modele që janë të forta nëpër një gamë të gjerë të hyrjeve testuese, grupet e të dhënave të trajnimit duhet të përfshijnë shembuj të ndryshëm që përhapin fenomene të shumta. Përmbledhja dinamike e të dhënave kundërshtare (DADC), ku anotatorët krijojnë shembuj që sfidojnë përmirësimin vazhdimisht të modeleve, mban premtimin si një qasje për krijimin e grupeve të tilla të ndryshme të trainimit. Puna e mëparshme ka treguar se vrapimi i DADC mbi 1-3 raunde mund të ndihmojë modelet të rregullojnë disa tipe gabimesh, por nuk shpie domosdoshmërisht në gjeneralizim më të mirë përtej të dhënave të test it kundërshtarë. Ne argumentojmë se drejtimi i DADC në shumë raunde maksimizon përfitimet e tij të trajnimit-kohës, pasi raundet e ndryshme mund të mbulojnë së bashku shumë nga fenomenet e lidhura me detyrat. Ne paraqesim studimin e parë të DADC afat-gjatë, ku mbledhim 20 raunde shembuj NLI për një grup të vogël paragjykimesh, si kundërshtare ashtu edhe jo kundërshtare. Models trained on DADC examples make 26\% fewer errors on our expert-curated test set compared to models trained on non-adversarial data. Analiza jonë tregon se DADC sjell shembuj që janë më të vështirë, më lexikalisht dhe sintaktikisht të ndryshëm dhe përmbajnë më pak artefakte anotacioni krahasuar me shembuj jo-kundërshtarë.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Da bi stvorili modele koji su snažni u širokom nizu testnih ulaganja, obuka podataka treba uključiti različite primjere koji šire brojne fenomene. Dinamička kolekcija negativnih podataka (DADC), gdje annotatori navode primjere koji izazivaju stalno poboljšavanje modela, obećava kao pristup stvaranju takvih različitih seta obuke. Prije posla pokazala je da vodeći DADC preko 1-3 runde može pomoći modelima da popravi neke vrste greške, ali ne mora da dovede do boljih generalizacija izvan podataka protivnih testova. Svađamo se da vodeći DADC tokom mnogih runda maksimalizira svoju korist za trening, jer različite runde mogu zajedno pokriti mnoge od fenomena vezanih za zadatak. Predstavljamo prvo proučavanje dugoročnog DADC-a, gdje skupljamo 20 rundi primjera NLI-a za mali set premijskih paragrafa, sa objektivnim i neprijateljskim pristupima. Modeli obučeni na primjerima DADC čine 26\% manje grešaka na našem testu u usporedbi s modelima obučenim na neprijateljskim podacima. Naša analiza pokazuje da DADC daje primjere koje su teže, leksičkije i sintaktički različite, i sadrže manje artifakta annotacije u usporedbi s neadversarnim primjerima.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>F철r att skapa modeller som 채r robusta 철ver ett brett spektrum av testing책ngar b철r utbildningsdataupps채ttningar inneh책lla olika exempel som sp채nner 철ver m책nga fenomen. Dynamisk kontradiktorisk datainsamling (DADC), d채r kommentatorer skapar exempel som utmanar st채ndigt f철rb채ttrade modeller, h책ller l철fte som ett tillv채gag책ngss채tt f철r att generera s책 olika tr채ningsupps채ttningar. Tidigare arbete har visat att k철rning av DADC 철ver 1-3 omg책ngar kan hj채lpa modeller att 책tg채rda vissa feltyper, men det leder inte n철dv채ndigtvis till b채ttre generalisering bortom motstridiga testdata. Vi menar att att k철ra DADC 철ver m책nga omg책ngar maximerar dess tr채ningstidsf철rdelar, eftersom de olika omg책ngarna tillsammans kan t채cka m책nga av de uppgiftsrelevanta fenomenen. Vi presenterar den f철rsta studien av l책ngsiktig DADC, d채r vi samlar in 20 omg책ngar av NLI exempel f철r en liten upps채ttning premisstycken, med b책de motstridiga och icke-motstridiga tillv채gag책ngss채tt. Modeller utbildade p책 DADC-exempel g철r 26\% f채rre fel p책 v책r expertkuraterade testupps채ttning j채mf철rt med modeller utbildade p책 icke-kontradiktoriska data. V책r analys visar att DADC ger exempel som 채r sv책rare, mer lexiskt och syntaktiskt olika, och inneh책ller f채rre anteckningar artefakter j채mf철rt med icke-fientliga exempel.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ili kutengeneza mifano ambayo inavamiwa katika vifaa vingi vya majaribio, seti za mafunzo zinapaswa kuwajumuisha mifano mbalimbali ambazo zinazungumzia matukio mengi. Mkusanyiko wa takwimu za upinzani (DADC), ambapo vifaa vya watangazaji vinavyochanganya changamoto zinazoendelea kuboresha mifano, huahidi kuwa njia ya kutengeneza seti za mafunzo mbalimbali. Kazi ya awali imeonyesha kwamba kuendesha DADC zaidi ya runde 1-3 inaweza kusaidia miundo mbili kurekebisha aina za makosa, lakini haina lazima kuongezeka vizuri zaidi ya taarifa za upinzani. Tunajadili kwamba kuendelea DADC kwa zaidi ya maeneo mengi yanaongezea faida zake za muda wa mafunzo, kwa sababu maeneo mbalimbali yanaweza kuungana na mambo mengi yanayohusiana na kazi. We present the first study of longer-term DADC, where we collect 20 rounds of NLI examples for a small set of premise paragraphs, with both adversarial and non-adversarial approaches. Modeli zilizofundishwa katika mifano ya DADC hufanya makosa 26\% wachache zaidi kwenye mtihani wetu wa wataalam uliofanyika ukilinganishwa na mifano iliyoendeshwa kwenye takwimu zisizo na upinzani. Uchambuzi wetu unaonyesha kwamba DADC hutoa mifano ambayo ni ngumu zaidi, yenye tofauti za kisaikolojia na kwa pamoja, na ina vitu vidogo vidogo vingi vinavyofanana na mifano isiyo na upinzani.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>பலவிதமான சோதனை உள்ளீடுகளுக்கு மேல் இயக்கப்பட்ட மாதிரிகளை உருவாக்குவதற்கு, பயிற்சி தகவல் அமைப்பு Dynamic எதிர்பார்வை தகவல் தொகுப்பு (DADC), அங்கு அறிவிப்பாளர்கள் செயல் உதாரணங்கள் தொடர்ந்து மாதிரிகளை மேம்படுத்தும் முறைமைகளை சவால் ச முன்னிருப்பு வேலை காண்பிக்கப்பட்டுள்ளது DADC க்கு மேல் 1- 3 சுற்றுகள் இயங்குகிறது சில பிழை வகைகளை சரிசெய்ய உதவ முடியும், ஆனால் அது எதிர We argue that running DADC over many rounds maximizes its training-time benefits, as the different rounds can together cover many of the task-relevant phenomena. நாம் நீண்ட நீண்ட காலத்தின் முதல் படிப்பை காண்பிக்கிறோம், அங்கு நாம் NLI சுற்றிய 20 சுற்று உதாரணங்களை சேகரிக்கிறோம், ஒரு சிறிய முன் DADC உதாரணம் எங்கள் ஆராய்ச்சி DADC மிகவும் கடினமான உதாரணங்களை கொடுக்கும் என்று காண்பிக்கிறது அது மிகவும் மிகவும் கடினமாக இருக்கும், அதிகமாக மிகவும் ம</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Di흫e bir g철rn체힊 testi흫 giri힊inde g체첵챌li modeller bejermek 체챌in, bilim sistemalary birn채챌e g철rn체힊 철r채n eserlerde bolmaly. Dynamik te흫kili maglumat koleksi첵asy (DADC), 힊ol 첵erde n채챌e g철rn체힊ler nusgalary 체첵tgetmek 체챌in 철rnekler 챌yk첵ar, nusgalary 철r채n 체첵tgetmelidir. 횜흫ki i힊e g철ren DADC 1-3 depden 첵okarynda bir hili hata t체rlerini bejermek 체챌in k철mek edip biler, 첵철ne bu durum te흫kil testi흫 maglumatyndan has gowy d철redip bilmez. DADC'i birn채챌e g철rn체힊 첵체z체nde duran 챌yky힊 wagtyny흫 체챌in azaltylygyny azalt첵ar di첵ip pikir ed첵채ris, seb채bi farkl캇 g철rn체힊ler i힊i bilen mejbur bolan birn채챌e g철rn체힊i bilen 체첵tgedip bilerler. Biz DADC uzak durmu힊yny흫 ilkinji aralygyny g철rke첵채ris we olary흫 20 sany NLI 철rnekleri ki챌i birn채챌e paragraflar 체챌in 첵ygna첵arys. DADC mysllerinde e휓lenen nusgalar bizi흫 uzmanlarymyz 첵ok hasaplan첵an testimizde 26\% indir 첵al흫y힊lyk 첵ok hasaplan첵ar. Bizi흫 analyzamyz DADC'y흫 kyn, leksi첵aly we sintakti첵aly d체rli 철rneklerini da힊aryl첵ar we te흫kil d철w체rler bilen g철r채 첵akyn du첵gulama sungatlaryny da힊aryl첵ar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>نمڈلوں بنانے کے لئے جو آزمائش میں بہت زیادہ حصہ پر مضبوط ہیں، تدریس ڈیٹ سٹ میں مختلف مثالیں شامل کرنا چاہیے جو بہت سی مثالیں پھیلاتے ہیں۔ داینامیکی مخالف ڈیٹ اکلکسر (DADC) جہاں انڈیٹور مثالیں اڑاتے ہیں جو مدل کو ہمیشہ بہتر کرنے کے لئے چال دیتے ہیں، اس طرح طریقہ کی تدریس سٹ پیدا کرنے کے لئے وعدہ کا ذریعہ رکھتا ہے. پہلے کام نے دکھایا ہے کہ 1-3 راندوں سے DADC چلنے کی مدلکوں کی تعمیر کی مدد کر سکتی ہے، لیکن یہ ضرورت نہیں ہے کہ مخالف ٹیسٹ ڈیٹوں سے زیادہ بہتر عمومی آزمائش کی وجہ سے۔ ہم argue that running DADC over many rounds maximizes its training-time benefits, as the different rounds can together cover many of the task-relevant phenomena. ہم پہلی مطالعہ دیر ڈاکسی کے لئے پہلی مطالعہ پیش کرتے ہیں، جہاں ہم NLI کے 20 روندے مثالیں جمع کرتے ہیں ایک چھوٹی مطالعہ کے لئے، دونوں مخالف اور غیر مخالف طریقے کے ساتھ. DADC مثالوں پر آموزش کی مدل 26\% کم خطا کرتی ہیں ہمارے متخصص کریٹ ٹیسٹ پر جو غیر مخالف ڈیٹ پر آموزش کی مدل کے مقابلے میں ہے۔ ہماری تحلیل دکھاتی ہے کہ DADC کی مثال بیان کرتا ہے جو زیادہ مشکل ہیں، زیادہ زبان سے اور سینٹیکٹی سے مختلف ہیں، اور کم مثالیں لکھاتی ہیں جو غیر مخالف مثالوں کے مقابلے میں کم مثالیں ہیں.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Name Name Birinchi vazifa 1- 3 marta DADC dasturini ishga tushirish mumkin, bir necha xato turlarini oʻrnatish mumkin, lekin u to ʻgʻri tizim maʼlumotdan bajarishi kerak emas. Biz murakkab qilamiz, ko'pchilik davlatda DADC ishga tushirishni taʼminlovchi vaqt imkoniyatini oshirish mumkin, chunki har xil guruhlar vazifaning ko'pchiligini birlashtirish mumkin. Biz uzoq DDC'ning birinchi o'qituvchisini hozir qilamiz. Bu yerda biz biz bir kichkina prezident paragraphlar uchun NLI kabi 20 rund misollarini birinchi o'qituvchimiz. Name Analytikizni ko'rsatadi, DADC juda qiyin masallarni chiqaradi, ko'proq leksikak va syntiktikk tarkibi, va bizga qisqa taʼminlovchi narsalarga ega bo'ladi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Để tạo ra những mô hình vững chắc trên một loạt các nguồn nhập thử nghiệm, các bộ dữ liệu huấn luyện phải gồm những ví dụ khác nhau bao gồm cả nhiều hiện tượng. Sự thu thập dữ liệu nhân tạo (DADC), nơi các nhà biên niên chuyên làm gương thách thức việc cải thiện các mô hình liên tục, giữ hứa hẹn như một phương pháp để tạo ra các tập đoàn đào tạo khác nhau. Việc trước đã cho thấy chạy DADC trên vòng 1-3 có thể giúp người mẫu sửa một số loại lỗi, nhưng nó không nhất thiết dẫn đến việc tổng hợp hơn dữ liệu thí nghiệm ngược nhau. Chúng tôi cho rằng chạy đua DADC trên nhiều hiệp hội tối đa hóa lợi ích thời gian huấn luyện của nó, vì các hiệp hội có thể cùng nhau bao gồm nhiều hiện tượng liên quan đến nhiệm vụ. Chúng tôi giới thiệu nghiên cứu đầu tiên về DADC lâu dài, nơi chúng tôi thu thập hàng chục hiệp về NLl ví dụ cho một số trường hợp nhỏ, với cả hai phương pháp trái ngược lẫn không đối đầu. Những mẫu được huấn luyện về ví dụ DADC khiến 26\\\\\\\\\\\\\\\\\\càngít lỗi trong bộ thử nghiệm chuyên gia so với các mẫu được huấn luyện. Phân tích của chúng tôi cho thấy rằng DADC cung cấp những ví dụ khó khăn hơn, từ vựng hơn và theo cấu trúc khác nhau hơn, và chứa ít đồ ghi chú hơn so với ví dụ không phải đối thủ.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>若创于诸试输中有鲁棒性模形,练数集应包越诸示例。 动对抗性数收(DADC),其注释者作挑战不断改进模形之示例,有望于此多样化练集之法。 前之论明,行于1-3轮中DADC可以助形修非,非对抗性测试数据之外,未必善泛化也。 臣愚以为行数合DADC可最大化练时之利,异宜可共涵盖多事也。 请长DADC之第一项,为一小组提段落收20轮NLI示例,有对抗性非对抗性之法。 比于非对抗性之数,比于 DADC 示例之试,损于吾家之 26\%。 臣等之分析表明,比于非对抗性示例,DADC生示例益难,词汇语法更多样化,而包注伪影。</span></div></div><dl><dt>Anthology ID:</dt><dd>2022.findings-acl.86</dd><dt>Volume:</dt><dd><a href=/volumes/2022.findings-acl/>Findings of the Association for Computational Linguistics: ACL 2022</a></dd><dt>Month:</dt><dd>May</dd><dt>Year:</dt><dd>2022</dd><dt>Address:</dt><dd>Dublin, Ireland</dd><dt>Venues:</dt><dd><a href=/venues/acl/>ACL</a>
| <a href=/venues/findings/>Findings</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>1075–1088</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2022.findings-acl.86>https://aclanthology.org/2022.findings-acl.86</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">carton-etal-2022-learn</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Samuel Carton, Surya Kanoria, and Chenhao Tan. 2022. <a href=https://aclanthology.org/2022.findings-acl.86>What to Learn, and How: Toward Effective Learning from Rationales</a>. In <i>Findings of the Association for Computational Linguistics: ACL 2022</i>, pages 1075–1088, Dublin, Ireland. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2022.findings-acl.86>What to Learn, and How: Toward Effective Learning from Rationales</a> (Carton et al., Findings 2022)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2022.findings-acl.86.pdf>https://aclanthology.org/2022.findings-acl.86.pdf</a></dd><dt>Code</dt><dd><a href=https://github.com/chicagohai/learning-from-rationales><i class="fab fa-github"></i>&nbsp;chicagohai/learning-from-rationales</a></dd><dt>Data</dt><dd><a href=https://paperswithcode.com/dataset/fever>FEVER</a>,&nbsp;<a href=https://paperswithcode.com/dataset/multirc>MultiRC</a>,&nbsp;<a href=https://paperswithcode.com/dataset/e-snli>e-SNLI</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2022.findings-acl.86.pdf title="Open PDF of 'What to Learn, and How: Toward Effective Learning from Rationales'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=What+to+Learn%2C+and+How%3A+Toward+Effective+Learning+from+Rationales" title="Search for 'What to Learn, and How: Toward Effective Learning from Rationales' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-secondary d-flex flex-wrap justify-content-center" href="https://paperswithcode.com/paper/?acl=2022.findings-acl.86" title="Code for 'What to Learn, and How: Toward Effective Learning from Rationales' on Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-big" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg><span class="pl-sm-2 d-none d-sm-inline">Code</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'What to Learn, and How: Toward Effective Learning from Rationales'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[What to Learn, and How: Toward Effective Learning from Rationales](https://aclanthology.org/2022.findings-acl.86) (Carton et al., Findings 2022)</p><ul class=mt-2><li><a href=https://aclanthology.org/2022.findings-acl.86>What to Learn, and How: Toward Effective Learning from Rationales</a> (Carton et al., Findings 2022)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Samuel Carton, Surya Kanoria, and Chenhao Tan. 2022. <a href=https://aclanthology.org/2022.findings-acl.86>What to Learn, and How: Toward Effective Learning from Rationales</a>. In <i>Findings of the Association for Computational Linguistics: ACL 2022</i>, pages 1075–1088, Dublin, Ireland. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>