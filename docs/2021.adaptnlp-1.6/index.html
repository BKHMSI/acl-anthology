<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Challenges in Annotating and Parsing Spoken, Code-switched, Frisian-Dutch DataFrisian-Dutch Data - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="Challenges in Annotating and Parsing Spoken, Code-switched, Frisian-Dutch DataFrisian-Dutch Data" name=citation_title><meta content="Anouck Braggaar" name=citation_author><meta content="Rob van der Goot" name=citation_author><meta content="Proceedings of the Second Workshop on Domain Adaptation for NLP" name=citation_conference_title><meta content="2021/4" name=citation_publication_date><meta content="https://aclanthology.org/2021.adaptnlp-1.6.pdf" name=citation_pdf_url><meta content="50" name=citation_firstpage><meta content="58" name=citation_lastpage><meta property="og:title" content="Challenges in Annotating and Parsing Spoken, Code-switched, Frisian-Dutch DataFrisian-Dutch Data"><meta property="og:image" content="https://aclanthology.org/thumb/2021.adaptnlp-1.6.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2021.adaptnlp-1.6"><meta property="og:description" content="Anouck Braggaar, Rob van der Goot. Proceedings of the Second Workshop on Domain Adaptation for NLP. 2021."><link rel=canonical href=https://aclanthology.org/2021.adaptnlp-1.6></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Challenges in Annotating and Parsing Spoken, Code-switched, Frisian-Dutch Data<span class=acl-fixed-case>F</span>risian-<span class=acl-fixed-case>D</span>utch Data</a>
<a id=af_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Opdragte in Annotating and Parsing Spoken, Code-switched, Frisian-Dutch Data</a>
<a id=am_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>ምርጫዎች</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>التحديات في شرح وتحليل البيانات المنطوقة والمبدلة بالشفرة والفريزية الهولندية</a>
<a id=az_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Annotating and Parsing Spoken, Code-switched, Frisian-Dutch Data</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Предизвикателства при анотирането и анализирането на говорени, кодово-променени, фризийско-холандски данни</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>বিজ্ঞাপন এবং পার্সিং স্পুকেন, কোড- পরিবর্তন, ফ্রিসিয়ান-ডাচ তথ্যের চ্যালেঞ্জ</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>གསལ་བཤད་དང་ཞིབ་བཤེར་གྱི་ནང་དུ་ཁོང་ལ་དགོས་པ།</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Izazovi u Annotating and Parsing Spoken, Code-switched, Frisian-Dutch Data</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Els reptes en anotar i analitzar les dades parlades, canviades de codi, francés-holandeses</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Výzvy v komentování a analýze mluvených dat, přepínání kódu, frízsko-holandská data</a>
<a id=da_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Udfordringer i notering og fortolkning af talte, kodeskiftede, frisisk-hollandske data</a>
<a id=de_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Herausforderungen beim Annotieren und Parsen gesprochener, kodierter, friesisch-niederländischer Daten</a>
<a id=el_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Προκλήσεις σε σχολιασμό και ανάλυση ομιλούμενων, αλλαγή κώδικα, Φριζιανά-ολλανδικά δεδομένα</a>
<a id=es_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Desafíos en la anotación y el análisis de datos hablados, con cambio de código y entre frisón y holandés</a>
<a id=et_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Väljakutsed räägitud, koodiga vahetatud, friisi-hollandi andmete märgistamisel ja parsimisel</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>challenges in Annotating and Parsing Spoken, Code-switched, Frisian-Dutch Data</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Haasteet puhuttujen merkintöjen ja analysoinnin, koodinvaihtoisten, friisialaisten ja hollantilaisten tietojen osalta</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Difficultés liées à l'annotation et à l'analyse des données parlées, à commutation de code et frison-néerlandais</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Dúshláin maidir le Anótáil agus Parsáil Sonraí Labhartha, Cóid-aistrithe, Freaslainnise-Ollainnis</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Challenges in Annotating and Parsing Spoken, Code-switched, Frisian-Dutch Data</a>
<a id=he_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>אתגרים בהעטפות ומחקרים מדברים, מחליפים קודים, מידע פריזי-הולנדי</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>एनोटेटिंग और पार्सिंग बोली गई, कोड-स्विच्ड, फ्रिसियन-डच डेटा में चुनौतियां</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Izazovi u Annotating and Parsing Spoken, Code-switched, Frisian-Dutch Data</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Kihívások a beszéd jegyzetelésében és értelmezésében, kódkapcsolású, fríz-holland adatok</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Խնդիրները նշում և վերլուծում խոսքերի, կոդի փոխակերպման, ֆրիսիական-հոլանդական տվյալների մեջ</a>
<a id=id_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>tantangan dalam Annotasi dan Analisasi Bicara, Kode-switched, Data Frisian-Belanda</a>
<a id=is_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Sfide nell'annotazione e nell'analisi dei dati parlati, commutazione di codice, Friso-Olandese</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>フリジア語-オランダ語データのコードスイッチによるアノテーションと解析の課題</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Delokan Nanggang-Ngerawat lan Pansing Pikno, kode-bisa, Dong-Olayan Jejarang</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Name</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Жазбалау және талдау тізбектері, код ауыстырылған, фрис- голландша деректері</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>구어, 코드 변환, 프리스 네덜란드어 데이터 주석과 해석의 도전</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Anotacijos ir analizavimo iššūkiai, kodų keitimas, prancūzų ir olandų duomenys</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Предизвики во анатирање и анализирање на зборови, промена на код, фризиско-холандски податоци</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>കോഡ്- മാറ്റി, ഫ്രിസിഷ്യന്‍ ഡേറ്റാName</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Аннотаци болон талбарлах хэмжээний шаардлага, Код-өөрчлөгдсөн, Фризиан-Датч өгөгдлийн шаардлага</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Challenges in Annotating and Parsing Spoken, Code-switched, Frisian-Dutch Data</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Sfidi fl-Annotazzjoni u l-Analiżi tal-Konflitti, Kodiċi mibdula, Data Franċiża-Olandiża</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Uitdagingen in Annoteren en Parsen Gesproken, Code-switched, Fries-Nederlandse data</a>
<a id=no_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Utfordringar i annotasjon og tolking av spoken, kodbytt, frisk- nederlandsk data</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Wyzwania w komentowaniu i analizie mówionych, przełączaniu kodu, fryzyjsko-holenderskich danych</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Desafios na anotação e análise de dados falados, trocados por código, frísios-holandeses</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Provocări în adnotarea și analizarea datelor vorbite, schimbarea codului, datele frisone-olandeze</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Проблемы, связанные с аннотацией и разбором речевых, кодовых, фризско-голландских данных</a>
<a id=si_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Name</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Izzivi pri označevanju in razčlenjanju govorjenih, preklopljenih s kodami, frizijsko-nizozemskih podatkov</a>
<a id=so_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Challenges in Annotation and Parsing, Cod-switched, Frisian-Dutch Data</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Sfidat në njoftimin dhe analizimin e të dhënave të folura, të ndryshuara me kod, të dhënave frizi-hollandeze</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Izazovi u Annotating and Parsing Spoken, Code-switched, Frisian-Dutch Data</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Utmaningar i att kommentera och tolka tal, kodväxlad, frisisk-holländska data</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Changamoto katika Mjadala wa Kutangaza na Kuchapisha, Kubadilishwa kwa Code, Taarifa za UFrisian-Dutch</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Name</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Annotating and Parsing Spoken, Kod-switched, Frisian-Dutch Data</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Annotating and Parsing Spoken, Code-switched, Frisian-Dutch Data میں چالنج</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Name</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>Bài thi đấu giải thích và giải thích bằng ngôn ngữ</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>注与解析口语、代码切换、弗里斯兰语-荷兰语数挑战</a></h2><p class=lead><a href=/people/a/anouck-braggaar/>Anouck Braggaar</a>,
<a href=/people/r/rob-van-der-goot/>Rob van der Goot</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>While high performance have been obtained for high-resource languages, performance on low-resource languages lags behind. In this paper we focus on the <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a> of the low-resource language Frisian. We use a sample of code-switched, spontaneously spoken data, which proves to be a challenging setup. We propose to train a <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> specifically tailored towards the target domain, by selecting instances from multiple <a href=https://en.wikipedia.org/wiki/Treebank>treebanks</a>. Specifically, we use Latent Dirichlet Allocation (LDA), with word and character N-grams. We use a deep biaffine parser initialized with mBERT. The best single source treebank (nl_alpino) resulted in an <a href=https://en.wikipedia.org/wiki/Greatest_common_divisor>LAS</a> of 54.7 whereas our data selection outperformed the single best transfer treebank and led to 55.6 <a href=https://en.wikipedia.org/wiki/Greatest_common_divisor>LAS</a> on the test data. Additional experiments consisted of removing <a href=https://en.wikipedia.org/wiki/Diacritic>diacritics</a> from our Frisian data, creating more similar training data by cropping sentences and running our best <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> using XLM-R. These experiments did not lead to a better performance.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Terwyl hoë prestasie vir hoë-hulpbronne tale ontvang is, het prestasie op lae-hulpbronne tale agter verlaat. In hierdie papier fokus ons op die verwerking van die lae hulpbron taal Frisian. Ons gebruik 'n voorbeeld van kode-geskuif, spontaneël gepraat data, wat bevestig dat 'n pragtige opstelling is. Ons voorstel om 'n analyseer spesifieke na die doel domein te trein deur voorbeelde te kies van veelvuldige treebanks. Spesifieke, ons gebruik Latent Dirichlet Allocation (LDA), met woord en karakter N- grame. Ons gebruik 'n diep biaffine ontwerker wat geïnisialiseer is met mBERT. Die beste enkele bron treebank (nl_alpino) het resultaat in 'n LAS van 54.7 terwyl ons data keuse uitgevoer het die enkele beste oordrag treebank en gelei na 55.6 LAS op die toets data. Addisionele eksperimente het bestuur van die verwyder van diakrities van ons Frisiese data, skep meer gelyke onderwerp data deur die kruip van teikens en die bestuur van ons beste model gebruik van XLM-R. Hierdie eksperimente het nie na 'n beter uitvoering gelei nie.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ከፍተኛ የክፍለ ሀብት ቋንቋዎች ሲያገኙ፣ የዝናብ ቋንቋዎች ፍላጎት በኋላ ነው፡፡ በዚህ ገጽ የዋናው የፍሪሳውያንን ቋንቋ ማዘጋጀት ላይ እናስማማታለን፡፡ የኮድ ተለወጠን ምሳሌ እናስቀምጣለን፡፡ በተለየ አካባቢ አካላቢ ዶሜን በመምረጥ የተመሳሳይ ምርጫዎችን በመምረጥ እናሳውቃለን፡፡ በተለያይነት፣ Latent Dirichlet Allocation (LDA), በቃል እና በ-graph እናስቀምጣለን፡፡ በ mBERT የተጀመረ ጥልቅ የቢፊን ምርጫዎች እናስቀምጣለን፡፡ The best single source treebank (nl_alpino) resulted in an LAS of 54.7 whereas our data selection outperformed the single best transfer treebank and led to 55.6 LAS on the test data. ጨዋታ ፈተናዎች ከፍሪሳዊ ዳታዎችን ለማስወግድ፣ እንደዚህ ብጤ የተሰናከረውን አስተማሪ ዳታዎችን በመፍጠር እና በXLM-R በመጠቀም የተሻለ ሞዴላዎችን ለመፈለግ ነው፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>في حين تم الحصول على أداء عالٍ للغات عالية الموارد ، فإن الأداء في اللغات منخفضة الموارد يتأخر. في هذه الورقة نركز على تحليل اللغة الفريزية منخفضة الموارد. نحن نستخدم عينة من البيانات المنطوقة تلقائيًا بتبديل الشفرة ، والتي تثبت أنها إعداد صعب. نقترح تدريب المحلل اللغوي المصمم خصيصًا نحو المجال المستهدف ، عن طريق اختيار مثيلات من بنوك شجرية متعددة. على وجه التحديد ، نستخدم تخصيص Latent Dirichlet (LDA) ، مع كلمة وحرف N-grams. نحن نستخدم محلل لغوي عميق للبيافيني تمت تهيئته بـ mBERT. نتج عن أفضل بنك شجرة أحادي المصدر (nl_alpino) معدل LAS قدره 54.7 في حين تفوق اختيارنا على البيانات على أفضل بنك شجرة واحد وأدى إلى 55.6 LAS في بيانات الاختبار. اشتملت التجارب الإضافية على إزالة علامات التشكيل من بياناتنا الفريزية ، وإنشاء بيانات تدريب أكثر تشابهًا عن طريق اقتصاص الجمل وتشغيل أفضل نموذج لدينا باستخدام XLM-R. لم تؤد هذه التجارب إلى أداء أفضل.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Yüksek performans yüksək kaynaqlar dillərinə verilən halda, düşük kaynaqlar dillərində performans geri qalar. Bu kağızda biz düşük ressurs dilini Frisian dilinin ayırmasına odaklanırıq. Biz kodu dəyişdirilmiş, spontane danışmış məlumatların nümunələrini istifadə edirik, bu isə çətin bir qurğu göstərir. Biz müəyyən edilmiş məqsəd domeinə təhsil edilən bir parçacın təhsil etməyi təklif edirik, çoxlu a ğaç çubuqlarından örnəkləri seçərək. Biz Latent Dirichlet Allocation (LDA) sözləri və karakterləri N-gramləri ilə istifadə edirik. Biz mBERT ilə başlanğıçlı bir biafin parçacısını istifadə edirik. Ən yaxşısı tək mənbə çubuğu (nl_alpino) 54.7-lik LAS olaraq gəldi, amma məlumatlarımız seçilməsi tək təkrar təkrar çubuğunu təkrar etdi və sınama məlumatlarında 55.6 LAS təkrar etdi. XLM-R vasitəsilə ən yaxşı modellərimizi istifadə etmək üçün daha çox bənzər təhsil məlumatları yaratmaq və XLM-R vasitəsilə ən yaxşı modellərimizi istifadə etmək məqsədilə idi. Bu experimentlər daha yaxşı təhsil etməyə yol vermədi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Въпреки че е постигната висока производителност за езици с висок ресурс, производителността на езици с нисък ресурс изостава. В тази статия се фокусираме върху анализирането на нискоресурсния език фризийски. Използваме пример от кодово превключени, спонтанно говорени данни, което се оказва предизвикателна настройка. Предлагаме да се обучи анализатор, специално пригоден за целевия домейн, като се избират инстанции от множество дървесни ленти. По-конкретно, ние използваме латентно разпределение на дириклет (ЛДА), с дума и знак Н-грама. Използваме дълбок биафинов анализатор инициализиран с mBERT. Най-добрата единична дървесна банка (Нл_алпино) доведе до LAS от 54.7, докато нашият избор на данни надмина най-добрата единична дървесна банка за трансфер и доведе до 55.6 LAS на тестовите данни. Допълнителните експерименти се състояха в премахване на диакритиката от фризийските ни данни, създаване на повече подобни данни за обучение чрез изрязване на изречения и стартиране на най-добрия ни модел с помощта на Тези експерименти не доведоха до по-добро представяне.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>যখন উচ্চ সম্পদের ভাষার জন্য উচ্চভাষা পাওয়া গেছে, তখন কম সম্পদ ভাষায় প্রদর্শন করা হয়েছে। এই পত্রিকায় আমরা নীচের সম্পদ ভাষা ফ্রিসিয়ানের পার্গিং দিয়ে মনোযোগ দিচ্ছি। আমরা কোড পরিবর্তনের উদাহরণ ব্যবহার করি, স্বয়ংক্রিয়ভাবে কথা বলা তথ্য ব্যবহার করি, যা একটি চ্যালেঞ্জের ব্যবস্থা প্রমাণ করে। আমরা বিশেষ করে লক্ষ্য ডোমেইনের দিকে একটি প্রশিক্ষণ প্রশিক্ষণ দিতে প্রস্তাব করছি, বেশ কয়েকটি ত্রিব্যাংক থেকে অনুষ্ঠিত হয়েছে। বিশেষ করে, আমরা ল্যাটেন্ট ডিরিচেলেট অ্যালোকেশন (এলডিএ) ব্যবহার করি, শব্দ এবং অক্ষর এন-গ্রাম দিয়ে। আমরা একটি গভীর বিয়াফিন প্যারেজার ব্যবহার করি যা এমবের্টের সাথে শুরু করা হয়েছে। সবচেয়ে ভালো সূত্র ট্রিবাঙ্ক (এনএল_আলপিনো) এর ফলে ৫৪. ৭ সালের একটি ল্যাসের ফলে আমাদের তথ্য নির্বাচনের মধ্যে সবচেয়ে ভালো ট্রেইব্যান্সফার্নারে আরো পরীক্ষার মধ্যে রয়েছে আমাদের ফ্রিসিয়ান ডাটা থেকে ডায়ারিকারীদের সরিয়ে নেয়ার জন্য, তারা বিভিন্ন ধরনের প্রশিক্ষণের তথ্য তৈরি করে এবং এক্সএলএম-</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>རྒྱུ་དངོས་ཐོག ང་ཚོས་ཤོག་བྱང་འདིའི་ནང་དུ་རྒྱ་ནག་མི་མང་ཆེ་བའི་སྐད་རིགས་ཕྱོགས་སྟོན་པ་ཚོར་བློ་གཏོང་ནི་ ང་ཚོས་མཚོན་རྟགས་ལ་བསྒྱུར་བཅོས་བྱས་པའི་མིག་གྲངས་ཀྱི་དཔེ་བརྗོད་ཞིག་སྤྱོད་ཀྱི་ཡོད། We propose to train a parser specifically tailored towards the target domain, by selecting instances from multiple treebanks. དམིགས་འཛུགས་ཀྱིས། ང་ཚོས་Latent Dirichlet Allocation (LDA)དང་ཐ་སྙད་དང་ཡིག་འབྲུ་N-gramདང་བེད་སྤྱོད་པ We use a deep biaffine parser initialized with mBERT. གསལ་ཤོག་མའི་ཐོག་མའི་འཇུག་སྣོད་གསལ་པོ(nl_alpino)དེ་འདྲ་བཤུ་ཐུབ་པ་ཡིན། ང་ཚོའི་གནས་སྡུད་འདེམས་ཀྱིས་གསལ་བཤད་ཀྱི་གནས་སྟངས་མང་ཤོས་མའི་འཇུག་སྣོད དབྱེ་ཚིག་གི་བརྟག་དཔྱད་ཆ་རྣམས་ང་ཚོའི་Frisian གནད་སྡུད་ཕྱིར་འཐེན་བྱས་ན་ཏེ།</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Iako je napravljena visoka učinkovitost za jezike visokog resursa, nastup na jezicima niskog resursa ostaje iza sebe. U ovom papiru fokusiramo se na analizu jezika niskog resursa Frisianca. Koristimo uzorak zamjene šifre, spontano govorenih podataka, koji dokazuje da je izazovna postavka. Predlažemo da treniramo analizatora posebno prilagođenog prema ciljnom domenu, birajući instance iz višestrukih područja. Posebno, koristimo Latent Dirichlet Allocation (LDA), sa riječima i karakterom N-grama. Koristimo duboki analizator biafina inicijaliziran sa mBERT-om. Najbolji jedinstveni izvor treeban (nl_alpino) rezultirao je LAS od 54,7, dok je naš izbor podataka iznosio jedinstveni najbolji prevoz treeban i doveo do 55,6 LAS na testne podatke. Dodatni eksperimenti su sastavljeni od uklanjanja diakritika iz naših Frijskih podataka, stvaranja sličnih podataka obuke usvajanjem rečenica i vodeći naš najbolji model koristeći XLM-R. Ovi eksperimenti nisu doveli do boljih izvođenja.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tot i que s'han aconseguit alts resultats en llengües d'alt recurso, els resultats en llengües de baix recurso es retarden. En aquest article ens centrem en l'analització del francès amb baix recursos. Utilitzem una mostra de dades parlades espontàniament canviades de codi, que resulta ser una configuració difícil. We propose to train a parser specifically tailored towards the target domain, by selecting instances from multiple treebanks. En concret, utilitzem l'Allocació Latent Dirichlet (LDA), amb paraula i caràcter N-grams. Utilitzem un analitzador biaffin profund inicializat amb mBERT. El millor banc d'arbres d'una sola font (nl_alpino) va resultar en un LAS de 54,7 mentre que la nostra selecció de dades va superar el millor banc d'arbres de transfer ència i va portar a 55,6 LAS en les dades de prova. Els experiments adicionals van consistir en eliminar diacrítics de les nostres dades frises, crear dades de formació més similars recollint frases i executant el nostre millor model fent servir XLM-R. Aquests experiments no van portar a millor rendiment.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Zatímco u jazyků s vysokými zdroji bylo dosaženo vysokého výkonu, výkon u jazyků s nízkými zdroji zaostává. V tomto článku se zaměřujeme na analýzu nízkoprostrojového jazyka fríštiny. Používáme vzorek kódově přepínaných, spontánně mluvených dat, což se ukáže jako náročné nastavení. Navrhujeme trénovat parser speciálně přizpůsobený cílové doméně výběrem instancí z více stromových bank. Konkrétně používáme Latent Dirichlet Allocation (LDA), s N-gramy slova a znaků. Používáme hluboký biafinový parser inicializovaný mBERT. Nejlepší single source stromová banka (nl_alpino) vyústila v LAS 54.7, zatímco náš výběr dat předčil nejlepší přenosovou stromovou banku a vedl k 55.6 LAS na testovacích datech. Další experimenty spočívaly v odstranění diakritiky z frízských dat, vytvoření podobnějších tréninkových dat oříznutím vět a spuštění našeho nejlepšího modelu pomocí XLM-R. Tyto experimenty nevedly k lepšímu výkonu.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mens der er opnået høj ydeevne for sprog med høj ressource, er ydeevnen på sprog med lav ressource bagud. I denne artikel fokuserer vi på tolkningen af det lave ressourcesprog frisisk. Vi bruger en prøve af kodekoblingte, spontant talte data, hvilket viser sig at være en udfordrende opsætning. Vi foreslår at træne en fortolker specifikt skræddersyet til måldomænet ved at vælge forekomster fra flere træbanker. Specielt bruger vi Latent Dirichlet Allocation (LDA), med ord og tegn N-gram. Vi bruger en dyb biaffin parser initialiseret med mBERT. Den bedste single source treebank (nl_alpino) resulterede i en LAS på 54,7, mens vores datavalg overgik den enkelte bedste transfer treebank og førte til 55,6 LAS på testdata. Yderligere eksperimenter bestod i at fjerne diakritikere fra vores frisiske data, skabe mere lignende træningsdata ved at beskære sætninger og køre vores bedste model ved hjælp af XLM-R. Disse eksperimenter førte ikke til en bedre præstation.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Während hohe Leistung für ressourcenintensive Sprachen erzielt wurde, hinkt die Leistung bei ressourcenarmen Sprachen hinterher. In diesem Beitrag konzentrieren wir uns auf das Parsen der ressourcenarmen Sprache Friesisch. Wir verwenden ein Beispiel von code-geschalteten, spontan gesprochenen Daten, was sich als herausforderndes Setup erweist. Wir schlagen vor, einen Parser zu trainieren, der speziell auf die Zieldomäne zugeschnitten ist, indem Instanzen aus mehreren Baumbänken ausgewählt werden. Insbesondere verwenden wir Latent Dirichlet Allocation (LDA), mit Wort- und Zeichen-N-Gramm. Wir verwenden einen tiefen Biaffinparser, der mit mBERT initialisiert wurde. Die beste Single Source Treebank (nl_alpino) führte zu einem LAS von 54.7, während unsere Datenauswahl die beste Single Transfer Treebank übertraf und zu 55.6 LAS auf den Testdaten führte. Weitere Experimente bestanden darin, Diakritiken aus unseren friesischen Daten zu entfernen, mehr ähnliche Trainingsdaten durch Zuschneiden von Sätzen zu erstellen und unser bestes Modell mit XLM-R auszuführen. Diese Experimente führten nicht zu einer besseren Leistung.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ενώ έχουν επιτευχθεί υψηλές επιδόσεις για γλώσσες υψηλής περιεκτικότητας, οι επιδόσεις στις γλώσσες χαμηλής περιεκτικότητας παραμένουν πίσω. Σε αυτή την εργασία εστιάζουμε στην ανάλυση της χαμηλής περιεκτικότητας στη φριζιανή γλώσσα. Χρησιμοποιούμε ένα δείγμα κωδικοποιημένων, αυθόρμητα μιλημένων δεδομένων, το οποίο αποδεικνύεται μια δύσκολη ρύθμιση. Προτείνουμε να εκπαιδεύσουμε έναν αναλυτή ειδικά προσαρμοσμένο στον τομέα προορισμού, επιλέγοντας περιπτώσεις από πολλαπλές τράπεζες δέντρων. Συγκεκριμένα, χρησιμοποιούμε τη Λατινική Κατανομή Διρίκλετ (με Ν-γράμματα λέξης και χαρακτήρων). Χρησιμοποιούμε έναν βαθύ αναλυτή μπιαφίνης αρχικοποιημένο με mBERT. Η καλύτερη τράπεζα δέντρων μίας πηγής (οδήγησε σε ένα LAS 54.7 ενώ η επιλογή δεδομένων μας ξεπερνούσε την καλύτερη τράπεζα δέντρων μεταφοράς και οδήγησε σε 55.6 LAS στα δεδομένα δοκιμής. Επιπρόσθετα πειράματα συνίσταντο στην αφαίρεση των διακοπτικών από τα φριζιανά δεδομένα μας, στη δημιουργία περισσότερων παρόμοιων εκπαιδευτικών δεδομένων με περικοπή προτάσεων και την εκτέλεση του καλύτερου μοντέλου μας χρησιμοποιώντας Αυτά τα πειράματα δεν οδήγησαν σε καλύτερη απόδοση.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Si bien se ha obtenido un alto rendimiento para los lenguajes de recursos altos, el rendimiento en idiomas de bajos recursos va a la zaga. En este artículo nos centramos en el análisis del idioma frisón de bajos recursos. Utilizamos una muestra de datos de cambio de código y hablados espontáneamente, lo que demuestra ser una configuración desafiante. Proponemos entrenar un analizador específicamente diseñado para el dominio de destino, mediante la selección de instancias de varios bancos de árboles. Específicamente, utilizamos la asignación de Dirichlet latente (LDA), con N-gramas de palabras y caracteres. Utilizamos un analizador biafín profundo inicializado con mBert. El mejor banco de árboles de una sola fuente (nl_alpino) dio como resultado un LAS de 54,7, mientras que nuestra selección de datos superó al mejor banco de árboles de transferencia y condujo a 55,6 LAS en los datos de prueba. Los experimentos adicionales consistieron en eliminar los signos diacríticos de nuestros datos en frisón, crear datos de entrenamiento más similares recortando oraciones y ejecutando nuestro mejor modelo con XLM-R. Estos experimentos no condujeron a un mejor rendimiento.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kuigi suure ressursiga keelte puhul on saavutatud suur jõudlus, jääb vähese ressursiga keelte puhul maha. Käesolevas töös keskendume parsimisele madala ressursiga keele friisi keel. Me kasutame koodiga vahetatud spontaanselt kõnelevate andmete näidist, mis osutub keeruliseks seadistuseks. Me teeme ettepaneku koolitada spetsiaalselt sihtdomeenile kohandatud parser, valides eksemplarid mitmest puupunktist. Täpsemalt kasutame Latent Dirichlet Allocation (LDA), sõna- ja märgiga N-grammid. Me kasutame sügavat biafiini parserit, mis on initsialiseeritud mBERT-ga. Parima ühe allika puupanga (nl_alpino) tulemuseks oli LAS 54,7, samas kui meie andmete valik ületas ühe parima ülekande puupanga ja viis 55,6 LAS testi andmetel. Täiendavad eksperimendid hõlmasid diakriitika eemaldamist meie friisi andmetest, sarnasemate treeningandmete loomist lausete kärpimise teel ja parima mudeli kasutamist XLM-R abil. Need eksperimendid ei viinud parema tulemuseni.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>در حالی که عملکرد بالا برای زبانهای منابع بالا دریافت شده است، عملکرد روی زبانهای منابع کم باقی مانده است. در این کاغذ ما روی تجزیه کردن زبان کم منبع فریزین تمرکز می کنیم. ما از نمونه‌ای از داده‌های تغییر کد استفاده می‌کنیم، که ثابت می‌کند یک تنظیم مشکل است. ما پیشنهاد می‌کنیم که یک بازیگر ویژه‌ای را به سمت دامنه هدف آموزش دهیم، با انتخاب نمونه‌ها از بسته‌های متعدد درخت‌ها. به طور خاصی، ما با کلمه و شخصیت N-گرم استفاده می‌کنیم از تقسیم دیریکلت Latent (LDA). ما از یک تجزیه‌کننده‌ی بیفاین عمیق استفاده می‌کنیم که با mBERT شروع شده است. بهترین ترکیب ترکیب منبع تنها (nl_alpino) به نتیجه یک LAS از 54.7 به وجود آورد، در حالی که انتخاب داده‌های ما بهترین ترکیب ترکیب ترکیب تنها را برداشت و به 55.6 LAS در داده‌های آزمایش برداشت. آزمایشات اضافه از حذف دیاکریک‌ها از داده‌های فریسی ما بودند، و داده‌های آموزش مشابه‌تر از جمله‌های جمع کردن جمله‌ها و اجرای بهترین مدل‌های ما با استفاده از XLM-R. این آزمایشات به انجام بهتر رهبری نکردند.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vaikka suuriresurssisten kielten suorituskyky on saavutettu, vähäresurssisten kielten suorituskyky on jäljessä. Tässä artikkelissa keskitymme jäsentämiseen vähäresurssinen kieli friisi. Käytämme koodinvaihtoista, spontaanisti puhuttua dataa, joka osoittautuu haastavaksi kokoonpanoksi. Ehdotamme, että koulutetaan kohdeverkkotunnukselle räätälöity jäsentäjä valitsemalla esiintymiä useista puupankeista. Erityisesti käytämme Latent Dirichlet Allocation (LDA), jossa on sana ja merkki N-grammia. Käytämme syvää biafiininparseria, joka on alustettu mBERT:llä. Paras yhden lähteen puupankki (nl_alpino) tuotti LAS:n 54,7, kun taas meidän tietovalikoimamme ylitti yksittäisen parhaan siirtopuupankin ja johti 55,6 LAS:iin testitiedoissa. Lisäkokeet koostuivat diakriitikkojen poistamisesta friisilaisista tiedoista, samankaltaisten harjoitustietojen luomisesta lauseita leikkaamalla ja parhaan mallimme ajamisesta XLM-R:llä. Nämä kokeet eivät johtaneet parempaan suorituskykyyn.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Alors que des performances élevées ont été obtenues pour les langues à ressources élevées, les performances dans les langues à faibles ressources sont à la traîne. Dans cet article, nous nous concentrons sur l'analyse de la langue frisonne à faibles ressources. Nous utilisons un échantillon de données vocales spontanément commutées par code, ce qui s'avère être une configuration difficile. Nous proposons de former un analyseur spécialement adapté au domaine cible, en sélectionnant des instances parmi plusieurs banques d'arbres. Plus précisément, nous utilisons l'allocation de Dirichlet latente (LDA), avec des N-grammes de mots et de caractères. Nous utilisons un analyseur biaffine profond initialisé avec MBert. La meilleure banque d'arbres source unique (nl_alpino) a donné un LAS de 54,7 alors que notre sélection de données a surpassé la meilleure banque d'arbres de transfert unique et a conduit à 55,6 LAS sur les données de test. Des expériences supplémentaires ont consisté à supprimer les signes diacritiques de nos données frisonnes, à créer des données d'entraînement plus similaires en recadrant des phrases et en utilisant notre meilleur modèle à l'aide de XLM-R. Ces expériences n'ont pas permis d'améliorer les performances.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Cé go bhfuil ardfheidhmíocht bainte amach do theangacha ard-acmhainne, tá feidhmíocht ar theangacha íseal-acmhainne chun deiridh. Sa pháipéar seo dírímid ar pharsáil na Freaslainnise Freaslainnise. Bainimid úsáid as sampla de shonraí cód-aistrithe, a labhraítear go spontáineach, rud a chruthaíonn gur socrú dúshlánach é. Tá sé beartaithe againn parsálaí a oiliúint a bheidh saindeartha don spriocfhearann, trí chásanna a roghnú ó ilchúnna crann. Go sonrach, úsáidimid Leithdháileadh Dirichlet Folaigh (LDA), le focal agus carachtar N-gram. Bainimid úsáid as parsálaí domhain biaifín inisealaithe le mBERT. Bhí SAR de 54.7 mar thoradh ar an gcruach crann aonfhoinse is fearr (nl_alpino) ach d’fheidhmigh ár rogha sonraí níos fearr ná an banc crann aistrithe aonair is fearr agus ba é an toradh a bhí air ná 55.6 LAS ar na sonraí tástála. Is éard a bhí i dturgnaimh bhreise diacritics a bhaint as ár sonraí Freaslainnise, sonraí oiliúna níos cosúla a chruthú trí abairtí a ghearradh agus ár múnla is fearr a rith ag baint úsáide as XLM-R. Ní raibh feidhmíocht níos fearr mar thoradh ar na turgnaimh seo.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Akwai da za'a iya samar da sauri wa harshen masu sarki, aiki na bakin harshen-wuri-resource. Ga wannan karatun, Munã fokus wa paring of the lower-resource language Frisian. Tuna yi amfani da wani misali da aka canza kodi, da aka yi magana farat ɗaya, da za'a iya kasa zama tsarin mai tsõratar. Tunamaɗa mu kõre wani parser wanda aka ƙayyade shi zuwa duk aka goa, kuma za mu zãɓi misãlai daga bakin turu masu yawa. A ƙayyade, Munã yi amfani da Allocation na Naƙasan Dirikla (LDA), da maganar da takardar N-gram. Tuna amfani da wani parse mai ƙari wa biffine wanda aka fara da mBERT. Tan da mafi kyaun source trebank (nl_alpino) ta ƙara wata MAS na 54.7 alhãli kuwa zaɓallinmu na zaɓe ta kowacan transfer ta Treebank kuma ya zaɓi 55.6 lass a kan data ta jarraba. Wata jarrabo na ƙaranci na sami da ta tafiyar da diagon daga data masu Frisian, suna samun data masu kama da kwatanku da za'a yi danganta da cire-garwaya kuma ya yi tafiyar da misãlai masu kyãwo da amfani da XLM-R. Wannan jarrabõ ba ta ƙara wani mafiya tsari ba.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>While high performance have been obtained for high-resource languages, performance on low-resource languages lags behind. בעיתון הזה אנו מתמקדים במחקר של שפת משאבים נמוכים פריזית. אנחנו משתמשים בדגימה של נתונים שנחלפו קודים, שדיברו באופן ספונטני, מה שמוכיח להיות התקנה מאתגרת. אנו מציעים לאמן מעבד מתוכנן במיוחד לכיוון תחום המטרה, על ידי לבחור מקרים ממספר עצים. במיוחד, אנו משתמשים בהחלטת דיריקלט לאנט (LDA), עם מילה ודמות N-גרם. אנחנו משתמשים במחקר ביאפין עמוק שנתחיל עם mBERT. בנק העץ המקור היחיד הטוב ביותר (nl_alpino) הוביל לאס.אס של 54.7 בזמן שבבחירת הנתונים שלנו עברה את בנק העץ היחיד הטוב ביותר והוביל ל-55.6 לאס.אס על הנתונים המבחנים. ניסויים נוספים כוללו להסיר מחתונים מהנתונים הפריסיים שלנו, ליצור נתונים אימונים דומים יותר על ידי גיבוי משפטים ולפעיל את המודל הטוב ביותר שלנו באמצעות XLM-R. ניסויים אלה לא הובילו להופעה טובה יותר.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>जबकि उच्च-संसाधन भाषाओं के लिए उच्च प्रदर्शन प्राप्त किया गया है, कम-संसाधन भाषाओं पर प्रदर्शन पीछे है। इस पेपर में हम कम-संसाधन भाषा फ्रिसियन के पार्सिंग पर ध्यान केंद्रित करते हैं। हम कोड-स्विच्ड, अनायास बोले जाने वाले डेटा के नमूने का उपयोग करते हैं, जो एक चुनौतीपूर्ण सेटअप साबित होता है। हम एक पार्सर को विशेष रूप से लक्ष्य डोमेन की ओर सिलवाया प्रशिक्षित करने का प्रस्ताव करते हैं, कई ट्रीबैंक से उदाहरणों का चयन करके। विशेष रूप से, हम अव्यक्त Dirichlet आवंटन (LDA) का उपयोग करें, शब्द और चरित्र एन-ग्राम के साथ। हम mBERT के साथ शुरू किए गए एक गहरे biaffine पार्सर का उपयोग करते हैं। सर्वश्रेष्ठ एकल स्रोत ट्रीबैंक (nl_alpino) के परिणामस्वरूप 54.7 का एलएएस हुआ, जबकि हमारे डेटा चयन ने एकल सर्वश्रेष्ठ ट्रांसफर ट्रीबैंक को पछाड़ दिया और परीक्षण डेटा पर 55.6 एलएएस का नेतृत्व किया। अतिरिक्त प्रयोगों में हमारे फ्रिसियन डेटा से डायक्रिटिक्स को हटाने, वाक्यों को क्रॉप करके और एक्सएलएम-आर का उपयोग करके हमारे सबसे अच्छे मॉडल को चलाने के द्वारा अधिक समान प्रशिक्षण डेटा बनाना शामिल था। इन प्रयोगों ने बेहतर प्रदर्शन नहीं किया।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Iako je napravljena visoka učinkovitost na jezicima visokih resursa, učinkovitost na jezicima niskih resursa ostaje iza nje. U ovom papiru fokusiramo se na analizu jezika niskog resursa Frisianca. Koristimo uzorak zamjene šifre, spontano govorenih podataka, koji dokazuje da je izazovna postavka. Predlažemo trenirati analizatora posebno prilagođenog prema ciljnom domenu, birajući instancije iz višestrukih područja. Posebno, koristimo Latent Dirichlet Allocation (LDA), s riječima i karakterom N-grama. Koristimo duboki analizator biafina inicijaliziran s mBERT-om. Najbolji jedinstveni izvor treeban (nl_alpino) rezultirao je LAS od 54,7, dok je naš izbor podataka iznosio jedinstveni najbolji prijenos treeban i doveo do 55,6 LAS na testne podatke. Dodatni eksperimenti su sastavljeni od uklanjanja dijamanata iz naših Frisijskih podataka, stvaranja sličnih podataka za obuku prijevozom rečenica i vodeći naš najbolji model koristeći XLM-R. Ovi eksperimenti nisu doveli do boljih učinka.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Míg a nagy erőforrásokat igénylő nyelvek nagy teljesítményét érték el, az alacsony erőforrásokat igénylő nyelvek teljesítménye lemarad. Ebben a tanulmányban az alacsony erőforrású fríz nyelv elemzésére összpontosítunk. Kódkapcsolt, spontán beszélt adatokból álló mintát használunk, ami kihívást jelent. Javasoljuk, hogy egy speciálisan a céltartományra szabott elemzőt képezzünk, több fabank példányát választva. Konkrétan a Latent Dirichlet Allocation (LDA) szót és karaktert használjuk N-grammokkal. Egy mély biaffin elemzőt használunk, amelyet mBERT-vel inicializálunk. A legjobb egyforrású treebank (nl_alpino) 54,7 LAS értéket eredményezett, míg az adatválasztásunk meghaladta az egyetlen legjobb transzfer treebank értékét és 55,6 LAS értéket eredményezett a teszt adataiban. További kísérletek a diakritikusok eltávolítása a fríz adatokból, több hasonló edzési adat létrehozása a mondatok kivágásával és a legjobb modellünk XLM-R használatával történt. Ezek a kísérletek nem eredményeztek jobb teljesítményt.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Մինչդեռ բարձր արտադրողականությունը հասել է բարձր ռեսուրսների լեզուների համար, ցածր ռեսուրսների լեզուների արտադրողականությունը հետաքրքիր է: Այս թղթի մեջ մենք կենտրոնանում ենք ցածր ռեսուրսների լեզվի վերլուծության վրա: Մենք օգտագործում ենք կոդի փոխակերպված, ինքնաբուխ խոսվող տվյալների նմուշ, որը պարզվում է դժվար կառուցվածք է: Մենք առաջարկում ենք դասակարգչի ուսուցանումը, որն առանձնահատուկ է նպատակային բնագավառի ուղղությամբ, ընտրելով բազմաթիվ ծառերից ստացված օրինակներ: Մասնավորապես, մենք օգտագործում ենք Վերջին դիրիկլետի (ԼԴԱ) բառերի և N-գրամանների հետ: Մենք օգտագործում ենք mBER-ի միջոցով հիմնված խորը բիաֆինի վերլուծողը: Ամենալավ մեկ աղբյուրի ծառի հիմքը (nl_AlPino) հանգեցրեց 54.7-ի LAS-ին, մինչդեռ մեր տվյալների ընտրությունը գերազանցեց ամենալավ փոխանցման ծառի հիմքը և հանգեցրեց 55.6 LAS-ին փորձարկման տվյալների վրա: Ավելի փորձարկումներ կազմակերպեցին մեր ֆրիզիացի տվյալներից դիաքնրիկներին հեռացնելը, ավելի նմանատիպ ուսուցման տվյալներ ստեղծելով վերբերյալ նախադասությունները և մեր լավագույն մոդելը XLM-R օգտագործելով: Այս փորձարկումները ավելի լավ արդ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Sementara prestasi tinggi telah diperoleh untuk bahasa sumber daya tinggi, prestasi bahasa sumber daya rendah tertinggal. Dalam kertas ini kita fokus pada penghuraian bahasa Frisian sumber daya rendah. We use a sample of code-switched, spontaneously spoken data, which proves to be a challenging setup. Kami mengusulkan untuk melatih parser khusus disesuaikan menuju domain sasaran, dengan memilih contoh dari beberapa batang pohon. Secara spesifik, kita menggunakan Allokasi Latent Dirichlet (LDA), dengan kata dan karakter N-gram. Kami menggunakan parser biaffin dalam yang diinisialisasikan dengan mBERT. Pangkalan pohon sumber tunggal terbaik (nl_alpino) menghasilkan LAS 54,7 sementara pemilihan data kami melebihi panggkalan pohon transfer terbaik tunggal dan membawa ke 55,6 LAS pada data tes. Eksperimen tambahan terdiri dari menghapus diakritik dari data Frisian kami, menciptakan data pelatihan yang lebih mirip dengan menambah kalimat dan menjalankan model terbaik kami menggunakan XLM-R. Eksperimen ini tidak menyebabkan prestasi yang lebih baik.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mentre le prestazioni elevate sono state ottenute per i linguaggi ad alto contenuto di risorse, le prestazioni sui linguaggi a basso contenuto di risorse rimangono indietro. In questo articolo ci concentriamo sull'analisi della lingua frisone a basso contenuto di risorse. Usiamo un campione di dati a commutazione di codice, parlati spontaneamente, che si rivela un setup impegnativo. Proponiamo di addestrare un parser su misura per il dominio di destinazione, selezionando istanze da più treebank. Nello specifico, utilizziamo Latent Dirichlet Allocation (LDA), con parole e caratteri N-grammi. Usiamo un analizzatore di biaffine profondo inizializzato con mBERT. Il miglior treebank single source (nl_alpino) ha portato a un LAS di 54,7 mentre la nostra selezione di dati ha superato il singolo treebank di trasferimento migliore e ha portato a 55,6 LAS sui dati di test. Ulteriori esperimenti consistevano nel rimuovere i diacritici dai nostri dati frisiani, creare dati di allenamento più simili ritagliando frasi ed eseguendo il nostro modello migliore utilizzando XLM-R. Questi esperimenti non hanno portato a prestazioni migliori.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>高リソース言語では高いパフォーマンスが得られていますが、低リソース言語ではパフォーマンスが遅れています。本稿では、低資源言語フリジア語の構文解析に焦点を当てる。私たちはコードスイッチされた自発的に話されたデータのサンプルを使用しています。これは難しいセットアップであることが証明されています。複数のツリーバンクからインスタンスを選択して、ターゲットドメインに特化したパーサーをトレーニングすることを提案します。具体的には、単語と文字Nグラムを含むLatent Dirichlet Allocation (LDA)を使用します。mBERTで初期化されたディープビアフィン構文解析器を使用します。最高の単一ソースツリーバンク（ nl_alpino ）は、54.7のLASをもたらしましたが、当社のデータ選択は、単一の最高の転送ツリーバンクを上回り、テストデータの55.6 LASにつながりました。追加の実験では、フリジアのデータからダイアクリティックを削除し、文章をトリミングしてより類似したトレーニングデータを作成し、XLM - Rを使用してベストモデルを実行しました。これらの実験は、より良いパフォーマンスにはつながりませんでした。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ssoffpolite"), and when there is a change ("assertive Nang pepul iki, kita dipunduh langkung urip nggambar kelas Jejaran Awak dhéwé nggunakake sampler kanggo kode bisa-bisa dadi, dadi mesthi o nggambar barang seneng pisan. We proposal to vlan a PASSMENDAR PASSMENDAR PASSMENDAR IGNOPAL PASSMENDAR olar" is the abbreviation for "Line", Col is the abbreviation for "Column Two Label Ndheke supaya karo hal-hal sing ngrusak diakritik tentang ning awak dhéwé dolanan ping dolanan, nggawe data sing luwih nggawe dolanan nggawe kesempatan kanggo ngwala macem nggawe model sing luwih nggambar XLM-R. Perintah sing iki dadi sing bisa pasar awak dhéwé.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>მაგრამ უფრო დიდი რესურსის ენათებისთვის მიღებულია, მაგრამ მარტივი რესურსის ენათებისთვის გამოსახულება. ამ დოკუნტში ჩვენ ფრისიანი ქვემოთ რესურსის ენის პანსუზაციაზე დავყენებთ. ჩვენ გამოყენებთ კოდის შეცვლა, სონტანოდ საუბრილო მონაცემების მონაცემების გამოყენება, რომელიც გამოწყენება შესაძლებელი მონაცემები. ჩვენ გვეძლევა განსხვავება პანსერტის განსაკუთრებით განსხვავებული მისაღების დიომინზე, რამდენიმე საბრძანების განსხვავებით. განსაკუთრებით, ჩვენ შევყენებთ Latent Dirichlet Allocation (LDA) სიტყვებით და სიტყვებით N- გრამით. ჩვენ გამოყენებთ ძალიან ბიფინის პანელერი, რომელიც mBERT-ით инициаლიზებულია. ყველაზე საუკეთესო მხოლოდ ერთი მხოლოდ საბეჭდო (nl_alpino) დაიწყება 54.7-ის LAS-ში, თუმცა ჩვენი მონაცემები მონიშნული მონაცემები ერთი საუკეთესო საბეჭდო საბეჭდო და დამატებული ექსპერიმენტები იყო დიაკრიტიკური ჩვენი ფრისიანი მონაცემების წაშლადან, უფრო სხვადასხვა მონაცემების შექმნა და XLM-R გამოყენებით ჩვენი უკეთესი მოდელს. ეს ექსპერიმე</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ресурстардың жоғары тілдері үшін жоғары істеу керек болғанда, төмен ресурс тілдерінің істеу керек. Бұл қағазда Фризияндың төмен ресурстар тілін талдау үшін көздейміз. Біз код ауыстырылған, автоматты түрде сөйлейтін деректер үлгісін қолданамыз. Бұл қиын баптау деген сияқты. Біз бірнеше орындағы мәліметтерді таңдап, мақсатты доменге өзгертілген талдаушы оқытуды ұсынамыз. Сонымен қатар, біз "Latent Dirichlet Allocation" (LDA) сөз мен N- граммалар таңбалармен қолданамыз. МБЕРТ арқылы инициализацияланған үлкен биафин талдаушысын қолданамыз. Ең жақсы жалпы көздегі требанды (nl_ alpino) 54. 7 тізімінің LAS болды, бірақ деректерді таңдағанда бір ең жақсы транспорттау требанды жасап, сынақ деректерінде 55. 6 LAS болды. Қосымша тәжірибелер біздің Фрис деректерімізден диаткритикаларды алып тастау, сөздерді қиып, XLM-R арқылы ең жақсы моделімізді орындау арқылы ұқсас оқыту деректерін құрып жатқан. Бұл тәжір</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>고자원 언어는 이미 고성능을 얻었지만 저자원 언어의 성능은 뒤떨어졌다.본고는 주로 저자원 언어인 프리시안의 문법 분석을 연구한다.우리는 코드 전환, 자발적으로 나온 데이터 샘플을 사용했는데 이것은 도전적인 설정임을 증명한다.여러 개의 트리 라이브러리에서 실례를 선택해서 목표 영역에 대한 맞춤형 해상도를 훈련하는 것을 권장합니다.구체적으로 말하면, 우리는 잠재적인 디릭레 분배 (LDA) 와 단어와 문자의 N-gram을 사용한다.우리는 mBERT로 초기화된 심비아핀 해상도를 사용합니다.최적 단원 트리 라이브러리(nl alpino)의 LAS는 54.7이고 우리의 데이터 선택은 단일 최적 이동 트리 라이브러리보다 우수하며 테스트 데이터의 LAS는 55.6이다.다른 실험으로는 프리스식 데이터에서 변음 기호를 삭제하고 문장을 재단하여 비슷한 훈련 데이터를 만들고 XLM-R로 우리의 가장 좋은 모델을 실행하는 것이 포함된다. 이 실험들은 더 좋은 성능을 가져오지 못했다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nors daug išteklių turinčių kalbų rezultatų pasiekta, mažai išteklių turinčių kalbų rezultatai atsilieka. Šiame dokumente daugiausia dėmesio skiriame mažai išteklių turinčios friziškos kalbos analizei. We use a sample of code-switched, spontaneously spoken data, which proves to be a challenging setup. Siūlome apmokyti analizatorių, specialiai pritaikytą tikslinei sričiai, pasirinkdami atvejus iš kelių medžių. Konkrečiai mes naudojame Latent Dirichlet Allocation (LDA) su žodžiu ir simboliu N-gramais. Naudojame gilią biffino analizatorių, inicijuotą mBERT. Geriausias vieno šaltinio medžio pagrindas (nl_alpino) lėmė 54,7 LAS, o mūsų duomenų atranka viršijo vieną geriausią perdavimo pagrindą ir 55,6 LAS bandymų duomenimis. Papildomi eksperimentai buvo diakritikų pašalinimas iš mūsų frizijos duomenų, panašių mokymo duomenų sukūrimas paspaudžiant sakinius ir naudojant XLM-R naudojamą geriausią model į. Šie eksperimentai nesukėlė geresnių rezultatų.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>И покрај тоа што се постигнати високи резултати за јазиците со високи ресурси, резултатите на јазиците со ниски ресурси се задржуваат. Во овој весник се фокусираме на анализирањето на фризискиот јазик со ниски ресурси. Користиме примерок на спонтано зборувани податоци кои се покажуваат како предизвикувачки поставување. Предлагаме да обучуваме анализатор специфично приспособен кон доменот на метата, со избор на примери од повеќе дрвја. Specifically, we use Latent Dirichlet Allocation (LDA), with word and character N-grams. Ние користиме длабок биафински анализатор иницијализиран со mBERT. Најдобрата група на дрвја од еден извор (nl_alpino) резултираше со LAS од 54,7 додека нашиот избор на податоци ја надмина најдобрата група на дрвја од трансфер и доведе до 55,6 LAS на тестовите податоци. Дополнителни експерименти се состојуваа од отстранувањето на дијакритичарите од нашите фризиски податоци, создавање на послични податоци за обука со собирање реченици и управување со нашиот најдобар модел користејќи XLM-R. Овие експерименти не доведоа до подобра резултат</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ഉയര്‍ന്ന വിഭവങ്ങളുടെ ഭാഷകള്‍ക്ക് ഉയര്‍ന്ന പ്രദര്‍ശനം ലഭിച്ചിരിക്കുമ്പോള്‍, കുറഞ്ഞ വിഭവഭാഷകളില്‍ പ്രകടനം ഈ പത്രത്തില്‍ ഞങ്ങള്‍ കുറഞ്ഞ വിഭവങ്ങളുടെ ഭാഷ ഫ്രിസ്യന്‍ പാര്‍ജിങ്ങിനെ ശ്രദ്ധിക്കുന്നു. നമ്മള്‍ ഒരു കോഡ് മാറ്റിയിട്ടുണ്ട്, സ്വയമായി സംസാരിക്കുന്ന ഡേറ്റാ ഉപയോഗിക്കുന്നു. അത് ഒരു വിലാല്‍ക്കാലി നമ്മള്‍ ഒരു പരിശീലിപ്പിക്കാന്‍ പ്രത്യേകിച്ച് ലക്ഷ്യത്തിലേക്ക് പ്രത്യേകിച്ച് ടോമെയിനിലേക്ക് തിരഞ്ഞെടുക്ക പ്രത്യേകിച്ച്, നമ്മള്‍ ലാറ്റെന്റ് ഡിറിച്ചില്ലെറ്റ് ഒലോക്ഷന്‍ (LDA) ഉപയോഗിക്കുന്നു. വാക്കും അക്ഷരങ്ങളും N- നമ്മള്‍ ഒരു ആഴമുള്ള ബീഫിന്‍ പരാജയപ്രകാരം ഉപയോഗിക്കുന്നു. The best single source treebank (nl_alpino) resulted in an LAS of 54.7 whereas our data selection outperformed the single best transfer treebank and led to 55.6 LAS on the test data. കൂടുതല്‍ പരീക്ഷണങ്ങള്‍ നമ്മുടെ ഫ്രിസ്യന്‍ വിവരങ്ങളില്‍ നിന്ന് ഡയറിക്രിക്കുന്നവരെ നീക്കം ചെയ്യുന്നതിനായിരുന്നു. വിവരങ്ങള്‍ വാങ്ങുന്നതിനാല്‍ കൂ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Хэдийгээр өндөр боловсролын хэл дээр ажиллагаа гаргасан ч, бага боловсролын хэл дээр ажиллагаа үлдсэн. Энэ цаасан дээр бид Фризийн бага боловсролын хэлний талаар анхаарлаа хандуулдаг. Бид кодыг өөрчлөгдсөн, сэтгэл хөдлөл өгөгдлийн жишээ хэрэглэдэг. Энэ нь хэцүү байдал юм. Бид хэд хэдэн загваруудын жишээг сонгож зорилготой зорилготой зорилготой хэлбэрээр хуваарч сургуульд сургуульд сургаж байна. Ялангуяа бид Latent Dirichlet Allocation (LDA), N-граммын үг болон дүрсийг ашиглаж байна. Бид mBERT-тай эхлэгдсэн гүн гүнзгий биефин хуваагч ашиглаж байна. Хамгийн шилдэг эх үүсвэрийн загвар (nl_alpino) нь 54.7-ын ЛАС болсон юм. Гэхдээ бидний мэдээллийн сонголт нь хамгийн сайн шилдэг шилжүүлэлтийн загварыг дамжуулж, шалгалтын өгөгдлийн талаар 55.6 ЛАС болсон юм. Тэгээд нэмэлт туршилтууд бидний Фризийн өгөгдлийн хувьд илүү төстэй суралцах өгөгдлийг бүтээж, XLM-R-г ашиглан бидний хамгийн сайн загварын загварыг ашиглаж байдаг.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Sementara prestasi tinggi telah dicapai untuk bahasa sumber tinggi, prestasi bahasa sumber rendah tertinggal. Dalam kertas ini kita fokus pada penghuraian bahasa Frisian sumber rendah. Kami menggunakan sampel data yang ditukar-kod, yang bercakap secara spontan, yang membuktikan menjadi seting yang mencabar. Kami cadangkan untuk melatih penghurai yang disesuaikan secara khusus ke arah domain sasaran, dengan memilih contoh dari garis pokok berbilang. Secara khusus, kita gunakan Allocation Latent Dirichlet (LDA), dengan perkataan dan aksara N-gram. Kami menggunakan penghurai biaffin yang diawalkan dengan mBERT. Pangkalan pokok sumber tunggal terbaik (nl_alpino) menghasilkan LAS 54.7 semasa pemilihan data kita melebihi pangkalan pokok pemindahan tunggal terbaik dan membawa ke 55.6 LAS pada data ujian. Eksperimen tambahan terdiri daripada membuang diakritik dari data Frisian kami, mencipta data latihan yang lebih serupa dengan menguap kalimat dan menjalankan model terbaik kami menggunakan XLM-R. Eksperimen ini tidak membawa kepada prestasi yang lebih baik.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Filwaqt li nkisbu prestazzjoni għolja għal lingwi b’riżorsi għoljin, il-prestazzjoni fuq lingwi b’riżorsi baxxi għadha lura. F’dan id-dokument niffokaw fuq l-analiżi tal-lingwa friża b’riżorsi baxxi. Aħna nużaw kampjun ta’ dejta mibdula bil-kodiċi, li titkellem b’mod spontanju, li turi li hija struttura ta’ sfida. Aħna nipproponu li nħarrġu analizzatur imfassal speċifikament lejn id-dominju fil-mira, billi nagħżlu każijiet minn għelieqi multipli tas-siġar. Speċifikament, aħna nużaw l-Allokazzjoni Latent Dirichlet (LDA), bil-kelma u l-karattru N-grammi. Aħna nużaw parser tal-biffina fond inizjalizzat b’mBERT. L-aħjar bank tas-siġar tas-sors uniku (nl_alpino) irriżulta f’LAS ta’ 54.7 filwaqt li l-għażla tad-dejta tagħna qabżet l-aħjar bank tas-siġar tat-trasferiment uniku u wasslet għal 55.6 LAS fuq id-dejta tat-test. Esperimenti addizzjonali kienu jikkonsistu fit-tneħħija tad-dijakritiċi mid-dejta Franċiża tagħna, il-ħolqien ta’ dejta ta’ taħriġ aktar simili permezz tas-sentenzi tal-għelejjel u t-tħaddim tal-a ħjar mudell tagħna bl-użu ta’ XLM-R. Dawn l-esperimenti ma wasslux għal prestazzjoni aħjar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Hoewel er hoge prestaties zijn behaald voor talen met veel resources, blijven de prestaties op talen met weinig resources achter. In dit artikel richten we ons op het parsen van de low-resource taal Fries. We gebruiken een voorbeeld van code-switched, spontaan gesproken data, wat een uitdagende opstelling blijkt te zijn. We stellen voor om een parser te trainen die specifiek is afgestemd op het doeldomein, door instances uit meerdere boombanken te selecteren. Specifiek gebruiken we Latent Dirichlet Allocation (LDA), met woord en teken N-grammen. We gebruiken een diepe biaffine parser geïnitialiseerd met mBERT. De beste single source boombank (nl_alpino) resulteerde in een LAS van 54.7 terwijl onze dataselectie de beste transferboombank overtrof en leidde tot 55.6 LAS op de testdata. Aanvullende experimenten bestonden uit het verwijderen van diacritici uit onze Friese data, het creëren van meer vergelijkbare trainingsdata door zinnen bij te snijden en het uitvoeren van ons beste model met XLM-R. Deze experimenten leidden niet tot een betere prestatie.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mens høg utviklinga er fått for høg ressursspråk, vil utviklinga på låg ressursspråk gå bak. I denne papiret fokuserer vi på tolking av den låg ressursspråket Frisian. Vi bruker eit prøve av kodbytt, spontane snakket data, som viser å vera eit vanskeleg oppsett. Vi foreslår å trena ei tolkar spesifikke tilpassa mot måldområdet ved å velja instansar frå fleire treebankar. Spesielt bruker vi Latent Dirichlet Allocation (LDA) med ord og teikn N- gramar. Vi bruker ein dyp biaffin- tolkar som er starta med mBERT. Den beste enkelte kjeldetrebanen (nl_alpino) resulterte i ein LAS med 54,7 mens datautvalet vårt utførte den enkelte beste overføringsbanken og førte til 55,6 LAS på test data. Ekstra eksperimenter best år av å fjerna diakritikk frå våre Frisiske data, oppretta meir liknande treningsdata ved å beskjera setningar og køyra våre beste modellen med XLM-R. Desse eksperimentene førte ikkje til ein bedre utvikling.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Podczas gdy uzyskano wysoką wydajność języków o wysokim zasobie, wydajność języków o niskim zasobie pozostaje w tyle. W niniejszym artykule skupiamy się na parsowaniu niskich zasobów języka fryzyjskiego. Wykorzystujemy próbkę przełączonych kodem, spontanicznie mówionych danych, co okazuje się trudną konfiguracją. Proponujemy szkolenie parsera specjalnie dopasowanego do domeny docelowej, wybierając instancje z wielu bank drzew. W szczególności używamy Latent Dirichlet Allocation (LDA), z N-gramami słowa i znaków. Używamy głębokiego parsera biafiny zainicjowanego mBERT. Najlepszy pojedynczy źródłowy bank drzew (nl_alpino) zaowocował LAS 54.7, podczas gdy nasz wybór danych przewyższył pojedynczy najlepszy bank drzew transferowych i doprowadził do 55.6 LAS na danych testowych. Dodatkowe eksperymenty polegały na usunięciu diakrytyki z naszych danych fryzyjskich, tworzeniu bardziej podobnych danych treningowych poprzez przycinanie zdań i uruchomieniu najlepszego modelu przy użyciu XLM-R. Eksperymenty te nie doprowadziły do lepszej wydajności.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Embora o alto desempenho tenha sido obtido para linguagens de alto recurso, o desempenho em linguagens de baixo recurso fica para trás. Neste artigo, focamos na análise da linguagem de poucos recursos Frisian. Usamos uma amostra de dados comutados por código e falados espontaneamente, o que prova ser uma configuração desafiadora. Propomos treinar um analisador específico para o domínio de destino, selecionando instâncias de vários bancos de árvores. Especificamente, usamos a Alocação de Dirichlet Latente (LDA), com N-grams de palavras e caracteres. Usamos um analisador biaffine profundo inicializado com mBERT. O melhor banco de árvore de fonte única (nl_alpino) resultou em um LAS de 54,7, enquanto nossa seleção de dados superou o melhor banco de árvore de transferência e levou a 55,6 LAS nos dados de teste. Experimentos adicionais consistiram em remover diacríticos de nossos dados frísios, criando dados de treinamento mais semelhantes cortando frases e executando nosso melhor modelo usando XLM-R. Esses experimentos não levaram a um melhor desempenho.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>În timp ce au fost obținute performanțe ridicate pentru limbile cu resurse ridicate, performanța pe limbile cu resurse reduse rămâne în urmă. În această lucrare ne concentrăm pe analizarea limbii frisone cu resurse reduse. Folosim un eșantion de date cu comutare de cod, vorbite spontan, ceea ce se dovedește a fi o configurație dificilă. Vă propunem să instruiți un parser special adaptat domeniului țintă, prin selectarea instanțelor din mai multe brake-uri. Mai exact, folosim Latent Dirichlet Allocation (LDA), cu cuvinte și caractere N-grame. Folosim un parser de biafine profund initializat cu mBERT. Cel mai bun treebank single source (nl_alpino) a rezultat într-un LAS de 54,7 în timp ce selecția noastră de date a depășit cel mai bun transfer treebank unic și a dus la 55,6 LAS pe datele de testare. Experimentele suplimentare au constat în eliminarea diacritică din datele noastre frisone, crearea mai multor date de antrenament similare prin decuparea frazelor și rularea celui mai bun model al nostru folosind XLM-R. Aceste experimente nu au dus la o performanță mai bună.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Несмотря на то, что высокая производительность была достигнута для языков с большими ресурсами, производительность для языков с ограниченными ресурсами отстает. В этой статье мы сосредоточимся на разборе малоресурсного фризского языка. Мы используем выборку спонтанно произнесенных данных с переключением кода, которая оказывается сложной установкой. Мы предлагаем обучить парсер, специально адаптированный к целевому домену, путем выбора экземпляров из нескольких древовидных блоков. В частности, мы используем Latent Dirichlet Allocation (LDA) с N-граммами слов и символов. Мы используем глубокий биаффиновый парсер, инициализированный с помощью mBERT. Лучший банк деревьев с одним источником (nl_alpino) показал LAS 54,7, в то время как наш выбор данных превзошел лучший банк деревьев трансфера и привел к 55,6 LAS по тестовым данным. Дополнительные эксперименты состояли из удаления диакритических знаков из наших фризских данных, создания более похожих обучающих данных путем обрезки предложений и запуска нашей лучшей модели с использованием XLM-R. Эти эксперименты не привели к лучшей производительности.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>උත්සන්ධ භාෂාව සඳහා උත්සන්ධ භාෂාව ලැබෙනවා නමුත්, අඩුම භාෂා භාෂාව අඩුම භාෂාව පි මේ පත්තරේ අපි ප්‍රශ්න භාෂාව අඩු ප්‍රශ්න භාෂාව විශ්වාස කරනවා. අපි කෝඩ් ස්විච්ච් කරපු නිර්මාණයක් පාවිච්චි කරනවා, ස්වයංගයෙන් කතා කරපු දත්ත, ඒක ප්‍රශ්න විශා අපි සැකසුම් කරනවා විශේෂයෙන් විශේෂයෙන් ලක්ෂණ ඩෝමින් වලට පරීක්ෂණය කරන්න, විශේෂයෙන් විශේෂයෙන් ස විශේෂයෙන්ම, අපි ලෙට්ට් ඩිරිච්ලෙට් අන්තිමාණය (LDA) පාවිච්චි කරනවා, N- ග්‍රාම්ස් වචන සහ අක්ෂර අපි ම්බෙර්ට් එක්ක පටන් ගත්ත ගොඩක් බියාෆින් විශේෂකයක් භාවිත කරනවා. හොඳම ප්‍රමාණයක් ත්‍රීබැන්ක් (nl_alpino) පරීක්ෂණ දත්තේ ලැස් 54.7 වලින් පරීක්ෂණය කරලා තියෙනවා නමුත් අපේ දත්ත තෝරණය පරීක්ෂණය කරන එකම හොඳම අතර පරීක්ෂණය සම්පූර්ණයෙන් අපේ ප්‍රිසියාන් දත්තෙන් පිළිගන්න බැරි විදිහට පරීක්ෂණ දත්ත සිද්ධ වුණා, ප්‍රශ්ණ දත්ත සිද්ධ ව</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Medtem ko je bila dosežena visoka zmogljivost jezikov z visokimi viri, zmogljivost jezikov z nizkimi viri zaostaja. V tem prispevku se osredotočamo na razčlenitev jezika z nizkimi viri frizijščine. Uporabljamo vzorec spontano govorjenih podatkov, ki se izkažejo za zahtevno nastavitev. Predlagamo usposabljanje razčlenjevalnika, ki je posebej prilagojen ciljni domeni, z izbiro primerkov iz več drevesnih zbirk. Natančneje uporabljamo Latent Dirichlet Allocation (LDA), z besedami in znaki N-grami. Uporabljamo globok biafin razčlenjevalec inicializiran z mBERT. Najboljša enovirna drevesna plošča (nl_alpino) je imela LAS 54,7, medtem ko je naša izbira podatkov presegla najboljšo prenosno drevesno ploščo in privedla do 55,6 LAS na testnih podatkih. Dodatni eksperimenti so vključevali odstranitev diakritikov iz frizijskih podatkov, ustvarjanje podobnih podatkov o treningu z obrezovanjem stavkov in izvajanje našega najboljšega modela z uporabo XLM-R. Ti eksperimenti niso privedli do boljše zmogljivosti.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Inta lagu helo muuqasho dheer oo luuqadaha sare ee luqadaha hoose ee rasmiga ah, waxyaabaha lagu sameeyo waxaa dib looga dhigaa. Warqadan waxaynu ku fiirsanaynaa baarlamaanka luqada Finnishka ee hoose. Waxaynu isticmaalnaa sameynta codsiga, oo si rasmi ah looga hadlo, taasoo caddaynaya inay tahay hab adag. Waxaynu soo jeedaynaa in aan ku tababarinno lambarada si gaar ah loogu talagalay guriga goalka, si aan u dooranno tusaalooyin kala duduwan qoraalka. Si gaar ah, waxaynu ugu isticmaalnaa Latent Dirichlet Allocation (LDA), hadal iyo xaraf N-gram. Waxaynu isticmaalnaa baaritaanka mool dheer oo lagu billaabiyey mBERT. Tan ugu wanaagsanayd treebank (nl_alpino) waxay sababtay LAS oo ka mid ah 54.7, iyadoo doorashadeedii macluumaadkayagu ay sameyn jireenka ugu wanaagsan ee treebank waxaana u keenay 55.6 LAS oo ku saabsan data imtixaanka. Imtixaanka dheeraadka ah waxaa ka mid ah dhaqdhaqaalaha macluumaadkayaga Frisian, waxayna sameyn jirrabaadyo la mid ah oo ka mid ah xafiiska beeraha iyo dhaqdhaqaalaha sameynta modelkeena ugu wanaagsan ee isticmaalaya XLM-R. Imtixaankaas ma uu sababin wax ka wanaagsan.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ndërsa paraqitja e lartë është arritur për gjuhët me burime të larta, paraqitja në gjuhët me burime të ulta mbetet prapa. Në këtë letër ne përqëndrohemi në analizimin e gjuhës me burime të ulëta friziane. We use a sample of code-switched, spontaneously spoken data, which proves to be a challenging setup. Ne propozojmë të trajnojmë një analizues specifikisht të përshtatur drejt domenisë objektive, duke zgjedhur raste nga vende të shumta pemësh. Specifically, we use Latent Dirichlet Allocation (LDA), with word and character N-grams. Ne përdorim një analizues biffine të thellë të inicializuar me mBERT. Banka më e mirë e një burimi (nl_alpino) rezultoi në një LAS 54.7 ndërsa zgjedhja jonë e të dhënave kaloi bankën më të mirë të transferimit dhe çoi në 55.6 LAS në të dhënat e testit. Eksperimente shtesë përbënin heqjen e diakritikëve nga të dhënat tona friziane, krijimin e të dhënave më të ngjashme të trajnimit duke mbledhur fjalë dhe duke drejtuar modelin tonë më të mirë duke përdorur XLM-R. Këto eksperimente nuk shpien në një performancë më të mirë.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Iako su dobili visoke funkcije za jezike visokog resursa, nastup na jezicima niskog resursa ostaje iza sebe. U ovom papiru fokusiramo se na analizu jezika niskog resursa Frisiana. Koristimo uzorak zamjene šifre, spontano govorenih podataka, koji dokazuje da je izazovna postavka. Predlažemo da treniramo analizatora posebno prilagođenog prema ciljnom domenu, birajući instance iz višestrukih treebana. Posebno, koristimo Latent Dirichlet Allocation (LDA), sa rijeèima i karakterom N-grama. Koristimo duboki analizator biafina inicijalizovan sa mBERT-om. Najbolji jedinstveni izvor treeban (nl_alpino) rezultirao je LAS od 54,7, dok je naš izbor podataka izneo jedinstveni najbolji treeban i doveo do 55,6 LAS na test podataka. Dodatni eksperimenti su sastavljeni od uklanjanja diakritika iz naših Frisijskih podataka, stvaranja sličnih podataka za obuku usvajajući rečenice i vodeći naš najbolji model koristeći XLM-R. Ovi eksperimenti nisu doveli do boljih izvođenja.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Även om hög prestanda har uppnåtts för språk med hög resurs släpar prestandan på språk med låg resurs efter. I denna uppsats fokuserar vi på tolkningen av lågresursspråket frisiska. Vi använder ett urval av kodväxlade, spontant talade data, vilket visar sig vara en utmanande installation. Vi föreslår att träna en parser specifikt anpassad för måldomänen, genom att välja instanser från flera trädbanker. Specifikt använder vi Latent Dirichlet Allocation (LDA), med ord och tecken N-gram. Vi använder en djup biaffin parser initierad med mBERT. Den bästa singel source treebank (nl_alpino) resulterade i en LAS på 54,7 medan vårt dataval överträffade singel best transfer treebank och ledde till 55,6 LAS på testdata. Ytterligare experiment bestod av att ta bort diakritiker från våra frisiska data, skapa mer liknande träningsdata genom att beskära meningar och köra vår bästa modell med XLM-R. Dessa experiment ledde inte till en bättre prestanda.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Wakati mafanikio makubwa yamekuwa yakipatikana kwa lugha za rasilimali za juu, utendaji wa lugha za rasilimali zilizobaki. Katika karatasi hii tunajikita kwenye kuimba lugha ya KiFrisia yenye rasilimali duni. Tunatumia mifano ya kubadilishwa kwa kodi, taarifa zinazozungumzwa kwa wenyewe, ambayo inaonyesha kuwa ni seti ya changamoto. Tunazipendekeza kuwafundisha mchambuzi hasa unaoongozwa kuelekea eneo la lengo, kwa kuchagua matukio kutoka kwenye viwanja vingi vya mitatu. Kwa ujumla, tunatumia Umoja wa Kusini wa Dirichlet (LDA), kwa maneno na tabia ya N-grams. Tunatumia mchambuzi wa kina wa biaffine ulioanzishwa na mBERT. Chanzo bora zaidi cha treebank (nl_alpino) kilisababisha LAS ya 54.7 wakati uchaguzi wetu wa takwimu ulifanya usafirishaji bora zaidi wa mitebank na ulipelekea LAS 55.6 kwenye takwimu za jaribio. Majaribio mengine yalikuwa ni pamoja na kuondoa wagonjwa kutoka kwenye takwimu zetu za KiFrisia, kutengeneza takwimu za mafunzo kama hizo kwa kutengeneza mifano yetu bora kwa kutumia XLM-R.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>அதிக மூலத்தின் மொழிகளுக்கான அதிக செயல்பாடு பெற்றது இந்த காகிதத்தில் நாம் குறைந்த மூலத்தின் பாக்கியத்தை கவனம் செலுத்துகிறோம். We use a sample of code-switched, spontaneously spoken data, which proves to be a challenging setup. இலக்கு களத்திற்கு குறிப்பிட்ட ஒரு பொருளை பயிற்சி செய்ய நாம் பரிந்துரைக்கிறோம், பல மூன்று கோடுகளில் இருந்து ந குறிப்பிட்டால், நாம் சொல்லும் எழுத்தும் N- கிராமுடன் அலங்காரத்தை பயன்படுத்துகிறோம். MBERT உடன் துவக்கப்பட்ட ஒரு ஆழமான பியாபின் பகுதியை பயன்படுத்துகிறோம். சிறந்த ஒற்றை மூலம் treebank (nl_ alpino) 54. 7 ல் ஒரு LAS வெளியேற்றினார். ஆனால் எங்கள் தரவு தேர்வு சிறந்த ஒற்றை மாற்று treebank செய்து சோதனை தரவில் 55. 6 LAS ஆக்க கூடுதல் சோதனைகள் எங்கள் ஃப்ரிசியன் தரவிலிருந்து டையாக்ரியன்களை நீக்குதல் இருந்தது, விளைச்சுட்டு வாக்கியங்களை உருவாக்கி எக்ஸ்எல்எம்- R பயன்படுத்</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Yüksek ressurs dilleri üçin ýokary ukyp edildi, iň-çeşme dilleriniň yzynda täsirler bar. Bu kagyzda biz Frisiýanyň iň köp ukyp dilini çözmek üçin üns berýäris. Biz köd üýtgedilmiş, spontaz gepleşilen maglumatyň örnekini ulanýarys. Bu kynçylyk düzümlenmesi üçin kanıtlaýar. Biz birden çoklu çubuktan örnekler seçmek üzere özellikle hedef domenya geçirilen bir ayıran öwrenmesini teklif ediyoruz. Adatça, biz Later Dirichlet Allocation (LDA), söz we karakter N-gramler bilen ullanyrys Biz mBERT bilen başlanýan bir çukur biafin çözümlerini ulanýarys. Iň gowy bir çeşme gatlaky (nl_alpino) 54.7 ýagdaýynda LAS sebäpli boldy. Maglumat saýlawymyz ýeke iň gowy gatlaky gatlakyny üstün etdi we testiň maglumatynda 55.6 LAS giddi. Ekstra deneyler Frisiýa maglumatlarymyzdan diakritikalary çykarmak bolupdyr, sözlerimizi kesip we iň gowy nusgasymyzy XLM-R ulanyp daşary çykarmak bilen meňzeşdirdi. Bu deneyler gowy bir hereket etmäge ýok edip bilmedi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>اچھی طرح عمدہ کامپیوتر بالا سروسیس زبانوں کے لئے حاصل کیا گیا ہے، کم سروسیس زبانوں کے پیچھے رہ جاتا ہے. اس کاغذ میں ہم کم سرمایہ کی زبان فریزین کے بارے میں تمرکز کرتے ہیں۔ ہم ایک نمونہ کا استعمال کرتے ہیں کوڈ-سوئٹ، اسپانیٹ سے بول دیے گئے ہیں، جو ایک مشکل سٹاپ ہے۔ ہم ایک پارچر کی ترینس کرنا چاہتے ہیں جو مخصوص طریقے سے موقع ڈومین کی طرف پھیلائی جاتی ہے، بہت سی ٹریب بانک سے موقعیتیں انتخاب کرتی ہیں۔ خاص طور پر، ہم Latent Dirichlet Allocation (LDA) کا استعمال کرتے ہیں، کلمات اور شخصت N-grams کے ساتھ۔ ہم نے mBERT کے ساتھ شروع کی ایک عمیق بیفن پارچر استعمال کیا۔ The best source treebank (nl_alpino) resulted in a LAS of 54.7 whereas our data selection outperformed the single best transfer treebank and led to 55.6 LAS on the test data. اور اضافہ آزمائش کی وجہ سے ہمارے فریس ڈیٹا سے دیاکریکٹی کو ہٹانے کے لئے تھا، کلمات کاٹنے کے ذریعہ اور ہمارے بہترین نمڈل کو XLM-R کے ذریعہ دوڑانے کے ذریعہ زیادہ برابر تربین ڈیٹا بناتے تھے. یہ آزمائش اچھی عمل</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Chunki juda katta manbalar tillari uchun bajarishga ega bo'lganda, kam manbaning tillarida bajarishni bajaradi. In this paper we focus on the parsing of the low-resource language Frisian. Biz avtomatik gapiradigan maʼlumotlardan foydalanamiz. Bu muammolar moslamasi mumkin. Biz bir nechta treeborni tanlash uchun qo'shilgan kompyuterni taʼminlashni talab qilamiz. Koʻrsatilgan, biz Yaqinda ochilgan Dirichlet kompyuterdan (LDA), so'z va belgi N- gram bilan foydalanamiz. Biz mBERT bilan boshlangan juda qiyin biaffin parameterdan foydalanamiz. Eng eng eng eng yaxshi manba treebank (nl_ alpino) 54. 7 yordamida boshqa maʼlumot tanlanganmiz bir eng eng eng eng yaxshi koʻpaytirilgan treebank va sinab maʼlumot bilan 55. 6 LAS ga erishildi. Koʻproq tajribalar Frisiy маълумотларимиздан diakritiklarni olib tashlashdir, bir xil taʼminlov maʼlumotni o'rganish va XLM-R yordamida eng yaxshi modelmizni ishga tushirish mumkin. Bu imtiyozlar yaxshi bajarishga sababdi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Một số hiệu suất cao dành cho các ngôn ngữ giàu có, nhưng khả năng ngôn ngữ ít tài nguyên vẫn chậm trễ. Trong tờ giấy này chúng ta tập trung vào việc phân tích ngôn ngữ trù phú Frisian. Chúng tôi sử dụng một mẫu dữ liệu đã được mã hóa thay đổi, tự động nói ra, một thiết lập đầy thử thách. Chúng tôi đề nghị huấn luyện một phân tách đặc biệt về miền đích, bằng cách chọn các trường hợp từ đa dạng ba bóng. Cụ thể, chúng tôi dùng Latent Dirichhlet Allocation (LDAP), with word and character N-grams. Chúng tôi dùng phân tách cà phê lát được khởi tạo bằng mBERT. The best single source treeback (nl*u alpino) đã dẫn đến một LAS of 45.7 trong khi chúng tôi đã chọn dữ liệu chỉ ra duy nhất một lần truyền giá và dẫn đến 5005.6 LAS trên dữ liệu thí nghiệm. Các thí nghiệm khác bao gồm việc loại bỏ Diacritics khỏi dữ liệu Frisian, tạo ra dữ liệu đào tạo tương tự bằng việc xén câu và chạy mô hình tốt nhất của chúng ta bằng XLM-R. Những thí nghiệm này không mang lại hiệu quả tốt hơn.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>虽高资言性高,而低资源言性后矣。 本文中,专注低资源语弗里斯兰语解析。 吾以代码切换、自发之数示例,此一挑战性之设也。 臣等请择树库实以练专解析器。 具体来说,以潜狄利克雷分(LDA),带单词符N-gram。 一用 mBERT 初始化深双affine解析器。 最佳单源树库(nl_alpino)之LAS为54.7,而吾数择优于传输树库,并致55.6 LAS于测试数据。 其他实验删弗里斯兰数变音符,裁句创练,用XLM-R行最佳。 此实验未有善者也。</span></div></div><dl><dt>Anthology ID:</dt><dd>2021.adaptnlp-1.6</dd><dt>Volume:</dt><dd><a href=/volumes/2021.adaptnlp-1/>Proceedings of the Second Workshop on Domain Adaptation for NLP</a></dd><dt>Month:</dt><dd>April</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Kyiv, Ukraine</dd><dt>Venues:</dt><dd><a href=/venues/adaptnlp/>AdaptNLP</a>
| <a href=/venues/eacl/>EACL</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>50–58</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.adaptnlp-1.6>https://aclanthology.org/2021.adaptnlp-1.6</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">braggaar-van-der-goot-2021-challenges</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Anouck Braggaar and Rob van der Goot. 2021. <a href=https://aclanthology.org/2021.adaptnlp-1.6>Challenges in Annotating and Parsing Spoken, Code-switched, Frisian-Dutch DataFrisian-Dutch Data</a>. In <i>Proceedings of the Second Workshop on Domain Adaptation for NLP</i>, pages 50–58, Kyiv, Ukraine. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2021.adaptnlp-1.6>Challenges in Annotating and Parsing Spoken, Code-switched, Frisian-Dutch DataFrisian-Dutch Data</a> (Braggaar & van der Goot, AdaptNLP 2021)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2021.adaptnlp-1.6.pdf>https://aclanthology.org/2021.adaptnlp-1.6.pdf</a></dd><dt>Code</dt><dd><a href=https://github.com/anouck96/parsingfrisian><i class="fab fa-github"></i>&nbsp;anouck96/parsingfrisian</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2021.adaptnlp-1.6.pdf title="Open PDF of 'Challenges in Annotating and Parsing Spoken, Code-switched, Frisian-Dutch DataFrisian-Dutch Data'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Challenges+in+Annotating+and+Parsing+Spoken%2C+Code-switched%2C+Frisian-Dutch+DataFrisian-Dutch+Data" title="Search for 'Challenges in Annotating and Parsing Spoken, Code-switched, Frisian-Dutch DataFrisian-Dutch Data' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-secondary d-flex flex-wrap justify-content-center" href="https://paperswithcode.com/paper/?acl=2021.adaptnlp-1.6" title="Code for 'Challenges in Annotating and Parsing Spoken, Code-switched, Frisian-Dutch DataFrisian-Dutch Data' on Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-big" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg><span class="pl-sm-2 d-none d-sm-inline">Code</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'Challenges in Annotating and Parsing Spoken, Code-switched, Frisian-Dutch DataFrisian-Dutch Data'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[Challenges in Annotating and Parsing Spoken, Code-switched, Frisian-Dutch DataFrisian-Dutch Data](https://aclanthology.org/2021.adaptnlp-1.6) (Braggaar & van der Goot, AdaptNLP 2021)</p><ul class=mt-2><li><a href=https://aclanthology.org/2021.adaptnlp-1.6>Challenges in Annotating and Parsing Spoken, Code-switched, Frisian-Dutch DataFrisian-Dutch Data</a> (Braggaar & van der Goot, AdaptNLP 2021)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Anouck Braggaar and Rob van der Goot. 2021. <a href=https://aclanthology.org/2021.adaptnlp-1.6>Challenges in Annotating and Parsing Spoken, Code-switched, Frisian-Dutch DataFrisian-Dutch Data</a>. In <i>Proceedings of the Second Workshop on Domain Adaptation for NLP</i>, pages 50–58, Kyiv, Ukraine. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>