<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>GECToR Grammatical Error Correction : Tag, Not RewriteGECToR – Grammatical Error Correction: Tag, Not Rewrite - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="GECToR Grammatical Error Correction : Tag, Not RewriteGECToR – Grammatical Error Correction: Tag, Not Rewrite" name=citation_title><meta content="Kostiantyn Omelianchuk" name=citation_author><meta content="Vitaliy Atrasevych" name=citation_author><meta content="Artem Chernodub" name=citation_author><meta content="Oleksandr Skurzhanskyi" name=citation_author><meta content="Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications" name=citation_conference_title><meta content="2020/7" name=citation_publication_date><meta content="https://aclanthology.org/2020.bea-1.16.pdf" name=citation_pdf_url><meta content="163" name=citation_firstpage><meta content="170" name=citation_lastpage><meta content="10.18653/v1/2020.bea-1.16" name=citation_doi><meta property="og:title" content="GECToR Grammatical Error Correction : Tag, Not RewriteGECToR – Grammatical Error Correction: Tag, Not Rewrite"><meta property="og:image" content="https://aclanthology.org/thumb/2020.bea-1.16.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2020.bea-1.16"><meta property="og:description" content="Kostiantyn Omelianchuk, Vitaliy Atrasevych, Artem Chernodub, Oleksandr Skurzhanskyi. Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications. 2020."><link rel=canonical href=https://aclanthology.org/2020.bea-1.16></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR Grammatical Error Correction : Tag, Not Rewrite<span class=acl-fixed-case>GECT</span>o<span class=acl-fixed-case>R</span> – Grammatical Error Correction: Tag, Not Rewrite</a>
<a id=af_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>Stencils</a>
<a id=am_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>ምስሉን በሌላ ስም አስቀምጥ</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - تصحيح الخطأ النحوي: الوسم وليس إعادة الكتابة</a>
<a id=az_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>Граматическа корекция на грешки: етикет, не пренаписване</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - গ্রামাটিক্যাল ত্রুটি সংশোধন: ট্যাগ, পুনরায় লেখা নয়</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - Grammatical Error Correction: Tag, Not Rewrite</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - Gramatična korekcija greške: etiketa, ne ponovno pisati</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - Correcció d'Errors Gramàtics: Etiqueta, No Reescriure</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>Oprava gramatických chyb GECToR: značka, ne přepsat</a>
<a id=da_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - Grammatisk fejlkorrektion: Tag, Ikke omskrive</a>
<a id=de_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR-Grammatical Error Correction: Tag, Not Rewrite</a>
<a id=el_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>Διόρθωση γραμματικού σφάλματος: ετικέτα, όχι επαναγραφή</a>
<a id=es_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GeCtor — Corrección de errores gramaticales: etiquetar, no reescribir</a>
<a id=et_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - grammatiline vigade parandamine: silt, mitte ümber kirjutada</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - اصلاح خطای Grammatical: Tag, not Rewrite</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - Kielioppinen virheenkorjaus: Tag, Ei uudelleenkirjoittaa</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>gEctor — Correction d'erreur grammaticale : étiquette, pas réécriture</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR – Earráid Ghramadaí a cheartú: Clib, Ní Athscríobh</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>KCharselect unicode block name</a>
<a id=he_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - תיקון שגיאה גרמטית: Tag, Not Rewrite</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - व्याकरण त्रुटि सुधार: टैग, नहीं फिर से लिखना</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - Gramatična korekcija greške: značka, ne ponovno pisati</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - Nyelvtani hibajavítás: Címke, Nem újraírás</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>Comment</a>
<a id=id_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - Koreksi Galat Grammatis: Tag, Tidak Tulis ulang</a>
<a id=is_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - Correzione degli errori grammaticali: Tag, Non riscrivere</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR –文法的誤り訂正:タグ、書き換えなし</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GENDOR - Gramatik Eror Ngubah: tag, Not Rewrite</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - Грамматикалық қатені түзету: тег, қайта жазу емес</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>문법 오류 수정: 다시 쓰기 대신 표시</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - Gramatinės klaidos korekcija: ženklas, neišrašyti iš naujo</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - Grammatical Error Correction: Tag, Not Rewrite</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - ഗ്രാമാറ്റിക്കല്‍ പിശക് തിരിച്ചറിയുന്നത്: ടാഗ്, വീണ്ടും എഴുതുന്നതല്ല</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - Pembetulan Ralat Grammatik: Tag, Tidak Tulis Semula</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - Korrezzjoni ta’ Żball Grammatiku: Tag, Mhux Rikiteb</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR-grammaticale foutcorrectie: Tag, niet herschrijven</a>
<a id=no_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR – Gramatisk feilretting: merkelapp, ikkje skriv på nytt</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>Korekta błędów gramatycznych GECToR: znacznik, nie przepisywanie</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR – Correção de erros gramaticais: Tag, não reescrever</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - Corecția erorilor gramaticale: Etichetă, nu rescrie</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR – Исправление грамматической ошибки: тег, не перезаписывать</a>
<a id=si_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - ග්‍රාමාටික් වැරදි සුදුසුම: ටැග්, නැවත ලියන්න එපා</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - Slovnični popravek napak: Oznaka, Ne ponovno napiši</a>
<a id=so_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - Heshiiska galmada grammatical: Tag, Not Rewrite</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - Korrektimi i Gabimeve Gramatike: Tag, Not Rewrite</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - Grammatisk felkorrigering: Tagg, Inte skriva om</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - Uharibifu wa Tamko: Tagha, Si Rewrite</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - சிறந்த பிழை திருத்தம்: ஒட்டு, மீண்டும் எழுதாது</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - Grammatical Error Correction: Tag, Not Rewrite</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR - Grammatical Error Correction: Tag, Not Rewrite</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>Lỗi biểu tượng: thẻ, không phải phục hồi</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2020.bea-1.16.pdf>GECToR – 语法纠错曰:表,非重写也</a></h2><p class=lead><a href=/people/k/kostiantyn-omelianchuk/>Kostiantyn Omelianchuk</a>,
<a href=/people/v/vitaliy-atrasevych/>Vitaliy Atrasevych</a>,
<a href=/people/a/artem-chernodub/>Artem Chernodub</a>,
<a href=/people/o/oleksandr-skurzhanskyi/>Oleksandr Skurzhanskyi</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In this paper, we present a simple and efficient GEC sequence tagger using a Transformer encoder. Our system is pre-trained on synthetic data and then fine-tuned in two stages : first on errorful corpora, and second on a combination of errorful and error-free parallel corpora. We design custom token-level transformations to map input tokens to target corrections. Our best single-model / ensemble GEC tagger achieves an F_0.5 of 65.3/66.5 on CONLL-2014 (test) and F_0.5 of 72.4/73.6 on BEA-2019 (test). Its inference speed is up to 10 times as fast as a Transformer-based seq2seq GEC system.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In hierdie papier, voorsien ons 'n eenvoudige en effektief GEC sekwensiemerker met gebruik van 'n Transformer enkoder. Ons stelsel is voor-opgelei op sintetiese data en dan fin-tuned in twee stadige: eerste op foutlike korpora, en tweede op 'n kombinasie van foutlike en foutlike parallele korpora. Ons ontwerp pasmaak token-vlak transformasies na kaart invoer tokens na doel korreksies. Ons beste enkel-model/ensemble GEC-etiket bereik 'n F_0.5 van 65.3/66.5 op CONLL-2014 (toets) en F_0.5 van 72.4/73.6 op BEA-2019 (toets). Sy inferensie spoed is tot 10 maal so vinnig as 'n Transformer-gebaseerde seq2seq GEC stelsel.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>በዚህ ፕሮግራም ቀላል እና አካባቢ የGEC ስካታዊ ምልክት እናቀርባለን፡፡ የስህተታችን ስህተት በሁለት ደረጃዎች ላይ ተማርቷል፡፡ We design custom token-level transformations to map input tokens to target corrections. የእኛ ትልቁ ዓይነት/ምሳሌ/የGEC ጋልጋሪ 65.3/66.5 ከ65.3/66.5 ከCONLL-2014 (ፈተና) እና የ72.4/73.6 BEA-2019 (ፈተና) F_0.5 አግኝቷል፡፡ የውጤት ፍጥረት እጥፍ ወደ 10 እጥፍ ይደርሳል፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>في هذا البحث ، نقدم أداة تحديد تسلسل GEC بسيطة وفعالة باستخدام مشفر محول. تم تدريب نظامنا مسبقًا على البيانات التركيبية ومن ثم صقله على مرحلتين: أولاً على مجموعة خاطئة ، وثانيًا على مجموعة من المؤسسات المتوازية الخاطئة والخالية من الأخطاء. نحن نصمم تحويلات مخصصة على مستوى الرمز المميز لتعيين رموز الإدخال المميزة للتصحيحات المستهدفة. يحقق أفضل أداة تمييز GEC أحادية الطراز / مجموعة لدينا F_0.5 من 65.3 / 66.5 في CONLL-2014 (اختبار) و F_0.5 من 72.4 / 73.6 في BEA-2019 (اختبار). تصل سرعته الاستدلالية إلى 10 أضعاف سرعة نظام seq2seq GEC القائم على المحولات.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bu kańüńĪzda, transformer kodlayńĪcńĪnńĪ kullanarak basit v…ô effektiv GEC sequence tagger g√∂st…ôririk. Sistemimiz sintetik m…ôlumatlardan …ôvv…ôl t…ôhsil edilmiŇüdir v…ô sonra iki d…ôf…ô d√ľz…ôldilmiŇüdir: ilk yanlńĪŇü korpora, ikincisi yanlńĪŇü v…ô hatasńĪz paralel korpora birl…ôŇüdirilmiŇüdir. Biz m√ľ…ôyy…ôn edilmiŇü token-seviyy…ôti transformasiyalarńĪnńĪ m…ôqs…ôd d√ľz…ôltm…ôy…ô g√∂nd…ôrdik. Bizim …ôn yaxŇüńĪ modell…ôrimiz/ensemble GEC etiket√ßisi CONLL-2014 (test) v…ô BEA-2019 (test) bar…ôsind…ô 72.4/73.6'un F_0.5-ini tapńĪr. Onun x…ôst…ôlik hńĪzlńĪńüńĪ Transformer tabanlńĪ seq2seq GEC sistemi kimi 10 d…ôf…ô hńĪzlńĪdńĪr.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>В тази статия представяме прост и ефективен маркер за последователност, използващ трансформаторен кодер. Системата ни е предварително обучена за синтетични данни и след това фина настройка на два етапа: първо за грешни корпуси и второ за комбинация от грешни и безгрешни паралелни корпуси. Ние проектираме персонализирани трансформации на ниво токен, за да картографираме входните токени за целеви корекции. Най-добрият ни маркер постига F_0.5 от 65.3/66.5 на тест и F_0.5 от 72.4/73.6 на тест. Скоростта на заключението му е до 10 пъти по-бърза от базираната на трансформатор GEC система.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>এই কাগজটিতে আমরা একটি সাধারণ এবং কার্যকর জিসি সেকেন্স ট্যাগার উপস্থাপন করি ট্রান্সফার্ন এনকোডার ব্যবহার করে। আমাদের সিস্টেম সিন্টেটিক ডাটা সম্পর্কে পূর্বে প্রশিক্ষণ প্রদান করা হয়েছে এবং তারপর দুই স্তরে সুন্দর করা হয়েছে: প্রথমে ভুল কর্পোরা এবং দ্বিতীয় ভুল এব We design custom token-level transformations to map input tokens to target corrections. আমাদের সবচেয়ে ভালো মডেল/এনস্পেল জেসি ট্যাগার কনএল-২০১৪ (পরীক্ষা) অর্জন করে ৬৫. ট্রান্সফ্রান্সফার ভিত্তিক সেক্স২সেক জিসি সিস্টেম হিসেবে এর আক্রান্ত গতি ১০ বার দ্রুত।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>འོག་གི་ཤོག་བྱང་འདིའི་ནང་དུ་ང་ཚོས་སྔོན་པོ་ཞིག ང་ཚོའི་མ་ལག་ནི་འདིའི་སྔོན་གྲངས་སྒྲིག་ཆ་འཕྲིན་ལས་རང་ཉིད་ཀྱི་གནས་སྟངས་གཉིས་ཀྱི་ནང་དུ་བཏོན་ཡོད། We design custom token-level transformations to map input tokens to target corrections. ང་ཚོའི་མ་དབྱིབས་གཅིག་གི་རྣམ་པ་ཞིག་དང་མཚོན་རྟགས་GEC tagger་གིས་ CONLL-2014 (བརྟག་ཞིབ་) ཐོག་ལས་ F_0.5 གནད་སྒྲིག BEA-2019 (བརྟག་ཞིབ་)ལས་F_0.5 གནད་སྒྲིག འདིའི་མཐའ་འཁོར་གྱི་མགྱོགས་ཚད་ལྡན་འགྱུར་བ་དང་གཞི་བརྟེན་ནས་seq2seq GEC་མ་ལག་གི་འགྱུར་ཚད་ལྡན་10ཡིས་མཐོ་རེད།</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>U ovom papiru predstavljamo jednostavan i efikasan označavač GEC sekvence koristeći koder transformera. Naš sistem je predobučen za sintetičke podatke, a zatim je ispravno sređen na dva faza: prvo na pogrešnoj korpori, a drugo na kombinaciji grešnog i bezgrešnog paralelnog korpora. Mi dizajniramo transformacije na nivou znakova na mapu ulaznih znakova na ciljne korekcije. Naš najbolji jedinstveni model/ensemble GEC tagger postiže F_0,5 od 65.3/66.5 na CONLL-2014 (test) i F_0,5 od 72.4/73.6 na BEA-2019 (test). Njegova brzina infekcije je do 10 puta brže kao sustav GEC na transformeri seq2seq.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>En aquest article presentem un etiquetador de seqüència GEC simple i eficient utilitzant un codificador Transformer. El nostre sistema està pré-entrenat en dades sintètiques i després fine-tuned en dues etapes: primer en corpora errònia, i segon en una combinació de corpora paral·lela errònia i sense errors. Desenyem transformacions personalitzades a nivell de fitxes per mapejar fitxes d'entrada per a corregir els objectius. El nostre millor etiquetador GEC amb un únic model/ensemble obté un F_0,5 de 65,3/66,5 a CONLL-2014 (test) i un F_0,5 de 72,4/73,6 a BEA-2019 (test). La velocitat d'inferència és fins a 10 vegades més ràpida que un sistema seq2seq GEC basat en Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>V tomto článku představujeme jednoduchý a efektivní GEC sekvenční tagger pomocí snímače Transformer. Náš systém je předem trénován na syntetických datech a poté jemně laděn ve dvou fázích: první na chybných korpusech a druhé na kombinaci chybných a bezchybných paralelních korpusů. Navrhujeme vlastní transformace na úrovni tokenů pro mapování vstupních tokenů k cílovým opravám. Náš nejlepší single-model/ensemble GEC tagger dosahuje F_0.5 z 65.3/66.5 na CONLL-2014 (test) a F_0.5 z 72.4/73.6 na BEA-2019 (test). Rychlost inference je až desetkrát rychlejší než systém seq2seq GEC založený na Transformeru.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>I denne artikel præsenterer vi en enkel og effektiv GEC sekvens tagger ved hjælp af en Transformer encoder. Vores system er præ-trænet på syntetiske data og derefter finjusteret i to faser: først på errorful corpora, og anden på en kombination af fejlfri og fejlfri parallelle corpora. Vi designer brugerdefinerede token-niveau transformationer for at kortlægge input tokens til målrettede korrektioner. Vores bedste single-model/ensemble GEC tagger opnår en F_0.5 af 65.3/66.5 på CONLL-2014 (test) og F_0.5 af 72.4/73.6 på BEA-2019 (test). Dens sluthastighed er op til 10 gange så hurtig som et Transformer-baseret sek2seq GEC system.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In diesem Beitrag stellen wir einen einfachen und effizienten GEC Sequence Tagger mit einem Transformer Encoder vor. Unser System ist auf synthetischen Daten vortrainiert und anschließend in zwei Stufen fein abgestimmt: erstens auf fehlerhafte Korpora und zweitens auf eine Kombination fehlerhafter und fehlerfreier paralleler Korpora. Wir entwerfen benutzerdefinierte Transformationen auf Tokenebene, um Eingabetoken Zielkorrekturen zuzuordnen. Unser bester Single-Model/Ensemble GEC Tagger erreicht eine F_0.5 von 65.3/66.5 auf CONLL-2014 (Test) und F_0.5 von 72.4/73.6 auf BEA-2019 (Test). Seine Inferenzgeschwindigkeit ist bis zu 10-mal so schnell wie ein Transformer-basiertes seq2seq GEC-System.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Σε αυτή την εργασία, παρουσιάζουμε έναν απλό και αποτελεσματικό δείκτη ακολουθίας που χρησιμοποιεί έναν κωδικοποιητή μετασχηματιστή. Το σύστημά μας είναι προ-εκπαιδευμένο σε συνθετικά δεδομένα και στη συνέχεια συντονισμένο σε δύο στάδια: πρώτον σε εσφαλμένα σώματα, και δεύτερον σε συνδυασμό εσφαλμένων και χωρίς σφάλματα παράλληλων σωμάτων. Σχεδιάζουμε προσαρμοσμένους μετασχηματισμούς επιπέδου σήματος για να αντιστοιχίσουμε τα σήματα εισόδου στις διορθώσεις στόχων. Το καλύτερο μονο-μοντέλο/σύνολο μας επιτυγχάνει ένα F_0.5 65.3/66.5 σε CONLL-2014 (δοκιμή) και F_0.5 72.4/73.6 σε BEA-2019 (δοκιμή). Η ταχύτητα συναγωγής του είναι έως και δέκα φορές μεγαλύτερη από ένα σύστημα GEC βασισμένο στον μετασχηματιστή.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>En este artículo, presentamos un etiquetador de secuencias GEC simple y eficiente que utiliza un codificador Transformer. Nuestro sistema se entrena previamente en datos sintéticos y luego se ajusta en dos etapas: primero en los cuerpos con errores y, en segundo lugar, en una combinación de cuerpos paralelos con errores y sin errores. Diseñamos transformaciones personalizadas a nivel de token para asignar tokens de entrada a correcciones de objetivos. Nuestro mejor etiquetador GEC de un solo modelo/conjunto logra una F_0.5 de 65.3/66.5 en CONLL-2014 (prueba) y F_0.5 de 72.4/73.6 en BEA-2019 (prueba). Su velocidad de inferencia es hasta 10 veces más rápida que la de un sistema GEC seq2seq basado en Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Käesolevas töös tutvustame lihtsat ja tõhusat GEC jada sildistajat, kasutades Transformer kodeerijat. Meie süsteem on eelnevalt koolitatud sünteetilistele andmetele ja seejärel peenhäälestatud kahes etapis: esiteks ekslike korpuste ja teiseks ekslike ja vigadeta paralleelkorpuste kombinatsiooni. Me kujundame kohandatud tokeni tasemel muundusi, et kaardistada sisendtokenid sihtparanduste jaoks. Meie parim ühe mudeli/ansambli GEC sildistaja saavutab F_0.5 65.3/66.5 CONLL-2014 (test) ja F_0.5 72.4/73.6 BEA-2019 (test). Selle järelduskiirus on kuni 10 korda kiirem kui Transformer-põhine seq2seq GEC süsteem.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>در این کاغذ، ما با استفاده از یک رمزنگار تغییر دهنده یک تاجر ردیابی GEC ساده و موثر را نشان می دهیم. سیستم ما پیش از این روی داده های سناتیک آموزش داده شده و سپس در دو مرحله درست شده است: اول روی شرکت اشتباهی و دوم روی ترکیب شرکت اشتباهی و اشتباهی آزاد است. ما تغییرات سطح معجزه‌های شخصی را طراحی می‌کنیم تا نشانه‌های ورودی را به سمت اصلاح هدف نقشه بگیریم. بهترین نمونه‌ی single-model/ensemble GEC tagger ما یک F_0.5 از 65.3/66.5 در CONLL-2014 (آزمایش) و F_0.5 از 72.4/73.6 در BEA-2019 (آزمایش) می‌رسد. سرعت آلودگی آن تا ۱۰ بار سریع تر از سیستم GEC بر اساس تغییر دهنده است.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tässä työssä esittelemme yksinkertaisen ja tehokkaan GEC-sekvenssitaggerin käyttäen Transformer-kooderia. Järjestelmämme on esikoulutettu synteettisestä datasta ja sen jälkeen hienosäädetty kahdessa vaiheessa: ensin virheellisillä korpusilla ja toiseksi virheellisten ja virheettömien rinnakkaiskorpusten yhdistelmällä. Suunnittelemme mukautetut token-tason muunnokset karttaan syöttötokenit kohdistamaan korjauksia. Paras yhden mallin/kokoonpanon GEC-tagger saavuttaa F_0.5 65.3/66.5 CONLL-2014 (testi) ja F_0.5 72.4/73.6 BEA-2019 (testi). Sen päättelynopeus on jopa 10 kertaa nopeampi kuin Transformer-pohjainen seq2seq GEC järjestelmä.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Dans cet article, nous présentons un tagger de séquence GEC simple et efficace utilisant un codeur Transformer. Notre système est pré-entraîné sur des données synthétiques, puis affiné en deux étapes : d'abord sur les corpus erronés, et ensuite sur une combinaison de corpus parallèles erronés et exempts d'erreurs. Nous concevons des transformations personnalisées au niveau des jetons pour mapper les jetons d'entrée aux corrections cibles. Notre meilleur tagger GEC mono-modèle/ensemble atteint un F_0.5 de 65,3/66,5 sur CONLL-2014 (test) et F_0.5 de 72,4/73,6 sur BEA-2019 (test). Sa vitesse d'inférence est jusqu'à 10 fois plus rapide qu'un système GEC seq2seq basé sur Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Sa pháipéar seo, cuirimid i láthair clibeálaí seicheamh GEC simplí agus éifeachtach ag baint úsáide as ionchódóir Trasfhoirmeoir. Déantar ár gcóras a réamhoiliúint ar shonraí sintéiseacha agus ansin mionchoigeartaithe in dhá chéim: ar dtús ar chorpora earráideach, agus sa dara háit ar mheascán de chorpora comhthreomhara earráideach agus saor ó earráidí. Dearaímid claochluithe leibhéal dearbhán chun comharthaí ionchuir a mhapáil chun ceartúcháin a spriocdhíriú. Baineann ár gclibálaí GEC aon-samhail/ensemble is fearr amach F_0.5 de 65.3/66.5 ar CONLL-2014 (tástáil) agus F_0.5 de 72.4/73.6 ar BEA-2019 (tástáil). Tá a luas tátal suas le 10 n-uaire chomh tapa le córas seq2seq GEC atá bunaithe ar Trasfhoirmeoir.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ga wannan takardan, Munã gaurar da wata tagger mai sauƙi da mai amfani da wani kode ta Transformer. Ana tafiyar da na'urarmu a gaba ɗaya a kan data na synthetic, sa'an nan kuma aka gyãra mai kyau a cikin daraja biyu: farkon a kan koropa mai ɓarna, da na ƙarƙashin a komai da wata shirin karkacin da aka samu wata shirin wata na ɓata ba-da-ɓata. Kana ƙayyade jujjuya masu shida cikin shirin ayuka na ɗabi'a zuwa map ayukan inputi don ya yi amfani da shiryarwa. Babu mafi kyaun motsi/ensemble GEC tagger na sãmu F_0.5 daga 65.3/66.5 kan CONLL-2014 (jarrabo) da F_0.5 daga 197.4/73.6 kan BEA-2019 (jarrabãwa). Gaskiya ya kai 10 sau kasu kamar wata na GPS ta Transformer-based seq2seq.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>בעיתון הזה, אנחנו מציגים תג רצף GEC פשוט ויעיל באמצעות קודד טרנספורר. המערכת שלנו מאומנת מראש על נתונים סינטטיים ואז מתאימה בשני שלבים: ראשית על גופורה שגויה, ושנייה על שילוב של גופורה קבועה שגויה ללא שגויות. אנחנו מעצבים שינויים מתאימים ברמה של סימנים כדי למפות סימנים כניסה לתיקונים מטרה. Our best single-model/ensemble GEC tagger achieves an F_0.5 of 65.3/66.5 on CONLL-2014 (test) and F_0.5 of 72.4/73.6 on BEA-2019 (test). מהירות ההנחה שלה עד 10 פעמים מהירה יותר ממערכת GEC המבוססת על Transformer seq2seq.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>इस पेपर में, हम एक ट्रांसफॉर्मर एनकोडर का उपयोग करके एक सरल और कुशल जीईसी अनुक्रम टैगर पेश करते हैं। हमारी प्रणाली को सिंथेटिक डेटा पर पूर्व-प्रशिक्षित किया जाता है और फिर दो चरणों में ठीक-ठाक किया जाता है: पहला त्रुटिपूर्ण कॉर्पोरेट पर, और दूसरा त्रुटिपूर्ण और त्रुटि-मुक्त समानांतर कॉर्पोरेट के संयोजन पर। हम लक्ष्य सुधारों के लिए इनपुट टोकन मैप करने के लिए कस्टम टोकन-स्तर परिवर्तनों को डिज़ाइन करते हैं। हमारा सबसे अच्छा एकल मॉडल / पहनावा जीईसी टैगर CONLL-2014 (परीक्षण) पर 65.3 / 66.5 का एक F_0.5 और बीईए -2019 (परीक्षण) पर 72.4 / 73.6 का F_0.5 प्राप्त करता है। इसकी अनुमान गति एक ट्रांसफॉर्मर-आधारित seq2seq GEC प्रणाली के रूप में 10 गुना तेज है।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>U ovom papiru predstavljamo jednostavan i učinkovit označavač GEC sekvencije koristeći koder transformera. Naš sustav je predobučen na sintetičkim podacima, a zatim je ispravno sređen na dva faza: prvo na pogrešnoj tijelo, a drugo na kombinaciji greške i bezgreške paralelne tijelo. Mi dizajniramo transformacije na razini znakova kako bi mapirali ulazne znakove na ciljne korekcije. Naš najbolji jedinstveni model/ensemble GEC tagger postiže F_0,5 od 65,3/66,5 na CONLL-2014 (test) i F_0,5 od 72,4/73,6 na BEA-2019 (test). Njezina brzina infekcije je do 10 puta brže kao sustav GEC na transformeri seq2seq.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ebben a tanulmányban egy egyszerű és hatékony GEC szekvencia címkézőt mutatunk be Transformer kódolóval. Rendszerünket előkészítettük a szintetikus adatokra, majd két szakaszban finomhangoljuk: először a hibás corpora, a második pedig a hibás és hibátlan párhuzamos corpora kombinációján. Egyéni tokenszintű átalakításokat tervezünk, hogy a beviteli tokeneket a céljavításokhoz térképezzük fel. Legjobb egymodell/együttes GEC címkézőnk elérte az F_0.5-et a 65.3/66.5-ből a CONLL-2014-en (teszt) és az F_0.5-et a 72.4/73.6-ból a BEA-2019-en (teszt). Következtetési sebessége akár 10-szer olyan gyors, mint egy Transformer alapú seq2seq GEC rendszer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Այս թղթի մեջ մենք ներկայացնում ենք պարզ և արդյունավետ ԳԵԿ հաջորդականության նշան՝ օգտագործելով Թանֆորմերի կոդեր: Մեր համակարգը նախապատրաստված է սինթետիկ տվյալների վրա և հետո բարձրացված է երկու փուլում. առաջինը սխալ մարմնի վրա, երկրորդը սխալ և անսխալ զուգահեռ մարմնի համադրման վրա: Մենք նախագծում ենք հնարավոր նշանների մակարդակի վերափոխություններ, որպեսզի քարտեզագրենք նշանների մուտքագրման նշանները նպատակային ուղղումների համար: Մեր ամենալավ մեկ մոդել-համակարգ ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդհանուր ընդ Its inference speed is up to 10 times as fast as a Transformer-based seq2seq GEC system.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Dalam kertas ini, kami mempersembahkan tag urutan GEC sederhana dan efisien menggunakan pengekode Transformer. Sistem kita dilatih-dilatih pada data sintetis dan kemudian disesuaikan dalam dua tahap: pertama pada corpora yang salah, dan kedua pada kombinasi dari corpora paralel yang salah dan tanpa kesalahan. We design custom token-level transformations to map input tokens to target corrections. Tagger GEC model/ensemble terbaik kami mencapai F_0.5 dari 65.3/66.5 pada CONLL-2014 (tes) dan F_0.5 dari 72.4/73.6 pada BEA-2019 (tes). Kecepatan kesimpulannya sampai 10 kali lebih cepat dari sistem SEq2seq GEC berdasarkan Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In questo articolo, presentiamo un tag di sequenza GEC semplice ed efficiente utilizzando un encoder Transformer. Il nostro sistema è pre-addestrato su dati sintetici e poi perfezionato in due fasi: primo su corpora errorful e secondo su una combinazione di corpora parallela errorful e senza errori. Progettiamo trasformazioni personalizzate a livello di token per mappare i token di input alle correzioni mirate. Il nostro miglior tagger GEC monomodello/ensemble raggiunge un F_0.5 su 65.3/66.5 su CONLL-2014 (test) e un F_0.5 su 72.4/73.6 su BEA-2019 (test). La sua velocità di inferenza è fino a 10 volte più veloce di un sistema GEC seq2seq basato su Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>本稿では、トランスフォーマーエンコーダを用いた簡便かつ効率的なＧＥＣシーケンスタグを提示する。当社のシステムは、合成データの事前トレーニングを受け、2段階で微調整されています。1段階目は誤ったコーパス、2段階目は誤ったパラレルコーパスと誤りのないパラレルコーパスの組み合わせです。カスタムトークンレベル変換を設計して、入力トークンをターゲット修正にマッピングします。当社の最高のシングルモデル/アンサンブルGECタガーは、CONLL -2014 （試験）でF_0.5の65.3/66.5、BEA -2019 （試験）でF_0.5の72.4/73.6を達成しています。その推論速度は、トランスフォーマーベースのseq 2 seq GECシステムの最大10倍の速度です。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nyong mapur iki, kita mulai un ajeng-ajeng GEC seng pangan ning koder Transformer. Sistem-siji sing ditambahak kelas-kelas nang data sinantesik lan sak gewis dipun-kelas telu wae: sampeyan tanggal kuwi corompora sing gak bener We design custom token-scale transformations to map input token to goal rections. Awake singular-model/ensamble GEC tagger success Digambungan kanggo kalih-kalih sabanjuré teka sakjane kanggo sistem seq2seq GEC sing basa gambar n' Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ჩვენ ამ კაურაში გავაჩვენოთ ერთადერთი და ეფექტიური GEC წერტილების ჭდერი, რომელიც გამოყენებული ტრანფორმაციის კოდერის გამოყენებული. ჩვენი სისტემა სინტეტიკური მონაცემებზე უბრალოდ განაკეთებულია და შემდეგ ორი ფაეში უბრალოდ განაკეთებულია: პირველი შეცდომა კოპორაზე და მეორე შეცდომა და შეცდომა დაკავშირებული პარალ ჩვენ განსაკუთრებული ტექნონის დონეზე გარემოქმედებით გარემოქმედებით, რომლებიც შეიყვანის ტექნონის გარემოქმედებისთვის. ჩვენი ყველაზე საუკეთესო მოდელ/ანსემბლის GEC ტეგერი 65.3/66.5-ის F_0.5-ს CONLL-2014 (ტესტი) და F_0.5-ის 72.4/73.6-ზე BEA-2019 (ტესტი). მისი ინფრენციის სიჩქარე 10-ჯერ უფრო სიჩქარე, როგორც ტრანფორმეტრის ბაზეული seq2seq GEC სისტემა.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Бұл қағазда қарапайым және эффективті GEC реттеу тегжерін түрлендіруші кодерін қолдану үшін көрсетеді. Біздің жүйеміз синтетикалық деректерге алдын- ала оқылған, кейін екі этап бойынша дұрыс түзетілген: біріншіден қате корпорада, екіншіден қате және қате бос параллелі корпорада біріктірілген. Кіріс белгілерін мақсатты түзету үшін өзгерту үшін өзгертіміз. Біздің ең жалғыз үлгі/сәйкестік GEC тегжеріміз CONLL-2014 (сынақ) және BEA-2019 (сынақтағы) 72,4/73,6 (сынақтағы) F_0,5 дегенді жеткізеді. Түрлендіру жылдамдығы, Түрлендіруші негізделген seq2seq GEC жүйесіне 10 рет жылдам.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>본고에서 우리는 간단하고 효과적인 GEC 시퀀스 표기기 사용 변압기 인코더를 제시했다.우리 시스템은 합성 데이터에 대해 미리 훈련한 다음에 두 단계로 나누어 미세하게 조정한다. 첫 번째 단계는 오류 자료 라이브러리이고 두 번째 단계는 오류와 무오류 평행 자료 라이브러리의 조합이다.우리는 맞춤형 영패 등급 전환을 설계하여 입력한 영패를 목표 수정에 비추었다.우리의 가장 좋은 단모형/전체 GEC 표기기는 CONLL-2014(테스트)에서 65.3/66.5의 F 0.5, BEA-2019(테스트)에서 72.4/73.6의 F 0.5에 달한다.그 추리 속도는 변압기 기반 seq2seq GEC 시스템의 10배에 달한다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In this paper, we present a simple and efficient GEC sequence tagger using a Transformer encoder. Mūsų sistema iš anksto apmokoma sintetiniais duomenimis, o po to patobulinta dviem etapais: pirma klaidinga korpora, antra klaidinga ir klaidinga lygiagreti korpora deriniu. Mes suprojektuojame pritaikytus žymenų lygio pokyčius, kad žymenų įvedimo žymenų žemėlapį būtų galima atlikti tikslines korekcijas. Mūsų geriausias vieno modelio ir (arba) komplekso GEC žymeklis atitinka 65.3/66.5 punkto F_0.5 CONLL-2014 (bandymas) ir 72.4/73.6 punkto F_0.5 BEA-2019 (bandymas). Jo išvados greitis yra ne greitesnis kaip 10 kartų greitesnis už Transformer pagrįstą sek2seq GEC sistemą.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Во овој весник, претставуваме едноставен и ефикасен геЦ секвенциски означувач користејќи трансформер кодер. Нашиот систем е предобучен на синтетички податоци, а потоа фино прилагоден во две фази: прво на грешна корпора, и второ на комбинација на грешна и безгрешна паралелна корпора. We design custom token-level transformations to map input tokens to target corrections. Нашиот најдобар единствен модел/ансембл ГЕЦ означувач постигнува F_0.5 од 65.3/66.5 на CONLL-2014 (тест) и F_0.5 од 72.4/73.6 на BEA-2019 (тест). Its inference speed is up to 10 times as fast as a Transformer-based seq2seq GEC system.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ഈ പത്രത്തില്‍, നമ്മള്‍ ഒരു എളുപ്പമുള്ള ജിസി സെക്സഞ്ചര്‍ ടാഗ്ഗര്‍ കൊണ്ടുവരുന്നു. ട്രാന്‍സ്ഫോര്‍മാന്‍ കോഡെ നമ്മുടെ സിസ്റ്റത്തിന് മുന്‍പ് പരിശീലിക്കപ്പെട്ടിരിക്കുന്നു. പിന്നീട് രണ്ട് സ്റ്റേജില്‍ മുഴുവന്‍ പരിശീലിക്കപ്പെട്ടിരിക്കുന്നു. ആദ് നമ്മള്‍ സ്വന്തം ടോക്ക് നില മാറ്റങ്ങള്‍ സൃഷ്ടിക്കുന്നു. ക്രമീകരണങ്ങള്‍ക്ക് ലക്ഷ്യം വരുത്താനുള്ള അടയാ Our best single-model/ensemble GEC tagger achieves an F_0.5 of 65.3/66.5 on CONLL-2014 (test) and F_0.5 of 72.4/73.6 on BEA-2019 (test). അതിന്റെ വേഗത 10 പ്രാവശ്യം വരെ ട്രാന്‍സ്ഫോര്‍മാര്‍ അടിസ്ഥാനമായ സെക്ക്2seq GEC സിസ്റ്റം പോലെയാണ്.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Энэ цаасан дээр бид энгийн болон эффективны GEC дарааллын тегжер ашиглаж байна. Бидний систем синтетик өгөгдлийн талаар урьд суралцаж, дараа нь хоёр дахь дахь сайжруулагдсан. Эхлээд алдаа гарсан корпора, хоёр дахь алдаа болон алдаа гарагүй параллел корпора дээр холбогдсон. Бид хувилбарын тонны түвшин өөрчлөлтийг зориулалтын зориулалтыг газрын зураг зураг хийдэг. Бидний хамгийн шилдэг нэг загвар/загвар GEC тэмдэглэгчид CONLL-2014 оны F_0.5 болон F_0.5 болон F_0.5 нь 72.4/73.6 болон BEA-2019 оны F_0.5 (шалгалт). Үүний халдварын хурд нь Трансфер-д суурилсан seq2seq GEC системээс 10 дахин хурдан байна.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In this paper, we present a simple and efficient GEC sequence tagger using a Transformer encoder. Sistem kita dilatih-dilatih pada data sintetik dan kemudian ditetapkan dalam dua tahap: pertama pada corpora yang salah, dan kedua pada kombinasi dari corpora paralel yang salah dan bebas ralat. Kami merancang perubahan aras token suai untuk peta token input ke penyesuaian sasaran. Tagger GEC tunggal-model/ensemble terbaik kami mencapai F_0.5 dari 65.3/66.5 pada CONLL-2014 (ujian) dan F_0.5 dari 72.4/73.6 pada BEA-2019 (ujian). Kelajuan kesimpulannya sehingga 10 kali lebih cepat daripada sistem GEC berasaskan Transformer seq2seq.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>F’dan id-dokument, qed nippreżentaw tag sempliċi u effiċjenti tas-sekwenza GEC bl-użu ta’ kodifikatur Transformer. Is-sistema tagħna hija mħarrġa minn qabel fuq dejta sintetika u mbagħad imfassla f’żewġ stadji: l-ewwel fuq corpora żbaljata, u t-tieni fuq kombinazzjoni ta’ corpora parallela żbaljata u mingħajr żbalji. Aħna niddisinjaw trasformazzjonijiet personali fil-livell tat-tokens biex nimmappjaw it-tokens tal-input għall-korrezzjonijiet fil-mira. Our best single-model/ensemble GEC tagger achieves an F_0.5 of 65.3/66.5 on CONLL-2014 (test) and F_0.5 of 72.4/73.6 on BEA-2019 (test). Il-veloċità tal-inferenza tagħha hija sa 10 darbiet aktar mgħa ġġla minn sistema tal-GEC seg2seq ibbażata fuq it-Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In dit artikel presenteren we een eenvoudige en efficiënte GEC sequence tagger met behulp van een Transformer encoder. Ons systeem is vooraf getraind op synthetische gegevens en vervolgens verfijnd in twee fasen: ten eerste op foutieve corpora, en ten tweede op een combinatie van foutloze en foutloze parallelle corpora. We ontwerpen aangepaste transformaties op tokenniveau om invoertokens toe te wijzen aan doelcorrecties. Onze beste single-model/ensemble GEC tagger behaalt een F_0.5 van 65.3/66.5 op CONLL-2014 (test) en F_0.5 van 72.4/73.6 op BEA-2019 (test). De inferentiesnelheid is tot tien keer zo snel als een Transformer-gebaseerd seq2seq GEC-systeem.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>I denne papiret viser vi ein enkel og effektiv GEC-sekvensmerker med ein transformeringskoder. Sistemet vårt er først trent på syntetiske data og så fint opp i to stader: først på feil korpora, og andre på ein kombinasjon av feil og feil-fri parallelle korpora. Vi design eigendefinerte transformasjonar for tokennivå til å kartera inntekens til målrettingar. Vårt beste enkelmodell/ensemble GEC-tagger oppnår ein F_0,5 av 65,3/66,5 på CONLL-2014 (test) og F_0,5 av 72,4/73,6 på BEA-2019 (test). Den inferensningsfarten er opp til 10 ganger så rask som eit transformeringsbasert seq2seq GEC-system.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>W artykule przedstawiamy prosty i wydajny tager sekwencji GEC z wykorzystaniem kodera Transformera. Nasz system jest wstępnie przeszkolony na podstawie danych syntetycznych, a następnie dostrojony w dwóch etapach: pierwszy na korpusach błędnych, a drugi na kombinacji korpusów równoległych bez błędów. Projektujemy niestandardowe transformacje na poziomie tokenów, aby mapować tokeny wejściowe do poprawek docelowych. Nasz najlepszy pojedynczy model/zespół tagera GEC osiąga F_0.5 od 65.3/66.5 na CONLL-2014 (test) i F_0.5 od 72.4/73.6 na BEA-2019 (test). Jego prędkość wnioskowania jest nawet 10-krotnie szybsza niż system GEC oparty na Transformerze.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Neste artigo, apresentamos um tagger de sequência GEC simples e eficiente usando um codificador Transformer. Nosso sistema é pré-treinado em dados sintéticos e, em seguida, ajustado em duas etapas: primeiro em corpora com erros, e segundo em uma combinação de corpora paralelos com erros e sem erros. Projetamos transformações personalizadas em nível de token para mapear tokens de entrada para correções de destino. Nosso melhor marcador GEC de modelo único/conjunto alcança um F_0.5 de 65.3/66.5 no CONLL-2014 (teste) e F_0.5 de 72.4/73.6 no BEA-2019 (teste). Sua velocidade de inferência é até 10 vezes mais rápida que um sistema GEC seq2seq baseado em Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>În această lucrare, prezentăm un etichetor de secvență GEC simplu și eficient folosind un encoder Transformer. Sistemul nostru este pre-instruit pe date sintetice și apoi reglat fin în două etape: în primul rând pe corpore erorful, și în al doilea rând pe o combinație de corpore paralele erorful și fără erori. Proiectăm transformări personalizate la nivel de token pentru a mapa token-urile de intrare pentru corecțiile țintite. Cel mai bun etichetator GEC single-model/ansamblu obține un F_0.5 din 65.3/66.5 pe CONLL-2014 (test) și F_0.5 din 72.4/73.6 pe BEA-2019 (test). Viteza sa de deducere este de până la 10 ori mai rapidă decât un sistem GEC bazat pe Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>В этой статье мы представляем простой и эффективный тегер последовательности GEC с использованием кодировщика Трансформатора. Наша система предварительно обучается синтетическим данным, а затем тонко настраивается в два этапа: первый - на ошибочных телах, а второй - на комбинации ошибочных и безошибочных параллельных тел. Мы разрабатываем пользовательские преобразования на уровне токенов для сопоставления входных токенов с целевыми исправлениями. Наш лучший одномодельный/ансамблевый тагер GEC достигает F_0.5 65.3/66.5 на CONLL-2014 (тест) и F_0.5 72.4/73.6 на BEA-2019 (тест). Его скорость вывода в 10 раз выше, чем у системы GEC Seq2seq на базе трансформатора.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>මේ පැත්තේ, අපි සාමාන්‍ය සහ හැකියාවක් GEC ක්‍රමාණය ටැගර් එකක් පෙන්වන්නේ. අපේ පද්ධතිය සංවිධාන දත්තේ ප්‍රධානය කරලා පස්සේ සංවිධානය දෙන්න ප්‍රධානය කරලා තියෙනවා: මුලින්ම වැරදි කොර්පෝරා වලින් ප්‍ අපි කැමතියි ටොකෙන් ලේවල් වෙනස් විදිහට අක්‍රියාත්මක වෙනුවෙන් ඉලක්ෂිත විදිහට ඇතුළු ටො අපේ හොඳම ප්‍රමාණය/පරීක්ෂණය GEC ටැග්ජර් එකට CONLL-2014 (පරීක්ෂණය) වල F_0.5 of 65.3/66.5 (පරීක්ෂණය) සහ F_0.5 of 72.4/73.6 on BEA-2019 (පරීක්ෂණය). එයාගේ පරීක්ෂණ වේගය 10 ක් වේගයෙන් වේගයෙන් ප්‍රවේගකයෙන් ආධාරිත seq2seq GEC පද්ධතියක් වගේ.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>V tem prispevku predstavljamo preprost in učinkovit označevalnik zaporedja GEC z uporabo transformatorskega kodirnika. Naš sistem je predhodno usposobljen za sintetične podatke in nato natančno nastavljen v dveh fazah: prvi na napačnih korpusih, drugi na kombinaciji napačnih in brez napak vzporednih korpusov. Oblikujemo transformacije na ravni žetonov po meri za kartiranje vhodnih žetonov za ciljne popravke. Naš najboljši enomodel označevalec GEC doseže F_0.5 65.3/66.5 na CONLL-2014 (test) in F_0.5 72.4/73.6 na BEA-2019 (test). Njegova sklepna hitrost je do 10-krat hitrejša kot transformatorski sistem seq2seq GEC.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Qoraalkan waxaynu ku soo bandhignaynaa tagger fudud oo faa’iido leh oo ku isticmaalaya qoraal turjumid ah. nidaamkayaga waxaa horay loo tababariyey macluumaadka synthetika, kadibna waxaa lagu sharraxay labada marxaladood: marka hore shirkadda qaladka ah, labaadna waxaa lagu soo bandhigaa shirkadda qaladka ah oo aan qaladka lahayn. Waxaynu u qornaa isbedelka sawirada calaamada ee caadiga ah si aan ugu sawiro hagitaanka. Jardiino ugu wanaagsan GEC tagger wuxuu gaadhaa F_0.5 oo ka mid ah 65.3/66.5 oo ku qoran CONLL-2014 (test) iyo F_0.5 oo ka mid ah 72.4/73.6 BEA-2019 (test). Fasaxa cudurku wuxuu gaadhaa ilaa 10 jeer sida nidaamka GEC ee ku saleysan turjumista 2seq.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Në këtë letër, ne paraqesim një shënues të thjeshtë dhe efektiv të sekuencës GEC duke përdorur një kodues Transformer. Sistemi ynë është i stërvitur në të dhënat sintetike dhe pastaj i rregulluar në dy faza: së pari në corpora të gabuara, dhe i dyti në një kombinim të corpora paralele të gabuara dhe pa gabime. Ne dizajnojmë transformime të personalizuara në nivel token për të hartuar token e hyrjes në objektiv korreksione. Tagger ynë më i mirë i një modeli/ensemble GEC arrin një F_0.5 të 65.3/66.5 në CONLL-2014 (test) dhe F_0.5 të 72.4/73.6 në BEA-2019 (test). Shpejtësia e inferencës së saj është deri në 10 herë më e shpejtë se një sistem SEq2seq GEC me bazë në Transformer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>U ovom papiru predstavljamo jednostavan i efikasan oznake GEC sekvence koristeći koder transformera. Naš sistem je predobučen za sintetičke podatke, a zatim je ispravno sređen na dva faza: prvo na pogrešnoj korpori, a drugo na kombinaciji grešne i bezgrešne paralelne korpore. Mi dizajniramo transformacije na nivou znakova za mapu ulaznih znakova na ciljne korekcije. Naš najbolji jedinstveni model/ensemble GEC tagger postiže F_0,5 od 65,3/66,5 na CONLL-2014 (test) i F_0,5 od 72,4/73,6 na BEA-2019 (test). Njegova brzina infekcije je do 10 puta brže kao transformer-based seq2seq GEC sistem.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>I denna uppsats presenterar vi en enkel och effektiv GEC sekvenstaggare med hjälp av en Transformer encoder. Vårt system är förinstallerat på syntetiska data och finjusterat i två steg: först på errorful corpora, och andra på en kombination av errorful och felfria parallella corpora. Vi designar anpassade transformationer på token-nivå för att kartlägga inmatningstokens till målkorrigeringar. Vår bästa engångsmodell/ensemble GEC tagger uppnår en F_0.5 av 65.3/66.5 på CONLL-2014 (test) och F_0.5 av 72.4/73.6 på BEA-2019 (test). Dess sluthastighet är upp till 10 gånger så snabb som ett Transformer-baserat sek2seq GEC-system.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Katika karatasi hii, tunaweka alama nyepesi na yenye ufanisi wa mfululizo wa GEC kwa kutumia kodi ya Transformer. Our system is pre-trained on synthetic data and then fine-tuned in two stages: first on errorful corpora, and second on a combination of errorful and error-free parallel corpora. Tunaweza kutengeneza mabadiliko ya kiwango cha alama kwa ajili ya ramani ishara za input ili kulenga sahihi. Bendera yetu ya GEC yenye mfano mzuri zaidi imefanikiwa F_0.5 ya 65.3/66.5 kwenye CONLL-2014 (jaribio) na F_0.5 ya 72.4/73.6 kwenye BEA-2019 (jaribio). Upunguzo wake umefikia mara 10 kwa haraka kama mfumo wa GEC wa zamani wa sekq2seq.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>இந்த காகிதத்தில், நாம் ஒரு எளிய மற்றும் தேவையான GEC பின்னணி ஒட்டிக்கொண்டு வருகிறோம். எங்கள் அமைப்பு கூட்டிணைப்பு தகவல் முன் பயிற்சி செய்யப்பட்டுள்ளது மற்றும் இரண்டு நிலைகளில் நன்றாக முடிக்கப்பட்டது: முதலில் தவறான நிறுவனத்தில் ம நாம் தனிப்பயன் குறியீடு நிலை மாற்றங்களை வடிவமை எங்கள் சிறந்த ஒற்றை மாதிரி/ensemble GEC ஒட்டிக்காட்டி 65.3/66.5 ல் ஒரு F_ 0.5 கிடைக்கும் CONLL- 2014 (சோதனை) மற்றும் BEA-2019 (சோதனையில் 72.4/73.6 ல் F_ 0.5 பெறுக அதன் பின்னணி வேகம் 10 முறை மாற்றுதல் அடிப்படையிலுள்ள பின்னணி GEC முறைமையாக இருக்கும்.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bu kagyzda basit we etkinlik bir GEC terjime tägleri tans edip görkezip Bizim sistemimiz sintetik verilerde öňünden öňünden eğitildi ve iki taýdan geçirildi: ilkinji hata korporasynda, ikincisi hata ve hata boş paralel korporasynda. Biz şahsy token-derejesi düzenlemek üçin girdi teknisini hedefi düzeltmek üçin bejerdik Biziň iň gowy tek-modelimiz/ensemble GEC taggerimiz CONLL-2014 (test) we BEA-2019 (test) üstünde F_0.5 we F_0.5 we F_0.5 we 72.4/73.6 we BEA-2019 (test). Onuň ýüregi ýigrenişi terjime edip seq2seq GEC sistemi ýaly 10 gezek ýigrendir.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>اس کاغذ میں ہم ایک ساده اور فعال GEC سطح ٹاگر کو ترنسفور اکڈر کے مطابق پیش کرتے ہیں. ہمارا سیستم سینٹٹیسی ڈیٹی پر پہلے آموزش کی گئی ہے اور پھر دو مرحلے میں ٹھیک ترکیب کی گئی ہے: پہلے غلطی شرکت پر، اور دوسرے مرتبہ غلطی اور غلطی آزاد شرکت پر۔ ہم تخصوصی ٹوکین سطح کی تغییرات طراحی کرتے ہیں تاہل اصلاح کے لئے اینپیٹ ٹوکینوں کو نقشه بنانے کے لئے۔ ہمارے سب سے بہترین single-model/ensemble GEC ٹاگر کو CONLL-2014 پر F_0.5 اور F_0.5 کو BEA-2019 میں 72.4/73.6 (امتحان) حاصل کرتا ہے۔ اس کی نازل کی गति 10 بار زیادہ تیز ہے ترنسفور-بنیاد سیک2سک GEC سیسٹم کی طرح.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bu qogʻozda, biz Transformer encoder yordamida oddiy va effektiv GEC sequence tagger bilan ishlatimiz. Bizning tizimmiz birinchi tizimdan foydalanadi va keyin ikki darajada yaxshi bog'langan: birinchi xato kompaniyada, keyin xato va xato bilan parametrlarni birlashtirishda. Tekshirish uchun tugmalar birikmasini yaratish. Bizning eng yuqori bitta model/ensemble GEC tagger 65.3/66.5 da CONLL-2014 (test) va BEA-2019da 72.4/73.6 (test) uchun F_0.5 ta'ni topadi. Ko'rinishi tezligi Transformer asosida seq2seq GEC tizimi sifatida 10 marta tez.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Trong tờ giấy này, chúng tôi giới thiệu một máy tạo chuỗi GEC đơn giản và hiệu quả sử dụng bộ mã hóa biến hình. Hệ thống của chúng tôi được huấn luyện trước về dữ liệu nhân tạo và sau đó hoàn chỉnh theo hai giai đoạn: đầu tiên là cơ thể lỗi, và thứ hai là sự kết hợp giữa cơ thể song song lỗi và sai lầm. Thiết lập biến dạng biểu tượng để vẽ bản đồ những thẻ nhập để sửa mục tiêu. Cách mô phỏng duy nhất của chúng ta có thể đạt được một cỡ cỡ lớn C5 của 85.3/6. Tốc độ nhận ra của nó lên tới mười lần nhanh như một hệ thống phát dịch độc lập.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>本文中,发一用变压器编码器简高效GEC序识器。 合数预训练之,然后分两调:一曰谬语料库,次曰过差并行语料库。 设计自定义令牌级转,以将输令牌映射到的更正。 莫若单/集成 GEC 标记器于 CONLL-2014(试)上得 65.3/66.5 F_0.5,于 BEA-2019(试)得 72.4/73.6 F_0.5。 其推理速度,盖变压器之seq2seq GEC10倍之。</span></div></div><dl><dt>Anthology ID:</dt><dd>2020.bea-1.16</dd><dt>Volume:</dt><dd><a href=/volumes/2020.bea-1/>Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications</a></dd><dt>Month:</dt><dd>July</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Seattle, WA, USA → Online</dd><dt>Venues:</dt><dd><a href=/venues/acl/>ACL</a>
| <a href=/venues/bea/>BEA</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd><a href=/sigs/sigedu/>SIGEDU</a></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>163–170</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.bea-1.16>https://aclanthology.org/2020.bea-1.16</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/2020.bea-1.16 title="To the current version of the paper by DOI">10.18653/v1/2020.bea-1.16</a></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">omelianchuk-etal-2020-gector</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Kostiantyn Omelianchuk, Vitaliy Atrasevych, Artem Chernodub, and Oleksandr Skurzhanskyi. 2020. <a href=https://aclanthology.org/2020.bea-1.16>GECToR Grammatical Error Correction : Tag, Not RewriteGECToR – Grammatical Error Correction: Tag, Not Rewrite</a>. In <i>Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications</i>, pages 163–170, Seattle, WA, USA → Online. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2020.bea-1.16>GECToR Grammatical Error Correction : Tag, Not RewriteGECToR – Grammatical Error Correction: Tag, Not Rewrite</a> (Omelianchuk et al., BEA 2020)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2020.bea-1.16.pdf>https://aclanthology.org/2020.bea-1.16.pdf</a></dd><dt>Code</dt><dd><a href=https://github.com/grammarly/gector><i class="fab fa-github"></i>&nbsp;grammarly/gector</a>
+
<a href="https://paperswithcode.com/paper/?acl=2020.bea-1.16"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg>&nbsp;additional community code</a></dd><dt>Data</dt><dd><a href=https://paperswithcode.com/dataset/conll-2014-shared-task-grammatical-error>CoNLL-2014 Shared Task: Grammatical Error Correction</a>,&nbsp;<a href=https://paperswithcode.com/dataset/fce>FCE</a>,&nbsp;<a href=https://paperswithcode.com/dataset/locness-corpus>WI-LOCNESS</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2020.bea-1.16.pdf title="Open PDF of 'GECToR Grammatical Error Correction : Tag, Not RewriteGECToR – Grammatical Error Correction: Tag, Not Rewrite'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=GECToR+Grammatical+Error+Correction+%3A+Tag%2C+Not+RewriteGECToR+%E2%80%93+Grammatical+Error+Correction%3A+Tag%2C+Not+Rewrite" title="Search for 'GECToR Grammatical Error Correction : Tag, Not RewriteGECToR – Grammatical Error Correction: Tag, Not Rewrite' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-secondary d-flex flex-wrap justify-content-center" href="https://paperswithcode.com/paper/?acl=2020.bea-1.16" title="Code for 'GECToR Grammatical Error Correction : Tag, Not RewriteGECToR – Grammatical Error Correction: Tag, Not Rewrite' on Papers with Code"><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-big" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg><span class="pl-sm-2 d-none d-sm-inline">Code</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'GECToR Grammatical Error Correction : Tag, Not RewriteGECToR – Grammatical Error Correction: Tag, Not Rewrite'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[GECToR Grammatical Error Correction : Tag, Not RewriteGECToR – Grammatical Error Correction: Tag, Not Rewrite](https://aclanthology.org/2020.bea-1.16) (Omelianchuk et al., BEA 2020)</p><ul class=mt-2><li><a href=https://aclanthology.org/2020.bea-1.16>GECToR Grammatical Error Correction : Tag, Not RewriteGECToR – Grammatical Error Correction: Tag, Not Rewrite</a> (Omelianchuk et al., BEA 2020)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Kostiantyn Omelianchuk, Vitaliy Atrasevych, Artem Chernodub, and Oleksandr Skurzhanskyi. 2020. <a href=https://aclanthology.org/2020.bea-1.16>GECToR Grammatical Error Correction : Tag, Not RewriteGECToR – Grammatical Error Correction: Tag, Not Rewrite</a>. In <i>Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications</i>, pages 163–170, Seattle, WA, USA → Online. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>