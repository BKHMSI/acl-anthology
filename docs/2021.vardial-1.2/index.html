<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Hierarchical Transformer for Multilingual Machine Translation - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="Hierarchical Transformer for Multilingual Machine Translation" name=citation_title><meta content="Albina Khusainova" name=citation_author><meta content="Adil Khan" name=citation_author><meta content="Adín Ramírez Rivera" name=citation_author><meta content="Vitaly Romanov" name=citation_author><meta content="Proceedings of the Eighth Workshop on NLP for Similar Languages, Varieties and Dialects" name=citation_conference_title><meta content="2021/4" name=citation_publication_date><meta content="https://aclanthology.org/2021.vardial-1.2.pdf" name=citation_pdf_url><meta content="12" name=citation_firstpage><meta content="20" name=citation_lastpage><meta property="og:title" content="Hierarchical Transformer for Multilingual Machine Translation"><meta property="og:image" content="https://aclanthology.org/thumb/2021.vardial-1.2.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2021.vardial-1.2"><meta property="og:description" content="Albina Khusainova, Adil Khan, Adín Ramírez Rivera, Vitaly Romanov. Proceedings of the Eighth Workshop on NLP for Similar Languages, Varieties and Dialects. 2021."><link rel=canonical href=https://aclanthology.org/2021.vardial-1.2></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2021.vardial-1.2.pdf>Hierarchical Transformer for Multilingual Machine Translation</a>
<a id=af_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Hierariese Transformeerder vir Veelvuldige Masjien Vertaling</a>
<a id=am_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>ትርጉም</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>محول هرمي للترجمة الآلية متعددة اللغات</a>
<a id=az_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Çoxlu dilli Makin Çeviri üçün hiyerarşik transformatörü</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Йерархичен трансформатор за многоезичен машинен превод</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>বহুভাষী মেশিন অনুবাদের জন্য হিরেরাক্কিল ট্রান্সফার্নার</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>སྐད་རིགས་འདྲ་མིའི་ནང་གི་སྒྲིག་དབྱིབས་བསྒྱུར་བཅོས་བྱེད་པ</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Hijerarhički transformator za multijezički prevod mašine</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Transformador Hierarquic per traducció multilingüe de màquines</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Hierarchický transformátor pro vícejazyčný strojový překlad</a>
<a id=da_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Hierarkisk transformator til flersproget maskinoversættelse</a>
<a id=de_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Hierarchischer Transformator für mehrsprachige maschinelle Übersetzung</a>
<a id=el_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Ιεραρχικός μετασχηματιστής για πολυγλωσσική μηχανική μετάφραση</a>
<a id=es_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Transformador jerárquico para traducción automática multilingüe</a>
<a id=et_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Hierarhiline muundur mitmekeelse masintõlke jaoks</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Name</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Hierarkkinen muuntaja monikieliseen konekäännökseen</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Transformateur hiérarchique pour la traduction automatique multilingue</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Claochladán Ordlathach le haghaidh Aistriúchán Meaisín Ilteangach</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>@ item Text character set</a>
<a id=he_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>התמרת הייררכית לתרגום מכונות רבות שפתיים</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>बहुभाषी मशीन अनुवाद के लिए पदानुक्रमित ट्रांसफार्मर</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Hierarični transformator za multijezički prevod strojeva</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Hierarchikus transzformátor a többnyelvű gépi fordításhoz</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Բազլեզու մեքենայի թարգմանման գերախիկ վերածիչը</a>
<a id=id_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Transformer Hierarkis untuk Translation Multilingual Machine</a>
<a id=is_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Trasformatore gerarchico per traduzione automatica multilingue</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>多言語機械翻訳のための階層トランスフォーマー</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Piranti Pilihan Transformer kanggo Terjamahan Karo Multilanggar</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Name</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Көп тілдік машинаны аудару үшін хиерархикалық түрлендірушіName</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>다국어 기계 번역에 사용되는 차원 변환기</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Hierarchinis daugiakalbio mašinų vertimo transformatorius</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Hierarchical Transformer for Multilingual Machine Translation</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Multilingual Mashine Translation</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Ихэнх хэлний машин орчуулахын тулд гиерархик шилжүүлэгч</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Penukar Hierarkik untuk Penerjemahan Mesin Berbahasa</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Trasferiment Erarkiku għat-Traduzzjoni Multilingwi tal-Magni</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Hiërarchische transformator voor meertalige machinevertaling</a>
<a id=no_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Hierarisk transformer for fleirspråk maskinsomsetjing</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Transformator hierarchiczny do wielojęzycznego tłumaczenia maszynowego</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Transformador hierárquico para tradução automática multilíngue</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Transformator ierarhic pentru traducere automată multilingvă</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Иерархический трансформатор для многоязычного машинного перевода</a>
<a id=si_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>ගොඩක් භාෂාවක් මැෂින් පරිවර්තනය වෙනුවෙන් හියාර්චිකල් ප්‍රවර්තනය</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Hierarhični transformator za večjezični strojni prevod</a>
<a id=so_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Turjumista hierarchical for multiluqado badan</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Hierarchical Transformer for Multilingual Machine Translation</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Hijerarhički transformator za multijezički prevod mašine</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Hierarkisk transformator för flerspråkig maskinöversättning</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Tafsiri ya Kiingereza kwa Tafsiri ya Mashine ya Kilugha</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>பல்மொழி இயந்திரத்திற்கான மொழிமாற்றியமைப்பு</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Çoklu dilli maşynyň terjimesine üçin iýerarhiýal terjimeçi</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Multilingual Machine Translation for Hierarchical Transformer</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>Name</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>KCharselect unicode block name</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2021.vardial-1.2.pdf>多言机器翻译者转换器</a></h2><p class=lead><a href=/people/a/albina-khusainova/>Albina Khusainova</a>,
<a href=/people/a/adil-khan/>Adil Khan</a>,
<a href=/people/a/adin-ramirez-rivera/>Adín Ramírez Rivera</a>,
<a href=/people/v/vitaly-romanov/>Vitaly Romanov</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>The choice of parameter sharing strategy in multilingual machine translation models determines how optimally <a href=https://en.wikipedia.org/wiki/Parameter_space>parameter space</a> is used and hence, directly influences ultimate translation quality. Inspired by <a href=https://en.wikipedia.org/wiki/Tree_(graph_theory)>linguistic trees</a> that show the degree of relatedness between different languages, the new general approach to parameter sharing in multilingual machine translation was suggested recently. The main idea is to use these expert language hierarchies as a basis for multilingual architecture : the closer two languages are, the more parameters they share. In this work, we test this idea using the Transformer architecture and show that despite the success in previous work there are problems inherent to training such hierarchical models. We demonstrate that in case of carefully chosen training strategy the hierarchical architecture can outperform bilingual models and multilingual models with full parameter sharing.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Die keuse van parameter deel strategie in multilingual masjien vertaling modele bepaal hoe optimale parameter spasie gebruik word en daarom, direk influens die ultimate vertaling kwaliteit. Inspirasie deur lingvisse bome wat die grad van verwantigheid tussen verskillende tale vertoon het, het die nuwe algemene toegang tot parameter deel in multilingse masjien vertaling onlangs voorgestel. Die hoof idee is om hierdie ekspertiese taal hierarkies as 'n basis vir multilinglike arkitektuur te gebruik: die nader twee tale is, die meer parameters wat hulle deel. In hierdie werk, ons probeer hierdie idee deur die Transformer-arkitektuur te gebruik en wys dat, alhoewel die sukses in die vorige werk, daar is probleme wat onderwerp is om sodanige hierarkiese modele te onderwerp. Ons wys dat in geval van versigtig gekose onderwerp strategie kan die hierarkiese arkitektuur twee tale modele en multitaal modele uitvoer met volle parameter deel.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>በ多ልቋንቋ ቋንቋ ማተርጓም ሞዴዎች ውስጥ የፓርላማ ማጋራጨት ትርጉም ምረጡ እንዴት እንደሚጠቀሙ እና ከዚህ በኋላ በአዲስ መጨረሻ ትርጉም ጥሩ እንዲያስቀምጥ ይፈጥራል። በልዩ ቋንቋዎች መካከል ግንኙነት የሚያሳየው የቋንቋ ዛፎች በቋንቋዎች ላይ የሚታየው አዲስ የጠቅላላ አካባቢ ግንኙነት በብልልቋንቋ ቋንቋ መሳሳይ ትርጉም በመጠቀም ተግሳጽቷል፡፡ የዋነኛው አሳብ ይህ የቋንቋ አዳራሲ ቋንቋዎች መሠረታዊ መሠረት መሆኑን ለመጠቀም ነው፤ በጣም የቀረበ ሁለት ቋንቋዎች ናቸው፣ ይልቁንም ይጨማራሉ፡፡ በዚህ ሥራ፣ ይህንን አእምሮን የTransformer የመሠረተ ሥርዓት በመጠቀም እናሳያቸዋለን፣ የቀድሞው ስርዓት ምንም እንኳ እንደሆነ እንደዚህ ያለ hierarchical models ለማስተማር መከራዎች አሉ፡፡ በጥንቃቄ የተመረጠውን ትምህርት ማሰናከል፣ የሐራርካዊ መሠረተ ሥርዓት በሁለት ቋንቋዎች እና በብዙ ቋንቋዎች ዓይነቶች በሙሉ ተማሪዎች ማሳየት ይችላል፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>يحدد اختيار استراتيجية مشاركة المعلمات في نماذج الترجمة الآلية متعددة اللغات كيفية استخدام مساحة المعلمة على النحو الأمثل ، وبالتالي ، يؤثر بشكل مباشر على جودة الترجمة النهائية. مستوحى من الأشجار اللغوية التي تظهر درجة الارتباط بين اللغات المختلفة ، تم اقتراح النهج العام الجديد لمشاركة المعلمات في الترجمة الآلية متعددة اللغات مؤخرًا. الفكرة الرئيسية هي استخدام هذه التسلسلات الهرمية اللغوية المتخصصة كأساس للعمارة متعددة اللغات: كلما اقتربت لغتان ، زاد عدد المعلمات المشتركة بينهما. في هذا العمل ، نختبر هذه الفكرة باستخدام بنية Transformer ونوضح أنه على الرغم من النجاح في العمل السابق ، هناك مشاكل متأصلة في تدريب مثل هذه النماذج الهرمية. نوضح أنه في حالة استراتيجية التدريب المختارة بعناية ، يمكن للهندسة الهرمية أن تتفوق على النماذج ثنائية اللغة والنماذج متعددة اللغات مع مشاركة كاملة للمعلمات.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Çoxlu dilli maşın çevirim modellərində parametru paylaşım stratejisinin seçimi necə optimallı parametru alanı istifadə edir və buna görə də sonrakı çevirim keyfiyyətinə təsir edir. Müxtəlif dillər arasındakı bağlılıq dərəcəsini göstərən dil ağacları tarafından təşkil edildi, çoxlu dil makinelərin tercüməsində paylaşılması üçün yeni genel yol göstərildi. Ən böyük fikir, bu müxtəlif dil hiyerarhiyatlarını çoxlu dil arhitektarının əsası kimi istifadə etməkdir: ən yaxın iki dildir, daha çox parametrləri paylaşırlar. Bu işdə, biz bu ideyanı Transformer arhitektürünün vasitəsilə imtahana çəkirik və göstəririk ki, əvvəlki işin başarısızlığına baxmayaraq böyük hiyerarşik modellərini təhsil etmək üçün problemlər var. Biz göstəririk ki, təhsil müəyyən edilmiş təhsil strateji olaraq hiyerarşik arhitektura iki dil modellərini və çoxlu dil modellərini tam parametrləri paylaşdırması ilə daha üstün edə bilər.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Изборът на стратегия за споделяне на параметри в многоезичните модели за машинен превод определя как оптимално се използва пространството на параметрите и следователно пряко влияе върху върховното качество на превода. Вдъхновен от езиковите дървета, които показват степента на свързаност между различните езици, наскоро беше предложен нов общ подход към споделянето на параметри в многоезичния машинен превод. Основната идея е да се използват тези експертни езикови йерархии като основа за многоезична архитектура: колкото по-близки са двата езика, толкова повече параметри споделят. В тази работа тестваме тази идея с помощта на архитектурата на трансформатора и показваме, че въпреки успеха в предишната работа съществуват проблеми, присъщи на обучението на такива йерархични модели. Ние демонстрираме, че при внимателно подбрана стратегия за обучение йерархичната архитектура може да надмине двуезичните модели и многоезичните модели с пълно споделяне на параметри.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>মাল্টিভাল মেশিন অনুবাদ মডেলে প্যারামিটার শেয়ার করার কৌশলের বেছে নির্ধারণ করা যায় কিভাবে অপ্রায় পরামিটারের স্থান ব্যবহার করা হয় ভাষাভাষী গাছ দ্বারা অনুপ্রাণিত হয়েছে যা ভিন্ন ভাষার মধ্যে যুক্তি প্রদর্শন করে, সম্প্রতি মাল্টিভাষার মেশিন অনুবাদে প্যারামিটার শ প্রধান ধারণা হচ্ছে এই বিশেষজ্ঞ ভাষার হিয়ারার্কি ব্যবহার করা মাল্টিভাষা ভাষার প্রতিষ্ঠানের জন্য ভিত্তিক হিসেবে: দুই ভাষা এই কাজে আমরা এই চিন্তা পরীক্ষা করি ট্রান্সফার্ন আর্কিকেট ব্যবহার করে এবং দেখাচ্ছি যে আগের কাজের সফল সত্ত্বেও এই ধরনের হিরেরার্কিকাল আমরা দেখাচ্ছি যে সাবধানে প্রশিক্ষণ কৌশলের ক্ষেত্রে হিয়ারেক্যাল কাঠামো দুই ভাষার মডেল এবং বহুভাষায় মডেল প্রদর্শন করতে পারে পুরো প</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>The choice of parameter sharing strategy in multilingual machine translation models determines how optimally parameter space is used and hence, directly influences ultimate translation quality. Inspired by linguistic trees that show the degree of relatedness between different languages, the new general approach to parameter sharing in multilingual machine translation was suggested recently. The main idea is to use these expert language hierarchies as a basis for multilingual architecture: the closer two languages are, the more parameters they share. འོན་ཀྱང་། ང་ཚོས་གནས་སྟངས་འདི་ལྟ་བུའི་ནང་དུ་བཟོ་བཅོས་མཁན་གྱི་སྒྲིག་བརྩལ་བ་སྤྱོད་བཞིན་པའི་ལྟ་བུའི་ནང་དུ་གྲུབ་སྐྱོར་བ་རྒྱུན་ལྡ We demonstrate that in case of carefully chosen training strategy the hierarchical architecture can outperform bilingual models and multilingual models with full parameter sharing.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Izbor strategije dijeljenja parametara u multijezičkim modelima prevođenja mašina određuje kako se optimalno koristi prostor parametara i stoga direktno utiče na kvalitet prevođenja. Nedavno je predloženo novi generalni pristup dijeljenju parametara u multijezičkom prevodu strojeva. Glavna ideja je da koristimo ove hijerarhije stručnih jezika kao osnova za multijezičku arhitekturu: što je bliže dvije jezike, što više parametara dijele. U ovom poslu testiramo ovu ideju koristeći arhitekturu Transformera i pokazujemo da, uprkos uspjehu prethodnog posla, postoje problema koji su obučeni takvim hijerarhijskim modelima. Pokazujemo da u slučaju pažljivo izabrane strategije obuke hijerarhička arhitektura može izvršiti dvojezičke modele i multijezičke modele sa punim dijelom parametara.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>L'elecció de l'estratègia de compartir paràmetres en models multilingües de traducció de màquines determina com s'utilitza l'espai de paràmetres de manera optima i, per tant, influeix directament en la qualitat final de traducció. Inspirat pels arbres lingüístics que mostran el grau de relació entre les diferents llengües, fa poc va suggerir un nou enfocament general al compartir paràmetres en la traducció multilingüe de màquines. The main idea is to use these expert language hierarchies as a basis for multilingual architecture: the closer two languages are, the more parameters they share. En aquesta feina, provem aquesta idea utilitzant l'arquitectura Transformer i demostrem que malgrat l'èxit de la feina anterior hi ha problemes inherents a l'entrenament d'aquests models jeràrquics. Demonstrem que en el cas d'una estratègia de formació escollida amb cura l'arquitectura jeràrquica pot superar els models bilingües i multilingües amb un compartiment complet de paràmetres.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Volba strategie sdílení parametrů ve vícejazyčných modelech strojového překladu určuje, jak je optimálně využíván parametrový prostor, a tím přímo ovlivňuje maximální kvalitu překladu. Inspirován jazykovými stromy, které ukazují stupeň souvislosti mezi různými jazyky, byl v poslední době navržen nový obecný přístup ke sdílení parametrů ve vícejazyčném strojovém překladu. Hlavní myšlenkou je využít tyto odborné jazykové hierarchie jako základ pro vícejazyčnou architekturu: čím blíže jsou dva jazyky, tím více parametrů sdílejí. V této práci tuto myšlenku testujeme s využitím architektury Transformeru a ukážeme, že i přes úspěch v předchozí práci existují problémy s tréninkem těchto hierarchických modelů. Ukazujeme, že v případě pečlivě zvolené tréninkové strategie hierarchická architektura může překonat dvojjazyčné modely a vícejazyčné modely s plným sdílením parametrů.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Valget af parameterdelingsstrategi i flersprogede maskinoversættelsesmodeller bestemmer, hvor optimalt parameterpladsen anvendes, og påvirker dermed den ultimative oversættelseskvalitet direkte. Inspireret af sproglige træer, der viser graden af relaterethed mellem forskellige sprog, blev den nye generelle tilgang til parameterdeling i flersproget maskinoversættelse foreslået for nylig. Hovedideen er at bruge disse ekspertssproghierarkier som grundlag for flersproget arkitektur: Jo tættere to sprog er, jo flere parametre deler de. I dette arbejde tester vi denne idé ved hjælp af Transformer-arkitekturen og viser, at trods succesen i tidligere arbejde er der problemer forbundet med at træne sådanne hierarkiske modeller. Vi demonstrerer, at i tilfælde af nøje valgt træningsstrategi kan den hierarkiske arkitektur overgå tosprogede modeller og flersprogede modeller med fuld parameterdeling.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Die Wahl der Parametersharing-Strategie in mehrsprachigen maschinellen Übersetzungsmodellen bestimmt, wie der Parameterraum optimal genutzt wird und beeinflusst somit direkt die ultimative Übersetzungsqualität. Inspiriert von linguistischen Bäumen, die den Grad der Verwandtschaft zwischen verschiedenen Sprachen zeigen, wurde kürzlich der neue allgemeine Ansatz für die gemeinsame Nutzung von Parametern in mehrsprachigen maschinellen Übersetzungen vorgeschlagen. Die Grundidee ist, diese fachkundigen Sprachhierarchien als Grundlage für mehrsprachige Architektur zu nutzen: Je näher zwei Sprachen sind, desto mehr Parameter teilen sie sich. In dieser Arbeit testen wir diese Idee mit Hilfe der Transformer Architektur und zeigen, dass trotz des Erfolgs in früheren Arbeiten Probleme beim Training solcher hierarchischen Modelle bestehen. Wir zeigen, dass die hierarchische Architektur im Falle einer sorgfältig gewählten Trainingsstrategie zweisprachige Modelle und mehrsprachige Modelle mit vollständiger Parameterfreigabe übertreffen kann.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Η επιλογή της στρατηγικής κοινής χρήσης παραμέτρων σε πολυγλωσσικά μοντέλα μηχανικής μετάφρασης καθορίζει τον βέλτιστο τρόπο χρήσης του χώρου παραμέτρων και ως εκ τούτου επηρεάζει άμεσα την τελική ποιότητα μετάφρασης. Εμπνευσμένη από γλωσσικά δέντρα που δείχνουν τον βαθμό συσχέτισης μεταξύ διαφορετικών γλωσσών, προτείνεται πρόσφατα η νέα γενική προσέγγιση για την κοινή χρήση παραμέτρων στην πολυγλωσσική μηχανική μετάφραση. Η κύρια ιδέα είναι να χρησιμοποιηθούν αυτές οι εξειδικευμένες γλωσσικές ιεραρχίες ως βάση για την πολυγλωσσική αρχιτεκτονική: όσο πιο κοντά είναι οι δύο γλώσσες, τόσο περισσότερες παράμετροι μοιράζονται. Σε αυτή την εργασία, δοκιμάζουμε αυτή την ιδέα χρησιμοποιώντας την αρχιτεκτονική και δείχνουν ότι παρά την επιτυχία σε προηγούμενες εργασίες υπάρχουν προβλήματα εγγενή στην εκπαίδευση τέτοιων ιεραρχικών μοντέλων. Αποδεικνύουμε ότι σε περίπτωση προσεκτικά επιλεγμένης στρατηγικής εκπαίδευσης η ιεραρχική αρχιτεκτονική μπορεί να ξεπεράσει τα δίγλωσσα μοντέλα και τα πολύγλωσσα μοντέλα με πλήρη κοινή χρήση παραμέτρων.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>La elección de la estrategia de uso compartido de parámetros en los modelos de traducción automática multilingüe determina el uso óptimo del espacio de parámetros y, por lo tanto, influye directamente en la calidad de la traducción Inspirado en los árboles lingüísticos que muestran el grado de relación entre los diferentes idiomas, recientemente se sugirió el nuevo enfoque general para compartir parámetros en la traducción automática multilingüe. La idea principal es utilizar estas jerarquías lingüísticas expertas como base para una arquitectura multilingüe: cuanto más cerca estén dos idiomas, más parámetros comparten. En este trabajo, probamos esta idea utilizando la arquitectura Transformer y demostramos que, a pesar del éxito obtenido en trabajos anteriores, existen problemas inherentes al entrenamiento de tales modelos jerárquicos. Demostramos que, en el caso de una estrategia de capacitación cuidadosamente elegida, la arquitectura jerárquica puede superar a los modelos bilingües y multilingües con un intercambio completo de parámetros.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Parameetrite jagamise strateegia valik mitmekeelsetes masintõlkemudelites määrab, kuidas parameetrite ruumi optimaalselt kasutatakse, ning mõjutab seega otseselt ülimat tõlkekvaliteeti. Hiljuti pakuti välja uus üldine lähenemisviis parameetrite jagamisele mitmekeelses masintõlkes, inspireerituna keelepuudest, mis näitavad erinevate keelte vahelist seost. Põhieesmärk on kasutada neid ekspertkeele hierarhiaid mitmekeelse arhitektuuri alusena: mida lähemal kaks keelt on, seda rohkem parameetreid nad jagavad. Selles töös katsetame seda ideed Transformeri arhitektuuri abil ja näitame, et vaatamata varasemate tööde edule on selliste hierarhiliste mudelite koolitamisega seotud probleeme. Näitame, et hoolikalt valitud koolitusstrateegia korral suudab hierarhiline arhitektuur ületada kakskeelseid mudeleid ja mitmekeelseid mudeleid täieliku parameetrite jagamisega.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>انتخاب استراتژی تقسیم پارامتر در مدل ترجمه‌های ماشین‌های زیادی زبان تعریف می‌کند که چگونه فضای پارامتر optimally استفاده می‌شود و بنابراین، مستقیماً کیفیت ترجمه را تأثیر می‌دهد. توسط درختان زبان‌شناسی که درجه ارتباط بین زبان‌های مختلف را نشان می‌دهند، دستور جدید عمومی برای تقسیم پارامتر در ترجمه ماشین‌های زیادی زبان اخیرا پیشنهاد داده شد. ایده اصلی این است که از این مجموعه‌های زبان متخصص به عنوان بنیادی برای معماری بسیاری زبان استفاده کنیم: هر دو زبان نزدیک تر از آن است، هر پارامتری بیشتری که آنها را تقسیم می‌کنند. در این کار، ما این ایده را با استفاده از معماری تغییر دهنده آزمایش می‌کنیم و نشان می‌دهیم که با وجود موفقیت در کار قبلی مشکل‌هایی وجود دارد که برای آموزش چنین مدل‌های معماری هستند. ما نشان می دهیم که در مورد استراتژی آموزش با دقت انتخاب شده، معماری معماری الهی می تواند مدل های دو زبانی و مدل های متعدد زبانی را با مشترک پارامتر کامل انجام دهد.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Monikielisten konekäännösmallien parametrinjakostrategian valinta määrittää, miten optimaalisesti parametritilaa käytetään ja siten vaikuttaa suoraan käännöksen lopulliseen laatuun. Äskettäin ehdotettiin uutta yleistä lähestymistapaa parametrien jakamiseen monikielisessä konekäännöksessä, joka perustuu kielipuihin, jotka osoittavat eri kielten keskinäisen yhteyden. Pääajatuksena on käyttää näitä asiantuntijakielihierarkioita monikielisen arkkitehtuurin perustana: mitä lähempänä kaksi kieltä ovat, sitä enemmän parametreja ne jakavat. Tässä työssä testaamme tätä ajatusta Transformer-arkkitehtuurin avulla ja osoitamme, että huolimatta aiemman työn onnistumisesta tällaisten hierarkkisten mallien kouluttamiseen liittyy ongelmia. Osoitamme, että huolellisesti valitun koulutusstrategian tapauksessa hierarkkinen arkkitehtuuri voi suoriutua kaksikielisistä malleista ja monikielisistä malleista täydellä parametrien jakamisella.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Le choix de la stratégie de partage des paramètres dans les modèles de traduction automatique multilingues détermine la façon dont l'espace des paramètres est utilisé de manière optimale et influence donc directement la qualité finale de la traduction. Inspirée par les arbres linguistiques qui montrent le degré de parenté entre les différentes langues, la nouvelle approche générale du partage de paramètres dans la traduction automatique multilingue a récemment été suggérée. L'idée principale est d'utiliser ces hiérarchies linguistiques expertes comme base pour une architecture multilingue : plus les deux langues sont proches, plus elles partagent de paramètres. Dans ce travail, nous testons cette idée à l'aide de l'architecture Transformer et montrons que malgré le succès des travaux précédents, il existe des problèmes inhérents à la formation de tels modèles hiérarchiques. Nous démontrons qu'en cas de stratégie de formation soigneusement choisie, l'architecture hiérarchique peut surpasser les modèles bilingues et les modèles multilingues avec un partage complet des paramètres.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Cinneann rogha na straitéise comhroinnte paraiméadar i múnlaí aistriúcháin meaisín ilteangacha cé chomh optamach a úsáidtear spás paraiméadar agus mar sin bíonn tionchar díreach aige ar cháilíocht an aistriúcháin deiridh. Arna spreagadh ag crainn theangeolaíocha a thaispeánann an ghaolmhaireacht atá idir teangacha éagsúla, moladh le déanaí an cur chuige ginearálta nua maidir le paraiméadar a chomhroinnt san aistriúchán meaisín ilteangach. Is é an príomh-smaoineamh ná úsáid a bhaint as na sainordlathas teanga seo mar bhunús don ailtireacht ilteangach: dá gaire an dá theanga is ea is mó paraiméadair a roinneann siad. San obair seo, déanaimid tástáil ar an smaoineamh seo ag baint úsáide as ailtireacht an Trasfhoirmeora agus taispeánann sé go bhfuil fadhbanna bunúsacha ag baint le hoiliúint a chur ar mhúnlaí ordlathacha den sórt sin in ainneoin an rath a bhí ar obair roimhe seo. Léirímid, i gcás straitéise oiliúna a roghnaítear go cúramach, gur féidir leis an ailtireacht ordlathach sárobair a dhéanamh ar mhúnlaí dátheangacha agus ar mhúnlaí ilteangacha le comhroinnt iomlán na bparaiméadar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Zaɓi shirin shari da parameter cikin misãlai masu fassarar masu cikin birai na ƙidãya, yana bayyana yadda ake amfani da filin parameteri da kuma, a bayan haka, yana yi amfani da tsarin fassarar ta ƙarami. An Inspire shi da itãce na linguistic waɗanda ke nũna daraja na haɗuwa a tsakanin harshen daban, an buƙata wata hanyor zuwa sharing da parameter cikin fassarar masu multilingu na ƙarani. Maɓancin yana amfani da waɗannan hiera masu cikin harshen masu fitarwa kamar bango wa matsayin mulki-lingui: don harshen biyu masu kusantar, ko da takarda zasu share. Daga wannan aikin, Munã jarraba wannan idãnar da Muke amfani da ¦arkin Transformer kuma Muke nũna cewa, kõ da yaushe an sami cin nasara a gabanin aikin na farko, there za'a sami masu tsari misãlai masu hiera. Tuna nũna cewa, idan an ƙididdige tayari masu amfani da taƙaitacce, an iya samar da matsayin na'asar da misãlai biyu masu cikin lugha da cikakken parameteri.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>הבחירה של אסטרטגיה לחלוק פרמטרים בדוגמאות תרגום מכונות רבות שפויות קובעת איך אופטימית השתמש בחלל פרמטרים ולכן, ישירות משפיעה על איכות תרגום אולטימטיבית. Inspired by linguistic trees that show the degree of relatedness between different languages, the new general approach to parameter sharing in multilingual machine translation was suggested recently. הרעיון העיקרי הוא להשתמש בהיררכיות השפה המומחיות האלה כבסיס לארכיטקטורה רבת-שפתית: ככל שתי שפות קרובות יותר, כך הם חולקים יותר פרמטרים. בעבודה הזו, אנו מבחנים את הרעיון הזה באמצעות הארכיטקטורה הטרנספורטרית ולהראות שלמרות הצלחה בעבודה הקודמת יש בעיות הנכונות לאימון דוגמנים היררכיים כאלה. אנחנו מראים כי במקרה של אסטרטגיה אימונים שנבחרה בזהירות הארכיטקטורה היררכית יכולה להתגבר על דוגמנים שתיים-שפתיים ומדוגמנים רבות-שפתיים עם חלקת פרמטרים מלאה.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>बहुभाषी मशीन अनुवाद मॉडल में पैरामीटर साझा करण रणनीति का विकल्प यह निर्धारित करता है कि पैरामीटर स्थान का उपयोग कैसे किया जाता है और इसलिए, सीधे अंतिम अनुवाद गुणवत्ता को प्रभावित करता है। भाषाई पेड़ों से प्रेरित होकर जो विभिन्न भाषाओं के बीच संबंधितता की डिग्री दिखाते हैं, बहुभाषी मशीन अनुवाद में पैरामीटर साझा करने के लिए नए सामान्य दृष्टिकोण का सुझाव हाल ही में दिया गया था। मुख्य विचार बहुभाषी वास्तुकला के लिए एक आधार के रूप में इन विशेषज्ञ भाषा पदानुक्रमों का उपयोग करना है: दो भाषाएं जितनी करीब होंगी, वे उतने ही अधिक पैरामीटर साझा करते हैं। इस काम में, हम ट्रांसफॉर्मर आर्किटेक्चर का उपयोग करके इस विचार का परीक्षण करते हैं और दिखाते हैं कि पिछले काम में सफलता के बावजूद ऐसे पदानुक्रमित मॉडल को प्रशिक्षित करने के लिए अंतर्निहित समस्याएं हैं। हम प्रदर्शित करते हैं कि सावधानीपूर्वक चुनी गई प्रशिक्षण रणनीति के मामले में पदानुक्रमित वास्तुकला पूर्ण पैरामीटर साझाकरण के साथ द्विभाषी मॉडल और बहुभाषी मॉडल को मात दे सकती है।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Izbor strategije dijeljenja parametara u multijezičkim modelima prevoda uređaja određuje kako se optimalno koristi prostor parametara, i stoga izravno utječe na konačnu kvalitet prevoda. Nedavno je predloženo novi opći pristup dijeljenju parametara u multijezičkom prevodu strojeva. Glavna ideja je koristiti ove hijerarhije stručnih jezika kao temelj za multijezičku arhitekturu: što je bliže dvije jezike, što više parametara dijele. U ovom poslu testiramo ovu ideju koristeći arhitekturu transformera i pokazujemo da, uprkos uspjehu prethodnog posla, postoje problema koji su uključujući obuku takvih hijerarhijskih modela. Pokazujemo da u slučaju pažljivo izabrane strategije obuke hijerarhička arhitektura može izvršiti dvojezičke modele i multijezičke modele sa punim dijelom parametara.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A többnyelvű gépi fordítási modellek paramétermegosztási stratégiájának megválasztása határozza meg, hogy a paraméterek optimális felhasználását hogyan használják, és így közvetlenül befolyásolja a végső fordítási minőséget. A különböző nyelvek közötti kapcsolat mértékét mutató nyelvi fák inspirálták a közelmúltban a többnyelvű gépi fordítás paramétereinek megosztására vonatkozó új általános megközelítést javasolták. A fő ötlet az, hogy ezeket a szakértői nyelvi hierarchiákat használjuk a többnyelvű architektúra alapjaként: minél közelebb van a két nyelv, annál több paramétert osztanak meg. Ebben a munkában ezt az ötletet a Transformer architektúrával teszteljük, és megmutatjuk, hogy a korábbi munkák sikere ellenére az ilyen hierarchikus modellek képzésének problémái vannak. Bemutatjuk, hogy gondosan megválasztott képzési stratégia esetén a hierarchikus architektúra teljes paraméterek megosztásával felülmúlhatja a kétnyelvű modelleket és a többnyelvű modelleket.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Բազլեզու մեքենայի թարգմանման մոդելների պարամետրերի կիսման ռազմավարության ընտրությունը որոշում է, թե ինչպես է օպտիմալ պարամետրերի տարածքը օգտագործվում և հետևաբար, անմիջապես ազդում է վերջնական թարգմանման որակին: Inspired by linguistic trees that show the degree of relatedness between different languages, the new general approach to parameter sharing in multilingual machine translation was suggested recently. Հիմնական գաղափարն այն է, որ այս մասնագետների լեզվի հիերարխիաները օգտագործենք որպես բազլեզու ճարտարապետության հիմք. որքան ավելի մոտ են երկու լեզուները, այնքան ավելի շատ պարամետրեր են նրանք կիսում: Այս աշխատանքի ընթացքում մենք փորձում ենք այս գաղափարը օգտագործելով Թանֆերմերների ճարտարապետությունը և ցույց ենք տալիս, որ չնայած նախորդ աշխատանքի հաջողության, կան խնդիրներ, որոնք բնորոշ են նման հիերարխիկ մոդելների Մենք ցույց ենք տալիս, որ ուշադիր ընտրված ուսումնասիրության ռազմավարության դեպքում հիերարխիկ ճարտարապետությունը կարող է գերազանցել երկլեզու մոդելները և բազլեզու մոդելները՝ ամբողջ պարամետրերի կիսվելով:</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>The choice of parameter sharing strategy in multilingual machine translation models determines how optimally parameter space is used and hence, directly influences ultimate translation quality. Terinspirasi oleh pohon bahasa yang menunjukkan tingkat hubungan antara bahasa yang berbeda, pendekatan umum baru untuk berbagi parameter dalam terjemahan mesin berbilang bahasa baru-baru ini disarankan. The main idea is to use these expert language hierarchies as a basis for multilingual architecture: the closer two languages are, the more parameters they share. Dalam pekerjaan ini, kami menguji ide ini menggunakan arsitektur Transformer dan menunjukkan bahwa meskipun sukses dalam pekerjaan sebelumnya ada masalah yang tergantung pada pelatihan model hierarkis seperti itu. Kami menunjukkan bahwa dalam kasus strategi latihan yang dipilih dengan hati-hati arsitektur hierarkis dapat melebihi model dua bahasa dan model berbilang bahasa dengan berbagi parameter penuh.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>La scelta della strategia di condivisione dei parametri nei modelli di traduzione automatica multilingue determina l'utilizzo ottimale dello spazio dei parametri e quindi influenza direttamente la qualità della traduzione finale. Ispirato da alberi linguistici che mostrano il grado di relazione tra le diverse lingue, è stato recentemente suggerito il nuovo approccio generale alla condivisione dei parametri nella traduzione automatica multilingue. L'idea principale è quella di utilizzare queste gerarchie linguistiche esperte come base per l'architettura multilingue: più sono vicine due lingue, più parametri condividono. In questo lavoro, testiamo questa idea utilizzando l'architettura Transformer e mostriamo che nonostante il successo nel lavoro precedente ci sono problemi inerenti alla formazione di tali modelli gerarchici. Dimostriamo che in caso di strategia formativa accuratamente scelta l'architettura gerarchica può superare modelli bilingui e modelli multilingue con condivisione completa dei parametri.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>多言語機械翻訳モデルにおけるパラメータ共有戦略の選択は、パラメータ空間がどのように最適に使用されるかを決定し、したがって、究極の翻訳品質に直接影響を与えます。異なる言語間の関連性の程度を示す言語ツリーに触発されて、多言語機械翻訳におけるパラメータ共有の新しい一般的なアプローチが最近提案された。主なアイデアは、これらのエキスパート言語の階層を多言語アーキテクチャの基礎として使用することです。2つの言語が近いほど、パラメータがより共有されます。この作業では、トランスフォーマーのアーキテクチャを使用してこのアイデアをテストし、以前の作業で成功したにもかかわらず、そのような階層モデルをトレーニングするには固有の問題があることを示します。慎重に選択されたトレーニング戦略の場合、階層的アーキテクチャは、完全なパラメータ共有でバイリンガルモデルや多言語モデルを上回ることができることを実証します。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>translation Ngubah bener Piyambak luwih apik lan gambar aturan kanggo nggawe luwih apik karo akeh basa kanggo arquitur multilanggar: akeh langgar sampeyan sing luwih apik, akeh sabên langgar sapa nyimpen. Nang barêng-barêng iki, kéné ujian akeh iki ning gambar architecture Transformer sampeyan ngono kuwi bagian sing perbudhakan kanggo nggawe barang nggawe barang kelas kuwi kudu nggawe sistem sing berarti kuwi mau. Awak dhéwé éntuk éntuk ngono cah akeh nggawe aturan sing paling berarti maneh karo akeh perusahaan winih lan model multilanggar sampek ndelak dhéwé karo perusahaan parameter.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>პარამეტრის გაყოფილი სტრატიგიის არჩევა მრავალენგური მანქანის გაგრძელების მოდელში განსაზღვრავს თუ როგორ ოპრამეტრის სივრცე გამოიყენება და ამიტომ, Direktively გამოიყენ ლენგურისტიკური ხეები, რომლებიც განსხვავებული ენების განმავლობაში დაკავშირებულების დონე, ახალი საერთო პროგრამის გაყოფილი პარამეტრების განმავლობაში მრავალენგური მაქინის განმავლ მნიშვნელოვანი იდეა, რომ ამ ექსპერტის ენის ჰიერაქტის გამოყენება მნიშვნელოვანი აქტიქტიქტიკის ბაზი: ორი ენები უფრო კიდევ, რაც უფრო მეტი პარამეტრები იყო ამ სამუშაოში, ჩვენ შევცვალოთ ეს იდეა ტრანფორმეტრის აქტიქტიქტურის გამოყენებით და ჩვენ ჩვენებთ, რომ წინა სამუშაო სამუშაო მუშაოდ არსებობს პრობლემები ჩვენ ევმონსტრაცით, რომ აღმოჩნეთ სტრატიფიკალური სტრატიფიკალური სტრატიქტიკალური მოდელები და მრავალენგური მოდელები შეუძლიათ გავაკეთოთ სრულ პარამეტრის გაყო</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Көптеген тілдік ортақтастыру стратегиясын бірнеше тілдік компьютер аудару үлгілерінде параметрлерді ортақтастыру стратегиясының таңдауы керек параметрлердің ортасын қалай қолданылатын аны Басқа тілдер арасындағы лингвистикалық ағаштардың қатынасын көрсетеді. Жаңа параметрлерді бірнеше тілдер аудармасында ортақтастыру үшін жаңа жалпы қатынасы жуырда ұсынылды. Негізгі идея - бұл эксперт тіл иерархиясын көптілік архитектурасының негізінде қолдану: екі тіл жақын, олардың ортақ параметрлері көп. Бұл жұмыс ішінде, біз бұл идеяны түрлендіруші архитектурасын қолданып, алдыңғы жұмыстың сәттілігіне қарамастан, бұл иерархиялық моделдерді оқыту үшін мәселелер бар. Біз тәжірибе таңдалған оқыту стратегиясы болса, иерархиялық архитектура екі тіл үлгілерін және көп тіл үлгілерін толық параметрлерді ортақтастыруға болады.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>다중 언어 기계 번역 모델에서 매개 변수 공유 전략의 선택은 매개 변수 공간의 가장 좋은 사용을 결정하고 최종 번역의 질에 직접적인 영향을 미친다.서로 다른 언어 간의 연관성을 나타내는 언어 트리의 계발을 받아 최근 새로운 통용 다언어 기계 번역 파라미터 공유 방법을 제시했다.그 주요 사상은 이런 전문가들의 언어 차원 구조를 다중 언어 체계 구조의 기초로 사용하는 것이다. 두 언어가 가까울수록 그들이 공유하는 파라미터가 많아진다.이 작업에서 우리는 Transformer 구조를 이용하여 이 생각을 테스트했고 이전의 작업에서 성공을 거두었지만 이런 차원 모델을 훈련할 때 여전히 고유한 문제가 존재한다는 것을 나타냈다.우리는 정성스럽게 선택한 훈련 전략의 상황에서 층 구조가 이중 언어 모델과 완전한 파라미터가 공유하는 다중 언어 모델보다 우수하다는 것을 증명했다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Pasirinkus parametrų pasidalijimo strategiją daugiakalbėse mašin ų vertimo modeliuose nustatoma, kaip optimaliai naudojama parametrų erdvė, taigi tiesiogiai daroma įtaka galutinei vertimo kokybei. Neseniai pasiūlytas naujas bendras požiūris į dalijimąsi parametrais daugiakalbio vertimo mašinomis metodu, įkvėptas kalbiniais medžiais, kurie rodo skirtingų kalbų ryšį. Pagrindinė idėja – naudoti šias ekspertų kalbų hierarchijas kaip daugiakalbės architektūros pagrindą: kuo artimesnės dvi kalbos, tuo daugiau parametrų jos dalijasi. Šiame darbe išbandome šią idėją naudojant Transformer architektūrą ir parodysime, kad nepaisant ankstesnio darbo sėkmės kyla problemų, susijusių su tokių hierarchinių modelių mokymu. Mes įrodome, kad kruopščiai pasirinktos mokymo strategijos atveju hierarchinė architektūra gali būti didesnė už dvikalbius modelius ir daugiakalbius modelius, visiškai dalijantis parametrais.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Изборот на стратегија за поделба на параметри во мултијазичните машински модели за превод одредува како се користи оптимално параметралниот простор и, со тоа, директно влијае врз апсолутниот квалитет на превод. Inspired by linguistic trees that show the degree of relatedness between different languages, the new general approach to parameter sharing in multilingual machine translation was suggested recently. The main idea is to use these expert language hierarchies as a basis for multilingual architecture: the closer two languages are, the more parameters they share. Во оваа работа, ја тестираме оваа идеја користејќи ја трансформираната архитектура и покажуваме дека и покрај успехот во претходната работа постојат проблеми поврзани со обуката на вакви хиерархички модели. Демонстрираме дека во случај на внимателно избрана стратегија за обука хиерархиската архитектура може да ги надмине двојјазичните модели и мултијазичните модели со целосно споделување на параметрите.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>പലില്ലാത്ത മെഷിന്‍ പരാമീറ്റര്‍ പങ്കെടുക്കുന്ന സ്ട്രാറ്റിജിയില്‍ പങ്കെടുക്കുന്നതിന്റെ തിരഞ്ഞെടുക്കുക, എങ്ങനെയാണ് പാ വ്യത്യസ്ത ഭാഷകള്‍ക്കിടയിലുള്ള ബന്ധം കാണിക്കുന്ന ഭാഷ്ട്രീകളാല്‍ ഭാഷയിലുള്ള വൃക്ഷങ്ങള്‍ നിര്‍ദ്ദേശിക്കുന്നു. അടുത്തുതന്നെ പല പ്രധാനപ്പെട്ട ഐഡിയയാണ് ഈ വിശേഷ ഭാഷയുടെ ഹിയേരാര്‍ക്കികള്‍ പല ഭാഷകളുടെ സ്ഥാനത്തിന്റെ അടിസ്ഥാനമായി ഉപയോഗിക്കുന്നത്: അടുത ഈ ജോലിയില്‍, നമ്മള്‍ ഈ ഐഡിയ പരീക്ഷിക്കുന്നു, ട്രാന്‍സ്ഫോര്‍മാന്‍ ആര്‍ക്കിക്കറ്റര്‍ ഉപയോഗിച്ച് കാണിക്കുന്നു. മുമ്പ് ജോലിയി സൂക്ഷ്മമായി തിരഞ്ഞെടുത്ത പരിശീലനത്തിന്റെ ട്രെയിനിജ്ജിയുടെ കാര്യത്തില്‍ ഹിയെരാര്‍ക്കിക്കല്‍ ആര്‍ക്ടിക്കറ്റിക്കാര്‍ക്ക</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Олон хэлний машины орчуулах загварын параметр хуваалцах стратегийн сонголт нь хэрхэн эерэг параметр орон зай хэрхэн ашигладгийг тодорхойлдог бөгөөд энэ нь шууд орчуулах чадварыг нөлөөлдөг. Өөр хэл хоорондын харилцааны түвшинд харилцааны хэлний модонуудын гайхалтай санагдаж, олон хэл хэлний машины хөрөнгө хуваалцааны шинэ ерөнхий арга зам нь саяхан санал болсон. Хамгийн гол санаа нь эдгээр мэргэжлийн хэл төрлийн архитектуруудыг олон хэл бүтээгдэхүүний суурь болгон ашиглах юм: хамгийн ойрхон хоёр хэл нь, тэдний хуваалцах илүү параметр юм. Энэ ажлын тулд бид энэ санааг Трансформфер архитектурыг ашиглан шалгаж, өмнөх ажлын амжилтын үр дүнд ч ийм төрлийн загваруудыг суралцах асуудлууд байдаг. Бид анхаархан сонгогдсон сургалтын стратегийг харуулж байна. Иерархик архитектур нь хоёр хэл загвар болон олон хэл загваруудыг бүрэн параметр хуваалцаж чадна.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Pilihan strategi berkongsi parameter dalam model terjemahan mesin berbilang bahasa menentukan bagaimana ruang parameter optimal digunakan dan oleh itu, secara langsung mempengaruhi kualiti terjemahan terbaik. Diinspirasi oleh pokok bahasa yang menunjukkan darjah hubungan antara bahasa berbeza, pendekatan umum baru untuk berkongsi parameter dalam terjemahan mesin berbilang bahasa telah disarankan baru-baru ini. Idea utama ialah menggunakan hierarki bahasa ahli ini sebagai dasar untuk arkitektur berbilang bahasa: semakin dekat dua bahasa, semakin banyak parameter yang mereka berkongsi. Dalam kerja ini, kami menguji idea ini menggunakan arkitektur Transformer dan menunjukkan bahawa walaupun sukses dalam kerja sebelumnya terdapat masalah yang berkaitan dengan latihan model hierarkis seperti itu. We demonstrate that in case of carefully chosen training strategy the hierarchical architecture can outperform bilingual models and multilingual models with full parameter sharing.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>The choice of parameter sharing strategy in multilingual machine translation models determines how optimally parameter space is used and hence, directly influences ultimate translation quality. Sperit minn siġar lingwistiċi li juru l-grad ta’ rabta bejn ilsna differenti, dan l-aħħar ġie ssuġġerit approċċ ġenerali ġdid għall-qsim tal-parametri fit-traduzzjoni tal-magni multilingwi. L-idea ewlenija hija li jintużaw dawn il-ġerarkiji tal-lingwi esperti bħala bażi għall-arkitettura multilingwi: aktar ikunu eqreb iż-żewġ lingwi, aktar parametri jaqsmu. F’dan ix-xogħol, nistestjaw din l-idea bl-użu tal-arkitettura Transformer u nuru li minkejja s-suċċess fix-xogħol preċedenti hemm problemi inerenti għat-taħriġ ta’ mudelli ġerarkiċi bħal dawn. Aħna nuru li fil-każ ta’ strateġija ta’ taħriġ magħżula bir-reqqa l-arkitettura ġerarkika tista’ taqbeż il-mudelli bilingwi u mudelli multilingwi b’kondiviżjoni sħiħa tal-parametri.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>De keuze van de strategie voor het delen van parameters in meertalige machinevertaalmodellen bepaalt hoe optimaal de parameterruimte wordt gebruikt en beïnvloedt daarmee direct de uiteindelijke vertaalkwaliteit. Geïnspireerd door taalbomen die de mate van verwantschap tussen verschillende talen tonen, werd onlangs de nieuwe algemene benadering voor het delen van parameters in meertalige machinevertaling voorgesteld. Het belangrijkste idee is om deze deskundige taalhiërarchieën te gebruiken als basis voor meertalige architectuur: hoe dichter de twee talen zijn, hoe meer parameters ze delen. In dit werk testen we dit idee met behulp van de Transformer architectuur en laten we zien dat ondanks het succes in eerdere werken er problemen inherent zijn aan het trainen van dergelijke hiërarchische modellen. We tonen aan dat in geval van zorgvuldig gekozen trainingsstrategie de hiërarchische architectuur tweetalige modellen en meertalige modellen met volledige parameterdeling kan overtreffen.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Valet til å dele strategi for parametrar i fleirspråk maskineomsetjingsmodular bestemmer korleis optimalt parametrarom vert brukt og derfor direkte påvirkar endringskvalitet for omsetjingar. I løpet av lingviske trær som viser kor mykje relatede mellom ulike språk, vart nyleg foreslått den nye generelle tilnærming til å dele parametrar i fleirspråksomsetjinga. Hovudsideen er å bruka disse ekspertspråkehierarkitene som grunnlag for fleirspråk arkitektur: dei nærmere to språke er, dei fleire parametra dei deler. I denne arbeida testerer vi denne ideen ved å bruka Transformeringsarkitekturen og vise at selv om suksessen i tidlegare arbeid er det problema som er tilhøyrande å lære slike hierarkiske modeller. Vi demonstrerer at i tilfelle med forsiktig valt treingingsstrategi kan hierarkiske arkitekturen utføre bilinguelmodeller og fleirspråk modeller med fullstendig deling av parametrar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Wybór strategii udostępniania parametrów w wielojęzycznych modelach tłumaczeń maszynowych określa optymalne wykorzystanie przestrzeni parametrów, a tym samym bezpośrednio wpływa na najwyższą jakość tłumaczenia. Zainspirowane drzewami językowymi, które pokazują stopień powiązania między różnymi językami, zaproponowano ostatnio nowe ogólne podejście do współdzielenia parametrów w wielojęzycznym tłumaczeniu maszynowym. Główną ideą jest wykorzystanie tych specjalistycznych hierarchii językowych jako podstawy architektury wielojęzycznej: im bliżej są dwa języki, tym więcej parametrów mają wspólne. W niniejszej pracy testujemy ten pomysł przy użyciu architektury Transformera i pokazujemy, że pomimo sukcesu w poprzednich pracach istnieją problemy nieodłączne z szkoleniem takich hierarchicznych modeli. Pokazujemy, że w przypadku starannie dobranej strategii szkoleniowej architektura hierarchiczna może przewyższyć modele dwujęzyczne i modele wielojęzyczne z pełnym współdzieleniem parametrów.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A escolha da estratégia de compartilhamento de parâmetros em modelos de tradução automática multilíngue determina como o espaço de parâmetros é usado de maneira ideal e, portanto, influencia diretamente a qualidade final da tradução. Inspirada em árvores linguísticas que mostram o grau de parentesco entre diferentes idiomas, a nova abordagem geral para compartilhamento de parâmetros na tradução automática multilíngue foi sugerida recentemente. A ideia principal é usar essas hierarquias de linguagens especializadas como base para a arquitetura multilíngue: quanto mais próximas duas linguagens estiverem, mais parâmetros eles compartilham. Neste trabalho, testamos essa ideia usando a arquitetura Transformer e mostramos que apesar do sucesso em trabalhos anteriores existem problemas inerentes ao treinamento de tais modelos hierárquicos. Demonstramos que, no caso de uma estratégia de treinamento cuidadosamente escolhida, a arquitetura hierárquica pode superar modelos bilíngues e modelos multilíngues com compartilhamento completo de parâmetros.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Alegerea strategiei de partajare a parametrilor în modelele de traducere automată multilingvă determină modul în care este utilizat optim spațiul parametrilor și, prin urmare, influențează direct calitatea finală a traducerii. Inspirată de arbori lingvistici care arată gradul de relație dintre diferitele limbi, noua abordare generală a partajării parametrilor în traducerea automată multilingvă a fost sugerată recent. Ideea principală este de a utiliza aceste ierarhii lingvistice experți ca bază pentru arhitectura multilingvă: cu cât sunt mai apropiate două limbi, cu atât împărtășesc mai mulți parametri. În această lucrare, testăm această idee folosind arhitectura Transformer și arătăm că, în ciuda succesului în lucrările anterioare, există probleme inerente formării unor astfel de modele ierarhice. Demonstrăm că în cazul strategiei de formare alese cu atenție arhitectura ierarhică poate depăși modelele bilingve și multilingve cu partajarea completă a parametrilor.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Выбор стратегии совместного использования параметров в многоязычных моделях машинного перевода определяет оптимальное использование пространства параметров и, следовательно, непосредственно влияет на конечное качество перевода. Вдохновленный лингвистическими деревьями, которые показывают степень взаимосвязи между различными языками, недавно был предложен новый общий подход к распределению параметров в многоязычном машинном переводе. Основная идея - использовать эти языковые иерархии экспертов в качестве основы для многоязычной архитектуры: чем ближе два языка, тем больше у них общих параметров. В этой работе мы тестируем эту идею с использованием архитектуры Трансформатора и показываем, что, несмотря на успех в предыдущей работе, существуют проблемы, присущие обучению таким иерархическим моделям. Мы демонстрируем, что в случае тщательно подобранной стратегии обучения иерархическая архитектура может превосходить двуязычные модели и многоязычные модели с полным обменом параметрами.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ගොඩක් භාෂාවක් පද්ධතිය පද්ධතිය පද්ධතිය අනුවාර්ථ විශේෂයෙන් ප්‍රතිභාවිතයේ තෝරණය තෝරණය නිර්ධාරණය කර වෙනස් භාෂාවල් අතර සම්බන්ධතාවක් පෙන්වන්න භාෂාවල් වලින් ප්‍රශ්නයක් තියෙන්නේ, අලුත් සාමාන්‍ය ප්‍රශ්නයක් ප්‍රධාන අදහසය තමයි මේ විශ්වාසික භාෂාව අයිරිෂ්ටියව භාවිතා කරන්න බොහොම භාෂාව සංවිධානයක් විදිහට: වඩ මේ වැඩේ අපි මේ අදහසක් පරීක්ෂා කරනවා මේ අදහසක් ප්‍රවේශකයේ ස්ථාපනය කරන්න සහ පෙන්වන්නේ, මුලින් වැඩේ වැඩේ සාර්ථක වැඩේ අපි පැහැදිලි කරනවා කියලා පරික්ෂා විදිහට තෝරාගන්න පුළුවන් පුළුවන් විදිහට පරික්ෂා විදිහට පරික්ෂා විදිහ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Izbira strategije delitve parametrov v večjezičnih modelih strojnega prevajanja določa, kako optimalno se uporablja prostor parametrov in s tem neposredno vpliva na končno kakovost prevajanja. Na podlagi jezikovnih dreves, ki kažejo stopnjo povezanosti med različnimi jeziki, je bil pred kratkim predlagan nov splošni pristop k delitvi parametrov v večjezičnem strojnem prevajanju. Glavna ideja je uporaba teh strokovnih jezikovnih hierarhij kot osnove za večjezično arhitekturo: bližje kot sta dva jezika, več parametrov si delita. V tem delu preizkušamo to idejo s pomočjo arhitekture transformatorjev in pokažemo, da kljub uspehu pri prejšnjem delu obstajajo težave pri usposabljanju takšnih hierarhičnih modelov. Pokazali smo, da lahko v primeru skrbno izbrane strategije usposabljanja hierarhična arhitektura presega dvojezične modele in večjezične modele s popolno delitvijo parametrov.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Doorashada qayb-qaybinta parameter ee noocyada turjumaadda luuqadaha kala duduwan ayaa go’aan ku saameysanaya sida loo isticmaalayo goobta parameter, taas darteed wuxuu toos u saameyn ku yeelanayaa qiimaha ugu danbeeya turjumaadda. Waxaa la soo dhiibay geedaha luuqadaha ku qoran oo muujiya shahaadada xiriirka luuqadaha kala duduwan, ugu dhowaad waxaa la soo jeeday qaababka cusub ee ku saabsan parameter ku saabsan turjumidda machine luuqadaha kala duduwan. Fikirada ugu horeysa waa in lagu isticmaalaa hierarkii luuqada khaaska ah sida aasaasi ah dhismaha luuqadaha kala duduwan: labada luqadood ee ugu dhow waa, si kamid ah oo ay u qeybiyaan. Markaas waxan, waxaynu tijaabinaynaa fikradan isticmaalka dhismaha turjumista iyo waxaynu tusaynaa in despite guulaysta shaqada hore dhibaatooyin ku jirta waxbarashada tusaalaha hierarkiisa ah. Waxaynu muujinnaa in marka qoraalka waxbarashada si taxadar leh loo doortay, dhismaha hierarkiis wuxuu sameyn karaa tusaalooyin labaad oo kala duduwan iyo tusaalooyin kala duduwan oo kala duduwan oo wada qaybsan parameter.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>The choice of parameter sharing strategy in multilingual machine translation models determines how optimally parameter space is used and hence, directly influences ultimate translation quality. Inspiruar nga pemët gjuhësore që tregojnë shkallën e lidhjes midis gjuhëve të ndryshme, u sugjerua kohët e fundit metoda e re e përgjithshme për ndarjen e parametrave në përkthimin shumëgjuhës të makinave. Ideja kryesore është të përdorim këto hierarki gjuhësh eksperte si bazë për arkitekturën shumëgjuhëse: sa më afër janë dy gjuhët, aq më shumë parametra ndajnë. Në këtë punë, ne e testojmë këtë ide duke përdorur arkitekturën Transformer dhe tregojmë se pavarësisht nga suksesi në punën e mëparshme ka probleme inerente në trajnimin e modeleve të tilla hierarkike. Ne demonstrojmë se në rast të strategjisë së trajnimit të zgjedhur me kujdes arkitektura hierarkike mund të kalojë modelet dygjuhëse dhe modelet shumëgjuhëse me ndarjen e plotë të parametrave.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Izbor strategije za dijeljenje parametara u modelima prevođenja multijezičkih mašina određuje kako se optimalno koristi prostor parametara, i stoga direktno utiče na kvalitet prevođenja. Inspirirali su jezički drveći koji pokazuju stepen odnosa između različitih jezika, nedavno je predložen novi opći pristup delivanju parametara u multijezičkom prevodu mašine. Glavna ideja je da koristimo ove hijerarhije stručnih jezika kao osnova za multijezičku arhitekturu: što je bliže dve jezike, što više parametra podijele. U ovom poslu, testiramo ovu ideju koristeći arhitekturu transformera i pokažemo da, uprkos uspjehu prethodnog posla, postoje problema koji su uključeni obuku takvih hijerarhijskih modela. Pokazujemo da u slučaju pažljivo izabrane strategije obuke hijerarhička arhitektura može izvršiti dvojezičke modele i multijezičke modele sa punim dijelom parametara.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Valet av parameterdelningsstrategi i flersprﾃ･kiga maskinﾃｶversﾃ､ttningsmodeller avgﾃｶr hur optimalt parameterutrymme anvﾃ､nds och pﾃ･verkar dﾃ､rmed den ultimata ﾃｶversﾃ､ttningskvaliteten direkt. Inspirerad av sprﾃ･kliga trﾃ､d som visar graden av samband mellan olika sprﾃ･k, fﾃｶreslogs nyligen en ny allmﾃ､n strategi fﾃｶr parameterdelning i flersprﾃ･kig maskinﾃｶversﾃ､ttning. Huvudidﾃｩn ﾃ､r att anvﾃ､nda dessa expertsprﾃ･khierarkier som grund fﾃｶr flersprﾃ･kig arkitektur: ju nﾃ､rmare tvﾃ･ sprﾃ･k ﾃ､r, desto fler parametrar delar de. I detta arbete testar vi denna idﾃｩ med hjﾃ､lp av Transformer-arkitekturen och visar att trots framgﾃ･ngarna i tidigare arbete finns problem inneboende med att utbilda sﾃ･dana hierarkiska modeller. Vi visar att vid noggrant vald utbildningsstrategi kan den hierarkiska arkitekturen ﾃｶvertrﾃ､ffa tvﾃ･sprﾃ･kiga modeller och flersprﾃ･kiga modeller med fullstﾃ､ndig parameterdelning.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Uchaguzi wa kushirikiana mpango wa kutumia mbinu za kutafsiri kwa lugha mbalimbali unaamua namna ambavyo nafasi ya parameter inavyotumiwa na hivyo, unaathiri moja kwa moja kiwango cha tafsiri cha mwisho. Imetumiwa na miti ya lugha inayoonyesha kiwango cha uhusiano kati ya lugha tofauti, mbinu mpya ya kushirikiana kwa vifaa vya lugha mbalimbali ilipendekezwa hivi karibuni. Wazo kuu ni kutumia hifadhi hizi za lugha za wataalam kama msingi wa ujenzi wa lugha mbalimbali: lugha mbili karibu zaidi ni, kipimo ambacho wanaweza kushirikiana. Katika kazi hii, tunajaribu wazo hili kwa kutumia ujenzi wa zamani na kuonyesha kwamba pamoja na mafanikio katika kazi zilizopita, kuna matatizo yanayohusiana na kufundisha mifano kama haya ya kihierarchical. We demonstrate that in case of carefully chosen training strategy the hierarchical architecture can outperform bilingual models and multilingual models with full parameter sharing.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>பல மொழி மொழி மொழிமாற்றி மாதிரிகளில் அளபுரு பகிர்ந்து தேர்வு தேர்ந்தெடுக்கப்பட்டுள்ளது எவ்வாறு தேர்வு அளபுரு இடத்தை பயன்படுத் மொழி மொழிகளுக்கு இடையே தொடர்புகளின் degree காட்டும் மொழிகளால் வழங்கப்பட்டுள்ளது, அளபுருவை பகிர்ந்து புதிய முறைமை சமீபத்தில் பல மொழ முக்கிய ய யோசனை பல மொழி கட்டுப்பாட்டுக்கான அடிப்படையாக பயன்படுத்த வேண்டும். நெருங்கிய இரு மொழிகள், அதிக அளவுருக்கள் அவர்கள் பகிர் இந்த வேலையில், நாம் இந்த கருத்தை பரிசோதிக்கிறோம் மாற்று உருவாக்கத்தை பயன்படுத்தி காட்டுகிறோம் முந்தைய வேலையில் வெற்றி நாம் கவனமாக தேர்ந்தெடுக்கப்பட்ட பயிற்சி திட்டத்திற்கு காண்பிக்கிறோம் என்றால் முழு அளபுரு பகிர்ந்து இரு மொழி மாதிரிகள் மற்ற</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Çoklu dilli maşynyň terjime nusgalarynda parameterler paylaşdyrma stratejiýasynyň saýlawy nähili optimiz seleňler ullanylýar we şonuň üçin iň üstüne terjime kwalitesini täsirleýär. Diller arasyndaky baglaýyşlar tarapyndan nähili bir baglaýyşyň barlygyny görkezýär, täze uly diller maşynyň terjimesinde paýlaşmak üçin täze ýagdaý maslahat edildi. Esasy ideýa şu uzmanly dil hijerarhiýasyny multi dil arhitektura üýtgetmekdir: iki diliň ýakyn bolsa, olaryň paylaşyklarynyň has köp parameterleri. Bu işde, biz bu ideýany Transformer arhitekturyny ulanyp barýarys we öňki işiň başarnygynyň ýöne şol ýaly iýerarhiýa nusgalary öwrenmek üçin kynçylyklary bar diýip görkezip bileris. Biz iýerarhiýa arhitekturyň iki dil nusgalaryny we multidil nusgalaryny doly parmaýa bilen dykkatly saýlandygyny görkez.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>پارامیٹر شریک استراتژی کا انتخاب multilingual machine translation models میں مقرر کرتا ہے کہ کس طرح optimal parameter space استعمال کیا جاتا ہے اور اسی طرح، بالکل ترجمہ کیفیت پر مستقیم تأثیر دیتا ہے. زبان کے درختوں کے ذریعہ جو مختلف زبانوں کے درمیان رابطہ کا درجہ دکھاتے ہیں، بہت سی زبان کے ماشین کی ترجمہ میں تقسیم کرنے کے لئے نئی عمومی طریقہ کی نصیحت کی گئی ہے. اصلی نظر یہ ہے کہ ان مخصوص زبان آئرکریٹیوں کو بہت سی زبان آئرکریٹ کے لئے بنیاد بنانا ہے: دو زبانوں سے زیادہ قریب تر ہے، جسے زیادہ پارامتر وہ شریک کرتے ہیں۔ اس کام میں ہم نے اس ایڈیوں کو تغییر پھیلانے والے معماری کے مطابق آزمایا اور دکھائی کہ اگلے کاموں کے موفقیت کے بغیر اس طرح کی آزمائش کی مسائل ہیں۔ ہم دکھاتے ہیں کہ اچھے طریقے سے انتخاب کئے گئے ترین استراتژی کے مطابق حکومت کی معماری دو زبان کی مدل اور بہت سی زبان کی مدل کو پورا پارامتر شریک کرنے کے ساتھ کامل کر سکتا ہے.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>@ info: whatsthis Yaqinda bir necha tilda bir xil mashina tarjima qiladigan parametrlar darajasini koʻrsatish uchun lingʻlik darajasi bilan imzolangan. Bu oddiy g'oya bir necha tillar arxituvchisi asosiy bo'lishi mumkin: ikkita tillar soni ko'proq parametrlar bo'lishi mumkin. Bu ishda biz bu g'oyani Transformer architektorlar bilan sinab ko'raymiz va oldingi ishda muvaffaqiyatlarni ko'rsatganimizda bunday hierarchik modellarini o'rganish uchun muammolar bor. Biz tajriba o'rganish strategiga qaramaymiz, hierarchik arxituvchisi bilan ikkita tillar modellari va bir necha tildagi modellarni butun parametr boʻlishi mumkin.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Lựa chọn chiến lược chia sẻ Tham số trong các mô hình dịch máy đa dạng, quyết định cách sử dụng các khu vực tham số tốt và do đó, ảnh hưởng trực tiếp đến chất lượng dịch thuật. Nguồn cảm hứng từ cây ngôn ngữ cho thấy độ liên quan giữa các ngôn ngữ khác nhau, bạn đã đề nghị gần đây một phương pháp chung chung mới về chia sẻ các tham số trong phiên dịch máy đa dạng. Chủ đề chính là sử dụng những cấp dưới ngôn ngữ chuyên môn này làm nền tảng cho kiến trúc đa dạng. Hai ngôn ngữ càng gần thì càng chia sẻ nhiều tham số. Trong công trình này, chúng ta thử nghiệm ý tưởng này qua kiến trúc biến áp và cho thấy mặc dù thành công trong công việc trước kia có vấn đề gì trong việc đào tạo các mô hình cấp bậc này. Chúng tôi chứng minh rằng trong trường hợp được chọn kỹ thuật huấn luyện cẩn thận cấu trúc thứ tự có thể đạt giới hạn cách làm ăn nhanh hơn các mô- đun và các mô-đun đa dạng.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>多言机器翻译模形参数共策定参数空中最佳,直染终译。 受示异语言树之启,近多言机器翻译中参数共享新通用之法。 凡心用其言层次结构以为多言架构基:两言愈近,其参数愈多。 以此观之,Transformer架构试之,明虽成功于前,而练之以固也。 吾证精择训练之策,架构胜双语模形与全参数共多言模。</span></div></div><dl><dt>Anthology ID:</dt><dd>2021.vardial-1.2</dd><dt>Volume:</dt><dd><a href=/volumes/2021.vardial-1/>Proceedings of the Eighth Workshop on NLP for Similar Languages, Varieties and Dialects</a></dd><dt>Month:</dt><dd>April</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Kiyv, Ukraine</dd><dt>Venues:</dt><dd><a href=/venues/eacl/>EACL</a>
| <a href=/venues/vardial/>VarDial</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>12–20</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.vardial-1.2>https://aclanthology.org/2021.vardial-1.2</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">khusainova-etal-2021-hierarchical</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Albina Khusainova, Adil Khan, Adín Ramírez Rivera, and Vitaly Romanov. 2021. <a href=https://aclanthology.org/2021.vardial-1.2>Hierarchical Transformer for Multilingual Machine Translation</a>. In <i>Proceedings of the Eighth Workshop on NLP for Similar Languages, Varieties and Dialects</i>, pages 12–20, Kiyv, Ukraine. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2021.vardial-1.2>Hierarchical Transformer for Multilingual Machine Translation</a> (Khusainova et al., VarDial 2021)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2021.vardial-1.2.pdf>https://aclanthology.org/2021.vardial-1.2.pdf</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2021.vardial-1.2.pdf title="Open PDF of 'Hierarchical Transformer for Multilingual Machine Translation'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Hierarchical+Transformer+for+Multilingual+Machine+Translation" title="Search for 'Hierarchical Transformer for Multilingual Machine Translation' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'Hierarchical Transformer for Multilingual Machine Translation'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[Hierarchical Transformer for Multilingual Machine Translation](https://aclanthology.org/2021.vardial-1.2) (Khusainova et al., VarDial 2021)</p><ul class=mt-2><li><a href=https://aclanthology.org/2021.vardial-1.2>Hierarchical Transformer for Multilingual Machine Translation</a> (Khusainova et al., VarDial 2021)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Albina Khusainova, Adil Khan, Adín Ramírez Rivera, and Vitaly Romanov. 2021. <a href=https://aclanthology.org/2021.vardial-1.2>Hierarchical Transformer for Multilingual Machine Translation</a>. In <i>Proceedings of the Eighth Workshop on NLP for Similar Languages, Varieties and Dialects</i>, pages 12–20, Kiyv, Ukraine. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>