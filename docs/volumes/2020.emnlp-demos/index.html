<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</h2><p class=lead><a href=/people/q/qun-liu/>Qun Liu</a>,
<a href=/people/d/david-schlangen/>David Schlangen</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2020.emnlp-demos</dd><dt>Month:</dt><dd>October</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Online</dd><dt>Venue:</dt><dd><a href=/venues/emnlp/>EMNLP</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.emnlp-demos>https://aclanthology.org/2020.emnlp-demos</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+2020+Conference+on+Empirical+Methods+in+Natural+Language+Processing%3A+System+Demonstrations" title="Search for 'Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-demos.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-demos.0/>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</a></strong><br><a href=/people/q/qun-liu/>Qun Liu</a>
|
<a href=/people/d/david-schlangen/>David Schlangen</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-demos.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-demos--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-demos.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-demos.2" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-demos.2/>BERTweet : A pre-trained language model for English Tweets<span class=acl-fixed-case>BERT</span>weet: A pre-trained language model for <span class=acl-fixed-case>E</span>nglish Tweets</a></strong><br><a href=/people/d/dat-quoc-nguyen/>Dat Quoc Nguyen</a>
|
<a href=/people/t/thanh-vu/>Thanh Vu</a>
|
<a href=/people/a/anh-tuan-nguyen/>Anh Tuan Nguyen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-demos--2><div class="card-body p-3 small">We present BERTweet, the first public large-scale pre-trained language model for English Tweets. Our BERTweet, having the same architecture as BERT-base (Devlin et al., 2019), is trained using the RoBERTa pre-training procedure (Liu et al., 2019). Experiments show that BERTweet outperforms strong baselines RoBERTa-base and XLM-R-base (Conneau et al., 2020), producing better performance results than the previous state-of-the-art models on three Tweet NLP tasks : <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>Part-of-speech tagging</a>, <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>Named-entity recognition</a> and text classification. We release BERTweet under the MIT License to facilitate future research and applications on Tweet data. Our BERTweet is available at https://github.com/VinAIResearch/BERTweet</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-demos.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-demos--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-demos.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-demos.3" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-demos.3/>NeuralQA : A Usable Library for <a href=https://en.wikipedia.org/wiki/Question_answering>Question Answering</a> (Contextual Query Expansion + BERT) on Large Datasets<span class=acl-fixed-case>N</span>eural<span class=acl-fixed-case>QA</span>: A Usable Library for Question Answering (Contextual Query Expansion + <span class=acl-fixed-case>BERT</span>) on Large Datasets</a></strong><br><a href=/people/v/victor-dibia/>Victor Dibia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-demos--3><div class="card-body p-3 small">Existing <a href=https://en.wikipedia.org/wiki/Tool>tools</a> for Question Answering (QA) have challenges that limit their use in practice. They can be complex to set up or integrate with existing infrastructure, do not offer configurable interactive interfaces, and do not cover the full set of subtasks that frequently comprise the QA pipeline (query expansion, retrieval, reading, and explanation / sensemaking). To help address these issues, we introduce NeuralQA-a usable library for <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA</a> on large datasets. NeuralQA integrates well with existing <a href=https://en.wikipedia.org/wiki/Infrastructure>infrastructure</a> (e.g., ElasticSearch instances and reader models trained with the HuggingFace Transformers API) and offers helpful defaults for QA subtasks. It introduces and implements contextual query expansion (CQE) using a masked language model (MLM) as well as relevant snippets (RelSnip)-a method for condensing large documents into smaller passages that can be speedily processed by a document reader model. Finally, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> offers a flexible user interface to support <a href=https://en.wikipedia.org/wiki/Workflow>workflows</a> for <a href=https://en.wikipedia.org/wiki/Scientific_method>research explorations</a> (e.g., visualization of gradient-based explanations to support qualitative inspection of model behaviour) and <a href=https://en.wikipedia.org/wiki/Search_engine_technology>large scale search deployment</a>. Code and documentation for NeuralQA is available as open source on Github.<tex-math>RelSnip</tex-math>) - a method for condensing large documents into smaller passages that can be speedily processed by a document reader model. Finally, it offers a flexible user interface to support workflows for research explorations (e.g., visualization of gradient-based explanations to support qualitative inspection of model behaviour) and large scale search deployment. Code and documentation for NeuralQA is available as open source on Github.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-demos.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-demos--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-demos.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-demos.9" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-demos.9/>DeezyMatch : A Flexible Deep Learning Approach to Fuzzy String Matching<span class=acl-fixed-case>D</span>eezy<span class=acl-fixed-case>M</span>atch: A Flexible Deep Learning Approach to Fuzzy String Matching</a></strong><br><a href=/people/k/kasra-hosseini/>Kasra Hosseini</a>
|
<a href=/people/f/federico-nanni/>Federico Nanni</a>
|
<a href=/people/m/mariona-coll-ardanuy/>Mariona Coll Ardanuy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-demos--9><div class="card-body p-3 small">We present DeezyMatch, a free, open-source software library written in <a href=https://en.wikipedia.org/wiki/Python_(programming_language)>Python</a> for fuzzy string matching and candidate ranking. Its pair classifier supports various deep neural network architectures for training new classifiers and for fine-tuning a pretrained model, which paves the way for <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> in fuzzy string matching. This approach is especially useful where only limited training examples are available. The learned DeezyMatch models can be used to generate rich vector representations from string inputs. The candidate ranker component in DeezyMatch uses these vector representations to find, for a given query, the best matching candidates in a <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge base</a>. It uses an adaptive searching algorithm applicable to large knowledge bases and <a href=https://en.wikipedia.org/wiki/Query_language>query sets</a>. We describe DeezyMatch&#8217;s functionality, design and implementation, accompanied by a use case in toponym matching and <a href=https://en.wikipedia.org/wiki/Feasible_region>candidate ranking</a> in realistic noisy datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-demos.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-demos--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-demos.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-demos.11/>InVeRo : Making Semantic Role Labeling Accessible with Intelligible Verbs and Roles<span class=acl-fixed-case>I</span>n<span class=acl-fixed-case>V</span>e<span class=acl-fixed-case>R</span>o: Making Semantic Role Labeling Accessible with Intelligible Verbs and Roles</a></strong><br><a href=/people/s/simone-conia/>Simone Conia</a>
|
<a href=/people/f/fabrizio-brignone/>Fabrizio Brignone</a>
|
<a href=/people/d/davide-zanfardino/>Davide Zanfardino</a>
|
<a href=/people/r/roberto-navigli/>Roberto Navigli</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-demos--11><div class="card-body p-3 small">Semantic Role Labeling (SRL) is deeply dependent on complex linguistic resources and sophisticated neural models, which makes the task difficult to approach for non-experts. To address this issue we present a new <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a> named Intelligible Verbs and Roles (InVeRo). This platform provides access to a new verb resource, VerbAtlas, and a state-of-the-art pretrained implementation of a neural, span-based architecture for SRL. Both the resource and the system provide human-readable verb sense and semantic role information, with an easy to use <a href=https://en.wikipedia.org/wiki/User_interface>Web interface</a> and <a href=https://en.wikipedia.org/wiki/Representational_state_transfer>RESTful APIs</a> available at http://nlp.uniroma1.it/invero.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-demos.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-demos--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-demos.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-demos.12/>Youling : an AI-assisted Lyrics Creation System<span class=acl-fixed-case>AI</span>-assisted Lyrics Creation System</a></strong><br><a href=/people/r/rongsheng-zhang/>Rongsheng Zhang</a>
|
<a href=/people/x/xiaoxi-mao/>Xiaoxi Mao</a>
|
<a href=/people/l/le-li/>Le Li</a>
|
<a href=/people/l/lin-jiang/>Lin Jiang</a>
|
<a href=/people/l/lin-chen/>Lin Chen</a>
|
<a href=/people/z/zhiwei-hu/>Zhiwei Hu</a>
|
<a href=/people/y/yadong-xi/>Yadong Xi</a>
|
<a href=/people/c/changjie-fan/>Changjie Fan</a>
|
<a href=/people/m/minlie-huang/>Minlie Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-demos--12><div class="card-body p-3 small">Recently, a variety of <a href=https://en.wikipedia.org/wiki/Neural_circuit>neural models</a> have been proposed for lyrics generation. However, most previous work completes the generation process in a single pass with little <a href=https://en.wikipedia.org/wiki/Human&#8211;computer_interaction>human intervention</a>. We believe that lyrics creation is a creative process with human intelligence centered. AI should play a role as an assistant in the lyrics creation process, where human interactions are crucial for high-quality creation. This paper demonstrates Youling, an AI-assisted lyrics creation system, designed to collaborate with music creators. In the lyrics generation process, Youling supports traditional one pass full-text generation mode as well as an interactive generation mode, which allows users to select the satisfactory sentences from generated candidates conditioned on preceding context. The <a href=https://en.wikipedia.org/wiki/System>system</a> also provides a revision module which enables users to revise undesired sentences or words of <a href=https://en.wikipedia.org/wiki/Lyrics>lyrics</a> repeatedly. Besides, Youling allows users to use multifaceted attributes to control the content and format of generated lyrics. The demo video of the <a href=https://en.wikipedia.org/wiki/System>system</a> is available at https://youtu.be/DFeNpHk0pm4.<i>Youling</i>, an AI-assisted lyrics creation system, designed to collaborate with music creators. In the lyrics generation process, <i>Youling</i> supports traditional one pass full-text generation mode as well as an interactive generation mode, which allows users to select the satisfactory sentences from generated candidates conditioned on preceding context. The system also provides a revision module which enables users to revise undesired sentences or words of lyrics repeatedly. Besides, <i>Youling</i> allows users to use multifaceted attributes to control the content and format of generated lyrics. The demo video of the system is available at https://youtu.be/DFeNpHk0pm4.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-demos.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-demos--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-demos.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-demos.13.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-demos.13" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-demos.13/>A Technical Question Answering System with Transfer Learning</a></strong><br><a href=/people/w/wenhao-yu/>Wenhao Yu</a>
|
<a href=/people/l/lingfei-wu/>Lingfei Wu</a>
|
<a href=/people/y/yu-deng/>Yu Deng</a>
|
<a href=/people/r/ruchi-mahindru/>Ruchi Mahindru</a>
|
<a href=/people/q/qingkai-zeng/>Qingkai Zeng</a>
|
<a href=/people/s/sinem-guven/>Sinem Guven</a>
|
<a href=/people/m/meng-jiang/>Meng Jiang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-demos--13><div class="card-body p-3 small">In recent years, the need for community technical question-answering sites has increased significantly. However, it is often expensive for human experts to provide timely and helpful responses on those forums. We develop TransTQA, which is a novel system that offers automatic responses by retrieving proper answers based on correctly answered similar questions in the past. TransTQA is built upon a siamese ALBERT network, which enables it to respond quickly and accurately. Furthermore, TransTQA adopts a standard deep transfer learning strategy to improve its capability of supporting multiple technical domains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-demos.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-demos--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-demos.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-demos.15" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-demos.15/>The Language Interpretability Tool : Extensible, Interactive Visualizations and Analysis for NLP Models<span class=acl-fixed-case>NLP</span> Models</a></strong><br><a href=/people/i/ian-tenney/>Ian Tenney</a>
|
<a href=/people/j/james-wexler/>James Wexler</a>
|
<a href=/people/j/jasmijn-bastings/>Jasmijn Bastings</a>
|
<a href=/people/t/tolga-bolukbasi/>Tolga Bolukbasi</a>
|
<a href=/people/a/andy-coenen/>Andy Coenen</a>
|
<a href=/people/s/sebastian-gehrmann/>Sebastian Gehrmann</a>
|
<a href=/people/e/ellen-jiang/>Ellen Jiang</a>
|
<a href=/people/m/mahima-pushkarna/>Mahima Pushkarna</a>
|
<a href=/people/c/carey-radebaugh/>Carey Radebaugh</a>
|
<a href=/people/e/emily-reif/>Emily Reif</a>
|
<a href=/people/a/ann-yuan/>Ann Yuan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-demos--15><div class="card-body p-3 small">We present the Language Interpretability Tool (LIT), an open-source platform for visualization and understanding of NLP models. We focus on core questions about model behavior : Why did my <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> make this prediction? When does <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> perform poorly? What happens under a controlled change in the input? LIT integrates local explanations, <a href=https://en.wikipedia.org/wiki/Aggregate_data>aggregate analysis</a>, and <a href=https://en.wikipedia.org/wiki/Counterfactual_conditional>counterfactual generation</a> into a streamlined, browser-based interface to enable rapid exploration and error analysis. We include case studies for a diverse set of workflows, including exploring <a href=https://en.wikipedia.org/wiki/Counterfactual_conditional>counterfactuals</a> for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>, measuring <a href=https://en.wikipedia.org/wiki/Gender_bias>gender bias</a> in <a href=https://en.wikipedia.org/wiki/Coreference>coreference systems</a>, and exploring local behavior in text generation. LIT supports a wide range of modelsincluding <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a>, seq2seq, and structured predictionand is highly extensible through a declarative, framework-agnostic API. LIT is under active development, with code and full documentation available at https://github.com/pair-code/lit.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-demos.26.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-demos--26 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-demos.26 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-demos.26" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-demos.26/>A Data-Centric Framework for Composable NLP Workflows<span class=acl-fixed-case>NLP</span> Workflows</a></strong><br><a href=/people/z/zhengzhong-liu/>Zhengzhong Liu</a>
|
<a href=/people/g/guanxiong-ding/>Guanxiong Ding</a>
|
<a href=/people/a/avinash-bukkittu/>Avinash Bukkittu</a>
|
<a href=/people/m/mansi-gupta/>Mansi Gupta</a>
|
<a href=/people/p/pengzhi-gao/>Pengzhi Gao</a>
|
<a href=/people/a/atif-ahmed/>Atif Ahmed</a>
|
<a href=/people/s/shikun-zhang/>Shikun Zhang</a>
|
<a href=/people/x/xin-gao/>Xin Gao</a>
|
<a href=/people/s/swapnil-singhavi/>Swapnil Singhavi</a>
|
<a href=/people/l/linwei-li/>Linwei Li</a>
|
<a href=/people/w/wei-wei/>Wei Wei</a>
|
<a href=/people/z/zecong-hu/>Zecong Hu</a>
|
<a href=/people/h/haoran-shi/>Haoran Shi</a>
|
<a href=/people/x/xiaodan-liang/>Xiaodan Liang</a>
|
<a href=/people/t/teruko-mitamura/>Teruko Mitamura</a>
|
<a href=/people/e/eric-xing/>Eric Xing</a>
|
<a href=/people/z/zhiting-hu/>Zhiting Hu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-demos--26><div class="card-body p-3 small">Empirical natural language processing (NLP) systems in application domains (e.g., healthcare, finance, education) involve interoperation among multiple components, ranging from data ingestion, human annotation, to text retrieval, <a href=https://en.wikipedia.org/wiki/Data_analysis>analysis</a>, generation, and <a href=https://en.wikipedia.org/wiki/Data_visualization>visualization</a>. We establish a unified open-source framework to support fast development of such sophisticated NLP workflows in a composable manner. The <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> introduces a uniform data representation to encode heterogeneous results by a wide range of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP tasks</a>. It offers a large repository of processors for NLP tasks, <a href=https://en.wikipedia.org/wiki/Visualization_(graphics)>visualization</a>, and <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a>, which can be easily assembled with full interoperability under the unified representation. The highly extensible framework allows plugging in custom processors from external off-the-shelf NLP and deep learning libraries. The whole framework is delivered through two modularized yet integratable open-source projects, namely Forte (for workflow infrastructure and NLP function processors) and Stave (for user interaction, visualization, and annotation).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-demos.27.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-demos--27 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-demos.27 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-demos.27" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-demos.27/>CoRefi : A Crowd Sourcing Suite for Coreference Annotation<span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>R</span>efi: A Crowd Sourcing Suite for Coreference Annotation</a></strong><br><a href=/people/a/ari-bornstein/>Ari Bornstein</a>
|
<a href=/people/a/arie-cattan/>Arie Cattan</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-demos--27><div class="card-body p-3 small">Coreference annotation is an important, yet expensive and time consuming, task, which often involved expert annotators trained on complex decision guidelines. To enable cheaper and more efficient <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a>, we present CoRefi, a web-based coreference annotation suite, oriented for <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing</a>. Beyond the core coreference annotation tool, CoRefi provides guided onboarding for the task as well as a novel <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> for a reviewing phase. CoRefi is open source and directly embeds into any website, including popular <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing platforms</a>. CoRefi Demo : aka.ms/corefi Video Tour : aka.ms/corefivideo Github Repo : https://github.com/aribornstein/corefi</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>