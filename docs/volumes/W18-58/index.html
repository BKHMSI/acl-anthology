<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/W18-58.pdf>Proceedings of the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology</a></h2><p class=lead><a href=/people/s/sandra-kubler/>Sandra Kuebler</a>,
<a href=/people/g/garrett-nicolai/>Garrett Nicolai</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>W18-58</dd><dt>Month:</dt><dd>October</dd><dt>Year:</dt><dd>2018</dd><dt>Address:</dt><dd>Brussels, Belgium</dd><dt>Venues:</dt><dd><a href=/venues/emnlp/>EMNLP</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd><a href=/sigs/sigmorphon/>SIGMORPHON</a></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/W18-58>https://aclanthology.org/W18-58</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/W18-58.pdf>https://aclanthology.org/W18-58.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/W18-58.pdf title="Open PDF of 'Proceedings of the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+Fifteenth+Workshop+on+Computational+Research+in+Phonetics%2C+Phonology%2C+and+Morphology" title="Search for 'Proceedings of the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5800.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5800/>Proceedings of the Fifteenth Workshop on Computational Research in Phonetics, Phonology, and Morphology</a></strong><br><a href=/people/s/sandra-kubler/>Sandra Kuebler</a>
|
<a href=/people/g/garrett-nicolai/>Garrett Nicolai</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5801.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5801 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5801 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5801/>Efficient Computation of Implicational Universals in Constraint-Based Phonology Through the <a href=https://en.wikipedia.org/wiki/Hyperplane_separation_theorem>Hyperplane Separation Theorem</a></a></strong><br><a href=/people/g/giorgio-magri/>Giorgio Magri</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5801><div class="card-body p-3 small">This paper focuses on the most basic implicational universals in <a href=https://en.wikipedia.org/wiki/Phonology>phonological theory</a>, called T-orders after Anttila and Andrus (2006). It develops necessary and sufficient constraint characterizations of T-orders within Harmonic Grammar and <a href=https://en.wikipedia.org/wiki/Optimality_theory>Optimality Theory</a>. These conditions rest on the rich convex geometry underlying these frameworks. They are phonologically intuitive and have significant algorithmic implications.<i>implicational universals</i> in phonological theory, called <i>T-orders</i> after Anttila and Andrus (2006). It develops necessary and sufficient constraint characterizations of T-orders within <i>Harmonic Grammar</i> and <i>Optimality Theory</i>. These conditions rest on the rich convex geometry underlying these frameworks. They are phonologically intuitive and have significant algorithmic implications.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5802.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5802 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5802 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5802/>Lexical Networks in ! Xung<span class=acl-fixed-case>X</span>ung</a></strong><br><a href=/people/s/syed-amad-hussain/>Syed-Amad Hussain</a>
|
<a href=/people/m/micha-elsner/>Micha Elsner</a>
|
<a href=/people/a/amanda-miller/>Amanda Miller</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5802><div class="card-body p-3 small">We investigate the lexical network properties of the large phoneme inventory Southern African language Mangetti Dune ! Xung as it compares to <a href=https://en.wikipedia.org/wiki/English_language>English</a> and other commonly-studied languages. Lexical networks are graphs in which nodes (words) are linked to their minimal pairs ; global properties of these <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>networks</a> are believed to mediate <a href=https://en.wikipedia.org/wiki/Lexical_access>lexical access</a> in the minds of speakers. We show that the network properties of ! Xung are within the range found in previously-studied languages. By simulating data (pseudolexicons) with varying levels of phonotactic structure, we find that the lexical network properties of ! Xung diverge from previously-studied languages when fewer phonotactic constraints are retained. We conclude that lexical network properties are representative of an underlying cognitive structure which is necessary for efficient word retrieval and that the <a href=https://en.wikipedia.org/wiki/Phonotactics>phonotactics</a> of ! Xung may be shaped by a selective pressure which preserves network properties within this cognitively useful range.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5803.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5803 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5803 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5803/>Acoustic Word Disambiguation with Phonogical Features in Danish ASR<span class=acl-fixed-case>D</span>anish <span class=acl-fixed-case>ASR</span></a></strong><br><a href=/people/a/andreas-soeborg-kirkedal/>Andreas SÃ¸eborg Kirkedal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5803><div class="card-body p-3 small">Phonological features can indicate <a href=https://en.wikipedia.org/wiki/Word_class>word class</a> and we can use <a href=https://en.wikipedia.org/wiki/Word_class>word class information</a> to disambiguate both <a href=https://en.wikipedia.org/wiki/Homophone>homophones</a> and <a href=https://en.wikipedia.org/wiki/Homograph>homographs</a> in automatic speech recognition (ASR). We show Danish std can be predicted from <a href=https://en.wikipedia.org/wiki/Speech>speech</a> and used to improve <a href=https://en.wikipedia.org/wiki/Speech_recognition>ASR</a>. We discover which acoustic features contain the signal of <a href=https://en.wikipedia.org/wiki/Standardized_test>std</a>, how to use these features to predict <a href=https://en.wikipedia.org/wiki/Standardized_test>std</a> and how we can make use of <a href=https://en.wikipedia.org/wiki/Standardized_test>std</a> and stdpredictive acoustic features to improve overall ASR accuracy and decoding speed. In the process, we discover acoustic features that are novel to the phonetic characterisation of std.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5804.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5804 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5804 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5804/>Adaptor Grammars for the Linguist : <a href=https://en.wikipedia.org/wiki/Word_segmentation>Word Segmentation</a> Experiments for Very Low-Resource Languages<span class=acl-fixed-case>A</span>daptor <span class=acl-fixed-case>G</span>rammars for the Linguist: Word Segmentation Experiments for Very Low-Resource Languages</a></strong><br><a href=/people/p/pierre-godard/>Pierre Godard</a>
|
<a href=/people/l/laurent-besacier/>Laurent Besacier</a>
|
<a href=/people/f/francois-yvon/>FranÃ§ois Yvon</a>
|
<a href=/people/m/martine-adda-decker/>Martine Adda-Decker</a>
|
<a href=/people/g/gilles-adda/>Gilles Adda</a>
|
<a href=/people/h/helene-bonneau-maynard/>HÃ©lÃ¨ne Maynard</a>
|
<a href=/people/a/annie-rialland/>Annie Rialland</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5804><div class="card-body p-3 small">Computational Language Documentation attempts to make the most recent research in speech and language technologies available to linguists working on <a href=https://en.wikipedia.org/wiki/Language_preservation>language preservation</a> and documentation. In this paper, we pursue two main goals along these lines. The first is to improve upon a strong baseline for the unsupervised word discovery task on two very low-resource Bantu languages, taking advantage of the expertise of linguists on these particular languages. The second consists in exploring the Adaptor Grammar framework as a decision and prediction tool for linguists studying a new language. We experiment 162 grammar configurations for each language and show that using Adaptor Grammars for <a href=https://en.wikipedia.org/wiki/Word_segmentation>word segmentation</a> enables us to test hypotheses about a language. Specializing a generic grammar with language specific knowledge leads to great improvements for the word discovery task, ultimately achieving a leap of about 30 % token F-score from the results of a strong baseline.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5805.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5805 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5805 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5805/>String Transduction with Target Language Models and Insertion Handling</a></strong><br><a href=/people/g/garrett-nicolai/>Garrett Nicolai</a>
|
<a href=/people/s/saeed-najafi/>Saeed Najafi</a>
|
<a href=/people/g/grzegorz-kondrak/>Grzegorz Kondrak</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5805><div class="card-body p-3 small">Many character-level tasks can be framed as sequence-to-sequence transduction, where the target is a word from a <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>. We show that leveraging target language models derived from unannotated target corpora, combined with a precise alignment of the training data, yields state-of-the art results on cognate projection, inflection generation, and phoneme-to-grapheme conversion.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5807.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5807 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5807 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5807/>Modeling Reduplication with 2-way Finite-State Transducers</a></strong><br><a href=/people/h/hossep-dolatian/>Hossep Dolatian</a>
|
<a href=/people/j/jeffrey-heinz/>Jeffrey Heinz</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5807><div class="card-body p-3 small">This article describes a novel approach to the computational modeling of reduplication. Reduplication is a well-studied <a href=https://en.wikipedia.org/wiki/Phenomenon>linguistic phenomenon</a>. However, it is often treated as a stumbling block within finite-state treatments of <a href=https://en.wikipedia.org/wiki/Morphology_(biology)>morphology</a>. Most finite-state implementations of computational morphology can not adequately capture the productivity of unbounded copying in <a href=https://en.wikipedia.org/wiki/Reduplication>reduplication</a>, nor can they adequately capture bounded copying. We show that an understudied type of finite-state machines, two-way finite-state transducers (2-way FSTs), captures virtually all reduplicative processes, including total reduplication. 2-way FSTs can model reduplicative typology in a way which is convenient, easy to design and debug in practice, and linguistically-motivated. By virtue of being finite-state, 2-way FSTs are likewise incorporable into existing <a href=https://en.wikipedia.org/wiki/Finite-state_machine>finite-state systems</a> and <a href=https://en.wikipedia.org/wiki/Computer_program>programs</a>. A small but representative typology of reduplicative processes is described in this article, alongside their corresponding 2-way FST models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5809.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5809 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5809 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5809/>A Comparison of Entity Matching Methods between <a href=https://en.wikipedia.org/wiki/English_language>English</a> and Japanese Katakana<span class=acl-fixed-case>E</span>nglish and <span class=acl-fixed-case>J</span>apanese Katakana</a></strong><br><a href=/people/m/michiharu-yamashita/>Michiharu Yamashita</a>
|
<a href=/people/h/hideki-awashima/>Hideki Awashima</a>
|
<a href=/people/h/hidekazu-oiwa/>Hidekazu Oiwa</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5809><div class="card-body p-3 small">Japanese Katakana is one component of the <a href=https://en.wikipedia.org/wiki/Japanese_writing_system>Japanese writing system</a> and is used to express English terms, <a href=https://en.wikipedia.org/wiki/Loanword>loanwords</a>, and <a href=https://en.wikipedia.org/wiki/Onomatopoeia>onomatopoeia</a> in <a href=https://en.wikipedia.org/wiki/Japanese_writing_system>Japanese characters</a> based on the <a href=https://en.wikipedia.org/wiki/Japanese_phonology>phonemes</a>. The main purpose of this research is to find the best entity matching methods between <a href=https://en.wikipedia.org/wiki/English_language>English</a> and Katakana. We built two research questions to clarify which types of <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity matching systems</a> works better than others. The first question is what <a href=https://en.wikipedia.org/wiki/Transliteration>transliteration</a> should be used for <a href=https://en.wikipedia.org/wiki/Conversion_(word_formation)>conversion</a>. We need to transliterate English or Katakana terms into the same form in order to compute the <a href=https://en.wikipedia.org/wiki/String_similarity>string similarity</a>. We consider five conversions that transliterate <a href=https://en.wikipedia.org/wiki/English_language>English</a> to Katakana directly, <a href=https://en.wikipedia.org/wiki/Katakana>Katakana</a> to English directly, <a href=https://en.wikipedia.org/wiki/English_language>English</a> to Katakana via phoneme, Katakana to <a href=https://en.wikipedia.org/wiki/English_language>English</a> via phoneme, and both <a href=https://en.wikipedia.org/wiki/English_language>English</a> and Katakana to phoneme. The second question is what should be used for the <a href=https://en.wikipedia.org/wiki/Similarity_measure>similarity measure</a> at <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity matching</a>. To investigate the problem, we choose six methods, which are <a href=https://en.wikipedia.org/wiki/Overlap_coefficient>Overlap Coefficient</a>, <a href=https://en.wikipedia.org/wiki/Cosine>Cosine</a>, <a href=https://en.wikipedia.org/wiki/Jaccard>Jaccard</a>, Jaro-Winkler, Levenshtein, and the similarity of the phoneme probability predicted by RNN. Our results show that 1) matching using <a href=https://en.wikipedia.org/wiki/Phoneme>phonemes</a> and conversion of Katakana to <a href=https://en.wikipedia.org/wiki/English_language>English</a> works better than other methods, and 2) the similarity of phonemes outperforms other methods while other similarity score is changed depending on data and models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5810.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5810 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5810 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5810/>Seq2Seq Models with Dropout can Learn Generalizable Reduplication<span class=acl-fixed-case>S</span>eq2<span class=acl-fixed-case>S</span>eq Models with Dropout can Learn Generalizable Reduplication</a></strong><br><a href=/people/b/brandon-prickett/>Brandon Prickett</a>
|
<a href=/people/a/aaron-traylor/>Aaron Traylor</a>
|
<a href=/people/j/joe-pater/>Joe Pater</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5810><div class="card-body p-3 small">Natural language reduplication can pose a challenge to neural models of language, and has been argued to require <a href=https://en.wikipedia.org/wiki/Variable_(mathematics)>variables</a> (Marcus et al., 1999). Sequence-to-sequence neural networks have been shown to perform well at a number of other morphological tasks (Cotterell et al., 2016), and produce results that highly correlate with human behavior (Kirov, 2017 ; Kirov & Cotterell, 2018) but do not include any explicit variables in their architecture. We find that they can learn a reduplicative pattern that generalizes to novel segments if they are trained with dropout (Srivastava et al., 2014). We argue that this matches the scope of <a href=https://en.wikipedia.org/wiki/Generalization>generalization</a> observed in human reduplication.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5811.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5811 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5811 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W18-5811" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W18-5811/>A Characterwise Windowed Approach to Hebrew Morphological Segmentation<span class=acl-fixed-case>H</span>ebrew Morphological Segmentation</a></strong><br><a href=/people/a/amir-zeldes/>Amir Zeldes</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5811><div class="card-body p-3 small">This paper presents a novel approach to the segmentation of orthographic word forms in contemporary <a href=https://en.wikipedia.org/wiki/Hebrew_language>Hebrew</a>, focusing purely on splitting without carrying out <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphological analysis</a> or <a href=https://en.wikipedia.org/wiki/Word-sense_disambiguation>disambiguation</a>. Casting the analysis task as character-wise binary classification and using adjacent character and word-based lexicon-lookup features, this approach achieves over 98 % accuracy on the benchmark SPMRL shared task data for <a href=https://en.wikipedia.org/wiki/Hebrew_language>Hebrew</a>, and 97 % accuracy on a new out of domain Wikipedia dataset, an improvement of 4 % and 5 % over previous state of the art performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5812.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5812 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5812 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5812/>Phonetic Vector Representations for Sound Sequence Alignment</a></strong><br><a href=/people/p/pavel-sofroniev/>Pavel Sofroniev</a>
|
<a href=/people/c/cagri-coltekin/>ÃaÄrÄ± ÃÃ¶ltekin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5812><div class="card-body p-3 small">This study explores a number of data-driven vector representations of the IPA-encoded sound segments for the purpose of sound sequence alignment. We test the alternative <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representations</a> based on the alignment accuracy in the context of computational historical linguistics. We show that the data-driven methods consistently do better than linguistically-motivated articulatory-acoustic features. The similarity scores obtained using the data-driven representations in a monolingual context, however, performs worse than the state-of-the-art distance (or similarity) scoring methods proposed in earlier studies of computational historical linguistics. We also show that adapting representations to the task at hand improves the results, yielding alignment accuracy comparable to the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state of the art methods</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5813.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5813 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5813 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5813/>Sounds Wilde. Phonetically Extended Embeddings for Author-Stylized Poetry Generation</a></strong><br><a href=/people/a/aleksey-tikhonov/>Aleksey Tikhonov</a>
|
<a href=/people/i/ivan-p-yamshchikov/>Ivan P. Yamshchikov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5813><div class="card-body p-3 small">This paper addresses author-stylized text generation. Using a version of a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> with extended phonetic and semantic embeddings for poetry generation we show that <a href=https://en.wikipedia.org/wiki/Phonetics>phonetics</a> has comparable contribution to the overall model performance as the information on the target author. Phonetic information is shown to be important for <a href=https://en.wikipedia.org/wiki/English_language>English and Russian language</a>. Humans tend to attribute machine generated texts to the target author.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5814.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5814 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5814 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5814/>On Hapax Legomena and Morphological Productivity</a></strong><br><a href=/people/j/janet-pierrehumbert/>Janet Pierrehumbert</a>
|
<a href=/people/r/ramon-granell/>Ramon Granell</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5814><div class="card-body p-3 small">Quantifying and predicting morphological productivity is a long-standing challenge in <a href=https://en.wikipedia.org/wiki/Corpus_linguistics>corpus linguistics</a> and <a href=https://en.wikipedia.org/wiki/Psycholinguistics>psycholinguistics</a>. The same challenge reappears in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> in the context of handling words that were not seen in the training set (out-of-vocabulary, or OOV, words). Prior research showed that a good indicator of the productivity of a <a href=https://en.wikipedia.org/wiki/Morpheme>morpheme</a> is the number of words involving it that occur exactly once (the hapax legomena). A technical connection was adduced between this result and <a href=https://en.wikipedia.org/wiki/Good-Turing_smoothing>Good-Turing smoothing</a>, which assigns <a href=https://en.wikipedia.org/wiki/Probability_mass_function>probability mass</a> to unseen events on the basis of the simplifying assumption that <a href=https://en.wikipedia.org/wiki/Word_frequency>word frequencies</a> are stationary. In a large-scale study of 133 affixes in <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>, we develop evidence that success in fact depends on tapping the frequency range in which the assumptions of Good-Turing are violated.<i>hapax legomena</i>). A technical connection was adduced between this result and Good-Turing smoothing, which assigns probability mass to unseen events on the basis of the simplifying assumption that word frequencies are stationary. In a large-scale study of 133 affixes in Wikipedia, we develop evidence that success in fact depends on tapping the frequency range in which the assumptions of Good-Turing are violated.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5816.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5816 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5816 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5816/>An Arabic Morphological Analyzer and Generator with Copious Features<span class=acl-fixed-case>A</span>rabic Morphological Analyzer and Generator with Copious Features</a></strong><br><a href=/people/d/dima-taji/>Dima Taji</a>
|
<a href=/people/s/salam-khalifa/>Salam Khalifa</a>
|
<a href=/people/o/ossama-obeid/>Ossama Obeid</a>
|
<a href=/people/f/fadhl-eryani/>Fadhl Eryani</a>
|
<a href=/people/n/nizar-habash/>Nizar Habash</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5816><div class="card-body p-3 small">We introduce CALIMA-Star, a very rich Arabic morphological analyzer and generator that provides functional and form-based morphological features as well as built-in tokenization, phonological representation, lexical rationality and much more. This tool includes a fast engine that can be easily integrated into other <a href=https://en.wikipedia.org/wiki/System>systems</a>, as well as an easy-to-use API and a <a href=https://en.wikipedia.org/wiki/User_interface>web interface</a>. CALIMA-Star also supports morphological reinflection. We evaluate CALIMA-Star against four commonly used analyzers for <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a> in terms of speed and morphological content.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5817.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5817 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5817 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5817/>Sanskrit n-Retroflexion is Input-Output Tier-Based Strictly Local<span class=acl-fixed-case>S</span>anskrit n-Retroflexion is Input-Output Tier-Based Strictly Local</a></strong><br><a href=/people/t/thomas-graf/>Thomas Graf</a>
|
<a href=/people/c/connor-mayer/>Connor Mayer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5817><div class="card-body p-3 small">Sanskrit /n/-retroflexion is one of the most complex segmental processes in <a href=https://en.wikipedia.org/wiki/Phonology>phonology</a>. While <a href=https://en.wikipedia.org/wiki/It_(novel)>it</a> is still star-free, <a href=https://en.wikipedia.org/wiki/It_(novel)>it</a> does not fit in any of the subregular classes that are commonly entertained in the literature. We show that when construed as a phonotactic dependency, the process fits into a <a href=https://en.wikipedia.org/wiki/Class_(computer_programming)>class</a> we call input-output tier-based strictly local (IO-TSL), a natural extension of the familiar class TSL. IO-TSL increases the power of TSL&#8217;s tier projection function by making it an input-output strictly local transduction. Assuming that /n/-retroflexion represents the upper bound on the complexity of segmental phonology, this shows that all of segmental phonology can be captured by combining the intuitive notion of tiers with the independently motivated machinery of strictly local mappings.<i>input-output tier-based strictly local</i> (IO-TSL), a natural extension of the familiar class TSL. IO-TSL increases the power of TSL&#8217;s tier projection function by making it an input-output strictly local transduction. Assuming that /n/-retroflexion represents the upper bound on the complexity of segmental phonology, this shows that all of segmental phonology can be captured by combining the intuitive notion of tiers with the independently motivated machinery of strictly local mappings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5818.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5818 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5818 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5818/>Phonological Features for Morphological Inflection</a></strong><br><a href=/people/a/adam-wiemerslage/>Adam Wiemerslage</a>
|
<a href=/people/m/miikka-silfverberg/>Miikka Silfverberg</a>
|
<a href=/people/m/mans-hulden/>Mans Hulden</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5818><div class="card-body p-3 small">Modeling morphological inflection is an important task in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a>. In contrast to earlier work that has largely used <a href=https://en.wikipedia.org/wiki/Orthographic_representation>orthographic representations</a>, we experiment with this task in a phonetic character space, representing inputs as either <a href=https://en.wikipedia.org/wiki/Segment_(linguistics)>IPA segments</a> or bundles of <a href=https://en.wikipedia.org/wiki/Distinctive_feature>phonological distinctive features</a>. We show that both of these inputs, somewhat counterintuitively, achieve similar accuracies on morphological inflection, slightly lower than orthographic models. We conclude that providing detailed phonological representations is largely redundant when compared to <a href=https://en.wikipedia.org/wiki/Segment_(linguistics)>IPA segments</a>, and that articulatory distinctions relevant for <a href=https://en.wikipedia.org/wiki/Inflection>word inflection</a> are already latently present in the distributional properties of many graphemic writing systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-5819.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-5819 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-5819 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-5819/>Extracting Morphophonology from Small Corpora</a></strong><br><a href=/people/m/marina-ermolaeva/>Marina Ermolaeva</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-5819><div class="card-body p-3 small">Probabilistic approaches have proven themselves well in learning <a href=https://en.wikipedia.org/wiki/Phonology>phonological structure</a>. In contrast, <a href=https://en.wikipedia.org/wiki/Theoretical_linguistics>theoretical linguistics</a> usually works with deterministic generalizations. The goal of this paper is to explore possible interactions between information-theoretic methods and deterministic linguistic knowledge and to examine some ways in which both can be used in tandem to extract phonological and morphophonological patterns from a small annotated dataset. Local and nonlocal processes in Mishar Tatar (Turkic / Kipchak) are examined as a case study.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>