<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the Fourth Workshop on Structured Prediction for NLP - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Proceedings of the Fourth Workshop on Structured Prediction for NLP</h2><p class=lead><a href=/people/p/priyanka-agrawal/>Priyanka Agrawal</a>,
<a href=/people/z/zornitsa-kozareva/>Zornitsa Kozareva</a>,
<a href=/people/j/julia-kreutzer/>Julia Kreutzer</a>,
<a href=/people/g/gerasimos-lampouras/>Gerasimos Lampouras</a>,
<a href=/people/a/andre-f-t-martins/>André Martins</a>,
<a href=/people/s/sujith-ravi/>Sujith Ravi</a>,
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2020.spnlp-1</dd><dt>Month:</dt><dd>November</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Online</dd><dt>Venues:</dt><dd><a href=/venues/emnlp/>EMNLP</a>
| <a href=/venues/spnlp/>spnlp</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.spnlp-1>https://aclanthology.org/2020.spnlp-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+Fourth+Workshop+on+Structured+Prediction+for+NLP" title="Search for 'Proceedings of the Fourth Workshop on Structured Prediction for NLP' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.spnlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.spnlp-1.0/>Proceedings of the Fourth Workshop on Structured Prediction for NLP</a></strong><br><a href=/people/p/priyanka-agrawal/>Priyanka Agrawal</a>
|
<a href=/people/z/zornitsa-kozareva/>Zornitsa Kozareva</a>
|
<a href=/people/j/julia-kreutzer/>Julia Kreutzer</a>
|
<a href=/people/g/gerasimos-lampouras/>Gerasimos Lampouras</a>
|
<a href=/people/a/andre-f-t-martins/>André Martins</a>
|
<a href=/people/s/sujith-ravi/>Sujith Ravi</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.spnlp-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--spnlp-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.spnlp-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.spnlp-1.2.OptionalSupplementaryMaterial.pdf data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38940142 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.spnlp-1.2/>CopyNext : Explicit Span Copying and Alignment in Sequence to Sequence Models<span class=acl-fixed-case>C</span>opy<span class=acl-fixed-case>N</span>ext: Explicit Span Copying and Alignment in Sequence to Sequence Models</a></strong><br><a href=/people/a/abhinav-singh/>Abhinav Singh</a>
|
<a href=/people/p/patrick-xia/>Patrick Xia</a>
|
<a href=/people/g/guanghui-qin/>Guanghui Qin</a>
|
<a href=/people/m/mahsa-yarmohammadi/>Mahsa Yarmohammadi</a>
|
<a href=/people/b/benjamin-van-durme/>Benjamin Van Durme</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--spnlp-1--2><div class="card-body p-3 small">Copy mechanisms are employed in sequence to sequence (seq2seq) models to generate reproductions of words from the input to the output. These frameworks, operating at the lexical type level, fail to provide an explicit alignment that records where each token was copied from. Further, they require contiguous token sequences from the input (spans) to be copied individually. We present a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> with an explicit token-level copy operation and extend it to copying entire spans. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> provides hard alignments between spans in the input and output, allowing for nontraditional applications of seq2seq, like <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction</a>. We demonstrate the approach on Nested Named Entity Recognition, achieving near state-of-the-art <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> with an order of magnitude increase in decoding speed.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.spnlp-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--spnlp-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.spnlp-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38940154 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.spnlp-1.5/>Energy-based Neural Modelling for Large-Scale Multiple Domain Dialogue State Tracking</a></strong><br><a href=/people/a/anh-duong-trinh/>Anh Duong Trinh</a>
|
<a href=/people/r/robert-j-ross/>Robert J. Ross</a>
|
<a href=/people/j/john-kelleher/>John D. Kelleher</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--spnlp-1--5><div class="card-body p-3 small">Scaling up dialogue state tracking to multiple domains is challenging due to the growth in the number of variables being tracked. Furthermore, dialog state tracking models do not yet explicitly make use of relationships between dialogue variables, such as slots across domains. We propose using energy-based structure prediction methods for large-scale dialogue state tracking task in two multiple domain dialogue datasets. Our results indicate that : (i) modelling variable dependencies yields better results ; and (ii) the structured prediction output aligns with the dialogue slot-value constraint principles. This leads to promising directions to improve state-of-the-art models by incorporating variable dependencies into their prediction process.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.spnlp-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--spnlp-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.spnlp-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.spnlp-1.7.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38940156 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.spnlp-1.7/>Layer-wise Guided Training for BERT : Learning Incrementally Refined Document Representations<span class=acl-fixed-case>BERT</span>: Learning Incrementally Refined Document Representations</a></strong><br><a href=/people/n/nikolaos-manginas/>Nikolaos Manginas</a>
|
<a href=/people/i/ilias-chalkidis/>Ilias Chalkidis</a>
|
<a href=/people/p/prodromos-malakasiotis/>Prodromos Malakasiotis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--spnlp-1--7><div class="card-body p-3 small">Although <a href=https://en.wikipedia.org/wiki/Brain-derived_neurotrophic_factor>BERT</a> is widely used by the <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP community</a>, little is known about its inner workings. Several attempts have been made to shed light on certain aspects of BERT, often with contradicting conclusions. A much raised concern focuses on BERT&#8217;s over-parameterization and under-utilization issues. To this end, we propose o novel approach to fine-tune BERT in a structured manner. Specifically, we focus on Large Scale Multilabel Text Classification (LMTC) where documents are assigned with one or more labels from a large predefined set of hierarchically organized labels. Our approach guides specific BERT layers to predict labels from specific hierarchy levels. Experimenting with two LMTC datasets we show that this structured fine-tuning approach not only yields better <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> results but also leads to better parameter utilization.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.spnlp-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--spnlp-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.spnlp-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.spnlp-1.10.OptionalSupplementaryMaterial.tex data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38940144 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.spnlp-1.10" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.spnlp-1.10/>On the Discrepancy between <a href=https://en.wikipedia.org/wiki/Density_estimation>Density Estimation</a> and Sequence Generation</a></strong><br><a href=/people/j/jason-lee/>Jason Lee</a>
|
<a href=/people/d/dustin-tran/>Dustin Tran</a>
|
<a href=/people/o/orhan-firat/>Orhan Firat</a>
|
<a href=/people/k/kyunghyun-cho/>Kyunghyun Cho</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--spnlp-1--10><div class="card-body p-3 small">Many sequence-to-sequence generation tasks, including <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> and <a href=https://en.wikipedia.org/wiki/Speech_synthesis>text-to-speech</a>, can be posed as estimating the density of the output y given the input x : p(y|x). Given this interpretation, it is natural to evaluate sequence-to-sequence models using conditional log-likelihood on a test set. However, the goal of sequence-to-sequence generation (or structured prediction) is to find the best output y given an input x, and each task has its own downstream metric R that scores a model output by comparing against a set of references y * : R(y, y * | x). While we hope that a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> that excels in <a href=https://en.wikipedia.org/wiki/Density_estimation>density estimation</a> also performs well on the downstream metric, the exact correlation has not been studied for sequence generation tasks. In this paper, by comparing several density estimators on five machine translation tasks, we find that the correlation between rankings of models based on <a href=https://en.wikipedia.org/wiki/Likelihood_function>log-likelihood</a> and BLEU varies significantly depending on the range of the model families being compared. First, <a href=https://en.wikipedia.org/wiki/Likelihood_function>log-likelihood</a> is highly correlated with <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a> when we consider <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> within the same family (e.g. autoregressive models, or <a href=https://en.wikipedia.org/wiki/Latent_variable_model>latent variable models</a> with the same parameterization of the prior).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.spnlp-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--spnlp-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.spnlp-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38940152 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.spnlp-1.12/>Deeply Embedded Knowledge Representation & Reasoning For Natural Language Question Answering : A Practitioner’s Perspective</a></strong><br><a href=/people/a/arindam-mitra/>Arindam Mitra</a>
|
<a href=/people/s/sanjay-narayana/>Sanjay Narayana</a>
|
<a href=/people/c/chitta-baral/>Chitta Baral</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--spnlp-1--12><div class="card-body p-3 small">Successful application of Knowledge Representation and Reasoning (KR) in Natural Language Understanding (NLU) is largely limited by the availability of a robust and general purpose natural language parser. Even though several projects have been launched in the pursuit of developing a universal meaning representation language, the existence of an accurate universal parser is far from reality. This has severely limited the application of knowledge representation and reasoning (KR) in the field of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> and also prevented a proper evaluation of KR based NLU systems. Our goal is to build KR based systems for <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>Natural Language Understanding</a> without relying on a <a href=https://en.wikipedia.org/wiki/Parsing>parser</a>. Towards this we propose a method named Deeply Embedded Knowledge Representation & Reasoning (DeepEKR) where we replace the parser by a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a>, soften the symbolic representation so that a deterministic mapping exists between the parser neural network and the interpretable logical form, and finally replace the symbolic solver by an equivalent <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a>, so the model can be trained end-to-end. We evaluate our method with respect to the task of Qualitative Word Problem Solving on the two available datasets (QuaRTz and QuaRel). Our system achieves same <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> as that of the state-of-the-art <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on QuaRTz, outperforms the state-of-the-art on QuaRel and severely outperforms a traditional KR based system. The results show that the bias introduced by a KR solution does not prevent it from doing a better job at the end task. Moreover, our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> is interpretable due to the bias introduced by the KR approach.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>