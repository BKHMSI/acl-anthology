<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the First Workshop on Language Technology for Equality, Diversity and Inclusion - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Proceedings of the First Workshop on Language Technology for Equality, Diversity and Inclusion</h2><p class=lead><a href=/people/b/bharathi-raja-chakravarthi/>Bharathi Raja Chakravarthi</a>,
<a href=/people/j/john-philip-mccrae/>John P. McCrae</a>,
<a href=/people/m/manel-zarrouk/>Manel Zarrouk</a>,
<a href=/people/k/kalika-bali/>Kalika Bali</a>,
<a href=/people/p/paul-buitelaar/>Paul Buitelaar</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2021.ltedi-1</dd><dt>Month:</dt><dd>April</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Kyiv</dd><dt>Venues:</dt><dd><a href=/venues/eacl/>EACL</a>
| <a href=/venues/ltedi/>LTEDI</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.ltedi-1>https://aclanthology.org/2021.ltedi-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+First+Workshop+on+Language+Technology+for+Equality%2C+Diversity+and+Inclusion" title="Search for 'Proceedings of the First Workshop on Language Technology for Equality, Diversity and Inclusion' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ltedi-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ltedi-1.0/>Proceedings of the First Workshop on Language Technology for Equality, Diversity and Inclusion</a></strong><br><a href=/people/b/bharathi-raja-chakravarthi/>Bharathi Raja Chakravarthi</a>
|
<a href=/people/j/john-philip-mccrae/>John P. McCrae</a>
|
<a href=/people/m/manel-zarrouk/>Manel Zarrouk</a>
|
<a href=/people/k/kalika-bali/>Kalika Bali</a>
|
<a href=/people/p/paul-buitelaar/>Paul Buitelaar</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ltedi-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ltedi-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ltedi-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ltedi-1.1/>Impact of COVID-19 in Natural Language Processing Publications : a Disaggregated Study in Gender, Contribution and Experience<span class=acl-fixed-case>COVID</span>-19 in Natural Language Processing Publications: a Disaggregated Study in Gender, Contribution and Experience</a></strong><br><a href=/people/c/christine-basta/>Christine Basta</a>
|
<a href=/people/m/marta-r-costa-jussa/>Marta R. Costa-jussa</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ltedi-1--1><div class="card-body p-3 small">This study sheds light on the effects of COVID-19 in the particular field of <a href=https://en.wikipedia.org/wiki/Computational_linguistics>Computational Linguistics</a> and <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a> within <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>Artificial Intelligence</a>. We provide an inter-sectional study on gender, contribution, and experience that considers one school year (from August 2019 to August 2020) as a pandemic year. August is included twice for the purpose of an inter-annual comparison. While the trend in publications increased with the crisis, the results show that the ratio between female and male publications decreased. This only helps to reduce the importance of the female role in the scientific contributions of <a href=https://en.wikipedia.org/wiki/Computational_linguistics>computational linguistics</a> (it is now far below its peak of 0.24). The pandemic has a particularly negative effect on the production of female senior researchers in the first position of authors (maximum work), followed by the female junior researchers in the last position of authors (supervision or collaborative work).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ltedi-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ltedi-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ltedi-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ltedi-1.4/>hBERT + BiasCorp-Fighting Racism on the Web<span class=acl-fixed-case>BERT</span> + <span class=acl-fixed-case>B</span>ias<span class=acl-fixed-case>C</span>orp - Fighting Racism on the Web</a></strong><br><a href=/people/o/olawale-onabola/>Olawale Onabola</a>
|
<a href=/people/z/zhuang-ma/>Zhuang Ma</a>
|
<a href=/people/x/xie-yang/>Xie Yang</a>
|
<a href=/people/b/benjamin-akera/>Benjamin Akera</a>
|
<a href=/people/i/ibraheem-abdulrahman/>Ibraheem Abdulrahman</a>
|
<a href=/people/j/jia-xue/>Jia Xue</a>
|
<a href=/people/d/dianbo-liu/>Dianbo Liu</a>
|
<a href=/people/y/yoshua-bengio/>Yoshua Bengio</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ltedi-1--4><div class="card-body p-3 small">Subtle and overt racism is still present both in physical and online communities today and has impacted many lives in different segments of the society. In this short piece of work, we present how we&#8217;re tackling this societal issue with <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a>. We are releasing BiasCorp, a dataset containing 139,090 comments and news segment from three specific sources-Fox News, <a href=https://en.wikipedia.org/wiki/Breitbart_News>BreitbartNews</a> and <a href=https://en.wikipedia.org/wiki/YouTube>YouTube</a>. The first batch (45,000 manually annotated) is ready for publication. We are currently in the final phase of manually labeling the remaining <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> using <a href=https://en.wikipedia.org/wiki/Amazon_Mechanical_Turk>Amazon Mechanical Turk</a>. BERT has been used widely in several downstream tasks. In this work, we present hBERT, where we modify certain layers of the pretrained BERT model with the new Hopfield Layer. hBert generalizes well across different distributions with the added advantage of a reduced model complexity. We are also releasing a JavaScript library 3 and a Chrome Extension Application, to help developers make use of our trained model in web applications (say chat application) and for users to identify and report racially biased contents on the web respectively</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ltedi-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ltedi-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ltedi-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ltedi-1.5/>An Overview of Fairness in Data Illuminating the Bias in Data Pipeline</a></strong><br><a href=/people/s/senthil-kumar-b/>Senthil Kumar B</a>
|
<a href=/people/a/aravindan-chandrabose/>Aravindan Chandrabose</a>
|
<a href=/people/b/bharathi-raja-chakravarthi/>Bharathi Raja Chakravarthi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ltedi-1--5><div class="card-body p-3 small">Data in general encodes human biases by default ; being aware of this is a good start, and the research around how to handle it is ongoing. The term &#8216;<a href=https://en.wikipedia.org/wiki/Bias>bias</a>&#8217; is extensively used in various contexts in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP systems</a>. In our research the focus is specific to biases such as <a href=https://en.wikipedia.org/wiki/Gender>gender</a>, <a href=https://en.wikipedia.org/wiki/Racism>racism</a>, <a href=https://en.wikipedia.org/wiki/Religion>religion</a>, demographic and other intersectional views on biases that prevail in text processing systems responsible for systematically discriminating specific population, which is not ethical in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. These <a href=https://en.wikipedia.org/wiki/Bias>biases</a> exacerbate the lack of <a href=https://en.wikipedia.org/wiki/Social_equality>equality</a>, <a href=https://en.wikipedia.org/wiki/Multiculturalism>diversity</a> and inclusion of specific population while utilizing the <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP applications</a>. The tools and technology at the intermediate level utilize <a href=https://en.wikipedia.org/wiki/Bias_(statistics)>biased data</a>, and transfer or amplify this <a href=https://en.wikipedia.org/wiki/Bias_(statistics)>bias</a> to the downstream applications. However, it is not enough to be colourblind, gender-neutral alone when designing a unbiased technology instead, we should take a conscious effort by designing a unified framework to measure and benchmark the <a href=https://en.wikipedia.org/wiki/Bias>bias</a>. In this paper, we recommend six measures and one augment measure based on the observations of the bias in data, annotations, text representations and debiasing techniques.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ltedi-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ltedi-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ltedi-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ltedi-1.6/>GEPSA, a tool for monitoring social challenges in <a href=https://en.wikipedia.org/wiki/Digital_media>digital press</a><span class=acl-fixed-case>GEPSA</span>, a tool for monitoring social challenges in digital press</a></strong><br><a href=/people/i/inaki-san-vicente/>Iñaki San Vicente</a>
|
<a href=/people/x/xabier-saralegi/>Xabier Saralegi</a>
|
<a href=/people/n/nerea-zubia/>Nerea Zubia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ltedi-1--6><div class="card-body p-3 small">This papers presents a platform for monitoring press narratives with respect to several social challenges, including <a href=https://en.wikipedia.org/wiki/Gender_equality>gender equality</a>, <a href=https://en.wikipedia.org/wiki/Human_migration>migrations</a> and <a href=https://en.wikipedia.org/wiki/Minority_language>minority languages</a>. As narratives are encoded in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language</a>, we have to use natural processing techniques to automate their analysis. Thus, crawled news are processed by means of several NLP modules, including <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>, keyword extraction, <a href=https://en.wikipedia.org/wiki/Document_classification>document classification</a> for social challenge detection, and <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>. A Flask powered interface provides <a href=https://en.wikipedia.org/wiki/Data_visualization>data visualization</a> for a user-based analysis of the data. This paper presents the architecture of the <a href=https://en.wikipedia.org/wiki/System>system</a> and describes in detail its different components. Evaluation is provided for the <a href=https://en.wikipedia.org/wiki/Modular_design>modules</a> related to extraction and classification of information regarding <a href=https://en.wikipedia.org/wiki/Social_issue>social challenges</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ltedi-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ltedi-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ltedi-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.ltedi-1.7.Dataset.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.ltedi-1.7" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.ltedi-1.7/>Finding Spoiler Bias in Tweets by Zero-shot Learning and Knowledge Distilling from Neural Text Simplification</a></strong><br><a href=/people/a/avi-bleiweiss/>Avi Bleiweiss</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ltedi-1--7><div class="card-body p-3 small">Automatic detection of critical plot information in reviews of media items poses unique challenges to both <a href=https://en.wikipedia.org/wiki/Social_computing>social computing</a> and <a href=https://en.wikipedia.org/wiki/Computational_linguistics>computational linguistics</a>. In this paper we propose to cast the problem of discovering spoiler bias in online discourse as a text simplification task. We conjecture that for an item-user pair, the simpler the user review we learn from an item summary the higher its likelihood to present a spoiler. Our neural model incorporates the advanced transformer network to rank the severity of a spoiler in user tweets. We constructed a sustainable high-quality movie dataset scraped from unsolicited review tweets and paired with a title summary and meta-data extracted from a movie specific domain. To a large extent, our quantitative and qualitative results weigh in on the performance impact of named entity presence in <a href=https://en.wikipedia.org/wiki/Plot_(graphics)>plot summaries</a>. Pretrained on a split-and-rephrase corpus with knowledge distilled from <a href=https://en.wikipedia.org/wiki/English_Wikipedia>English Wikipedia</a> and fine-tuned on our movie dataset, our neural model shows to outperform both a language modeler and monolingual translation baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ltedi-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ltedi-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ltedi-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.ltedi-1.13.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.ltedi-1.13" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.ltedi-1.13/>IIITT@LT-EDI-EACL2021-Hope Speech Detection : There is always hope in Transformers<span class=acl-fixed-case>IIITT</span>@<span class=acl-fixed-case>LT</span>-<span class=acl-fixed-case>EDI</span>-<span class=acl-fixed-case>EACL</span>2021-Hope Speech Detection: There is always hope in Transformers</a></strong><br><a href=/people/k/karthik-puranik/>Karthik Puranik</a>
|
<a href=/people/a/adeep-hande/>Adeep Hande</a>
|
<a href=/people/r/ruba-priyadharshini/>Ruba Priyadharshini</a>
|
<a href=/people/s/sajeetha-thavareesan/>Sajeetha Thavareesan</a>
|
<a href=/people/b/bharathi-raja-chakravarthi/>Bharathi Raja Chakravarthi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ltedi-1--13><div class="card-body p-3 small">In a world with serious challenges like <a href=https://en.wikipedia.org/wiki/Climate_change>climate change</a>, religious and political conflicts, global pandemics, <a href=https://en.wikipedia.org/wiki/Terrorism>terrorism</a>, and racial discrimination, an <a href=https://en.wikipedia.org/wiki/Internet>internet</a> full of <a href=https://en.wikipedia.org/wiki/Hate_speech>hate speech</a>, abusive and offensive content is the last thing we desire for. In this paper, we work to identify and promote positive and supportive content on these <a href=https://en.wikipedia.org/wiki/Computing_platform>platforms</a>. We work with several transformer-based models to classify social media comments as hope speech or not hope speech in <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam</a>, and Tamil languages. This paper portrays our work for the Shared Task on Hope Speech Detection for Equality, Diversity, and Inclusion at LT-EDI 2021- EACL 2021. The codes for our best submission can be viewed.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ltedi-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ltedi-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ltedi-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.ltedi-1.16.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.ltedi-1.16/>ZYJ@LT-EDI-EACL2021 : XLM-RoBERTa-Based Model with Attention for Hope Speech Detection<span class=acl-fixed-case>ZYJ</span>@<span class=acl-fixed-case>LT</span>-<span class=acl-fixed-case>EDI</span>-<span class=acl-fixed-case>EACL</span>2021:<span class=acl-fixed-case>XLM</span>-<span class=acl-fixed-case>R</span>o<span class=acl-fixed-case>BERT</span>a-Based Model with Attention for Hope Speech Detection</a></strong><br><a href=/people/y/yingjia-zhao/>Yingjia Zhao</a>
|
<a href=/people/x/xin-tao/>Xin Tao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ltedi-1--16><div class="card-body p-3 small">Due to the development of modern computer technology and the increase in the number of online media users, we can see all kinds of posts and comments everywhere on the internet. Hope speech can not only inspire the creators but also make other viewers pleasant. It is necessary to effectively and automatically detect hope speech. This paper describes the approach of our team in the task of hope speech detection. We use the attention mechanism to adjust the weight of all the output layers of XLM-RoBERTa to make full use of the information extracted from each layer, and use the weighted sum of all the output layers to complete the classification task. And we use the Stratified-K-Fold method to enhance the <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training data set</a>. We achieve a weighted average F1-score of 0.59, 0.84, and 0.92 for <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil</a>, <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam</a>, and <a href=https://en.wikipedia.org/wiki/English_language>English language</a>, ranked 3rd, 2nd, and 2nd.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ltedi-1.20.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ltedi-1--20 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ltedi-1.20 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.ltedi-1.20.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.ltedi-1.20/>TeamUNCC@LT-EDI-EACL2021 : Hope Speech Detection using Transfer Learning with Transformers<span class=acl-fixed-case>T</span>eam<span class=acl-fixed-case>UNCC</span>@<span class=acl-fixed-case>LT</span>-<span class=acl-fixed-case>EDI</span>-<span class=acl-fixed-case>EACL</span>2021: Hope Speech Detection using Transfer Learning with Transformers</a></strong><br><a href=/people/k/khyati-mahajan/>Khyati Mahajan</a>
|
<a href=/people/e/erfan-al-hossami/>Erfan Al-Hossami</a>
|
<a href=/people/s/samira-shaikh/>Samira Shaikh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ltedi-1--20><div class="card-body p-3 small">In this paper, we describe our approach towards utilizing pre-trained models for the task of hope speech detection. We participated in Task 2 : Hope Speech Detection for Equality, Diversity and Inclusion at LT-EDI-2021 @ EACL2021. The goal of this task is to predict the presence of hope speech, along with the presence of samples that do not belong to the same language in the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. We describe our approach to fine-tuning RoBERTa for Hope Speech detection in <a href=https://en.wikipedia.org/wiki/English_language>English</a> and our approach to fine-tuning XLM-RoBERTa for Hope Speech detection in <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil</a> and <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam</a>, two low resource Indic languages. We demonstrate the performance of our approach on classifying text into hope-speech, non-hope and not-language. Our approach ranked 1st in <a href=https://en.wikipedia.org/wiki/English_language>English</a> (F1 = 0.93), 1st in <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil</a> (F1 = 0.61) and 3rd in <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam</a> (F1 = 0.83).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ltedi-1.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ltedi-1--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ltedi-1.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.ltedi-1.21.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.ltedi-1.21/>Autobots@LT-EDI-EACL2021 : One World, One Family : Hope Speech Detection with BERT Transformer Model<span class=acl-fixed-case>LT</span>-<span class=acl-fixed-case>EDI</span>-<span class=acl-fixed-case>EACL</span>2021: One World, One Family: Hope Speech Detection with <span class=acl-fixed-case>BERT</span> Transformer Model</a></strong><br><a href=/people/s/sunil-gundapu/>Sunil Gundapu</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ltedi-1--21><div class="card-body p-3 small">The rapid rise of <a href=https://en.wikipedia.org/wiki/List_of_social_networking_websites>online social networks</a> like <a href=https://en.wikipedia.org/wiki/YouTube>YouTube</a>, <a href=https://en.wikipedia.org/wiki/Facebook>Facebook</a>, <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> allows people to express their views more widely online. However, at the same time, it can lead to an increase in <a href=https://en.wikipedia.org/wiki/Conflict_(process)>conflict</a> and hatred among consumers in the form of <a href=https://en.wikipedia.org/wiki/Freedom_of_speech>freedom of speech</a>. Therefore, it is essential to take a positive strengthening method to research on encouraging, positive, helping, and supportive social media content. In this paper, we describe a Transformer-based BERT model for Hope speech detection for equality, diversity, and inclusion, submitted for LT-EDI-2021 Task 2. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves a weighted averaged f1-score of 0.93 on the test set.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ltedi-1.24.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ltedi-1--24 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ltedi-1.24 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ltedi-1.24/>Hopeful NLP@LT-EDI-EACL2021 : Finding Hope in YouTube Comment Section<span class=acl-fixed-case>NLP</span>@<span class=acl-fixed-case>LT</span>-<span class=acl-fixed-case>EDI</span>-<span class=acl-fixed-case>EACL</span>2021: Finding Hope in <span class=acl-fixed-case>Y</span>ou<span class=acl-fixed-case>T</span>ube Comment Section</a></strong><br><a href=/people/v/vasudev-awatramani/>Vasudev Awatramani</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ltedi-1--24><div class="card-body p-3 small">The proliferation of <a href=https://en.wikipedia.org/wiki/Hate_speech>Hate Speech</a> and <a href=https://en.wikipedia.org/wiki/Misinformation>misinformation</a> in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> is fast becoming a menace to society. In compliment, the dissemination of hate-diffusing, promising and anti-oppressive messages become a unique alternative. Unfortunately, due to its complex nature as well as the relatively limited manifestation in comparison to hostile and neutral content, the identification of Hope Speech becomes a challenge. This work revolves around the detection of Hope Speech in Youtube comments, for the Shared Task on Hope Speech Detection for <a href=https://en.wikipedia.org/wiki/Social_equality>Equality</a>, <a href=https://en.wikipedia.org/wiki/Multiculturalism>Diversity</a>, and <a href=https://en.wikipedia.org/wiki/Inclusion_(disability_rights)>Inclusion</a>. We achieve an <a href=https://en.wikipedia.org/wiki/F-score>f-score</a> of 0.93, ranking 1st on the <a href=https://en.wikipedia.org/wiki/Glossary_of_French_expressions_in_English>leaderboard</a> for English comments.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ltedi-1.25.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ltedi-1--25 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ltedi-1.25 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.ltedi-1.25.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.ltedi-1.25" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.ltedi-1.25/>NLP-CUET@LT-EDI-EACL2021 : Multilingual Code-Mixed Hope Speech Detection using Cross-lingual Representation Learner<span class=acl-fixed-case>NLP</span>-<span class=acl-fixed-case>CUET</span>@<span class=acl-fixed-case>LT</span>-<span class=acl-fixed-case>EDI</span>-<span class=acl-fixed-case>EACL</span>2021: Multilingual Code-Mixed Hope Speech Detection using Cross-lingual Representation Learner</a></strong><br><a href=/people/e/eftekhar-hossain/>Eftekhar Hossain</a>
|
<a href=/people/o/omar-sharif/>Omar Sharif</a>
|
<a href=/people/m/mohammed-moshiul-hoque/>Mohammed Moshiul Hoque</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ltedi-1--25><div class="card-body p-3 small">In recent years, several systems have been developed to regulate the spread of negativity and eliminate aggressive, offensive or abusive contents from the online platforms. Nevertheless, a limited number of researches carried out to identify positive, encouraging and supportive contents. In this work, our goal is to identify whether a social media post / comment contains hope speech or not. We propose three distinct models to identify hope speech in English, Tamil and Malayalam language to serve this purpose. To attain this goal, we employed various machine learning (SVM, LR, ensemble), deep learning (CNN+BiLSTM) and transformer (m-BERT, Indic-BERT, XLNet, XLM-R) based methods. Results indicate that XLM-R outdoes all other techniques by gaining a <a href=https://en.wikipedia.org/wiki/Weighted_arithmetic_mean>weighted f_1-score</a> of 0.93, 0.60 and 0.85 respectively for English, Tamil and Malayalam language. Our team has achieved 1st, 2nd and 1st rank in these three <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ltedi-1.28.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ltedi-1--28 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ltedi-1.28 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.ltedi-1.28.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.ltedi-1.28/>Spartans@LT-EDI-EACL2021 : Inclusive Speech Detection using Pretrained Language Models<span class=acl-fixed-case>LT</span>-<span class=acl-fixed-case>EDI</span>-<span class=acl-fixed-case>EACL</span>2021: Inclusive Speech Detection using Pretrained Language Models</a></strong><br><a href=/people/m/megha-sharma/>Megha Sharma</a>
|
<a href=/people/g/gaurav-arora/>Gaurav Arora</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ltedi-1--28><div class="card-body p-3 small">We describe our system that ranked first in Hope Speech Detection (HSD) shared task and fourth in Offensive Language Identification (OLI) shared task, both in <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil language</a>. The goal of HSD and OLI is to identify if a code-mixed comment or post contains hope speech or offensive content respectively. We pre-train a transformer-based model RoBERTa using synthetically generated code-mixed data and use it in an ensemble along with their pre-trained ULMFiT model available from iNLTK.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>