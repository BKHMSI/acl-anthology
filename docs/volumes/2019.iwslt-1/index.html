<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 16th International Conference on Spoken Language Translation - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Proceedings of the 16th International Conference on Spoken Language Translation</h2><p class=lead><a href=/people/j/jan-niehues/>Jan Niehues</a>,
<a href=/people/r/rolando-cattoni/>Rolando Cattoni</a>,
<a href=/people/s/sebastian-stuker/>Sebastian Stüker</a>,
<a href=/people/m/matteo-negri/>Matteo Negri</a>,
<a href=/people/m/marco-turchi/>Marco Turchi</a>,
<a href=/people/t/thanh-le-ha/>Thanh-Le Ha</a>,
<a href=/people/e/elizabeth-salesky/>Elizabeth Salesky</a>,
<a href=/people/r/ramon-sanabria/>Ramon Sanabria</a>,
<a href=/people/l/loic-barrault/>Loic Barrault</a>,
<a href=/people/l/lucia-specia/>Lucia Specia</a>,
<a href=/people/m/marcello-federico/>Marcello Federico</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2019.iwslt-1</dd><dt>Month:</dt><dd>November 2-3</dd><dt>Year:</dt><dd>2019</dd><dt>Address:</dt><dd>Hong Kong</dd><dt>Venues:</dt><dd><a href=/venues/emnlp/>EMNLP</a>
| <a href=/venues/iwslt/>IWSLT</a></dd><dt>SIG:</dt><dd><a href=/sigs/sigslt/>SIGSLT</a></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2019.iwslt-1>https://aclanthology.org/2019.iwslt-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+16th+International+Conference+on+Spoken+Language+Translation" title="Search for 'Proceedings of the 16th International Conference on Spoken Language Translation' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.iwslt-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--iwslt-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.iwslt-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.iwslt-1.1/>The IWSLT 2019 Evaluation Campaign<span class=acl-fixed-case>IWSLT</span> 2019 Evaluation Campaign</a></strong><br><a href=/people/j/jan-niehues/>Jan Niehues</a>
|
<a href=/people/r/rolando-cattoni/>Rolando Cattoni</a>
|
<a href=/people/s/sebastian-stuker/>Sebastian Stüker</a>
|
<a href=/people/m/matteo-negri/>Matteo Negri</a>
|
<a href=/people/m/marco-turchi/>Marco Turchi</a>
|
<a href=/people/t/thanh-le-ha/>Thanh-Le Ha</a>
|
<a href=/people/e/elizabeth-salesky/>Elizabeth Salesky</a>
|
<a href=/people/r/ramon-sanabria/>Ramon Sanabria</a>
|
<a href=/people/l/loic-barrault/>Loic Barrault</a>
|
<a href=/people/l/lucia-specia/>Lucia Specia</a>
|
<a href=/people/m/marcello-federico/>Marcello Federico</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--iwslt-1--1><div class="card-body p-3 small">The IWSLT 2019 evaluation campaign featured three tasks : speech translation of (i) <a href=https://en.wikipedia.org/wiki/TED_(conference)>TED talks</a> and (ii) How2 instructional videos from <a href=https://en.wikipedia.org/wiki/English_language>English</a> into <a href=https://en.wikipedia.org/wiki/German_language>German</a> and <a href=https://en.wikipedia.org/wiki/Portuguese_language>Portuguese</a>, and (iii) text translation of <a href=https://en.wikipedia.org/wiki/TED_(conference)>TED talks</a> from <a href=https://en.wikipedia.org/wiki/English_language>English</a> into <a href=https://en.wikipedia.org/wiki/Czech_language>Czech</a>. For the first two tasks we encouraged submissions of end- to-end speech-to-text systems, and for the second task participants could also use the video as additional input. We received submissions by 12 research teams. This overview provides detailed descriptions of the data and evaluation conditions of each task and reports results of the participating systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.iwslt-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--iwslt-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.iwslt-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.iwslt-1.4/>ESPnet How2 Speech Translation System for IWSLT 2019 : Pre-training, Knowledge Distillation, and Going Deeper<span class=acl-fixed-case>ESP</span>net How2 Speech Translation System for <span class=acl-fixed-case>IWSLT</span> 2019: Pre-training, Knowledge Distillation, and Going Deeper</a></strong><br><a href=/people/h/hirofumi-inaguma/>Hirofumi Inaguma</a>
|
<a href=/people/s/shun-kiyono/>Shun Kiyono</a>
|
<a href=/people/n/nelson-enrique-yalta-soplin/>Nelson Enrique Yalta Soplin</a>
|
<a href=/people/j/jun-suzuki/>Jun Suzuki</a>
|
<a href=/people/k/kevin-duh/>Kevin Duh</a>
|
<a href=/people/s/shinji-watanabe/>Shinji Watanabe</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--iwslt-1--4><div class="card-body p-3 small">This paper describes the ESPnet submissions to the How2 Speech Translation task at IWSLT2019. In this year, we mainly build our systems based on Transformer architectures in all tasks and focus on the end-to-end speech translation (E2E-ST). We first compare RNN-based models and Transformer, and then confirm Transformer models significantly and consistently outperform RNN models in all tasks and corpora. Next, we investigate pre-training of E2E-ST models with the ASR and MT tasks. On top of the pre-training, we further explore knowledge distillation from the NMT model and the deeper speech encoder, and confirm drastic improvements over the baseline model. All of our codes are publicly available in ESPnet.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.iwslt-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--iwslt-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.iwslt-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.iwslt-1.5/>ON-TRAC Consortium End-to-End Speech Translation Systems for the IWSLT 2019 Shared Task<span class=acl-fixed-case>ON</span>-<span class=acl-fixed-case>TRAC</span> Consortium End-to-End Speech Translation Systems for the <span class=acl-fixed-case>IWSLT</span> 2019 Shared Task</a></strong><br><a href=/people/h/ha-nguyen/>Ha Nguyen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--iwslt-1--5><div class="card-body p-3 small">This paper describes the ON-TRAC Consortium translation systems developed for the end-to-end model task of IWSLT Evaluation 2019 for the English Portuguese language pair. ON-TRAC Consortium is composed of researchers from three French academic laboratories : LIA (Avignon Universit), LIG (Universit Grenoble Alpes), and LIUM (Le Mans Universit). A single end-to-end model built as a neural encoder-decoder architecture with attention mechanism was used for two primary submissions corresponding to the two EN-PT evaluations sets : (1) TED (MuST-C) and (2) How2. In this paper, we notably investigate impact of pooling heterogeneous corpora for training, impact of target tokenization (characters or BPEs), impact of <a href=https://en.wikipedia.org/wiki/Speech_segmentation>speech input segmentation</a> and we also compare our best <a href=https://en.wikipedia.org/wiki/End-to-end_principle>end-to-end model</a> (BLEU of 26.91 on MuST-C and 43.82 on How2 validation sets) to a pipeline (ASR+MT) approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.iwslt-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--iwslt-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.iwslt-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.iwslt-1.6/>Transformer-based Cascaded Multimodal Speech Translation</a></strong><br><a href=/people/z/zixiu-wu/>Zixiu Wu</a>
|
<a href=/people/o/ozan-caglayan/>Ozan Caglayan</a>
|
<a href=/people/j/julia-ive/>Julia Ive</a>
|
<a href=/people/j/josiah-wang/>Josiah Wang</a>
|
<a href=/people/l/lucia-specia/>Lucia Specia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--iwslt-1--6><div class="card-body p-3 small">This paper describes the cascaded multimodal speech translation systems developed by Imperial College London for the IWSLT 2019 evaluation campaign. The architecture consists of an automatic speech recognition (ASR) system followed by a Transformer-based multimodal machine translation (MMT) system. While the ASR component is identical across the experiments, the MMT model varies in terms of the way of integrating the <a href=https://en.wikipedia.org/wiki/Context_(language_use)>visual context</a> (simple conditioning vs. attention), the type of <a href=https://en.wikipedia.org/wiki/Visual_system>visual features</a> exploited (pooled, convolutional, action categories) and the underlying architecture. For the latter, we explore both the canonical transformer and its deliberation version with additive and cascade variants which differ in how they integrate the textual attention. Upon conducting extensive experiments, we found that (i) the explored visual integration schemes often harm the translation performance for the transformer and additive deliberation, but considerably improve the cascade deliberation ; (ii) the transformer and cascade deliberation integrate the visual modality better than the additive deliberation, as shown by the incongruence analysis.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.iwslt-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--iwslt-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.iwslt-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.iwslt-1.11/>The LIG system for the English-Czech Text Translation Task of IWSLT 2019<span class=acl-fixed-case>LIG</span> system for the <span class=acl-fixed-case>E</span>nglish-<span class=acl-fixed-case>C</span>zech Text Translation Task of <span class=acl-fixed-case>IWSLT</span> 2019</a></strong><br><a href=/people/l/loic-vial/>Loïc Vial</a>
|
<a href=/people/b/benjamin-lecouteux/>Benjamin Lecouteux</a>
|
<a href=/people/d/didier-schwab/>Didier Schwab</a>
|
<a href=/people/h/hang-le/>Hang Le</a>
|
<a href=/people/l/laurent-besacier/>Laurent Besacier</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--iwslt-1--11><div class="card-body p-3 small">In this paper, we present our submission for the English to Czech Text Translation Task of IWSLT 2019. Our system aims to study how pre-trained language models, used as input embeddings, can improve a specialized machine translation system trained on few data. Therefore, we implemented a Transformer-based encoder-decoder neural system which is able to use the output of a pre-trained language model as input embeddings, and we compared its performance under three configurations : 1) without any pre-trained language model (constrained), 2) using a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> trained on the monolingual parts of the allowed English-Czech data (constrained), and 3) using a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> trained on a large quantity of external monolingual data (unconstrained). We used BERT as external pre-trained language model (configuration 3), and BERT architecture for training our own <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> (configuration 2). Regarding the training data, we trained our MT system on a small quantity of parallel text : one set only consists of the provided MuST-C corpus, and the other set consists of the MuST-C corpus and the News Commentary corpus from WMT. We observed that using the external pre-trained BERT improves the scores of our <a href=https://en.wikipedia.org/wiki/System>system</a> by +0.8 to +1.5 of BLEU on our development set, and +0.97 to +1.94 of BLEU on the test set. However, using our own <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> trained only on the allowed parallel data seems to improve the <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> performances only when the system is trained on the smallest dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.iwslt-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--iwslt-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.iwslt-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.iwslt-1.13/>KIT’s Submission to the IWSLT 2019 Shared Task on Text Translation<span class=acl-fixed-case>KIT</span>’s Submission to the <span class=acl-fixed-case>IWSLT</span> 2019 Shared Task on Text Translation</a></strong><br><a href=/people/f/felix-schneider/>Felix Schneider</a>
|
<a href=/people/a/alex-waibel/>Alex Waibel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--iwslt-1--13><div class="card-body p-3 small">In this paper, we describe KIT&#8217;s submission for the IWSLT 2019 shared task on text translation. Our <a href=https://en.wikipedia.org/wiki/System>system</a> is based on the transformer model [ 1 ] using our in-house implementation. We augment the available training data using <a href=https://en.wikipedia.org/wiki/Back-translation>back-translation</a> and employ <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> for the final <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>. For our best results, we used a 12-layer transformer-big config- uration, achieving state-of-the-art results on the WMT2018 test set. We also experiment with student-teacher models to improve performance of smaller <a href=https://en.wikipedia.org/wiki/Computer_simulation>models</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.iwslt-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--iwslt-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.iwslt-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2019.iwslt-1.16" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2019.iwslt-1.16/>Adapting Multilingual Neural Machine Translation to Unseen Languages</a></strong><br><a href=/people/s/surafel-m-lakew/>Surafel M. Lakew</a>
|
<a href=/people/a/alina-karakanta/>Alina Karakanta</a>
|
<a href=/people/m/marcello-federico/>Marcello Federico</a>
|
<a href=/people/m/matteo-negri/>Matteo Negri</a>
|
<a href=/people/m/marco-turchi/>Marco Turchi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--iwslt-1--16><div class="card-body p-3 small">Multilingual Neural Machine Translation (MNMT) for low- resource languages (LRL) can be enhanced by the presence of related high-resource languages (HRL), but the relatedness of HRL usually relies on predefined linguistic assumptions about language similarity. Recently, adapting MNMT to a <a href=https://en.wikipedia.org/wiki/Linear_regression>LRL</a> has shown to greatly improve performance. In this work, we explore the problem of adapting an MNMT model to an unseen <a href=https://en.wikipedia.org/wiki/Linear_regression>LRL</a> using data selection and model adapta- tion. In order to improve NMT for <a href=https://en.wikipedia.org/wiki/Linguistic_description>LRL</a>, we employ perplexity to select HRL data that are most similar to the <a href=https://en.wikipedia.org/wiki/Linguistic_description>LRL</a> on the basis of <a href=https://en.wikipedia.org/wiki/Language_distance>language distance</a>. We extensively explore data selection in popular multilingual NMT settings, namely in (zero-shot) translation, and in adaptation from a multilingual pre-trained model, for both directions (LRLen). We further show that dynamic adaptation of the model&#8217;s vocabulary results in a more favourable segmentation for the LRL in comparison with direct adaptation. Experiments show re- ductions in training time and significant performance gains over LRL baselines, even with zero LRL data (+13.0 BLEU), up to +17.0 BLEU for pre-trained multilingual model dynamic adaptation with related data selection. Our method outperforms current approaches, such as massively multilingual models and <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a>, on four <a href=https://en.wikipedia.org/wiki/Linear_regression>LRL</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.iwslt-1.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--iwslt-1--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.iwslt-1.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2019.iwslt-1.17" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2019.iwslt-1.17/>Transformers without Tears : Improving the Normalization of Self-Attention</a></strong><br><a href=/people/t/toan-q-nguyen/>Toan Q. Nguyen</a>
|
<a href=/people/j/julian-salazar/>Julian Salazar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--iwslt-1--17><div class="card-body p-3 small">We evaluate three simple, normalization-centric changes to improve Transformer training. First, we show that pre-norm residual connections (PRENORM) and smaller initializations enable warmup-free, validation-based training with large learning rates. Second, we propose l2 normalization with a single scale parameter (SCALENORM) for faster training and better performance. Finally, we reaffirm the effectiveness of normalizing word embeddings to a fixed length (FIXNORM). On five low-resource translation pairs from <a href=https://en.wikipedia.org/wiki/TED_(conference)>TED Talks-based corpora</a>, these changes always converge, giving an average +1.1 BLEU over state-of-the-art bilingual baselines and a new 32.8 BLEU on IWSLT&#8217; 15 English-Vietnamese. We ob- serve sharper performance curves, more consistent gradient norms, and a linear relationship between activation scaling and decoder depth. Surprisingly, in the high-resource setting (WMT&#8217; 14 English-German), SCALENORM and FIXNORM remain competitive but PRENORM degrades performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.iwslt-1.18.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--iwslt-1--18 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.iwslt-1.18 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.iwslt-1.18/>Harnessing Indirect Training Data for End-to-End Automatic Speech Translation : Tricks of the Trade</a></strong><br><a href=/people/j/juan-pino/>Juan Pino</a>
|
<a href=/people/l/liezl-puzon/>Liezl Puzon</a>
|
<a href=/people/j/jiatao-gu/>Jiatao Gu</a>
|
<a href=/people/x/xutai-ma/>Xutai Ma</a>
|
<a href=/people/a/arya-d-mccarthy/>Arya D. McCarthy</a>
|
<a href=/people/d/deepak-gopinath/>Deepak Gopinath</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--iwslt-1--18><div class="card-body p-3 small">For automatic speech translation (AST), end-to-end approaches are outperformed by cascaded models that transcribe with automatic speech recognition (ASR), then trans- late with machine translation (MT). A major cause of the performance gap is that, while existing AST corpora are small, massive datasets exist for both the ASR and MT subsystems. In this work, we evaluate several data augmentation and pretraining approaches for <a href=https://en.wikipedia.org/wiki/Abstract_syntax_tree>AST</a>, by comparing all on the same <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>. Simple <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> by translating ASR transcripts proves most effective on the EnglishFrench augmented LibriSpeech dataset, closing the performance gap from 8.2 to 1.4 BLEU, compared to a very strong cascade that could directly utilize copious ASR and MT data. The same <a href=https://en.wikipedia.org/wiki/End-to-end_principle>end-to-end approach</a> plus <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> closes the gap on the EnglishRomanian MuST-C dataset from 6.7 to 3.7 <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>. In addition to these results, we present practical rec- ommendations for augmentation and pretraining approaches. Finally, we decrease the performance gap to 0.01 BLEU us- ing a Transformer-based architecture.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.iwslt-1.22.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--iwslt-1--22 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.iwslt-1.22 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.iwslt-1.22/>On Using SpecAugment for End-to-End Speech Translation<span class=acl-fixed-case>S</span>pec<span class=acl-fixed-case>A</span>ugment for End-to-End Speech Translation</a></strong><br><a href=/people/p/parnia-bahar/>Parnia Bahar</a>
|
<a href=/people/a/albert-zeyer/>Albert Zeyer</a>
|
<a href=/people/r/ralf-schlueter/>Ralf Schlüter</a>
|
<a href=/people/h/hermann-ney/>Hermann Ney</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--iwslt-1--22><div class="card-body p-3 small">This work investigates a simple data augmentation technique, SpecAugment, for end-to-end speech translation. SpecAugment is a low-cost implementation method applied directly to the audio input features and it consists of masking blocks of frequency channels, and/or time steps. We apply SpecAugment on end-to-end speech translation tasks and achieve up to +2.2 % BLEU on LibriSpeech Audiobooks EnFr and +1.2 % on IWSLT TED-talks EnDe by alleviating <a href=https://en.wikipedia.org/wiki/Overfitting>overfitting</a> to some extent. We also examine the effectiveness of the <a href=https://en.wikipedia.org/wiki/Methodology>method</a> in a variety of data scenarios and show that the <a href=https://en.wikipedia.org/wiki/Methodology>method</a> also leads to significant improvements in various data conditions irrespective of the amount of training data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.iwslt-1.23.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--iwslt-1--23 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.iwslt-1.23 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2019.iwslt-1.23" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2019.iwslt-1.23/>Estimating post-editing effort : a study on human judgements, task-based and reference-based metrics of MT quality<span class=acl-fixed-case>MT</span> quality</a></strong><br><a href=/people/s/scarton-scarton/>Scarton Scarton</a>
|
<a href=/people/m/mikel-l-forcada/>Mikel L. Forcada</a>
|
<a href=/people/m/miquel-espla-gomis/>Miquel Esplà-Gomis</a>
|
<a href=/people/l/lucia-specia/>Lucia Specia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--iwslt-1--23><div class="card-body p-3 small">Devising <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> to assess translation quality has always been at the core of machine translation (MT) research. Traditional automatic reference-based metrics, such as <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>, have shown correlations with human judgements of adequacy and fluency and have been paramount for the advancement of MT system development. Crowd-sourcing has popularised and enabled the scalability of <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> based on human judgments, such as subjective direct assessments (DA) of adequacy, that are believed to be more reliable than reference-based automatic metrics. Finally, task-based measurements, such as post-editing time, are expected to provide a more de- tailed evaluation of the usefulness of translations for a specific task. Therefore, while DA averages adequacy judgements to obtain an appraisal of (perceived) quality independently of the task, and reference-based automatic metrics try to objectively estimate quality also in a task-independent way, task-based metrics are measurements obtained either during or after performing a specific task. In this paper we argue that, although expensive, task-based measurements are the most reliable when estimating MT quality in a specific task ; in our case, this task is <a href=https://en.wikipedia.org/wiki/Post-editing>post-editing</a>. To that end, we report experiments on a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> with newly-collected post-editing indicators and show their usefulness when estimating post-editing effort. Our results show that task-based metrics comparing machine-translated and post-edited versions are the best at tracking post-editing effort, as expected.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.iwslt-1.24.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--iwslt-1--24 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.iwslt-1.24 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.iwslt-1.24/>Exploring Kernel Functions in the Softmax Layer for Contextual Word Classification</a></strong><br><a href=/people/y/yingbo-gao/>Yingbo Gao</a>
|
<a href=/people/c/christian-herold/>Christian Herold</a>
|
<a href=/people/w/weiyue-wang/>Weiyue Wang</a>
|
<a href=/people/h/hermann-ney/>Hermann Ney</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--iwslt-1--24><div class="card-body p-3 small">Prominently used in support vector machines and <a href=https://en.wikipedia.org/wiki/Logistic_regression>logistic re-gressions</a>, kernel functions (kernels) can implicitly map data points into high dimensional spaces and make it easier to learn complex decision boundaries. In this work, by replacing the inner product function in the softmax layer, we explore the use of <a href=https://en.wikipedia.org/wiki/Kernel_method>kernels</a> for contextual word classification. In order to compare the individual kernels, experiments are conducted on standard language modeling and machine translation tasks. We observe a wide range of performances across different <a href=https://en.wikipedia.org/wiki/Kernel_(operating_system)>kernel settings</a>. Extending the results, we look at the gradient properties, investigate various mixture strategies and examine the disambiguation abilities.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.iwslt-1.26.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--iwslt-1--26 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.iwslt-1.26 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.iwslt-1.26/>Generic and Specialized Word Embeddings for Multi-Domain Machine Translation</a></strong><br><a href=/people/m/minh-quang-pham/>MinhQuang Pham</a>
|
<a href=/people/j/josep-m-crego/>Josep Crego</a>
|
<a href=/people/f/francois-yvon/>François Yvon</a>
|
<a href=/people/j/jean-senellart/>Jean Senellart</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--iwslt-1--26><div class="card-body p-3 small">Supervised machine translation works well when the train and test data are sampled from the same distribution. When this is not the case, adaptation techniques help ensure that the knowledge learned from out-of-domain texts generalises to in-domain sentences. We study here a related setting, multi-domain adaptation, where the number of domains is potentially large and adapting separately to each domain would waste training resources. Our proposal transposes to <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a> the feature expansion technique of (Daum III, 2007): it isolates domain-agnostic from domain-specific lexical representations, while sharing the most of the network across domains. Our experiments use two architectures and two language pairs : they show that our approach, while simple and computationally inexpensive, outperforms several strong baselines and delivers a multi-domain system that successfully translates texts from diverse sources.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.iwslt-1.27.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--iwslt-1--27 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.iwslt-1.27 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.iwslt-1.27/>Lexical Micro-adaptation for Neural Machine Translation</a></strong><br><a href=/people/j/jitao-xu/>Jitao Xu</a>
|
<a href=/people/j/josep-m-crego/>Josep Crego</a>
|
<a href=/people/j/jean-senellart/>Jean Senellart</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--iwslt-1--27><div class="card-body p-3 small">This work is inspired by a typical machine translation industry scenario in which translators make use of in-domain data for facilitating translation of similar or repeating sentences. We introduce a generic framework applied at <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference</a> in which a subset of segment pairs are first extracted from training data according to their similarity to the input sentences. These segments are then used to dynamically update the parameters of a generic NMT network, thus performing a lexical micro-adaptation. Our approach demonstrates strong adaptation performance to new and existing <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> including pseudo in-domain data. We evaluate our approach on a heterogeneous English-French training dataset showing accuracy gains on all evaluated domains when compared to strong adaptation baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.iwslt-1.28.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--iwslt-1--28 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.iwslt-1.28 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.iwslt-1.28/>Efficient Bilingual Generalization from Neural Transduction Grammar Induction</a></strong><br><a href=/people/y/yuchen-yan/>Yuchen Yan</a>
|
<a href=/people/d/dekai-wu/>Dekai Wu</a>
|
<a href=/people/s/serkan-kumyol/>Serkan Kumyol</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--iwslt-1--28><div class="card-body p-3 small">We introduce (1) a novel neural network structure for bilingual modeling of sentence pairs that allows efficient capturing of bilingual relationship via biconstituent composition, (2) the concept of neural network biparsing, which applies to not only machine translation (MT) but also to a variety of other bilingual research areas, and (3) the concept of a biparsing-backpropagation training loop, which we hypothesize that can efficiently learn complex biparse tree patterns. Our work distinguishes from sequential attention-based models, which are more traditionally found in neural machine translation (NMT) in three aspects. First, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> enforces compositional constraints. Second, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> has a smaller search space in terms of discovering bilingual relationships from bilingual sentence pairs. Third, our model produces explicit biparse trees, which enable transparent error analysis during evaluation and external tree constraints during training.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.iwslt-1.29.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--iwslt-1--29 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.iwslt-1.29 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.iwslt-1.29/>Breaking the Data Barrier : Towards Robust Speech Translation via Adversarial Stability Training</a></strong><br><a href=/people/q/qiao-cheng/>Qiao Cheng</a>
|
<a href=/people/m/meiyuan-fan/>Meiyuan Fan</a>
|
<a href=/people/y/yaqian-han/>Yaqian Han</a>
|
<a href=/people/j/jin-huang/>Jin Huang</a>
|
<a href=/people/y/yitao-duan/>Yitao Duan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--iwslt-1--29><div class="card-body p-3 small">In a pipeline speech translation system, automatic speech recognition (ASR) system will transmit errors in recognition to the downstream machine translation (MT) system. A standard <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation system</a> is usually trained on <a href=https://en.wikipedia.org/wiki/Parallel_text>parallel corpus</a> composed of clean text and will perform poorly on text with recognition noise, a gap well known in speech translation community. In this paper, we propose a <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training architecture</a> which aims at making a neural machine translation model more robust against speech recognition errors. Our approach addresses the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> and the <a href=https://en.wikipedia.org/wiki/Code>decoder</a> simultaneously using <a href=https://en.wikipedia.org/wiki/Adversarial_learning>adversarial learning</a> and <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a>, respectively. Experimental results on IWSLT2018 speech translation task show that our approach can bridge the gap between the ASR output and the MT input, outperforms the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> by up to 2.83 BLEU on noisy ASR output, while maintaining close performance on clean text.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2019.iwslt-1.31.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2019--iwslt-1--31 data-toggle=collapse aria-expanded=false aria-controls=abstract-2019.iwslt-1.31 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2019.iwslt-1.31/>Controlling the Output Length of Neural Machine Translation</a></strong><br><a href=/people/s/surafel-melaku-lakew/>Surafel Melaku Lakew</a>
|
<a href=/people/m/mattia-di-gangi/>Mattia Di Gangi</a>
|
<a href=/people/m/marcello-federico/>Marcello Federico</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2019--iwslt-1--31><div class="card-body p-3 small">The recent advances introduced by neural machine translation (NMT) are rapidly expanding the application fields of <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, as well as reshaping the quality level to be targeted. In particular, if translations have to fit some given layout, <a href=https://en.wikipedia.org/wiki/Quality_(business)>quality</a> should not only be measured in terms of adequacy and <a href=https://en.wikipedia.org/wiki/Fluency>fluency</a>, but also length. Exemplary cases are the translation of document files, <a href=https://en.wikipedia.org/wiki/Subtitle_(titling)>subtitles</a>, and scripts for dubbing, where the output length should ideally be as close as possible to the length of the input text. This pa-per addresses for the first time, to the best of our knowledge, the problem of controlling the output length in NMT. We investigate two methods for biasing the output length with a transformer architecture : i) conditioning the output to a given target-source length-ratio class and ii) enriching the transformer positional embedding with length information. Our experiments show that both methods can induce the <a href=https://en.wikipedia.org/wiki/Social_network>network</a> to generate shorter translations, as well as acquiring inter- pretable linguistic skills.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>