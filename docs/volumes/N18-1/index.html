<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/N18-1.pdf>Proceedings of the 2018 Conference of the North <span class=acl-fixed-case>A</span>merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></h2><p class=lead><a href=/people/m/marilyn-walker/>Marilyn Walker</a>,
<a href=/people/h/heng-ji/>Heng Ji</a>,
<a href=/people/a/amanda-stent/>Amanda Stent</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>N18-1</dd><dt>Month:</dt><dd>June</dd><dt>Year:</dt><dd>2018</dd><dt>Address:</dt><dd>New Orleans, Louisiana</dd><dt>Venue:</dt><dd><a href=/venues/naacl/>NAACL</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/N18-1>https://aclanthology.org/N18-1</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/N18-1 title="To the current version of the paper by DOI">10.18653/v1/N18-1</a></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/N18-1.pdf>https://aclanthology.org/N18-1.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/N18-1.pdf title="Open PDF of 'Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+2018+Conference+of+the+North+American+Chapter+of+the+Association+for+Computational+Linguistics%3A+Human+Language+Technologies%2C+Volume+1+%28Long+Papers%29" title="Search for 'Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1000/>Proceedings of the 2018 Conference of the North <span class=acl-fixed-case>A</span>merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)</a></strong><br><a href=/people/m/marilyn-walker/>Marilyn Walker</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/a/amanda-stent/>Amanda Stent</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1001 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276388781 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1001/>Label-Aware Double Transfer Learning for Cross-Specialty Medical Named Entity Recognition</a></strong><br><a href=/people/z/zhenghui-wang/>Zhenghui Wang</a>
|
<a href=/people/y/yanru-qu/>Yanru Qu</a>
|
<a href=/people/l/liheng-chen/>Liheng Chen</a>
|
<a href=/people/j/jian-shen/>Jian Shen</a>
|
<a href=/people/w/weinan-zhang/>Weinan Zhang</a>
|
<a href=/people/s/shaodian-zhang/>Shaodian Zhang</a>
|
<a href=/people/y/yimei-gao/>Yimei Gao</a>
|
<a href=/people/g/gen-gu/>Gen Gu</a>
|
<a href=/people/k/ken-chen/>Ken Chen</a>
|
<a href=/people/y/yong-yu/>Yong Yu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1001><div class="card-body p-3 small">We study the problem of named entity recognition (NER) from <a href=https://en.wikipedia.org/wiki/Electronic_health_record>electronic medical records</a>, which is one of the most fundamental and critical problems for medical text mining. Medical records which are written by clinicians from different specialties usually contain quite different terminologies and writing styles. The difference of specialties and the cost of human annotation makes it particularly difficult to train a universal medical NER system. In this paper, we propose a label-aware double transfer learning framework (La-DTL) for cross-specialty NER, so that a medical NER system designed for one specialty could be conveniently applied to another one with minimal annotation efforts. The transferability is guaranteed by two components : (i) we propose label-aware MMD for feature representation transfer, and (ii) we perform parameter transfer with a theoretical upper bound which is also label aware. We conduct extensive experiments on 12 cross-specialty NER tasks. The experimental results demonstrate that La-DTL provides consistent accuracy improvement over strong <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a>. Besides, the promising experimental results on non-medical NER scenarios indicate that La-DTL is potential to be seamlessly adapted to a wide range of NER tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1002 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276389935 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1002" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1002/>Neural Fine-Grained Entity Type Classification with Hierarchy-Aware Loss</a></strong><br><a href=/people/p/peng-xu/>Peng Xu</a>
|
<a href=/people/d/denilson-barbosa/>Denilson Barbosa</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1002><div class="card-body p-3 small">The task of Fine-grained Entity Type Classification (FETC) consists of assigning types from a <a href=https://en.wikipedia.org/wiki/Hierarchy>hierarchy</a> to entity mentions in text. Existing methods rely on distant supervision and are thus susceptible to noisy labels that can be out-of-context or overly-specific for the training sentence. Previous methods that attempt to address these issues do so with heuristics or with the help of hand-crafted features. Instead, we propose an end-to-end solution with a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network model</a> that uses a variant of cross-entropy loss function to handle out-of-context labels, and hierarchical loss normalization to cope with overly-specific ones. Also, previous work solve FETC a <a href=https://en.wikipedia.org/wiki/Multi-label_classification>multi-label classification</a> followed by ad-hoc post-processing. In contrast, our solution is more elegant : we use public word embeddings to train a single-label that jointly learns representations for entity mentions and their context. We show experimentally that our approach is robust against <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noise</a> and consistently outperforms the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> on established <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmarks</a> for the task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1004.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1004 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276386708 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1004/>A Deep Generative Model of Vowel Formant Typology</a></strong><br><a href=/people/r/ryan-cotterell/>Ryan Cotterell</a>
|
<a href=/people/j/jason-eisner/>Jason Eisner</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1004><div class="card-body p-3 small">What makes some types of <a href=https://en.wikipedia.org/wiki/Language>languages</a> more probable than others? For instance, we know that almost all <a href=https://en.wikipedia.org/wiki/Spoken_language>spoken languages</a> contain the <a href=https://en.wikipedia.org/wiki/Vowel>vowel phoneme</a> /i/ ; why should that be? The field of <a href=https://en.wikipedia.org/wiki/Linguistic_typology>linguistic typology</a> seeks to answer these questions and, thereby, divine the mechanisms that underlie <a href=https://en.wikipedia.org/wiki/Human_language>human language</a>. In our work, we tackle the problem of vowel system typology, i.e., we propose a <a href=https://en.wikipedia.org/wiki/Generative_model>generative probability model</a> of which vowels a language contains. In contrast to previous work, we work directly with the acoustic informationthe first two formant valuesrather than modeling discrete sets of symbols from the <a href=https://en.wikipedia.org/wiki/International_Phonetic_Alphabet>international phonetic alphabet</a>. We develop a novel generative probability model and report results on over 200 languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1005.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1005 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1005 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276387788 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1005/>Fortification of Neural Morphological Segmentation Models for Polysynthetic Minimal-Resource Languages</a></strong><br><a href=/people/k/katharina-kann/>Katharina Kann</a>
|
<a href=/people/j/jesus-manuel-mager-hois/>Jesus Manuel Mager Hois</a>
|
<a href=/people/i/ivan-meza-ruiz/>Ivan Vladimir Meza-Ruiz</a>
|
<a href=/people/h/hinrich-schutze/>Hinrich Schütze</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1005><div class="card-body p-3 small">Morphological segmentation for polysynthetic languages is challenging, because a word may consist of many individual morphemes and training data can be extremely scarce. Since neural sequence-to-sequence (seq2seq) models define the state of the art for morphological segmentation in high-resource settings and for (mostly) European languages, we first show that they also obtain competitive performance for Mexican polysynthetic languages in minimal-resource settings. We then propose two novel multi-task training approachesone with, one without need for external unlabeled resources, and two corresponding data augmentation methods, improving over the neural baseline for all languages. Finally, we explore cross-lingual transfer as a third way to fortify our neural model and show that we can train one single multi-lingual model for related languages while maintaining comparable or even improved performance, thus reducing the amount of parameters by close to 75 %. We provide our morphological segmentation datasets for <a href=https://en.wikipedia.org/wiki/Mexicanero_language>Mexicanero</a>, <a href=https://en.wikipedia.org/wiki/Nahuatl>Nahuatl</a>, Wixarika and Yorem Nokki for future research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1006.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1006 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1006 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276415442 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1006/>Improving Character-Based Decoding Using Target-Side Morphological Information for Neural Machine Translation</a></strong><br><a href=/people/p/peyman-passban/>Peyman Passban</a>
|
<a href=/people/q/qun-liu/>Qun Liu</a>
|
<a href=/people/a/andy-way/>Andy Way</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1006><div class="card-body p-3 small">Recently, neural machine translation (NMT) has emerged as a powerful alternative to conventional statistical approaches. However, its performance drops considerably in the presence of morphologically rich languages (MRLs). Neural engines usually fail to tackle the large vocabulary and high out-of-vocabulary (OOV) word rate of MRLs. Therefore, it is not suitable to exploit existing word-based models to translate this set of languages. In this paper, we propose an extension to the state-of-the-art model of Chung et al. (2016), which works at the character level and boosts the decoder with target-side morphological information. In our <a href=https://en.wikipedia.org/wiki/Architecture>architecture</a>, an additional morphology table is plugged into the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>. Each time the <a href=https://en.wikipedia.org/wiki/Encoder>decoder</a> samples from a target vocabulary, the table sends auxiliary signals from the most relevant <a href=https://en.wikipedia.org/wiki/Affix>affixes</a> in order to enrich the <a href=https://en.wikipedia.org/wiki/Encoder>decoder</a>&#8217;s current state and constrain it to provide better predictions. We evaluated our model to translate <a href=https://en.wikipedia.org/wiki/English_language>English</a> into <a href=https://en.wikipedia.org/wiki/German_language>German</a>, <a href=https://en.wikipedia.org/wiki/Russian_language>Russian</a>, and <a href=https://en.wikipedia.org/wiki/Turkish_language>Turkish</a> as three MRLs and observed significant improvements.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1007.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1007 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1007 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276439724 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1007" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1007/>Parsing Speech : a Neural Approach to Integrating Lexical and Acoustic-Prosodic Information</a></strong><br><a href=/people/t/trang-tran/>Trang Tran</a>
|
<a href=/people/s/shubham-toshniwal/>Shubham Toshniwal</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a>
|
<a href=/people/k/kevin-gimpel/>Kevin Gimpel</a>
|
<a href=/people/k/karen-livescu/>Karen Livescu</a>
|
<a href=/people/m/mari-ostendorf/>Mari Ostendorf</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1007><div class="card-body p-3 small">In conversational speech, the acoustic signal provides cues that help listeners disambiguate difficult parses. For automatically parsing spoken utterances, we introduce a model that integrates transcribed text and acoustic-prosodic features using a <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>convolutional neural network</a> over energy and pitch trajectories coupled with an attention-based recurrent neural network that accepts text and prosodic features. We find that different types of acoustic-prosodic features are individually helpful, and together give statistically significant improvements in parse and disfluency detection F1 scores over a strong text-only baseline. For this study with known sentence boundaries, error analyses show that the main benefit of acoustic-prosodic features is in sentences with disfluencies, attachment decisions are most improved, and transcription errors obscure gains from <a href=https://en.wikipedia.org/wiki/Prosody_(linguistics)>prosody</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1008.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1008 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1008 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276441141 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1008/>Tied Multitask Learning for Neural Speech Translation</a></strong><br><a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a>
|
<a href=/people/d/david-chiang/>David Chiang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1008><div class="card-body p-3 small">We explore multitask models for neural translation of speech, augmenting them in order to reflect two intuitive notions. First, we introduce a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> where the second task decoder receives information from the decoder of the first <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>, since higher-level intermediate representations should provide useful information. Second, we apply <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularization</a> that encourages transitivity and <a href=https://en.wikipedia.org/wiki/Inverse_problem>invertibility</a>. We show that the application of these notions on jointly trained models improves performance on the tasks of low-resource speech transcription and <a href=https://en.wikipedia.org/wiki/Translation>translation</a>. It also leads to better performance when using <a href=https://en.wikipedia.org/wiki/Attentional_control>attention information</a> for word discovery over unsegmented input.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1010.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1010 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1010 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1010" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1010/>Attentive Interaction Model : Modeling Changes in View in Argumentation</a></strong><br><a href=/people/y/yohan-jo/>Yohan Jo</a>
|
<a href=/people/s/shivani-poddar/>Shivani Poddar</a>
|
<a href=/people/b/byungsoo-jeon/>Byungsoo Jeon</a>
|
<a href=/people/q/qinlan-shen/>Qinlan Shen</a>
|
<a href=/people/c/carolyn-rose/>Carolyn Rosé</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1010><div class="card-body p-3 small">We present a neural architecture for modeling argumentative dialogue that explicitly models the interplay between an Opinion Holder&#8217;s (OH&#8217;s) reasoning and a challenger&#8217;s argument, with the goal of predicting if the argument successfully changes the OH&#8217;s view. The model has two components : (1) vulnerable region detection, an attention model that identifies parts of the OH&#8217;s reasoning that are amenable to change, and (2) interaction encoding, which identifies the relationship between the content of the OH&#8217;s reasoning and that of the challenger&#8217;s argument. Based on evaluation on discussions from the Change My View forum on <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a>, the two components work together to predict an OH&#8217;s change in view, outperforming several baselines. A posthoc analysis suggests that sentences picked out by the attention model are addressed more frequently by successful arguments than by unsuccessful ones.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1011.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1011 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1011 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1011/>Automatic Focus Annotation : Bringing Formal Pragmatics Alive in Analyzing the Information Structure of Authentic Data</a></strong><br><a href=/people/r/ramon-ziai/>Ramon Ziai</a>
|
<a href=/people/d/detmar-meurers/>Detmar Meurers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1011><div class="card-body p-3 small">Analyzing language in context, both from a theoretical and from a computational perspective, is receiving increased interest. Complementing the research in <a href=https://en.wikipedia.org/wiki/Linguistics>linguistics</a> on discourse and information structure, in <a href=https://en.wikipedia.org/wiki/Computational_linguistics>computational linguistics</a> identifying discourse concepts was also shown to improve the performance of certain applications, for example, Short Answer Assessment systems (Ziai and Meurers, 2014). Building on the research that established detailed annotation guidelines for manual annotation of information structural concepts for written (Dipper et al., 2007 ; Ziai and Meurers, 2014) and spoken language data (Calhoun et al., 2010), this paper presents the first approach automating the analysis of focus in authentic written data. Our classification approach combines a range of lexical, syntactic, and semantic features to achieve an accuracy of 78.1 % for identifying focus.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1012 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1012.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1012" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1012/>Dear Sir or Madam, May I Introduce the GYAFC Dataset : Corpus, Benchmarks and Metrics for Formality Style Transfer<span class=acl-fixed-case>I</span> Introduce the <span class=acl-fixed-case>GYAFC</span> Dataset: Corpus, Benchmarks and Metrics for Formality Style Transfer</a></strong><br><a href=/people/s/sudha-rao/>Sudha Rao</a>
|
<a href=/people/j/joel-tetreault/>Joel Tetreault</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1012><div class="card-body p-3 small">Style transfer is the task of automatically transforming a piece of text in one particular style into another. A major barrier to progress in this field has been a lack of <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training and evaluation datasets</a>, as well as benchmarks and <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>automatic metrics</a>. In this work, we create the largest <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> for a particular stylistic transfer (formality) and show that techniques from the machine translation community can serve as strong baselines for future work. We also discuss challenges of using <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>automatic metrics</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1013.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1013 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1013 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1013/>Improving Implicit Discourse Relation Classification by Modeling Inter-dependencies of Discourse Units in a Paragraph</a></strong><br><a href=/people/z/zeyu-dai/>Zeyu Dai</a>
|
<a href=/people/r/ruihong-huang/>Ruihong Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1013><div class="card-body p-3 small">We argue that semantic meanings of a sentence or clause can not be interpreted independently from the rest of a paragraph, or independently from all discourse relations and the overall paragraph-level discourse structure. With the goal of improving implicit discourse relation classification, we introduce a paragraph-level neural networks that model inter-dependencies between discourse units as well as discourse relation continuity and patterns, and predict a sequence of discourse relations in a paragraph. Experimental results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms the previous state-of-the-art systems on the benchmark corpus of PDTB.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1014.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1014 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1014/>A Deep Ensemble Model with Slot Alignment for Sequence-to-Sequence Natural Language Generation</a></strong><br><a href=/people/j/juraj-juraska/>Juraj Juraska</a>
|
<a href=/people/p/panagiotis-karagiannis/>Panagiotis Karagiannis</a>
|
<a href=/people/k/kevin-bowden/>Kevin Bowden</a>
|
<a href=/people/m/marilyn-walker/>Marilyn Walker</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1014><div class="card-body p-3 small">Natural language generation lies at the core of generative dialogue systems and conversational agents. We describe an ensemble neural language generator, and present several novel methods for data representation and augmentation that yield improved results in our model. We test the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on three datasets in the restaurant, TV and laptop domains, and report both objective and subjective evaluations of our best <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. Using a range of automatic metrics, as well as <a href=https://en.wikipedia.org/wiki/Human&#8211;computer_interaction>human evaluators</a>, we show that our approach achieves better results than state-of-the-art models on the same <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1023.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1023 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1023 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1023.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1023/>Looking Beyond the Surface : A Challenge Set for Reading Comprehension over Multiple Sentences</a></strong><br><a href=/people/d/daniel-khashabi/>Daniel Khashabi</a>
|
<a href=/people/s/snigdha-chaturvedi/>Snigdha Chaturvedi</a>
|
<a href=/people/m/michael-roth/>Michael Roth</a>
|
<a href=/people/s/shyam-upadhyay/>Shyam Upadhyay</a>
|
<a href=/people/d/dan-roth/>Dan Roth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1023><div class="card-body p-3 small">We present a reading comprehension challenge in which questions can only be answered by taking into account information from multiple sentences. We solicit and verify questions and answers for this challenge through a 4-step crowdsourcing experiment. Our challenge dataset contains 6,500 + questions for 1000 + paragraphs across 7 different domains (elementary school science, <a href=https://en.wikipedia.org/wiki/News>news</a>, <a href=https://en.wikipedia.org/wiki/Guide_book>travel guides</a>, <a href=https://en.wikipedia.org/wiki/Narrative>fiction stories</a>, etc) bringing in linguistic diversity to the texts and to the questions wordings. On a subset of our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, we found <a href=https://en.wikipedia.org/wiki/Solver>human solvers</a> to achieve an <a href=https://en.wikipedia.org/wiki/F-number>F1-score</a> of 88.1 %. We analyze a range of <a href=https://en.wikipedia.org/wiki/Baseline_(surveying)>baselines</a>, including a recent state-of-art reading comprehension system, and demonstrate the difficulty of this challenge, despite a high human performance. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> is the first to study multi-sentence inference at scale, with an open-ended set of question types that requires reasoning skills.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1024 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1024" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1024/>Neural Automated Essay Scoring and Coherence Modeling for Adversarially Crafted Input</a></strong><br><a href=/people/y/youmna-farag/>Youmna Farag</a>
|
<a href=/people/h/helen-yannakoudakis/>Helen Yannakoudakis</a>
|
<a href=/people/t/ted-briscoe/>Ted Briscoe</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1024><div class="card-body p-3 small">We demonstrate that current state-of-the-art approaches to Automated Essay Scoring (AES) are not well-suited to capturing adversarially crafted input of grammatical but incoherent sequences of sentences. We develop a neural model of local coherence that can effectively learn connectedness features between sentences, and propose a framework for integrating and jointly training the local coherence model with a state-of-the-art AES model. We evaluate our approach against a number of baselines and experimentally demonstrate its effectiveness on both the AES task and the task of flagging adversarial input, further contributing to the development of an approach that strengthens the validity of neural essay scoring models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1025.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1025 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1025 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1025/>QuickEdit : Editing Text & Translations by Crossing Words Out<span class=acl-fixed-case>Q</span>uick<span class=acl-fixed-case>E</span>dit: Editing Text & Translations by Crossing Words Out</a></strong><br><a href=/people/d/david-grangier/>David Grangier</a>
|
<a href=/people/m/michael-auli/>Michael Auli</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1025><div class="card-body p-3 small">We propose a <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> for computer-assisted text editing. It applies to translation post-editing and to <a href=https://en.wikipedia.org/wiki/Paraphrasing>paraphrasing</a>. Our proposal relies on very simple interactions : a human editor modifies a sentence by marking tokens they would like the system to change. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> then generates a new sentence which reformulates the initial sentence by avoiding marked words. The approach builds upon neural sequence-to-sequence modeling and introduces a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> which takes as input a sentence along with change markers. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is trained on translation bitext by simulating post-edits. We demonstrate the advantage of our approach for translation post-editing through simulated post-edits. We also evaluate our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> for <a href=https://en.wikipedia.org/wiki/Paraphrasing>paraphrasing</a> through a <a href=https://en.wikipedia.org/wiki/User_study>user study</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1026.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1026 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1026 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1026/>Tempo-Lexical Context Driven Word Embedding for Cross-Session Search Task Extraction</a></strong><br><a href=/people/p/procheta-sen/>Procheta Sen</a>
|
<a href=/people/d/debasis-ganguly/>Debasis Ganguly</a>
|
<a href=/people/g/gareth-jones/>Gareth Jones</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1026><div class="card-body p-3 small">Task extraction is the process of identifying search intents over a set of queries potentially spanning multiple search sessions. Most existing research on task extraction has focused on identifying tasks within a single session, where the notion of a session is defined by a fixed length time window. By contrast, in this work we seek to identify <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> that span across multiple sessions. To identify tasks, we conduct a <a href=https://en.wikipedia.org/wiki/Global_analysis>global analysis</a> of a query log in its entirety without restricting analysis to individual temporal windows. To capture inherent task semantics, we represent queries as vectors in an <a href=https://en.wikipedia.org/wiki/Abstract_and_concrete>abstract space</a>. We learn the embedding of query words in this space by leveraging the temporal and lexical contexts of queries. Embedded query vectors are then clustered into tasks. Experiments demonstrate that task extraction effectiveness is improved significantly with our proposed method of query vector embedding in comparison to existing approaches that make use of documents retrieved from a collection to estimate semantic similarities between queries.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1028.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1028 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1028 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1028.Datasets.tgz data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file-archive"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276395060 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1028/>Variable Typing : Assigning Meaning to Variables in Mathematical Text</a></strong><br><a href=/people/y/yiannos-stathopoulos/>Yiannos Stathopoulos</a>
|
<a href=/people/s/simon-baker/>Simon Baker</a>
|
<a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/s/simone-teufel/>Simone Teufel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1028><div class="card-body p-3 small">Information about the meaning of mathematical variables in text is useful in NLP / IR tasks such as symbol disambiguation, <a href=https://en.wikipedia.org/wiki/Topic_modeling>topic modeling</a> and mathematical information retrieval (MIR). We introduce variable typing, the task of assigning one mathematical type (multi-word technical terms referring to mathematical concepts) to each variable in a sentence of mathematical text. As part of this work, we also introduce a new annotated data set composed of 33,524 data points extracted from scientific documents published on arXiv. Our intrinsic evaluation demonstrates that our <a href=https://en.wikipedia.org/wiki/Data_set>data set</a> is sufficient to successfully train and evaluate current <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> from three different model architectures. The best performing <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is evaluated on an extrinsic task : MIR, by producing a typed formula index. Our results show that the best performing MIR models make use of our typed index, compared to a formula index only containing raw symbols, thereby demonstrating the usefulness of variable typing.<i>variable typing</i>, the task of assigning one\n <i>mathematical type</i> (multi-word technical terms referring\n to mathematical concepts) to each variable in a sentence of\n mathematical text. As part of this work, we also introduce a new\n annotated data set composed of 33,524 data points extracted from\n scientific documents published on arXiv. Our intrinsic\n evaluation demonstrates that our data set is sufficient to\n successfully train and evaluate current classifiers from three\n different model architectures. The best performing model is\n evaluated on an extrinsic task: MIR, by producing a <i>typed formula index</i>. Our results show that the best performing MIR\n models make use of our typed index, compared to a formula index\n only containing raw symbols, thereby demonstrating the\n usefulness of variable typing.\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1029.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1029 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1029 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276416920 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1029/>Learning beyond Datasets : Knowledge Graph Augmented Neural Networks for Natural Language Processing</a></strong><br><a href=/people/a/annervaz-k-m/>Annervaz K M</a>
|
<a href=/people/s/somnath-basu-roy-chowdhury/>Somnath Basu Roy Chowdhury</a>
|
<a href=/people/a/ambedkar-dukkipati/>Ambedkar Dukkipati</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1029><div class="card-body p-3 small">Machine Learning has been the quintessential solution for many AI problems, but <a href=https://en.wikipedia.org/wiki/Machine_learning>learning models</a> are heavily dependent on specific training data. Some <a href=https://en.wikipedia.org/wiki/Machine_learning>learning models</a> can be incorporated with prior knowledge using a <a href=https://en.wikipedia.org/wiki/Bayesian_inference>Bayesian setup</a>, but these <a href=https://en.wikipedia.org/wiki/Machine_learning>learning models</a> do not have the ability to access any organized world knowledge on demand. In this work, we propose to enhance learning models with <a href=https://en.wikipedia.org/wiki/World_knowledge>world knowledge</a> in the form of Knowledge Graph (KG) fact triples for Natural Language Processing (NLP) tasks. Our aim is to develop a <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning model</a> that can extract relevant prior support facts from <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graphs</a> depending on the task using attention mechanism. We introduce a convolution-based model for learning representations of knowledge graph entity and relation clusters in order to reduce the attention space. We show that the proposed method is highly scalable to the amount of prior information that has to be processed and can be applied to any generic NLP task. Using this method we show significant improvement in performance for text classification with 20Newsgroups (News20) & DBPedia datasets, and natural language inference with Stanford Natural Language Inference (SNLI) dataset. We also demonstrate that a deep learning model can be trained with substantially less amount of labeled training data, when it has access to organized world knowledge in the form of a <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge base</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1032.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1032 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1032 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276448004 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1032/>Universal Neural Machine Translation for Extremely Low Resource Languages</a></strong><br><a href=/people/j/jiatao-gu/>Jiatao Gu</a>
|
<a href=/people/h/hany-hassan-awadalla/>Hany Hassan</a>
|
<a href=/people/j/jacob-devlin/>Jacob Devlin</a>
|
<a href=/people/v/victor-o-k-li/>Victor O.K. Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1032><div class="card-body p-3 small">In this paper, we propose a new universal machine translation approach focusing on languages with a limited amount of parallel data. Our proposed approach utilizes a transfer-learning approach to share lexical and sentence level representations across multiple source languages into one target language. The lexical part is shared through a Universal Lexical Representation to support multi-lingual word-level sharing. The sentence-level sharing is represented by a model of experts from all source languages that share the source encoders with all other languages. This enables the low-resource language to utilize the lexical and sentence representations of the higher resource languages. Our approach is able to achieve 23 BLEU on Romanian-English WMT2016 using a tiny parallel corpus of 6k sentences, compared to the 18 BLEU of strong baseline system which uses multi-lingual training and back-translation. Furthermore, we show that the proposed approach can achieve almost 20 BLEU on the same <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> through fine-tuning a pre-trained multi-lingual system in a zero-shot setting.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1034.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1034 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1034 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276397933 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1034" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1034/>Deep Dirichlet Multinomial Regression<span class=acl-fixed-case>D</span>irichlet Multinomial Regression</a></strong><br><a href=/people/a/adrian-benton/>Adrian Benton</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1034><div class="card-body p-3 small">Dirichlet Multinomial Regression (DMR) and other supervised topic models can incorporate arbitrary document-level features to inform topic priors. However, their ability to model corpora are limited by the representation and selection of these <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> a choice the topic modeler must make. Instead, we seek <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that can learn the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature representations</a> upon which to condition topic selection. We present deep Dirichlet Multinomial Regression (dDMR), a generative topic model that simultaneously learns document feature representations and topics. We evaluate dDMR on three datasets : New York Times articles with fine-grained tags, Amazon product reviews with product images, and Reddit posts with subreddit identity. dDMR learns representations that outperform DMR and LDA according to heldout perplexity and are more effective at downstream predictive tasks as the number of topics grows. Additionally, human subjects judge dDMR topics as being more representative of associated document features. Finally, we find that supervision leads to faster convergence as compared to an LDA baseline and that dDMR&#8217;s model fit is less sensitive to training parameters than DMR.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1035.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1035 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1035 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276422518 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1035/>Microblog Conversation Recommendation via Joint Modeling of Topics and Discourse</a></strong><br><a href=/people/x/xingshan-zeng/>Xingshan Zeng</a>
|
<a href=/people/j/jing-li/>Jing Li</a>
|
<a href=/people/l/lu-wang/>Lu Wang</a>
|
<a href=/people/n/nicholas-beauchamp/>Nicholas Beauchamp</a>
|
<a href=/people/s/sarah-shugars/>Sarah Shugars</a>
|
<a href=/people/k/kam-fai-wong/>Kam-Fai Wong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1035><div class="card-body p-3 small">Millions of conversations are generated every day on <a href=https://en.wikipedia.org/wiki/Social_media>social media platforms</a>. With limited attention, it is challenging for users to select which discussions they would like to participate in. Here we propose a new <a href=https://en.wikipedia.org/wiki/Methodology>method</a> for microblog conversation recommendation. While much prior work has focused on post-level recommendation, we exploit both the conversational context, and user content and behavior preferences. We propose a <a href=https://en.wikipedia.org/wiki/Statistical_model>statistical model</a> that jointly captures : (1) topics for representing user interests and conversation content, and (2) discourse modes for describing user replying behavior and conversation dynamics. Experimental results on two Twitter datasets demonstrate that our <a href=https://en.wikipedia.org/wiki/System>system</a> outperforms methods that only model content without considering <a href=https://en.wikipedia.org/wiki/Discourse>discourse</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1036.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1036 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1036 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1036.Datasets.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file-archive"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276425357 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1036" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1036/>Before Name-Calling : Dynamics and Triggers of Ad Hominem Fallacies in Web Argumentation</a></strong><br><a href=/people/i/ivan-habernal/>Ivan Habernal</a>
|
<a href=/people/h/henning-wachsmuth/>Henning Wachsmuth</a>
|
<a href=/people/i/iryna-gurevych/>Iryna Gurevych</a>
|
<a href=/people/b/benno-stein/>Benno Stein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1036><div class="card-body p-3 small">Arguing without committing a fallacy is one of the main requirements of an ideal debate. But even when debating rules are strictly enforced and fallacious arguments punished, arguers often lapse into attacking the opponent by an ad hominem argument. As existing research lacks solid empirical investigation of the typology of <a href=https://en.wikipedia.org/wiki/Ad_hominem>ad hominem arguments</a> as well as their potential causes, this paper fills this gap by (1) performing several large-scale annotation studies, (2) experimenting with various neural architectures and validating our working hypotheses, such as controversy or reasonableness, and (3) providing linguistic insights into triggers of <a href=https://en.wikipedia.org/wiki/Ad_hominem>ad hominem</a> using explainable neural network architectures.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1037.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1037 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1037 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276453229 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1037" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1037/>Scene Graph Parsing as Dependency Parsing</a></strong><br><a href=/people/y/yu-siang-wang/>Yu-Siang Wang</a>
|
<a href=/people/c/chenxi-liu/>Chenxi Liu</a>
|
<a href=/people/x/xiaohui-zeng/>Xiaohui Zeng</a>
|
<a href=/people/a/alan-yuille/>Alan Yuille</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1037><div class="card-body p-3 small">In this paper, we study the problem of parsing structured knowledge graphs from textual descriptions. In particular, we consider the scene graph representation that considers objects together with their attributes and relations : this <a href=https://en.wikipedia.org/wiki/Representation_theory>representation</a> has been proved useful across a variety of vision and language applications. We begin by introducing an alternative but equivalent edge-centric view of scene graphs that connect to dependency parses. Together with a careful redesign of label and action space, we combine the two-stage pipeline used in prior work (generic dependency parsing followed by simple post-processing) into one, enabling end-to-end training. The scene graphs generated by our learned neural dependency parser achieve an <a href=https://en.wikipedia.org/wiki/F-score>F-score similarity</a> of 49.67 % to <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>ground truth graphs</a> on our evaluation set, surpassing best previous approaches by 5 %. We further demonstrate the effectiveness of our learned <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> on image retrieval applications.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1039.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1039 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1039 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277631187 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1039" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1039/>Comparatives, Quantifiers, Proportions : a Multi-Task Model for the Learning of Quantities from Vision</a></strong><br><a href=/people/s/sandro-pezzelle/>Sandro Pezzelle</a>
|
<a href=/people/i/ionut-sorodoc/>Ionut-Teodor Sorodoc</a>
|
<a href=/people/r/raffaella-bernardi/>Raffaella Bernardi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1039><div class="card-body p-3 small">The present work investigates whether different quantification mechanisms (set comparison, vague quantification, and proportional estimation) can be jointly learned from visual scenes by a multi-task computational model. The motivation is that, in humans, these processes underlie the same cognitive, non-symbolic ability, which allows an automatic estimation and comparison of set magnitudes. We show that when information about lower-complexity tasks is available, the higher-level proportional task becomes more accurate than when performed in isolation. Moreover, the multi-task model is able to generalize to unseen combinations of target / non-target objects. Consistently with behavioral evidence showing the interference of absolute number in the proportional task, the multi-task model no longer works when asked to provide the number of target objects in the scene.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1040.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1040 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1040 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1040.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276455887 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1040/>Being Negative but Constructively : Lessons Learnt from Creating Better Visual Question Answering Datasets</a></strong><br><a href=/people/w/wei-lun-chao/>Wei-Lun Chao</a>
|
<a href=/people/h/hexiang-hu/>Hexiang Hu</a>
|
<a href=/people/f/fei-sha/>Fei Sha</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1040><div class="card-body p-3 small">Visual question answering (Visual QA) has attracted a lot of attention lately, seen essentially as a form of (visual) Turing test that <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>artificial intelligence</a> should strive to achieve. In this paper, we study a crucial component of this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> : how can we design good <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> for the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>? We focus on the design of <a href=https://en.wikipedia.org/wiki/Multiple_choice>multiple-choice based datasets</a> where the learner has to select the right answer from a set of candidate ones including the target (i.e., the correct one) and the decoys (i.e., the incorrect ones). Through careful analysis of the results attained by state-of-the-art <a href=https://en.wikipedia.org/wiki/Machine_learning>learning models</a> and human annotators on existing datasets, we show that the design of the decoy answers has a significant impact on how and what the <a href=https://en.wikipedia.org/wiki/Machine_learning>learning models</a> learn from the <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>. In particular, the resulting learner can ignore the <a href=https://en.wikipedia.org/wiki/Visual_system>visual information</a>, the question, or both while still doing well on the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. Inspired by this, we propose automatic procedures to remedy such design deficiencies. We apply the procedures to re-construct decoy answers for two popular Visual QA datasets as well as to create a new Visual QA dataset from the Visual Genome project, resulting in the largest dataset for this task. Extensive empirical studies show that the design deficiencies have been alleviated in the remedied datasets and the performance on them is likely a more faithful indicator of the difference among learning models. The datasets are released and publicly available via.<url>http://www.teds.usc.edu/website_vqa/</url>.\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1041.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1041 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1041 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1041/>Abstract Meaning Representation for <a href=https://en.wikipedia.org/wiki/Paraphrase_detection>Paraphrase Detection</a><span class=acl-fixed-case>A</span>bstract <span class=acl-fixed-case>M</span>eaning <span class=acl-fixed-case>R</span>epresentation for Paraphrase Detection</a></strong><br><a href=/people/f/fuad-issa/>Fuad Issa</a>
|
<a href=/people/m/marco-damonte/>Marco Damonte</a>
|
<a href=/people/s/shay-b-cohen/>Shay B. Cohen</a>
|
<a href=/people/x/xiaohui-yan/>Xiaohui Yan</a>
|
<a href=/people/y/yi-chang/>Yi Chang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1041><div class="card-body p-3 small">Abstract Meaning Representation (AMR) parsing aims at abstracting away from the syntactic realization of a sentence, and denote only its meaning in a canonical form. As such, it is ideal for <a href=https://en.wikipedia.org/wiki/Paraphrase_detection>paraphrase detection</a>, a problem in which one is required to specify whether two sentences have the same meaning. We show that nave use of AMR in <a href=https://en.wikipedia.org/wiki/Paraphrase_detection>paraphrase detection</a> is not necessarily useful, and turn to describe a technique based on latent semantic analysis in combination with AMR parsing that significantly advances state-of-the-art results in <a href=https://en.wikipedia.org/wiki/Paraphrase_detection>paraphrase detection</a> for the Microsoft Research Paraphrase Corpus. Our best results in the transductive setting are 86.6 % for <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and 90.0 % for <a href=https://en.wikipedia.org/wiki/F-number>F_1 measure</a>.<tex-math>_1</tex-math> measure.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1043.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1043 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1043 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1043/>Can Network Embedding of Distributional Thesaurus Be Combined with Word Vectors for Better Representation?</a></strong><br><a href=/people/a/abhik-jana/>Abhik Jana</a>
|
<a href=/people/p/pawan-goyal/>Pawan Goyal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1043><div class="card-body p-3 small">Distributed representations of words learned from text have proved to be successful in various natural language processing tasks in recent times. While some methods represent words as vectors computed from text using predictive model (Word2vec) or dense count based model (GloVe), others attempt to represent these in a distributional thesaurus network structure where the neighborhood of a word is a set of words having adequate context overlap. Being motivated by recent surge of research in network embedding techniques (DeepWalk, LINE, node2vec etc.), we turn a distributional thesaurus network into dense word vectors and investigate the usefulness of distributional thesaurus embedding in improving overall word representation. This is the first attempt where we show that combining the proposed word representation obtained by distributional thesaurus embedding with the state-of-the-art word representations helps in improving the performance by a significant margin when evaluated against NLP tasks like word similarity and relatedness, synonym detection, analogy detection. Additionally, we show that even without using any handcrafted lexical resources we can come up with <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a> having comparable performance in the word similarity and relatedness tasks compared to the <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a> where a lexical resource has been used.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1044.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1044 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1044 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1044.Datasets.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file-archive"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1044/>Deep Neural Models of Semantic Shift</a></strong><br><a href=/people/a/alex-rosenfeld/>Alex Rosenfeld</a>
|
<a href=/people/k/katrin-erk/>Katrin Erk</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1044><div class="card-body p-3 small">Diachronic distributional models track changes in word use over time. In this paper, we propose a deep neural network diachronic distributional model. Instead of modeling lexical change via a <a href=https://en.wikipedia.org/wiki/Time_series>time series</a> as is done in previous work, we represent <a href=https://en.wikipedia.org/wiki/Time>time</a> as a <a href=https://en.wikipedia.org/wiki/Continuous_or_discrete_variable>continuous variable</a> and model a word&#8217;s usage as a function of time. Additionally, we have also created a novel synthetic task which measures a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s ability to capture the semantic trajectory. This evaluation quantitatively measures how well a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> captures the semantic trajectory of a word over time. Finally, we explore how well the <a href=https://en.wikipedia.org/wiki/Derivative>derivatives</a> of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can be used to measure the speed of lexical change.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1045.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1045 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1045 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1045.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1045/>Distributional Inclusion Vector Embedding for Unsupervised Hypernymy Detection</a></strong><br><a href=/people/h/haw-shiuan-chang/>Haw-Shiuan Chang</a>
|
<a href=/people/z/ziyun-wang/>Ziyun Wang</a>
|
<a href=/people/l/luke-vilnis/>Luke Vilnis</a>
|
<a href=/people/a/andrew-mccallum/>Andrew McCallum</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1045><div class="card-body p-3 small">Modeling hypernymy, such as poodle is-a dog, is an important generalization aid to many NLP tasks, such as <a href=https://en.wikipedia.org/wiki/Logical_consequence>entailment</a>, relation extraction, and <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>. Supervised learning from labeled hypernym sources, such as <a href=https://en.wikipedia.org/wiki/WordNet>WordNet</a>, limits the coverage of these models, which can be addressed by learning <a href=https://en.wikipedia.org/wiki/Hypernym>hypernyms</a> from unlabeled text. Existing <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised methods</a> either do not scale to large vocabularies or yield unacceptably poor accuracy. This paper introduces distributional inclusion vector embedding (DIVE), a simple-to-implement unsupervised method of hypernym discovery via per-word non-negative vector embeddings which preserve the inclusion property of word contexts. In experimental evaluations more comprehensive than any previous literature of which we are awareevaluating on 11 datasets using multiple existing as well as newly proposed scoring functionswe find that our method provides up to double the precision of previous <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised methods</a>, and the highest average performance, using a much more compact word representation, and yielding many new state-of-the-art results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1046.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1046 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1046 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1046/>Mining Possessions : Existence, Type and Temporal Anchors</a></strong><br><a href=/people/d/dhivya-chinnappa/>Dhivya Chinnappa</a>
|
<a href=/people/e/eduardo-blanco/>Eduardo Blanco</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1046><div class="card-body p-3 small">This paper presents a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> and experiments to mine <a href=https://en.wikipedia.org/wiki/Possession_(linguistics)>possession relations</a> from text. Specifically, we target alienable and control possessions, and assign temporal anchors indicating when the possession holds between possessor and possessee. We present new <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a> for this task, and experimental results using both traditional <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> and <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>. Results show that the three subtasks (predicting possession existence, possession type and temporal anchors) can be automated.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1047.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1047 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1047 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1047/>Neural Tensor Networks with Diagonal Slice Matrices</a></strong><br><a href=/people/t/takahiro-ishihara/>Takahiro Ishihara</a>
|
<a href=/people/k/katsuhiko-hayashi/>Katsuhiko Hayashi</a>
|
<a href=/people/h/hitoshi-manabe/>Hitoshi Manabe</a>
|
<a href=/people/m/masashi-shimbo/>Masashi Shimbo</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1047><div class="card-body p-3 small">Although neural tensor networks (NTNs) have been successful in many NLP tasks, they require a large number of parameters to be estimated, which often leads to <a href=https://en.wikipedia.org/wiki/Overfitting>overfitting</a> and a long training time. We address these issues by applying <a href=https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix>eigendecomposition</a> to each slice matrix of a <a href=https://en.wikipedia.org/wiki/Tensor>tensor</a> to reduce its number of paramters. First, we evaluate our proposed NTN models on knowledge graph completion. Second, we extend the models to recursive NTNs (RNTNs) and evaluate them on logical reasoning tasks. These experiments show that our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> learn better and faster than the original (R)NTNs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1048.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1048 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1048 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1048" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1048/>Post-Specialisation : Retrofitting Vectors of Words Unseen in Lexical Resources</a></strong><br><a href=/people/i/ivan-vulic/>Ivan Vulić</a>
|
<a href=/people/g/goran-glavas/>Goran Glavaš</a>
|
<a href=/people/n/nikola-mrksic/>Nikola Mrkšić</a>
|
<a href=/people/a/anna-korhonen/>Anna Korhonen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1048><div class="card-body p-3 small">Word vector specialisation (also known as retrofitting) is a portable, light-weight approach to fine-tuning arbitrary distributional word vector spaces by injecting external knowledge from rich lexical resources such as <a href=https://en.wikipedia.org/wiki/WordNet>WordNet</a>. By design, these post-processing methods only update the vectors of words occurring in external lexicons, leaving the representations of all unseen words intact. In this paper, we show that constraint-driven vector space specialisation can be extended to unseen words. We propose a novel post-specialisation method that : a) preserves the useful linguistic knowledge for seen words ; while b) propagating this external signal to unseen words in order to improve their vector representations as well. Our post-specialisation approach explicits a non-linear specialisation function in the form of a <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural network</a> by learning to predict specialised vectors from their original distributional counterparts. The learned <a href=https://en.wikipedia.org/wiki/Function_(mathematics)>function</a> is then used to specialise vectors of unseen words. This approach, applicable to any post-processing model, yields considerable gains over the initial specialisation models both in intrinsic word similarity tasks, and in two downstream tasks : dialogue state tracking and lexical text simplification. The positive effects persist across three languages, demonstrating the importance of specialising the full vocabulary of distributional word vector spaces.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1052.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1052 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1052 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1052/>Relevant Emotion Ranking from Text Constrained with Emotion Relationships</a></strong><br><a href=/people/d/deyu-zhou/>Deyu Zhou</a>
|
<a href=/people/y/yang-yang/>Yang Yang</a>
|
<a href=/people/y/yulan-he/>Yulan He</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1052><div class="card-body p-3 small">Text might contain or invoke multiple emotions with varying intensities. As such, <a href=https://en.wikipedia.org/wiki/Emotion_detection>emotion detection</a>, to predict multiple <a href=https://en.wikipedia.org/wiki/Emotion>emotions</a> associated with a given text, can be cast into a multi-label classification problem. We would like to go one step further so that a ranked list of relevant emotions are generated where top ranked emotions are more intensely associated with text compared to lower ranked emotions, whereas the rankings of irrelevant emotions are not important. A novel framework of relevant emotion ranking is proposed to tackle the <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a>. In the <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a>, the <a href=https://en.wikipedia.org/wiki/Loss_function>objective loss function</a> is designed elaborately so that both emotion prediction and <a href=https://en.wikipedia.org/wiki/Ranking>rankings</a> of only relevant emotions can be achieved. Moreover, we observe that some emotions co-occur more often while other emotions rarely co-exist. Such information is incorporated into the <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> as <a href=https://en.wikipedia.org/wiki/Constraint_(mathematics)>constraints</a> to improve the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of <a href=https://en.wikipedia.org/wiki/Emotion_detection>emotion detection</a>. Experimental results on two real-world corpora show that the proposed framework can effectively deal with <a href=https://en.wikipedia.org/wiki/Emotion_detection>emotion detection</a> and performs remarkably better than the state-of-the-art <a href=https://en.wikipedia.org/wiki/Emotion_detection>emotion detection approaches</a> and multi-label learning methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1053.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1053 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1053 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1053/>Solving Data Sparsity for Aspect Based Sentiment Analysis Using Cross-Linguality and Multi-Linguality</a></strong><br><a href=/people/m/md-shad-akhtar/>Md Shad Akhtar</a>
|
<a href=/people/p/palaash-sawant/>Palaash Sawant</a>
|
<a href=/people/s/sukanta-sen/>Sukanta Sen</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1053><div class="card-body p-3 small">Efficient word representations play an important role in solving various problems related to <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing (NLP)</a>, <a href=https://en.wikipedia.org/wiki/Data_mining>data mining</a>, <a href=https://en.wikipedia.org/wiki/Text_mining>text mining</a> etc. The issue of data sparsity poses a great challenge in creating efficient word representation model for solving the underlying problem. The <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> is more intensified in resource-poor scenario due to the absence of sufficient amount of corpus. In this work we propose to minimize the effect of data sparsity by leveraging bilingual word embeddings learned through a <a href=https://en.wikipedia.org/wiki/Parallel_corpus>parallel corpus</a>. We train and evaluate Long Short Term Memory (LSTM) based architecture for aspect level sentiment classification. The neural network architecture is further assisted by the hand-crafted features for the <a href=https://en.wikipedia.org/wiki/Prediction>prediction</a>. We show the efficacy of the proposed <a href=https://en.wikipedia.org/wiki/Scientific_modelling>model</a> against <a href=https://en.wikipedia.org/wiki/Scientific_method>state-of-the-art methods</a> in two experimental setups i.e. multi-lingual and cross-lingual.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1054.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1054 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1054 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1054.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1054" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1054/>SRL4ORL : Improving Opinion Role Labeling Using Multi-Task Learning with Semantic Role Labeling<span class=acl-fixed-case>SRL</span>4<span class=acl-fixed-case>ORL</span>: Improving Opinion Role Labeling Using Multi-Task Learning with Semantic Role Labeling</a></strong><br><a href=/people/a/ana-marasovic/>Ana Marasović</a>
|
<a href=/people/a/anette-frank/>Anette Frank</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1054><div class="card-body p-3 small">For over a decade, <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning</a> has been used to extract opinion-holder-target structures from text to answer the question Who expressed what kind of sentiment towards what?. Recent neural approaches do not outperform the state-of-the-art feature-based models for Opinion Role Labeling (ORL). We suspect this is due to the scarcity of <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>labeled training data</a> and address this issue using different multi-task learning (MTL) techniques with a related <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> which has substantially more data, i.e. Semantic Role Labeling (SRL). We show that two MTL models improve significantly over the single-task model for labeling of both holders and targets, on the development and the test sets. We found that the vanilla MTL model, which makes predictions using only shared ORL and SRL features, performs the best. With deeper analysis we determine what works and what might be done to make further improvements for ORL.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1057.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1057 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1057 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276371501 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1057/>Noising and Denoising Natural Language : Diverse Backtranslation for Grammar Correction</a></strong><br><a href=/people/z/ziang-xie/>Ziang Xie</a>
|
<a href=/people/g/guillaume-genthial/>Guillaume Genthial</a>
|
<a href=/people/s/stanley-xie/>Stanley Xie</a>
|
<a href=/people/a/andrew-y-ng/>Andrew Ng</a>
|
<a href=/people/d/dan-jurafsky/>Dan Jurafsky</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1057><div class="card-body p-3 small">Translation-based methods for grammar correction that directly map noisy, ungrammatical text to their clean counterparts are able to correct a broad range of errors ; however, such techniques are bottlenecked by the need for a large parallel corpus of noisy and clean sentence pairs. In this paper, we consider synthesizing <a href=https://en.wikipedia.org/wiki/Parallel_computing>parallel data</a> by noising a clean monolingual corpus. While most previous approaches introduce perturbations using <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> computed from local context windows, we instead develop error generation processes using a neural sequence transduction model trained to translate clean examples to their noisy counterparts. Given a corpus of clean examples, we propose beam search noising procedures to synthesize additional noisy examples that human evaluators were nearly unable to discriminate from nonsynthesized examples. Surprisingly, when trained on additional <a href=https://en.wikipedia.org/wiki/Data>data</a> synthesized using our best-performing noising scheme, our model approaches the same performance as when trained on additional nonsynthesized data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1058.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1058 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1058 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1058/>Self-Training for Jointly Learning to Ask and Answer Questions</a></strong><br><a href=/people/m/mrinmaya-sachan/>Mrinmaya Sachan</a>
|
<a href=/people/e/eric-xing/>Eric Xing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1058><div class="card-body p-3 small">Building curious machines that can answer as well as ask questions is an important challenge for <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>AI</a>. The two <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> of <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a> and question generation are usually tackled separately in the <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP literature</a>. At the same time, both require significant amounts of supervised data which is hard to obtain in many domains. To alleviate these issues, we propose a self-training method for jointly learning to ask as well as answer questions, leveraging unlabeled text along with labeled question answer pairs for <a href=https://en.wikipedia.org/wiki/Learning>learning</a>. We evaluate our approach on four benchmark datasets : SQUAD, MS MARCO, WikiQA and TrecQA, and show significant improvements over a number of established baselines on both question answering and question generation tasks. We also achieved new state-of-the-art results on two competitive answer sentence selection tasks : WikiQA and TrecQA.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1060.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1060 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1060 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276431486 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1060" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1060/>A Meaning-Based Statistical English Math Word Problem Solver<span class=acl-fixed-case>E</span>nglish Math Word Problem Solver</a></strong><br><a href=/people/c/chao-chun-liang/>Chao-Chun Liang</a>
|
<a href=/people/y/yu-shiang-wong/>Yu-Shiang Wong</a>
|
<a href=/people/y/yi-chung-lin/>Yi-Chung Lin</a>
|
<a href=/people/k/keh-yih-su/>Keh-Yih Su</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1060><div class="card-body p-3 small">We introduce MeSys, a meaning-based approach, for solving English math word problems (MWPs) via understanding and reasoning in this paper. It first analyzes the text, transforms both body and question parts into their corresponding <a href=https://en.wikipedia.org/wiki/Logical_form>logic forms</a>, and then performs <a href=https://en.wikipedia.org/wiki/Inference>inference</a> on them. The associated context of each quantity is represented with proposed <a href=https://en.wikipedia.org/wiki/Tag_(metadata)>role-tags</a> (e.g., <a href=https://en.wikipedia.org/wiki/Subjunctive_mood>nsubj</a>, <a href=https://en.wikipedia.org/wiki/Verb>verb</a>, etc.), which provides the flexibility for annotating an extracted <a href=https://en.wikipedia.org/wiki/Quantity>math quantity</a> with its associated <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context information</a> (i.e., the <a href=https://en.wikipedia.org/wiki/Meaning_(linguistics)>physical meaning</a> of this quantity). Statistical models are proposed to select the <a href=https://en.wikipedia.org/wiki/Operator_(mathematics)>operator</a> and operands. A noisy dataset is designed to assess if a <a href=https://en.wikipedia.org/wiki/Solver>solver</a> solves MWPs mainly via understanding or mechanical pattern matching. Experimental results show that our approach outperforms existing systems on both benchmark datasets and the noisy dataset, which demonstrates that the proposed approach understands the meaning of each quantity in the text more.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1062.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1062 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1062 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1062/>Querying Word Embeddings for Similarity and Relatedness</a></strong><br><a href=/people/f/fatemeh-torabi-asr/>Fatemeh Torabi Asr</a>
|
<a href=/people/r/robert-zinkov/>Robert Zinkov</a>
|
<a href=/people/m/michael-jones/>Michael Jones</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1062><div class="card-body p-3 small">Word embeddings obtained from neural network models such as Word2Vec Skipgram have become popular representations of word meaning and have been evaluated on a variety of word similarity and relatedness norming data. Skipgram generates a set of word and context embeddings, the latter typically discarded after training. We demonstrate the usefulness of context embeddings in predicting asymmetric association between words from a recently published dataset of production norms (Jouravlev & McRae, 2016). Our findings suggest that humans respond with words closer to the cue within the context embedding space (rather than the word embedding space), when asked to generate thematically related words.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1063.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1063 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1063 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/282318359 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1063" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1063/>Semantic Structural Evaluation for Text Simplification</a></strong><br><a href=/people/e/elior-sulem/>Elior Sulem</a>
|
<a href=/people/o/omri-abend/>Omri Abend</a>
|
<a href=/people/a/ari-rappoport/>Ari Rappoport</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1063><div class="card-body p-3 small">Current measures for evaluating text simplification systems focus on evaluating lexical text aspects, neglecting its structural aspects. In this paper we propose the first <a href=https://en.wikipedia.org/wiki/Measure_(mathematics)>measure</a> to address structural aspects of text simplification, called SAMSA. It leverages recent advances in semantic parsing to assess simplification quality by decomposing the input based on its semantic structure and comparing it to the output. SAMSA provides a reference-less automatic evaluation procedure, avoiding the problems that reference-based methods face due to the vast space of valid simplifications for a given sentence. Our human evaluation experiments show both SAMSA&#8217;s substantial correlation with human judgments, as well as the deficiency of existing reference-based measures in evaluating structural simplification.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1067.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1067 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1067 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276898126 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1067/>Neural Models of Factuality</a></strong><br><a href=/people/r/rachel-rudinger/>Rachel Rudinger</a>
|
<a href=/people/a/aaron-steven-white/>Aaron Steven White</a>
|
<a href=/people/b/benjamin-van-durme/>Benjamin Van Durme</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1067><div class="card-body p-3 small">We present two neural models for event factuality prediction, which yield significant performance gains over previous models on three event factuality datasets : FactBank, UW, and MEANTIME. We also present a substantial expansion of the It Happened portion of the Universal Decompositional Semantics dataset, yielding the largest event factuality dataset to date. We report <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> results on this extended factuality dataset as well.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1069.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1069 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1069 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1069" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1069/>Acquisition of Phrase Correspondences Using Natural Deduction Proofs</a></strong><br><a href=/people/h/hitomi-yanaka/>Hitomi Yanaka</a>
|
<a href=/people/k/koji-mineshima/>Koji Mineshima</a>
|
<a href=/people/p/pascual-martinez-gomez/>Pascual Martínez-Gómez</a>
|
<a href=/people/d/daisuke-bekki/>Daisuke Bekki</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1069><div class="card-body p-3 small">How to identify, extract, and use phrasal knowledge is a crucial problem for the task of Recognizing Textual Entailment (RTE). To solve this problem, we propose a method for detecting paraphrases via natural deduction proofs of semantic relations between sentence pairs. Our solution relies on a graph reformulation of partial variable unifications and an <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> that induces subgraph alignments between meaning representations. Experiments show that our method can automatically detect various <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrases</a> that are absent from existing paraphrase databases. In addition, the detection of paraphrases using proof information improves the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of RTE tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1070.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1070 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1070 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1070/>Automatic Stance Detection Using End-to-End Memory Networks</a></strong><br><a href=/people/m/mitra-mohtarami/>Mitra Mohtarami</a>
|
<a href=/people/r/ramy-baly/>Ramy Baly</a>
|
<a href=/people/j/james-glass/>James Glass</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/l/lluis-marquez/>Lluís Màrquez</a>
|
<a href=/people/a/alessandro-moschitti/>Alessandro Moschitti</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1070><div class="card-body p-3 small">We present an effective end-to-end memory network model that jointly (i) predicts whether a given document can be considered as relevant evidence for a given claim, and (ii) extracts snippets of evidence that can be used to reason about the factuality of the target claim. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> combines the advantages of convolutional and recurrent neural networks as part of a memory network. We further introduce a <a href=https://en.wikipedia.org/wiki/Similarity_matrix>similarity matrix</a> at the inference level of the memory network in order to extract snippets of evidence for input claims more accurately. Our experiments on a public benchmark dataset, FakeNewsChallenge, demonstrate the effectiveness of our approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1073.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1073 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1073 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1073/>Efficient <a href=https://en.wikipedia.org/wiki/Sequence_learning>Sequence Learning</a> with Group Recurrent Networks</a></strong><br><a href=/people/f/fei-gao/>Fei Gao</a>
|
<a href=/people/l/lijun-wu/>Lijun Wu</a>
|
<a href=/people/l/li-zhao/>Li Zhao</a>
|
<a href=/people/t/tao-qin/>Tao Qin</a>
|
<a href=/people/x/xueqi-cheng/>Xueqi Cheng</a>
|
<a href=/people/t/tie-yan-liu/>Tie-Yan Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1073><div class="card-body p-3 small">Recurrent neural networks have achieved state-of-the-art results in many artificial intelligence tasks, such as <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a>, <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a>, <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech recognition</a> and so on. One of the key factors to these successes is big models. However, training such <a href=https://en.wikipedia.org/wiki/Big_data>big models</a> usually takes days or even weeks of time even if using tens of <a href=https://en.wikipedia.org/wiki/Graphics_processing_unit>GPU cards</a>. In this paper, we propose an efficient architecture to improve the efficiency of such RNN model training, which adopts the <a href=https://en.wikipedia.org/wiki/Group_action_(mathematics)>group strategy</a> for recurrent layers, while exploiting the representation rearrangement strategy between layers as well as time steps. To demonstrate the advantages of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>, we conduct experiments on several datasets and tasks. The results show that our <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> achieves comparable or better <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> comparing with <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a>, with a much smaller number of parameters and at a much lower <a href=https://en.wikipedia.org/wiki/Computational_cost>computational cost</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1075.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1075 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1075 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1075" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1075/>Global Relation Embedding for <a href=https://en.wikipedia.org/wiki/Relation_extraction>Relation Extraction</a></a></strong><br><a href=/people/y/yu-su/>Yu Su</a>
|
<a href=/people/h/honglei-liu/>Honglei Liu</a>
|
<a href=/people/s/semih-yavuz/>Semih Yavuz</a>
|
<a href=/people/i/izzeddin-gur/>Izzeddin Gür</a>
|
<a href=/people/h/huan-sun/>Huan Sun</a>
|
<a href=/people/x/xifeng-yan/>Xifeng Yan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1075><div class="card-body p-3 small">We study the problem of textual relation embedding with distant supervision. To combat the wrong labeling problem of distant supervision, we propose to embed textual relations with global statistics of relations, i.e., the co-occurrence statistics of textual and knowledge base relations collected from the entire corpus. This approach turns out to be more robust to the training noise introduced by distant supervision. On a popular relation extraction dataset, we show that the learned textual relation embedding can be used to augment existing relation extraction models and significantly improve their performance. Most remarkably, for the top 1,000 relational facts discovered by the best existing <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>, the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a> can be improved from 83.9 % to 89.3 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1077.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1077 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1077 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1077.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1077/>Improving Temporal Relation Extraction with a Globally Acquired Statistical Resource</a></strong><br><a href=/people/q/qiang-ning/>Qiang Ning</a>
|
<a href=/people/h/hao-wu/>Hao Wu</a>
|
<a href=/people/h/haoruo-peng/>Haoruo Peng</a>
|
<a href=/people/d/dan-roth/>Dan Roth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1077><div class="card-body p-3 small">Extracting temporal relations (before, after, overlapping, etc.) is a key aspect of understanding events described in <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>. We argue that this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> would gain from the availability of a <a href=https://en.wikipedia.org/wiki/Resource>resource</a> that provides prior knowledge in the form of the temporal order that events usually follow. This paper develops such a resource a probabilistic knowledge base acquired in the news domain by extracting temporal relations between events from the New York Times (NYT) articles over a 20-year span (19872007). We show that existing temporal extraction systems can be improved via this <a href=https://en.wikipedia.org/wiki/Resource>resource</a>. As a byproduct, we also show that interesting statistics can be retrieved from this <a href=https://en.wikipedia.org/wiki/Resource_(computer_science)>resource</a>, which can potentially benefit other time-aware tasks. The proposed <a href=https://en.wikipedia.org/wiki/System>system</a> and <a href=https://en.wikipedia.org/wiki/Resource>resource</a> are both publicly available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1078.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1078 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1078 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1078/>Multimodal Named Entity Recognition for Short Social Media Posts</a></strong><br><a href=/people/s/seungwhan-moon/>Seungwhan Moon</a>
|
<a href=/people/l/leonardo-neves/>Leonardo Neves</a>
|
<a href=/people/v/vitor-carvalho/>Vitor Carvalho</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1078><div class="card-body p-3 small">We introduce a new task called Multimodal Named Entity Recognition (MNER) for noisy user-generated data such as <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a> or Snapchat captions, which comprise short text with accompanying images. These social media posts often come in inconsistent or incomplete syntax and lexical notations with very limited surrounding textual contexts, bringing significant challenges for NER. To this end, we create a new dataset for MNER called SnapCaptions (Snapchat image-caption pairs submitted to public and crowd-sourced stories with fully annotated named entities). We then build upon the state-of-the-art Bi-LSTM word / character based NER models with 1) a deep image network which incorporates relevant visual context to augment textual information, and 2) a generic modality-attention module which learns to attenuate irrelevant modalities while amplifying the most informative ones to extract contexts from, adaptive to each sample and token. The proposed MNER model with modality attention significantly outperforms the state-of-the-art text-only NER models by successfully leveraging provided visual contexts, opening up potential applications of MNER on myriads of social media platforms.<i>modality-attention</i>\n module which learns to attenuate irrelevant modalities while amplifying\n the most informative ones to extract contexts from, adaptive to each\n sample and token. The proposed MNER model with modality attention\n significantly outperforms the state-of-the-art text-only NER models by\n successfully leveraging provided visual contexts, opening up potential\n applications of MNER on myriads of social media platforms.\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1079.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1079 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1079 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1079/>Nested Named Entity Recognition Revisited</a></strong><br><a href=/people/a/arzoo-katiyar/>Arzoo Katiyar</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1079><div class="card-body p-3 small">We propose a novel recurrent neural network-based approach to simultaneously handle nested named entity recognition and nested entity mention detection. The model learns a <a href=https://en.wikipedia.org/wiki/Hypergraph>hypergraph representation</a> for nested entities using <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> extracted from a <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network</a>. In evaluations on three standard <a href=https://en.wikipedia.org/wiki/Data_set>data sets</a>, we show that our approach significantly outperforms existing state-of-the-art methods, which are feature-based. The approach is also efficient : <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> operates linearly in the number of tokens and the number of possible output labels at any token. Finally, we present an extension of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> that jointly learns the head of each entity mention.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1081.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1081 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1081 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1081/>Supervised Open Information Extraction</a></strong><br><a href=/people/g/gabriel-stanovsky/>Gabriel Stanovsky</a>
|
<a href=/people/j/julian-michael/>Julian Michael</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1081><div class="card-body p-3 small">We present data and methods that enable a supervised learning approach to Open Information Extraction (Open IE). Central to the approach is a novel formulation of <a href=https://en.wikipedia.org/wiki/Open_IE>Open IE</a> as a sequence tagging problem, addressing challenges such as encoding multiple extractions for a predicate. We also develop a bi-LSTM transducer, extending recent deep Semantic Role Labeling models to extract Open IE tuples and provide confidence scores for tuning their precision-recall tradeoff. Furthermore, we show that the recently released Question-Answer Meaning Representation dataset can be automatically converted into an Open IE corpus which significantly increases the amount of available training data. Our <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised model</a> outperforms the existing state-of-the-art Open IE systems on <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark datasets</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1084.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1084 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1084 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1084" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1084/>Monte Carlo Syntax Marginals for Exploring and Using Dependency Parses<span class=acl-fixed-case>M</span>onte <span class=acl-fixed-case>C</span>arlo Syntax Marginals for Exploring and Using Dependency Parses</a></strong><br><a href=/people/k/katherine-keith/>Katherine Keith</a>
|
<a href=/people/s/su-lin-blodgett/>Su Lin Blodgett</a>
|
<a href=/people/b/brendan-oconnor/>Brendan O’Connor</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1084><div class="card-body p-3 small">Dependency parsing research, which has made significant gains in recent years, typically focuses on improving the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of single-tree predictions. However, <a href=https://en.wikipedia.org/wiki/Ambiguity>ambiguity</a> is inherent to <a href=https://en.wikipedia.org/wiki/Syntax_(programming_languages)>natural language syntax</a>, and communicating such <a href=https://en.wikipedia.org/wiki/Ambiguity>ambiguity</a> is important for <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error analysis</a> and better-informed downstream applications. In this work, we propose a transition sampling algorithm to sample from the full joint distribution of parse trees defined by a transition-based parsing model, and demonstrate the use of the samples in probabilistic dependency analysis. First, we define the new task of dependency path prediction, inferring syntactic substructures over part of a sentence, and provide the first analysis of performance on this <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>. Second, we demonstrate the usefulness of our Monte Carlo syntax marginal method for parser error analysis and <a href=https://en.wikipedia.org/wiki/Calibration>calibration</a>. Finally, we use this method to propagate parse uncertainty to two downstream information extraction applications : identifying persons killed by police and semantic role assignment.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1085.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1085 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1085 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1085.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1085/>Neural Particle Smoothing for Sampling from Conditional Sequence Models</a></strong><br><a href=/people/c/chu-cheng-lin/>Chu-Cheng Lin</a>
|
<a href=/people/j/jason-eisner/>Jason Eisner</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1085><div class="card-body p-3 small">We introduce neural particle smoothing, a <a href=https://en.wikipedia.org/wiki/Sequential_Monte_Carlo_method>sequential Monte Carlo method</a> for sampling annotations of an input string from a given <a href=https://en.wikipedia.org/wiki/Probability_model>probability model</a>. In contrast to conventional particle filtering algorithms, we train a proposal distribution that looks ahead to the end of the input string by means of a right-to-left LSTM. We demonstrate that this <a href=https://en.wikipedia.org/wiki/Innovation>innovation</a> can improve the quality of the sample. To motivate our formal choices, we explain how neural transduction models and our <a href=https://en.wikipedia.org/wiki/Sampler_(musical_instrument)>sampler</a> can be viewed as low-dimensional but nonlinear approximations to working with HMMs over very large state spaces.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1086.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1086 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1086 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1086/>Neural Syntactic Generative Models with Exact Marginalization</a></strong><br><a href=/people/j/jan-buys/>Jan Buys</a>
|
<a href=/people/p/phil-blunsom/>Phil Blunsom</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1086><div class="card-body p-3 small">We present neural syntactic generative models with exact marginalization that support both <a href=https://en.wikipedia.org/wiki/Dependency_grammar>dependency parsing</a> and <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a>. Exact marginalization is made tractable through <a href=https://en.wikipedia.org/wiki/Dynamic_programming>dynamic programming</a> over <a href=https://en.wikipedia.org/wiki/Shift-reduce>shift-reduce parsing</a> and minimal RNN-based feature sets. Our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> complement previous approaches by supporting batched training and enabling online computation of next word probabilities. For supervised dependency parsing, our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> achieves a state-of-the-art result among generative approaches. We also report empirical results on unsupervised syntactic models and their role in <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a>. We find that our model formulation of latent dependencies with exact marginalization do not lead to better intrinsic language modeling performance than vanilla RNNs, and that parsing accuracy is not correlated with language modeling perplexity in stack-based models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1087.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1087 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1087 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1087/>Noise-Robust Morphological Disambiguation for Dialectal Arabic<span class=acl-fixed-case>A</span>rabic</a></strong><br><a href=/people/n/nasser-zalmout/>Nasser Zalmout</a>
|
<a href=/people/a/alexander-erdmann/>Alexander Erdmann</a>
|
<a href=/people/n/nizar-habash/>Nizar Habash</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1087><div class="card-body p-3 small">User-generated text tends to be noisy with many lexical and orthographic inconsistencies, making natural language processing (NLP) tasks more challenging. The challenging nature of noisy text processing is exacerbated for dialectal content, where in addition to spelling and lexical differences, dialectal text is characterized with morpho-syntactic and phonetic variations. These issues increase sparsity in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP models</a> and reduce <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. We present a neural morphological tagging and disambiguation model for <a href=https://en.wikipedia.org/wiki/Egyptian_Arabic>Egyptian Arabic</a>, with various extensions to handle noisy and inconsistent content. Our models achieve about 5 % <a href=https://en.wikipedia.org/wiki/Errors-in-variables_models>relative error reduction</a> (1.1 % absolute improvement) for full morphological analysis, and around 22 % <a href=https://en.wikipedia.org/wiki/Errors-in-variables_models>relative error reduction</a> (1.8 % absolute improvement) for <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a>, over a state-of-the-art baseline.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1088.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1088 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1088 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1088" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1088/>Parsing Tweets into Universal Dependencies<span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependencies</a></strong><br><a href=/people/y/yijia-liu/>Yijia Liu</a>
|
<a href=/people/y/yi-zhu/>Yi Zhu</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/b/bing-qin/>Bing Qin</a>
|
<a href=/people/n/nathan-schneider/>Nathan Schneider</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1088><div class="card-body p-3 small">We study the problem of analyzing <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a> with universal dependencies (UD). We extend the UD guidelines to cover special constructions in tweets that affect <a href=https://en.wikipedia.org/wiki/Lexical_analysis>tokenization</a>, <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a>, and labeled dependencies. Using the extended guidelines, we create a new tweet treebank for English (Tweebank v2) that is four times larger than the (unlabeled) Tweebank v1 introduced by Kong et al. We characterize the disagreements between our annotators and show that it is challenging to deliver consistent annotation due to ambiguity in understanding and explaining tweets. Nonetheless, using the new <a href=https://en.wikipedia.org/wiki/Treebank>treebank</a>, we build a <a href=https://en.wikipedia.org/wiki/Pipeline_(software)>pipeline system</a> to parse raw tweets into UD. To overcome the annotation noise without sacrificing computational efficiency, we propose a new method to distill an ensemble of 20 transition-based parsers into a single one. Our <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> achieves an improvement of 2.2 in <a href=https://en.wikipedia.org/wiki/Lisp_(programming_language)>LAS</a> over the un-ensembled baseline and outperforms parsers that are state-of-the-art on other treebanks in both <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and <a href=https://en.wikipedia.org/wiki/Speed>speed</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1089.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1089 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1089 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1089" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1089/>Robust Multilingual Part-of-Speech Tagging via Adversarial Training</a></strong><br><a href=/people/m/michihiro-yasunaga/>Michihiro Yasunaga</a>
|
<a href=/people/j/jungo-kasai/>Jungo Kasai</a>
|
<a href=/people/d/dragomir-radev/>Dragomir Radev</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1089><div class="card-body p-3 small">Adversarial training (AT) is a powerful <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularization method</a> for <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>, aiming to achieve <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> to input perturbations. Yet, the specific effects of the <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> obtained from AT are still unclear in the context of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. In this paper, we propose and analyze a neural POS tagging model that exploits AT. In our experiments on the Penn Treebank WSJ corpus and the Universal Dependencies (UD) dataset (27 languages), we find that AT not only improves the overall tagging accuracy, but also 1) prevents over-fitting well in low resource languages and 2) boosts tagging accuracy for rare / unseen words. We also demonstrate that 3) the improved <a href=https://en.wikipedia.org/wiki/Tag_(metadata)>tagging</a> performance by AT contributes to the downstream task of dependency parsing, and that 4) AT helps the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to learn cleaner word representations. 5) The proposed AT model is generally effective in different sequence labeling tasks. These positive results motivate further use of AT for <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language tasks</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1092.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1092 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1092 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277669962 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1092" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1092/>Deep Generative Model for Joint Alignment and Word Representation</a></strong><br><a href=/people/m/miguel-rios/>Miguel Rios</a>
|
<a href=/people/w/wilker-aziz/>Wilker Aziz</a>
|
<a href=/people/k/khalil-simaan/>Khalil Sima’an</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1092><div class="card-body p-3 small">This work exploits translation data as a source of semantically relevant learning signal for models of word representation. In particular, we exploit equivalence through translation as a form of distributional context and jointly learn how to embed and align with a deep generative model. Our EmbedAlign model embeds words in their complete observed context and learns by marginalisation of latent lexical alignments. Besides, it embeds <a href=https://en.wikipedia.org/wiki/Word_(group_theory)>words</a> as posterior probability densities, rather than <a href=https://en.wikipedia.org/wiki/Point_estimation>point estimates</a>, which allows us to compare words in context using a measure of overlap between distributions (e.g. KL divergence). We investigate our model&#8217;s performance on a range of lexical semantics tasks achieving competitive results on several standard benchmarks including natural language inference, <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrasing</a>, and text similarity.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1094.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1094 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1094 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/282323369 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1094/>Exploring the Role of Prior Beliefs for Argument Persuasion</a></strong><br><a href=/people/e/esin-durmus/>Esin Durmus</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1094><div class="card-body p-3 small">Public debate forums provide a common platform for exchanging opinions on a topic of interest. While recent studies in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP)</a> have provided empirical evidence that the language of the debaters and their patterns of interaction play a key role in changing the mind of a reader, research in <a href=https://en.wikipedia.org/wiki/Psychology>psychology</a> has shown that prior beliefs can affect our interpretation of an argument and could therefore constitute a competing alternative explanation for resistance to changing one&#8217;s stance. To study the actual effect of language use vs. prior beliefs on <a href=https://en.wikipedia.org/wiki/Persuasion>persuasion</a>, we provide a new dataset and propose a controlled setting that takes into consideration two reader-level factors : <a href=https://en.wikipedia.org/wiki/Ideology>political and religious ideology</a>. We find that prior beliefs affected by these reader-level factors play a more important role than language use effects and argue that it is important to account for them in NLP studies of persuasion.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1096.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1096 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1096 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/282327794 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1096/>Author Commitment and Social Power : Automatic Belief Tagging to Infer the Social Context of Interactions</a></strong><br><a href=/people/v/vinodkumar-prabhakaran/>Vinodkumar Prabhakaran</a>
|
<a href=/people/p/premkumar-ganeshkumar/>Premkumar Ganeshkumar</a>
|
<a href=/people/o/owen-rambow/>Owen Rambow</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1096><div class="card-body p-3 small">Understanding how <a href=https://en.wikipedia.org/wiki/Power_(social_and_political)>social power structures</a> affect the way we interact with one another is of great interest to social scientists who want to answer fundamental questions about human behavior, as well as to computer scientists who want to build automatic methods to infer the social contexts of interactions. In this paper, we employ advancements in extra-propositional semantics extraction within <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> to study how author commitment reflects the social context of an interactions. Specifically, we investigate whether the level of <a href=https://en.wikipedia.org/wiki/Commitment>commitment</a> expressed by individuals in an <a href=https://en.wikipedia.org/wiki/Organizational_behavior>organizational interaction</a> reflects the <a href=https://en.wikipedia.org/wiki/Hierarchical_organization>hierarchical power structures</a> they are part of. We find that <a href=https://en.wikipedia.org/wiki/Hierarchy>subordinates</a> use significantly more instances of non-commitment than superiors. More importantly, we also find that subordinates attribute propositions to other agents more often than superiors do an aspect that has not been studied before. Finally, we show that enriching lexical features with commitment labels captures important distinctions in <a href=https://en.wikipedia.org/wiki/Social_relation>social meanings</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1097.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1097 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1097 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1097/>Comparing Automatic and Human Evaluation of Local Explanations for Text Classification</a></strong><br><a href=/people/d/dong-nguyen/>Dong Nguyen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1097><div class="card-body p-3 small">Text classification models are becoming increasingly complex and opaque, however for many applications it is essential that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are interpretable. Recently, a variety of <a href=https://en.wikipedia.org/wiki/Scientific_method>approaches</a> have been proposed for generating local explanations. While robust evaluations are needed to drive further progress, so far it is unclear which evaluation approaches are suitable. This paper is a first step towards more robust evaluations of local explanations. We evaluate a variety of local explanation approaches using automatic measures based on word deletion. Furthermore, we show that an evaluation using a <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing experiment</a> correlates moderately with these automatic measures and that a variety of other factors also impact the human judgements.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1098.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1098 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1098 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277669869 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1098/>Deep Temporal-Recurrent-Replicated-Softmax for Topical Trends over Time</a></strong><br><a href=/people/p/pankaj-gupta/>Pankaj Gupta</a>
|
<a href=/people/s/subburam-rajaram/>Subburam Rajaram</a>
|
<a href=/people/h/hinrich-schutze/>Hinrich Schütze</a>
|
<a href=/people/b/bernt-andrassy/>Bernt Andrassy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1098><div class="card-body p-3 small">Dynamic topic modeling facilitates the identification of topical trends over time in temporal collections of unstructured documents. We introduce a novel unsupervised neural dynamic topic model named as Recurrent Neural Network-Replicated Softmax Model (RNNRSM), where the discovered topics at each time influence the topic discovery in the subsequent time steps. We account for the temporal ordering of documents by explicitly modeling a joint distribution of latent topical dependencies over time, using distributional estimators with temporal recurrent connections. Applying RNN-RSM to 19 years of articles on NLP research, we demonstrate that compared to state-of-the art topic models, RNNRSM shows better generalization, topic interpretation, evolution and trends. We also introduce a <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> (named as SPAN) to quantify the capability of <a href=https://en.wikipedia.org/wiki/Dynamic_topic_model>dynamic topic model</a> to capture word evolution in topics over time.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1099.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1099 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1099 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277669906 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1099/>Lessons from the Bible on Modern Topics : Low-Resource Multilingual Topic Model Evaluation<span class=acl-fixed-case>B</span>ible on Modern Topics: Low-Resource Multilingual Topic Model Evaluation</a></strong><br><a href=/people/s/shudong-hao/>Shudong Hao</a>
|
<a href=/people/j/jordan-boyd-graber/>Jordan Boyd-Graber</a>
|
<a href=/people/m/michael-paul/>Michael J. Paul</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1099><div class="card-body p-3 small">Multilingual topic models enable <a href=https://en.wikipedia.org/wiki/Document_analysis>document analysis</a> across languages through coherent multilingual summaries of the data. However, there is no standard and effective <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> to evaluate the quality of multilingual topics. We introduce a new intrinsic evaluation of multilingual topic models that correlates well with human judgments of multilingual topic coherence as well as performance in downstream applications. Importantly, we also study evaluation for low-resource languages. Because standard <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> fail to accurately measure topic quality when robust external resources are unavailable, we propose an adaptation model that improves the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and <a href=https://en.wikipedia.org/wiki/Reliability_(statistics)>reliability</a> of these <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> in low-resource settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1100.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1100 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1100 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1100" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1100/>Explainable Prediction of Medical Codes from Clinical Text</a></strong><br><a href=/people/j/james-mullenbach/>James Mullenbach</a>
|
<a href=/people/s/sarah-wiegreffe/>Sarah Wiegreffe</a>
|
<a href=/people/j/jon-duke/>Jon Duke</a>
|
<a href=/people/j/jimeng-sun/>Jimeng Sun</a>
|
<a href=/people/j/jacob-eisenstein/>Jacob Eisenstein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1100><div class="card-body p-3 small">Clinical notes are <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>text documents</a> that are created by clinicians for each patient encounter. They are typically accompanied by <a href=https://en.wikipedia.org/wiki/Medical_code>medical codes</a>, which describe the diagnosis and treatment. Annotating these <a href=https://en.wikipedia.org/wiki/Code>codes</a> is labor intensive and error prone ; furthermore, the connection between the codes and the text is not annotated, obscuring the reasons and details behind specific diagnoses and treatments. We present an attentional convolutional network that predicts <a href=https://en.wikipedia.org/wiki/Medical_classification>medical codes</a> from clinical text. Our method aggregates information across the document using a <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>convolutional neural network</a>, and uses an attention mechanism to select the most relevant segments for each of the thousands of possible codes. The <a href=https://en.wikipedia.org/wiki/Numerical_methods_for_ordinary_differential_equations>method</a> is accurate, achieving precision@8 of 0.71 and a Micro-F1 of 0.54, which are both better than the prior state of the art. Furthermore, through an interpretability evaluation by a physician, we show that the attention mechanism identifies meaningful explanations for each code assignment.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1101.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1101 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1101 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/282330248 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1101" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1101/>A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference</a></strong><br><a href=/people/a/adina-williams/>Adina Williams</a>
|
<a href=/people/n/nikita-nangia/>Nikita Nangia</a>
|
<a href=/people/s/samuel-bowman/>Samuel Bowman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1101><div class="card-body p-3 small">This paper introduces the Multi-Genre Natural Language Inference (MultiNLI) corpus, a dataset designed for use in the development and evaluation of machine learning models for sentence understanding. At 433k examples, this <a href=https://en.wikipedia.org/wiki/Resource>resource</a> is one of the largest corpora available for natural language inference (a.k.a. recognizing textual entailment), improving upon available resources in both its coverage and difficulty. MultiNLI accomplishes this by offering data from ten distinct genres of written and spoken English, making it possible to evaluate systems on nearly the full complexity of the language, while supplying an explicit setting for evaluating cross-genre domain adaptation. In addition, an evaluation using existing machine learning models designed for the Stanford NLI corpus shows that it represents a substantially more difficult task than does that <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>, despite the two showing similar levels of inter-annotator agreement.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1102.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1102 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1102 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1102.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/282332520 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1102/>Filling Missing Paths : Modeling Co-occurrences of Word Pairs and Dependency Paths for Recognizing Lexical Semantic Relations</a></strong><br><a href=/people/k/koki-washio/>Koki Washio</a>
|
<a href=/people/t/tsuneaki-kato/>Tsuneaki Kato</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1102><div class="card-body p-3 small">Recognizing lexical semantic relations between word pairs is an important task for many applications of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. One of the mainstream approaches to this task is to exploit the lexico-syntactic paths connecting two target words, which reflect the <a href=https://en.wikipedia.org/wiki/Semantics>semantic relations</a> of word pairs. However, this method requires that the considered words co-occur in a sentence. This requirement is hardly satisfied because of <a href=https://en.wikipedia.org/wiki/Zipf&#8217;s_law>Zipf&#8217;s law</a>, which states that most content words occur very rarely. In this paper, we propose novel methods with a neural model of P(path|w1,w2) to solve this problem. Our proposed model of P (path|w1, w2) can be learned in an unsupervised manner and can generalize the co-occurrences of word pairs and dependency paths. This model can be used to augment the path data of word pairs that do not co-occur in the corpus, and extract features capturing relational information from word pairs. Our experimental results demonstrate that our methods improve on previous neural approaches based on dependency paths and successfully solve the focused problem.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1103.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1103 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1103 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/282333968 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1103" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1103/>Specialising <a href=https://en.wikipedia.org/wiki/Lexical_analysis>Word Vectors</a> for Lexical Entailment</a></strong><br><a href=/people/i/ivan-vulic/>Ivan Vulić</a>
|
<a href=/people/n/nikola-mrksic/>Nikola Mrkšić</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1103><div class="card-body p-3 small">We present LEAR (Lexical Entailment Attract-Repel), a novel post-processing method that transforms any input word vector space to emphasise the asymmetric relation of lexical entailment (LE), also known as the IS-A or hyponymy-hypernymy relation. By injecting external linguistic constraints (e.g., WordNet links) into the initial <a href=https://en.wikipedia.org/wiki/Vector_space>vector space</a>, the LE specialisation procedure brings true <a href=https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy>hyponymy-hypernymy pairs</a> closer together in the transformed <a href=https://en.wikipedia.org/wiki/Euclidean_space>Euclidean space</a>. The proposed asymmetric distance measure adjusts the norms of word vectors to reflect the actual WordNet-style hierarchy of concepts. Simultaneously, a joint objective enforces <a href=https://en.wikipedia.org/wiki/Semantic_similarity>semantic similarity</a> using the symmetric cosine distance, yielding a <a href=https://en.wikipedia.org/wiki/Vector_space>vector space</a> specialised for both lexical relations at once. LEAR specialisation achieves state-of-the-art performance in the tasks of hypernymy directionality, hypernymy detection, and graded lexical entailment, demonstrating the effectiveness and robustness of the proposed asymmetric specialisation model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1104.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1104 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1104 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/282336638 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1104" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1104/>Cross-Lingual Abstract Meaning Representation Parsing<span class=acl-fixed-case>A</span>bstract <span class=acl-fixed-case>M</span>eaning <span class=acl-fixed-case>R</span>epresentation Parsing</a></strong><br><a href=/people/m/marco-damonte/>Marco Damonte</a>
|
<a href=/people/s/shay-b-cohen/>Shay B. Cohen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1104><div class="card-body p-3 small">Abstract Meaning Representation (AMR) research has mostly focused on <a href=https://en.wikipedia.org/wiki/English_language>English</a>. We show that it is possible to use AMR annotations for <a href=https://en.wikipedia.org/wiki/English_language>English</a> as a semantic representation for sentences written in other languages. We exploit an AMR parser for English and parallel corpora to learn AMR parsers for <a href=https://en.wikipedia.org/wiki/Italian_language>Italian</a>, <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>, <a href=https://en.wikipedia.org/wiki/German_language>German</a> and <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>. Qualitative analysis show that the new <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a> overcome structural differences between the languages. We further propose a method to evaluate the <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a> that does not require gold standard data in the target languages. This <a href=https://en.wikipedia.org/wiki/Methodology>method</a> highly correlates with the gold standard evaluation, obtaining a <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>Pearson correlation coefficient</a> of 0.95.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1107.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1107 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1107 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276898201 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1107" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1107/>End-to-End Graph-Based TAG Parsing with <a href=https://en.wikipedia.org/wiki/Neural_network>Neural Networks</a><span class=acl-fixed-case>TAG</span> Parsing with Neural Networks</a></strong><br><a href=/people/j/jungo-kasai/>Jungo Kasai</a>
|
<a href=/people/r/robert-frank/>Robert Frank</a>
|
<a href=/people/p/pauli-xu/>Pauli Xu</a>
|
<a href=/people/w/william-merrill/>William Merrill</a>
|
<a href=/people/o/owen-rambow/>Owen Rambow</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1107><div class="card-body p-3 small">We present a graph-based Tree Adjoining Grammar (TAG) parser that uses BiLSTMs, highway connections, and character-level CNNs. Our best end-to-end parser, which jointly performs supertagging, <a href=https://en.wikipedia.org/wiki/Tag_(metadata)>POS tagging</a>, and <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a>, outperforms the previously reported best results by more than 2.2 LAS and UAS points. The graph-based parsing architecture allows for global inference and rich feature representations for TAG parsing, alleviating the fundamental trade-off between transition-based and graph-based parsing systems. We also demonstrate that the proposed <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> achieves state-of-the-art performance in the downstream tasks of Parsing Evaluation using Textual Entailments (PETE) and Unbounded Dependency Recovery. This provides further support for the claim that TAG is a viable <a href=https://en.wikipedia.org/wiki/Formalism_(philosophy_of_mathematics)>formalism</a> for problems that require rich structural analysis of sentences.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1108.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1108 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1108 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/276898233 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1108" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1108/>Colorless Green Recurrent Networks Dream Hierarchically</a></strong><br><a href=/people/k/kristina-gulordava/>Kristina Gulordava</a>
|
<a href=/people/p/piotr-bojanowski/>Piotr Bojanowski</a>
|
<a href=/people/e/edouard-grave/>Edouard Grave</a>
|
<a href=/people/t/tal-linzen/>Tal Linzen</a>
|
<a href=/people/m/marco-baroni/>Marco Baroni</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1108><div class="card-body p-3 small">Recurrent neural networks (RNNs) achieved impressive results in a variety of linguistic processing tasks, suggesting that they can induce non-trivial properties of language. We investigate to what extent <a href=https://en.wikipedia.org/wiki/Radio-frequency_identification>RNNs</a> learn to track abstract hierarchical syntactic structure. We test whether RNNs trained with a generic language modeling objective in four languages (Italian, English, Hebrew, Russian) can predict long-distance number agreement in various constructions. We include in our evaluation nonsensical sentences where RNNs can not rely on semantic or lexical cues (The colorless green ideas I ate with the chair sleep furiously), and, for <a href=https://en.wikipedia.org/wiki/Italian_language>Italian</a>, we compare model performance to human intuitions. Our language-model-trained RNNs make reliable predictions about <a href=https://en.wikipedia.org/wiki/Agreement_(linguistics)>long-distance agreement</a>, and do not lag much behind human performance. We thus bring support to the hypothesis that RNNs are not just shallow-pattern extractors, but they also acquire deeper grammatical competence.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1110.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1110 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1110 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1110/>Early Text Classification Using Multi-Resolution Concept Representations</a></strong><br><a href=/people/a/adrian-pastor-lopez-monroy/>Adrian Pastor López-Monroy</a>
|
<a href=/people/f/fabio-a-gonzalez/>Fabio A. González</a>
|
<a href=/people/m/manuel-montes/>Manuel Montes</a>
|
<a href=/people/h/hugo-jair-escalante/>Hugo Jair Escalante</a>
|
<a href=/people/t/thamar-solorio/>Thamar Solorio</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1110><div class="card-body p-3 small">The intensive use of <a href=https://en.wikipedia.org/wiki/Electronic_communication>e-communications</a> in everyday life has given rise to new threats and risks. When the vulnerable asset is the user, detecting these potential attacks before they cause serious damages is extremely important. This paper proposes a novel document representation to improve the early detection of risks in social media sources. The goal is to effectively identify the potential risk using as few text as possible and with as much anticipation as possible. Accordingly, we devise a Multi-Resolution Representation (MulR), which allows us to generate multiple views of the analyzed text. These views capture different semantic meanings for words and documents at different levels of detail, which is very useful in early scenarios to model the variable amounts of evidence. Intuitively, the representation captures better the content of short documents (very early stages) in low resolutions, whereas large documents (medium / large stages) are better modeled with higher resolutions. We evaluate the proposed ideas in two different tasks where <a href=https://en.wikipedia.org/wiki/Anticipation>anticipation</a> is critical : sexual predator detection and <a href=https://en.wikipedia.org/wiki/Depression_(mood)>depression detection</a>. The experimental evaluation for these early <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> revealed that the proposed approach outperforms previous <a href=https://en.wikipedia.org/wiki/Methodology>methodologies</a> by a considerable margin.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1112.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1112 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1112 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1112/>Pivot Based Language Modeling for Improved Neural Domain Adaptation</a></strong><br><a href=/people/y/yftah-ziser/>Yftah Ziser</a>
|
<a href=/people/r/roi-reichart/>Roi Reichart</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1112><div class="card-body p-3 small">Representation learning with pivot-based methods and with Neural Networks (NNs) have lead to significant progress in <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a>. However, most previous work that follows these approaches does not explicitly exploit the structure of the input text, and its output is most often a single <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representation vector</a> for the entire text. In this paper we present the Pivot Based Language Model (PBLM), a representation learning model that marries together pivot-based and NN modeling in a structure aware manner. Particularly, our model processes the information in the text with a sequential NN (LSTM) and its output consists of a <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representation vector</a> for every input word. Unlike most previous representation learning models in <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a>, PBLM can naturally feed structure aware text classifiers such as LSTM and CNN. We experiment with the task of cross-domain sentiment classification on 20 domain pairs and show substantial improvements over strong baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1113.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1113 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1113 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1113/>Reinforced Co-Training</a></strong><br><a href=/people/j/jiawei-wu/>Jiawei Wu</a>
|
<a href=/people/l/lei-li/>Lei Li</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1113><div class="card-body p-3 small">Co-training is a popular semi-supervised learning framework to utilize a large amount of unlabeled data in addition to a small labeled set. Co-training methods exploit predicted labels on the unlabeled data and select samples based on prediction confidence to augment the training. However, the selection of samples in existing co-training methods is based on a predetermined policy, which ignores the <a href=https://en.wikipedia.org/wiki/Sampling_bias>sampling bias</a> between the unlabeled and the labeled subsets, and fails to explore the data space. In this paper, we propose a novel method, Reinforced Co-Training, to select high-quality unlabeled samples to better co-train on. More specifically, our approach uses <a href=https://en.wikipedia.org/wiki/Q-learning>Q-learning</a> to learn a data selection policy with a small labeled dataset, and then exploits this <a href=https://en.wikipedia.org/wiki/Policy>policy</a> to train the co-training classifiers automatically. Experimental results on clickbait detection and generic text classification tasks demonstrate that our proposed method can obtain more accurate <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a> results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1114.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1114 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1114 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1114" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1114/>Tensor Product Generation Networks for Deep NLP Modeling<span class=acl-fixed-case>NLP</span> Modeling</a></strong><br><a href=/people/q/qiuyuan-huang/>Qiuyuan Huang</a>
|
<a href=/people/p/paul-smolensky/>Paul Smolensky</a>
|
<a href=/people/x/xiaodong-he/>Xiaodong He</a>
|
<a href=/people/l/li-deng/>Li Deng</a>
|
<a href=/people/d/dapeng-wu/>Dapeng Wu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1114><div class="card-body p-3 small">We present a new approach to the design of <a href=https://en.wikipedia.org/wiki/Deep_learning>deep networks</a> for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP)</a>, based on the general technique of <a href=https://en.wikipedia.org/wiki/Tensor_product_representation>Tensor Product Representations (TPRs)</a> for encoding and processing symbol structures in distributed neural networks. A <a href=https://en.wikipedia.org/wiki/Network_architecture>network architecture</a> the Tensor Product Generation Network (TPGN) is proposed which is capable in principle of carrying out TPR computation, but which uses unconstrained deep learning to design its internal representations. Instantiated in a model for image-caption generation, TPGN outperforms LSTM baselines when evaluated on the COCO dataset. The TPR-capable structure enables interpretation of <a href=https://en.wikipedia.org/wiki/Internal_representation>internal representations</a> and <a href=https://en.wikipedia.org/wiki/Operation_(mathematics)>operations</a>, which prove to contain considerable <a href=https://en.wikipedia.org/wiki/Grammaticality>grammatical content</a>. Our caption-generation model can be interpreted as generating sequences of grammatical categories and retrieving words by their categories from a plan encoded as a <a href=https://en.wikipedia.org/wiki/Distributed_representation>distributed representation</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1116.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1116 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1116 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1116/>Combining Character and Word Information in <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a> Using a Multi-Level Attention</a></strong><br><a href=/people/h/huadong-chen/>Huadong Chen</a>
|
<a href=/people/s/shujian-huang/>Shujian Huang</a>
|
<a href=/people/d/david-chiang/>David Chiang</a>
|
<a href=/people/x/xinyu-dai/>Xinyu Dai</a>
|
<a href=/people/j/jiajun-chen/>Jiajun Chen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1116><div class="card-body p-3 small">Natural language sentences, being hierarchical, can be represented at different levels of <a href=https://en.wikipedia.org/wiki/Granularity>granularity</a>, like <a href=https://en.wikipedia.org/wiki/Word>words</a>, <a href=https://en.wikipedia.org/wiki/Subword>subwords</a>, or <a href=https://en.wikipedia.org/wiki/Character_(symbol)>characters</a>. But most neural machine translation systems require the sentence to be represented as a sequence at a single level of granularity. It can be difficult to determine which <a href=https://en.wikipedia.org/wiki/Granularity>granularity</a> is better for a particular translation task. In this paper, we improve the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> by incorporating multiple levels of granularity. Specifically, we propose (1) an encoder with character attention which augments the (sub)word-level representation with character-level information ; (2) a decoder with multiple attentions that enable the representations from different levels of granularity to control the translation cooperatively. Experiments on three translation tasks demonstrate that our proposed models outperform the standard word-based model, the subword-based model, and a strong character-based model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1117.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1117 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1117 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1117" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1117/>Dense Information Flow for <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a></a></strong><br><a href=/people/y/yanyao-shen/>Yanyao Shen</a>
|
<a href=/people/x/xu-tan/>Xu Tan</a>
|
<a href=/people/d/di-he/>Di He</a>
|
<a href=/people/t/tao-qin/>Tao Qin</a>
|
<a href=/people/t/tie-yan-liu/>Tie-Yan Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1117><div class="card-body p-3 small">Recently, <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a> has achieved remarkable progress by introducing well-designed deep neural networks into its encoder-decoder framework. From the optimization perspective, residual connections are adopted to improve learning performance for both <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> and <a href=https://en.wikipedia.org/wiki/Codec>decoder</a> in most of these deep architectures, and advanced attention connections are applied as well. Inspired by the success of the DenseNet model in computer vision problems, in this paper, we propose a densely connected NMT architecture (DenseNMT) that is able to train more efficiently for <a href=https://en.wikipedia.org/wiki/Network_topology>NMT</a>. The proposed DenseNMT not only allows dense connection in creating new features for both encoder and decoder, but also uses the dense attention structure to improve <a href=https://en.wikipedia.org/wiki/Attentional_control>attention quality</a>. Our experiments on multiple datasets show that DenseNMT structure is more competitive and efficient.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1119.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1119 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1119 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1119/>Fast Lexically Constrained Decoding with Dynamic Beam Allocation for Neural Machine Translation</a></strong><br><a href=/people/m/matt-post/>Matt Post</a>
|
<a href=/people/d/david-vilar/>David Vilar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1119><div class="card-body p-3 small">The end-to-end nature of neural machine translation (NMT) removes many ways of manually guiding the translation process that were available in older paradigms. Recent work, however, has introduced a new capability : lexically constrained or guided decoding, a modification to beam search that forces the inclusion of pre-specified words and phrases in the output. However, while theoretically sound, existing approaches have computational complexities that are either linear (Hokamp and Liu, 2017) or exponential (Anderson et al., 2017) in the number of <a href=https://en.wikipedia.org/wiki/Constraint_(mathematics)>constraints</a>. We present a <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> for lexically constrained decoding with a <a href=https://en.wikipedia.org/wiki/Computational_complexity_theory>complexity</a> of O(1) in the number of constraints. We demonstrate the <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a>&#8217;s remarkable ability to properly place these <a href=https://en.wikipedia.org/wiki/Constraint_(mathematics)>constraints</a>, and use it to explore the shaky relationship between <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> and BLEU scores. Our <a href=https://en.wikipedia.org/wiki/Implementation>implementation</a> is available as part of <a href=https://en.wikipedia.org/wiki/Sockeye>Sockeye</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1120.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1120 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1120 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1120/>Guiding Neural Machine Translation with Retrieved Translation Pieces</a></strong><br><a href=/people/j/jingyi-zhang/>Jingyi Zhang</a>
|
<a href=/people/m/masao-utiyama/>Masao Utiyama</a>
|
<a href=/people/e/eiichiro-sumita/>Eiichro Sumita</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/s/satoshi-nakamura/>Satoshi Nakamura</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1120><div class="card-body p-3 small">One of the difficulties of neural machine translation (NMT) is the recall and appropriate translation of low-frequency words or phrases. In this paper, we propose a simple, fast, and effective method for recalling previously seen translation examples and incorporating them into the NMT decoding process. Specifically, for an input sentence, we use a <a href=https://en.wikipedia.org/wiki/Web_search_engine>search engine</a> to retrieve sentence pairs whose source sides are similar with the input sentence, and then collect <a href=https://en.wikipedia.org/wiki/N-gram>n-grams</a> that are both in the retrieved target sentences and aligned with words that match in the source sentences, which we call translation pieces. We compute pseudo-probabilities for each retrieved sentence based on similarities between the input sentence and the retrieved source sentences, and use these to weight the retrieved translation pieces. Finally, an existing NMT model is used to translate the input sentence, with an additional bonus given to outputs that contain the collected translation pieces. We show our method improves NMT translation results up to 6 BLEU points on three narrow domain translation tasks where repetitiveness of the target sentences is particularly salient. It also causes little increase in the translation time, and compares favorably to another alternative retrieval-based method with respect to <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, <a href=https://en.wikipedia.org/wiki/Speed>speed</a>, and simplicity of implementation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1121.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1121 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1121 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1121/>Handling <a href=https://en.wikipedia.org/wiki/Homograph>Homographs</a> in Neural Machine Translation</a></strong><br><a href=/people/f/frederick-liu/>Frederick Liu</a>
|
<a href=/people/h/han-lu/>Han Lu</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1121><div class="card-body p-3 small">Homographs, words with different meanings but the same surface form, have long caused difficulty for machine translation systems, as it is difficult to select the correct <a href=https://en.wikipedia.org/wiki/Translation>translation</a> based on the context. However, with the advent of neural machine translation (NMT) systems, which can theoretically take into account global sentential context, one may hypothesize that this problem has been alleviated. In this paper, we first provide empirical evidence that existing NMT systems in fact still have significant problems in properly translating ambiguous words. We then proceed to describe methods, inspired by the word sense disambiguation literature, that model the context of the input word with context-aware word embeddings that help to differentiate the word sense before feeding it into the encoder. Experiments on three language pairs demonstrate that such models improve the performance of NMT systems both in terms of BLEU score and in the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of translating <a href=https://en.wikipedia.org/wiki/Homograph>homographs</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1122.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1122 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1122 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1122.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1122" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1122/>Improving <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a> with Conditional Sequence Generative Adversarial Nets</a></strong><br><a href=/people/z/zhen-yang/>Zhen Yang</a>
|
<a href=/people/w/wei-chen/>Wei Chen</a>
|
<a href=/people/f/feng-wang/>Feng Wang</a>
|
<a href=/people/b/bo-xu/>Bo Xu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1122><div class="card-body p-3 small">This paper proposes an approach for applying <a href=https://en.wikipedia.org/wiki/Global_area_network>GANs</a> to <a href=https://en.wikipedia.org/wiki/Network_topology>NMT</a>. We build a conditional sequence generative adversarial net which comprises of two adversarial sub models, a generator and a <a href=https://en.wikipedia.org/wiki/Discriminator>discriminator</a>. The <a href=https://en.wikipedia.org/wiki/Generator_(mathematics)>generator</a> aims to generate sentences which are hard to be discriminated from <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>human-translated sentences</a> (i.e., the golden target sentences) ; And the <a href=https://en.wikipedia.org/wiki/Discriminator>discriminator</a> makes efforts to discriminate the machine-generated sentences from <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>human-translated ones</a>. The two sub models play a mini-max game and achieve the <a href=https://en.wikipedia.org/wiki/Win-win_game>win-win situation</a> when they reach a <a href=https://en.wikipedia.org/wiki/Nash_equilibrium>Nash Equilibrium</a>. Additionally, the static sentence-level BLEU is utilized as the reinforced objective for the generator, which biases the generation towards high BLEU points. During <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training</a>, both the dynamic discriminator and the static BLEU objective are employed to evaluate the generated sentences and feedback the evaluations to guide the learning of the generator. Experimental results show that the proposed model consistently outperforms the traditional RNNSearch and the newly emerged state-of-the-art Transformer on English-German and Chinese-English translation tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1123.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1123 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1123 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1123/>Neural Machine Translation for Bilingually Scarce Scenarios : a Deep Multi-Task Learning Approach</a></strong><br><a href=/people/p/poorya-zaremoodi/>Poorya Zaremoodi</a>
|
<a href=/people/g/gholamreza-haffari/>Gholamreza Haffari</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1123><div class="card-body p-3 small">Neural machine translation requires large amount of parallel training text to learn a reasonable quality <a href=https://en.wikipedia.org/wiki/Translation_(biology)>translation model</a>. This is particularly inconvenient for language pairs for which enough <a href=https://en.wikipedia.org/wiki/Parallel_text>parallel text</a> is not available. In this paper, we use monolingual linguistic resources in the source side to address this challenging problem based on a multi-task learning approach. More specifically, we scaffold the machine translation task on auxiliary tasks including <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a>, <a href=https://en.wikipedia.org/wiki/Syntactic_parsing>syntactic parsing</a>, and <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named-entity recognition</a>. This effectively injects semantic and/or syntactic knowledge into the translation model, which would otherwise require a large amount of training bitext to learn from. We empirically analyze and show the effectiveness of our multitask learning approach on three translation tasks : <a href=https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language>English-to-French</a>, <a href=https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language>English-to-Farsi</a>, and <a href=https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language>English-to-Vietnamese</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1124.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1124 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1124 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1124.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1124" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1124/>Self-Attentive Residual Decoder for <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a></a></strong><br><a href=/people/l/lesly-miculicich-werlen/>Lesly Miculicich Werlen</a>
|
<a href=/people/n/nikolaos-pappas/>Nikolaos Pappas</a>
|
<a href=/people/d/dhananjay-ram/>Dhananjay Ram</a>
|
<a href=/people/a/andrei-popescu-belis/>Andrei Popescu-Belis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1124><div class="card-body p-3 small">Neural sequence-to-sequence networks with attention have achieved remarkable performance for <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. One of the reasons for their effectiveness is their ability to capture relevant source-side contextual information at each time-step prediction through an attention mechanism. However, the target-side context is solely based on the sequence model which, in practice, is prone to a <a href=https://en.wikipedia.org/wiki/Recency_bias>recency bias</a> and lacks the ability to capture effectively non-sequential dependencies among words. To address this limitation, we propose a target-side-attentive residual recurrent network for decoding, where <a href=https://en.wikipedia.org/wiki/Attention>attention</a> over previous words contributes directly to the prediction of the next word. The residual learning facilitates the flow of information from the distant past and is able to emphasize any of the previously translated words, hence it gains access to a wider context. The proposed model outperforms a neural MT baseline as well as a memory and self-attention network on three language pairs. The analysis of the <a href=https://en.wikipedia.org/wiki/Attention>attention</a> learned by the <a href=https://en.wikipedia.org/wiki/Code>decoder</a> confirms that it emphasizes a wider context, and that it captures syntactic-like structures.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1126.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1126 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1126 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1126/>Context Sensitive Neural Lemmatization with Lematus<span class=acl-fixed-case>L</span>ematus</a></strong><br><a href=/people/t/toms-bergmanis/>Toms Bergmanis</a>
|
<a href=/people/s/sharon-goldwater/>Sharon Goldwater</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1126><div class="card-body p-3 small">The main motivation for developing contextsensitive lemmatizers is to improve performance on unseen and ambiguous words. Yet previous systems have not carefully evaluated whether the use of <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context</a> actually helps in these cases. We introduce Lematus, a <a href=https://en.wikipedia.org/wiki/Lemmatizer>lemmatizer</a> based on a standard encoder-decoder architecture, which incorporates character-level sentence context. We evaluate its lemmatization accuracy across 20 languages in both a full data setting and a lower-resource setting with 10k training examples in each language. In both settings, we show that including <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context</a> significantly improves results against a context-free version of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. Context helps more for ambiguous words than for unseen words, though the latter has a greater effect on overall performance differences between languages. We also compare to three previous context-sensitive lemmatization systems, which all use pre-extracted edit trees as well as hand-selected features and/or additional sources of information such as tagged training data. Without using any of these, our context-sensitive model outperforms the best competitor system (Lemming) in the fulldata setting, and performs on par in the lowerresource setting.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1127.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1127 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1127 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1127/>Modeling Noisiness to Recognize Named Entities using Multitask Neural Networks on Social Media</a></strong><br><a href=/people/g/gustavo-aguilar/>Gustavo Aguilar</a>
|
<a href=/people/a/adrian-pastor-lopez-monroy/>Adrian Pastor López-Monroy</a>
|
<a href=/people/f/fabio-a-gonzalez/>Fabio González</a>
|
<a href=/people/t/thamar-solorio/>Thamar Solorio</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1127><div class="card-body p-3 small">Recognizing named entities in a document is a key task in many <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP applications</a>. Although current state-of-the-art approaches to this <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a> reach a high performance on clean text (e.g. newswire genres), those <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> dramatically degrade when they are moved to noisy environments such as social media domains. We present two systems that address the challenges of processing social media data using character-level phonetics and <a href=https://en.wikipedia.org/wiki/Phonology>phonology</a>, <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a>, and Part-of-Speech tags as features. The first model is a multitask end-to-end Bidirectional Long Short-Term Memory (BLSTM)-Conditional Random Field (CRF) network whose output layer contains two CRF classifiers. The second model uses a multitask BLSTM network as <a href=https://en.wikipedia.org/wiki/Feature_extraction>feature extractor</a> that transfers the learning to a CRF classifier for the final prediction. Our systems outperform the current F1 scores of the state of the art on the Workshop on Noisy User-generated Text 2017 dataset by 2.45 % and 3.69 %, establishing a more suitable approach for social media environments.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1131.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1131 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1131 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/277349441 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1131/>A Neural Layered Model for Nested Named Entity Recognition</a></strong><br><a href=/people/m/meizhi-ju/>Meizhi Ju</a>
|
<a href=/people/m/makoto-miwa/>Makoto Miwa</a>
|
<a href=/people/s/sophia-ananiadou/>Sophia Ananiadou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1131><div class="card-body p-3 small">Entity mentions embedded in longer entity mentions are referred to as nested entities. Most named entity recognition (NER) systems deal only with the flat entities and ignore the inner nested ones, which fails to capture finer-grained semantic information in underlying texts. To address this issue, we propose a novel neural model to identify nested entities by dynamically stacking flat NER layers. Each flat NER layer is based on the state-of-the-art flat NER model that captures sequential context representation with bidirectional Long Short-Term Memory (LSTM) layer and feeds it to the cascaded CRF layer. Our model merges the output of the LSTM layer in the current flat NER layer to build new representation for detected entities and subsequently feeds them into the next flat NER layer. This allows our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to extract outer entities by taking full advantage of information encoded in their corresponding inner entities, in an inside-to-outside way. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> dynamically stacks the flat NER layers until no outer entities are extracted. Extensive evaluation shows that our <a href=https://en.wikipedia.org/wiki/Dynamical_system>dynamic model</a> outperforms state-of-the-art feature-based systems on nested NER, achieving 74.7 % and 72.2 % on GENIA and ACE2005 datasets, respectively, in terms of <a href=https://en.wikipedia.org/wiki/F-score>F-score</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1133.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1133 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1133 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1133.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277671743 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1133" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1133/>KBGAN : <a href=https://en.wikipedia.org/wiki/Adversarial_learning>Adversarial Learning</a> for Knowledge Graph Embeddings<span class=acl-fixed-case>KBGAN</span>: Adversarial Learning for Knowledge Graph Embeddings</a></strong><br><a href=/people/l/liwei-cai/>Liwei Cai</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1133><div class="card-body p-3 small">We introduce KBGAN, an adversarial learning framework to improve the performances of a wide range of existing knowledge graph embedding models. Because <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graphs</a> typically only contain positive facts, sampling useful negative training examples is a nontrivial task. Replacing the head or tail entity of a fact with a uniformly randomly selected entity is a conventional method for generating negative facts, but the majority of the generated negative facts can be easily discriminated from positive facts, and will contribute little towards the training. Inspired by generative adversarial networks (GANs), we use one knowledge graph embedding model as a negative sample generator to assist the training of our desired model, which acts as the discriminator in GANs. This framework is independent of the concrete form of generator and discriminator, and therefore can utilize a wide variety of knowledge graph embedding models as its building blocks. In experiments, we adversarially train two translation-based models, TRANSE and TRANSD, each with assistance from one of the two probability-based models, DISTMULT and COMPLEX. We evaluate the performances of KBGAN on the link prediction task, using three knowledge base completion datasets : FB15k-237, WN18 and WN18RR. Experimental results show that adversarial training substantially improves the performances of target embedding models under various settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1136.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1136 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1136 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1136.Datasets.tgz data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file-archive"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277672916 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1136" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1136/>Identifying Semantic Divergences in <a href=https://en.wikipedia.org/wiki/Parallel_text>Parallel Text</a> without Annotations</a></strong><br><a href=/people/y/yogarshi-vyas/>Yogarshi Vyas</a>
|
<a href=/people/x/xing-niu/>Xing Niu</a>
|
<a href=/people/m/marine-carpuat/>Marine Carpuat</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1136><div class="card-body p-3 small">Recognizing that even correct translations are not always semantically equivalent, we automatically detect meaning divergences in parallel sentence pairs with a deep neural model of bilingual semantic similarity which can be trained for any parallel corpus without any manual annotation. We show that our <a href=https://en.wikipedia.org/wiki/Semantic_model>semantic model</a> detects divergences more accurately than models based on surface features derived from word alignments, and that these divergences matter for neural machine translation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1137.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1137 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1137 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/277348853 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1137" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1137/>Bootstrapping Generators from Noisy Data</a></strong><br><a href=/people/l/laura-perez-beltrachini/>Laura Perez-Beltrachini</a>
|
<a href=/people/m/mirella-lapata/>Mirella Lapata</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1137><div class="card-body p-3 small">A core step in statistical data-to-text generation concerns learning correspondences between <a href=https://en.wikipedia.org/wiki/Data_structure>structured data representations</a> (e.g., facts in a database) and associated texts. In this paper we aim to bootstrap <a href=https://en.wikipedia.org/wiki/Generator_(mathematics)>generators</a> from <a href=https://en.wikipedia.org/wiki/Data_set>large scale datasets</a> where the data (e.g., <a href=https://en.wikipedia.org/wiki/Dbpedia>DBPedia facts</a>) and related texts (e.g., Wikipedia abstracts) are loosely aligned. We tackle this challenging <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> by introducing a special-purpose content selection mechanism. We use multi-instance learning to automatically discover correspondences between data and text pairs and show how these can be used to enhance the content signal while training an encoder-decoder architecture. Experimental results demonstrate that <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained with content-specific objectives improve upon a vanilla encoder-decoder which solely relies on soft attention.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1138.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1138 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1138 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/277348640 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1138/>SHAPED : Shared-Private Encoder-Decoder for Text Style Adaptation<span class=acl-fixed-case>SHAPED</span>: Shared-Private Encoder-Decoder for Text Style Adaptation</a></strong><br><a href=/people/y/ye-zhang/>Ye Zhang</a>
|
<a href=/people/n/nan-ding/>Nan Ding</a>
|
<a href=/people/r/radu-soricut/>Radu Soricut</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1138><div class="card-body p-3 small">Supervised training of abstractive language generation models results in learning conditional probabilities over language sequences based on the supervised training signal. When the training signal contains a variety of <a href=https://en.wikipedia.org/wiki/Writing_style>writing styles</a>, such models may end up learning an &#8216;average&#8217; style that is directly influenced by the training data make-up and can not be controlled by the needs of an application. We describe a family of model architectures capable of capturing both generic language characteristics via shared model parameters, as well as particular style characteristics via private model parameters. Such <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are able to generate <a href=https://en.wikipedia.org/wiki/Language>language</a> according to a specific learned style, while still taking advantage of their power to model generic language phenomena. Furthermore, we describe an extension that uses a mixture of output distributions from all learned styles to perform on-the-fly style adaptation based on the textual input alone. Experimentally, we find that the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> consistently outperform <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that encapsulate single-style or average-style language generation capabilities.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1139.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1139 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1139 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1139" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1139/>Generating Descriptions from Structured Data Using a Bifocal Attention Mechanism and Gated Orthogonalization</a></strong><br><a href=/people/p/preksha-nema/>Preksha Nema</a>
|
<a href=/people/s/shreyas-shetty/>Shreyas Shetty</a>
|
<a href=/people/p/parag-jain/>Parag Jain</a>
|
<a href=/people/a/anirban-laha/>Anirban Laha</a>
|
<a href=/people/k/karthik-sankaranarayanan/>Karthik Sankaranarayanan</a>
|
<a href=/people/m/mitesh-m-khapra/>Mitesh M. Khapra</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1139><div class="card-body p-3 small">In this work, we focus on the task of generating natural language descriptions from a structured table of facts containing fields (such as nationality, occupation, etc) and values (such as <a href=https://en.wikipedia.org/wiki/Indian_people>Indian</a>, <a href=https://en.wikipedia.org/wiki/Actor>actor</a>, director, etc). One simple choice is to treat the table as a sequence of fields and values and then use a standard seq2seq model for this task. However, such a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> is too generic and does not exploit task specific characteristics. For example, while generating descriptions from a table, a human would attend to information at two levels : (i) the fields (macro level) and (ii) the values within the field (micro level). Further, a human would continue attending to a field for a few timesteps till all the information from that field has been rendered and then never return back to this field (because there is nothing left to say about it). To capture this behavior we use (i) a fused bifocal attention mechanism which exploits and combines this micro and macro level information and (ii) a gated orthogonalization mechanism which tries to ensure that a field is remembered for a few time steps and then forgotten. We experiment with a recently released dataset which contains fact tables about people and their corresponding one line biographical descriptions in English. In addition, we also introduce two similar <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> for <a href=https://en.wikipedia.org/wiki/French_language>French</a> and <a href=https://en.wikipedia.org/wiki/German_language>German</a>. Our experiments show that the proposed model gives 21 % relative improvement over a recently proposed state of the art method and 10 % relative improvement over basic seq2seq models.<url>https://github.com/PrekshaNema25/StructuredData_To_Descriptions</url>\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1140.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1140 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1140 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1140" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1140/>CliCR : a Dataset of Clinical Case Reports for Machine Reading Comprehension<span class=acl-fixed-case>C</span>li<span class=acl-fixed-case>CR</span>: a Dataset of Clinical Case Reports for Machine Reading Comprehension</a></strong><br><a href=/people/s/simon-suster/>Simon Šuster</a>
|
<a href=/people/w/walter-daelemans/>Walter Daelemans</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1140><div class="card-body p-3 small">We present a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for <a href=https://en.wikipedia.org/wiki/Machine_learning>machine comprehension</a> in the <a href=https://en.wikipedia.org/wiki/Medicine>medical domain</a>. Our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> uses clinical case reports with around 100,000 gap-filling queries about these cases. We apply several baselines and state-of-the-art neural readers to the dataset, and observe a considerable gap in performance (20 % F1) between the best human and machine readers. We analyze the skills required for successful answering and show how <a href=https://en.wikipedia.org/wiki/Reading>reader</a> performance varies depending on the applicable skills. We find that inferences using <a href=https://en.wikipedia.org/wiki/Domain_knowledge>domain knowledge</a> and object tracking are the most frequently required skills, and that recognizing omitted information and spatio-temporal reasoning are the most difficult for the machines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1141.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1141 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1141 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1141/>Learning to Collaborate for Question Answering and Asking</a></strong><br><a href=/people/d/duyu-tang/>Duyu Tang</a>
|
<a href=/people/n/nan-duan/>Nan Duan</a>
|
<a href=/people/z/zhao-yan/>Zhao Yan</a>
|
<a href=/people/z/zhirui-zhang/>Zhirui Zhang</a>
|
<a href=/people/y/yibo-sun/>Yibo Sun</a>
|
<a href=/people/s/shujie-liu/>Shujie Liu</a>
|
<a href=/people/y/yuanhua-lv/>Yuanhua Lv</a>
|
<a href=/people/m/ming-zhou/>Ming Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1141><div class="card-body p-3 small">Question answering (QA) and question generation (QG) are closely related <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> that could improve each other ; however, the connection of these two <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> is not well explored in literature. In this paper, we give a systematic study that seeks to leverage the connection to improve both QA and QG. We present a training algorithm that generalizes both Generative Adversarial Network (GAN) and Generative Domain-Adaptive Nets (GDAN) under the question answering scenario. The two key ideas are improving the QG model with QA through incorporating additional QA-specific signal as the <a href=https://en.wikipedia.org/wiki/Loss_function>loss function</a>, and improving the QA model with QG through adding artificially generated training instances. We conduct experiments on both document based and knowledge based question answering tasks. We have two main findings. Firstly, the performance of a QG model (e.g in terms of BLEU score) could be easily improved by a QA model via policy gradient. Secondly, directly applying GAN that regards all the generated questions as negative instances could not improve the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of the QA model. Learning when to regard generated questions as positive instances could bring performance boost.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1143.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1143 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1143 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1143/>Supervised and Unsupervised Transfer Learning for Question Answering</a></strong><br><a href=/people/y/yu-an-chung/>Yu-An Chung</a>
|
<a href=/people/h/hung-yi-lee/>Hung-Yi Lee</a>
|
<a href=/people/j/james-glass/>James Glass</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1143><div class="card-body p-3 small">Although <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> has been shown to be successful for tasks like <a href=https://en.wikipedia.org/wiki/Outline_of_object_recognition>object and speech recognition</a>, its applicability to <a href=https://en.wikipedia.org/wiki/Question_answering>question answering (QA)</a> has yet to be well-studied. In this paper, we conduct extensive experiments to investigate the transferability of knowledge learned from a source QA dataset to a target dataset using two QA models. The performance of both models on a TOEFL listening comprehension test (Tseng et al., 2016) and MCTest (Richardson et al., 2013) is significantly improved via a simple transfer learning technique from MovieQA (Tapaswi et al., 2016). In particular, one of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> achieves the state-of-the-art on all target datasets ; for the <a href=https://en.wikipedia.org/wiki/Test_of_English_as_a_Foreign_Language>TOEFL listening comprehension test</a>, it outperforms the previous best <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> by 7 %. Finally, we show that <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> is helpful even in unsupervised scenarios when correct answers for target QA dataset examples are not available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1146.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1146 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1146 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1146/>Deconfounded Lexicon Induction for Interpretable Social Science</a></strong><br><a href=/people/r/reid-pryzant/>Reid Pryzant</a>
|
<a href=/people/k/kelly-shen/>Kelly Shen</a>
|
<a href=/people/d/dan-jurafsky/>Dan Jurafsky</a>
|
<a href=/people/s/stefan-wagner/>Stefan Wagner</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1146><div class="card-body p-3 small">NLP algorithms are increasingly used in <a href=https://en.wikipedia.org/wiki/Computational_social_science>computational social science</a> to take <a href=https://en.wikipedia.org/wiki/Linguistic_description>linguistic observations</a> and predict outcomes like <a href=https://en.wikipedia.org/wiki/Preference>human preferences</a> or actions. Making these <a href=https://en.wikipedia.org/wiki/Social_model>social models</a> transparent and interpretable often requires identifying <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> in the input that predict outcomes while also controlling for potential <a href=https://en.wikipedia.org/wiki/Confounding>confounds</a>. We formalize this need as a new task : inducing a lexicon that is predictive of a set of target variables yet uncorrelated to a set of confounding variables. We introduce two <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning algorithms</a> for the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. The first uses a bifurcated architecture to separate the explanatory power of the text and <a href=https://en.wikipedia.org/wiki/Confounding>confounds</a>. The second uses an adversarial discriminator to force confound-invariant text encodings. Both elicit <a href=https://en.wikipedia.org/wiki/Lexicon>lexicons</a> from learned weights and <a href=https://en.wikipedia.org/wiki/Attentional_control>attentional scores</a>. We use them to induce lexicons that are predictive of timely responses to consumer complaints (controlling for product), enrollment from course descriptions (controlling for subject), and sales from product descriptions (controlling for seller). In each domain our algorithms pick words that are associated with narrative persuasion ; more predictive and less confound-related than those of standard feature weighting and lexicon induction techniques like <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression</a> and log odds.<i>narrative persuasion</i>; more\n predictive and less confound-related than those of standard\n feature weighting and lexicon induction techniques like\n regression and log odds.\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1149.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1149 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1149 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1149.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1149" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1149/>A Dataset of Peer Reviews (PeerRead): Collection, Insights and NLP Applications<span class=acl-fixed-case>P</span>eer<span class=acl-fixed-case>R</span>ead): Collection, Insights and <span class=acl-fixed-case>NLP</span> Applications</a></strong><br><a href=/people/d/dongyeop-kang/>Dongyeop Kang</a>
|
<a href=/people/w/waleed-ammar/>Waleed Ammar</a>
|
<a href=/people/b/bhavana-dalvi/>Bhavana Dalvi</a>
|
<a href=/people/m/madeleine-van-zuylen/>Madeleine van Zuylen</a>
|
<a href=/people/s/sebastian-kohlmeier/>Sebastian Kohlmeier</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a>
|
<a href=/people/r/roy-schwartz/>Roy Schwartz</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1149><div class="card-body p-3 small">Peer reviewing is a central component in the <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific publishing process</a>. We present the first public dataset of scientific peer reviews available for research purposes (PeerRead v1),1 providing an opportunity to study this important artifact. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> consists of 14.7 K paper drafts and the corresponding accept / reject decisions in top-tier venues including ACL, <a href=https://en.wikipedia.org/wiki/National_Institute_of_Standards_and_Technology>NIPS</a> and ICLR. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> also includes 10.7 K textual peer reviews written by experts for a subset of the papers. We describe the data collection process and report interesting observed phenomena in the <a href=https://en.wikipedia.org/wiki/Peer_review>peer reviews</a>. We also propose two novel NLP tasks based on this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> and provide simple baseline models. In the first <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, we show that simple <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> can predict whether a paper is accepted with up to 21 % <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error reduction</a> compared to the majority baseline. In the second task, we predict the numerical scores of review aspects and show that simple models can outperform the mean baseline for aspects with high variance such as &#8216;originality&#8217; and &#8216;impact&#8217;.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1150.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1150 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1150 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1150/>Deep Communicating Agents for Abstractive Summarization</a></strong><br><a href=/people/a/asli-celikyilmaz/>Asli Celikyilmaz</a>
|
<a href=/people/a/antoine-bosselut/>Antoine Bosselut</a>
|
<a href=/people/x/xiaodong-he/>Xiaodong He</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1150><div class="card-body p-3 small">We present deep communicating agents in an encoder-decoder architecture to address the challenges of representing a long document for abstractive summarization. With deep communicating agents, the task of encoding a long text is divided across multiple collaborating agents, each in charge of a subsection of the input text. These encoders are connected to a single <a href=https://en.wikipedia.org/wiki/Encoder>decoder</a>, trained end-to-end using <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a> to generate a focused and coherent summary. Empirical results demonstrate that multiple communicating encoders lead to a higher quality summary compared to several strong baselines, including those based on a single <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> or multiple non-communicating encoders.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1152.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1152 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1152 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1152/>Estimating Summary Quality with Pairwise Preferences</a></strong><br><a href=/people/m/markus-zopf/>Markus Zopf</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1152><div class="card-body p-3 small">Automatic evaluation systems in the field of <a href=https://en.wikipedia.org/wiki/Automatic_summarization>automatic summarization</a> have been relying on the availability of gold standard summaries for over ten years. Gold standard summaries are expensive to obtain and often require the availability of domain experts to achieve high quality. In this paper, we propose an alternative evaluation approach based on pairwise preferences of sentences. In comparison to gold standard summaries, they are simpler and cheaper to obtain. In our experiments, we show that humans are able to provide useful feedback in the form of pairwise preferences. The new <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> performs better than the three most popular versions of ROUGE with less expensive human input. We also show that our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> can reuse already available evaluation data and achieve even better results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1158.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1158 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1158 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1158" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1158/>Ranking Sentences for Extractive Summarization with <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>Reinforcement Learning</a></a></strong><br><a href=/people/s/shashi-narayan/>Shashi Narayan</a>
|
<a href=/people/s/shay-b-cohen/>Shay B. Cohen</a>
|
<a href=/people/m/mirella-lapata/>Mirella Lapata</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1158><div class="card-body p-3 small">Single document summarization is the task of producing a shorter version of a document while preserving its principal information content. In this paper we conceptualize extractive summarization as a sentence ranking task and propose a novel <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training algorithm</a> which globally optimizes the ROUGE evaluation metric through a reinforcement learning objective. We use our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> to train a neural summarization model on the CNN and DailyMail datasets and demonstrate experimentally that it outperforms state-of-the-art extractive and abstractive systems when evaluated automatically and by humans.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1163.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1163 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1163 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277671902 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1163/>Detecting Egregious Conversations between Customers and Virtual Agents</a></strong><br><a href=/people/t/tommy-sandbank/>Tommy Sandbank</a>
|
<a href=/people/m/michal-shmueli-scheuer/>Michal Shmueli-Scheuer</a>
|
<a href=/people/j/jonathan-herzig/>Jonathan Herzig</a>
|
<a href=/people/d/david-konopnicki/>David Konopnicki</a>
|
<a href=/people/j/john-richards/>John Richards</a>
|
<a href=/people/d/david-piorkowski/>David Piorkowski</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1163><div class="card-body p-3 small">Virtual agents are becoming a prominent channel of interaction in <a href=https://en.wikipedia.org/wiki/Customer_service>customer service</a>. Not all <a href=https://en.wikipedia.org/wiki/Customer_relationship_management>customer interactions</a> are smooth, however, and some can become almost comically bad. In such instances, a <a href=https://en.wikipedia.org/wiki/Agent-based_model>human agent</a> might need to step in and salvage the conversation. Detecting bad conversations is important since disappointing customer service may threaten <a href=https://en.wikipedia.org/wiki/Loyalty_business_model>customer loyalty</a> and impact revenue. In this paper, we outline an approach to detecting such egregious conversations, using behavioral cues from the user, patterns in agent responses, and user-agent interaction. Using logs of two commercial systems, we show that using these <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> improves the detection F1-score by around 20 % over using textual features alone. In addition, we show that those <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> are common across two quite different domains and, arguably, universal.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1164.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1164 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1164 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277671673 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1164/>Learning to Disentangle Interleaved Conversational Threads with a Siamese Hierarchical Network and Similarity Ranking<span class=acl-fixed-case>S</span>iamese Hierarchical Network and Similarity Ranking</a></strong><br><a href=/people/j/jyun-yu-jiang/>Jyun-Yu Jiang</a>
|
<a href=/people/f/francine-chen/>Francine Chen</a>
|
<a href=/people/y/yan-ying-chen/>Yan-Ying Chen</a>
|
<a href=/people/w/wei-wang/>Wei Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1164><div class="card-body p-3 small">An enormous amount of <a href=https://en.wikipedia.org/wiki/Conversation>conversation</a> occurs online every day, such as on chat platforms where multiple conversations may take place concurrently. Interleaved conversations lead to difficulties in not only following discussions but also retrieving relevant information from simultaneous messages. Conversation disentanglement aims to separate <a href=https://en.wikipedia.org/wiki/Interpersonal_communication>intermingled messages</a> into <a href=https://en.wikipedia.org/wiki/Conversation>detached conversations</a>. In this paper, we propose to leverage <a href=https://en.wikipedia.org/wiki/Representation_learning>representation learning</a> for conversation disentanglement. A Siamese hierarchical convolutional neural network (SHCNN), which integrates local and more global representations of a message, is first presented to estimate the conversation-level similarity between closely posted messages. With the estimated similarity scores, our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> for conversation identification by similarity ranking (CISIR) then derives conversations based on high-confidence message pairs and pairwise redundancy. Experiments were conducted with four publicly available <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> of conversations from <a href=https://en.wikipedia.org/wiki/Internet_Relay_Chat>Reddit and IRC channels</a>. The experimental results show that our approach significantly outperforms comparative baselines in both pairwise similarity estimation and conversation disentanglement.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1165.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1165 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1165 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277673049 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1165/>Variational Knowledge Graph Reasoning</a></strong><br><a href=/people/w/wenhu-chen/>Wenhu Chen</a>
|
<a href=/people/w/wenhan-xiong/>Wenhan Xiong</a>
|
<a href=/people/x/xifeng-yan/>Xifeng Yan</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1165><div class="card-body p-3 small">Inferring missing links in knowledge graphs (KG) has attracted a lot of attention from the research community. In this paper, we tackle a practical query answering task involving predicting the relation of a given entity pair. We frame this prediction problem as an inference problem in a probabilistic graphical model and aim at resolving it from a variational inference perspective. In order to model the relation between the query entity pair, we assume that there exists an underlying <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variable</a> (paths connecting two nodes) in the KG, which carries the equivalent semantics of their relations. However, due to the intractability of connections in large KGs, we propose to use variation inference to maximize the evidence lower bound. More specifically, our framework (Diva) is composed of three <a href=https://en.wikipedia.org/wiki/Modular_programming>modules</a>, i.e. a posterior approximator, a prior (path finder), and a likelihood (path reasoner). By using <a href=https://en.wikipedia.org/wiki/Variational_inference>variational inference</a>, we are able to incorporate them closely into a unified architecture and jointly optimize them to perform KG reasoning. With active interactions among these sub-modules, Diva is better at handling <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noise</a> and coping with more complex reasoning scenarios. In order to evaluate our method, we conduct the experiment of the link prediction task on multiple datasets and achieve state-of-the-art performances on both datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1168.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1168 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1168 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277673836 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1168" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1168/>Interpretable Charge Predictions for Criminal Cases : Learning to Generate Court Views from Fact Descriptions</a></strong><br><a href=/people/h/hai-ye/>Hai Ye</a>
|
<a href=/people/x/xin-jiang/>Xin Jiang</a>
|
<a href=/people/z/zhunchen-luo/>Zhunchen Luo</a>
|
<a href=/people/w/wenhan-chao/>Wenhan Chao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1168><div class="card-body p-3 small">In this paper, we propose to study the problem of court view generation from the fact description in a <a href=https://en.wikipedia.org/wiki/Criminal_law>criminal case</a>. The <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> aims to improve the interpretability of charge prediction systems and help automatic legal document generation. We formulate this task as a text-to-text natural language generation (NLG) problem. Sequence-to-sequence model has achieved cutting-edge performances in many NLG tasks. However, due to the non-distinctions of fact descriptions, it is hard for Seq2Seq model to generate charge-discriminative court views. In this work, we explore charge labels to tackle this issue. We propose a label-conditioned Seq2Seq model with <a href=https://en.wikipedia.org/wiki/Attention>attention</a> for this problem, to decode court views conditioned on encoded charge labels. Experimental results show the effectiveness of our <a href=https://en.wikipedia.org/wiki/Methodology>method</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1169.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1169 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1169 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1169.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277673818 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1169" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1169/>Delete, Retrieve, Generate : a Simple Approach to Sentiment and Style Transfer</a></strong><br><a href=/people/j/juncen-li/>Juncen Li</a>
|
<a href=/people/r/robin-jia/>Robin Jia</a>
|
<a href=/people/h/he-he/>He He</a>
|
<a href=/people/p/percy-liang/>Percy Liang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1169><div class="card-body p-3 small">We consider the task of text attribute transfer : transforming a sentence to alter a specific attribute (e.g., sentiment) while preserving its <a href=https://en.wikipedia.org/wiki/Content_(media)>attribute-independent content</a> (e.g., screen is just the right size to screen is too small). Our training data includes only sentences labeled with their attribute (e.g., positive and negative), but not pairs of sentences that only differ in the attributes, so we must learn to disentangle <a href=https://en.wikipedia.org/wiki/Attribute_(computing)>attributes</a> from attribute-independent content in an unsupervised way. Previous work using <a href=https://en.wikipedia.org/wiki/Adversarial_system>adversarial methods</a> has struggled to produce high-quality outputs. In this paper, we propose simpler <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> motivated by the observation that <a href=https://en.wikipedia.org/wiki/Attribute_(computing)>text attributes</a> are often marked by distinctive phrases (e.g., too small). Our strongest method extracts content words by deleting phrases associated with the sentence&#8217;s original attribute value, retrieves new phrases associated with the target attribute, and uses a neural model to fluently combine these into a final output. Based on human evaluation, our best method generates grammatical and appropriate responses on 22 % more inputs than the best previous system, averaged over three attribute transfer datasets : altering sentiment of reviews on <a href=https://en.wikipedia.org/wiki/Yelp>Yelp</a>, altering sentiment of reviews on <a href=https://en.wikipedia.org/wiki/Amazon_(company)>Amazon</a>, and altering image captions to be more romantic or humorous.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1170.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1170 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1170 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277673796 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1170" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1170/>Adversarial Example Generation with Syntactically Controlled Paraphrase Networks</a></strong><br><a href=/people/m/mohit-iyyer/>Mohit Iyyer</a>
|
<a href=/people/j/john-wieting/>John Wieting</a>
|
<a href=/people/k/kevin-gimpel/>Kevin Gimpel</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1170><div class="card-body p-3 small">We propose syntactically controlled paraphrase networks (SCPNs) and use them to generate adversarial examples. Given a sentence and a target <a href=https://en.wikipedia.org/wiki/Syntax_(programming_languages)>syntactic form</a> (e.g., a <a href=https://en.wikipedia.org/wiki/Constituent_(linguistics)>constituency parse</a>), SCPNs are trained to produce a <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrase</a> of the sentence with the desired <a href=https://en.wikipedia.org/wiki/Syntax_(programming_languages)>syntax</a>. We show it is possible to create <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training data</a> for this task by first doing backtranslation at a very large scale, and then using a <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> to label the syntactic transformations that naturally occur during this process. Such data allows us to train a neural encoder-decoder model with extra inputs to specify the target syntax. A combination of automated and human evaluations show that SCPNs generate <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrases</a> that follow their target specifications without decreasing paraphrase quality when compared to baseline (uncontrolled) paraphrase systems. Furthermore, they are more capable of generating syntactically adversarial examples that both (1) fool pretrained models and (2) improve the robustness of these models to syntactic variation when used to augment their training data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1173.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1173 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1173 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277671439 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1173" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1173/>Word Emotion Induction for Multiple Languages as a Deep Multi-Task Learning Problem</a></strong><br><a href=/people/s/sven-buechel/>Sven Buechel</a>
|
<a href=/people/u/udo-hahn/>Udo Hahn</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1173><div class="card-body p-3 small">Predicting the emotional value of lexical items is a well-known problem in <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>. While research has focused on polarity for quite a long time, meanwhile this early focus has been shifted to more expressive emotion representation models (such as Basic Emotions or Valence-Arousal-Dominance). This change resulted in a proliferation of heterogeneous formats and, in parallel, often small-sized, non-interoperable resources (lexicons and corpus annotations). In particular, the limitations in size hampered the application of deep learning methods in this area because they typically require large amounts of input data. We here present a solution to get around this language data bottleneck by rephrasing word emotion induction as a multi-task learning problem. In this approach, the prediction of each independent emotion dimension is considered as an individual task and hidden layers are shared between these dimensions. We investigate whether <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a> is more advantageous than single-task learning for emotion prediction by comparing our model against a wide range of alternative emotion and polarity induction methods featuring 9 typologically diverse languages and a total of 15 conditions. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> turns out to outperform each one of them. Against all odds, the proposed deep learning approach yields the largest gain on the smallest data sets, merely composed of one thousand samples.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1174.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1174 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1174 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277671591 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1174/>Human Needs Categorization of Affective Events Using Labeled and Unlabeled Data</a></strong><br><a href=/people/h/haibo-ding/>Haibo Ding</a>
|
<a href=/people/e/ellen-riloff/>Ellen Riloff</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1174><div class="card-body p-3 small">We often talk about events that impact us positively or negatively. For example I got a job is good news, but I lost my job is bad news. When we discuss an event, we not only understand its <a href=https://en.wikipedia.org/wiki/Affect_(psychology)>affective polarity</a> but also the reason why the event is beneficial or detrimental. For example, getting or losing a job has affective polarity primarily because it impacts us financially. Our work aims to categorize affective events based upon human need categories that often explain people&#8217;s motivations and desires : PHYSIOLOGICAL, HEALTH, LEISURE, SOCIAL, FINANCIAL, COGNITION, and FREEDOM. We create classification models based on event expressions as well as <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that use contexts surrounding event mentions. We also design a co-training model that learns from unlabeled data by simultaneously training event expression and event context classifiers in an iterative learning process. Our results show that <a href=https://en.wikipedia.org/wiki/Co-training>co-training</a> performs well, producing substantially better results than the individual <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1176.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1176 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1176 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277672970 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1176/>Linguistic Cues to Deception and Perceived Deception in Interview Dialogues</a></strong><br><a href=/people/s/sarah-ita-levitan/>Sarah Ita Levitan</a>
|
<a href=/people/a/angel-maredia/>Angel Maredia</a>
|
<a href=/people/j/julia-hirschberg/>Julia Hirschberg</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1176><div class="card-body p-3 small">We explore deception detection in interview dialogues. We analyze a set of <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>linguistic features</a> in both truthful and deceptive responses to interview questions. We also study the perception of deception, identifying characteristics of statements that are perceived as truthful or deceptive by interviewers. Our analysis show significant differences between truthful and deceptive question responses, as well as variations in deception patterns across gender and native language. This analysis motivated our selection of <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> for <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning</a> experiments aimed at classifying globally deceptive speech. Our best <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> performance is 72.74 % F1-Score (about 17 % better than human performance), which is achieved using a combination of <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>linguistic features</a> and <a href=https://en.wikipedia.org/wiki/Phenotypic_trait>individual traits</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1177.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1177 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1177 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277672896 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1177" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1177/>Unified Pragmatic Models for Generating and Following Instructions</a></strong><br><a href=/people/d/daniel-fried/>Daniel Fried</a>
|
<a href=/people/j/jacob-andreas/>Jacob Andreas</a>
|
<a href=/people/d/dan-klein/>Dan Klein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1177><div class="card-body p-3 small">We show that explicit pragmatic inference aids in correctly generating and following <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language instructions</a> for complex, sequential tasks. Our pragmatics-enabled models reason about why speakers produce certain instructions, and about how listeners will react upon hearing them. Like previous pragmatic models, we use learned base listener and speaker models to build a pragmatic speaker that uses the base listener to simulate the interpretation of candidate descriptions, and a pragmatic listener that reasons counterfactually about alternative descriptions. We extend these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> to tasks with <a href=https://en.wikipedia.org/wiki/Sequential_analysis>sequential structure</a>. Evaluation of <a href=https://en.wikipedia.org/wiki/Language_generation>language generation</a> and <a href=https://en.wikipedia.org/wiki/Language_interpretation>interpretation</a> shows that pragmatic inference improves state-of-the-art listener models (at correctly interpreting human instructions) and speaker models (at producing instructions correctly interpreted by humans) in diverse settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1178.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1178 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1178 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277672945 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1178/>Hierarchical Structured Model for Fine-to-Coarse Manifesto Text Analysis</a></strong><br><a href=/people/s/shivashankar-subramanian/>Shivashankar Subramanian</a>
|
<a href=/people/t/trevor-cohn/>Trevor Cohn</a>
|
<a href=/people/t/timothy-baldwin/>Timothy Baldwin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1178><div class="card-body p-3 small">Election manifestos document the intentions, motives, and views of political parties. They are often used for analysing a party&#8217;s fine-grained position on a particular issue, as well as for coarse-grained positioning of a party on the leftright spectrum. In this paper we propose a two-stage model for automatically performing both levels of analysis over <a href=https://en.wikipedia.org/wiki/Manifesto>manifestos</a>. In the first step we employ a hierarchical multi-task structured deep model to predict fine- and coarse-grained positions, and in the second step we perform post-hoc calibration of coarse-grained positions using probabilistic soft logic. We empirically show that the proposed model outperforms state-of-art approaches at both granularities using manifestos from twelve countries, written in ten different languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1179.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1179 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1179 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1179.Datasets.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file-archive"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277673944 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1179/>Behavior Analysis of NLI Models : Uncovering the Influence of Three Factors on Robustness<span class=acl-fixed-case>NLI</span> Models: Uncovering the Influence of Three Factors on Robustness</a></strong><br><a href=/people/i/ivan-sanchez/>Ivan Sanchez</a>
|
<a href=/people/j/jeff-mitchell/>Jeff Mitchell</a>
|
<a href=/people/s/sebastian-riedel/>Sebastian Riedel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1179><div class="card-body p-3 small">Natural Language Inference is a challenging task that has received substantial attention, and state-of-the-art models now achieve impressive test set performance in the form of accuracy scores. Here, we go beyond this single evaluation metric to examine <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> to semantically-valid alterations to the input data. We identify three factors-insensitivity, polarity and unseen pairs-and compare their impact on three SNLI models under a variety of conditions. Our results demonstrate a number of strengths and weaknesses in the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>&#8217; ability to generalise to new in-domain instances. In particular, while strong performance is possible on unseen hypernyms, unseen antonyms are more challenging for all the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. More generally, the models suffer from an insensitivity to certain small but semantically significant alterations, and are also often influenced by simple <a href=https://en.wikipedia.org/wiki/Correlation_and_dependence>statistical correlations</a> between words and training labels. Overall, we show that evaluations of NLI models can benefit from studying the influence of factors intrinsic to the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> or found in the dataset used.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1180.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1180 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1180 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1180/>Assessing Language Proficiency from Eye Movements in Reading</a></strong><br><a href=/people/y/yevgeni-berzak/>Yevgeni Berzak</a>
|
<a href=/people/b/boris-katz/>Boris Katz</a>
|
<a href=/people/r/roger-levy/>Roger Levy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1180><div class="card-body p-3 small">We present a novel approach for determining learners&#8217; second language proficiency which utilizes behavioral traces of eye movements during reading. Our approach provides stand-alone eyetracking based English proficiency scores which reflect the extent to which the learner&#8217;s gaze patterns in reading are similar to those of native English speakers. We show that our <a href=https://en.wikipedia.org/wiki/Test_score>scores</a> correlate strongly with standardized English proficiency tests. We also demonstrate that gaze information can be used to accurately predict the outcomes of such tests. Our approach yields the strongest performance when the test taker is presented with a suite of sentences for which we have eyetracking data from other readers. However, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> remains effective even using <a href=https://en.wikipedia.org/wiki/Eyetracking>eyetracking</a> with sentences for which eye movement data have not been previously collected. By deriving <a href=https://en.wikipedia.org/wiki/Language_proficiency>proficiency</a> as an automatic byproduct of <a href=https://en.wikipedia.org/wiki/Eye_movement>eye movements</a> during ordinary reading, our approach offers a potentially valuable new tool for second language proficiency assessment. More broadly, our results open the door to future methods for inferring reader characteristics from the behavioral traces of reading.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1184.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1184 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1184 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1184/>Unsupervised Induction of Linguistic Categories with Records of Reading, Speaking, and Writing</a></strong><br><a href=/people/m/maria-barrett/>Maria Barrett</a>
|
<a href=/people/a/ana-valeria-gonzalez-garduno/>Ana Valeria González-Garduño</a>
|
<a href=/people/l/lea-frermann/>Lea Frermann</a>
|
<a href=/people/a/anders-sogaard/>Anders Søgaard</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1184><div class="card-body p-3 small">When learning POS taggers and syntactic chunkers for low-resource languages, different resources may be available, and often all we have is a small tag dictionary, motivating type-constrained unsupervised induction. Even small dictionaries can improve the performance of unsupervised induction algorithms. This paper shows that performance can be further improved by including data that is readily available or can be easily obtained for most <a href=https://en.wikipedia.org/wiki/Language>languages</a>, i.e., <a href=https://en.wikipedia.org/wiki/Eye_tracking>eye-tracking</a>, <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech</a>, or <a href=https://en.wikipedia.org/wiki/Keystroke_logging>keystroke logs</a> (or any combination thereof). We project information from all these data sources into shared spaces, in which the union of words is represented. For English unsupervised POS induction, the additional information, which is not required at test time, leads to an average error reduction on Ontonotes domains of 1.5 % over systems augmented with state-of-the-art <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a>. On <a href=https://en.wikipedia.org/wiki/Penn_Treebank>Penn Treebank</a> the best <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves 5.4 % <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error reduction</a> over a word embeddings baseline. We also achieve significant improvements for syntactic chunk induction. Our analysis shows that improvements are even bigger when the available tag dictionaries are smaller.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1185.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1185 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1185 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1185/>Challenging Reading Comprehension on Daily Conversation : Passage Completion on Multiparty Dialog</a></strong><br><a href=/people/k/kaixin-ma/>Kaixin Ma</a>
|
<a href=/people/t/tomasz-jurczyk/>Tomasz Jurczyk</a>
|
<a href=/people/j/jinho-d-choi/>Jinho D. Choi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1185><div class="card-body p-3 small">This paper presents a new <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> and a robust deep learning architecture for a task in <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a>, passage completion, on multiparty dialog. Given a dialog in text and a passage containing factual descriptions about the dialog where mentions of the characters are replaced by blanks, the task is to fill the blanks with the most appropriate character names that reflect the contexts in the dialog. Since there is no dataset that challenges the task of passage completion in this <a href=https://en.wikipedia.org/wiki/Genre>genre</a>, we create a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> by selecting transcripts from a <a href=https://en.wikipedia.org/wiki/Television_show>TV show</a> that comprise 1,681 dialogs, generating passages for each dialog through <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing</a>, and annotating mentions of characters in both the dialog and the passages. Given this dataset, we build a <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural model</a> that integrates rich feature extraction from <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>convolutional neural networks</a> into sequence modeling in <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural networks</a>, optimized by utterance and dialog level attentions. Our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> outperforms the previous state-of-the-art <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> on this task in a different genre using bidirectional LSTM, showing a 13.0+% improvement for longer dialogs. Our analysis shows the effectiveness of the <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanisms</a> and suggests a direction to machine comprehension on multiparty dialog.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1186.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1186 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1186 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1186/>Dialog Generation Using Multi-Turn Reasoning Neural Networks</a></strong><br><a href=/people/x/xianchao-wu/>Xianchao Wu</a>
|
<a href=/people/a/ander-martinez/>Ander Martínez</a>
|
<a href=/people/m/momo-klyen/>Momo Klyen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1186><div class="card-body p-3 small">In this paper, we propose a generalizable dialog generation approach that adapts multi-turn reasoning, one recent advancement in the field of document comprehension, to generate responses (answers) by taking current conversation session context as a document and current query as a question. The major idea is to represent a conversation session into memories upon which attention-based memory reading mechanism can be performed multiple times, so that (1) user&#8217;s query is properly extended by contextual clues and (2) optimal responses are step-by-step generated. Considering that the speakers of one conversation are not limited to be one, we separate the single memory used for document comprehension into different groups for speaker-specific topic and opinion embedding. Namely, we utilize the queries&#8217; memory, the responses&#8217; memory, and their unified memory, following the time sequence of the conversation session. Experiments on Japanese 10-sentence (5-round) conversation modeling show impressive results on how multi-turn reasoning can produce more diverse and acceptable responses than state-of-the-art single-turn and non-reasoning baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1187.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1187 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1187 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1187" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N18-1187/>Dialogue Learning with Human Teaching and Feedback in End-to-End Trainable Task-Oriented Dialogue Systems</a></strong><br><a href=/people/b/bing-liu/>Bing Liu</a>
|
<a href=/people/g/gokhan-tur/>Gokhan Tür</a>
|
<a href=/people/d/dilek-hakkani-tur/>Dilek Hakkani-Tür</a>
|
<a href=/people/p/pararth-shah/>Pararth Shah</a>
|
<a href=/people/l/larry-heck/>Larry Heck</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1187><div class="card-body p-3 small">In this work, we present a hybrid learning method for training task-oriented dialogue systems through online user interactions. Popular methods for learning task-oriented dialogues include applying <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a> with <a href=https://en.wikipedia.org/wiki/User-generated_content>user feedback</a> on supervised pre-training models. Efficiency of such learning method may suffer from the mismatch of dialogue state distribution between offline training and online interactive learning stages. To address this challenge, we propose a hybrid imitation and reinforcement learning method, with which a dialogue agent can effectively learn from its interaction with users by learning from human teaching and feedback. We design a neural network based task-oriented dialogue agent that can be optimized end-to-end with the proposed learning method. Experimental results show that our end-to-end dialogue agent can learn effectively from the mistake it makes via imitation learning from user teaching. Applying <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a> with user feedback after the imitation learning stage further improves the <a href=https://en.wikipedia.org/wiki/Intelligent_agent>agent</a>&#8217;s capability in successfully completing a task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1188.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1188 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1188 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1188.Datasets.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file-archive"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1188.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1188/>LSDSCC : a Large Scale Domain-Specific Conversational Corpus for Response Generation with Diversity Oriented Evaluation Metrics<span class=acl-fixed-case>LSDSCC</span>: a Large Scale Domain-Specific Conversational Corpus for Response Generation with Diversity Oriented Evaluation Metrics</a></strong><br><a href=/people/z/zhen-xu/>Zhen Xu</a>
|
<a href=/people/n/nan-jiang/>Nan Jiang</a>
|
<a href=/people/b/bingquan-liu/>Bingquan Liu</a>
|
<a href=/people/w/wenge-rong/>Wenge Rong</a>
|
<a href=/people/b/bowen-wu/>Bowen Wu</a>
|
<a href=/people/b/baoxun-wang/>Baoxun Wang</a>
|
<a href=/people/z/zhuoran-wang/>Zhuoran Wang</a>
|
<a href=/people/x/xiaolong-wang/>Xiaolong Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1188><div class="card-body p-3 small">It has been proven that automatic conversational agents can be built up using the Endto-End Neural Response Generation (NRG) framework, and such a data-driven methodology requires a large number of dialog pairs for model training and reasonable evaluation metrics for testing. This paper proposes a Large Scale Domain-Specific Conversational Corpus (LSDSCC) composed of high-quality queryresponse pairs extracted from the domainspecific online forum, with thorough preprocessing and cleansing procedures. Also, a <a href=https://en.wikipedia.org/wiki/Test_set>testing set</a>, including multiple diverse responses annotated for each query, is constructed, and on this basis, the <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> for measuring the diversity of generated results are further presented. We evaluate the performances of neural dialog models with the widely applied diversity boosting strategies on the proposed <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. The experimental results have shown that our proposed <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> can be taken as a new benchmark dataset for the NRG task, and the presented metrics are promising to guide the optimization of NRG models by quantifying the diversity of the generated responses reasonably.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1191.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1191 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1191 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1191/>Mining Evidences for Concept Stock Recommendation</a></strong><br><a href=/people/q/qi-liu/>Qi Liu</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1191><div class="card-body p-3 small">We investigate the task of mining relevant stocks given a topic of concern on <a href=https://en.wikipedia.org/wiki/Emerging_market>emerging capital markets</a>, for which there is lack of <a href=https://en.wikipedia.org/wiki/Structural_analysis>structural understanding</a>. Deep learning is leveraged to mine evidences from large scale textual data, which contain valuable market information. In particular, distributed word similarities trained over large scale raw texts are taken as a basis of relevance measuring, and deep reinforcement learning is leveraged to learn a strategy of topic expansion, given a small amount of manually labeled data from financial analysts. Results on two Chinese stock market datasets show that our method outperforms a strong <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> using <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval techniques</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1192.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1192 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1192 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1192/>Binarized LSTM Language Model<span class=acl-fixed-case>LSTM</span> Language Model</a></strong><br><a href=/people/x/xuan-liu/>Xuan Liu</a>
|
<a href=/people/d/di-cao/>Di Cao</a>
|
<a href=/people/k/kai-yu/>Kai Yu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1192><div class="card-body p-3 small">Long short-term memory (LSTM) language model (LM) has been widely investigated for <a href=https://en.wikipedia.org/wiki/Speech_recognition>automatic speech recognition (ASR)</a> and <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP)</a>. Although excellent performance is obtained for large vocabulary tasks, tremendous <a href=https://en.wikipedia.org/wiki/Computer_memory>memory consumption</a> prohibits the use of LSTM LM in low-resource devices. The memory consumption mainly comes from the word embedding layer. In this paper, a novel binarized LSTM LM is proposed to address the problem. Words are encoded into binary vectors and other LSTM parameters are further binarized to achieve high <a href=https://en.wikipedia.org/wiki/Data_compression>memory compression</a>. This is the first effort to investigate binary LSTM for large vocabulary LM. Experiments on both English and Chinese LM and ASR tasks showed that can achieve a <a href=https://en.wikipedia.org/wiki/Compression_ratio>compression ratio</a> of 11.3 without any loss of <a href=https://en.wikipedia.org/wiki/Line_level>LM</a> and ASR performances and a <a href=https://en.wikipedia.org/wiki/Compression_ratio>compression ratio</a> of 31.6 with acceptable minor performance degradation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1194.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1194 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1194 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1194/>How Time Matters : Learning Time-Decay Attention for Contextual Spoken Language Understanding in Dialogues</a></strong><br><a href=/people/s/shang-yu-su/>Shang-Yu Su</a>
|
<a href=/people/p/pei-chieh-yuan/>Pei-Chieh Yuan</a>
|
<a href=/people/y/yun-nung-chen/>Yun-Nung Chen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1194><div class="card-body p-3 small">Spoken language understanding (SLU) is an essential component in <a href=https://en.wikipedia.org/wiki/Interpersonal_communication>conversational systems</a>. Most SLU components treats each utterance independently, and then the following <a href=https://en.wikipedia.org/wiki/Component-based_software_engineering>components</a> aggregate the multi-turn information in the separate phases. In order to avoid <a href=https://en.wikipedia.org/wiki/Error_propagation>error propagation</a> and effectively utilize <a href=https://en.wikipedia.org/wiki/Context_(language_use)>contexts</a>, prior work leveraged <a href=https://en.wikipedia.org/wiki/History>history</a> for contextual SLU. However, most previous <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> only paid attention to the related content in history utterances, ignoring their temporal information. In the dialogues, it is intuitive that the most recent utterances are more important than the least recent ones, in other words, time-aware attention should be in a decaying manner. Therefore, this paper designs and investigates various types of time-decay attention on the sentence-level and speaker-level, and further proposes a flexible universal time-decay attention mechanism. The experiments on the benchmark Dialogue State Tracking Challenge (DSTC4) dataset show that the proposed time-decay attention mechanisms significantly improve the <a href=https://en.wikipedia.org/wiki/State-of-the-art>state-of-the-art model</a> for contextual understanding performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1195.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1195 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1195 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1195/>Towards Understanding Text Factors in Oral Reading</a></strong><br><a href=/people/a/anastassia-loukina/>Anastassia Loukina</a>
|
<a href=/people/v/van-rynald-t-liceralde/>Van Rynald T. Liceralde</a>
|
<a href=/people/b/beata-beigman-klebanov/>Beata Beigman Klebanov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1195><div class="card-body p-3 small">Using a case study, we show that variation in oral reading rate across passages for professional narrators is consistent across readers and much of it can be explained using features of the texts being read. While text complexity is a poor predictor of the <a href=https://en.wikipedia.org/wiki/Reading_rate>reading rate</a>, a substantial share of variability can be explained by timing and story-based factors with performance reaching r=0.75 for unseen passages and narrator.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1198.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1198 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1198 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-1198/>Object Counts ! Bringing Explicit Detections Back into Image Captioning</a></strong><br><a href=/people/j/josiah-wang/>Josiah Wang</a>
|
<a href=/people/p/pranava-swaroop-madhyastha/>Pranava Swaroop Madhyastha</a>
|
<a href=/people/l/lucia-specia/>Lucia Specia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1198><div class="card-body p-3 small">The use of explicit object detectors as an intermediate step to image captioning which used to constitute an essential stage in early work is often bypassed in the currently dominant end-to-end approaches, where the <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> is conditioned directly on a mid-level image embedding. We argue that explicit detections provide rich semantic information, and can thus be used as an interpretable representation to better understand why end-to-end image captioning systems work well. We provide an in-depth analysis of end-to-end image captioning by exploring a variety of cues that can be derived from such object detections. Our study reveals that end-to-end image captioning systems rely on matching image representations to generate captions, and that encoding the frequency, size and position of objects are complementary and all play a role in forming a good image representation. It also reveals that different <a href=https://en.wikipedia.org/wiki/Object_(philosophy)>object categories</a> contribute in different ways towards image captioning.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1203.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1203 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1203 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/N18-1203.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277672864 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N18-1203" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1203/>Learning to Map Context-Dependent Sentences to Executable Formal Queries</a></strong><br><a href=/people/a/alane-suhr/>Alane Suhr</a>
|
<a href=/people/s/srinivasan-iyer/>Srinivasan Iyer</a>
|
<a href=/people/y/yoav-artzi/>Yoav Artzi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1203><div class="card-body p-3 small">We propose a context-dependent model to map utterances within an interaction to executable formal queries. To incorporate interaction history, the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> maintains an interaction-level encoder that updates after each turn, and can copy sub-sequences of previously predicted queries during generation. Our approach combines implicit and explicit modeling of references between utterances. We evaluate our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on the ATIS flight planning interactions, and demonstrate the benefits of modeling context and explicit references.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-1204.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-1204 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-1204 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277672801 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-1204/>Neural Text Generation in Stories Using Entity Representations as Context</a></strong><br><a href=/people/e/elizabeth-clark/>Elizabeth Clark</a>
|
<a href=/people/y/yangfeng-ji/>Yangfeng Ji</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-1204><div class="card-body p-3 small">We introduce an approach to neural text generation that explicitly represents entities mentioned in the text. Entity representations are vectors that are updated as the text proceeds ; they are designed specifically for narrative text like <a href=https://en.wikipedia.org/wiki/Fiction>fiction</a> or <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news stories</a>. Our experiments demonstrate that modeling entities offers a benefit in two automatic evaluations : mention generation (in which a model chooses which entity to mention next and which words to use in the mention) and selection between a correct next sentence and a distractor from later in the same story. We also conduct a human evaluation on automatically generated text in story contexts ; this study supports our emphasis on <a href=https://en.wikipedia.org/wiki/Non-physical_entity>entities</a> and suggests directions for further research.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>