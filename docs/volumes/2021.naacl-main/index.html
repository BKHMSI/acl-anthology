<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/2021.naacl-main.pdf>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></h2><p class=lead><a href=/people/k/kristina-toutanova/>Kristina Toutanova</a>,
<a href=/people/a/anna-rumshisky/>Anna Rumshisky</a>,
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a>,
<a href=/people/d/dilek-hakkani-tur/>Dilek Hakkani-Tur</a>,
<a href=/people/i/iz-beltagy/>Iz Beltagy</a>,
<a href=/people/s/steven-bethard/>Steven Bethard</a>,
<a href=/people/r/ryan-cotterell/>Ryan Cotterell</a>,
<a href=/people/t/tanmoy-chakraborty/>Tanmoy Chakraborty</a>,
<a href=/people/y/yichao-zhou/>Yichao Zhou</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2021.naacl-main</dd><dt>Month:</dt><dd>June</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Online</dd><dt>Venue:</dt><dd><a href=/venues/naacl/>NAACL</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.naacl-main>https://aclanthology.org/2021.naacl-main</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2021.naacl-main.pdf>https://aclanthology.org/2021.naacl-main.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2021.naacl-main.pdf title="Open PDF of 'Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+2021+Conference+of+the+North+American+Chapter+of+the+Association+for+Computational+Linguistics%3A+Human+Language+Technologies" title="Search for 'Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.0/>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</a></strong><br><a href=/people/k/kristina-toutanova/>Kristina Toutanova</a>
|
<a href=/people/a/anna-rumshisky/>Anna Rumshisky</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a>
|
<a href=/people/d/dilek-hakkani-tur/>Dilek Hakkani-Tur</a>
|
<a href=/people/i/iz-beltagy/>Iz Beltagy</a>
|
<a href=/people/s/steven-bethard/>Steven Bethard</a>
|
<a href=/people/r/ryan-cotterell/>Ryan Cotterell</a>
|
<a href=/people/t/tanmoy-chakraborty/>Tanmoy Chakraborty</a>
|
<a href=/people/y/yichao-zhou/>Yichao Zhou</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.1/>Knowledge Router : Learning Disentangled Representations for Knowledge Graphs</a></strong><br><a href=/people/s/shuai-zhang/>Shuai Zhang</a>
|
<a href=/people/x/xi-rao/>Xi Rao</a>
|
<a href=/people/y/yi-tay/>Yi Tay</a>
|
<a href=/people/c/ce-zhang/>Ce Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--1><div class="card-body p-3 small">The design of expressive representations of entities and relations in a <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graph</a> is an important endeavor. While many of the existing approaches have primarily focused on learning from relational patterns and structural information, the intrinsic <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a> of KG entities has been more or less overlooked. More concretely, we hypothesize KG entities may be more complex than we think, i.e., an entity may wear many hats and relational triplets may form due to more than a single reason. To this end, this paper proposes to learn disentangled representations of KG entities-a new method that disentangles the inner latent properties of KG entities. Our disentangled process operates at the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph level</a> and a neighborhood mechanism is leveraged to disentangle the hidden properties of each entity. This disentangled representation learning approach is model agnostic and compatible with canonical KG embedding approaches. We conduct extensive experiments on several benchmark datasets, equipping a variety of models (DistMult, SimplE, and QuatE) with our proposed disentangling mechanism. Experimental results demonstrate that our proposed approach substantially improves performance on key metrics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.3/>Cross-Task Instance Representation Interactions and Label Dependencies for Joint Information Extraction with Graph Convolutional Networks</a></strong><br><a href=/people/m/minh-van-nguyen/>Minh Van Nguyen</a>
|
<a href=/people/v/viet-lai/>Viet Lai</a>
|
<a href=/people/t/thien-huu-nguyen/>Thien Huu Nguyen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--3><div class="card-body p-3 small">Existing works on information extraction (IE) have mainly solved the four main tasks separately (entity mention recognition, relation extraction, event trigger detection, and argument extraction), thus failing to benefit from inter-dependencies between tasks. This paper presents a novel deep learning model to simultaneously solve the four tasks of IE in a single <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> (called FourIE). Compared to few prior work on jointly performing four IE tasks, FourIE features two novel contributions to capture inter-dependencies between tasks. First, at the representation level, we introduce an interaction graph between instances of the four <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> that is used to enrich the prediction representation for one instance with those from related instances of other tasks. Second, at the label level, we propose a <a href=https://en.wikipedia.org/wiki/Dependency_graph>dependency graph</a> for the information types in the four IE tasks that captures the connections between the types expressed in an input sentence. A new <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularization mechanism</a> is introduced to enforce the consistency between the golden and predicted type dependency graphs to improve <a href=https://en.wikipedia.org/wiki/Representation_learning>representation learning</a>. We show that the proposed model achieves the state-of-the-art performance for joint IE on both monolingual and multilingual learning settings with three different languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.10" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.10/>Multilingual Language Models Predict Human Reading Behavior</a></strong><br><a href=/people/n/nora-hollenstein/>Nora Hollenstein</a>
|
<a href=/people/f/federico-pirovano/>Federico Pirovano</a>
|
<a href=/people/c/ce-zhang/>Ce Zhang</a>
|
<a href=/people/l/lena-jager/>Lena Jäger</a>
|
<a href=/people/l/lisa-beinborn/>Lisa Beinborn</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--10><div class="card-body p-3 small">We analyze if large language models are able to predict patterns of human reading behavior. We compare the performance of language-specific and multilingual pretrained transformer models to predict reading time measures reflecting natural human sentence processing on <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch</a>, <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/German_language>German</a>, and Russian texts. This results in accurate <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> of human reading behavior, which indicates that transformer models implicitly encode relative importance in language in a way that is comparable to human processing mechanisms. We find that BERT and XLM models successfully predict a range of eye tracking features. In a series of experiments, we analyze the cross-domain and cross-language abilities of these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> and show how they reflect human sentence processing.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.12/>A Non-Linear Structural Probe</a></strong><br><a href=/people/j/jennifer-c-white/>Jennifer C. White</a>
|
<a href=/people/t/tiago-pimentel/>Tiago Pimentel</a>
|
<a href=/people/n/naomi-saphra/>Naomi Saphra</a>
|
<a href=/people/r/ryan-cotterell/>Ryan Cotterell</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--12><div class="card-body p-3 small">Probes are models devised to investigate the encoding of knowledgee.g. syntactic structurein <a href=https://en.wikipedia.org/wiki/Context_(language_use)>contextual representations</a>. Probes are often designed for simplicity, which has led to restrictions on probe design that may not allow for the full exploitation of the structure of encoded information ; one such restriction is <a href=https://en.wikipedia.org/wiki/Linearity>linearity</a>. We examine the case of a structural probe (Hewitt and Manning, 2019), which aims to investigate the encoding of syntactic structure in contextual representations through learning only <a href=https://en.wikipedia.org/wiki/Linear_map>linear transformations</a>. By observing that the structural probe learns a <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a>, we are able to kernelize it and develop a novel non-linear variant with an identical number of parameters. We test on 6 languages and find that the radial-basis function (RBF) kernel, in conjunction with <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularization</a>, achieves a statistically significant improvement over the baseline in all languagesimplying that at least part of the syntactic knowledge is encoded non-linearly. We conclude by discussing how the RBF kernel resembles BERT&#8217;s self-attention layers and speculate that this resemblance leads to the RBF-based probe&#8217;s stronger performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.13/>Concealed Data Poisoning Attacks on <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP Models</a><span class=acl-fixed-case>NLP</span> Models</a></strong><br><a href=/people/e/eric-wallace/>Eric Wallace</a>
|
<a href=/people/t/tony-zhao/>Tony Zhao</a>
|
<a href=/people/s/shi-feng/>Shi Feng</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--13><div class="card-body p-3 small">Adversarial attacks alter NLP model predictions by perturbing test-time inputs. However, it is much less understood whether, and how, predictions can be manipulated with small, concealed changes to the training data. In this work, we develop a new data poisoning attack that allows an adversary to control model predictions whenever a desired trigger phrase is present in the input. For instance, we insert 50 poison examples into a sentiment model&#8217;s training set that causes the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> to frequently predict Positive whenever the input contains James Bond. Crucially, we craft these poison examples using a gradient-based procedure so that they do not mention the trigger phrase. We also apply our poison attack to <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a> (Apple iPhone triggers negative generations) and <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> (iced coffee mistranslated as hot coffee). We conclude by proposing three defenses that can mitigate our <a href=https://en.wikipedia.org/wiki/Cyberattack>attack</a> at some cost in prediction accuracy or extra human annotation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.naacl-main.14.OptionalSupplementaryCode.zip data-toggle=tooltip data-placement=top title="Optional supplementary code"><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.14" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.14/>Backtranslation Feedback Improves User Confidence in MT, Not Quality<span class=acl-fixed-case>MT</span>, Not Quality</a></strong><br><a href=/people/v/vilem-zouhar/>Vilém Zouhar</a>
|
<a href=/people/m/michal-novak/>Michal Novák</a>
|
<a href=/people/m/matus-zilinec/>Matúš Žilinec</a>
|
<a href=/people/o/ondrej-bojar/>Ondřej Bojar</a>
|
<a href=/people/m/mateo-obregon/>Mateo Obregón</a>
|
<a href=/people/r/robin-l-hill/>Robin L. Hill</a>
|
<a href=/people/f/frederic-blain/>Frédéric Blain</a>
|
<a href=/people/m/marina-fomicheva/>Marina Fomicheva</a>
|
<a href=/people/l/lucia-specia/>Lucia Specia</a>
|
<a href=/people/l/lisa-yankovskaya/>Lisa Yankovskaya</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--14><div class="card-body p-3 small">Translating text into a language unknown to the text&#8217;s author, dubbed outbound translation, is a modern need for which the user experience has significant room for improvement, beyond the basic machine translation facility. We demonstrate this by showing three ways in which user confidence in the outbound translation, as well as its overall final quality, can be affected : backward translation, quality estimation (with alignment) and source paraphrasing. In this paper, we describe an experiment on outbound translation from <a href=https://en.wikipedia.org/wiki/English_language>English</a> to <a href=https://en.wikipedia.org/wiki/Czech_language>Czech</a> and <a href=https://en.wikipedia.org/wiki/Estonian_language>Estonian</a>. We examine the effects of each proposed feedback module and further focus on how the quality of machine translation systems influence these findings and the user perception of success. We show that backward translation feedback has a mixed effect on the whole process : it increases user confidence in the produced translation, but not the objective quality.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.17" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.17/>Neural Machine Translation without Embeddings</a></strong><br><a href=/people/u/uri-shaham/>Uri Shaham</a>
|
<a href=/people/o/omer-levy/>Omer Levy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--17><div class="card-body p-3 small">Many NLP models operate over sequences of subword tokens produced by hand-crafted tokenization rules and heuristic subword induction algorithms. A simple universal alternative is to represent every computerized text as a sequence of bytes via <a href=https://en.wikipedia.org/wiki/UTF-8>UTF-8</a>, obviating the need for an embedding layer since there are fewer token types (256) than dimensions. Surprisingly, replacing the ubiquitous embedding layer with one-hot representations of each byte does not hurt performance ; experiments on byte-to-byte machine translation from <a href=https://en.wikipedia.org/wiki/English_language>English</a> to 10 different languages show a consistent improvement in BLEU, rivaling character-level and even standard subword-level models. A deeper investigation reveals that the combination of embeddingless models with decoder-input dropout amounts to token dropout, which benefits byte-to-byte models in particular.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.18.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--18 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.18 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.18" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.18/>Counterfactual Data Augmentation for Neural Machine Translation</a></strong><br><a href=/people/q/qi-liu/>Qi Liu</a>
|
<a href=/people/m/matt-kusner/>Matt Kusner</a>
|
<a href=/people/p/phil-blunsom/>Phil Blunsom</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--18><div class="card-body p-3 small">We propose a data augmentation method for <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a>. It works by interpreting <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> and phrasal alignment causally. Specifically, it creates augmented parallel translation corpora by generating (path-specific) counterfactual aligned phrases. We generate these by sampling new source phrases from a masked language model, then sampling an aligned counterfactual target phrase by noting that a translation language model can be interpreted as a Gumbel-Max Structural Causal Model (Oberst and Sontag, 2019). Compared to previous work, our method takes both <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context</a> and <a href=https://en.wikipedia.org/wiki/Sequence_alignment>alignment</a> into account to maintain the <a href=https://en.wikipedia.org/wiki/Symmetry>symmetry</a> between source and target sequences. Experiments on IWSLT&#8217;15 English Vietnamese, WMT&#8217;17 English German, WMT&#8217;18 English Turkish, and WMT&#8217;19 robust English French show that the method can improve the performance of <a href=https://en.wikipedia.org/wiki/Translation>translation</a>, backtranslation and <a href=https://en.wikipedia.org/wiki/Translation>translation robustness</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.25.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--25 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.25 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.25" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.25/>DATE : Detecting Anomalies in Text via Self-Supervision of Transformers<span class=acl-fixed-case>DATE</span>: Detecting Anomalies in Text via Self-Supervision of Transformers</a></strong><br><a href=/people/a/andrei-manolache/>Andrei Manolache</a>
|
<a href=/people/f/florin-brad/>Florin Brad</a>
|
<a href=/people/e/elena-burceanu/>Elena Burceanu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--25><div class="card-body p-3 small">Leveraging <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning models</a> for Anomaly Detection (AD) has seen widespread use in recent years due to superior performances over traditional methods. Recent deep methods for anomalies in images learn better features of normality in an end-to-end self-supervised setting. These methods train a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to discriminate between different <a href=https://en.wikipedia.org/wiki/Transformation_(function)>transformations</a> applied to <a href=https://en.wikipedia.org/wiki/Visual_system>visual data</a> and then use the output to compute an anomaly score. We use this approach for AD in text, by introducing a novel pretext task on text sequences. We learn our DATE model end-to-end, enforcing two independent and complementary self-supervision signals, one at the token-level and one at the sequence-level. Under this new task formulation, we show strong quantitative and qualitative results on the 20Newsgroups and AG News datasets. In the <a href=https://en.wikipedia.org/wiki/Semi-supervised_learning>semi-supervised setting</a>, we outperform state-of-the-art results by +13.5 % and +6.9 %, respectively (AUROC). In the unsupervised configuration, DATE surpasses all other methods even when 10 % of its training data is contaminated with <a href=https://en.wikipedia.org/wiki/Outlier>outliers</a> (compared with 0 % for the others).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.27.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--27 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.27 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.27/>Fast and Scalable Dialogue State Tracking with Explicit Modular Decomposition</a></strong><br><a href=/people/d/dingmin-wang/>Dingmin Wang</a>
|
<a href=/people/c/chenghua-lin/>Chenghua Lin</a>
|
<a href=/people/q/qi-liu/>Qi Liu</a>
|
<a href=/people/k/kam-fai-wong/>Kam-Fai Wong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--27><div class="card-body p-3 small">We present a fast and scalable architecture called Explicit Modular Decomposition (EMD), in which we incorporate both classification-based and extraction-based methods and design four modules (for clas- sification and sequence labelling) to jointly extract dialogue states. Experimental results based on the MultiWoz 2.0 dataset validates the superiority of our proposed model in terms of both <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a> and <a href=https://en.wikipedia.org/wiki/Scalability>scalability</a> when compared to the state-of-the-art methods, especially in the scenario of multi-domain dialogues entangled with many turns of utterances.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.28.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--28 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.28 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.28" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.28/>Augmented SBERT : Data Augmentation Method for Improving Bi-Encoders for Pairwise Sentence Scoring Tasks<span class=acl-fixed-case>SBERT</span>: Data Augmentation Method for Improving Bi-Encoders for Pairwise Sentence Scoring Tasks</a></strong><br><a href=/people/n/nandan-thakur/>Nandan Thakur</a>
|
<a href=/people/n/nils-reimers/>Nils Reimers</a>
|
<a href=/people/j/johannes-daxenberger/>Johannes Daxenberger</a>
|
<a href=/people/i/iryna-gurevych/>Iryna Gurevych</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--28><div class="card-body p-3 small">There are two approaches for pairwise sentence scoring : Cross-encoders, which perform full-attention over the input pair, and Bi-encoders, which map each input independently to a dense vector space. While cross-encoders often achieve higher performance, they are too slow for many practical use cases. Bi-encoders, on the other hand, require substantial training data and <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> over the target task to achieve competitive performance. We present a simple yet efficient data augmentation strategy called Augmented SBERT, where we use the cross-encoder to label a larger set of input pairs to augment the training data for the bi-encoder. We show that, in this process, selecting the sentence pairs is non-trivial and crucial for the success of the method. We evaluate our approach on multiple tasks (in-domain) as well as on a domain adaptation task. Augmented SBERT achieves an improvement of up to 6 points for in-domain and of up to 37 points for domain adaptation tasks compared to the original bi-encoder performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.30.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--30 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.30 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.30/>SGL : Speaking the Graph Languages of Semantic Parsing via Multilingual Translation<span class=acl-fixed-case>SGL</span>: Speaking the Graph Languages of Semantic Parsing via Multilingual Translation</a></strong><br><a href=/people/l/luigi-procopio/>Luigi Procopio</a>
|
<a href=/people/r/rocco-tripodi/>Rocco Tripodi</a>
|
<a href=/people/r/roberto-navigli/>Roberto Navigli</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--30><div class="card-body p-3 small">Graph-based semantic parsing aims to represent <a href=https://en.wikipedia.org/wiki/Meaning_(linguistics)>textual meaning</a> through <a href=https://en.wikipedia.org/wiki/Directed_graph>directed graphs</a>. As one of the most promising general-purpose meaning representations, these <a href=https://en.wikipedia.org/wiki/Structure_(mathematical_logic)>structures</a> and their parsing have gained a significant interest momentum during recent years, with several diverse formalisms being proposed. Yet, owing to this very heterogeneity, most of the research effort has focused mainly on solutions specific to a given <a href=https://en.wikipedia.org/wiki/Formalism_(philosophy_of_mathematics)>formalism</a>. In this work, instead, we reframe semantic parsing towards multiple formalisms as Multilingual Neural Machine Translation (MNMT), and propose SGL, a many-to-many seq2seq architecture trained with an MNMT objective. Backed by several experiments, we show that this framework is indeed effective once the learning procedure is enhanced with large parallel corpora coming from <a href=https://en.wikipedia.org/wiki/Machine_translation>Machine Translation</a> : we report competitive performances on AMR and UCCA parsing, especially once paired with pre-trained architectures. Furthermore, we find that models trained under this configuration scale remarkably well to tasks such as cross-lingual AMR parsing : SGL outperforms all its competitors by a large margin without even explicitly seeing non-English to AMR examples at training time and, once these examples are included as well, sets an unprecedented state of the art in this task. We release our code and our models for research purposes at https://github.com/SapienzaNLP/sgl.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.33.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--33 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.33 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.33/>Meta-Learning for Domain Generalization in Semantic Parsing</a></strong><br><a href=/people/b/bailin-wang/>Bailin Wang</a>
|
<a href=/people/m/mirella-lapata/>Mirella Lapata</a>
|
<a href=/people/i/ivan-titov/>Ivan Titov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--33><div class="card-body p-3 small">The importance of building semantic parsers which can be applied to new domains and generate programs unseen at training has long been acknowledged, and datasets testing out-of-domain performance are becoming increasingly available. However, little or no attention has been devoted to learning algorithms or objectives which promote domain generalization, with virtually all existing approaches relying on standard <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised learning</a>. In this work, we use a meta-learning framework which targets zero-shot domain generalization for <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a>. We apply a model-agnostic training algorithm that simulates zero-shot parsing by constructing virtual train and test sets from disjoint domains. The learning objective capitalizes on the intuition that gradient steps that improve source-domain performance should also improve target-domain performance, thus encouraging a <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> to generalize to unseen target domains. Experimental results on the (English) Spider and Chinese Spider datasets show that the meta-learning objective significantly boosts the performance of a baseline parser.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.36.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--36 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.36 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.36/>APo-VAE : Text Generation in <a href=https://en.wikipedia.org/wiki/Hyperbolic_space>Hyperbolic Space</a><span class=acl-fixed-case>AP</span>o-<span class=acl-fixed-case>VAE</span>: Text Generation in Hyperbolic Space</a></strong><br><a href=/people/s/shuyang-dai/>Shuyang Dai</a>
|
<a href=/people/z/zhe-gan/>Zhe Gan</a>
|
<a href=/people/y/yu-cheng/>Yu Cheng</a>
|
<a href=/people/c/chenyang-tao/>Chenyang Tao</a>
|
<a href=/people/l/lawrence-carin/>Lawrence Carin</a>
|
<a href=/people/j/jingjing-liu/>Jingjing Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--36><div class="card-body p-3 small">Natural language often exhibits inherent <a href=https://en.wikipedia.org/wiki/Hierarchical_organization>hierarchical structure</a> ingrained with complex syntax and semantics. However, most state-of-the-art <a href=https://en.wikipedia.org/wiki/Deep_learning>deep generative models</a> learn <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> only in <a href=https://en.wikipedia.org/wiki/Euclidean_space>Euclidean vector space</a>, without accounting for this structural property of language. In this paper, we investigate <a href=https://en.wikipedia.org/wiki/Text_generator>text generation</a> in a hyperbolic latent space to learn continuous hierarchical representations. An Adversarial Poincare Variational Autoencoder (APo-VAE) is presented, where both the prior and variational posterior of latent variables are defined over a Poincare ball via wrapped normal distributions. By adopting the primal-dual formulation of <a href=https://en.wikipedia.org/wiki/Kullback&#8211;Leibler_divergence>Kullback-Leibler divergence</a>, an adversarial learning procedure is introduced to empower robust model training. Extensive experiments in language modeling, unaligned style transfer, and dialog-response generation demonstrate the effectiveness of the proposed APo-VAE model over VAEs in Euclidean latent space, thanks to its superb capabilities in capturing latent language hierarchies in hyperbolic space.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.37.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--37 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.37 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.37" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.37/>DART : Open-Domain Structured Data Record to Text Generation<span class=acl-fixed-case>DART</span>: Open-Domain Structured Data Record to Text Generation</a></strong><br><a href=/people/l/linyong-nan/>Linyong Nan</a>
|
<a href=/people/d/dragomir-radev/>Dragomir Radev</a>
|
<a href=/people/r/rui-zhang/>Rui Zhang</a>
|
<a href=/people/a/amrit-rau/>Amrit Rau</a>
|
<a href=/people/a/abhinand-sivaprasad/>Abhinand Sivaprasad</a>
|
<a href=/people/c/chiachun-hsieh/>Chiachun Hsieh</a>
|
<a href=/people/x/xiangru-tang/>Xiangru Tang</a>
|
<a href=/people/a/aadit-vyas/>Aadit Vyas</a>
|
<a href=/people/n/neha-verma/>Neha Verma</a>
|
<a href=/people/p/pranav-krishna/>Pranav Krishna</a>
|
<a href=/people/y/yangxiaokang-liu/>Yangxiaokang Liu</a>
|
<a href=/people/n/nadia-irwanto/>Nadia Irwanto</a>
|
<a href=/people/j/jessica-pan/>Jessica Pan</a>
|
<a href=/people/f/faiaz-rahman/>Faiaz Rahman</a>
|
<a href=/people/a/ahmad-zaidi/>Ahmad Zaidi</a>
|
<a href=/people/m/mutethia-mutuma/>Mutethia Mutuma</a>
|
<a href=/people/y/yasin-tarabar/>Yasin Tarabar</a>
|
<a href=/people/a/ankit-gupta/>Ankit Gupta</a>
|
<a href=/people/t/tao-yu/>Tao Yu</a>
|
<a href=/people/y/yi-chern-tan/>Yi Chern Tan</a>
|
<a href=/people/x/xi-victoria-lin/>Xi Victoria Lin</a>
|
<a href=/people/c/caiming-xiong/>Caiming Xiong</a>
|
<a href=/people/r/richard-socher/>Richard Socher</a>
|
<a href=/people/n/nazneen-fatema-rajani/>Nazneen Fatema Rajani</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--37><div class="card-body p-3 small">We present DART, an open domain structured DAta Record to Text generation dataset with over 82k instances (DARTs). Data-to-text annotations can be a costly process, especially when dealing with tables which are the major source of structured data and contain nontrivial structures. To this end, we propose a procedure of extracting semantic triples from tables that encodes their structures by exploiting the semantic dependencies among table headers and the table title. Our dataset construction framework effectively merged heterogeneous sources from open domain semantic parsing and spoken dialogue systems by utilizing techniques including tree ontology annotation, question-answer pair to declarative sentence conversion, and predicate unification, all with minimum post-editing. We present systematic evaluation on DART as well as new state-of-the-art results on WebNLG 2017 to show that DART (1) poses new challenges to existing data-to-text datasets and (2) facilitates out-of-domain generalization. Our data and code can be found at https://github.com/Yale-LILY/dart.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.39.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--39 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.39 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.39/>Multi-Adversarial Learning for Cross-Lingual Word Embeddings</a></strong><br><a href=/people/h/haozhou-wang/>Haozhou Wang</a>
|
<a href=/people/j/james-henderson/>James Henderson</a>
|
<a href=/people/p/paola-merlo/>Paola Merlo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--39><div class="card-body p-3 small">Generative adversarial networks (GANs) have succeeded in inducing cross-lingual word embeddings-maps of matching words across languages-without supervision. Despite these successes, <a href=https://en.wikipedia.org/wiki/Grammatical_number>GANs</a>&#8217; performance for the difficult case of distant languages is still not satisfactory. These limitations have been explained by GANs&#8217; incorrect assumption that source and target embedding spaces are related by a single linear mapping and are approximately isomorphic. We assume instead that, especially across distant languages, the <a href=https://en.wikipedia.org/wiki/Map_(mathematics)>mapping</a> is only piece-wise linear, and propose a multi-adversarial learning method. This novel method induces the seed cross-lingual dictionary through multiple <a href=https://en.wikipedia.org/wiki/Map_(mathematics)>mappings</a>, each induced to fit the <a href=https://en.wikipedia.org/wiki/Map_(mathematics)>mapping</a> for one subspace. Our experiments on unsupervised bilingual lexicon induction and cross-lingual document classification show that this method improves performance over previous single-mapping methods, especially for distant languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.40.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--40 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.40 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.naacl-main.40.OptionalSupplementaryData.zip data-toggle=tooltip data-placement=top title="Optional supplementary data"><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.40" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.40/>Multi-view Subword Regularization</a></strong><br><a href=/people/x/xinyi-wang/>Xinyi Wang</a>
|
<a href=/people/s/sebastian-ruder/>Sebastian Ruder</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--40><div class="card-body p-3 small">Multilingual pretrained representations generally rely on subword segmentation algorithms to create a shared multilingual vocabulary. However, standard <a href=https://en.wikipedia.org/wiki/Heuristic_(computer_science)>heuristic algorithms</a> often lead to sub-optimal segmentation, especially for languages with limited amounts of data. In this paper, we take two major steps towards alleviating this problem. First, we demonstrate empirically that applying existing subword regularization methods (Kudo, 2018 ; Provilkov et al., 2020) during fine-tuning of pre-trained multilingual representations improves the effectiveness of cross-lingual transfer. Second, to take full advantage of different possible input segmentations, we propose Multi-view Subword Regularization (MVR), a method that enforces the consistency of predictors between using inputs tokenized by the standard and probabilistic segmentations. Results on the XTREME multilingual benchmark (Hu et al., 2020) show that MVR brings consistent improvements of up to 2.5 points over using standard segmentation algorithms.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.42.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--42 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.42 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.42" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.42/>MetaXL : Meta Representation Transformation for Low-resource Cross-lingual Learning<span class=acl-fixed-case>M</span>eta<span class=acl-fixed-case>XL</span>: Meta Representation Transformation for Low-resource Cross-lingual Learning</a></strong><br><a href=/people/m/mengzhou-xia/>Mengzhou Xia</a>
|
<a href=/people/g/guoqing-zheng/>Guoqing Zheng</a>
|
<a href=/people/s/subhabrata-mukherjee/>Subhabrata Mukherjee</a>
|
<a href=/people/m/milad-shokouhi/>Milad Shokouhi</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/a/ahmed-hassan/>Ahmed Hassan Awadallah</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--42><div class="card-body p-3 small">The combination of multilingual pre-trained representations and cross-lingual transfer learning is one of the most effective methods for building functional NLP systems for low-resource languages. However, for extremely low-resource languages without large-scale monolingual corpora for pre-training or sufficient annotated data for <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a>, <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> remains an understudied and challenging task. Moreover, recent work shows that multilingual representations are surprisingly disjoint across languages, bringing additional challenges for transfer onto extremely low-resource languages. In this paper, we propose MetaXL, a meta-learning based framework that learns to transform representations judiciously from auxiliary languages to a target one and brings their representation spaces closer for effective transfer. Extensive experiments on real-world low-resource languages without access to large-scale monolingual corpora or large amounts of labeled data for tasks like cross-lingual sentiment analysis and <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a> show the effectiveness of our approach. Code for MetaXL is publicly available at github.com/microsoft/MetaXL.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.43.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--43 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.43 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.43" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.43/>Open Domain Question Answering over Tables via Dense Retrieval</a></strong><br><a href=/people/j/jonathan-herzig/>Jonathan Herzig</a>
|
<a href=/people/t/thomas-mueller/>Thomas Müller</a>
|
<a href=/people/s/syrine-krichene/>Syrine Krichene</a>
|
<a href=/people/j/julian-eisenschlos/>Julian Eisenschlos</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--43><div class="card-body p-3 small">Recent advances in open-domain QA have led to strong models based on dense retrieval, but only focused on retrieving textual passages. In this work, we tackle open-domain QA over tables for the first time, and show that retrieval can be improved by a retriever designed to handle tabular context. We present an effective pre-training procedure for our <a href=https://en.wikipedia.org/wiki/Retriever>retriever</a> and improve retrieval quality with mined hard negatives. As relevant datasets are missing, we extract a subset of <a href=https://en.wikipedia.org/wiki/Natural_Questions>Natural Questions</a> (Kwiatkowski et al., 2019) into a Table QA dataset. We find that our <a href=https://en.wikipedia.org/wiki/Retriever>retriever</a> improves <a href=https://en.wikipedia.org/wiki/Recall_(memory)>retrieval</a> results from 72.0 to 81.1 recall@10 and <a href=https://en.wikipedia.org/wiki/End-to-end_principle>end-to-end QA</a> results from 33.8 to 37.7 exact match, over a BERT based retriever.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.44.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--44 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.44 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.44" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.44/>Open-Domain Question Answering Goes Conversational via Question Rewriting</a></strong><br><a href=/people/r/raviteja-anantha/>Raviteja Anantha</a>
|
<a href=/people/s/svitlana-vakulenko/>Svitlana Vakulenko</a>
|
<a href=/people/z/zhucheng-tu/>Zhucheng Tu</a>
|
<a href=/people/s/shayne-longpre/>Shayne Longpre</a>
|
<a href=/people/s/stephen-pulman/>Stephen Pulman</a>
|
<a href=/people/s/srinivas-chappidi/>Srinivas Chappidi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--44><div class="card-body p-3 small">We introduce a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for Question Rewriting in Conversational Context (QReCC), which contains 14 K conversations with 80 K question-answer pairs. The task in QReCC is to find answers to conversational questions within a collection of 10 M web pages (split into 54 M passages). Answers to questions in the same conversation may be distributed across several web pages. QReCC provides annotations that allow us to train and evaluate individual subtasks of question rewriting, passage retrieval and <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a> required for the end-to-end conversational question answering (QA) task. We report the effectiveness of a strong baseline approach that combines the state-of-the-art model for question rewriting, and competitive models for open-domain QA. Our results set the first <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> for the QReCC dataset with <a href=https://en.wikipedia.org/wiki/Quantitative_structure&#8211;activity_relationship>F1</a> of 19.10, compared to the <a href=https://en.wikipedia.org/wiki/Quantitative_structure&#8211;activity_relationship>human upper bound</a> of 75.45, indicating the difficulty of the setup and a large room for improvement.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.46.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--46 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.46 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.46" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.46/>XOR QA : Cross-lingual Open-Retrieval Question Answering<span class=acl-fixed-case>XOR</span> <span class=acl-fixed-case>QA</span>: Cross-lingual Open-Retrieval Question Answering</a></strong><br><a href=/people/a/akari-asai/>Akari Asai</a>
|
<a href=/people/j/jungo-kasai/>Jungo Kasai</a>
|
<a href=/people/j/jonathan-h-clark/>Jonathan Clark</a>
|
<a href=/people/k/kenton-lee/>Kenton Lee</a>
|
<a href=/people/e/eunsol-choi/>Eunsol Choi</a>
|
<a href=/people/h/hannaneh-hajishirzi/>Hannaneh Hajishirzi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--46><div class="card-body p-3 small">Multilingual question answering tasks typically assume that answers exist in the same language as the question. Yet in practice, many languages face both information scarcitywhere languages have few reference articlesand information asymmetrywhere questions reference concepts from other cultures. This work extends open-retrieval question answering to a cross-lingual setting enabling questions from one language to be answered via answer content from another language. We construct a large-scale dataset built on 40 K information-seeking questions across 7 diverse non-English languages that TyDi QA could not find same-language answers for. Based on this dataset, we introduce a task framework, called Cross-lingual Open-Retrieval Question Answering (XOR QA), that consists of three new tasks involving cross-lingual document retrieval from multilingual and English resources. We establish <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baselines</a> with state-of-the-art <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation systems</a> and cross-lingual pretrained models. Experimental results suggest that XOR QA is a challenging task that will facilitate the development of novel techniques for multilingual question answering. Our data and code are available at https://nlp.cs.washington.edu/xorqa/.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.50.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--50 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.50 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.50/>On learning and representing social meaning in <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP</a> : a sociolinguistic perspective<span class=acl-fixed-case>NLP</span>: a sociolinguistic perspective</a></strong><br><a href=/people/d/dong-nguyen/>Dong Nguyen</a>
|
<a href=/people/l/laura-rosseel/>Laura Rosseel</a>
|
<a href=/people/j/jack-grieve/>Jack Grieve</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--50><div class="card-body p-3 small">The field of <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP</a> has made substantial progress in building meaning representations. However, an important aspect of <a href=https://en.wikipedia.org/wiki/Meaning_(linguistics)>linguistic meaning</a>, <a href=https://en.wikipedia.org/wiki/Meaning_(linguistics)>social meaning</a>, has been largely overlooked. We introduce the concept of social meaning to <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP</a> and discuss how insights from <a href=https://en.wikipedia.org/wiki/Sociolinguistics>sociolinguistics</a> can inform work on <a href=https://en.wikipedia.org/wiki/Representation_learning>representation learning</a> in <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP</a>. We also identify key challenges for this new line of research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.53.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--53 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.53 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.53/>Representing Numbers in NLP : a Survey and a Vision<span class=acl-fixed-case>NLP</span>: a Survey and a Vision</a></strong><br><a href=/people/a/avijit-thawani/>Avijit Thawani</a>
|
<a href=/people/j/jay-pujara/>Jay Pujara</a>
|
<a href=/people/f/filip-ilievski/>Filip Ilievski</a>
|
<a href=/people/p/pedro-szekely/>Pedro Szekely</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--53><div class="card-body p-3 small">NLP systems rarely give special consideration to numbers found in text. This starkly contrasts with the consensus in <a href=https://en.wikipedia.org/wiki/Neuroscience>neuroscience</a> that, in the brain, numbers are represented differently from words. We arrange recent NLP work on <a href=https://en.wikipedia.org/wiki/Numeracy>numeracy</a> into a comprehensive taxonomy of tasks and methods. We break down the subjective notion of numeracy into 7 subtasks, arranged along two dimensions : granularity (exact vs approximate) and units (abstract vs grounded). We analyze the myriad representational choices made by over a dozen previously published <a href=https://en.wikipedia.org/wiki/Encoder>number encoders</a> and <a href=https://en.wikipedia.org/wiki/Code>decoders</a>. We synthesize best practices for representing numbers in text and articulate a vision for holistic numeracy in <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP</a>, comprised of design trade-offs and a unified evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.55.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--55 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.55 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.55/>Identifying Helpful Sentences in Product Reviews</a></strong><br><a href=/people/i/iftah-gamzu/>Iftah Gamzu</a>
|
<a href=/people/h/hila-gonen/>Hila Gonen</a>
|
<a href=/people/g/gilad-kutiel/>Gilad Kutiel</a>
|
<a href=/people/r/ran-levy/>Ran Levy</a>
|
<a href=/people/e/eugene-agichtein/>Eugene Agichtein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--55><div class="card-body p-3 small">In recent years <a href=https://en.wikipedia.org/wiki/Online_shopping>online shopping</a> has gained momentum and became an important venue for customers wishing to save time and simplify their shopping process. A key advantage of shopping online is the ability to read what other customers are saying about products of interest. In this work, we aim to maintain this advantage in situations where extreme brevity is needed, for example, when shopping by voice. We suggest a novel task of extracting a single representative helpful sentence from a set of reviews for a given product. The selected sentence should meet two conditions : first, it should be helpful for a purchase decision and second, the opinion it expresses should be supported by multiple reviewers. This <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is closely related to the task of Multi Document Summarization in the product reviews domain but differs in its objective and its level of conciseness. We collect a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> in English of sentence helpfulness scores via <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowd-sourcing</a> and demonstrate its reliability despite the inherent subjectivity involved. Next, we describe a complete model that extracts representative helpful sentences with positive and negative sentiment towards the product and demonstrate that it outperforms several baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.56.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--56 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.56 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.56" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.56/>Noisy Self-Knowledge Distillation for Text Summarization</a></strong><br><a href=/people/y/yang-liu-edinburgh/>Yang Liu</a>
|
<a href=/people/s/sheng-shen/>Sheng Shen</a>
|
<a href=/people/m/mirella-lapata/>Mirella Lapata</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--56><div class="card-body p-3 small">In this paper we apply self-knowledge distillation to <a href=https://en.wikipedia.org/wiki/Automatic_summarization>text summarization</a> which we argue can alleviate problems with <a href=https://en.wikipedia.org/wiki/Maximum_likelihood_estimation>maximum-likelihood training</a> on single reference and noisy datasets. Instead of relying on one-hot annotation labels, our student summarization model is trained with guidance from a teacher which generates smoothed labels to help regularize training. Furthermore, to better model uncertainty during <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training</a>, we introduce multiple noise signals for both teacher and student models. We demonstrate experimentally on three benchmarks that our framework boosts the performance of both pretrained and non-pretrained summarizers achieving state-of-the-art results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.57.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--57 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.57 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.57/>Improving Zero and Few-Shot Abstractive Summarization with Intermediate Fine-tuning and Data Augmentation</a></strong><br><a href=/people/a/alexander-richard-fabbri/>Alexander Fabbri</a>
|
<a href=/people/s/simeng-han/>Simeng Han</a>
|
<a href=/people/h/haoyuan-li/>Haoyuan Li</a>
|
<a href=/people/h/haoran-li/>Haoran Li</a>
|
<a href=/people/m/marjan-ghazvininejad/>Marjan Ghazvininejad</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/d/dragomir-radev/>Dragomir Radev</a>
|
<a href=/people/y/yashar-mehdad/>Yashar Mehdad</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--57><div class="card-body p-3 small">Models pretrained with self-supervised objectives on large text corpora achieve state-of-the-art performance on English text summarization tasks. However, these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are typically fine-tuned on hundreds of thousands of data points, an infeasible requirement when applying <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> to new, niche domains. In this work, we introduce a novel and generalizable method, called WikiTransfer, for fine-tuning pretrained models for <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> in an unsupervised, dataset-specific manner. WikiTransfer fine-tunes pretrained models on pseudo-summaries, produced from generic Wikipedia data, which contain characteristics of the target dataset, such as the length and level of abstraction of the desired summaries. WikiTransfer models achieve state-of-the-art, zero-shot abstractive summarization performance on the CNN-DailyMail dataset and demonstrate the effectiveness of our approach on three additional diverse datasets. These models are more robust to noisy data and also achieve better or comparable few-shot performance using 10 and 100 training examples when compared to few-shot transfer from other summarization datasets. To further boost performance, we employ <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> via <a href=https://en.wikipedia.org/wiki/Round-trip_translation>round-trip translation</a> as well as introduce a regularization term for improved few-shot transfer. To understand the role of dataset aspects in transfer performance and the quality of the resulting output summaries, we further study the effect of the components of our unsupervised fine-tuning data and analyze few-shot performance using both automatic and human evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.60.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--60 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.60 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.60/>Nice Try, Kiddo : Investigating Ad Hominems in Dialogue Responses</a></strong><br><a href=/people/e/emily-sheng/>Emily Sheng</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/p/prem-natarajan/>Prem Natarajan</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--60><div class="card-body p-3 small">Ad hominem attacks are those that target some feature of a person&#8217;s character instead of the position the person is maintaining. These attacks are harmful because they propagate implicit biases and diminish a person&#8217;s credibility. Since <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue systems</a> respond directly to <a href=https://en.wikipedia.org/wiki/Input_(computer_science)>user input</a>, it is important to study ad hominems in dialogue responses. To this end, we propose categories of ad hominems, compose an annotated dataset, and build a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> to analyze human and dialogue system responses to English Twitter posts. We specifically compare responses to Twitter topics about marginalized communities (# BlackLivesMatter, # MeToo) versus other topics (# Vegan, # WFH), because the abusive language of ad hominems could further amplify the skew of power away from marginalized populations. Furthermore, we propose a constrained decoding technique that uses salient n-gram similarity as a soft constraint for top-k sampling to reduce the amount of ad hominems generated. Our results indicate that 1) responses from both humans and DialoGPT contain more <a href=https://en.wikipedia.org/wiki/Ad_hominem>ad hominems</a> for discussions around marginalized communities, 2) different quantities of <a href=https://en.wikipedia.org/wiki/Ad_hominem>ad hominems</a> in the training data can influence the likelihood of generating <a href=https://en.wikipedia.org/wiki/Ad_hominem>ad hominems</a>, and 3) we can use constrained decoding techniques to reduce <a href=https://en.wikipedia.org/wiki/Ad_hominem>ad hominems</a> in generated dialogue responses.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.63.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--63 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.63 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.63/>Spoken Language Understanding for Task-oriented Dialogue Systems with Augmented Memory Networks</a></strong><br><a href=/people/j/jie-wu/>Jie Wu</a>
|
<a href=/people/i/ian-harris/>Ian Harris</a>
|
<a href=/people/h/hongzhi-zhao/>Hongzhi Zhao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--63><div class="card-body p-3 small">Spoken language understanding, usually including intent detection and slot filling, is a core component to build a spoken dialog system. Recent research shows promising results by jointly learning of those two tasks based on the fact that slot filling and intent detection are sharing <a href=https://en.wikipedia.org/wiki/Semantic_memory>semantic knowledge</a>. Furthermore, attention mechanism boosts joint learning to achieve state-of-the-art results. However, current joint learning models ignore the following important facts : 1. Long-term slot context is not traced effectively, which is crucial for future slot filling. Slot tagging and intent detection could be mutually rewarding, but bi-directional interaction between slot filling and intent detection remains seldom explored. In this paper, we propose a novel approach to model long-term slot context and to fully utilize the semantic correlation between slots and intents. We adopt a key-value memory network to model slot context dynamically and to track more important slot tags decoded before, which are then fed into our decoder for slot tagging. Furthermore, gated memory information is utilized to perform intent detection, mutually improving both tasks through <a href=https://en.wikipedia.org/wiki/Global_optimization>global optimization</a>. Experiments on benchmark ATIS and Snips datasets show that our model achieves state-of-the-art performance and outperforms other methods, especially for the slot filling task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.66.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--66 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.66 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.66" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.66/>Self-Training with Weak Supervision</a></strong><br><a href=/people/g/giannis-karamanolakis/>Giannis Karamanolakis</a>
|
<a href=/people/s/subhabrata-mukherjee/>Subhabrata Mukherjee</a>
|
<a href=/people/g/guoqing-zheng/>Guoqing Zheng</a>
|
<a href=/people/a/ahmed-hassan/>Ahmed Hassan Awadallah</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--66><div class="card-body p-3 small">State-of-the-art deep neural networks require large-scale labeled training data that is often expensive to obtain or not available for many tasks. Weak supervision in the form of domain-specific rules has been shown to be useful in such settings to automatically generate weakly labeled training data. However, learning with weak rules is challenging due to their inherent heuristic and noisy nature. An additional challenge is rule coverage and overlap, where prior work on weak supervision only considers instances that are covered by weak rules, thus leaving valuable unlabeled data behind. In this work, we develop a weak supervision framework (ASTRA) that leverages all the available data for a given <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>. To this end, we leverage task-specific unlabeled data through self-training with a model (student) that considers contextualized representations and predicts pseudo-labels for instances that may not be covered by weak rules. We further develop a rule attention network (teacher) that learns how to aggregate student pseudo-labels with weak rule labels, conditioned on their fidelity and the underlying context of an instance. Finally, we construct a semi-supervised learning objective for end-to-end training with unlabeled data, domain-specific rules, and a small amount of labeled data. Extensive experiments on six benchmark datasets for text classification demonstrate the effectiveness of our approach with significant improvements over state-of-the-art baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.68.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--68 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.68 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.68" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.68/>Probabilistic Box Embeddings for Uncertain Knowledge Graph Reasoning</a></strong><br><a href=/people/x/xuelu-chen/>Xuelu Chen</a>
|
<a href=/people/m/michael-boratko/>Michael Boratko</a>
|
<a href=/people/m/muhao-chen/>Muhao Chen</a>
|
<a href=/people/s/shib-sankar-dasgupta/>Shib Sankar Dasgupta</a>
|
<a href=/people/x/xiang-lorraine-li/>Xiang Lorraine Li</a>
|
<a href=/people/a/andrew-mccallum/>Andrew McCallum</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--68><div class="card-body p-3 small">Knowledge bases often consist of facts which are harvested from a variety of sources, many of which are noisy and some of which conflict, resulting in a level of uncertainty for each triple. Knowledge bases are also often incomplete, prompting the use of <a href=https://en.wikipedia.org/wiki/Embedding>embedding methods</a> to generalize from known facts, however, existing <a href=https://en.wikipedia.org/wiki/Embedding>embedding methods</a> only model triple-level uncertainty, and reasoning results lack <a href=https://en.wikipedia.org/wiki/Global_consistency>global consistency</a>. To address these shortcomings, we propose BEUrRE, a novel uncertain knowledge graph embedding method with calibrated probabilistic semantics. BEUrRE models each entity as a box (i.e. axis-aligned hyperrectangle) and relations between two entities as affine transforms on the head and tail entity boxes. The geometry of the boxes allows for efficient calculation of intersections and volumes, endowing the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> with calibrated probabilistic semantics and facilitating the incorporation of relational constraints. Extensive experiments on two benchmark datasets show that BEUrRE consistently outperforms baselines on <a href=https://en.wikipedia.org/wiki/Confidence_interval>confidence prediction</a> and fact ranking due to its probabilistic calibration and ability to capture high-order dependencies among facts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.69.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--69 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.69 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.naacl-main.69.OptionalSupplementaryData.zip data-toggle=tooltip data-placement=top title="Optional supplementary data"><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.69" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.69/>Document-Level Event Argument Extraction by Conditional Generation</a></strong><br><a href=/people/s/sha-li/>Sha Li</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/j/jiawei-han/>Jiawei Han</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--69><div class="card-body p-3 small">Event extraction has long been treated as a sentence-level task in the IE community. We argue that this <a href=https://en.wikipedia.org/wiki/Setting_(narrative)>setting</a> does not match human informative seeking behavior and leads to incomplete and uninformative extraction results. We propose a document-level neural event argument extraction model by formulating the task as conditional generation following event templates. We also compile a new document-level event extraction benchmark dataset WikiEvents which includes complete event and coreference annotation. On the task of argument extraction, we achieve an absolute gain of 7.6 % <a href=https://en.wikipedia.org/wiki/F-number>F1</a> and 5.7 % <a href=https://en.wikipedia.org/wiki/F-number>F1</a> over the next best <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on the RAMS and WikiEvents dataset respectively. On the more challenging task of informative argument extraction, which requires implicit coreference reasoning, we achieve a 9.3 % F1 gain over the best <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a>. To demonstrate the portability of our model, we also create the first end-to-end zero-shot event extraction framework and achieve 97 % of fully supervised model&#8217;s trigger extraction performance and 82 % of the argument extraction performance given only access to 10 out of the 33 types on ACE.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.70.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--70 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.70 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.70" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.70/>Template Filling with Generative Transformers</a></strong><br><a href=/people/x/xinya-du/>Xinya Du</a>
|
<a href=/people/a/alexander-m-rush/>Alexander Rush</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--70><div class="card-body p-3 small">Template filling is generally tackled by a pipeline of two separate supervised systems one for role-filler extraction and another for template / event recognition. Since <a href=https://en.wikipedia.org/wiki/Pipeline_transport>pipelines</a> consider events in isolation, they can suffer from <a href=https://en.wikipedia.org/wiki/Error_propagation>error propagation</a>. We introduce a <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> based on end-to-end generative transformers for this task (i.e., GTT). It naturally models the dependence between entities both within a single event and across the multiple events described in a document. Experiments demonstrate that this framework substantially outperforms pipeline-based approaches, and other neural end-to-end baselines that do not model between-event dependencies. We further show that our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> specifically improves performance on documents containing multiple events.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.72.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--72 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.72 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.72/>On Attention Redundancy : A Comprehensive Study</a></strong><br><a href=/people/y/yuchen-bian/>Yuchen Bian</a>
|
<a href=/people/j/jiaji-huang/>Jiaji Huang</a>
|
<a href=/people/x/xingyu-cai/>Xingyu Cai</a>
|
<a href=/people/j/jiahong-yuan/>Jiahong Yuan</a>
|
<a href=/people/k/kenneth-church/>Kenneth Church</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--72><div class="card-body p-3 small">Multi-layer multi-head self-attention mechanism is widely applied in modern neural language models. Attention redundancy has been observed among <a href=https://en.wikipedia.org/wiki/Attentional_control>attention heads</a> but has not been deeply studied in the literature. Using BERT-base model as an example, this paper provides a comprehensive study on attention redundancy which is helpful for model interpretation and model compression. We analyze the attention redundancy with Five-Ws and How. (What) We define and focus the study on redundancy matrices generated from pre-trained and fine-tuned BERT-base model for GLUE datasets. (How) We use both token-based and sentence-based distance functions to measure the <a href=https://en.wikipedia.org/wiki/Redundancy_(engineering)>redundancy</a>. (Where) Clear and similar redundancy patterns (cluster structure) are observed among attention heads. (When) Redundancy patterns are similar in both pre-training and fine-tuning phases. (Who) We discover that <a href=https://en.wikipedia.org/wiki/Redundancy_(engineering)>redundancy patterns</a> are task-agnostic. Similar <a href=https://en.wikipedia.org/wiki/Redundancy_(information_theory)>redundancy patterns</a> even exist for randomly generated token sequences. (Why) We also evaluate influences of the pre-training dropout ratios on attention redundancy. Based on the phase-independent and task-agnostic attention redundancy patterns, we propose a simple zero-shot pruning method as a case study. Experiments on fine-tuning GLUE tasks verify its effectiveness. The comprehensive analyses on attention redundancy make model understanding and zero-shot model pruning promising.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.73.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--73 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.73 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.73" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.73/>Does BERT Pretrained on Clinical Notes Reveal Sensitive Data?<span class=acl-fixed-case>BERT</span> Pretrained on Clinical Notes Reveal Sensitive Data?</a></strong><br><a href=/people/e/eric-lehman/>Eric Lehman</a>
|
<a href=/people/s/sarthak-jain/>Sarthak Jain</a>
|
<a href=/people/k/karl-pichotta/>Karl Pichotta</a>
|
<a href=/people/y/yoav-goldberg/>Yoav Goldberg</a>
|
<a href=/people/b/byron-c-wallace/>Byron Wallace</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--73><div class="card-body p-3 small">Large Transformers pretrained over clinical notes from Electronic Health Records (EHR) have afforded substantial gains in performance on predictive clinical tasks. The cost of training such <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> (and the necessity of data access to do so) coupled with their utility motivates parameter sharing, i.e., the release of pretrained <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> such as ClinicalBERT. While most efforts have used deidentified EHR, many researchers have access to large sets of sensitive, non-deidentified EHR with which they might train a BERT model (or similar). Would it be safe to release the weights of such a <a href=https://en.wikipedia.org/wiki/Physical_model>model</a> if they did? In this work, we design a battery of approaches intended to recover Personal Health Information (PHI) from a trained BERT. Specifically, we attempt to recover patient names and conditions with which they are associated. We find that simple probing methods are not able to meaningfully extract sensitive information from BERT trained over the MIMIC-III corpus of EHR. However, more sophisticated attacks may succeed in doing so : To facilitate such research, we make our experimental setup and baseline probing models available at https://github.com/elehman16/exposing_patient_data_release.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.74.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--74 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.74 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.74" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.74/>Low-Complexity Probing via Finding Subnetworks</a></strong><br><a href=/people/s/steven-cao/>Steven Cao</a>
|
<a href=/people/v/victor-sanh/>Victor Sanh</a>
|
<a href=/people/a/alexander-m-rush/>Alexander Rush</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--74><div class="card-body p-3 small">The dominant approach in probing neural networks for linguistic properties is to train a new shallow multi-layer perceptron (MLP) on top of the model&#8217;s internal representations. This approach can detect properties encoded in the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>, but at the cost of adding new parameters that may learn the task directly. We instead propose a subtractive pruning-based probe, where we find an existing <a href=https://en.wikipedia.org/wiki/Subnetwork>subnetwork</a> that performs the linguistic task of interest. Compared to an MLP, the subnetwork probe achieves both higher <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on pre-trained models and lower <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on random models, so it is both better at finding properties of interest and worse at learning on its own. Next, by varying the <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a> of each probe, we show that subnetwork probing Pareto-dominates MLP probing in that it achieves higher <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> given any budget of probe complexity. Finally, we analyze the resulting subnetworks across various tasks to locate where each task is encoded, and we find that lower-level tasks are captured in lower layers, reproducing similar findings in past work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.75.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--75 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.75 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.75" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.75/>An Empirical Comparison of Instance Attribution Methods for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a><span class=acl-fixed-case>NLP</span></a></strong><br><a href=/people/p/pouya-pezeshkpour/>Pouya Pezeshkpour</a>
|
<a href=/people/s/sarthak-jain/>Sarthak Jain</a>
|
<a href=/people/b/byron-c-wallace/>Byron Wallace</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--75><div class="card-body p-3 small">Widespread adoption of <a href=https://en.wikipedia.org/wiki/Deep_learning>deep models</a> has motivated a pressing need for approaches to interpret network outputs and to facilitate model debugging. Instance attribution methods constitute one means of accomplishing these goals by retrieving training instances that (may have) led to a particular prediction. Influence functions (IF ; Koh and Liang 2017) provide machinery for doing this by quantifying the effect that perturbing individual train instances would have on a specific test prediction. However, even approximating the <a href=https://en.wikipedia.org/wiki/Conditional_(computer_programming)>IF</a> is computationally expensive, to the degree that may be prohibitive in many cases. Might simpler approaches (e.g., retrieving train examples most similar to a given test point) perform comparably? In this work, we evaluate the degree to which different potential instance attribution agree with respect to the importance of training samples. We find that simple retrieval methods yield training instances that differ from those identified via gradient-based methods (such as IFs), but that nonetheless exhibit desirable characteristics similar to more complex attribution methods. Code for all methods and experiments in this paper is available at : https://github.com/successar/instance_attributions_NLP.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.76.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--76 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.76 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.76/>Generalization in Instruction Following Systems</a></strong><br><a href=/people/s/soham-dan/>Soham Dan</a>
|
<a href=/people/m/michael-zhou/>Michael Zhou</a>
|
<a href=/people/d/dan-roth/>Dan Roth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--76><div class="card-body p-3 small">Understanding and executing <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language instructions</a> in a grounded domain is one of the hallmarks of <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>artificial intelligence</a>. In this paper, we focus on instruction understanding in the blocks world domain and investigate the language understanding abilities of two top-performing <a href=https://en.wikipedia.org/wiki/System>systems</a> for the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. We aim to understand if the test performance of these models indicates an understanding of the spatial domain and of the <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language instructions</a> relative to it, or whether they merely over-fit spurious signals in the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. We formulate a set of expectations one might have from an instruction following model and concretely characterize the different dimensions of robustness such a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> should possess. Despite decent test performance, we find that <a href=https://en.wikipedia.org/wiki/State-of-the-art>state-of-the-art models</a> fall short of these expectations and are extremely brittle. We then propose a learning strategy that involves <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> and show through extensive experiments that the proposed learning strategy yields models that are competitive on the original test set while satisfying our expectations much better.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.79.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--79 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.79 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.79" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.79/>MTAG : Modal-Temporal Attention Graph for Unaligned Human Multimodal Language Sequences<span class=acl-fixed-case>MTAG</span>: Modal-Temporal Attention Graph for Unaligned Human Multimodal Language Sequences</a></strong><br><a href=/people/j/jianing-yang/>Jianing Yang</a>
|
<a href=/people/y/yongxin-wang/>Yongxin Wang</a>
|
<a href=/people/r/ruitao-yi/>Ruitao Yi</a>
|
<a href=/people/y/yuying-zhu/>Yuying Zhu</a>
|
<a href=/people/a/azaan-rehman/>Azaan Rehman</a>
|
<a href=/people/a/amir-zadeh/>Amir Zadeh</a>
|
<a href=/people/s/soujanya-poria/>Soujanya Poria</a>
|
<a href=/people/l/louis-philippe-morency/>Louis-Philippe Morency</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--79><div class="card-body p-3 small">Human communication is multimodal in nature ; it is through multiple modalities such as <a href=https://en.wikipedia.org/wiki/Language>language</a>, <a href=https://en.wikipedia.org/wiki/Human_voice>voice</a>, and <a href=https://en.wikipedia.org/wiki/Facial_expression>facial expressions</a>, that opinions and emotions are expressed. Data in this <a href=https://en.wikipedia.org/wiki/Domain_(biology)>domain</a> exhibits complex multi-relational and temporal interactions. Learning from this <a href=https://en.wikipedia.org/wiki/Data>data</a> is a fundamentally challenging research problem. In this paper, we propose Modal-Temporal Attention Graph (MTAG). MTAG is an interpretable graph-based neural model that provides a suitable framework for analyzing multimodal sequential data. We first introduce a procedure to convert unaligned multimodal sequence data into a <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a> with heterogeneous nodes and edges that captures the rich interactions across modalities and through time. Then, a novel graph fusion operation, called MTAG fusion, along with a dynamic pruning and read-out technique, is designed to efficiently process this modal-temporal graph and capture various interactions. By learning to focus only on the important interactions within the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a>, MTAG achieves state-of-the-art performance on multimodal sentiment analysis and emotion recognition benchmarks, while utilizing significantly fewer model parameters.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.80.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--80 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.80 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.80" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.80/>Grounding Open-Domain Instructions to Automate Web Support Tasks</a></strong><br><a href=/people/n/nancy-xu/>Nancy Xu</a>
|
<a href=/people/s/sam-masling/>Sam Masling</a>
|
<a href=/people/m/michael-du/>Michael Du</a>
|
<a href=/people/g/giovanni-campagna/>Giovanni Campagna</a>
|
<a href=/people/l/larry-heck/>Larry Heck</a>
|
<a href=/people/j/james-landay/>James Landay</a>
|
<a href=/people/m/monica-lam/>Monica Lam</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--80><div class="card-body p-3 small">Grounding natural language instructions on the web to perform previously unseen tasks enables <a href=https://en.wikipedia.org/wiki/Accessibility>accessibility</a> and <a href=https://en.wikipedia.org/wiki/Automation>automation</a>. We introduce a task and dataset to train <a href=https://en.wikipedia.org/wiki/Intelligent_agent>AI agents</a> from open-domain, step-by-step instructions originally written for people. We build RUSS (Rapid Universal Support Service) to tackle this problem. RUSS consists of two models : First, a BERT-LSTM with pointers parses instructions to WebLang, a <a href=https://en.wikipedia.org/wiki/Domain-specific_language>domain-specific language</a> we design for grounding <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a> on the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>web</a>. Then, a grounding model retrieves the unique IDs of any webpage elements requested in the WebLang. RUSS may interact with the user through a <a href=https://en.wikipedia.org/wiki/Dialogue>dialogue</a> (e.g. ask for an address) or execute a <a href=https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol>web operation</a> (e.g. click a button) inside the web runtime. To augment <a href=https://en.wikipedia.org/wiki/Training>training</a>, we synthesize <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language instructions</a> mapped to WebLang. Our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> consists of 80 different customer service problems from help websites, with a total of 741 step-by-step instructions and their corresponding actions. RUSS achieves 76.7 % end-to-end accuracy predicting agent actions from single instructions. It outperforms state-of-the-art <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> that directly map instructions to actions without WebLang. Our user study shows that RUSS is preferred by actual users over <a href=https://en.wikipedia.org/wiki/Web_navigation>web navigation</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.82.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--82 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.82 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.82" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.82/>Improving Cross-Modal Alignment in Vision Language Navigation via Syntactic Information</a></strong><br><a href=/people/j/jialu-li/>Jialu Li</a>
|
<a href=/people/h/hao-tan/>Hao Tan</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--82><div class="card-body p-3 small">Vision language navigation is the task that requires an agent to navigate through a 3D environment based on <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language instructions</a>. One key challenge in this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is to ground instructions with the current <a href=https://en.wikipedia.org/wiki/Visual_system>visual information</a> that the agent perceives. Most of the existing work employs soft attention over individual words to locate the instruction required for the next action. However, different words have different functions in a sentence (e.g., <a href=https://en.wikipedia.org/wiki/Grammatical_modifier>modifiers</a> convey attributes, <a href=https://en.wikipedia.org/wiki/Verb>verbs</a> convey actions). Syntax information like <a href=https://en.wikipedia.org/wiki/Coupling_(computer_programming)>dependencies</a> and <a href=https://en.wikipedia.org/wiki/Phrase_structure_grammar>phrase structures</a> can aid the <a href=https://en.wikipedia.org/wiki/Intelligent_agent>agent</a> to locate important parts of the instruction. Hence, in this paper, we propose a navigation agent that utilizes syntax information derived from a dependency tree to enhance alignment between the instruction and the current visual scenes. Empirically, our agent outperforms the baseline model that does not use syntax information on the Room-to-Room dataset, especially in the unseen environment. Besides, our agent achieves the new state-of-the-art on Room-Across-Room dataset, which contains instructions in 3 languages (English, Hindi, and Telugu). We also show that our <a href=https://en.wikipedia.org/wiki/Intelligent_agent>agent</a> is better at aligning instructions with the current <a href=https://en.wikipedia.org/wiki/Visual_system>visual information</a> via qualitative visualizations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.86.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--86 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.86 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.86" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.86/>Understanding Hard Negatives in Noise Contrastive Estimation</a></strong><br><a href=/people/w/wenzheng-zhang/>Wenzheng Zhang</a>
|
<a href=/people/k/karl-stratos/>Karl Stratos</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--86><div class="card-body p-3 small">The choice of negative examples is important in noise contrastive estimation. Recent works find that hard negativeshighest-scoring incorrect examples under the modelare effective in practice, but they are used without a formal justification. We develop analytical tools to understand the role of hard negatives. Specifically, we view the contrastive loss as a biased estimator of the gradient of the cross-entropy loss, and show both theoretically and empirically that setting the negative distribution to be the model distribution results in bias reduction. We also derive a general form of the <a href=https://en.wikipedia.org/wiki/Score_function>score function</a> that unifies various <a href=https://en.wikipedia.org/wiki/Information_retrieval>architectures</a> used in <a href=https://en.wikipedia.org/wiki/Information_retrieval>text retrieval</a>. By combining hard negatives with appropriate score functions, we obtain strong results on the challenging task of zero-shot entity linking.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.88.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--88 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.88 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.88/>DReCa : A General Task Augmentation Strategy for Few-Shot Natural Language Inference<span class=acl-fixed-case>DR</span>e<span class=acl-fixed-case>C</span>a: A General Task Augmentation Strategy for Few-Shot Natural Language Inference</a></strong><br><a href=/people/s/shikhar-murty/>Shikhar Murty</a>
|
<a href=/people/t/tatsunori-b-hashimoto/>Tatsunori B. Hashimoto</a>
|
<a href=/people/c/christopher-d-manning/>Christopher Manning</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--88><div class="card-body p-3 small">Meta-learning promises few-shot learners that can adapt to new distributions by repurposing knowledge acquired from previous training. However, we believe <a href=https://en.wikipedia.org/wiki/Meta-learning>meta-learning</a> has not yet succeeded in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> due to the lack of a well-defined task distribution, leading to attempts that treat datasets as tasks. Such an ad hoc task distribution causes problems of quantity and quality. Since there&#8217;s only a handful of datasets for any NLP problem, meta-learners tend to overfit their adaptation mechanism and, since NLP datasets are highly heterogeneous, many learning episodes have poor transfer between their support and query sets, which discourages the meta-learner from adapting. To alleviate these issues, we propose DReCA (Decomposing datasets into Reasoning Categories), a simple method for discovering and using latent reasoning categories in a dataset, to form additional high quality tasks. DReCA works by splitting examples into label groups, embedding them with a finetuned BERT model and then clustering each group into reasoning categories. Across four few-shot NLI problems, we demonstrate that using DReCA improves the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of <a href=https://en.wikipedia.org/wiki/Meta-learning>meta-learners</a> by 1.5-4 %</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.89.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--89 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.89 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.89/>Harnessing <a href=https://en.wikipedia.org/wiki/Multilinguality>Multilinguality</a> in Unsupervised Machine Translation for Rare Languages</a></strong><br><a href=/people/x/xavier-garcia/>Xavier Garcia</a>
|
<a href=/people/a/aditya-siddhant/>Aditya Siddhant</a>
|
<a href=/people/o/orhan-firat/>Orhan Firat</a>
|
<a href=/people/a/ankur-parikh/>Ankur Parikh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--89><div class="card-body p-3 small">Unsupervised translation has reached impressive performance on resource-rich language pairs such as English-French and <a href=https://en.wikipedia.org/wiki/Standard_German>English-German</a>. However, early studies have shown that in more realistic settings involving low-resource, rare languages, unsupervised translation performs poorly, achieving less than 3.0 <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>. In this work, we show that <a href=https://en.wikipedia.org/wiki/Multilinguality>multilinguality</a> is critical to making <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised systems</a> practical for low-resource settings. In particular, we present a single model for 5 low-resource languages (Gujarati, Kazakh, Nepali, Sinhala, and Turkish) to and from English directions, which leverages monolingual and auxiliary parallel data from other high-resource language pairs via a three-stage training scheme. We outperform all current state-of-the-art unsupervised baselines for these languages, achieving gains of up to 14.4 BLEU. Additionally, we outperform strong supervised baselines for various language pairs as well as match the performance of the current state-of-the-art <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised model</a> for <a href=https://en.wikipedia.org/wiki/Nepali_language>Nepali-English</a>. We conduct a series of ablation studies to establish the robustness of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> under different degrees of <a href=https://en.wikipedia.org/wiki/Data_quality>data quality</a>, as well as to analyze the factors which led to the superior performance of the proposed approach over traditional <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised models</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.91.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--91 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.91 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.91/>Assessing Reference-Free Peer Evaluation for Machine Translation</a></strong><br><a href=/people/s/sweta-agrawal/>Sweta Agrawal</a>
|
<a href=/people/g/george-foster/>George Foster</a>
|
<a href=/people/m/markus-freitag/>Markus Freitag</a>
|
<a href=/people/c/colin-cherry/>Colin Cherry</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--91><div class="card-body p-3 small">Reference-free evaluation has the potential to make machine translation evaluation substantially more scalable, allowing us to pivot easily to new languages or domains. It has been recently shown that the probabilities given by a large, multilingual model can achieve state of the art results when used as a reference-free metric. We experiment with various modifications to this <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>, and demonstrate that by scaling it up we can match the performance of <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>. We analyze various potential weaknesses of the approach, and find that it is surprisingly robust and likely to offer reasonable performance across a broad spectrum of domains and different system qualities.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.92.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--92 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.92 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.92" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.92/>The Curious Case of <a href=https://en.wikipedia.org/wiki/Hallucination>Hallucinations</a> in Neural Machine Translation</a></strong><br><a href=/people/v/vikas-raunak/>Vikas Raunak</a>
|
<a href=/people/a/arul-menezes/>Arul Menezes</a>
|
<a href=/people/m/marcin-junczys-dowmunt/>Marcin Junczys-Dowmunt</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--92><div class="card-body p-3 small">In this work, we study <a href=https://en.wikipedia.org/wiki/Hallucination>hallucinations</a> in Neural Machine Translation (NMT), which lie at an extreme end on the spectrum of NMT pathologies. Firstly, we connect the phenomenon of <a href=https://en.wikipedia.org/wiki/Hallucination>hallucinations</a> under source perturbation to the Long-Tail theory of Feldman, and present an empirically validated hypothesis that explains <a href=https://en.wikipedia.org/wiki/Hallucination>hallucinations</a> under source perturbation. Secondly, we consider <a href=https://en.wikipedia.org/wiki/Hallucination>hallucinations</a> under corpus-level noise (without any source perturbation) and demonstrate that two prominent types of natural hallucinations (detached and oscillatory outputs) could be generated and explained through specific corpus-level noise patterns. Finally, we elucidate the phenomenon of hallucination amplification in popular data-generation processes such as Backtranslation and sequence-level Knowledge Distillation. We have released the datasets and code to replicate our results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.94.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--94 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.94 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.94/>Towards Modeling the Style of Translators in <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a></a></strong><br><a href=/people/y/yue-wang/>Yue Wang</a>
|
<a href=/people/c/cuong-hoang/>Cuong Hoang</a>
|
<a href=/people/m/marcello-federico/>Marcello Federico</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--94><div class="card-body p-3 small">One key ingredient of <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a> is the use of large datasets from different domains and resources (e.g. Europarl, TED talks). These <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> contain documents translated by professional translators using different but consistent translation styles. Despite that, the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> is usually trained in a way that neither explicitly captures the variety of translation styles present in the data nor translates new data in different and controllable styles. In this work, we investigate methods to augment the state of the art Transformer model with translator information that is available in part of the training data. We show that our style-augmented translation models are able to capture the style variations of translators and to generate translations with different styles on new data. Indeed, the generated variations differ significantly, up to +4.5 BLEU score difference. Despite that, <a href=https://en.wikipedia.org/wiki/Human_factors_and_ergonomics>human evaluation</a> confirms that the translations are of the same quality.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.95.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--95 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.95 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.95/>Self-Supervised Test-Time Learning for Reading Comprehension</a></strong><br><a href=/people/p/pratyay-banerjee/>Pratyay Banerjee</a>
|
<a href=/people/t/tejas-gokhale/>Tejas Gokhale</a>
|
<a href=/people/c/chitta-baral/>Chitta Baral</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--95><div class="card-body p-3 small">Recent work on unsupervised question answering has shown that models can be trained with procedurally generated question-answer pairs and can achieve performance competitive with <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised methods</a>. In this work, we consider the task of unsupervised reading comprehension and present a method that performs test-time learning (TTL) on a given context (text passage), without requiring training on large-scale human-authored datasets containing context-question-answer triplets. This method operates directly on a single test context, uses self-supervision to train <a href=https://en.wikipedia.org/wiki/Computer_simulation>models</a> on synthetically generated question-answer pairs, and then infers answers to unseen human-authored questions for this context. Our method achieves accuracies competitive with <a href=https://en.wikipedia.org/wiki/Supervised_learning>fully supervised methods</a> and significantly outperforms current <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised methods</a>. TTL methods with a smaller <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> are also competitive with the current <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> in unsupervised reading comprehension.<i>context-question-answer</i> triplets. This method operates directly on a single test context, uses self-supervision to train models on synthetically generated question-answer pairs, and then infers answers to unseen human-authored questions for this context. Our method achieves accuracies competitive with fully supervised methods and significantly outperforms current unsupervised methods. TTL methods with a smaller model are also competitive with the current state-of-the-art in unsupervised reading comprehension.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.96.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--96 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.96 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.96" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.96/>Capturing Row and Column Semantics in Transformer Based Question Answering over Tables</a></strong><br><a href=/people/m/michael-glass/>Michael Glass</a>
|
<a href=/people/m/mustafa-canim/>Mustafa Canim</a>
|
<a href=/people/a/alfio-gliozzo/>Alfio Gliozzo</a>
|
<a href=/people/s/saneem-chemmengath/>Saneem Chemmengath</a>
|
<a href=/people/v/vishwajeet-kumar/>Vishwajeet Kumar</a>
|
<a href=/people/r/rishav-chakravarti/>Rishav Chakravarti</a>
|
<a href=/people/a/avirup-sil/>Avi Sil</a>
|
<a href=/people/f/feifei-pan/>Feifei Pan</a>
|
<a href=/people/s/samarth-bharadwaj/>Samarth Bharadwaj</a>
|
<a href=/people/n/nicolas-rodolfo-fauceglia/>Nicolas Rodolfo Fauceglia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--96><div class="card-body p-3 small">Transformer based architectures are recently used for the task of answering questions over tables. In order to improve the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, specialized pre-training techniques have been developed and applied on millions of open-domain web tables. In this paper, we propose two novel approaches demonstrating that one can achieve superior performance on table QA task without even using any of these specialized pre-training techniques. The first model, called RCI interaction, leverages a transformer based architecture that independently classifies rows and columns to identify relevant cells. While this model yields extremely high accuracy at finding cell values on recent benchmarks, a second model we propose, called RCI representation, provides a significant efficiency advantage for online QA systems over tables by materializing embeddings for existing tables. Experiments on recent benchmarks prove that the proposed methods can effectively locate cell values on tables (up to ~98 % Hit@1 accuracy on WikiSQL lookup questions). Also, the <a href=https://en.wikipedia.org/wiki/Interaction_model>interaction model</a> outperforms the state-of-the-art transformer based approaches, pre-trained on very large table corpora (TAPAS and TaBERT), achieving ~3.4 % and ~18.86 % additional precision improvement on the standard WikiSQL benchmark.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.98.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--98 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.98 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.98/>Robust Question Answering Through Sub-part Alignment</a></strong><br><a href=/people/j/jifan-chen/>Jifan Chen</a>
|
<a href=/people/g/greg-durrett/>Greg Durrett</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--98><div class="card-body p-3 small">Current textual question answering (QA) models achieve strong performance on in-domain test sets, but often do so by fitting surface-level patterns, so they fail to generalize to out-of-distribution settings. To make a more robust and understandable <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA system</a>, we model <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a> as an alignment problem. We decompose both the question and context into smaller units based on off-the-shelf semantic representations (here, semantic roles), and align the question to a subgraph of the context in order to find the answer. We formulate our model as a structured SVM, with alignment scores computed via BERT, and we can train end-to-end despite using beam search for approximate inference. Our use of explicit alignments allows us to explore a set of <a href=https://en.wikipedia.org/wiki/Constraint_(mathematics)>constraints</a> with which we can prohibit certain types of bad model behavior arising in cross-domain settings. Furthermore, by investigating differences in scores across different potential answers, we can seek to understand what particular aspects of the input lead the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to choose the answer without relying on post-hoc explanation techniques. We train our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on SQuAD v1.1 and test it on several adversarial and out-of-domain datasets. The results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is more robust than the standard BERT QA model, and constraints derived from alignment scores allow us to effectively trade off coverage and <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.100.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--100 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.100 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.100/>RECONSIDER : Improved Re-Ranking using Span-Focused Cross-Attention for Open Domain Question Answering<span class=acl-fixed-case>RECONSIDER</span>: Improved Re-Ranking using Span-Focused Cross-Attention for Open Domain Question Answering</a></strong><br><a href=/people/s/srinivasan-iyer/>Srinivasan Iyer</a>
|
<a href=/people/s/sewon-min/>Sewon Min</a>
|
<a href=/people/y/yashar-mehdad/>Yashar Mehdad</a>
|
<a href=/people/w/wen-tau-yih/>Wen-tau Yih</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--100><div class="card-body p-3 small">State-of-the-art Machine Reading Comprehension (MRC) models for Open-domain Question Answering (QA) are typically trained for span selection using distantly supervised positive examples and heuristically retrieved negative examples. This training scheme possibly explains empirical observations that these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> achieve a high <a href=https://en.wikipedia.org/wiki/Precision_(computer_science)>recall</a> amongst their top few predictions, but a low overall <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, motivating the need for answer re-ranking. We develop a successful re-ranking approach (RECONSIDER) for span-extraction tasks that improves upon the performance of MRC models, even beyond large-scale pre-training. RECONSIDER is trained on positive and negative examples extracted from high confidence MRC model predictions, and uses in-passage span annotations to perform span-focused re-ranking over a smaller candidate set. As a result, RECONSIDER learns to eliminate close false positives, achieving a new extractive state of the art on four <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA tasks</a>, with 45.5 % Exact Match accuracy on Natural Questions with real user questions, and 61.7 % on TriviaQA. We will release all related data, <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a>, and code.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.104.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--104 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.104 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.104/>Looking Beyond Sentence-Level Natural Language Inference for <a href=https://en.wikipedia.org/wiki/Question_answering>Question Answering</a> and Text Summarization</a></strong><br><a href=/people/a/anshuman-mishra/>Anshuman Mishra</a>
|
<a href=/people/d/dhruvesh-patel/>Dhruvesh Patel</a>
|
<a href=/people/a/aparna-vijayakumar/>Aparna Vijayakumar</a>
|
<a href=/people/x/xiang-lorraine-li/>Xiang Lorraine Li</a>
|
<a href=/people/p/pavan-kapanipathi/>Pavan Kapanipathi</a>
|
<a href=/people/k/kartik-talamadupula/>Kartik Talamadupula</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--104><div class="card-body p-3 small">Natural Language Inference (NLI) has garnered significant attention in recent years ; however, the promise of applying NLI breakthroughs to other downstream NLP tasks has remained unfulfilled. In this work, we use the multiple-choice reading comprehension (MCRC) and checking factual correctness of textual summarization (CFCS) tasks to investigate potential reasons for this. Our findings show that : (1) the relatively shorter length of premises in traditional NLI datasets is the primary challenge prohibiting usage in downstream applications (which do better with longer contexts) ; (2) this challenge can be addressed by automatically converting resource-rich reading comprehension datasets into longer-premise NLI datasets ; and (3) models trained on the converted, longer-premise datasets outperform those trained using short-premise traditional NLI datasets on downstream tasks primarily due to the difference in premise lengths.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.110.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--110 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.110 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.110" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.110/>A New Approach to Overgenerating and Scoring Abstractive Summaries</a></strong><br><a href=/people/k/kaiqiang-song/>Kaiqiang Song</a>
|
<a href=/people/b/bingqing-wang/>Bingqing Wang</a>
|
<a href=/people/z/zhe-feng/>Zhe Feng</a>
|
<a href=/people/f/fei-liu-utdallas/>Fei Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--110><div class="card-body p-3 small">We propose a new approach to generate multiple variants of the target summary with diverse content and varying lengths, then score and select admissible ones according to users&#8217; needs. Abstractive summarizers trained on single reference summaries may struggle to produce outputs that achieve multiple desirable properties, i.e., capturing the most important information, being faithful to the original, grammatical and fluent. In this paper, we propose a two-staged strategy to generate a diverse set of candidate summaries from the source text in stage one, then score and select admissible ones in stage two. Importantly, our generator gives a precise control over the length of the summary, which is especially well-suited when space is limited. Our selectors are designed to predict the optimal summary length and put special emphasis on faithfulness to the original text. Both <a href=https://en.wikipedia.org/wiki/Stage_(theatre)>stages</a> can be effectively trained, optimized and evaluated. Our experiments on benchmark summarization datasets suggest that this <a href=https://en.wikipedia.org/wiki/Paradigm>paradigm</a> can achieve state-of-the-art performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.111.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--111 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.111 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.111" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.111/>D2S : Document-to-Slide Generation Via Query-Based Text Summarization<span class=acl-fixed-case>D</span>2<span class=acl-fixed-case>S</span>: Document-to-Slide Generation Via Query-Based Text Summarization</a></strong><br><a href=/people/e/edward-sun/>Edward Sun</a>
|
<a href=/people/y/yufang-hou/>Yufang Hou</a>
|
<a href=/people/d/dakuo-wang/>Dakuo Wang</a>
|
<a href=/people/y/yunfeng-zhang/>Yunfeng Zhang</a>
|
<a href=/people/n/nancy-x-r-wang/>Nancy X. R. Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--111><div class="card-body p-3 small">Presentations are critical for communication in all areas of our lives, yet the creation of <a href=https://en.wikipedia.org/wiki/Slide_show>slide decks</a> is often tedious and time-consuming. There has been limited research aiming to automate the document-to-slides generation process and all face a critical challenge : no publicly available dataset for training and benchmarking. In this work, we first contribute a new dataset, SciDuet, consisting of pairs of papers and their corresponding slides decks from recent years&#8217; NLP and ML conferences (e.g., ACL). Secondly, we present D2S, a novel system that tackles the document-to-slides task with a two-step approach : 1) Use slide titles to retrieve relevant and engaging text, figures, and tables ; 2) Summarize the retrieved context into bullet points with long-form question answering. Our evaluation suggests that long-form QA outperforms state-of-the-art summarization baselines on both automated ROUGE metrics and qualitative human evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.112.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--112 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.112 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.112" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.112/>Efficient Attentions for Long Document Summarization</a></strong><br><a href=/people/l/luyang-huang/>Luyang Huang</a>
|
<a href=/people/s/shuyang-cao/>Shuyang Cao</a>
|
<a href=/people/n/nikolaus-parulian/>Nikolaus Parulian</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/l/lu-wang/>Lu Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--112><div class="card-body p-3 small">The quadratic computational and memory complexities of large Transformers have limited their scalability for long document summarization. In this paper, we propose Hepos, a novel efficient encoder-decoder attention with head-wise positional strides to effectively pinpoint salient information from the source. We further conduct a systematic study of existing efficient <a href=https://en.wikipedia.org/wiki/Self-interest>self-attentions</a>. Combined with Hepos, we are able to process ten times more tokens than existing models that use full attentions. For evaluation, we present a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, GovReport, with significantly longer documents and summaries. Results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> produce significantly higher ROUGE scores than competitive comparisons, including new state-of-the-art results on <a href=https://en.wikipedia.org/wiki/PubMed>PubMed</a>. Human evaluation also shows that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> generate more informative summaries with fewer unfaithful errors.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.113.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--113 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.113 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.113" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.113/>RefSum : Refactoring Neural Summarization<span class=acl-fixed-case>R</span>ef<span class=acl-fixed-case>S</span>um: Refactoring Neural Summarization</a></strong><br><a href=/people/y/yixin-liu/>Yixin Liu</a>
|
<a href=/people/z/zi-yi-dou/>Zi-Yi Dou</a>
|
<a href=/people/p/pengfei-liu/>Pengfei Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--113><div class="card-body p-3 small">Although some recent works show potential complementarity among different state-of-the-art systems, few works try to investigate this <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> in <a href=https://en.wikipedia.org/wiki/Automatic_summarization>text summarization</a>. Researchers in other areas commonly refer to the techniques of <a href=https://en.wikipedia.org/wiki/Ranking>reranking</a> or stacking to approach this <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a>. In this work, we highlight several limitations of previous methods, which motivates us to present a new framework <a href=https://en.wikipedia.org/wiki/Code_refactoring>Refactor</a> that provides a unified view of <a href=https://en.wikipedia.org/wiki/Automatic_summarization>text summarization</a> and summaries combination. Experimentally, we perform a comprehensive evaluation that involves twenty-two base systems, four <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, and three different application scenarios. Besides new state-of-the-art results on CNN / DailyMail dataset (46.18 ROUGE-1), we also elaborate on how our proposed method addresses the limitations of the traditional methods and the effectiveness of the Refactor model sheds light on insight for performance improvement. Our <a href=https://en.wikipedia.org/wiki/System>system</a> can be directly used by other researchers as an off-the-shelf tool to achieve further performance improvements. We open-source all the code and provide a convenient interface to use it : https://github.com/yixinL7/Refactoring-Summarization.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.114.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--114 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.114 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.114" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.114/>Annotating and Modeling Fine-grained Factuality in <a href=https://en.wikipedia.org/wiki/Summarization>Summarization</a></a></strong><br><a href=/people/t/tanya-goyal/>Tanya Goyal</a>
|
<a href=/people/g/greg-durrett/>Greg Durrett</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--114><div class="card-body p-3 small">Recent pre-trained abstractive summarization systems have started to achieve credible performance, but a major barrier to their use in practice is their propensity to output summaries that are not faithful to the input and that contain factual errors. While a number of annotated datasets and <a href=https://en.wikipedia.org/wiki/Statistical_model>statistical models</a> for assessing factuality have been explored, there is no clear picture of what errors are most important to target or where current techniques are succeeding and failing. We explore both synthetic and human-labeled data sources for training models to identify factual errors in <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a>, and study <a href=https://en.wikipedia.org/wiki/Factuality>factuality</a> at the word-, dependency-, and sentence-level. Our observations are threefold. First, exhibited factual errors differ significantly across datasets, and commonly-used training sets of simple synthetic errors do not reflect errors made on abstractive datasets like XSum. Second, human-labeled data with fine-grained annotations provides a more effective training signal than sentence-level annotations or synthetic data. Finally, we show that our best factuality detection model enables training of more factual XSum summarization models by allowing us to identify non-factual tokens in the training data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.115.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--115 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.115 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.115/>Larger-Context Tagging : When and Why Does It Work?</a></strong><br><a href=/people/j/jinlan-fu/>Jinlan Fu</a>
|
<a href=/people/l/liangjing-feng/>Liangjing Feng</a>
|
<a href=/people/q/qi-zhang/>Qi Zhang</a>
|
<a href=/people/x/xuan-jing-huang/>Xuanjing Huang</a>
|
<a href=/people/p/pengfei-liu/>Pengfei Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--115><div class="card-body p-3 small">The development of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> and pretraining techniques has spawned many sentence-level tagging systems that achieved superior performance on typical benchmarks. However, a relatively less discussed topic is what if more <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context information</a> is introduced into current top-scoring tagging systems. Although several existing works have attempted to shift tagging systems from sentence-level to document-level, there is still no consensus conclusion about when and why it works, which limits the applicability of the larger-context approach in tagging tasks. In this paper, instead of pursuing a state-of-the-art tagging system by architectural exploration, we focus on investigating when and why the larger-context training, as a general strategy, can work. To this end, we conduct a thorough comparative study on four proposed aggregators for context information collecting and present an attribute-aided evaluation method to interpret the improvement brought by larger-context training. Experimentally, we set up a testbed based on four tagging tasks and thirteen datasets. Hopefully, our preliminary observations can deepen the understanding of larger-context training and enlighten more follow-up works on the use of <a href=https://en.wikipedia.org/wiki/Context_(language_use)>contextual information</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.116.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--116 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.116 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.116" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.116/>Neural Sequence Segmentation as Determining the Leftmost Segments</a></strong><br><a href=/people/y/yangming-li/>Yangming Li</a>
|
<a href=/people/l/lemao-liu/>Lemao Liu</a>
|
<a href=/people/k/kaisheng-yao/>Kaisheng Yao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--116><div class="card-body p-3 small">Prior methods to <a href=https://en.wikipedia.org/wiki/Text_segmentation>text segmentation</a> are mostly at <a href=https://en.wikipedia.org/wiki/Lexical_analysis>token level</a>. Despite the adequacy, this nature limits their full potential to capture the long-term dependencies among segments. In this work, we propose a novel <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> that incrementally segments <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>natural language sentences</a> at segment level. For every step in segmentation, it recognizes the leftmost segment of the remaining sequence. Implementations involve LSTM-minus technique to construct the phrase representations and <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural networks (RNN)</a> to model the iterations of determining the leftmost segments. We have conducted extensive experiments on syntactic chunking and Chinese part-of-speech (POS) tagging across 3 datasets, demonstrating that our methods have significantly outperformed previous all baselines and achieved new state-of-the-art results. Moreover, <a href=https://en.wikipedia.org/wiki/Qualitative_research>qualitative analysis</a> and the study on segmenting long-length sentences verify its effectiveness in modeling long-term dependencies.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.123.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--123 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.123 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.123/>Put Chatbot into Its Interlocutor’s Shoes : New Framework to Learn Chatbot Responding with Intention</a></strong><br><a href=/people/h/hsuan-su/>Hsuan Su</a>
|
<a href=/people/j/jiun-hao-jhan/>Jiun-Hao Jhan</a>
|
<a href=/people/f/fan-yun-sun/>Fan-yun Sun</a>
|
<a href=/people/s/saurav-sahay/>Saurav Sahay</a>
|
<a href=/people/h/hung-yi-lee/>Hung-yi Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--123><div class="card-body p-3 small">Most chatbot literature that focuses on improving the <a href=https://en.wikipedia.org/wiki/Fluency>fluency</a> and coherence of a <a href=https://en.wikipedia.org/wiki/Chatbot>chatbot</a>, is dedicated to making <a href=https://en.wikipedia.org/wiki/Chatbot>chatbots</a> more human-like. However, very little work delves into what really separates humans from chatbots humans intrinsically understand the effect their responses have on the interlocutor and often respond with an intention such as proposing an optimistic view to make the interlocutor feel better. This paper proposes an innovative <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> to train <a href=https://en.wikipedia.org/wiki/Chatbot>chatbots</a> to possess human-like intentions. Our framework includes a guiding chatbot and an interlocutor model that plays the role of humans. The guiding chatbot is assigned an intention and learns to induce the interlocutor to reply with responses matching the intention, for example, long responses, joyful responses, responses with specific words, etc. We examined our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> using three experimental setups and evaluated the guiding chatbot with four different <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> to demonstrate flexibility and performance advantages. Additionally, we performed trials with human interlocutors to substantiate the guiding chatbot&#8217;s effectiveness in influencing the responses of humans to a certain extent. Code will be made available to the public.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.124.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--124 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.124 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.124/>Adding Chit-Chat to Enhance Task-Oriented Dialogues</a></strong><br><a href=/people/k/kai-sun/>Kai Sun</a>
|
<a href=/people/s/seungwhan-moon/>Seungwhan Moon</a>
|
<a href=/people/p/paul-a-crook/>Paul Crook</a>
|
<a href=/people/s/stephen-roller/>Stephen Roller</a>
|
<a href=/people/b/becka-silvert/>Becka Silvert</a>
|
<a href=/people/b/bing-liu/>Bing Liu</a>
|
<a href=/people/z/zhiguang-wang/>Zhiguang Wang</a>
|
<a href=/people/h/honglei-liu/>Honglei Liu</a>
|
<a href=/people/e/eunjoon-cho/>Eunjoon Cho</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--124><div class="card-body p-3 small">Existing dialogue corpora and <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> are typically designed under two disjoint motives : while task-oriented systems focus on achieving functional goals (e.g., booking hotels), open-domain chatbots aim at making socially engaging conversations. In this work, we propose to integrate both types of systems by Adding <a href=https://en.wikipedia.org/wiki/Chit-chat>Chit-Chat</a> to ENhance Task-ORiented dialogues (ACCENTOR), with the goal of making virtual assistant conversations more engaging and interactive. Specifically, we propose a Human-AI collaborative data collection approach for generating diverse chit-chat responses to augment task-oriented dialogues with minimal annotation effort. We then present our new chit-chat-based annotations to 23.8 K dialogues from two popular <a href=https://en.wikipedia.org/wiki/Task_(computing)>task-oriented datasets</a> (Schema-Guided Dialogue and MultiWOZ 2.1) and demonstrate their advantage over the originals via human evaluation. Lastly, we propose three new models for adding <a href=https://en.wikipedia.org/wiki/Chit-chat>chit-chat</a> to task-oriented dialogues, explicitly trained to predict user goals and to generate contextually relevant chit-chat responses. Automatic and human evaluations show that, compared with the state-of-the-art task-oriented baseline, our models can code-switch between task and chit-chat to be more engaging, interesting, knowledgeable, and humanlike, while maintaining competitive task performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.129.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--129 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.129 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.129" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.129/>Did they answer? Subjective acts and intents in <a href=https://en.wikipedia.org/wiki/Conversation>conversational discourse</a></a></strong><br><a href=/people/e/elisa-ferracane/>Elisa Ferracane</a>
|
<a href=/people/g/greg-durrett/>Greg Durrett</a>
|
<a href=/people/j/junyi-jessy-li/>Junyi Jessy Li</a>
|
<a href=/people/k/katrin-erk/>Katrin Erk</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--129><div class="card-body p-3 small">Discourse signals are often implicit, leaving it up to the interpreter to draw the required inferences. At the same time, <a href=https://en.wikipedia.org/wiki/Discourse>discourse</a> is embedded in a <a href=https://en.wikipedia.org/wiki/Social_environment>social context</a>, meaning that interpreters apply their own assumptions and beliefs when resolving these inferences, leading to multiple, valid interpretations. However, current <a href=https://en.wikipedia.org/wiki/Discourse_analysis>discourse data</a> and frameworks ignore the <a href=https://en.wikipedia.org/wiki/Social_relation>social aspect</a>, expecting only a single ground truth. We present the first <a href=https://en.wikipedia.org/wiki/Discourse_analysis>discourse dataset</a> with multiple and subjective interpretations of English conversation in the form of perceived conversation acts and intents. We carefully analyze our dataset and create computational models to (1) confirm our hypothesis that taking into account the bias of the interpreters leads to better predictions of the interpretations, (2) and show disagreements are nuanced and require a deeper understanding of the different contextual factors. We share our dataset and code at http://github.com/elisaF/subjective_discourse.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.130.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--130 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.130 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.130/>Evaluating the Impact of a Hierarchical Discourse Representation on Entity Coreference Resolution Performance</a></strong><br><a href=/people/s/sopan-khosla/>Sopan Khosla</a>
|
<a href=/people/j/james-fiacco/>James Fiacco</a>
|
<a href=/people/c/carolyn-rose/>Carolyn Rosé</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--130><div class="card-body p-3 small">Recent work on entity coreference resolution (CR) follows current trends in <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Learning</a> applied to embeddings and relatively simple task-related features. SOTA models do not make use of hierarchical representations of discourse structure. In this work, we leverage automatically constructed discourse parse trees within a neural approach and demonstrate a significant improvement on two benchmark entity coreference-resolution datasets. We explore how the impact varies depending upon the type of mention.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.131.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--131 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.131 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.131/>Bridging Resolution : Making Sense of the State of the Art</a></strong><br><a href=/people/h/hideo-kobayashi/>Hideo Kobayashi</a>
|
<a href=/people/v/vincent-ng/>Vincent Ng</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--131><div class="card-body p-3 small">While Yu and Poesio (2020) have recently demonstrated the superiority of their neural multi-task learning (MTL) model to rule-based approaches for bridging anaphora resolution, there is little understanding of (1) how it is better than the rule-based approaches (e.g., are the two approaches making similar or complementary mistakes?) and (2) what should be improved. To shed light on these issues, we (1) propose a hybrid rule-based and MTL approach that would enable a better understanding of their comparative strengths and weaknesses ; and (2) perform a manual analysis of the errors made by the MTL model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.135.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--135 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.135 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.135/>Mask Attention Networks : Rethinking and Strengthen Transformer</a></strong><br><a href=/people/z/zhihao-fan/>Zhihao Fan</a>
|
<a href=/people/y/yeyun-gong/>Yeyun Gong</a>
|
<a href=/people/d/dayiheng-liu/>Dayiheng Liu</a>
|
<a href=/people/z/zhongyu-wei/>Zhongyu Wei</a>
|
<a href=/people/s/siyuan-wang/>Siyuan Wang</a>
|
<a href=/people/j/jian-jiao/>Jian Jiao</a>
|
<a href=/people/n/nan-duan/>Nan Duan</a>
|
<a href=/people/r/ruofei-zhang/>Ruofei Zhang</a>
|
<a href=/people/x/xuan-jing-huang/>Xuanjing Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--135><div class="card-body p-3 small">Transformer is an attention-based neural network, which consists of two sublayers, namely, Self-Attention Network (SAN) and Feed-Forward Network (FFN). Existing research explores to enhance the two sublayers separately to improve the capability of Transformer for text representation. In this paper, we present a novel understanding of SAN and FFN as Mask Attention Networks (MANs) and show that they are two special cases of MANs with static mask matrices. However, their static mask matrices limit the capability for localness modeling in text representation learning. We therefore introduce a new layer named dynamic mask attention network (DMAN) with a learnable mask matrix which is able to model localness adaptively. To incorporate advantages of <a href=https://en.wikipedia.org/wiki/DMAN>DMAN</a>, SAN, and FFN, we propose a sequential layered structure to combine the three types of layers. Extensive experiments on various tasks, including <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a> and <a href=https://en.wikipedia.org/wiki/Automatic_summarization>text summarization</a> demonstrate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms the original Transformer.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.136.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--136 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.136 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.136" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.136/>ERNIE-Gram : Pre-Training with Explicitly N-Gram Masked Language Modeling for <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>Natural Language Understanding</a><span class=acl-fixed-case>ERNIE</span>-Gram: Pre-Training with Explicitly N-Gram Masked Language Modeling for Natural Language Understanding</a></strong><br><a href=/people/d/dongling-xiao/>Dongling Xiao</a>
|
<a href=/people/y/yu-kun-li/>Yu-Kun Li</a>
|
<a href=/people/h/han-zhang/>Han Zhang</a>
|
<a href=/people/y/yu-sun/>Yu Sun</a>
|
<a href=/people/h/hao-tian/>Hao Tian</a>
|
<a href=/people/h/hua-wu/>Hua Wu</a>
|
<a href=/people/h/haifeng-wang/>Haifeng Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--136><div class="card-body p-3 small">Coarse-grained linguistic information, such as named entities or phrases, facilitates adequately representation learning in pre-training. Previous works mainly focus on extending the objective of BERT&#8217;s Masked Language Modeling (MLM) from masking individual tokens to contiguous sequences of n tokens. We argue that such contiguously masking method neglects to model the intra-dependencies and inter-relation of coarse-grained linguistic information. As an alternative, we propose ERNIE-Gram, an explicitly n-gram masking method to enhance the integration of coarse-grained information into pre-training. In ERNIE-Gram, <a href=https://en.wikipedia.org/wiki/N-gram>n-grams</a> are masked and predicted directly using explicit n-gram identities rather than contiguous sequences of n tokens. Furthermore, ERNIE-Gram employs a generator model to sample plausible n-gram identities as optional n-gram masks and predict them in both coarse-grained and fine-grained manners to enable comprehensive n-gram prediction and relation modeling. We pre-train ERNIE-Gram on English and Chinese text corpora and fine-tune on 19 downstream tasks. Experimental results show that ERNIE-Gram outperforms previous pre-training models like XLNet and RoBERTa by a large margin, and achieves comparable results with state-of-the-art methods. The source codes and pre-trained models have been released at https://github.com/PaddlePaddle/ERNIE.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.137.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--137 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.137 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.137" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.137/>Lattice-BERT : Leveraging Multi-Granularity Representations in Chinese Pre-trained Language Models<span class=acl-fixed-case>BERT</span>: Leveraging Multi-Granularity Representations in <span class=acl-fixed-case>C</span>hinese Pre-trained Language Models</a></strong><br><a href=/people/y/yuxuan-lai/>Yuxuan Lai</a>
|
<a href=/people/y/yijia-liu/>Yijia Liu</a>
|
<a href=/people/y/yansong-feng/>Yansong Feng</a>
|
<a href=/people/s/songfang-huang/>Songfang Huang</a>
|
<a href=/people/d/dongyan-zhao/>Dongyan Zhao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--137><div class="card-body p-3 small">Chinese pre-trained language models usually process text as a sequence of characters, while ignoring more <a href=https://en.wikipedia.org/wiki/Granularity>coarse granularity</a>, e.g., <a href=https://en.wikipedia.org/wiki/Word>words</a>. In this work, we propose a novel pre-training paradigm for Chinese Lattice-BERT, which explicitly incorporates word representations along with <a href=https://en.wikipedia.org/wiki/Chinese_characters>characters</a>, thus can model a sentence in a multi-granularity manner. Specifically, we construct a <a href=https://en.wikipedia.org/wiki/Lattice_graph>lattice graph</a> from the <a href=https://en.wikipedia.org/wiki/Character_(computing)>characters</a> and words in a sentence and feed all these text units into transformers. We design a lattice position attention mechanism to exploit the <a href=https://en.wikipedia.org/wiki/Lattice_model_(physics)>lattice structures</a> in self-attention layers. We further propose a masked segment prediction task to push the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to learn from rich but redundant information inherent in <a href=https://en.wikipedia.org/wiki/Lattice_model_(physics)>lattices</a>, while avoiding learning unexpected tricks. Experiments on 11 Chinese natural language understanding tasks show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can bring an average increase of 1.5 % under the 12-layer setting, which achieves new state-of-the-art among base-size models on the CLUE benchmarks. Further analysis shows that Lattice-BERT can harness the <a href=https://en.wikipedia.org/wiki/Lattice_model_(physics)>lattice structures</a>, and the improvement comes from the exploration of <a href=https://en.wikipedia.org/wiki/Redundancy_(information_theory)>redundant information</a> and multi-granularity representations. Our code will be available at https://github.com/alibaba/pretrained-language-models/LatticeBERT.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.139.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--139 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.139 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.139" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.139/>UmlsBERT : Clinical Domain Knowledge Augmentation of Contextual Embeddings Using the Unified Medical Language System Metathesaurus<span class=acl-fixed-case>U</span>mls<span class=acl-fixed-case>BERT</span>: Clinical Domain Knowledge Augmentation of Contextual Embeddings Using the <span class=acl-fixed-case>U</span>nified <span class=acl-fixed-case>M</span>edical <span class=acl-fixed-case>L</span>anguage <span class=acl-fixed-case>S</span>ystem <span class=acl-fixed-case>M</span>etathesaurus</a></strong><br><a href=/people/g/george-michalopoulos/>George Michalopoulos</a>
|
<a href=/people/y/yuanxin-wang/>Yuanxin Wang</a>
|
<a href=/people/h/hussam-kaka/>Hussam Kaka</a>
|
<a href=/people/h/helen-chen/>Helen Chen</a>
|
<a href=/people/a/alexander-wong/>Alexander Wong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--139><div class="card-body p-3 small">Contextual word embedding models, such as BioBERT and Bio_ClinicalBERT, have achieved state-of-the-art results in biomedical natural language processing tasks by focusing their pre-training process on domain-specific corpora. However, such <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> do not take into consideration structured expert domain knowledge from a <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge base</a>. We introduce UmlsBERT, a contextual embedding model that integrates <a href=https://en.wikipedia.org/wiki/Domain_knowledge>domain knowledge</a> during the pre-training process via a novel knowledge augmentation strategy. More specifically, the augmentation on UmlsBERT with the Unified Medical Language System (UMLS) Metathesaurus is performed in two ways : i) connecting words that have the same underlying &#8216;concept&#8217; in UMLS and ii) leveraging semantic type knowledge in UMLS to create clinically meaningful input embeddings. By applying these two strategies, UmlsBERT can encode clinical domain knowledge into word embeddings and outperform existing domain-specific models on common named-entity recognition (NER) and clinical natural language inference tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.143.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--143 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.143 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.143" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.143/>Why Do Document-Level Polarity Classifiers Fail?</a></strong><br><a href=/people/k/karen-martins/>Karen Martins</a>
|
<a href=/people/p/pedro-o-s-vaz-de-melo/>Pedro O.S Vaz-de-Melo</a>
|
<a href=/people/r/rodrygo-santos/>Rodrygo Santos</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--143><div class="card-body p-3 small">Machine learning solutions are often criticized for the lack of explanation of their successes and failures. Understanding which instances are misclassified and why is essential to improve the <a href=https://en.wikipedia.org/wiki/Learning>learning process</a>. This work helps to fill this gap by proposing a <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> to characterize, quantify and measure the impact of hard instances in the task of polarity classification of movie reviews. We characterize such instances into two categories : neutrality, where the text does not convey a clear polarity, and discrepancy, where the polarity of the text is the opposite of its true rating. We quantify the number of hard instances in polarity classification of movie reviews and provide empirical evidence about the need to pay attention to such problematic instances, as they are much harder to classify, for both machine and human classifiers. To the best of our knowledge, this is the first systematic analysis of the impact of hard instances in polarity detection from well-formed textual reviews.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.147.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--147 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.147 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.147/>Domain Divergences : A Survey and Empirical Analysis</a></strong><br><a href=/people/a/abhinav-ramesh-kashyap/>Abhinav Ramesh Kashyap</a>
|
<a href=/people/d/devamanyu-hazarika/>Devamanyu Hazarika</a>
|
<a href=/people/m/min-yen-kan/>Min-Yen Kan</a>
|
<a href=/people/r/roger-zimmermann/>Roger Zimmermann</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--147><div class="card-body p-3 small">Domain divergence plays a significant role in estimating the performance of a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> in <a href=https://en.wikipedia.org/wiki/Domain_of_a_function>new domains</a>. While there is a significant literature on <a href=https://en.wikipedia.org/wiki/Divergence>divergence measures</a>, researchers find it hard to choose an appropriate <a href=https://en.wikipedia.org/wiki/Divergence>divergence</a> for a given NLP application. We address this shortcoming by both surveying the literature and through an empirical study. We develop a taxonomy of divergence measures consisting of three classes Information-theoretic, Geometric, and Higher-order measures and identify the relationships between them. Further, to understand the common use-cases of these measures, we recognise three novel applications 1) Data Selection, 2) Learning Representation, and 3) Decisions in the Wild and use it to organise our literature. From this, we identify that Information-theoretic measures are prevalent for 1) and 3), and Higher-order measures are more common for 2). To further help researchers choose appropriate measures to predict drop in performance an important aspect of Decisions in the Wild, we perform <a href=https://en.wikipedia.org/wiki/Correlation_and_dependence>correlation analysis</a> spanning 130 domain adaptation scenarios, 3 varied NLP tasks and 12 divergence measures identified from our survey. To calculate these divergences, we consider the current contextual word representations (CWR) and contrast with the older distributed representations. We find that traditional <a href=https://en.wikipedia.org/wiki/Measure_(mathematics)>measures</a> over word distributions still serve as strong baselines, while higher-order measures with CWR are effective.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.148.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--148 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.148 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.148/>Target-Aware Data Augmentation for Stance Detection</a></strong><br><a href=/people/y/yingjie-li/>Yingjie Li</a>
|
<a href=/people/c/cornelia-caragea/>Cornelia Caragea</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--148><div class="card-body p-3 small">The goal of stance detection is to identify whether the author of a text is in favor of, neutral or against a specific target. Despite substantial progress on this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, one of the remaining challenges is the scarcity of <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a>. Data augmentation is commonly used to address annotation scarcity by generating more training samples. However, the augmented sentences that are generated by existing methods are either less diversified or inconsistent with the given target and stance label. In this paper, we formulate the data augmentation of stance detection as a conditional masked language modeling task and augment the dataset by predicting the masked word conditioned on both its context and the auxiliary sentence that contains target and label information. Moreover, we propose another simple yet effective method that generates target-aware sentence by replacing a target mention with the other. Experimental results show that our proposed <a href=https://en.wikipedia.org/wiki/Methods_of_detecting_exoplanets>methods</a> significantly outperforms previous augmentation methods on 11 targets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.151.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--151 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.151 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.151/>Searchable Hidden Intermediates for End-to-End Models of Decomposable Sequence Tasks</a></strong><br><a href=/people/s/siddharth-dalmia/>Siddharth Dalmia</a>
|
<a href=/people/b/brian-yan/>Brian Yan</a>
|
<a href=/people/v/vikas-raunak/>Vikas Raunak</a>
|
<a href=/people/f/florian-metze/>Florian Metze</a>
|
<a href=/people/s/shinji-watanabe/>Shinji Watanabe</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--151><div class="card-body p-3 small">End-to-end approaches for sequence tasks are becoming increasingly popular. Yet for complex sequence tasks, like <a href=https://en.wikipedia.org/wiki/Speech_translation>speech translation</a>, systems that cascade several models trained on sub-tasks have shown to be superior, suggesting that the compositionality of cascaded systems simplifies learning and enables sophisticated search capabilities. In this work, we present an end-to-end framework that exploits compositionality to learn searchable hidden representations at intermediate stages of a sequence model using decomposed sub-tasks. These hidden intermediates can be improved using <a href=https://en.wikipedia.org/wiki/Beam_search>beam search</a> to enhance the overall performance and can also incorporate external models at intermediate stages of the <a href=https://en.wikipedia.org/wiki/Computer_network>network</a> to re-score or adapt towards out-of-domain data. One instance of the proposed framework is a Multi-Decoder model for <a href=https://en.wikipedia.org/wiki/Speech_translation>speech translation</a> that extracts the searchable hidden intermediates from a speech recognition sub-task. The model demonstrates the aforementioned benefits and outperforms the previous <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> by around +6 and +3 BLEU on the two test sets of Fisher-CallHome and by around +3 and +4 BLEU on the English-German and English-French test sets of MuST-C.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.153.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--153 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.153 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.naacl-main.153.OptionalSupplementaryCode.zip data-toggle=tooltip data-placement=top title="Optional supplementary code"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.naacl-main.153.OptionalSupplementaryData.zip data-toggle=tooltip data-placement=top title="Optional supplementary data"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.naacl-main.153/>Worldly Wise (WoW)-Cross-Lingual Knowledge Fusion for Fact-based Visual Spoken-Question Answering<span class=acl-fixed-case>W</span>o<span class=acl-fixed-case>W</span>) - Cross-Lingual Knowledge Fusion for Fact-based Visual Spoken-Question Answering</a></strong><br><a href=/people/k/kiran-ramnath/>Kiran Ramnath</a>
|
<a href=/people/l/leda-sari/>Leda Sari</a>
|
<a href=/people/m/mark-hasegawa-johnson/>Mark Hasegawa-Johnson</a>
|
<a href=/people/c/chang-yoo/>Chang Yoo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--153><div class="card-body p-3 small">Although <a href=https://en.wikipedia.org/wiki/Question_answering>Question-Answering</a> has long been of research interest, its accessibility to users through a <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech interface</a> and its support to multiple languages have not been addressed in prior studies. Towards these ends, we present a new task and a synthetically-generated dataset to do Fact-based Visual Spoken-Question Answering (FVSQA). FVSQA is based on the FVQA dataset, which requires a system to retrieve an entity from Knowledge Graphs (KGs) to answer a question about an image. In FVSQA, the question is spoken rather than typed. Three sub-tasks are proposed : (1) speech-to-text based, (2) end-to-end, without <a href=https://en.wikipedia.org/wiki/Speech-to-text>speech-to-text</a> as an intermediate component, and (3) cross-lingual, in which the question is spoken in a language different from that in which the KG is recorded. The end-to-end and cross-lingual tasks are the first to require world knowledge from a multi-relational KG as a differentiable layer in an end-to-end spoken language understanding task, hence the proposed reference implementation is called Worldly-Wise (WoW).WoW is shown to perform end-to-end cross-lingual FVSQA at same levels of accuracy across 3 languages-English, <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a>, and <a href=https://en.wikipedia.org/wiki/Turkish_language>Turkish</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.154.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--154 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.154 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.154/>Align-Refine : Non-Autoregressive Speech Recognition via Iterative Realignment</a></strong><br><a href=/people/e/ethan-a-chi/>Ethan A. Chi</a>
|
<a href=/people/j/julian-salazar/>Julian Salazar</a>
|
<a href=/people/k/katrin-kirchhoff/>Katrin Kirchhoff</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--154><div class="card-body p-3 small">Non-autoregressive encoder-decoder models greatly improve decoding speed over <a href=https://en.wikipedia.org/wiki/Autoregressive_model>autoregressive models</a>, at the expense of generation quality. To mitigate this, iterative decoding models repeatedly infill or refine the proposal of a non-autoregressive model. However, editing at the level of output sequences limits model flexibility. We instead propose * iterative realignment *, which by refining latent alignments allows more flexible edits in fewer steps. Our model, Align-Refine, is an end-to-end Transformer which iteratively realigns connectionist temporal classification (CTC) alignments. On the WSJ dataset, Align-Refine matches an autoregressive baseline with a 14x decoding speedup ; on LibriSpeech, we reach an LM-free test-other WER of 9.0 % (19 % relative improvement on comparable work) in three iterations. We release our code at https://github.com/amazon-research/align-refine.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.155.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--155 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.155 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.155" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.155/>Everything Has a Cause : Leveraging <a href=https://en.wikipedia.org/wiki/Causal_inference>Causal Inference</a> in Legal Text Analysis</a></strong><br><a href=/people/x/xiao-liu/>Xiao Liu</a>
|
<a href=/people/d/da-yin/>Da Yin</a>
|
<a href=/people/y/yansong-feng/>Yansong Feng</a>
|
<a href=/people/y/yuting-wu/>Yuting Wu</a>
|
<a href=/people/d/dongyan-zhao/>Dongyan Zhao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--155><div class="card-body p-3 small">Causal inference is the process of capturing cause-effect relationship among variables. Most existing works focus on dealing with <a href=https://en.wikipedia.org/wiki/Structured_data>structured data</a>, while mining causal relationship among factors from <a href=https://en.wikipedia.org/wiki/Unstructured_data>unstructured data</a>, like text, has been less examined, but is of great importance, especially in the <a href=https://en.wikipedia.org/wiki/Legal_research>legal domain</a>. In this paper, we propose a novel Graph-based Causal Inference (GCI) framework, which builds causal graphs from fact descriptions without much human involvement and enables causal inference to facilitate legal practitioners to make proper decisions. We evaluate the <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> on a challenging similar charge disambiguation task. Experimental results show that GCI can capture the nuance from fact descriptions among multiple confusing charges and provide explainable discrimination, especially in few-shot settings. We also observe that the <a href=https://en.wikipedia.org/wiki/Causality>causal knowledge</a> contained in GCI can be effectively injected into powerful <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> for better performance and <a href=https://en.wikipedia.org/wiki/Interpretability>interpretability</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.156.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--156 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.156 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.156" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.156/>Counterfactual Supporting Facts Extraction for Explainable Medical Record Based Diagnosis with Graph Network</a></strong><br><a href=/people/h/haoran-wu/>Haoran Wu</a>
|
<a href=/people/w/wei-chen/>Wei Chen</a>
|
<a href=/people/s/shuang-xu/>Shuang Xu</a>
|
<a href=/people/b/bo-xu/>Bo Xu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--156><div class="card-body p-3 small">Providing a reliable explanation for <a href=https://en.wikipedia.org/wiki/Medical_diagnosis>clinical diagnosis</a> based on the Electronic Medical Record (EMR) is fundamental to the application of <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>Artificial Intelligence</a> in the <a href=https://en.wikipedia.org/wiki/Medicine>medical field</a>. Current methods mostly treat the <a href=https://en.wikipedia.org/wiki/Electronic_health_record>EMR</a> as a text sequence and provide explanations based on a precise medical knowledge base, which is disease-specific and difficult to obtain for experts in reality. Therefore, we propose a counterfactual multi-granularity graph supporting facts extraction (CMGE) method to extract supporting facts from irregular EMR itself without external knowledge bases in this paper. Specifically, we first structure the sequence of EMR into a hierarchical graph network and then obtain the causal relationship between multi-granularity features and diagnosis results through counterfactual intervention on the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a>. Features having the strongest causal connection with the results provide interpretive support for the <a href=https://en.wikipedia.org/wiki/Diagnosis>diagnosis</a>. Experimental results on real Chinese EMR of the <a href=https://en.wikipedia.org/wiki/Lymphedema>lymphedema</a> demonstrate that our method can diagnose four types of <a href=https://en.wikipedia.org/wiki/Electrophysiology>EMR</a> correctly, and can provide accurate supporting facts for the results. More importantly, the results on different diseases demonstrate the robustness of our approach, which represents the potential application in the <a href=https://en.wikipedia.org/wiki/Medicine>medical field</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.157.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--157 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.157 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.naacl-main.157.OptionalSupplementaryData.pdf data-toggle=tooltip data-placement=top title="Optional supplementary data"><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.157" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.157/>Personalized Response Generation via Generative Split Memory Network</a></strong><br><a href=/people/y/yuwei-wu/>Yuwei Wu</a>
|
<a href=/people/x/xuezhe-ma/>Xuezhe Ma</a>
|
<a href=/people/d/diyi-yang/>Diyi Yang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--157><div class="card-body p-3 small">Despite the impressive successes of generation and dialogue systems, how to endow a text generation system with particular <a href=https://en.wikipedia.org/wiki/Trait_theory>personality traits</a> to deliver more personalized responses remains under-investigated. In this work, we look at how to generate personalized responses for questions on Reddit by utilizing personalized user profiles and posting histories. Specifically, we release an open-domain single-turn dialog dataset made up of 1.5 M conversation pairs together with 300k profiles of users and related comments. We then propose a memory network to generate personalized responses in dialogue that utilizes a novel mechanism of splitting memories : one for user profile meta attributes and the other for user-generated information like comment histories. Experimental results show the quantitative and qualitative improvements of our simple split memory network model over the state-of-the-art response generation baselines.<i>single-turn</i> dialog dataset made up of 1.5M conversation pairs together with 300k profiles of users and related comments. We then propose a memory network to generate personalized responses in dialogue that utilizes a novel mechanism of splitting memories: one for user profile meta attributes and the other for user-generated information like comment histories. Experimental results show the quantitative and qualitative improvements of our simple split memory network model over the state-of-the-art response generation baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.158.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--158 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.158 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.158/>Towards Few-shot Fact-Checking via Perplexity</a></strong><br><a href=/people/n/nayeon-lee/>Nayeon Lee</a>
|
<a href=/people/y/yejin-bang/>Yejin Bang</a>
|
<a href=/people/a/andrea-madotto/>Andrea Madotto</a>
|
<a href=/people/p/pascale-fung/>Pascale Fung</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--158><div class="card-body p-3 small">Few-shot learning has drawn researchers&#8217; attention to overcome the problem of data scarcity. Recently, large pre-trained language models have shown great performance in few-shot learning for various downstream tasks, such as <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a> and <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. Nevertheless, little exploration has been made to achieve few-shot learning for the fact-checking task. However, <a href=https://en.wikipedia.org/wiki/Fact-checking>fact-checking</a> is an important problem, especially when the amount of information online is growing exponentially every day. In this paper, we propose a new way of utilizing the powerful transfer learning ability of a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> via a perplexity score. The most notable strength of our <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> lies in its capability in few-shot learning. With only two training samples, our methodology can already outperform the Major Class baseline by more than an absolute 10 % on the F1-Macro metric across multiple datasets. Through experiments, we empirically verify the plausibility of the rather surprising usage of the perplexity score in the context of <a href=https://en.wikipedia.org/wiki/Fact-checking>fact-checking</a> and highlight the strength of our few-shot methodology by comparing it to strong fine-tuning-based baseline models. Moreover, we construct and publicly release two new fact-checking datasets related to COVID-19.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.161.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--161 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.161 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.161" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.161/>Model Extraction and Adversarial Transferability, Your BERT is Vulnerable !<span class=acl-fixed-case>BERT</span> is Vulnerable!</a></strong><br><a href=/people/x/xuanli-he/>Xuanli He</a>
|
<a href=/people/l/lingjuan-lyu/>Lingjuan Lyu</a>
|
<a href=/people/l/lichao-sun/>Lichao Sun</a>
|
<a href=/people/q/qiongkai-xu/>Qiongkai Xu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--161><div class="card-body p-3 small">Natural language processing (NLP) tasks, ranging from <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a> to text generation, have been revolutionised by the pretrained language models, such as BERT. This allows corporations to easily build powerful <a href=https://en.wikipedia.org/wiki/Application_programming_interface>APIs</a> by encapsulating fine-tuned BERT models for <a href=https://en.wikipedia.org/wiki/Downstream_(networking)>downstream tasks</a>. However, when a fine-tuned BERT model is deployed as a service, it may suffer from different attacks launched by the malicious users. In this work, we first present how an adversary can steal a BERT-based API service (the victim / target model) on multiple benchmark datasets with limited prior knowledge and queries. We further show that the extracted <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can lead to highly transferable adversarial attacks against the victim model. Our studies indicate that the potential vulnerabilities of BERT-based API services still hold, even when there is an architectural mismatch between the victim model and the <a href=https://en.wikipedia.org/wiki/Attack_model>attack model</a>. Finally, we investigate two defence strategies to protect the victim model, and find that unless the performance of the victim model is sacrificed, both model extraction and adversarial transferability can effectively compromise the target models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.166.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--166 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.166 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.166/>DA-Transformer : Distance-aware Transformer<span class=acl-fixed-case>DA</span>-Transformer: Distance-aware Transformer</a></strong><br><a href=/people/c/chuhan-wu/>Chuhan Wu</a>
|
<a href=/people/f/fangzhao-wu/>Fangzhao Wu</a>
|
<a href=/people/y/yongfeng-huang/>Yongfeng Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--166><div class="card-body p-3 small">Transformer has achieved great success in the NLP field by composing various advanced <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> like BERT and GPT. However, Transformer and its existing variants may not be optimal in capturing token distances because the position or distance embeddings used by these methods usually can not keep the precise information of real distances, which may not be beneficial for modeling the orders and relations of contexts. In this paper, we propose DA-Transformer, which is a distance-aware Transformer that can exploit the real distance. We propose to incorporate the real distances between tokens to re-scale the raw self-attention weights, which are computed by the <a href=https://en.wikipedia.org/wiki/Relevance_(information_retrieval)>relevance</a> between attention query and key. Concretely, in different self-attention heads the relative distance between each pair of tokens is weighted by different learnable parameters, which control the different preferences on long- or short-term information of these heads. Since the raw weighted real distances may not be optimal for adjusting self-attention weights, we propose a learnable sigmoid function to map them into re-scaled coefficients that have proper ranges. We first clip the raw self-attention weights via the ReLU function to keep non-negativity and introduce sparsity, and then multiply them with the re-scaled coefficients to encode real distance information into self-attention. Extensive experiments on five benchmark datasets show that DA-Transformer can effectively improve the performance of many tasks and outperform the vanilla Transformer and its several variants.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.170.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--170 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.170 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.naacl-main.170.OptionalSupplementaryData.pdf data-toggle=tooltip data-placement=top title="Optional supplementary data"><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.170" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.170/>KPQA : A <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>Metric</a> for Generative Question Answering Using Keyphrase Weights<span class=acl-fixed-case>KPQA</span>: A Metric for Generative Question Answering Using Keyphrase Weights</a></strong><br><a href=/people/h/hwanhee-lee/>Hwanhee Lee</a>
|
<a href=/people/s/seunghyun-yoon/>Seunghyun Yoon</a>
|
<a href=/people/f/franck-dernoncourt/>Franck Dernoncourt</a>
|
<a href=/people/d/doo-soon-kim/>Doo Soon Kim</a>
|
<a href=/people/t/trung-bui/>Trung Bui</a>
|
<a href=/people/j/joongbo-shin/>Joongbo Shin</a>
|
<a href=/people/k/kyomin-jung/>Kyomin Jung</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--170><div class="card-body p-3 small">In the automatic evaluation of generative question answering (GenQA) systems, it is difficult to assess the correctness of generated answers due to the free-form of the answer. Especially, widely used n-gram similarity metrics often fail to discriminate the incorrect answers since they equally consider all of the tokens. To alleviate this problem, we propose KPQA metric, a new <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> for evaluating the correctness of GenQA. Specifically, our new <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> assigns different weights to each token via keyphrase prediction, thereby judging whether a generated answer sentence captures the key meaning of the reference answer. To evaluate our <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a>, we create high-quality human judgments of correctness on two GenQA datasets. Using our human-evaluation datasets, we show that our proposed <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> has a significantly higher correlation with human judgments than existing <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> in various <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>. Code for KPQA-metric will be available at https://github.com/hwanheelee1993/KPQA.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.179.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--179 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.179 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.179" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.179/>Modeling Framing in Immigration Discourse on <a href=https://en.wikipedia.org/wiki/Social_media>Social Media</a></a></strong><br><a href=/people/j/julia-mendelsohn/>Julia Mendelsohn</a>
|
<a href=/people/c/ceren-budak/>Ceren Budak</a>
|
<a href=/people/d/david-jurgens/>David Jurgens</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--179><div class="card-body p-3 small">The framing of political issues can influence <a href=https://en.wikipedia.org/wiki/Policy>policy</a> and public opinion. Even though the public plays a key role in creating and spreading frames, little is known about how ordinary people on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> frame political issues. By creating a new dataset of immigration-related tweets labeled for multiple <a href=https://en.wikipedia.org/wiki/Framing_(social_sciences)>framing typologies</a> from political communication theory, we develop <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised models</a> to detect <a href=https://en.wikipedia.org/wiki/Framing_(social_sciences)>frames</a>. We demonstrate how users&#8217; ideology and region impact framing choices, and how a message&#8217;s framing influences audience responses. We find that the more commonly-used issue-generic frames obscure important ideological and regional patterns that are only revealed by immigration-specific frames. Furthermore, <a href=https://en.wikipedia.org/wiki/Framing_(social_sciences)>frames</a> oriented towards human interests, culture, and <a href=https://en.wikipedia.org/wiki/Politics>politics</a> are associated with higher <a href=https://en.wikipedia.org/wiki/User_engagement>user engagement</a>. This large-scale analysis of a complex social and linguistic phenomenon contributes to both NLP and social science research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.184.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--184 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.184 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.184/>Learning to Recognize Dialect Features</a></strong><br><a href=/people/d/dorottya-demszky/>Dorottya Demszky</a>
|
<a href=/people/d/devyani-sharma/>Devyani Sharma</a>
|
<a href=/people/j/jonathan-h-clark/>Jonathan Clark</a>
|
<a href=/people/v/vinodkumar-prabhakaran/>Vinodkumar Prabhakaran</a>
|
<a href=/people/j/jacob-eisenstein/>Jacob Eisenstein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--184><div class="card-body p-3 small">Building <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP systems</a> that serve everyone requires accounting for <a href=https://en.wikipedia.org/wiki/Dialect>dialect differences</a>. But <a href=https://en.wikipedia.org/wiki/List_of_dialects_of_English>dialects</a> are not monolithic entities : rather, distinctions between and within dialects are captured by the presence, absence, and frequency of dozens of <a href=https://en.wikipedia.org/wiki/Dialect>dialect features</a> in speech and text, such as the deletion of the copula in He running. In this paper, we introduce the task of dialect feature detection, and present two multitask learning approaches, both based on pretrained transformers. For most <a href=https://en.wikipedia.org/wiki/Dialect>dialects</a>, large-scale annotated corpora for these <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>features</a> are unavailable, making it difficult to train recognizers. We train our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on a small number of minimal pairs, building on how linguists typically define <a href=https://en.wikipedia.org/wiki/Dialect>dialect features</a>. Evaluation on a test set of 22 dialect features of <a href=https://en.wikipedia.org/wiki/Indian_English>Indian English</a> demonstrates that these models learn to recognize many <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> with high accuracy, and that a few minimal pairs can be as effective for training as thousands of labeled examples. We also demonstrate the downstream applicability of dialect feature detection both as a measure of <a href=https://en.wikipedia.org/wiki/Dialect_continuum>dialect density</a> and as a dialect classifier.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.187.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--187 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.187 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.187" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.187/>Highly Efficient Knowledge Graph Embedding Learning with Orthogonal Procrustes Analysis<span class=acl-fixed-case>O</span>rthogonal <span class=acl-fixed-case>P</span>rocrustes <span class=acl-fixed-case>A</span>nalysis</a></strong><br><a href=/people/x/xutan-peng/>Xutan Peng</a>
|
<a href=/people/g/guanyi-chen/>Guanyi Chen</a>
|
<a href=/people/c/chenghua-lin/>Chenghua Lin</a>
|
<a href=/people/m/mark-stevenson/>Mark Stevenson</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--187><div class="card-body p-3 small">Knowledge Graph Embeddings (KGEs) have been intensively explored in recent years due to their promise for a wide range of applications. However, existing studies focus on improving the final <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performance without acknowledging the <a href=https://en.wikipedia.org/wiki/Computational_cost>computational cost</a> of the proposed approaches, in terms of <a href=https://en.wikipedia.org/wiki/Time_complexity>execution time</a> and environmental impact. This paper proposes a simple yet effective KGE framework which can reduce the training time and <a href=https://en.wikipedia.org/wiki/Carbon_footprint>carbon footprint</a> by orders of magnitudes compared with state-of-the-art approaches, while producing competitive performance. We highlight three technical innovations : full batch learning via relational matrices, closed-form Orthogonal Procrustes Analysis for KGEs, and non-negative-sampling training. In addition, as the first KGE method whose entity embeddings also store full relation information, our trained models encode rich semantics and are highly interpretable. Comprehensive experiments and ablation studies involving 13 strong baselines and two standard datasets verify the effectiveness and efficiency of our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.188.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--188 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.188 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.naacl-main.188.OptionalSupplementaryCode.zip data-toggle=tooltip data-placement=top title="Optional supplementary code"><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.188" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.188/>Rethinking Network Pruning under the Pre-train and Fine-tune Paradigm</a></strong><br><a href=/people/d/dongkuan-xu/>Dongkuan Xu</a>
|
<a href=/people/i/ian-en-hsu-yen/>Ian En-Hsu Yen</a>
|
<a href=/people/j/jinxi-zhao/>Jinxi Zhao</a>
|
<a href=/people/z/zhibin-xiao/>Zhibin Xiao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--188><div class="card-body p-3 small">Transformer-based pre-trained language models have significantly improved the performance of various natural language processing (NLP) tasks in the recent years. While effective and prevalent, these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are usually prohibitively large for resource-limited deployment scenarios. A thread of research has thus been working on applying network pruning techniques under the pretrain-then-finetune paradigm widely adopted in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. However, the existing <a href=https://en.wikipedia.org/wiki/Pruning>pruning</a> results on benchmark transformers, such as BERT, are not as remarkable as the pruning results in the literature of convolutional neural networks (CNNs). In particular, common wisdom in pruning CNN states that sparse pruning technique compresses a model more than that obtained by reducing number of channels and layers, while existing works on sparse pruning of BERT yields inferior results than its small-dense counterparts such as TinyBERT. In this work, we aim to fill this gap by studying how knowledge are transferred and lost during the pre-train, fine-tune, and pruning process, and proposing a knowledge-aware sparse pruning process that achieves significantly superior results than existing literature. We show for the first time that sparse pruning compresses a BERT model significantly more than reducing its number of channels and layers. Experiments on multiple data sets of GLUE benchmark show that our method outperforms the leading competitors with a 20-times weight / FLOPs compression and neglectable loss in prediction accuracy.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.190.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--190 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.190 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.190" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.190/>Detoxifying Language Models Risks Marginalizing Minority Voices</a></strong><br><a href=/people/a/albert-xu/>Albert Xu</a>
|
<a href=/people/e/eshaan-pathak/>Eshaan Pathak</a>
|
<a href=/people/e/eric-wallace/>Eric Wallace</a>
|
<a href=/people/s/suchin-gururangan/>Suchin Gururangan</a>
|
<a href=/people/m/maarten-sap/>Maarten Sap</a>
|
<a href=/people/d/dan-klein/>Dan Klein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--190><div class="card-body p-3 small">Language models (LMs) must be both safe and equitable to be responsibly deployed in practice. With safety in mind, numerous detoxification techniques (e.g., Dathathri et al. 2020 ; Krause et al. 2020) have been proposed to mitigate toxic LM generations. In this work, we show that these detoxification techniques hurt equity : they decrease the utility of LMs on language used by marginalized groups (e.g., African-American English and minority identity mentions). In particular, we perform automatic and human evaluations of text generation quality when LMs are conditioned on inputs with different <a href=https://en.wikipedia.org/wiki/Dialect>dialects</a> and group identifiers. We find that detoxification makes LMs more brittle to distribution shift, especially on language used by <a href=https://en.wikipedia.org/wiki/Social_exclusion>marginalized groups</a>. We identify that these failures stem from <a href=https://en.wikipedia.org/wiki/Detoxification_(alternative_medicine)>detoxification methods</a> exploiting spurious correlations in toxicity datasets. Overall, our results highlight the tension between the <a href=https://en.wikipedia.org/wiki/Controllability>controllability</a> and distributional robustness of LMs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.191.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--191 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.191 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.191/>HONEST : Measuring Hurtful Sentence Completion in Language Models<span class=acl-fixed-case>HONEST</span>: Measuring Hurtful Sentence Completion in Language Models</a></strong><br><a href=/people/d/debora-nozza/>Debora Nozza</a>
|
<a href=/people/f/federico-bianchi/>Federico Bianchi</a>
|
<a href=/people/d/dirk-hovy/>Dirk Hovy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--191><div class="card-body p-3 small">Language models have revolutionized the field of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. However, <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> capture and proliferate hurtful stereotypes, especially in <a href=https://en.wikipedia.org/wiki/Text_generation>text generation</a>. Our results show that 4.3 % of the time, <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> complete a sentence with a hurtful word. These cases are not random, but follow language and gender-specific patterns. We propose a <a href=https://en.wikipedia.org/wiki/Score_(statistics)>score</a> to measure hurtful sentence completions in language models (HONEST). It uses a systematic template- and lexicon-based bias evaluation methodology for six languages. Our findings suggest that these <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> replicate and amplify deep-seated societal stereotypes about <a href=https://en.wikipedia.org/wiki/Gender_role>gender roles</a>. Sentence completions refer to <a href=https://en.wikipedia.org/wiki/Promiscuity>sexual promiscuity</a> when the target is female in 9 % of the time, and in 4 % to <a href=https://en.wikipedia.org/wiki/Homosexuality>homosexuality</a> when the target is male. The results raise questions about the use of these <a href=https://en.wikipedia.org/wiki/Physical_model>models</a> in <a href=https://en.wikipedia.org/wiki/Production_line>production settings</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.193.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--193 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.193 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.193" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.193/>DeCEMBERT : Learning from Noisy Instructional Videos via Dense Captions and Entropy Minimization<span class=acl-fixed-case>D</span>e<span class=acl-fixed-case>CEMBERT</span>: Learning from Noisy Instructional Videos via Dense Captions and Entropy Minimization</a></strong><br><a href=/people/z/zineng-tang/>Zineng Tang</a>
|
<a href=/people/j/jie-lei/>Jie Lei</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--193><div class="card-body p-3 small">Leveraging large-scale unlabeled web videos such as instructional videos for pre-training followed by task-specific finetuning has become the de facto approach for many video-and-language tasks. However, these instructional videos are very noisy, the accompanying ASR narrations are often incomplete, and can be irrelevant to or temporally misaligned with the visual content, limiting the performance of the models trained on such data. To address these issues, we propose an improved video-and-language pre-training method that first adds automatically-extracted dense region captions from the video frames as auxiliary text input, to provide informative visual cues for learning better video and language associations. Second, to alleviate the temporal misalignment issue, our method incorporates an entropy minimization-based constrained attention loss, to encourage the model to automatically focus on the correct caption from a pool of candidate ASR captions. Our overall approach is named DeCEMBERT (Dense Captions and Entropy Minimization). Comprehensive experiments on three video-and-language tasks (text-to-video retrieval, video captioning, and video question answering) across five datasets demonstrate that our approach outperforms previous state-of-the-art methods. Ablation studies on pre-training and downstream tasks show that adding dense captions and constrained attention loss help improve the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performance. Lastly, we also provide attention visualization to show the effect of applying the proposed constrained attention loss.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.195.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--195 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.195 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.naacl-main.195.OptionalSupplementaryData.txt data-toggle=tooltip data-placement=top title="Optional supplementary data"><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.195" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.195/>Multilingual Multimodal Pre-training for Zero-Shot Cross-Lingual Transfer of Vision-Language Models</a></strong><br><a href=/people/p/po-yao-huang/>Po-Yao Huang</a>
|
<a href=/people/m/mandela-patrick/>Mandela Patrick</a>
|
<a href=/people/j/junjie-hu/>Junjie Hu</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/f/florian-metze/>Florian Metze</a>
|
<a href=/people/a/alexander-g-hauptmann/>Alexander Hauptmann</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--195><div class="card-body p-3 small">This paper studies zero-shot cross-lingual transfer of vision-language models. Specifically, we focus on multilingual text-to-video search and propose a Transformer-based model that learns contextual multilingual multimodal embeddings. Under a zero-shot setting, we empirically demonstrate that performance degrades significantly when we query the multilingual text-video model with non-English sentences. To address this problem, we introduce a multilingual multimodal pre-training strategy, and collect a new multilingual instructional video dataset (Multi-HowTo100 M) for pre-training. Experiments on VTT show that our method significantly improves <a href=https://en.wikipedia.org/wiki/Video_search_engine>video search</a> in non-English languages without additional annotations. Furthermore, when multilingual annotations are available, our method outperforms recent baselines by a large margin in multilingual text-to-video search on VTT and VATEX ; as well as in multilingual text-to-image search on Multi30K. Our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> and Multi-HowTo100 M is available at http://github.com/berniebear/Multi-HT100M.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.196.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--196 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.196 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.196/>Video Question Answering with Phrases via Semantic Roles</a></strong><br><a href=/people/a/arka-sadhu/>Arka Sadhu</a>
|
<a href=/people/k/kan-chen/>Kan Chen</a>
|
<a href=/people/r/ram-nevatia/>Ram Nevatia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--196><div class="card-body p-3 small">Video Question Answering (VidQA) evaluation metrics have been limited to a single-word answer or selecting a phrase from a fixed set of phrases. These <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> limit the VidQA models&#8217; application scenario. In this work, we leverage semantic roles derived from video descriptions to mask out certain phrases, to introduce VidQAP which poses VidQA as a fill-in-the-phrase task. To enable evaluation of answer phrases, we compute the relative improvement of the predicted answer compared to an empty string. To reduce the influence of language bias in VidQA datasets, we retrieve a video having a different answer for the same question. To facilitate research, we construct ActivityNet-SRL-QA and Charades-SRL-QA and benchmark them by extending three vision-language models. We perform extensive analysis and ablative studies to guide future work. Code and data are public.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.197.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--197 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.197 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.197" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.197/>From Masked Language Modeling to <a href=https://en.wikipedia.org/wiki/Translation>Translation</a> : Non-English Auxiliary Tasks Improve Zero-shot Spoken Language Understanding<span class=acl-fixed-case>E</span>nglish Auxiliary Tasks Improve Zero-shot Spoken Language Understanding</a></strong><br><a href=/people/r/rob-van-der-goot/>Rob van der Goot</a>
|
<a href=/people/i/ibrahim-sharaf/>Ibrahim Sharaf</a>
|
<a href=/people/a/aizhan-imankulova/>Aizhan Imankulova</a>
|
<a href=/people/a/ahmet-ustun/>Ahmet Üstün</a>
|
<a href=/people/m/marija-stepanovic/>Marija Stepanović</a>
|
<a href=/people/a/alan-ramponi/>Alan Ramponi</a>
|
<a href=/people/s/siti-oryza-khairunnisa/>Siti Oryza Khairunnisa</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a>
|
<a href=/people/b/barbara-plank/>Barbara Plank</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--197><div class="card-body p-3 small">The lack of publicly available evaluation data for low-resource languages limits progress in Spoken Language Understanding (SLU). As key tasks like intent classification and slot filling require abundant training data, it is desirable to reuse existing <a href=https://en.wikipedia.org/wiki/Data>data</a> in high-resource languages to develop models for low-resource scenarios. We introduce xSID, a new benchmark for cross-lingual (x) Slot and Intent Detection in 13 languages from 6 language families, including a very low-resource dialect. To tackle the challenge, we propose a joint learning approach, with English SLU training data and non-English auxiliary tasks from raw text, <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a> and <a href=https://en.wikipedia.org/wiki/Translation>translation</a> for transfer. We study two setups which differ by type and language coverage of the pre-trained embeddings. Our results show that jointly learning the main tasks with masked language modeling is effective for slots, while machine translation transfer works best for intent classification.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.199.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--199 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.199 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.199" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.199/>Challenging <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>distributional models</a> with a conceptual network of philosophical terms</a></strong><br><a href=/people/y/yvette-oortwijn/>Yvette Oortwijn</a>
|
<a href=/people/j/jelke-bloem/>Jelke Bloem</a>
|
<a href=/people/p/pia-sommerauer/>Pia Sommerauer</a>
|
<a href=/people/f/francois-meyer/>Francois Meyer</a>
|
<a href=/people/w/wei-zhou/>Wei Zhou</a>
|
<a href=/people/a/antske-fokkens/>Antske Fokkens</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--199><div class="card-body p-3 small">Computational linguistic research on <a href=https://en.wikipedia.org/wiki/Language_change>language change</a> through distributional semantic (DS) models has inspired researchers from fields such as philosophy and literary studies, who use these methods for the exploration and comparison of comparatively small datasets traditionally analyzed by close reading. Research on <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> for <a href=https://en.wikipedia.org/wiki/Small_data>small data</a> is still in early stages and it is not clear which methods achieve the best results. We investigate the possibilities and limitations of using distributional semantic models for analyzing philosophical data by means of a realistic use-case. We provide a ground truth for evaluation created by philosophy experts and a blueprint for using DS models in a sound methodological setup. We compare three <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> for creating specialized models from <a href=https://en.wikipedia.org/wiki/Data_set>small datasets</a>. Though the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> do not perform well enough to directly support philosophers yet, we find that <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> designed for small data yield promising directions for future work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.200.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--200 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.200 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.200" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.200/>KILT : a Benchmark for Knowledge Intensive Language Tasks<span class=acl-fixed-case>KILT</span>: a Benchmark for Knowledge Intensive Language Tasks</a></strong><br><a href=/people/f/fabio-petroni/>Fabio Petroni</a>
|
<a href=/people/a/aleksandra-piktus/>Aleksandra Piktus</a>
|
<a href=/people/a/angela-fan/>Angela Fan</a>
|
<a href=/people/p/patrick-lewis/>Patrick Lewis</a>
|
<a href=/people/m/majid-yazdani/>Majid Yazdani</a>
|
<a href=/people/n/nicola-de-cao/>Nicola De Cao</a>
|
<a href=/people/j/james-thorne/>James Thorne</a>
|
<a href=/people/y/yacine-jernite/>Yacine Jernite</a>
|
<a href=/people/v/vladimir-karpukhin/>Vladimir Karpukhin</a>
|
<a href=/people/j/jean-maillard/>Jean Maillard</a>
|
<a href=/people/v/vassilis-plachouras/>Vassilis Plachouras</a>
|
<a href=/people/t/tim-rocktaschel/>Tim Rocktäschel</a>
|
<a href=/people/s/sebastian-riedel/>Sebastian Riedel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--200><div class="card-body p-3 small">Challenging problems such as open-domain question answering, <a href=https://en.wikipedia.org/wiki/Fact-checking>fact checking</a>, slot filling and <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity linking</a> require access to large, external knowledge sources. While some <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> do well on individual tasks, developing general models is difficult as each task might require computationally expensive indexing of custom knowledge sources, in addition to dedicated infrastructure. To catalyze research on <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> that condition on specific information in large textual resources, we present a <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmark</a> for knowledge-intensive language tasks (KILT). All tasks in KILT are grounded in the same snapshot of <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>, reducing <a href=https://en.wikipedia.org/wiki/Turnaround_time>engineering turnaround</a> through the re-use of components, as well as accelerating research into task-agnostic memory architectures. We test both task-specific and general baselines, evaluating downstream performance in addition to the ability of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> to provide <a href=https://en.wikipedia.org/wiki/Provenance>provenance</a>. We find that a shared dense vector index coupled with a seq2seq model is a strong baseline, outperforming more tailor-made approaches for fact checking, open-domain question answering and dialogue, and yielding competitive results on entity linking and slot filling, by generating disambiguated text. KILT data and code are available at https://github.com/facebookresearch/KILT.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.203.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--203 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.203 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.203" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.203/>UDALM : Unsupervised Domain Adaptation through <a href=https://en.wikipedia.org/wiki/Language_model>Language Modeling</a><span class=acl-fixed-case>UDALM</span>: Unsupervised Domain Adaptation through Language Modeling</a></strong><br><a href=/people/c/constantinos-karouzos/>Constantinos Karouzos</a>
|
<a href=/people/g/georgios-paraskevopoulos/>Georgios Paraskevopoulos</a>
|
<a href=/people/a/alexandros-potamianos/>Alexandros Potamianos</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--203><div class="card-body p-3 small">In this work we explore Unsupervised Domain Adaptation (UDA) of pretrained language models for downstream tasks. We introduce UDALM, a fine-tuning procedure, using a mixed classification and Masked Language Model loss, that can adapt to the target domain distribution in a robust and sample efficient manner. Our experiments show that performance of models trained with the mixed loss scales with the amount of available target data and the mixed loss can be effectively used as a stopping criterion during UDA training. Furthermore, we discuss the relationship between A-distance and the target error and explore some limitations of the Domain Adversarial Training approach. Our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> is evaluated on twelve domain pairs of the Amazon Reviews Sentiment dataset, yielding 91.74 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, which is an 1.11 % absolute improvement over the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.204.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--204 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.204 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.204/>Beyond Black & White : Leveraging Annotator Disagreement via Soft-Label Multi-Task Learning</a></strong><br><a href=/people/t/tommaso-fornaciari/>Tommaso Fornaciari</a>
|
<a href=/people/a/alexandra-uma/>Alexandra Uma</a>
|
<a href=/people/s/silviu-paun/>Silviu Paun</a>
|
<a href=/people/b/barbara-plank/>Barbara Plank</a>
|
<a href=/people/d/dirk-hovy/>Dirk Hovy</a>
|
<a href=/people/m/massimo-poesio/>Massimo Poesio</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--204><div class="card-body p-3 small">Supervised learning assumes that a ground truth label exists. However, the <a href=https://en.wikipedia.org/wiki/Reliability_(statistics)>reliability</a> of this ground truth depends on human annotators, who often disagree. Prior work has shown that this disagreement can be helpful in training <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. We propose a novel method to incorporate this disagreement as information : in addition to the standard error computation, we use soft-labels (i.e., probability distributions over the annotator labels) as an auxiliary task in a multi-task neural network. We measure the <a href=https://en.wikipedia.org/wiki/Divergence>divergence</a> between the predictions and the target soft-labels with several <a href=https://en.wikipedia.org/wiki/Loss_function>loss-functions</a> and evaluate the models on various <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP tasks</a>. We find that the soft-label prediction auxiliary task reduces the penalty for errors on ambiguous entities, and thereby mitigates <a href=https://en.wikipedia.org/wiki/Overfitting>overfitting</a>. It significantly improves performance across <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>, beyond the standard approach and prior work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.205.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--205 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.205 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.205/>Clustering-based Inference for Biomedical Entity Linking</a></strong><br><a href=/people/r/rico-angell/>Rico Angell</a>
|
<a href=/people/n/nicholas-monath/>Nicholas Monath</a>
|
<a href=/people/s/sunil-mohan/>Sunil Mohan</a>
|
<a href=/people/n/nishant-yadav/>Nishant Yadav</a>
|
<a href=/people/a/andrew-mccallum/>Andrew McCallum</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--205><div class="card-body p-3 small">Due to large number of entities in biomedical knowledge bases, only a small fraction of entities have corresponding labelled training data. This necessitates entity linking models which are able to link mentions of unseen entities using learned representations of entities. Previous approaches link each mention independently, ignoring the relationships within and across documents between the entity mentions. These relations can be very useful for linking mentions in biomedical text where linking decisions are often difficult due mentions having a generic or a highly specialized form. In this paper, we introduce a model in which linking decisions can be made not merely by linking to a knowledge base entity but also by grouping multiple mentions together via <a href=https://en.wikipedia.org/wiki/Cluster_analysis>clustering</a> and jointly making linking predictions. In experiments on the largest publicly available biomedical dataset, we improve the best <a href=https://en.wikipedia.org/wiki/Independence_(probability_theory)>independent prediction</a> for <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity linking</a> by 3.0 points of <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, and our clustering-based inference model further improves <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity linking</a> by 2.3 points.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.207.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--207 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.207 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.207" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.207/>Diversity-Aware Batch Active Learning for Dependency Parsing</a></strong><br><a href=/people/t/tianze-shi/>Tianze Shi</a>
|
<a href=/people/a/adrian-benton/>Adrian Benton</a>
|
<a href=/people/i/igor-malioutov/>Igor Malioutov</a>
|
<a href=/people/o/ozan-irsoy/>Ozan İrsoy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--207><div class="card-body p-3 small">While the predictive performance of modern statistical dependency parsers relies heavily on the availability of expensive expert-annotated treebank data, not all annotations contribute equally to the training of the <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a>. In this paper, we attempt to reduce the number of labeled examples needed to train a strong dependency parser using batch active learning (AL). In particular, we investigate whether enforcing diversity in the sampled batches, using determinantal point processes (DPPs), can improve over their diversity-agnostic counterparts. Simulation experiments on an English newswire corpus show that selecting diverse batches with DPPs is superior to strong selection strategies that do not enforce batch diversity, especially during the initial stages of the learning process. Additionally, our diversity-aware strategy is robust under a corpus duplication setting, where diversity-agnostic sampling strategies exhibit significant degradation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.209.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--209 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.209 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.209/>Can Latent Alignments Improve Autoregressive Machine Translation?</a></strong><br><a href=/people/a/adi-haviv/>Adi Haviv</a>
|
<a href=/people/l/lior-vassertail/>Lior Vassertail</a>
|
<a href=/people/o/omer-levy/>Omer Levy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--209><div class="card-body p-3 small">Latent alignment objectives such as CTC and AXE significantly improve non-autoregressive machine translation models. Can they improve <a href=https://en.wikipedia.org/wiki/Autoregressive_model>autoregressive models</a> as well? We explore the possibility of training autoregressive machine translation models with latent alignment objectives, and observe that, in practice, this approach results in degenerate models. We provide a theoretical explanation for these empirical results, and prove that latent alignment objectives are incompatible with teacher forcing.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.210.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--210 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.210 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.210" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.210/>Smoothing and Shrinking the Sparse Seq2Seq Search Space<span class=acl-fixed-case>S</span>eq2<span class=acl-fixed-case>S</span>eq Search Space</a></strong><br><a href=/people/b/ben-peters/>Ben Peters</a>
|
<a href=/people/a/andre-f-t-martins/>André F. T. Martins</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--210><div class="card-body p-3 small">Current sequence-to-sequence models are trained to minimize <a href=https://en.wikipedia.org/wiki/Cross-entropy>cross-entropy</a> and use <a href=https://en.wikipedia.org/wiki/Softmax>softmax</a> to compute the locally normalized probabilities over target sequences. While this setup has led to strong results in a variety of tasks, one unsatisfying aspect is its length bias : models give high scores to short, inadequate hypotheses and often make the empty string the argmaxthe so-called cat got your tongue problem. Recently proposed entmax-based sparse sequence-to-sequence models present a possible solution, since they can shrink the search space by assigning zero probability to bad hypotheses, but their ability to handle word-level tasks with transformers has never been tested. In this work, we show that entmax-based models effectively solve the cat got your tongue problem, removing a major source of model error for <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a>. In addition, we generalize label smoothing, a critical regularization technique, to the broader family of Fenchel-Young losses, which includes both <a href=https://en.wikipedia.org/wiki/Cross-entropy>cross-entropy</a> and the entmax losses. Our resulting label-smoothed entmax loss models set a new state of the art on multilingual grapheme-to-phoneme conversion and deliver improvements and better calibration properties on cross-lingual morphological inflection and <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> for 7 language pairs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.214.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--214 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.214 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.214" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.214/>Cross-Lingual Word Embedding Refinement by _ 1 Norm Optimisation<span class=tex-math>ℓ<sub>1</sub></span> Norm Optimisation</a></strong><br><a href=/people/x/xutan-peng/>Xutan Peng</a>
|
<a href=/people/c/chenghua-lin/>Chenghua Lin</a>
|
<a href=/people/m/mark-stevenson/>Mark Stevenson</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--214><div class="card-body p-3 small">Cross-Lingual Word Embeddings (CLWEs) encode words from two or more languages in a shared high-dimensional space in which vectors representing words with similar meaning (regardless of language) are closely located. Existing methods for building high-quality CLWEs learn <a href=https://en.wikipedia.org/wiki/Map_(mathematics)>mappings</a> that minimise the 2 norm loss function. However, this optimisation objective has been demonstrated to be sensitive to <a href=https://en.wikipedia.org/wiki/Outlier>outliers</a>. Based on the more robust Manhattan norm (aka. 1 norm) goodness-of-fit criterion, this paper proposes a simple post-processing step to improve CLWEs. An advantage of this approach is that it is fully agnostic to the training process of the original CLWEs and can therefore be applied widely. Extensive experiments are performed involving ten diverse languages and embeddings trained on different corpora. Evaluation results based on bilingual lexicon induction and cross-lingual transfer for natural language inference tasks show that the 1 refinement substantially outperforms four state-of-the-art baselines in both supervised and unsupervised settings. It is therefore recommended that this <a href=https://en.wikipedia.org/wiki/Strategy>strategy</a> be adopted as a standard for CLWE methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.220.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--220 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.220 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.220" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.220/>Learning to Synthesize Data for Semantic Parsing</a></strong><br><a href=/people/b/bailin-wang/>Bailin Wang</a>
|
<a href=/people/w/wenpeng-yin/>Wenpeng Yin</a>
|
<a href=/people/x/xi-victoria-lin/>Xi Victoria Lin</a>
|
<a href=/people/c/caiming-xiong/>Caiming Xiong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--220><div class="card-body p-3 small">Synthesizing data for <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a> has gained increasing attention recently. However, most methods require handcrafted (high-precision) rules in their generative process, hindering the exploration of diverse unseen data. In this work, we propose a <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a> which features a (non-neural) PCFG that models the composition of programs (e.g., SQL), and a BART-based translation model that maps a program to an utterance. Due to the simplicity of PCFG and pre-trained BART, our <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a> can be efficiently learned from existing data at hand. Moreover, explicitly modeling compositions using PCFG leads to better exploration of unseen programs, thus generate more diverse data. We evaluate our method in both in-domain and out-of-domain settings of text-to-SQL parsing on the standard benchmarks of GeoQuery and Spider, respectively. Our empirical results show that the synthesized data generated from our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can substantially help a <a href=https://en.wikipedia.org/wiki/Semantic_parser>semantic parser</a> achieve better compositional and domain generalization.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.221.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--221 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.221 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.221/>Edge : Enriching Knowledge Graph Embeddings with External Text</a></strong><br><a href=/people/s/saed-rezayi/>Saed Rezayi</a>
|
<a href=/people/h/handong-zhao/>Handong Zhao</a>
|
<a href=/people/s/sungchul-kim/>Sungchul Kim</a>
|
<a href=/people/r/ryan-rossi/>Ryan Rossi</a>
|
<a href=/people/n/nedim-lipka/>Nedim Lipka</a>
|
<a href=/people/s/sheng-li/>Sheng Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--221><div class="card-body p-3 small">Knowledge graphs suffer from sparsity which degrades the quality of representations generated by various methods. While there is an abundance of textual information throughout the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>web</a> and many existing <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge bases</a>, aligning information across these diverse data sources remains a challenge in the literature. Previous work has partially addressed this issue by enriching knowledge graph entities based on hard co-occurrence of words present in the entities of the knowledge graphs and external text, while we achieve soft augmentation by proposing a knowledge graph enrichment and embedding framework named Edge. Given an original <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graph</a>, we first generate a rich but noisy augmented graph using external texts in semantic and structural level. To distill the relevant knowledge and suppress the introduced noise, we design a <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph alignment term</a> in a shared embedding space between the original <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a> and augmented graph. To enhance the embedding learning on the augmented graph, we further regularize the locality relationship of target entity based on negative sampling. Experimental results on four benchmark datasets demonstrate the robustness and effectiveness of Edge in link prediction and node classification.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.225.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--225 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.225 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.225/>Compositional Generalization for Neural Semantic Parsing via Span-level Supervised Attention</a></strong><br><a href=/people/p/pengcheng-yin/>Pengcheng Yin</a>
|
<a href=/people/h/hao-fang/>Hao Fang</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/a/adam-pauls/>Adam Pauls</a>
|
<a href=/people/e/emmanouil-antonios-platanios/>Emmanouil Antonios Platanios</a>
|
<a href=/people/y/yu-su/>Yu Su</a>
|
<a href=/people/s/sam-thomson/>Sam Thomson</a>
|
<a href=/people/j/jacob-andreas/>Jacob Andreas</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--225><div class="card-body p-3 small">We describe a span-level supervised attention loss that improves compositional generalization in <a href=https://en.wikipedia.org/wiki/Semantic_parser>semantic parsers</a>. Our approach builds on existing losses that encourage attention maps in neural sequence-to-sequence models to imitate the output of classical word alignment algorithms. Where past work has used word-level alignments, we focus on spans ; borrowing ideas from phrase-based machine translation, we align subtrees in semantic parses to spans of input sentences, and encourage neural attention mechanisms to mimic these alignments. This method improves the performance of transformers, <a href=https://en.wikipedia.org/wiki/Radio-frequency_identification>RNNs</a>, and structured decoders on three benchmarks of compositional generalization.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.229.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--229 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.229 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.229/>Graph Ensemble Learning over Multiple Dependency Trees for Aspect-level Sentiment Classification</a></strong><br><a href=/people/x/xiaochen-hou/>Xiaochen Hou</a>
|
<a href=/people/p/peng-qi/>Peng Qi</a>
|
<a href=/people/g/guangtao-wang/>Guangtao Wang</a>
|
<a href=/people/r/rex-ying/>Rex Ying</a>
|
<a href=/people/j/jing-huang/>Jing Huang</a>
|
<a href=/people/x/xiaodong-he/>Xiaodong He</a>
|
<a href=/people/b/bowen-zhou/>Bowen Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--229><div class="card-body p-3 small">Recent work on aspect-level sentiment classification has demonstrated the efficacy of incorporating syntactic structures such as dependency trees with graph neural networks (GNN), but these approaches are usually vulnerable to parsing errors. To better leverage syntactic information in the face of unavoidable errors, we propose a simple yet effective graph ensemble technique, GraphMerge, to make use of the predictions from different <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a>. Instead of assigning one set of model parameters to each dependency tree, we first combine the dependency relations from different <a href=https://en.wikipedia.org/wiki/Parsing>parses</a> before applying GNNs over the resulting <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a>. This allows GNN models to be robust to parse errors at no additional computational cost, and helps avoid overparameterization and <a href=https://en.wikipedia.org/wiki/Overfitting>overfitting</a> from GNN layer stacking by introducing more connectivity into the ensemble graph. Our experiments on the SemEval 2014 Task 4 and ACL 14 Twitter datasets show that our GraphMerge model not only outperforms models with single dependency tree, but also beats other ensemble models without adding model parameters.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.230.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--230 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.230 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.230" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.230/>Emotion-Infused Models for Explainable Psychological Stress Detection</a></strong><br><a href=/people/e/elsbeth-turcan/>Elsbeth Turcan</a>
|
<a href=/people/s/smaranda-muresan/>Smaranda Muresan</a>
|
<a href=/people/k/kathleen-mckeown/>Kathleen McKeown</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--230><div class="card-body p-3 small">The problem of detecting psychological stress in online posts, and more broadly, of detecting people in distress or in need of help, is a sensitive application for which the ability to interpret models is vital. Here, we present work exploring the use of a semantically related task, <a href=https://en.wikipedia.org/wiki/Emotion_detection>emotion detection</a>, for equally competent but more explainable and human-like psychological stress detection as compared to a black-box model. In particular, we explore the use of <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a> as well as emotion-based language model fine-tuning. With our emotion-infused models, we see comparable results to state-of-the-art BERT. Our analysis of the words used for prediction show that our emotion-infused models mirror psychological components of stress.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.231.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--231 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.231 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.231" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.231/>Aspect-based Sentiment Analysis with Type-aware Graph Convolutional Networks and Layer Ensemble</a></strong><br><a href=/people/y/yuanhe-tian/>Yuanhe Tian</a>
|
<a href=/people/g/guimin-chen/>Guimin Chen</a>
|
<a href=/people/y/yan-song/>Yan Song</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--231><div class="card-body p-3 small">It is popular that neural graph-based models are applied in existing aspect-based sentiment analysis (ABSA) studies for utilizing word relations through dependency parses to facilitate the task with better semantic guidance for analyzing context and aspect words. However, most of these studies only leverage dependency relations without considering their dependency types, and are limited in lacking efficient mechanisms to distinguish the important relations as well as learn from different layers of graph based models. To address such limitations, in this paper, we propose an approach to explicitly utilize dependency types for ABSA with type-aware graph convolutional networks (T-GCN), where attention is used in T-GCN to distinguish different edges (relations) in the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a> and attentive layer ensemble is proposed to comprehensively learn from different layers of T-GCN. The validity and effectiveness of our approach are demonstrated in the experimental results, where state-of-the-art performance is achieved on six English benchmark datasets. Further experiments are conducted to analyze the contributions of each component in our approach and illustrate how different layers in T-GCN help ABSA with quantitative and qualitative analysis.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.235.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--235 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.235 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.235/>Bot-Adversarial Dialogue for Safe Conversational Agents</a></strong><br><a href=/people/j/jing-xu/>Jing Xu</a>
|
<a href=/people/d/da-ju/>Da Ju</a>
|
<a href=/people/m/margaret-li/>Margaret Li</a>
|
<a href=/people/y/y-lan-boureau/>Y-Lan Boureau</a>
|
<a href=/people/j/jason-weston/>Jason Weston</a>
|
<a href=/people/e/emily-dinan/>Emily Dinan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--235><div class="card-body p-3 small">Conversational agents trained on large unlabeled corpora of human interactions will learn patterns and mimic behaviors therein, which include offensive or otherwise toxic behavior. We introduce a new human-and-model-in-the-loop framework for evaluating the toxicity of such models, and compare a variety of existing methods in both the cases of non-adversarial and adversarial users that expose their weaknesses. We then go on to propose two novel methods for safe conversational agents, by either training on data from our new human-and-model-in-the-loop framework in a two-stage system, or baking-in safety to the generative model itself. We find our new techniques are (i) safer than existing models ; while (ii) maintaining usability metrics such as engagingness relative to state-of-the-art <a href=https://en.wikipedia.org/wiki/Chatbot>chatbots</a>. In contrast, we expose serious safety issues in existing standard systems like GPT2, DialoGPT, and BlenderBot.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.239.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--239 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.239 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.239" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.239/>Action-Based Conversations Dataset : A Corpus for Building More In-Depth Task-Oriented Dialogue Systems</a></strong><br><a href=/people/d/derek-chen/>Derek Chen</a>
|
<a href=/people/h/howard-chen/>Howard Chen</a>
|
<a href=/people/y/yi-yang/>Yi Yang</a>
|
<a href=/people/a/alexander-lin/>Alexander Lin</a>
|
<a href=/people/z/zhou-yu/>Zhou Yu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--239><div class="card-body p-3 small">Existing goal-oriented dialogue datasets focus mainly on identifying slots and values. However, customer support interactions in reality often involve agents following multi-step procedures derived from explicitly-defined company policies as well. To study customer service dialogue systems in more realistic settings, we introduce the Action-Based Conversations Dataset (ABCD), a fully-labeled dataset with over 10 K human-to-human dialogues containing 55 distinct user intents requiring unique sequences of actions constrained by policies to achieve task success. We propose two additional dialog tasks, Action State Tracking and Cascading Dialogue Success, and establish a series of baselines involving large-scale, pre-trained language models on this dataset. Empirical results demonstrate that while more sophisticated <a href=https://en.wikipedia.org/wiki/Computer_network>networks</a> outperform simpler <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>, a considerable gap (50.8 % absolute accuracy) still exists to reach human-level performance on ABCD.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.241.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--241 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.241 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.241" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.241/>COIL : Revisit Exact Lexical Match in Information Retrieval with Contextualized Inverted List<span class=acl-fixed-case>COIL</span>: Revisit Exact Lexical Match in Information Retrieval with Contextualized Inverted List</a></strong><br><a href=/people/l/luyu-gao/>Luyu Gao</a>
|
<a href=/people/z/zhuyun-dai/>Zhuyun Dai</a>
|
<a href=/people/j/jamie-callan/>Jamie Callan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--241><div class="card-body p-3 small">Classical information retrieval systems such as <a href=https://en.wikipedia.org/wiki/BM25>BM25</a> rely on exact lexical match and can carry out search efficiently with inverted list index. Recent neural IR models shifts towards soft matching all query document terms, but they lose the computation efficiency of exact match systems. This paper presents COIL, a contextualized exact match retrieval architecture, where scoring is based on overlapping query document tokens&#8217; contextualized representations. The new architecture stores contextualized token representations in inverted lists, bringing together the efficiency of <a href=https://en.wikipedia.org/wiki/Exact_match>exact match</a> and the representation power of <a href=https://en.wikipedia.org/wiki/Deep_learning>deep language models</a>. Our experimental results show COIL outperforms classical lexical retrievers and state-of-the-art deep LM retrievers with similar or smaller latency.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.244.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--244 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.244 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.244" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.244/>Exploring the Relationship Between Algorithm Performance, <a href=https://en.wikipedia.org/wiki/Vocabulary>Vocabulary</a>, and <a href=https://en.wikipedia.org/wiki/Run_time_(program_lifecycle_phase)>Run-Time</a> in Text Classification</a></strong><br><a href=/people/w/wilson-fearn/>Wilson Fearn</a>
|
<a href=/people/o/orion-weller/>Orion Weller</a>
|
<a href=/people/k/kevin-seppi/>Kevin Seppi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--244><div class="card-body p-3 small">Text classification is a significant branch of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>, and has many applications including <a href=https://en.wikipedia.org/wiki/Document_classification>document classification</a> and <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>. Unsurprisingly, those who do <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a> are concerned with the <a href=https://en.wikipedia.org/wiki/Run_time_(program_lifecycle_phase)>run-time</a> of their algorithms, many of which depend on the size of the corpus&#8217; vocabulary due to their bag-of-words representation. Although many studies have examined the effect of preprocessing techniques on vocabulary size and <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, none have examined how these methods affect a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model&#8217;s run-time</a>. To fill this gap, we provide a comprehensive study that examines how preprocessing techniques affect the vocabulary size, model performance, and model run-time, evaluating ten techniques over four models and two datasets. We show that some individual methods can reduce <a href=https://en.wikipedia.org/wiki/Run_time_(program_lifecycle_phase)>run-time</a> with no loss of <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, while some combinations of methods can trade 2-5 % of the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> for up to a 65 % reduction of <a href=https://en.wikipedia.org/wiki/Run_time_(program_lifecycle_phase)>run-time</a>. Furthermore, some combinations of preprocessing techniques can even provide a 15 % reduction in <a href=https://en.wikipedia.org/wiki/Run_time_(program_lifecycle_phase)>run-time</a> while simultaneously improving model accuracy.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.246.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--246 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.246 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.246" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.246/>You Sound Like Someone Who Watches Drama Movies : Towards Predicting Movie Preferences from Conversational Interactions</a></strong><br><a href=/people/s/sergey-volokhin/>Sergey Volokhin</a>
|
<a href=/people/j/joyce-ho/>Joyce Ho</a>
|
<a href=/people/o/oleg-rokhlenko/>Oleg Rokhlenko</a>
|
<a href=/people/e/eugene-agichtein/>Eugene Agichtein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--246><div class="card-body p-3 small">The increasing popularity of voice-based personal assistants provides new opportunities for conversational recommendation. One particularly interesting area is movie recommendation, which can benefit from an open-ended interaction with the user, through a natural conversation. We explore one promising direction for conversational recommendation : mapping a conversational user, for whom there is limited or no data available, to most similar external reviewers, whose preferences are known, by representing the conversation as a user&#8217;s interest vector, and adapting collaborative filtering techniques to estimate the current user&#8217;s preferences for new movies. We call our proposed method ConvExtr (Conversational Collaborative Filtering using External Data), which 1) infers a user&#8217;s sentiment towards an entity from the conversation context, and 2) transforms the ratings of similar external reviewers to predict the current user&#8217;s preferences. We implement these steps by adapting contextual sentiment prediction techniques, and domain adaptation, respectively. To evaluate our method, we develop and make available a finely annotated dataset of movie recommendation conversations, which we call MovieSent. Our results demonstrate that ConvExtr can improve the accuracy of predicting users&#8217; ratings for new movies by exploiting conversation content and external data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.247.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--247 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.247 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.247/>Reading and Acting while Blindfolded : The Need for <a href=https://en.wikipedia.org/wiki/Semantics>Semantics</a> in Text Game Agents</a></strong><br><a href=/people/s/shunyu-yao/>Shunyu Yao</a>
|
<a href=/people/k/karthik-narasimhan/>Karthik Narasimhan</a>
|
<a href=/people/m/matthew-hausknecht/>Matthew Hausknecht</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--247><div class="card-body p-3 small">Text-based games simulate worlds and interact with players using <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>. Recent work has used them as a testbed for autonomous language-understanding agents, with the motivation being that understanding the meanings of words or <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> is a key component of how humans understand, reason, and act in these worlds. However, it remains unclear to what extent <a href=https://en.wikipedia.org/wiki/Intelligent_agent>artificial agents</a> utilize semantic understanding of the text. To this end, we perform experiments to systematically reduce the amount of <a href=https://en.wikipedia.org/wiki/Semantics>semantic information</a> available to a <a href=https://en.wikipedia.org/wiki/Intelligent_agent>learning agent</a>. Surprisingly, we find that an <a href=https://en.wikipedia.org/wiki/Intelligent_agent>agent</a> is capable of achieving high scores even in the complete absence of <a href=https://en.wikipedia.org/wiki/Semantics>language semantics</a>, indicating that the currently popular experimental setup and <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> may be poorly designed to understand and leverage game texts. To remedy this deficiency, we propose an inverse dynamics decoder to regularize the representation space and encourage exploration, which shows improved performance on several games including Zork I. We discuss the implications of our findings for designing future <a href=https://en.wikipedia.org/wiki/Intelligent_agent>agents</a> with stronger semantic understanding.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.254.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--254 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.254 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.254" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.254/>CaSiNo : A Corpus of Campsite Negotiation Dialogues for Automatic Negotiation Systems<span class=acl-fixed-case>C</span>a<span class=acl-fixed-case>S</span>i<span class=acl-fixed-case>N</span>o: A Corpus of Campsite Negotiation Dialogues for Automatic Negotiation Systems</a></strong><br><a href=/people/k/kushal-chawla/>Kushal Chawla</a>
|
<a href=/people/j/jaysa-ramirez/>Jaysa Ramirez</a>
|
<a href=/people/r/rene-clever/>Rene Clever</a>
|
<a href=/people/g/gale-lucas/>Gale Lucas</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/j/jonathan-gratch/>Jonathan Gratch</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--254><div class="card-body p-3 small">Automated systems that negotiate with humans have broad applications in <a href=https://en.wikipedia.org/wiki/Pedagogy>pedagogy</a> and conversational AI. To advance the development of practical <a href=https://en.wikipedia.org/wiki/Negotiation>negotiation systems</a>, we present CaSiNo : a novel <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> of over a thousand <a href=https://en.wikipedia.org/wiki/Negotiation>negotiation dialogues</a> in English. Participants take the role of campsite neighbors and negotiate for food, water, and firewood packages for their upcoming trip. Our design results in diverse and linguistically rich negotiations while maintaining a tractable, closed-domain environment. Inspired by the literature in human-human negotiations, we annotate <a href=https://en.wikipedia.org/wiki/Persuasion>persuasion strategies</a> and perform <a href=https://en.wikipedia.org/wiki/Correlation_and_dependence>correlation analysis</a> to understand how the dialogue behaviors are associated with the <a href=https://en.wikipedia.org/wiki/Negotiation>negotiation</a> performance. We further propose and evaluate a multi-task framework to recognize these <a href=https://en.wikipedia.org/wiki/Strategy>strategies</a> in a given utterance. We find that <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a> substantially improves the performance for all strategy labels, especially for the ones that are the most skewed. We release the dataset, annotations, and the code to propel future work in human-machine negotiations : https://github.com/kushalchawla/CaSiNo</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.255.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--255 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.255 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.255" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.255/>News Headline Grouping as a Challenging NLU Task<span class=acl-fixed-case>NLU</span> Task</a></strong><br><a href=/people/p/philippe-laban/>Philippe Laban</a>
|
<a href=/people/l/lucas-bandarkar/>Lucas Bandarkar</a>
|
<a href=/people/m/marti-a-hearst/>Marti A. Hearst</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--255><div class="card-body p-3 small">Recent progress in Natural Language Understanding (NLU) has seen the latest <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> outperform human performance on many standard <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. These impressive results have led the community to introspect on dataset limitations, and iterate on more nuanced challenges. In this paper, we introduce the task of HeadLine Grouping (HLG) and a corresponding <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> (HLGD) consisting of 20,056 pairs of <a href=https://en.wikipedia.org/wiki/Headline>news headlines</a>, each labeled with a binary judgement as to whether the pair belongs within the same group. On HLGD, human annotators achieve high performance of around 0.9 F-1, while current state-of-the art Transformer models only reach 0.75 F-1, opening the path for further improvements. We further propose a novel unsupervised Headline Generator Swap model for the task of HeadLine Grouping that achieves within 3 F-1 of the best supervised model. Finally, we analyze high-performing <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> with consistency tests, and find that <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are not consistent in their predictions, revealing modeling limits of current <a href=https://en.wikipedia.org/wiki/Computer_architecture>architectures</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.262.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--262 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.262 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.262" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.262/>Ensemble of MRR and NDCG models for Visual Dialog<span class=acl-fixed-case>MRR</span> and <span class=acl-fixed-case>NDCG</span> models for Visual Dialog</a></strong><br><a href=/people/i/idan-schwartz/>Idan Schwartz</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--262><div class="card-body p-3 small">Assessing an <a href=https://en.wikipedia.org/wiki/Intelligent_agent>AI agent</a> that can converse in <a href=https://en.wikipedia.org/wiki/Human_language>human language</a> and understand <a href=https://en.wikipedia.org/wiki/Visual_system>visual content</a> is challenging. Generation metrics, such as BLEU scores favor correct <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a> over <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a>. Hence a discriminative approach is often used, where an agent ranks a set of candidate options. The mean reciprocal rank (MRR) metric evaluates the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performance by taking into account the <a href=https://en.wikipedia.org/wiki/Rank_(linear_algebra)>rank</a> of a single human-derived answer. This approach, however, raises a new challenge : the ambiguity and synonymy of answers, for instance, <a href=https://en.wikipedia.org/wiki/Semantic_equivalence>semantic equivalence</a> (e.g., &#8216;yeah&#8217; and &#8216;yes&#8217;). To address this, the normalized discounted cumulative gain (NDCG) metric has been used to capture the relevance of all the correct answers via dense annotations. However, the NDCG metric favors the usually applicable uncertain answers such as &#8216;I do n&#8217;t know.&#8217; Crafting a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> that excels on both MRR and NDCG metrics is challenging. Ideally, an <a href=https://en.wikipedia.org/wiki/Intelligent_agent>AI agent</a> should answer a human-like reply and validate the correctness of any answer. To address this issue, we describe a two-step non-parametric ranking approach that can merge strong MRR and NDCG models. Using our <a href=https://en.wikipedia.org/wiki/Software_development_process>approach</a>, we manage to keep most MRR state-of-the-art performance (70.41 % vs. 71.24 %) and the NDCG state-of-the-art performance (72.16 % vs. 75.35 %). Moreover, our <a href=https://en.wikipedia.org/wiki/Software_development_process>approach</a> won the recent Visual Dialog 2020 challenge. Source code is available at https://github.com/idansc/mrr-ndcg.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.265.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--265 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.265 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.265" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.265/>CREAD : Combined Resolution of Ellipses and Anaphora in Dialogues<span class=acl-fixed-case>CREAD</span>: Combined Resolution of Ellipses and Anaphora in Dialogues</a></strong><br><a href=/people/b/bo-hsiang-tseng/>Bo-Hsiang Tseng</a>
|
<a href=/people/s/shruti-bhargava/>Shruti Bhargava</a>
|
<a href=/people/j/jiarui-lu/>Jiarui Lu</a>
|
<a href=/people/j/joel-ruben-antony-moniz/>Joel Ruben Antony Moniz</a>
|
<a href=/people/d/dhivya-piraviperumal/>Dhivya Piraviperumal</a>
|
<a href=/people/l/lin-li/>Lin Li</a>
|
<a href=/people/h/hong-yu/>Hong Yu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--265><div class="card-body p-3 small">Anaphora and <a href=https://en.wikipedia.org/wiki/Ellipsis>ellipses</a> are two common phenomena in <a href=https://en.wikipedia.org/wiki/Dialogue>dialogues</a>. Without resolving <a href=https://en.wikipedia.org/wiki/Reference>referring expressions</a> and information omission, <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue systems</a> may fail to generate consistent and coherent responses. Traditionally, <a href=https://en.wikipedia.org/wiki/Anaphora_(linguistics)>anaphora</a> is resolved by <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> and ellipses by query rewrite. In this work, we propose a novel joint learning framework of modeling <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> and query rewriting for complex, multi-turn dialogue understanding. Given an ongoing dialogue between a user and a dialogue assistant, for the user query, our joint learning model first predicts coreference links between the query and the dialogue context, and then generates a self-contained rewritten user query. To evaluate our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>, we annotate a dialogue based coreference resolution dataset, MuDoCo, with rewritten queries. Results show that the performance of query rewrite can be substantially boosted (+2.3 % F1) with the aid of coreference modeling. Furthermore, our joint model outperforms the state-of-the-art coreference resolution model (+2 % F1) on this dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.266.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--266 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.266 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.266" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.266/>Knowledge-Driven Slot Constraints for Goal-Oriented Dialogue Systems</a></strong><br><a href=/people/p/piyawat-lertvittayakumjorn/>Piyawat Lertvittayakumjorn</a>
|
<a href=/people/d/daniele-bonadiman/>Daniele Bonadiman</a>
|
<a href=/people/s/saab-mansour/>Saab Mansour</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--266><div class="card-body p-3 small">In goal-oriented dialogue systems, users provide information through slot values to achieve specific goals. Practically, some combinations of slot values can be invalid according to external knowledge. For example, a combination of <a href=https://en.wikipedia.org/wiki/Cheese_pizza>cheese pizza</a> (a menu item) and oreo cookies (a topping) from an input utterance Can I order a <a href=https://en.wikipedia.org/wiki/Cheese_pizza>cheese pizza</a> with <a href=https://en.wikipedia.org/wiki/Oreo>oreo cookies</a> on top? exemplifies such invalid combinations according to the menu of a restaurant business. Traditional dialogue systems allow execution of validation rules as a post-processing step after slots have been filled which can lead to error accumulation. In this paper, we formalize knowledge-driven slot constraints and present a new task of constraint violation detection accompanied with benchmarking data. Then, we propose methods to integrate the external knowledge into the system and model constraint violation detection as an end-to-end classification task and compare it to the traditional rule-based pipeline approach. Experiments on two domains of the MultiDoGO dataset reveal challenges of constraint violation detection and sets the stage for future work and improvements.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.267.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--267 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.267 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.267/>Clipping Loops for Sample-Efficient Dialogue Policy Optimisation</a></strong><br><a href=/people/y/yen-chen-wu/>Yen-Chen Wu</a>
|
<a href=/people/c/carl-edward-rasmussen/>Carl Edward Rasmussen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--267><div class="card-body p-3 small">Training dialogue agents requires a large number of interactions with users : agents have no idea about which responses are bad among a lengthy dialogue. In this paper, we propose loop-clipping policy optimisation (LCPO) to eliminate useless responses. LCPO consists of two stages : loop clipping and advantage clipping. In loop clipping, we clip off useless responses (called loops) from dialogue history (called trajectories). The clipped trajectories are more succinct than the original ones, and the estimation of state-value is more accurate. Second, in advantage clipping, we estimate and clip the advantages of useless responses and normal ones separately. The clipped advantage distinguish useless actions from others and reduce the probabilities of useless actions efficiently. In experiments on Cambridge Restaurant Dialogue System, LCPO uses only 260 training dialogues to achieve 80 % success rate, while PPO baseline requires 2160 dialogues. Besides, LCPO receives 3.7/5 scores in <a href=https://en.wikipedia.org/wiki/Human&#8211;computer_interaction>human evaluation</a> where the agent interactively collects 100 real-user dialogues in training phase.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.270.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--270 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.270 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.270" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.270/>TABBIE : Pretrained Representations of Tabular Data<span class=acl-fixed-case>TABBIE</span>: Pretrained Representations of Tabular Data</a></strong><br><a href=/people/h/hiroshi-iida/>Hiroshi Iida</a>
|
<a href=/people/d/dung-thai/>Dung Thai</a>
|
<a href=/people/v/varun-manjunatha/>Varun Manjunatha</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--270><div class="card-body p-3 small">Existing work on tabular representation-learning jointly models tables and associated text using self-supervised objective functions derived from pretrained language models such as BERT. While this joint pretraining improves <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> involving paired tables and text (e.g., answering questions about tables), we show that it underperforms on <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> that operate over tables without any associated text (e.g., populating missing cells). We devise a simple pretraining objective (corrupt cell detection) that learns exclusively from tabular data and reaches the state-of-the-art on a suite of table-based prediction tasks. Unlike competing approaches, our model (TABBIE) provides embeddings of all table substructures (cells, rows, and columns), and it also requires far less compute to train. A qualitative analysis of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s learned cell, column, and row representations shows that it understands complex table semantics and numerical trends.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.275.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--275 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.275 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.275/>Multi-Style Transfer with Discriminative Feedback on Disjoint Corpus</a></strong><br><a href=/people/n/navita-goyal/>Navita Goyal</a>
|
<a href=/people/b/balaji-vasan-srinivasan/>Balaji Vasan Srinivasan</a>
|
<a href=/people/a/anandhavelu-n/>Anandhavelu N</a>
|
<a href=/people/a/abhilasha-sancheti/>Abhilasha Sancheti</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--275><div class="card-body p-3 small">Style transfer has been widely explored in <a href=https://en.wikipedia.org/wiki/Natural-language_generation>natural language generation</a> with non-parallel corpus by directly or indirectly extracting a notion of <a href=https://en.wikipedia.org/wiki/Style_(sociolinguistics)>style</a> from source and target domain corpus. A common shortcoming of existing approaches is the prerequisite of joint annotations across all the <a href=https://en.wikipedia.org/wiki/Style_(visual_arts)>stylistic dimensions</a> under consideration. Availability of such <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> across a combination of styles limits the extension of these setups to multiple style dimensions. While cascading single-dimensional models across multiple styles is a possibility, it suffers from content loss, especially when the style dimensions are not completely independent of each other. In our work, we relax this requirement of jointly annotated data across multiple styles by using independently acquired data across different style dimensions without any additional annotations. We initialize an encoder-decoder setup with transformer-based language model pre-trained on a generic corpus and enhance its re-writing capability to multiple target style dimensions by employing multiple style-aware language models as discriminators. Through quantitative and qualitative evaluation, we show the ability of our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to control styles across multiple style dimensions while preserving content of the input text. We compare it against baselines involving cascaded state-of-the-art uni-dimensional style transfer models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.280.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--280 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.280 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.280" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.280/>InfoXLM : An Information-Theoretic Framework for Cross-Lingual Language Model Pre-Training<span class=acl-fixed-case>I</span>nfo<span class=acl-fixed-case>XLM</span>: An Information-Theoretic Framework for Cross-Lingual Language Model Pre-Training</a></strong><br><a href=/people/z/zewen-chi/>Zewen Chi</a>
|
<a href=/people/l/li-dong/>Li Dong</a>
|
<a href=/people/f/furu-wei/>Furu Wei</a>
|
<a href=/people/n/nan-yang/>Nan Yang</a>
|
<a href=/people/s/saksham-singhal/>Saksham Singhal</a>
|
<a href=/people/w/wenhui-wang/>Wenhui Wang</a>
|
<a href=/people/x/xia-song/>Xia Song</a>
|
<a href=/people/x/xian-ling-mao/>Xian-Ling Mao</a>
|
<a href=/people/h/he-yan-huang/>Heyan Huang</a>
|
<a href=/people/m/ming-zhou/>Ming Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--280><div class="card-body p-3 small">In this work, we present an information-theoretic framework that formulates cross-lingual language model pre-training as maximizing <a href=https://en.wikipedia.org/wiki/Mutual_information>mutual information</a> between multilingual-multi-granularity texts. The unified view helps us to better understand the existing <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> for learning cross-lingual representations. More importantly, inspired by the <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a>, we propose a new pre-training task based on contrastive learning. Specifically, we regard a bilingual sentence pair as two views of the same meaning and encourage their encoded representations to be more similar than the negative examples. By leveraging both monolingual and parallel corpora, we jointly train the pretext tasks to improve the cross-lingual transferability of pre-trained models. Experimental results on several benchmarks show that our approach achieves considerably better performance. The <a href=https://en.wikipedia.org/wiki/Source_code>code</a> and pre-trained models are available at https://aka.ms/infoxlm.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.283.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--283 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.283 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.283" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.283/>X-METRA-ADA : Cross-lingual Meta-Transfer learning Adaptation to <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>Natural Language Understanding</a> and Question Answering<span class=acl-fixed-case>X</span>-<span class=acl-fixed-case>METRA</span>-<span class=acl-fixed-case>ADA</span>: Cross-lingual Meta-Transfer learning Adaptation to Natural Language Understanding and Question Answering</a></strong><br><a href=/people/m/meryem-mhamdi/>Meryem M’hamdi</a>
|
<a href=/people/d/doo-soon-kim/>Doo Soon Kim</a>
|
<a href=/people/f/franck-dernoncourt/>Franck Dernoncourt</a>
|
<a href=/people/t/trung-bui/>Trung Bui</a>
|
<a href=/people/x/xiang-ren/>Xiang Ren</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--283><div class="card-body p-3 small">Multilingual models, such as M-BERT and XLM-R, have gained increasing popularity, due to their zero-shot cross-lingual transfer learning capabilities. However, their <a href=https://en.wikipedia.org/wiki/Generalization>generalization ability</a> is still inconsistent for <a href=https://en.wikipedia.org/wiki/Linguistic_typology>typologically diverse languages</a> and across different benchmarks. Recently, <a href=https://en.wikipedia.org/wiki/Meta-learning>meta-learning</a> has garnered attention as a promising technique for enhancing <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> under low-resource scenarios : particularly for cross-lingual transfer in Natural Language Understanding (NLU). In this work, we propose X-METRA-ADA, a cross-lingual MEta-TRAnsfer learning ADAptation approach for NLU. Our approach adapts MAML, an optimization-based meta-learning approach, to learn to adapt to new languages. We extensively evaluate our framework on two challenging cross-lingual NLU tasks : multilingual task-oriented dialog and typologically diverse question answering. We show that our approach outperforms naive fine-tuning, reaching competitive performance on both tasks for most languages. Our analysis reveals that X-METRA-ADA can leverage limited data for faster adaptation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.288.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--288 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.288 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.288/>Adaptable and Interpretable Neural MemoryOver Symbolic Knowledge<span class=acl-fixed-case>M</span>emory<span class=acl-fixed-case>O</span>ver Symbolic Knowledge</a></strong><br><a href=/people/p/pat-verga/>Pat Verga</a>
|
<a href=/people/h/haitian-sun/>Haitian Sun</a>
|
<a href=/people/l/livio-baldini-soares/>Livio Baldini Soares</a>
|
<a href=/people/w/william-cohen/>William Cohen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--288><div class="card-body p-3 small">Past research has demonstrated that large neural language models (LMs) encode surprising amounts of factual information : however, augmenting or modifying this <a href=https://en.wikipedia.org/wiki/Information>information</a> requires modifying a corpus and retraining, which is computationally expensive. To address this problem, we develop a neural LM that includes an interpretable neuro-symbolic KB in the form of a fact memory. Each element of the fact memory is formed from a triple of vectors, where each vector corresponds to a KB entity or relation. Our LM improves performance on knowledge-intensive question-answering tasks, sometimes dramatically, including a 27 point increase in one setting of WebQuestionsSP over a state-of-the-art open-book model, despite using 5 % of the parameters. Most interestingly, we demonstrate that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can be modified, without any <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>re-training</a>, by updating the fact memory.<i>any</i> re-training, by updating the fact memory.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.290.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--290 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.290 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.290" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.290/>Refining Targeted Syntactic Evaluation of <a href=https://en.wikipedia.org/wiki/Language_model>Language Models</a></a></strong><br><a href=/people/b/benjamin-newman/>Benjamin Newman</a>
|
<a href=/people/k/kai-siang-ang/>Kai-Siang Ang</a>
|
<a href=/people/j/julia-gong/>Julia Gong</a>
|
<a href=/people/j/john-hewitt/>John Hewitt</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--290><div class="card-body p-3 small">Targeted syntactic evaluation of subject-verb number agreement in English (TSE) evaluates language models&#8217; syntactic knowledge using hand-crafted minimal pairs of sentences that differ only in the main verb&#8217;s conjugation. The method evaluates whether language models rate each grammatical sentence as more likely than its ungrammatical counterpart. We identify two distinct goals for TSE. First, evaluating the systematicity of a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a>&#8217;s syntactic knowledge : given a sentence, can it conjugate arbitrary verbs correctly? Second, evaluating a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s likely behavior : given a sentence, does the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> concentrate its <a href=https://en.wikipedia.org/wiki/Probability_mass_function>probability mass</a> on correctly conjugated verbs, even if only on a subset of the possible verbs? We argue that current implementations of TSE do not directly capture either of these goals, and propose new <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> to capture each goal separately. Under our metrics, we find that TSE overestimates systematicity of language models, but that <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> score up to 40 % better on verbs that they predict are likely in context.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.293.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--293 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.293 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.293" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.293/>Dynamically Disentangling Social Bias from Task-Oriented Representations with Adversarial Attack</a></strong><br><a href=/people/l/liwen-wang/>Liwen Wang</a>
|
<a href=/people/y/yuanmeng-yan/>Yuanmeng Yan</a>
|
<a href=/people/k/keqing-he/>Keqing He</a>
|
<a href=/people/y/yanan-wu/>Yanan Wu</a>
|
<a href=/people/w/weiran-xu/>Weiran Xu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--293><div class="card-body p-3 small">Representation learning is widely used in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> for a vast range of <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. However, <a href=https://en.wikipedia.org/wiki/Representation_(arts)>representations</a> derived from <a href=https://en.wikipedia.org/wiki/Text_corpus>text corpora</a> often reflect <a href=https://en.wikipedia.org/wiki/Bias>social biases</a>. This phenomenon is pervasive and consistent across different neural models, causing serious concern. Previous methods mostly rely on a pre-specified, user-provided direction or suffer from unstable training. In this paper, we propose an adversarial disentangled debiasing model to dynamically decouple social bias attributes from the intermediate representations trained on the main task. We aim to denoise bias information while training on the downstream task, rather than completely remove social bias and pursue static unbiased representations. Experiments show the effectiveness of our method, both on the effect of <a href=https://en.wikipedia.org/wiki/Debiasing>debiasing</a> and the main task performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.299.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--299 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.299 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.299/>On the Impact of <a href=https://en.wikipedia.org/wiki/Random_seed>Random Seeds</a> on the Fairness of Clinical Classifiers</a></strong><br><a href=/people/s/silvio-amir/>Silvio Amir</a>
|
<a href=/people/j/jan-willem-van-de-meent/>Jan-Willem van de Meent</a>
|
<a href=/people/b/byron-c-wallace/>Byron Wallace</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--299><div class="card-body p-3 small">Recent work has shown that fine-tuning large networks is surprisingly sensitive to changes in random seed(s). We explore the implications of this phenomenon for model fairness across demographic groups in clinical prediction tasks over electronic health records (EHR) in MIMIC-III the standard dataset in clinical NLP research. Apparent subgroup performance varies substantially for seeds that yield similar overall performance, although there is no evidence of a trade-off between overall and subgroup performance. However, we also find that the small sample sizes inherent to looking at intersections of <a href=https://en.wikipedia.org/wiki/Minority_group>minority groups</a> and somewhat rare conditions limit our ability to accurately estimate disparities. Further, we find that jointly optimizing for high overall performance and low disparities does not yield statistically significant improvements. Our results suggest that fairness work using MIMIC-III should carefully account for variations in apparent differences that may arise from <a href=https://en.wikipedia.org/wiki/Stochastic>stochasticity</a> and small sample sizes.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.300.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--300 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.300 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.naacl-main.300.OptionalSupplementaryData.zip data-toggle=tooltip data-placement=top title="Optional supplementary data"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.naacl-main.300/>Topic Model or Topic Twaddle? Re-evaluating Semantic Interpretability Measures</a></strong><br><a href=/people/c/caitlin-doogan/>Caitlin Doogan</a>
|
<a href=/people/w/wray-buntine/>Wray Buntine</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--300><div class="card-body p-3 small">When developing topic models, a critical question that should be asked is : How well will this <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> work in an applied setting? Because standard performance evaluation of topic interpretability uses automated measures modeled on human evaluation tests that are dissimilar to applied usage, these models&#8217; generalizability remains in question. In this paper, we probe the issue of <a href=https://en.wikipedia.org/wiki/Validity_(statistics)>validity</a> in topic model evaluation and assess how informative coherence measures are for specialized collections used in an applied setting. Informed by the literature, we propose four understandings of <a href=https://en.wikipedia.org/wiki/Interpretability>interpretability</a>. We evaluate these using a novel experimental framework reflective of varied applied settings, including human evaluations using <a href=https://en.wikipedia.org/wiki/Open_label>open labeling</a>, typical of <a href=https://en.wikipedia.org/wiki/Applied_science>applied research</a>. These evaluations show that for some specialized collections, standard coherence measures may not inform the most appropriate topic model or the optimal number of topics, and current interpretability performance validation methods are challenged as a means to confirm model quality in the absence of ground truth data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.304.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--304 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.304 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.304/>Learning to Learn to be Right for the Right Reasons</a></strong><br><a href=/people/p/pride-kavumba/>Pride Kavumba</a>
|
<a href=/people/b/benjamin-heinzerling/>Benjamin Heinzerling</a>
|
<a href=/people/a/ana-brassard/>Ana Brassard</a>
|
<a href=/people/k/kentaro-inui/>Kentaro Inui</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--304><div class="card-body p-3 small">Improving model generalization on held-out data is one of the core objectives in common- sense reasoning. Recent work has shown that models trained on the dataset with superficial cues tend to perform well on the easy test set with superficial cues but perform poorly on the hard test set without superficial cues. Previous approaches have resorted to manual methods of encouraging models not to overfit to superficial cues. While some of the <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>methods</a> have improved performance on hard instances, they also lead to degraded performance on easy in- stances. Here, we propose to explicitly learn a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> that does well on both the easy test set with superficial cues and the hard test set without superficial cues. Using a meta-learning objective, we learn such a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> that improves performance on both the easy test set and the hard test set. By evaluating our models on Choice of Plausible Alternatives (COPA) and Commonsense Explanation, we show that our proposed method leads to improved performance on both the easy test set and the hard test set upon which we observe up to 16.5 percentage points improvement over the baseline.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.305.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--305 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.305 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.305" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.305/>Double Perturbation : On the Robustness of Robustness and Counterfactual Bias Evaluation</a></strong><br><a href=/people/c/chong-zhang/>Chong Zhang</a>
|
<a href=/people/j/jieyu-zhao/>Jieyu Zhao</a>
|
<a href=/people/h/huan-zhang/>Huan Zhang</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/c/cho-jui-hsieh/>Cho-Jui Hsieh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--305><div class="card-body p-3 small">Robustness and counterfactual bias are usually evaluated on a test dataset. However, are these <a href=https://en.wikipedia.org/wiki/Evaluation>evaluations</a> robust? If the test dataset is perturbed slightly, will the evaluation results keep the same? In this paper, we propose a double perturbation framework to uncover model weaknesses beyond the test dataset. The framework first perturbs the test dataset to construct abundant natural sentences similar to the test data, and then diagnoses the prediction change regarding a single-word substitution. We apply this framework to study two perturbation-based approaches that are used to analyze models&#8217; robustness and counterfactual bias in <a href=https://en.wikipedia.org/wiki/English_language>English</a>. (1) For <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a>, we focus on synonym substitutions and identify vulnerable examples where prediction can be altered. Our proposed <a href=https://en.wikipedia.org/wiki/Cyberattack>attack</a> attains high success rates (96.0%-99.8 %) in finding vulnerable examples on both original and robustly trained <a href=https://en.wikipedia.org/wiki/Computer_simulation>CNNs</a> and Transformers. (2) For counterfactual bias, we focus on substituting demographic tokens (e.g., gender, race) and measure the shift of the expected prediction among constructed sentences. Our method is able to reveal the hidden model biases not directly shown in the test dataset. Our code is available at https://github.com/chong-z/nlp-second-order-attack.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.307.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--307 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.307 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.307/>Almost Free Semantic Draft for Neural Machine Translation</a></strong><br><a href=/people/x/xi-ai/>Xi Ai</a>
|
<a href=/people/b/bin-fang/>Bin Fang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--307><div class="card-body p-3 small">Translation quality can be improved by global information from the required target sentence because the <a href=https://en.wikipedia.org/wiki/Code>decoder</a> can understand both past and future information. However, the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> needs additional cost to produce and consider such <a href=https://en.wikipedia.org/wiki/Geographic_data_and_information>global information</a>. In this work, to inject global information but also save cost, we present an efficient method to sample and consider a semantic draft as global information from <a href=https://en.wikipedia.org/wiki/Semantic_space>semantic space</a> for decoding with almost free of cost. Unlike other successful adaptations, we do not have to perform an EM-like process that repeatedly samples a possible <a href=https://en.wikipedia.org/wiki/Semantics>semantic</a> from the <a href=https://en.wikipedia.org/wiki/Semantics>semantic space</a>. Empirical experiments show that the presented method can achieve competitive performance in common language pairs with a clear advantage in inference efficiency. We will open all our source code on GitHub.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.308.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--308 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.308 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.308" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.308/>Pruning-then-Expanding Model for <a href=https://en.wikipedia.org/wiki/Domain_adaptation>Domain Adaptation</a> of Neural Machine Translation</a></strong><br><a href=/people/s/shuhao-gu/>Shuhao Gu</a>
|
<a href=/people/y/yang-feng/>Yang Feng</a>
|
<a href=/people/w/wanying-xie/>Wanying Xie</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--308><div class="card-body p-3 small">Domain Adaptation is widely used in practical applications of <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a>, which aims to achieve good performance on both general domain and in-domain data. However, the existing methods for <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> usually suffer from catastrophic forgetting, large domain divergence, and model explosion. To address these three problems, we propose a method of <a href=https://en.wikipedia.org/wiki/Divide-and-conquer_algorithm>divide and conquer</a> which is based on the importance of neurons or parameters for the <a href=https://en.wikipedia.org/wiki/Translation_(biology)>translation model</a>. In this method, we first prune the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> and only keep the important neurons or parameters, making them responsible for both general-domain and in-domain translation. Then we further train the pruned model supervised by the original whole model with knowledge distillation. Last we expand the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to the original size and fine-tune the added parameters for the in-domain translation. We conducted experiments on different language pairs and domains and the results show that our method can achieve significant improvements compared with several strong baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.310.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--310 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.310 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.310/>Continual Learning for <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a></a></strong><br><a href=/people/y/yue-cao/>Yue Cao</a>
|
<a href=/people/h/hao-ran-wei/>Hao-Ran Wei</a>
|
<a href=/people/b/boxing-chen/>Boxing Chen</a>
|
<a href=/people/x/xiaojun-wan/>Xiaojun Wan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--310><div class="card-body p-3 small">Neural machine translation (NMT) models are data-driven and require large-scale training corpus. In practical applications, NMT models are usually trained on a general domain corpus and then fine-tuned by continuing training on the in-domain corpus. However, this bears the risk of catastrophic forgetting that the performance on the <a href=https://en.wikipedia.org/wiki/Domain_(software_engineering)>general domain</a> is decreased drastically. In this work, we propose a new continual learning framework for NMT models. We consider a scenario where the training is comprised of multiple stages and propose a dynamic knowledge distillation technique to alleviate the problem of catastrophic forgetting systematically. We also find that the bias exists in the output linear projection when fine-tuning on the in-domain corpus, and propose a bias-correction module to eliminate the bias. We conduct experiments on three representative settings of NMT application. Experimental results show that the proposed method achieves superior performance compared to baseline models in all settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.314.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--314 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.314 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.314" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.314/>ER-AE : Differentially Private Text Generation for Authorship Anonymization<span class=acl-fixed-case>ER</span>-<span class=acl-fixed-case>AE</span>: Differentially Private Text Generation for Authorship Anonymization</a></strong><br><a href=/people/h/haohan-bo/>Haohan Bo</a>
|
<a href=/people/s/steven-h-h-ding/>Steven H. H. Ding</a>
|
<a href=/people/b/benjamin-c-m-fung/>Benjamin C. M. Fung</a>
|
<a href=/people/f/farkhund-iqbal/>Farkhund Iqbal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--314><div class="card-body p-3 small">Most of privacy protection studies for <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>textual data</a> focus on removing explicit sensitive identifiers. However, <a href=https://en.wikipedia.org/wiki/Writing_style>personal writing style</a>, as a strong indicator of the <a href=https://en.wikipedia.org/wiki/Author>authorship</a>, is often neglected. Recent <a href=https://en.wikipedia.org/wiki/Research>studies</a>, such as SynTF, have shown promising results on privacy-preserving text mining. However, their <a href=https://en.wikipedia.org/wiki/Data_anonymization>anonymization algorithm</a> can only output numeric term vectors which are difficult for the recipients to interpret. We propose a novel text generation model with a two-set exponential mechanism for authorship anonymization. By augmenting the semantic information through a REINFORCE training reward function, the model can generate differentially private text that has a close semantic and similar grammatical structure to the original text while removing personal traits of the writing style. It does not assume any conditioned labels or paralleled text data for training. We evaluate the performance of the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on the real-life peer reviews dataset and the Yelp review dataset. The result suggests that our model outperforms the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> on semantic preservation, <a href=https://en.wikipedia.org/wiki/Obfuscation_(software)>authorship obfuscation</a>, and stylometric transformation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.320.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--320 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.320 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.320/>A recipe for annotating grounded clarifications</a></strong><br><a href=/people/l/luciana-benotti/>Luciana Benotti</a>
|
<a href=/people/p/patrick-blackburn/>Patrick Blackburn</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--320><div class="card-body p-3 small">In order to interpret the communicative intents of an utterance, it needs to be grounded in something that is outside of language ; that is, grounded in world modalities. In this paper, we argue that dialogue clarification mechanisms make explicit the process of interpreting the communicative intents of the speaker&#8217;s utterances by grounding them in the various modalities in which the dialogue is situated. This paper frames dialogue clarification mechanisms as an understudied research problem and a key missing piece in the giant jigsaw puzzle of <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a>. We discuss both the theoretical background and practical challenges posed by this problem and propose a recipe for obtaining grounding annotations. We conclude by highlighting ethical issues that need to be addressed in future work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.321.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--321 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.321 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.naacl-main.321.OptionalSupplementaryData.zip data-toggle=tooltip data-placement=top title="Optional supplementary data"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.naacl-main.321/>Grey-box Adversarial Attack And Defence For Sentiment Classification</a></strong><br><a href=/people/y/ying-xu/>Ying Xu</a>
|
<a href=/people/x/xu-zhong/>Xu Zhong</a>
|
<a href=/people/a/antonio-jimeno-yepes/>Antonio Jimeno Yepes</a>
|
<a href=/people/j/jey-han-lau/>Jey Han Lau</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--321><div class="card-body p-3 small">We introduce a grey-box adversarial attack and defence framework for sentiment classification. We address the issues of differentiability, label preservation and input reconstruction for adversarial attack and defence in one unified framework. Our results show that once trained, the attacking model is capable of generating high-quality adversarial examples substantially faster (one order of magnitude less in time) than state-of-the-art attacking methods. These examples also preserve the original <a href=https://en.wikipedia.org/wiki/Sentimentality>sentiment</a> according to <a href=https://en.wikipedia.org/wiki/Evaluation>human evaluation</a>. Additionally, our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> produces an improved <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> that is robust in defending against multiple adversarial attacking methods. Code is available at : https://github.com/ibm-aur-nlp/adv-def-text-dist.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.324.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--324 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.324 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.324/>Dynabench : Rethinking Benchmarking in NLP<span class=acl-fixed-case>NLP</span></a></strong><br><a href=/people/d/douwe-kiela/>Douwe Kiela</a>
|
<a href=/people/m/max-bartolo/>Max Bartolo</a>
|
<a href=/people/y/yixin-nie/>Yixin Nie</a>
|
<a href=/people/d/divyansh-kaushik/>Divyansh Kaushik</a>
|
<a href=/people/a/atticus-geiger/>Atticus Geiger</a>
|
<a href=/people/z/zhengxuan-wu/>Zhengxuan Wu</a>
|
<a href=/people/b/bertie-vidgen/>Bertie Vidgen</a>
|
<a href=/people/g/grusha-prasad/>Grusha Prasad</a>
|
<a href=/people/a/amanpreet-singh/>Amanpreet Singh</a>
|
<a href=/people/p/pratik-ringshia/>Pratik Ringshia</a>
|
<a href=/people/z/zhiyi-ma/>Zhiyi Ma</a>
|
<a href=/people/t/tristan-thrush/>Tristan Thrush</a>
|
<a href=/people/s/sebastian-riedel/>Sebastian Riedel</a>
|
<a href=/people/z/zeerak-waseem/>Zeerak Waseem</a>
|
<a href=/people/p/pontus-stenetorp/>Pontus Stenetorp</a>
|
<a href=/people/r/robin-jia/>Robin Jia</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a>
|
<a href=/people/c/christopher-potts/>Christopher Potts</a>
|
<a href=/people/a/adina-williams/>Adina Williams</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--324><div class="card-body p-3 small">We introduce Dynabench, an open-source platform for dynamic dataset creation and model benchmarking. Dynabench runs in a web browser and supports human-and-model-in-the-loop dataset creation : annotators seek to create examples that a target model will misclassify, but that another person will not. In this paper, we argue that Dynabench addresses a critical need in our community : contemporary models quickly achieve outstanding performance on benchmark tasks but nonetheless fail on simple challenge examples and falter in real-world scenarios. With Dynabench, dataset creation, model development, and model assessment can directly inform each other, leading to more robust and informative benchmarks. We report on four initial NLP tasks, illustrating these concepts and highlighting the promise of the <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a>, and address potential objections to dynamic benchmarking as a new standard for the field.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.326.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--326 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.326 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.326" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.326/>Predicting Discourse Trees from Transformer-based Neural Summarizers</a></strong><br><a href=/people/w/wen-xiao/>Wen Xiao</a>
|
<a href=/people/p/patrick-huber/>Patrick Huber</a>
|
<a href=/people/g/giuseppe-carenini/>Giuseppe Carenini</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--326><div class="card-body p-3 small">Previous work indicates that <a href=https://en.wikipedia.org/wiki/Discourse_analysis>discourse information</a> benefits <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a>. In this paper, we explore whether this synergy between <a href=https://en.wikipedia.org/wiki/Discourse>discourse</a> and <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> is bidirectional, by inferring document-level discourse trees from pre-trained neural summarizers. In particular, we generate unlabeled RST-style discourse trees from the self-attention matrices of the transformer model. Experiments across models and datasets reveal that the summarizer learns both, dependency- and constituency-style discourse information, which is typically encoded in a single head, covering long- and short-distance discourse dependencies. Overall, the experimental results suggest that the learned <a href=https://en.wikipedia.org/wiki/Discourse_analysis>discourse information</a> is general and transferable inter-domain.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.329.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--329 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.329 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.329" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.329/>Stay Together : A System for Single and Split-antecedent Anaphora Resolution</a></strong><br><a href=/people/j/juntao-yu/>Juntao Yu</a>
|
<a href=/people/n/nafise-sadat-moosavi/>Nafise Sadat Moosavi</a>
|
<a href=/people/s/silviu-paun/>Silviu Paun</a>
|
<a href=/people/m/massimo-poesio/>Massimo Poesio</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--329><div class="card-body p-3 small">The state-of-the-art on basic, single-antecedent anaphora has greatly improved in recent years. Researchers have therefore started to pay more attention to more complex cases of <a href=https://en.wikipedia.org/wiki/Anaphora_(linguistics)>anaphora</a> such as split-antecedent anaphora, as in Time-Warner is considering a legal challenge to Telecommunications Inc&#8217;s plan to buy half of Showtime Networks Inca move that could lead to all-out war between the two powerful companies. Split-antecedent anaphora is rarer and more complex to resolve than single-antecedent anaphora ; as a result, it is not annotated in many datasets designed to test <a href=https://en.wikipedia.org/wiki/Coreference>coreference</a>, and previous work on resolving this type of <a href=https://en.wikipedia.org/wiki/Anaphora_(linguistics)>anaphora</a> was carried out in unrealistic conditions that assume gold mentions and/or gold split-antecedent anaphors are available. These systems also focus on split-antecedent anaphors only. In this work, we introduce a system that resolves both single and split-antecedent anaphors, and evaluate it in a more realistic setting that uses predicted mentions. We also start addressing the question of how to evaluate single and split-antecedent anaphors together using standard coreference evaluation metrics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.331.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--331 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.331 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.331" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.331/>CoRT : Complementary Rankings from Transformers<span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>RT</span>: Complementary Rankings from Transformers</a></strong><br><a href=/people/m/marco-wrzalik/>Marco Wrzalik</a>
|
<a href=/people/d/dirk-krechel/>Dirk Krechel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--331><div class="card-body p-3 small">Many recent approaches towards neural information retrieval mitigate their <a href=https://en.wikipedia.org/wiki/Computational_cost>computational costs</a> by using a multi-stage ranking pipeline. In the first stage, a number of potentially relevant candidates are retrieved using an efficient retrieval model such as <a href=https://en.wikipedia.org/wiki/BM25>BM25</a>. Although <a href=https://en.wikipedia.org/wiki/BM25>BM25</a> has proven decent performance as a first-stage ranker, <a href=https://en.wikipedia.org/wiki/It_(2017_film)>it</a> tends to miss relevant passages. In this context we propose CoRT, a simple neural first-stage ranking model that leverages contextual representations from pretrained language models such as BERT to complement term-based ranking functions while causing no significant delay at query time. Using the MS MARCO dataset, we show that CoRT significantly increases the candidate recall by complementing <a href=https://en.wikipedia.org/wiki/BM25>BM25</a> with missing candidates. Consequently, we find subsequent re-rankers achieve superior results with less candidates. We further demonstrate that passage retrieval using <a href=https://en.wikipedia.org/wiki/CoRoT>CoRT</a> can be realized with surprisingly low latencies.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.332.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--332 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.332 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.332" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.332/>Multi-source Neural Topic Modeling in Multi-view Embedding Spaces</a></strong><br><a href=/people/p/pankaj-gupta/>Pankaj Gupta</a>
|
<a href=/people/y/yatin-chaudhary/>Yatin Chaudhary</a>
|
<a href=/people/h/hinrich-schutze/>Hinrich Schütze</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--332><div class="card-body p-3 small">Though <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> and topics are complementary representations, several past works have only used pretrained word embeddings in (neural) topic modeling to address data sparsity in short-text or small collection of documents. This work presents a novel neural topic modeling framework using multi-view embed ding spaces : (1) pretrained topic-embeddings, and (2) pretrained word-embeddings (context-insensitive from Glove and context-sensitive from BERT models) jointly from one or many sources to improve topic quality and better deal with polysemy. In doing so, we first build respective pools of pretrained topic (i.e., TopicPool) and <a href=https://en.wikipedia.org/wiki/Word_processor_(electronic_device)>word embeddings</a> (i.e., WordPool). We then identify one or more relevant source domain(s) and <a href=https://en.wikipedia.org/wiki/Knowledge_transfer>transfer knowledge</a> to guide meaningful learning in the sparse target domain. Within neural topic modeling, we quantify the quality of topics and document representations via generalization (perplexity), interpretability (topic coherence) and information retrieval (IR) using short-text, long-text, small and large document collections from news and medical domains. Introducing the multi-source multi-view embedding spaces, we have shown state-of-the-art neural topic modeling using 6 source (high-resource) and 5 target (low-resource) corpora.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.334.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--334 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.334 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.334" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.334/>Self-Alignment Pretraining for Biomedical Entity Representations</a></strong><br><a href=/people/f/fangyu-liu/>Fangyu Liu</a>
|
<a href=/people/e/ehsan-shareghi/>Ehsan Shareghi</a>
|
<a href=/people/z/zaiqiao-meng/>Zaiqiao Meng</a>
|
<a href=/people/m/marco-basaldella/>Marco Basaldella</a>
|
<a href=/people/n/nigel-collier/>Nigel Collier</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--334><div class="card-body p-3 small">Despite the widespread success of self-supervised learning via masked language models (MLM), accurately capturing fine-grained semantic relationships in the biomedical domain remains a challenge. This is of paramount importance for entity-level tasks such as <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity linking</a> where the ability to model entity relations (especially synonymy) is pivotal. To address this challenge, we propose SapBERT, a pretraining scheme that self-aligns the representation space of biomedical entities. We design a scalable metric learning framework that can leverage <a href=https://en.wikipedia.org/wiki/Unified_Modeling_Language>UMLS</a>, a massive collection of biomedical ontologies with 4M+ concepts. In contrast with previous pipeline-based hybrid systems, SapBERT offers an elegant one-model-for-all solution to the problem of medical entity linking (MEL), achieving a new state-of-the-art (SOTA) on six MEL benchmarking datasets. In the <a href=https://en.wikipedia.org/wiki/Scientific_method>scientific domain</a>, we achieve SOTA even without task-specific supervision. With substantial improvement over various domain-specific pretrained MLMs such as BioBERT, SciBERTand and PubMedBERT, our pretraining scheme proves to be both effective and robust.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.335.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--335 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.335 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.335/>TaxoClass : Hierarchical Multi-Label Text Classification Using Only Class Names<span class=acl-fixed-case>T</span>axo<span class=acl-fixed-case>C</span>lass: Hierarchical Multi-Label Text Classification Using Only Class Names</a></strong><br><a href=/people/j/jiaming-shen/>Jiaming Shen</a>
|
<a href=/people/w/wenda-qiu/>Wenda Qiu</a>
|
<a href=/people/y/yu-meng/>Yu Meng</a>
|
<a href=/people/j/jingbo-shang/>Jingbo Shang</a>
|
<a href=/people/x/xiang-ren/>Xiang Ren</a>
|
<a href=/people/j/jiawei-han/>Jiawei Han</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--335><div class="card-body p-3 small">Hierarchical multi-label text classification (HMTC) aims to tag each document with a set of classes from a <a href=https://en.wikipedia.org/wiki/Taxonomic_rank>taxonomic class hierarchy</a>. Most existing HMTC methods train <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> using massive human-labeled documents, which are often too costly to obtain in real-world applications. In this paper, we explore to conduct HMTC based on only class surface names as supervision signals. We observe that to perform HMTC, human experts typically first pinpoint a few most essential classes for the document as its core classes, and then check core classes&#8217; ancestor classes to ensure the coverage. To mimic human experts, we propose a novel HMTC framework, named TaxoClass. Specifically, TaxoClass (1) calculates document-class similarities using a textual entailment model, (2) identifies a document&#8217;s core classes and utilizes confident core classes to train a taxonomy-enhanced classifier, and (3) generalizes the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> via multi-label self-training. Our experiments on two challenging datasets show TaxoClass can achieve around 0.71 Example-F1 using only <a href=https://en.wikipedia.org/wiki/Class_(computer_programming)>class names</a>, outperforming the best previous <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> by 25 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.336.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--336 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.336 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.336" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.336/>MERMAID : Metaphor Generation with <a href=https://en.wikipedia.org/wiki/Symbol>Symbolism</a> and Discriminative Decoding<span class=acl-fixed-case>MERMAID</span>: Metaphor Generation with Symbolism and Discriminative Decoding</a></strong><br><a href=/people/t/tuhin-chakrabarty/>Tuhin Chakrabarty</a>
|
<a href=/people/x/xurui-zhang/>Xurui Zhang</a>
|
<a href=/people/s/smaranda-muresan/>Smaranda Muresan</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--336><div class="card-body p-3 small">Generating metaphors is a challenging task as it requires a proper understanding of <a href=https://en.wikipedia.org/wiki/Abstraction>abstract concepts</a>, making connections between unrelated concepts, and deviating from the <a href=https://en.wikipedia.org/wiki/Literal_and_figurative_language>literal meaning</a>. In this paper, we aim to generate a metaphoric sentence given a <a href=https://en.wikipedia.org/wiki/Literal_and_figurative_language>literal expression</a> by replacing relevant verbs. Based on a theoretically-grounded connection between metaphors and symbols, we propose a method to automatically construct a parallel corpus by transforming a large number of metaphorical sentences from the Gutenberg Poetry corpus (CITATION) to their literal counterpart using recent advances in masked language modeling coupled with commonsense inference. For the generation task, we incorporate a metaphor discriminator to guide the decoding of a sequence to sequence model fine-tuned on our parallel data to generate high-quality metaphors. Human evaluation on an independent test set of literal statements shows that our best <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> generates <a href=https://en.wikipedia.org/wiki/Metaphor>metaphors</a> better than three well-crafted baselines 66 % of the time on average. A task-based evaluation shows that human-written poems enhanced with <a href=https://en.wikipedia.org/wiki/Metaphor>metaphors</a> proposed by our model are preferred 68 % of the time compared to poems without <a href=https://en.wikipedia.org/wiki/Metaphor>metaphors</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.340.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--340 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.340 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.340" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.340/>Ask what’s missing and what’s useful : Improving Clarification Question Generation using Global Knowledge</a></strong><br><a href=/people/b/bodhisattwa-prasad-majumder/>Bodhisattwa Prasad Majumder</a>
|
<a href=/people/s/sudha-rao/>Sudha Rao</a>
|
<a href=/people/m/michel-galley/>Michel Galley</a>
|
<a href=/people/j/julian-mcauley/>Julian McAuley</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--340><div class="card-body p-3 small">The ability to generate clarification questions i.e., questions that identify useful missing information in a given context, is important in reducing <a href=https://en.wikipedia.org/wiki/Ambiguity>ambiguity</a>. Humans use previous experience with similar contexts to form a global view and compare it to the given context to ascertain what is missing and what is useful in the context. Inspired by this, we propose a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> for clarification question generation where we first identify what is missing by taking a difference between the global and the local view and then train a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to identify what is useful and generate a question about it. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms several <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> as judged by both <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>automatic metrics</a> and <a href=https://en.wikipedia.org/wiki/Human>humans</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.346.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--346 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.346 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.346/>I’m Not Mad : Commonsense Implications of Negation and Contradiction<span class=acl-fixed-case>I</span>’m Not Mad”: Commonsense Implications of Negation and Contradiction</a></strong><br><a href=/people/l/liwei-jiang/>Liwei Jiang</a>
|
<a href=/people/a/antoine-bosselut/>Antoine Bosselut</a>
|
<a href=/people/c/chandra-bhagavatula/>Chandra Bhagavatula</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--346><div class="card-body p-3 small">Natural language inference requires reasoning about <a href=https://en.wikipedia.org/wiki/Contradiction>contradictions</a>, <a href=https://en.wikipedia.org/wiki/Affirmation_and_negation>negations</a>, and their commonsense implications. Given a simple premise (e.g., I&#8217;m mad at you), humans can reason about the varying shades of contradictory statements ranging from straightforward negations (I&#8217;m not mad at you) to commonsense contradictions (I&#8217;m happy). Moreover, these negated or contradictory statements shift the commonsense implications of the original premise in interesting and nontrivial ways. For example, while I&#8217;m mad implies I&#8217;m unhappy about something, negating the premise does not necessarily negate the corresponding commonsense implications. In this paper, we present the first comprehensive study focusing on commonsense implications of <a href=https://en.wikipedia.org/wiki/Negation>negated statements</a> and <a href=https://en.wikipedia.org/wiki/Contradiction>contradictions</a>. We introduce ANION, a new commonsense knowledge graph with 624 K if-then rules focusing on negated and contradictory events. We then present joint generative and discriminative inference models for this new resource, providing novel empirical insights on how logical negations and commonsense contradictions reshape the commonsense implications of their original premises.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.347.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--347 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.347 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.347/>Identifying Medical Self-Disclosure in Online Communities</a></strong><br><a href=/people/m/mina-valizadeh/>Mina Valizadeh</a>
|
<a href=/people/p/pardis-ranjbar-noiey/>Pardis Ranjbar-Noiey</a>
|
<a href=/people/c/cornelia-caragea/>Cornelia Caragea</a>
|
<a href=/people/n/natalie-parde/>Natalie Parde</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--347><div class="card-body p-3 small">Self-disclosure in online health conversations may offer a host of benefits, including earlier detection and treatment of medical issues that may have otherwise gone unaddressed. However, research analyzing medical self-disclosure in <a href=https://en.wikipedia.org/wiki/Online_community>online communities</a> is limited. We address this shortcoming by introducing a new dataset of health-related posts collected from online social platforms, categorized into three groups (No Self-Disclosure, Possible Self-Disclosure, and Clear Self-Disclosure) with high inter-annotator agreement (_ k_=0.88). We make this <a href=https://en.wikipedia.org/wiki/Data>data</a> available to the research community. We also release a <a href=https://en.wikipedia.org/wiki/Predictive_modelling>predictive model</a> trained on this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> that achieves an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 81.02 %, establishing a strong performance benchmark for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.348.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--348 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.348 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.348/>Language in a (Search) Box : Grounding <a href=https://en.wikipedia.org/wiki/Language_acquisition>Language Learning</a> in Real-World Human-Machine Interaction</a></strong><br><a href=/people/f/federico-bianchi/>Federico Bianchi</a>
|
<a href=/people/c/ciro-greco/>Ciro Greco</a>
|
<a href=/people/j/jacopo-tagliabue/>Jacopo Tagliabue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--348><div class="card-body p-3 small">We investigate grounded language learning through real-world data, by modelling a teacher-learner dynamics through the natural interactions occurring between users and <a href=https://en.wikipedia.org/wiki/Web_search_engine>search engines</a> ; in particular, we explore the emergence of semantic generalization from unsupervised dense representations outside of synthetic environments. A grounding domain, a denotation function and a <a href=https://en.wikipedia.org/wiki/Composition_function>composition function</a> are learned from user data only. We show how the resulting <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> for <a href=https://en.wikipedia.org/wiki/Noun_phrase>noun phrases</a> exhibits compositional properties while being fully learnable without any explicit <a href=https://en.wikipedia.org/wiki/Labelling>labelling</a>. We benchmark our grounded semantics on compositionality and zero-shot inference tasks, and we show that it provides better results and better generalizations than SOTA non-grounded models, such as <a href=https://en.wikipedia.org/wiki/Word2vec>word2vec</a> and BERT.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.349.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--349 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.349 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.349" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.349/>Finding Concept-specific Biases in FormMeaning Associations</a></strong><br><a href=/people/t/tiago-pimentel/>Tiago Pimentel</a>
|
<a href=/people/b/brian-roark/>Brian Roark</a>
|
<a href=/people/s/soren-wichmann/>Søren Wichmann</a>
|
<a href=/people/r/ryan-cotterell/>Ryan Cotterell</a>
|
<a href=/people/d/damian-blasi/>Damián Blasi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--349><div class="card-body p-3 small">This work presents an information-theoretic operationalisation of cross-linguistic non-arbitrariness. It is not a new idea that there are small, cross-linguistic associations between the forms and meanings of words. For instance, it has been claimed (Blasi et al., 2016) that the word for tongue is more likely than chance to contain the phone [ l ]. By controlling for the influence of language family and geographic proximity within a very large concept-aligned, cross-lingual lexicon, we extend methods previously used to detect within language non-arbitrariness (Pimentel et al., 2019) to measure cross-linguistic associations. We find that there is a significant effect of non-arbitrariness, but it is unsurprisingly small (less than 0.5 % on average according to our information-theoretic estimate). We also provide a concept-level analysis which shows that a quarter of the <a href=https://en.wikipedia.org/wiki/Concept>concepts</a> considered in our work exhibit a significant level of cross-linguistic non-arbitrariness. In sum, the paper provides new methods to detect cross-linguistic associations at scale, and confirms their effects are minor.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.352.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--352 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.352 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.352/>Linguistic Complexity Loss in Text-Based Therapy</a></strong><br><a href=/people/j/jason-wei/>Jason Wei</a>
|
<a href=/people/k/kelly-finn/>Kelly Finn</a>
|
<a href=/people/e/emma-templeton/>Emma Templeton</a>
|
<a href=/people/t/thalia-wheatley/>Thalia Wheatley</a>
|
<a href=/people/s/soroush-vosoughi/>Soroush Vosoughi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--352><div class="card-body p-3 small">The complexity loss paradox, which posits that individuals suffering from disease exhibit surprisingly predictable behavioral dynamics, has been observed in a variety of both human and animal physiological systems. The recent advent of online text-based therapy presents a new opportunity to analyze the complexity loss paradox in a novel <a href=https://en.wikipedia.org/wiki/Operationalization>operationalization</a> : linguistic complexity loss in text-based therapy conversations. In this paper, we analyze linguistic complexity correlates of <a href=https://en.wikipedia.org/wiki/Mental_health>mental health</a> in the online therapy messages sent between therapists and 7,170 clients who provided 30,437 corresponding survey responses on their anxiety. We found that when clients reported more anxiety, they showed reduced <a href=https://en.wikipedia.org/wiki/Lexical_diversity>lexical diversity</a> as estimated by the moving average type-token ratio. Therapists, on the other hand, used language of higher reading difficulty, <a href=https://en.wikipedia.org/wiki/Syntax>syntactic complexity</a>, and age of acquisition when clients were more anxious. Finally, we found that clients, and to an even greater extent, <a href=https://en.wikipedia.org/wiki/Therapy>therapists</a>, exhibited consistent levels of many linguistic complexity measures. These results demonstrate how linguistic analysis of text-based communication can be leveraged as a marker for <a href=https://en.wikipedia.org/wiki/Anxiety>anxiety</a>, an exciting prospect in a time of both increased online communication and increased mental health issues.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.353.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--353 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.353 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.353" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.353/>Ab Antiquo : Neural Proto-language Reconstruction</a></strong><br><a href=/people/c/carlo-meloni/>Carlo Meloni</a>
|
<a href=/people/s/shauli-ravfogel/>Shauli Ravfogel</a>
|
<a href=/people/y/yoav-goldberg/>Yoav Goldberg</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--353><div class="card-body p-3 small">Historical linguists have identified regularities in the process of historic sound change. The comparative method utilizes those regularities to reconstruct proto-words based on observed forms in <a href=https://en.wikipedia.org/wiki/Daughter_language>daughter languages</a>. Can this <a href=https://en.wikipedia.org/wiki/Process_(engineering)>process</a> be efficiently automated? We address the task of proto-word reconstruction, in which the model is exposed to cognates in contemporary daughter languages, and has to predict the proto word in the ancestor language. We provide a novel <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, encompassing over 8,000 comparative entries, and show that neural sequence models outperform conventional methods applied to this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> so far. Error analysis reveals a variability in the ability of neural model to capture different <a href=https://en.wikipedia.org/wiki/Phonological_change>phonological changes</a>, correlating with the <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a> of the changes. Analysis of learned embeddings reveals the models learn phonologically meaningful generalizations, corresponding to well-attested phonological shifts documented by <a href=https://en.wikipedia.org/wiki/Historical_linguistics>historical linguistics</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.361.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--361 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.361 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.361/>Adapting <a href=https://en.wikipedia.org/wiki/Coreference_resolution>Coreference Resolution</a> for Processing Violent Death Narratives</a></strong><br><a href=/people/a/ankith-uppunda/>Ankith Uppunda</a>
|
<a href=/people/s/susan-cochran/>Susan Cochran</a>
|
<a href=/people/j/jacob-foster/>Jacob Foster</a>
|
<a href=/people/a/alina-arseniev-koehler/>Alina Arseniev-Koehler</a>
|
<a href=/people/v/vickie-mays/>Vickie Mays</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--361><div class="card-body p-3 small">Coreference resolution is an important compo-nent in analyzing <a href=https://en.wikipedia.org/wiki/Narrative>narrative text</a> from admin-istrative data (e.g., clinical or police sources).However, existing coreference models trainedon general language corpora suffer from poortransferability due to domain gaps, especiallywhen they are applied to gender-inclusive datawith lesbian, gay, bisexual, and transgender(LGBT) individuals. In this paper, we an-alyzed the challenges of coreference resolu-tion in an exemplary form of administrativetext written in English : violent death nar-ratives from the USA&#8217;s Centers for DiseaseControl&#8217;s (CDC) National Violent Death Re-porting System. We developed a set of dataaugmentation rules to improve model perfor-mance using a probabilistic data programmingframework. Experiments on narratives froman administrative database, as well as existinggender-inclusive coreference datasets, demon-strate the effectiveness of data augmentationin training coreference models that can betterhandle text data about LGBT individuals.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.367.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--367 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.367 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.367/>Does Structure Matter? Encoding Documents for Machine Reading Comprehension</a></strong><br><a href=/people/h/hui-wan/>Hui Wan</a>
|
<a href=/people/s/song-feng/>Song Feng</a>
|
<a href=/people/c/chulaka-gunasekara/>Chulaka Gunasekara</a>
|
<a href=/people/s/siva-sankalp-patel/>Siva Sankalp Patel</a>
|
<a href=/people/s/sachindra-joshi/>Sachindra Joshi</a>
|
<a href=/people/l/luis-lastras/>Luis Lastras</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--367><div class="card-body p-3 small">Machine reading comprehension is a challenging <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> especially for querying documents with deep and interconnected contexts. Transformer-based methods have shown advanced performances on this task ; however, most of them still treat documents as a flat sequence of tokens. This work proposes a new Transformer-based method that reads a document as <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>tree slices</a>. It contains two modules for identifying more relevant text passage and the best answer span respectively, which are not only jointly trained but also jointly consulted at inference time. Our evaluation results show that our proposed method outperforms several competitive baseline approaches on two <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> from varied domains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.373.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--373 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.373 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.373/>Constructing Taxonomies from Pretrained Language Models</a></strong><br><a href=/people/c/catherine-chen/>Catherine Chen</a>
|
<a href=/people/k/kevin-lin/>Kevin Lin</a>
|
<a href=/people/d/dan-klein/>Dan Klein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--373><div class="card-body p-3 small">We present a <a href=https://en.wikipedia.org/wiki/Methodology>method</a> for constructing <a href=https://en.wikipedia.org/wiki/Taxonomy_(biology)>taxonomic trees</a> (e.g., WordNet) using pretrained language models. Our approach is composed of two <a href=https://en.wikipedia.org/wiki/Modular_programming>modules</a>, one that predicts parenthood relations and another that reconciles those pairwise predictions into <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>trees</a>. The parenthood prediction module produces likelihood scores for each potential parent-child pair, creating a graph of parent-child relation scores. The tree reconciliation module treats the task as a <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph optimization problem</a> and outputs the maximum spanning tree of this <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a>. We train our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on subtrees sampled from <a href=https://en.wikipedia.org/wiki/WordNet>WordNet</a>, and test on nonoverlapping WordNet subtrees. We show that incorporating web-retrieved glosses can further improve performance. On the task of constructing subtrees of <a href=https://en.wikipedia.org/wiki/WordNet>English WordNet</a>, the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves 66.7 ancestor F1, a 20.0 % relative increase over the previous best published result on this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. In addition, we convert the original English dataset into nine other languages using Open Multilingual WordNet and extend our results across these languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.378.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--378 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.378 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.378" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.378/>Adapting <a href=https://en.wikipedia.org/wiki/BERT>BERT</a> for Continual Learning of a Sequence of Aspect Sentiment Classification Tasks<span class=acl-fixed-case>BERT</span> for Continual Learning of a Sequence of Aspect Sentiment Classification Tasks</a></strong><br><a href=/people/z/zixuan-ke/>Zixuan Ke</a>
|
<a href=/people/h/hu-xu/>Hu Xu</a>
|
<a href=/people/b/bing-liu/>Bing Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--378><div class="card-body p-3 small">This paper studies continual learning (CL) of a sequence of aspect sentiment classification (ASC) tasks. Although some CL techniques have been proposed for document sentiment classification, we are not aware of any CL work on ASC. A CL system that incrementally learns a sequence of ASC tasks should address the following two issues : (1) transfer knowledge learned from previous tasks to the new task to help it learn a better model, and (2) maintain the performance of the models for previous tasks so that they are not forgotten. This paper proposes a novel capsule network based model called B-CL to address these issues. B-CL markedly improves the ASC performance on both the new task and the old tasks via forward and backward knowledge transfer. The effectiveness of B-CL is demonstrated through extensive experiments.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.381.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--381 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.381 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.381" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.381/>Enriching Transformers with Structured Tensor-Product Representations for Abstractive Summarization</a></strong><br><a href=/people/y/yichen-jiang/>Yichen Jiang</a>
|
<a href=/people/a/asli-celikyilmaz/>Asli Celikyilmaz</a>
|
<a href=/people/p/paul-smolensky/>Paul Smolensky</a>
|
<a href=/people/p/paul-soulos/>Paul Soulos</a>
|
<a href=/people/s/sudha-rao/>Sudha Rao</a>
|
<a href=/people/h/hamid-palangi/>Hamid Palangi</a>
|
<a href=/people/r/roland-fernandez/>Roland Fernandez</a>
|
<a href=/people/c/caitlin-smith/>Caitlin Smith</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a>
|
<a href=/people/j/jianfeng-gao/>Jianfeng Gao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--381><div class="card-body p-3 small">Abstractive summarization, the task of generating a concise summary of input documents, requires : (1) reasoning over the source document to determine the salient pieces of information scattered across the long document, and (2) composing a cohesive text by reconstructing these salient facts into a shorter summary that faithfully reflects the complex relations connecting these facts. In this paper, we adapt TP-Transformer (Schlag et al., 2019), an architecture that enriches the original Transformer (Vaswani et al., 2017) with the explicitly compositional Tensor Product Representation (TPR), for the task of abstractive summarization. The key feature of our model is a structural bias that we introduce by encoding two separate representations for each token to represent the syntactic structure (with role vectors) and semantic content (with filler vectors) separately. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> then binds the role and filler vectors into the TPR as the layer output. We argue that the structured intermediate representations enable the model to take better control of the contents (salient facts) and structures (the syntax that connects the facts) when generating the summary. Empirically, we show that our TP-Transformer outperforms the Transformer and the original TP-Transformer significantly on several abstractive summarization datasets based on both automatic and human evaluations. On several syntactic and semantic probing tasks, we demonstrate the emergent structural information in the role vectors and the performance gain by information specificity of the role vectors and improved syntactic interpretability in the TPR layer outputs. (Code and models are available at https://github.com/jiangycTarheel/TPT-Summ)</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.383.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--383 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.383 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.383" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.383/>Understanding Factuality in Abstractive Summarization with FRANK : A Benchmark for Factuality Metrics<span class=acl-fixed-case>FRANK</span>: A Benchmark for Factuality Metrics</a></strong><br><a href=/people/a/artidoro-pagnoni/>Artidoro Pagnoni</a>
|
<a href=/people/v/vidhisha-balachandran/>Vidhisha Balachandran</a>
|
<a href=/people/y/yulia-tsvetkov/>Yulia Tsvetkov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--383><div class="card-body p-3 small">Modern <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization models</a> generate highly fluent but often factually unreliable outputs. This motivated a surge of <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> attempting to measure the <a href=https://en.wikipedia.org/wiki/Fact>factuality</a> of automatically generated summaries. Due to the lack of common benchmarks, these <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> can not be compared. Moreover, all these methods treat <a href=https://en.wikipedia.org/wiki/Factuality>factuality</a> as a binary concept and fail to provide deeper insights on the kinds of inconsistencies made by different systems. To address these limitations, we devise a typology of factual errors and use it to collect human annotations of generated summaries from state-of-the-art summarization systems for the CNN / DM and XSum datasets. Through these annotations we identify the proportion of different categories of factual errors and benchmark factuality metrics, showing their correlation with human judgement as well as their specific strengths and weaknesses.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.384.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--384 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.384 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.384" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.384/>GSum : A General Framework for Guided Neural Abstractive Summarization<span class=acl-fixed-case>GS</span>um: A General Framework for Guided Neural Abstractive Summarization</a></strong><br><a href=/people/z/zi-yi-dou/>Zi-Yi Dou</a>
|
<a href=/people/p/pengfei-liu/>Pengfei Liu</a>
|
<a href=/people/h/hiroaki-hayashi/>Hiroaki Hayashi</a>
|
<a href=/people/z/zhengbao-jiang/>Zhengbao Jiang</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--384><div class="card-body p-3 small">Neural abstractive summarization models are flexible and can produce coherent summaries, but they are sometimes unfaithful and can be difficult to control. While previous studies attempt to provide different types of <a href=https://en.wikipedia.org/wiki/Guidance>guidance</a> to control the output and increase <a href=https://en.wikipedia.org/wiki/Faithfulness>faithfulness</a>, it is not clear how these <a href=https://en.wikipedia.org/wiki/Strategy>strategies</a> compare and contrast to each other. In this paper, we propose a general and extensible guided summarization framework (GSum) that can effectively take different kinds of external guidance as input, and we perform experiments across several different varieties. Experiments demonstrate that this model is effective, achieving state-of-the-art performance according to ROUGE on 4 popular summarization datasets when using highlighted sentences as guidance. In addition, we show that our guided model can generate more faithful summaries and demonstrate how different types of <a href=https://en.wikipedia.org/wiki/Guidance>guidance</a> generate qualitatively different summaries, lending a degree of <a href=https://en.wikipedia.org/wiki/Controllability>controllability</a> to the learned models.<b>GSum</b>) that can effectively take different kinds of external guidance as input, and we perform experiments across several different varieties. Experiments demonstrate that this model is effective, achieving state-of-the-art performance according to ROUGE on 4 popular summarization datasets when using highlighted sentences as guidance. In addition, we show that our guided model can generate more faithful summaries and demonstrate how different types of guidance generate qualitatively different summaries, lending a degree of controllability to the learned models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.386.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--386 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.386 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.386/>TuringAdvice : A Generative and Dynamic Evaluation of Language Use<span class=acl-fixed-case>T</span>uring<span class=acl-fixed-case>A</span>dvice: A Generative and Dynamic Evaluation of Language Use</a></strong><br><a href=/people/r/rowan-zellers/>Rowan Zellers</a>
|
<a href=/people/a/ari-holtzman/>Ari Holtzman</a>
|
<a href=/people/e/elizabeth-clark/>Elizabeth Clark</a>
|
<a href=/people/l/lianhui-qin/>Lianhui Qin</a>
|
<a href=/people/a/ali-farhadi/>Ali Farhadi</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--386><div class="card-body p-3 small">We propose TuringAdvice, a new challenge task and dataset for language understanding models. Given a written situation that a real person is currently facing, a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> must generate helpful advice in natural language. Our evaluation framework tests a fundamental aspect of human language understanding : our ability to use <a href=https://en.wikipedia.org/wiki/Language>language</a> to resolve open-ended situations by communicating with each other. Empirical results show that today&#8217;s <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> struggle at TuringAdvice, even multibillion parameter models finetuned on 600k in-domain training examples. The best <a href=https://en.wikipedia.org/wiki/Scientific_modelling>model</a>, T5, writes advice that is at least as helpful as human-written advice in only 14 % of cases ; a much larger non-finetunable GPT3 model does even worse at 4 %. This low performance reveals language understanding errors that are hard to spot outside of a generative setting, showing much room for progress.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.390.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--390 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.390 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.390/>Identifying inherent disagreement in natural language inference</a></strong><br><a href=/people/x/xinliang-frederick-zhang/>Xinliang Frederick Zhang</a>
|
<a href=/people/m/marie-catherine-de-marneffe/>Marie-Catherine de Marneffe</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--390><div class="card-body p-3 small">Natural language inference (NLI) is the task of determining whether a piece of text is entailed, contradicted by or unrelated to another piece of text. In this paper, we investigate how to tease systematic inferences (i.e., items for which people agree on the NLI label) apart from disagreement items (i.e., items which lead to different annotations), which most prior work has overlooked. To distinguish systematic inferences from disagreement items, we propose Artificial Annotators (AAs) to simulate the uncertainty in the annotation process by capturing the modes in annotations. Results on the CommitmentBank, a corpus of naturally occurring discourses in English, confirm that our approach performs statistically significantly better than all baselines. We further show that <a href=https://en.wikipedia.org/wiki/Adult_learner>AAs</a> learn <a href=https://en.wikipedia.org/wiki/Pattern_recognition>linguistic patterns</a> and context-dependent reasoning.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.391.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--391 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.391 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.391" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.391/>Modeling Human Mental States with an Entity-based Narrative Graph</a></strong><br><a href=/people/i/i-ta-lee/>I-Ta Lee</a>
|
<a href=/people/m/maria-leonor-pacheco/>Maria Leonor Pacheco</a>
|
<a href=/people/d/dan-goldwasser/>Dan Goldwasser</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--391><div class="card-body p-3 small">Understanding <a href=https://en.wikipedia.org/wiki/Narrative>narrative text</a> requires capturing characters&#8217; motivations, goals, and <a href=https://en.wikipedia.org/wiki/Mental_state>mental states</a>. This paper proposes an Entity-based Narrative Graph (ENG) to model the internal- states of characters in a story. We explicitly model entities, their interactions and the context in which they appear, and learn rich representations for them. We experiment with different task-adaptive pre-training objectives, in-domain training, and symbolic inference to capture dependencies between different decisions in the output space. We evaluate our model on two narrative understanding tasks : predicting character mental states, and desire fulfillment, and conduct a <a href=https://en.wikipedia.org/wiki/Qualitative_property>qualitative analysis</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.393.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--393 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.393 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.naacl-main.393.OptionalSupplementaryData.zip data-toggle=tooltip data-placement=top title="Optional supplementary data"><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.393" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.393/>Hurdles to Progress in Long-form Question Answering</a></strong><br><a href=/people/k/kalpesh-krishna/>Kalpesh Krishna</a>
|
<a href=/people/a/aurko-roy/>Aurko Roy</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--393><div class="card-body p-3 small">The task of long-form question answering (LFQA) involves retrieving documents relevant to a given question and using them to generate a paragraph-length answer. While many models have recently been proposed for LFQA, we show in this paper that the task formulation raises fundamental challenges regarding evaluation and dataset creation that currently preclude meaningful modeling progress. To demonstrate these challenges, we first design a new system that relies on sparse attention and contrastive retriever learning to achieve state-of-the-art performance on the ELI5 LFQA dataset. While our system tops the public leaderboard, a detailed analysis reveals several troubling trends : (1) our system&#8217;s generated answers are not actually grounded in the documents that it retrieves ; (2) ELI5 contains significant train / validation overlap, as at least 81 % of ELI5 validation questions occur in paraphrased form in the training set ; (3) ROUGE-L is not an informative metric of generated answer quality and can be easily gamed ; and (4) human evaluations used for other text generation tasks are unreliable for LFQA. We offer suggestions to mitigate each of these issues, which we hope will lead to more rigorous LFQA research and meaningful progress in the future.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.397.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--397 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.397 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.397/>Attention Head Masking for Inference Time Content Selection in Abstractive Summarization</a></strong><br><a href=/people/s/shuyang-cao/>Shuyang Cao</a>
|
<a href=/people/l/lu-wang/>Lu Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--397><div class="card-body p-3 small">How can we effectively inform content selection in Transformer-based abstractive summarization models? In this work, we present a simple-yet-effective attention head masking technique, which is applied on encoder-decoder attentions to pinpoint salient content at inference time. Using attention head masking, we are able to reveal the relation between encoder-decoder attentions and content selection behaviors of summarization models. We then demonstrate its effectiveness on three document summarization datasets based on both in-domain and cross-domain settings. Importantly, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> outperform prior state-of-the-art <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on CNN / Daily Mail and New York Times datasets. Moreover, our inference-time masking technique is also data-efficient, requiring only 20 % of the training samples to outperform BART fine-tuned on the full CNN / DailyMail dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.398.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--398 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.398 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.398" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.398/>Factual Probing Is [ MASK ] : <a href=https://en.wikipedia.org/wiki/Learning>Learning</a> vs. Learning to Recall<span class=acl-fixed-case>MASK</span>]: Learning vs. Learning to Recall</a></strong><br><a href=/people/z/zexuan-zhong/>Zexuan Zhong</a>
|
<a href=/people/d/dan-friedman/>Dan Friedman</a>
|
<a href=/people/d/danqi-chen/>Danqi Chen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--398><div class="card-body p-3 small">Petroni et al. (2019) demonstrated that it is possible to retrieve world facts from a pre-trained language model by expressing them as cloze-style prompts and interpret the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>&#8217;s prediction accuracy as a lower bound on the amount of factual information it encodes. Subsequent work has attempted to tighten the estimate by searching for better prompts, using a disjoint set of facts as training data. In this work, we make two complementary contributions to better understand these factual probing techniques. First, we propose OptiPrompt, a novel and efficient method which directly optimizes in continuous embedding space. We find this simple method is able to predict an additional 6.4 % of facts in the LAMA benchmark. Second, we raise a more important question : Can we really interpret these probing results as a <a href=https://en.wikipedia.org/wiki/Upper_and_lower_bounds>lower bound</a>? Is it possible that these prompt-search methods learn from the training data too? We find, somewhat surprisingly, that the training data used by these methods contains certain regularities of the underlying fact distribution, and all the existing prompt methods, including ours, are able to exploit them for better fact prediction. We conduct a set of control experiments to disentangle <a href=https://en.wikipedia.org/wiki/Learning>learning</a> from learning to recall, providing a more detailed picture of what different prompts can reveal about pre-trained language models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.400.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--400 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.400 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.400" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.400/>Contextualized Perturbation for Textual Adversarial Attack</a></strong><br><a href=/people/d/dianqi-li/>Dianqi Li</a>
|
<a href=/people/y/yizhe-zhang/>Yizhe Zhang</a>
|
<a href=/people/h/hao-peng/>Hao Peng</a>
|
<a href=/people/l/liqun-chen/>Liqun Chen</a>
|
<a href=/people/c/chris-brockett/>Chris Brockett</a>
|
<a href=/people/m/ming-ting-sun/>Ming-Ting Sun</a>
|
<a href=/people/w/william-b-dolan/>Bill Dolan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--400><div class="card-body p-3 small">Adversarial examples expose the vulnerabilities of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP) models</a>, and can be used to evaluate and improve their <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a>. Existing techniques of generating such examples are typically driven by local heuristic rules that are agnostic to the context, often resulting in unnatural and ungrammatical outputs. This paper presents CLARE, a ContextuaLized AdversaRial Example generation model that produces fluent and grammatical outputs through a mask-then-infill procedure. CLARE builds on a pre-trained masked language model and modifies the inputs in a context-aware manner. We propose three contextualized perturbations, Replace, Insert and Merge, that allow for generating outputs of varied lengths. CLARE can flexibly combine these perturbations and apply them at any position in the inputs, and is thus able to attack the victim model more effectively with fewer edits. Extensive experiments and human evaluation demonstrate that CLARE outperforms the baselines in terms of attack success rate, textual similarity, <a href=https://en.wikipedia.org/wiki/Fluency>fluency</a> and <a href=https://en.wikipedia.org/wiki/Grammaticality>grammaticality</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.402.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--402 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.402 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.402" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.402/>Evaluating the Values of Sources in <a href=https://en.wikipedia.org/wiki/Transfer_learning>Transfer Learning</a></a></strong><br><a href=/people/m/md-rizwan-parvez/>Md Rizwan Parvez</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--402><div class="card-body p-3 small">Transfer learning that adapts a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> trained on data-rich sources to low-resource targets has been widely applied in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP)</a>. However, when training a transfer model over multiple sources, not every source is equally useful for the target. To better transfer a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>, it is essential to understand the values of the sources. In this paper, we develop, an efficient source valuation framework for quantifying the usefulness of the sources (e.g.,) in <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> based on the Shapley value method. Experiments and comprehensive analyses on both cross-domain and cross-lingual transfers demonstrate that our framework is not only effective in choosing useful transfer sources but also the source values match the intuitive source-target similarity.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.405.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--405 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.405 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.405/>Limitations of <a href=https://en.wikipedia.org/wiki/Autoregressive_model>Autoregressive Models</a> and Their Alternatives</a></strong><br><a href=/people/c/chu-cheng-lin/>Chu-Cheng Lin</a>
|
<a href=/people/a/aaron-jaech/>Aaron Jaech</a>
|
<a href=/people/x/xin-li/>Xin Li</a>
|
<a href=/people/m/matthew-r-gormley/>Matthew R. Gormley</a>
|
<a href=/people/j/jason-eisner/>Jason Eisner</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--405><div class="card-body p-3 small">Standard autoregressive language models perform only <a href=https://en.wikipedia.org/wiki/Time_complexity>polynomial-time computation</a> to compute the probability of the next symbol. While this is attractive, it means they can not model <a href=https://en.wikipedia.org/wiki/Probability_distribution>distributions</a> whose next-symbol probability is hard to compute. Indeed, they can not even model them well enough to solve associated easy decision problems for which an engineer might want to consult a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a>. These limitations apply no matter how much computation and data are used to train the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>, unless the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is given access to <a href=https://en.wikipedia.org/wiki/Oracle_machine>oracle parameters</a> that grow superpolynomially in sequence length. Thus, simply training larger autoregressive language models is not a panacea for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. Alternatives include energy-based models (which give up efficient sampling) and latent-variable autoregressive models (which give up efficient scoring of a given string). Both are powerful enough to escape the above limitations.<i>hard</i> to compute. Indeed, they cannot even model them well enough to solve associated <i>easy</i> decision problems for which an engineer might want to consult a language model. These limitations apply no matter how much computation and data are used to train the model, unless the model is given access to oracle parameters that grow <i>superpolynomially</i> in sequence length. Thus, simply training larger autoregressive language models is not a panacea for NLP. Alternatives include energy-based models (which give up efficient sampling) and latent-variable autoregressive models (which give up efficient scoring of a given string). Both are powerful enough to escape the above limitations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.406.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--406 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.406 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.406/>On the Transformer Growth for Progressive BERT Training<span class=acl-fixed-case>BERT</span> Training</a></strong><br><a href=/people/x/xiaotao-gu/>Xiaotao Gu</a>
|
<a href=/people/l/liyuan-liu/>Liyuan Liu</a>
|
<a href=/people/h/hongkun-yu/>Hongkun Yu</a>
|
<a href=/people/j/jing-li/>Jing Li</a>
|
<a href=/people/c/chen-chen/>Chen Chen</a>
|
<a href=/people/j/jiawei-han/>Jiawei Han</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--406><div class="card-body p-3 small">As the excessive pre-training cost arouses the need to improve <a href=https://en.wikipedia.org/wiki/Efficiency>efficiency</a>, considerable efforts have been made to train BERT progressivelystart from an inferior but low-cost model and gradually increase the <a href=https://en.wikipedia.org/wiki/Computational_complexity_theory>computational complexity</a>. Our objective is to help advance the understanding of such Transformer growth and discover principles that guide progressive training. First, we find that similar to network architecture selection, Transformer growth also favors <a href=https://en.wikipedia.org/wiki/Scaling_(geometry)>compound scaling</a>. Specifically, while existing methods only conduct network growth in a single dimension, we observe that it is beneficial to use compound growth operators and balance multiple dimensions (e.g., depth, width, and input length of the model). Moreover, we explore alternative growth operators in each dimension via controlled comparison to give practical guidance for operator selection. In light of our analyses, the proposed method CompoundGrow speeds up <a href=https://en.wikipedia.org/wiki/Brain-derived_neurotrophic_factor>BERT pre-training</a> by 73.6 % and 82.2 % for the base and large models respectively while achieving comparable performances.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.408.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--408 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.408 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.408/>ReadTwice : Reading Very Large Documents with Memories<span class=acl-fixed-case>R</span>ead<span class=acl-fixed-case>T</span>wice: Reading Very Large Documents with Memories</a></strong><br><a href=/people/y/yury-zemlyanskiy/>Yury Zemlyanskiy</a>
|
<a href=/people/j/joshua-ainslie/>Joshua Ainslie</a>
|
<a href=/people/m/michiel-de-jong/>Michiel de Jong</a>
|
<a href=/people/p/philip-pham/>Philip Pham</a>
|
<a href=/people/i/ilya-eckstein/>Ilya Eckstein</a>
|
<a href=/people/f/fei-sha/>Fei Sha</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--408><div class="card-body p-3 small">Knowledge-intensive tasks such as <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a> often require assimilating information from different sections of large inputs such as <a href=https://en.wikipedia.org/wiki/Book>books</a> or article collections. We propose ReadTwice, a simple and effective technique that combines several strengths of prior approaches to model long-range dependencies with Transformers. The main idea is to read text in small segments, in parallel, summarizing each segment into a memory table to be used in a second read of the text. We show that the method outperforms models of comparable size on several question answering (QA) datasets and sets a new state of the art on the challenging NarrativeQA task, with questions about entire books.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.410.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--410 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.410 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><span class="align-middle mr-1" data-toggle=tooltip data-placement=bottom title="Best Short Paper"><i class="fas fa-award"></i></span><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.naacl-main.410.OptionalSupplementaryCode.zip data-toggle=tooltip data-placement=top title="Optional supplementary code">
<i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.naacl-main.410.OptionalSupplementaryData.zip data-toggle=tooltip data-placement=top title="Optional supplementary data"><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.410" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.410/>Learning How to Ask : Querying LMs with Mixtures of Soft Prompts<span class=acl-fixed-case>LM</span>s with Mixtures of Soft Prompts</a></strong><br><a href=/people/g/guanghui-qin/>Guanghui Qin</a>
|
<a href=/people/j/jason-eisner/>Jason Eisner</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--410><div class="card-body p-3 small">Natural-language prompts have recently been used to coax pretrained language models into performing other AI tasks, using a fill-in-the-blank paradigm (Petroni et al., 2019) or a few-shot extrapolation paradigm (Brown et al., 2020). For example, <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> retain factual knowledge from their training corpora that can be extracted by asking them to fill in the blank in a sentential prompt. However, where does this prompt come from? We explore the idea of learning <a href=https://en.wikipedia.org/wiki/Command-line_interface>prompts</a> by gradient descenteither fine-tuning prompts taken from previous work, or starting from random initialization. Our prompts consist of soft words, i.e., <a href=https://en.wikipedia.org/wiki/Continuous_or_discrete_variable>continuous vectors</a> that are not necessarily word type embeddings from the <a href=https://en.wikipedia.org/wiki/Language_model>language model</a>. Furthermore, for each <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, we optimize a mixture of <a href=https://en.wikipedia.org/wiki/Command_(computing)>prompts</a>, learning which <a href=https://en.wikipedia.org/wiki/Command_(computing)>prompts</a> are most effective and how to ensemble them. Across multiple English LMs and tasks, our approach hugely outperforms previous methods, showing that the implicit factual knowledge in <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> was previously underestimated. Moreover, this knowledge is cheap to elicit : random initialization is nearly as good as informed initialization.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.413.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--413 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.413 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.naacl-main.413.OptionalSupplementaryCode.zip data-toggle=tooltip data-placement=top title="Optional supplementary code"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.naacl-main.413/>SpanPredict : Extraction of Predictive Document Spans with Neural Attention<span class=acl-fixed-case>S</span>pan<span class=acl-fixed-case>P</span>redict: Extraction of Predictive Document Spans with Neural Attention</a></strong><br><a href=/people/v/vivek-subramanian/>Vivek Subramanian</a>
|
<a href=/people/m/matthew-engelhard/>Matthew Engelhard</a>
|
<a href=/people/s/sam-berchuck/>Sam Berchuck</a>
|
<a href=/people/l/liqun-chen/>Liqun Chen</a>
|
<a href=/people/r/ricardo-henao/>Ricardo Henao</a>
|
<a href=/people/l/lawrence-carin/>Lawrence Carin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--413><div class="card-body p-3 small">In many <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing applications</a>, identifying predictive text can be as important as the predictions themselves. When predicting medical diagnoses, for example, identifying predictive content in <a href=https://en.wikipedia.org/wiki/Medical_record>clinical notes</a> not only enhances interpretability, but also allows unknown, descriptive (i.e., text-based) risk factors to be identified. We here formalize this <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> as predictive extraction and address it using a simple <a href=https://en.wikipedia.org/wiki/Mechanism_design>mechanism</a> based on <a href=https://en.wikipedia.org/wiki/Attentional_control>linear attention</a>. Our method preserves differentiability, allowing scalable inference via <a href=https://en.wikipedia.org/wiki/Stochastic_gradient_descent>stochastic gradient descent</a>. Further, the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> decomposes predictions into a sum of contributions of distinct text spans. Importantly, we require only <a href=https://en.wikipedia.org/wiki/Document_classification>document labels</a>, not ground-truth spans. Results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> identifies semantically-cohesive spans and assigns them scores that agree with human ratings, while preserving <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.416.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--416 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.416 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.416" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.416/>Improving Factual Completeness and Consistency of Image-to-Text Radiology Report Generation</a></strong><br><a href=/people/y/yasuhide-miura/>Yasuhide Miura</a>
|
<a href=/people/y/yuhao-zhang/>Yuhao Zhang</a>
|
<a href=/people/e/emily-tsai/>Emily Tsai</a>
|
<a href=/people/c/curtis-langlotz/>Curtis Langlotz</a>
|
<a href=/people/d/dan-jurafsky/>Dan Jurafsky</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--416><div class="card-body p-3 small">Neural image-to-text radiology report generation systems offer the potential to improve radiology reporting by reducing the repetitive process of report drafting and identifying possible <a href=https://en.wikipedia.org/wiki/Medical_error>medical errors</a>. However, existing report generation systems, despite achieving high performances on natural language generation metrics such as CIDEr or <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>, still suffer from incomplete and inconsistent generations. Here we introduce two new simple rewards to encourage the generation of factually complete and consistent radiology reports : one that encourages the system to generate radiology domain entities consistent with the reference, and one that uses natural language inference to encourage these entities to be described in inferentially consistent ways. We combine these with the novel use of an existing semantic equivalence metric (BERTScore). We further propose a report generation system that optimizes these <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>rewards</a> via <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a>. On two open radiology report datasets, our <a href=https://en.wikipedia.org/wiki/System>system</a> substantially improved the F1 score of a clinical information extraction performance by +22.1 (Delta +63.9 %). We further show via a <a href=https://en.wikipedia.org/wiki/Evaluation>human evaluation</a> and a <a href=https://en.wikipedia.org/wiki/Qualitative_property>qualitative analysis</a> that our <a href=https://en.wikipedia.org/wiki/System>system</a> leads to generations that are more factually complete and consistent compared to the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.418.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--418 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.418 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.418/>MIMOQA : Multimodal Input Multimodal Output Question Answering<span class=acl-fixed-case>MIMOQA</span>: Multimodal Input Multimodal Output Question Answering</a></strong><br><a href=/people/h/hrituraj-singh/>Hrituraj Singh</a>
|
<a href=/people/a/anshul-nasery/>Anshul Nasery</a>
|
<a href=/people/d/denil-mehta/>Denil Mehta</a>
|
<a href=/people/a/aishwarya-agarwal/>Aishwarya Agarwal</a>
|
<a href=/people/j/jatin-lamba/>Jatin Lamba</a>
|
<a href=/people/b/balaji-vasan-srinivasan/>Balaji Vasan Srinivasan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--418><div class="card-body p-3 small">Multimodal research has picked up significantly in the space of <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a> with the task being extended to visual question answering, charts question answering as well as multimodal input question answering. However, all these explorations produce a unimodal textual output as the answer. In this paper, we propose a novel task-MIMOQA-Multimodal Input Multimodal Output Question Answering in which the output is also multimodal. Through human experiments, we empirically show that such multimodal outputs provide better cognitive understanding of the answers. We also propose a novel multimodal question-answering framework, MExBERT, that incorporates a joint textual and visual attention towards producing such a multimodal output. Our method relies on a novel multimodal dataset curated for this problem from publicly available unimodal datasets. We show the superior performance of MExBERT against strong baselines on both the automatic as well as human metrics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.420.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--420 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.420 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.naacl-main.420.OptionalSupplementaryData.zip data-toggle=tooltip data-placement=top title="Optional supplementary data"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.naacl-main.420/>Unsupervised Vision-and-Language Pre-training Without Parallel Images and Captions</a></strong><br><a href=/people/l/liunian-harold-li/>Liunian Harold Li</a>
|
<a href=/people/h/haoxuan-you/>Haoxuan You</a>
|
<a href=/people/z/zhecan-wang/>Zhecan Wang</a>
|
<a href=/people/a/alireza-zareian/>Alireza Zareian</a>
|
<a href=/people/s/shih-fu-chang/>Shih-Fu Chang</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--420><div class="card-body p-3 small">Pre-trained contextual vision-and-language (V&L) models have achieved impressive performance on various <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmarks</a>. However, existing <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> require a large amount of parallel image-caption data for <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>pre-training</a>. Such <a href=https://en.wikipedia.org/wiki/Data>data</a> are costly to collect and require cumbersome curation. Inspired by unsupervised machine translation, we investigate if a strong V&L representation model can be learned through unsupervised pre-training without image-caption corpora. In particular, we propose to conduct mask-and-predict pre-training on text-only and image-only corpora and introduce the object tags detected by an object recognition model as anchor points to bridge two modalities. We find that such a simple approach achieves performance close to a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> pre-trained with <a href=https://en.wikipedia.org/wiki/Data_alignment>aligned data</a>, on four English V&L benchmarks. Our work challenges the widely held notion that aligned data is necessary for V&L pre-training, while significantly reducing the amount of supervision needed for V&L models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.421.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--421 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.421 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.421/>Multitasking Inhibits Semantic Drift</a></strong><br><a href=/people/a/athul-paul-jacob/>Athul Paul Jacob</a>
|
<a href=/people/m/mike-lewis/>Mike Lewis</a>
|
<a href=/people/j/jacob-andreas/>Jacob Andreas</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--421><div class="card-body p-3 small">When <a href=https://en.wikipedia.org/wiki/Intelligent_agent>intelligent agents</a> communicate to accomplish shared goals, how do these goals shape the agents&#8217; language? We study the dynamics of learning in latent language policies (LLPs), in which instructor agents generate natural-language subgoal descriptions and executor agents map these descriptions to low-level actions. LLPs can solve challenging long-horizon reinforcement learning problems and provide a rich model for studying task-oriented language use. But previous work has found that LLP training is prone to <a href=https://en.wikipedia.org/wiki/Semantic_drift>semantic drift</a> (use of messages in ways inconsistent with their original natural language meanings). Here, we demonstrate theoretically and empirically that multitask training is an effective counter to this problem : we prove that multitask training eliminates <a href=https://en.wikipedia.org/wiki/Semantic_drift>semantic drift</a> in a well-studied family of signaling games, and show that multitask training of neural LLPs in a complex strategy game reduces drift and while improving sample efficiency.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.429.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--429 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.429 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.429" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.429/>Neural Quality Estimation with Multiple Hypotheses for Grammatical Error Correction</a></strong><br><a href=/people/z/zhenghao-liu/>Zhenghao Liu</a>
|
<a href=/people/x/xiaoyuan-yi/>Xiaoyuan Yi</a>
|
<a href=/people/m/maosong-sun/>Maosong Sun</a>
|
<a href=/people/l/liner-yang/>Liner Yang</a>
|
<a href=/people/t/tat-seng-chua/>Tat-Seng Chua</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--429><div class="card-body p-3 small">Grammatical Error Correction (GEC) aims to correct writing errors and help <a href=https://en.wikipedia.org/wiki/Language_acquisition>language learners</a> improve their writing skills. However, existing GEC models tend to produce spurious corrections or fail to detect lots of errors. The quality estimation model is necessary to ensure learners get accurate GEC results and avoid misleading from poorly corrected sentences. Well-trained GEC models can generate several high-quality hypotheses through decoding, such as <a href=https://en.wikipedia.org/wiki/Beam_search>beam search</a>, which provide valuable GEC evidence and can be used to evaluate GEC quality. However, existing <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> neglect the possible GEC evidence from different hypotheses. This paper presents the Neural Verification Network (VERNet) for GEC quality estimation with multiple hypotheses. VERNet establishes interactions among hypotheses with a reasoning graph and conducts two kinds of attention mechanisms to propagate GEC evidence to verify the quality of generated hypotheses. Our experiments on four GEC datasets show that VERNet achieves state-of-the-art grammatical error detection performance, achieves the best quality estimation results, and significantly improves GEC performance by reranking hypotheses. All data and source codes are available at https://github.com/thunlp/VERNet.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.434.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--434 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.434 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.434" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.434/>Few-Shot Text Classification with Triplet Networks, Data Augmentation, and Curriculum Learning</a></strong><br><a href=/people/j/jason-wei/>Jason Wei</a>
|
<a href=/people/c/chengyu-huang/>Chengyu Huang</a>
|
<a href=/people/s/soroush-vosoughi/>Soroush Vosoughi</a>
|
<a href=/people/y/yu-cheng/>Yu Cheng</a>
|
<a href=/people/s/shiqi-xu/>Shiqi Xu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--434><div class="card-body p-3 small">Few-shot text classification is a fundamental NLP task in which a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> aims to classify text into a large number of categories, given only a few training examples per category. This paper explores data augmentationa technique particularly suitable for training with limited datafor this few-shot, highly-multiclass text classification setting. On four diverse text classification tasks, we find that common <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation techniques</a> can improve the performance of triplet networks by up to 3.0 % on average. To further boost performance, we present a simple training strategy called curriculum data augmentation, which leverages curriculum learning by first training on only original examples and then introducing augmented data as training progresses. We explore a two-stage and a gradual schedule, and find that, compared with standard single-stage training, curriculum data augmentation trains faster, improves performance, and remains robust to high amounts of noising from augmentation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.438.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--438 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.438 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.438" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.438/>User-Generated Text Corpus for Evaluating Japanese Morphological Analysis and Lexical Normalization<span class=acl-fixed-case>J</span>apanese Morphological Analysis and Lexical Normalization</a></strong><br><a href=/people/s/shohei-higashiyama/>Shohei Higashiyama</a>
|
<a href=/people/m/masao-utiyama/>Masao Utiyama</a>
|
<a href=/people/t/taro-watanabe/>Taro Watanabe</a>
|
<a href=/people/e/eiichiro-sumita/>Eiichiro Sumita</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--438><div class="card-body p-3 small">Morphological analysis (MA) and lexical normalization (LN) are both important tasks for Japanese user-generated text (UGT). To evaluate and compare different MA / LN systems, we have constructed a publicly available Japanese UGT corpus. Our <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> comprises 929 sentences annotated with morphological and normalization information, along with category information we classified for frequent UGT-specific phenomena. Experiments on the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> demonstrated the low performance of existing MA / LN methods for non-general words and non-standard forms, indicating that the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> would be a challenging benchmark for further research on UGT.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.442.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--442 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.442 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.442/>Contextualized and Generalized Sentence Representations by Contrastive Self-Supervised Learning : A Case Study on Discourse Relation Analysis</a></strong><br><a href=/people/h/hirokazu-kiyomaru/>Hirokazu Kiyomaru</a>
|
<a href=/people/s/sadao-kurohashi/>Sadao Kurohashi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--442><div class="card-body p-3 small">We propose a method to learn contextualized and generalized sentence representations using contrastive self-supervised learning. In the proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a>, a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> is given a text consisting of multiple sentences. One sentence is randomly selected as a target sentence. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is trained to maximize the similarity between the representation of the target sentence with its context and that of the masked target sentence with the same context. Simultaneously, the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> minimizes the similarity between the latter <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representation</a> and the representation of a random sentence with the same context. We apply our method to discourse relation analysis in <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a> and show that it outperforms strong baseline methods based on BERT, XLNet, and RoBERTa.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.445.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--445 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.445 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.445/>Unsupervised Concept Representation Learning for Length-Varying Text Similarity</a></strong><br><a href=/people/x/xuchao-zhang/>Xuchao Zhang</a>
|
<a href=/people/b/bo-zong/>Bo Zong</a>
|
<a href=/people/w/wei-cheng/>Wei Cheng</a>
|
<a href=/people/j/jingchao-ni/>Jingchao Ni</a>
|
<a href=/people/y/yanchi-liu/>Yanchi Liu</a>
|
<a href=/people/h/haifeng-chen/>Haifeng Chen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--445><div class="card-body p-3 small">Measuring document similarity plays an important role in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing tasks</a>. Most existing document similarity approaches suffer from the <a href=https://en.wikipedia.org/wiki/Information_gap>information gap</a> caused by <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context and vocabulary mismatches</a> when comparing varying-length texts. In this paper, we propose an unsupervised concept representation learning approach to address the above issues. Specifically, we propose a novel Concept Generation Network (CGNet) to learn concept representations from the perspective of the entire <a href=https://en.wikipedia.org/wiki/Text_corpus>text corpus</a>. Moreover, a concept-based document matching method is proposed to leverage advances in the recognition of local phrase features and corpus-level concept features. Extensive experiments on real-world data sets demonstrate that new method can achieve a considerable improvement in comparing length-varying texts. In particular, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieved 6.5 % better <a href=https://en.wikipedia.org/wiki/F1_score>F1 Score</a> compared to the best of the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline models</a> for a concept-project benchmark dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.447.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--447 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.447 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.447" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.447/>Adversarial Self-Supervised Learning for Out-of-Domain Detection</a></strong><br><a href=/people/z/zhiyuan-zeng/>Zhiyuan Zeng</a>
|
<a href=/people/k/keqing-he/>Keqing He</a>
|
<a href=/people/y/yuanmeng-yan/>Yuanmeng Yan</a>
|
<a href=/people/h/hong-xu/>Hong Xu</a>
|
<a href=/people/w/weiran-xu/>Weiran Xu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--447><div class="card-body p-3 small">Detecting out-of-domain (OOD) intents is crucial for the deployed task-oriented dialogue system. Previous unsupervised OOD detection methods only extract discriminative features of different in-domain intents while supervised counterparts can directly distinguish OOD and in-domain intents but require extensive labeled OOD data. To combine the benefits of both types, we propose a self-supervised contrastive learning framework to model discriminative semantic features of both in-domain intents and OOD intents from unlabeled data. Besides, we introduce an adversarial augmentation neural module to improve the efficiency and <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> of contrastive learning. Experiments on two public benchmark datasets show that our method can consistently outperform the baselines with a statistically significant margin.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.449.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--449 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.449 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.449" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.449/>Hierarchical Transformer for Task Oriented Dialog Systems</a></strong><br><a href=/people/b/bishal-santra/>Bishal Santra</a>
|
<a href=/people/p/potnuru-anusha/>Potnuru Anusha</a>
|
<a href=/people/p/pawan-goyal/>Pawan Goyal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--449><div class="card-body p-3 small">Generative models for dialog systems have gained much interest because of the recent success of RNN and Transformer based models in tasks like <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a> and <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a>. Although the task of dialog response generation is generally seen as a sequence to sequence (Seq2Seq) problem, researchers in the past have found it challenging to train dialog systems using the standard Seq2Seq models. Therefore, to help the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> learn meaningful utterance and conversation level features, Sordoni et al. (2015b), Serban et al. (2016) proposed Hierarchical RNN architecture, which was later adopted by several other RNN based dialog systems. With the transformer-based models dominating the seq2seq problems lately, the natural question to ask is the applicability of the notion of <a href=https://en.wikipedia.org/wiki/Hierarchy>hierarchy</a> in transformer-based dialog systems. In this paper, we propose a generalized framework for Hierarchical Transformer Encoders and show how a standard transformer can be morphed into any hierarchical encoder, including HRED and HIBERT like models, by using specially designed attention masks and positional encodings. We demonstrate that Hierarchical Encoding helps achieve better natural language understanding of the contexts in transformer-based models for task-oriented dialog systems through a wide range of experiments.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.451.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--451 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.451 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.451/>RTFE : A Recursive Temporal Fact Embedding Framework for Temporal Knowledge Graph Completion<span class=acl-fixed-case>RTFE</span>: A Recursive Temporal Fact Embedding Framework for Temporal Knowledge Graph Completion</a></strong><br><a href=/people/y/youri-xu/>Youri Xu</a>
|
<a href=/people/h/haihong-e/>Haihong E</a>
|
<a href=/people/m/meina-song/>Meina Song</a>
|
<a href=/people/w/wenyu-song/>Wenyu Song</a>
|
<a href=/people/x/xiaodong-lv/>Xiaodong Lv</a>
|
<a href=/people/w/wang-haotian/>Wang Haotian</a>
|
<a href=/people/y/yang-jinrui/>Yang Jinrui</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--451><div class="card-body p-3 small">Static knowledge graph (SKG) embedding (SKGE) has been studied intensively in the past years. Recently, temporal knowledge graph (TKG) embedding (TKGE) has emerged. In this paper, we propose a Recursive Temporal Fact Embedding (RTFE) framework to transplant SKGE models to TKGs and to enhance the performance of existing TKGE models for TKG completion. Different from previous work which ignores the continuity of states of TKG in <a href=https://en.wikipedia.org/wiki/Time_evolution>time evolution</a>, we treat the sequence of <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graphs</a> as a <a href=https://en.wikipedia.org/wiki/Markov_chain>Markov chain</a>, which transitions from the previous state to the next state. RTFE takes the SKGE to initialize the embeddings of <a href=https://en.wikipedia.org/wiki/TKG>TKG</a>. Then it recursively tracks the state transition of <a href=https://en.wikipedia.org/wiki/TKG>TKG</a> by passing updated parameters / features between timestamps. Specifically, at each timestamp, we approximate the <a href=https://en.wikipedia.org/wiki/State_transition>state transition</a> as the gradient update process. Since RTFE learns each timestamp recursively, it can naturally transit to future timestamps. Experiments on five TKG datasets show the effectiveness of RTFE.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.454.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--454 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.454 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.454" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.454/>Multi-Grained Knowledge Distillation for Named Entity Recognition</a></strong><br><a href=/people/x/xuan-zhou/>Xuan Zhou</a>
|
<a href=/people/x/xiao-zhang/>Xiao Zhang</a>
|
<a href=/people/c/chenyang-tao/>Chenyang Tao</a>
|
<a href=/people/j/junya-chen/>Junya Chen</a>
|
<a href=/people/b/bing-xu/>Bing Xu</a>
|
<a href=/people/w/wei-wang/>Wei Wang</a>
|
<a href=/people/j/jing-xiao/>Jing Xiao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--454><div class="card-body p-3 small">Although pre-trained big models (e.g., BERT, <a href=https://en.wikipedia.org/wiki/ERNIE>ERNIE</a>, XLNet, GPT3 etc.) have delivered top performance in Seq2seq modeling, their deployments in real-world applications are often hindered by the excessive computations and memory demand involved. For many applications, including named entity recognition (NER), matching the state-of-the-art result under budget has attracted considerable attention. Drawing power from the recent advance in knowledge distillation (KD), this work presents a novel distillation scheme to efficiently transfer the knowledge learned from big models to their more affordable counterpart. Our solution highlights the construction of surrogate labels through the k-best Viterbi algorithm to distill knowledge from the teacher model. To maximally assimilate knowledge into the student model, we propose a multi-grained distillation scheme, which integrates cross entropy involved in conditional random field (CRF) and fuzzy learning. To validate the effectiveness of our proposal, we conducted a comprehensive evaluation on five NER benchmarks, reporting cross-the-board performance gains relative to competing prior-arts. We further discuss ablation results to dissect our gains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.463.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--463 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.463 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.463" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.463/>TR-BERT : Dynamic Token Reduction for Accelerating BERT Inference<span class=acl-fixed-case>TR</span>-<span class=acl-fixed-case>BERT</span>: Dynamic Token Reduction for Accelerating <span class=acl-fixed-case>BERT</span> Inference</a></strong><br><a href=/people/d/deming-ye/>Deming Ye</a>
|
<a href=/people/y/yankai-lin/>Yankai Lin</a>
|
<a href=/people/y/yufei-huang/>Yufei Huang</a>
|
<a href=/people/m/maosong-sun/>Maosong Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--463><div class="card-body p-3 small">Existing pre-trained language models (PLMs) are often computationally expensive in <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference</a>, making them impractical in various resource-limited real-world applications. To address this issue, we propose a dynamic token reduction approach to accelerate PLMs&#8217; inference, named TR-BERT, which could flexibly adapt the layer number of each token in <a href=https://en.wikipedia.org/wiki/Inference>inference</a> to avoid redundant calculation. Specially, TR-BERT formulates the token reduction process as a multi-step token selection problem and automatically learns the selection strategy via <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a>. The experimental results on several downstream NLP tasks show that TR-BERT is able to speed up BERT by 2-5 times to satisfy various performance demands. Moreover, TR-BERT can also achieve better performance with less computation in a suite of long-text tasks since its token-level layer number adaption greatly accelerates the self-attention operation in PLMs. The source code and experiment details of this paper can be obtained from https://github.com/thunlp/TR-BERT.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.464.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--464 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.464 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.464/>Breadth First Reasoning Graph for Multi-hop Question Answering</a></strong><br><a href=/people/y/yongjie-huang/>Yongjie Huang</a>
|
<a href=/people/m/meng-yang/>Meng Yang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--464><div class="card-body p-3 small">Recently Graph Neural Network (GNN) has been used as a promising tool in multi-hop question answering task. However, the unnecessary updations and simple edge constructions prevent an accurate answer span extraction in a more direct and interpretable way. In this paper, we propose a novel model of Breadth First Reasoning Graph (BFR-Graph), which presents a new message passing way that better conforms to the reasoning process. In BFR-Graph, the reasoning message is required to start from the question node and pass to the next sentences node hop by hop until all the edges have been passed, which can effectively prevent each <a href=https://en.wikipedia.org/wiki/Node_(networking)>node</a> from over-smoothing or being updated multiple times unnecessarily. To introduce more <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a>, we also define the reasoning graph as a <a href=https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms>weighted graph</a> with considering the number of co-occurrence entities and the distance between sentences. Then we present a more direct and interpretable way to aggregate scores from different levels of <a href=https://en.wikipedia.org/wiki/Granularity>granularity</a> based on the GNN. On HotpotQA leaderboard, the proposed BFR-Graph achieves state-of-the-art on answer span prediction.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.469.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--469 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.469 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.469" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.469/>Unsupervised Multi-hop Question Answering by Question Generation</a></strong><br><a href=/people/l/liangming-pan/>Liangming Pan</a>
|
<a href=/people/w/wenhu-chen/>Wenhu Chen</a>
|
<a href=/people/w/wenhan-xiong/>Wenhan Xiong</a>
|
<a href=/people/m/min-yen-kan/>Min-Yen Kan</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--469><div class="card-body p-3 small">Obtaining training data for multi-hop question answering (QA) is time-consuming and resource-intensive. We explore the possibility to train a well-performed multi-hop QA model without referencing any human-labeled multi-hop question-answer pairs, i.e., unsupervised multi-hop QA. We propose MQA-QG, an <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised framework</a> that can generate human-like multi-hop training data from both homogeneous and heterogeneous data sources. MQA-QG generates questions by first selecting / generating relevant information from each data source and then integrating the multiple information to form a multi-hop question. Using only generated training data, we can train a competent multi-hop QA which achieves 61 % and 83 % of the <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised learning</a> performance for the HybridQA and the HotpotQA dataset, respectively. We also show that pretraining the QA system with the generated data would greatly reduce the demand for human-annotated training data. Our codes are publicly available at https://github.com/teacherpeterpan/Unsupervised-Multi-hop-QA.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.naacl-main.470.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--naacl-main--470 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.naacl-main.470 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.naacl-main.470" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.naacl-main.470/>Sliding Selector Network with Dynamic Memory for Extractive Summarization of Long Documents</a></strong><br><a href=/people/p/peng-cui/>Peng Cui</a>
|
<a href=/people/l/le-hu/>Le Hu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--naacl-main--470><div class="card-body p-3 small">Neural-based summarization models suffer from the length limitation of text encoder. Long documents have to been truncated before they are sent to the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>, which results in huge loss of summary-relevant contents. To address this issue, we propose the sliding selector network with <a href=https://en.wikipedia.org/wiki/Dynamic_memory>dynamic memory</a> for extractive summarization of long-form documents, which employs a sliding window to extract summary sentences segment by segment. Moreover, we adopt memory mechanism to preserve and update the history information dynamically, allowing the semantic flow across different windows. Experimental results on two large-scale datasets that consist of scientific papers demonstrate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> substantially outperforms previous state-of-the-art <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. Besides, we perform qualitative and quantitative investigations on how our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> works and where the performance gain comes from.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>