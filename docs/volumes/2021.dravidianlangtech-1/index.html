<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages</h2><p class=lead><a href=/people/b/bharathi-raja-chakravarthi/>Bharathi Raja Chakravarthi</a>,
<a href=/people/r/ruba-priyadharshini/>Ruba Priyadharshini</a>,
<a href=/people/a/anand-kumar-m/>Anand Kumar M</a>,
<a href=/people/p/parameswari-krishnamurthy/>Parameswari Krishnamurthy</a>,
<a href=/people/e/elizabeth-sherly/>Elizabeth Sherly</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2021.dravidianlangtech-1</dd><dt>Month:</dt><dd>April</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Kyiv</dd><dt>Venues:</dt><dd><a href=/venues/dravidianlangtech/>DravidianLangTech</a>
| <a href=/venues/eacl/>EACL</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.dravidianlangtech-1>https://aclanthology.org/2021.dravidianlangtech-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+First+Workshop+on+Speech+and+Language+Technologies+for+Dravidian+Languages" title="Search for 'Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dravidianlangtech-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.dravidianlangtech-1.0/>Proceedings of the First Workshop on Speech and Language Technologies for Dravidian Languages</a></strong><br><a href=/people/b/bharathi-raja-chakravarthi/>Bharathi Raja Chakravarthi</a>
|
<a href=/people/r/ruba-priyadharshini/>Ruba Priyadharshini</a>
|
<a href=/people/a/anand-kumar-m/>Anand Kumar M</a>
|
<a href=/people/p/parameswari-krishnamurthy/>Parameswari Krishnamurthy</a>
|
<a href=/people/e/elizabeth-sherly/>Elizabeth Sherly</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dravidianlangtech-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dravidianlangtech-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dravidianlangtech-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.dravidianlangtech-1.3.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.dravidianlangtech-1.3" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.dravidianlangtech-1.3/>Towards Offensive Language Identification for Dravidian Languages<span class=acl-fixed-case>D</span>ravidian Languages</a></strong><br><a href=/people/s/siva-sai/>Siva Sai</a>
|
<a href=/people/y/yashvardhan-sharma/>Yashvardhan Sharma</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dravidianlangtech-1--3><div class="card-body p-3 small">Offensive speech identification in countries like <a href=https://en.wikipedia.org/wiki/India>India</a> poses several challenges due to the usage of code-mixed and romanized variants of multiple languages by the users in their posts on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. The challenge of offensive language identification on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> for <a href=https://en.wikipedia.org/wiki/Dravidian_languages>Dravidian languages</a> is harder, considering the low resources available for the same. In this paper, we explored the zero-shot learning and few-shot learning paradigms based on multilingual language models for offensive speech detection in code-mixed and romanized variants of three Dravidian languages-Malayalam, <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil</a>, and <a href=https://en.wikipedia.org/wiki/Kannada>Kannada</a>. We propose a novel and flexible approach of selective translation and <a href=https://en.wikipedia.org/wiki/Transliteration>transliteration</a> to reap better results from fine-tuning and ensembling multilingual transformer networks like XLMRoBERTa and mBERT. We implemented pretrained, fine-tuned, and ensembled versions of XLM-RoBERTa for offensive speech classification. Further, we experimented with interlanguage, inter-task, and multi-task transfer learning techniques to leverage the rich resources available for offensive speech identification in the <a href=https://en.wikipedia.org/wiki/English_language>English language</a> and to enrich the models with <a href=https://en.wikipedia.org/wiki/Knowledge_transfer>knowledge transfer</a> from related tasks. The proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> yielded good results and are promising for effective offensive speech identification in low resource settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dravidianlangtech-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dravidianlangtech-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dravidianlangtech-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.dravidianlangtech-1.4.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.dravidianlangtech-1.4/>Sentiment Classification of Code-Mixed Tweets using Bi-Directional RNN and Language Tags<span class=acl-fixed-case>RNN</span> and Language Tags</a></strong><br><a href=/people/s/sainik-mahata/>Sainik Mahata</a>
|
<a href=/people/d/dipankar-das/>Dipankar Das</a>
|
<a href=/people/s/sivaji-bandyopadhyay/>Sivaji Bandyopadhyay</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dravidianlangtech-1--4><div class="card-body p-3 small">Sentiment analysis tools and <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> have been developed extensively throughout the years, for <a href=https://en.wikipedia.org/wiki/Languages_of_Europe>European languages</a>. In contrast, similar <a href=https://en.wikipedia.org/wiki/Tool>tools</a> for <a href=https://en.wikipedia.org/wiki/Languages_of_India>Indian Languages</a> are scarce. This is because, state-of-the-art pre-processing tools like POS tagger, shallow parsers, etc., are not readily available for <a href=https://en.wikipedia.org/wiki/Languages_of_India>Indian languages</a>. Although, such working tools for Indian languages, like <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a> and <a href=https://en.wikipedia.org/wiki/Bengali_language>Bengali</a>, that are spoken by the majority of the population, are available, finding the same for less spoken languages like, <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil</a>, <a href=https://en.wikipedia.org/wiki/Telugu_language>Telugu</a>, and <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam</a>, is difficult. Moreover, due to the advent of <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>, the multi-lingual population of India, who are comfortable with both <a href=https://en.wikipedia.org/wiki/English_language>English</a> ad their regional language, prefer to communicate by mixing both languages. This gives rise to massive code-mixed content and automatically annotating them with their respective sentiment labels becomes a challenging task. In this work, we take up a similar challenge of developing a <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis model</a> that can work with English-Tamil code-mixed data. The proposed work tries to solve this by using bi-directional LSTMs along with <a href=https://en.wikipedia.org/wiki/Tag_(metadata)>language tagging</a>. Other traditional methods, based on classical machine learning algorithms have also been discussed in the literature, and they also act as the baseline systems to which we will compare our Neural Network based model. The performance of the developed <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a>, based on Neural Network architecture, garnered <a href=https://en.wikipedia.org/wiki/Precision_(computer_science)>precision</a>, <a href=https://en.wikipedia.org/wiki/Recall_(memory)>recall</a>, and F1 scores of 0.59, 0.66, and 0.58 respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dravidianlangtech-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dravidianlangtech-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dravidianlangtech-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.dravidianlangtech-1.11.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.dravidianlangtech-1.11/>Task-Oriented Dialog Systems for Dravidian Languages<span class=acl-fixed-case>D</span>ravidian Languages</a></strong><br><a href=/people/t/tushar-kanakagiri/>Tushar Kanakagiri</a>
|
<a href=/people/k/karthik-radhakrishnan/>Karthik Radhakrishnan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dravidianlangtech-1--11><div class="card-body p-3 small">Task-oriented dialog systems help a user achieve a particular goal by parsing user requests to execute a particular action. These systems typically require copious amounts of training data to effectively understand the user intent and its corresponding slots. Acquiring large training corpora requires significant manual effort in annotation, rendering its construction infeasible for low-resource languages. In this paper, we present a two-step approach for automatically constructing task-oriented dialogue data in such <a href=https://en.wikipedia.org/wiki/Programming_language>languages</a> by making use of annotated data from high resource languages. First, we use a machine translation (MT) system to translate the utterance and slot information to the target language. Second, we use token prefix matching and mBERT based semantic matching to align the slot tokens to the corresponding tokens in the utterance. We hand-curate a new test dataset in two low-resource Dravidian languages and show the significance and impact of our training dataset construction using a state-of-the-art mBERT model-achieving a Slot F1 of 81.51 (Kannada) and 78.82 (Tamil) on our test sets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dravidianlangtech-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dravidianlangtech-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dravidianlangtech-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.dravidianlangtech-1.12/>A Survey on <a href=https://en.wikipedia.org/wiki/Paralinguistics>Paralinguistics</a> in Tamil Speech Processing<span class=acl-fixed-case>T</span>amil Speech Processing</a></strong><br><a href=/people/a/anosha-ignatius/>Anosha Ignatius</a>
|
<a href=/people/u/uthayasanker-thayasivam/>Uthayasanker Thayasivam</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dravidianlangtech-1--12><div class="card-body p-3 small">Speech carries not only the semantic content but also the paralinguistic information which captures the <a href=https://en.wikipedia.org/wiki/Style_(sociolinguistics)>speaking style</a>. Speaker traits and <a href=https://en.wikipedia.org/wiki/Emotion>emotional states</a> affect how words are being spoken. The research on paralinguistic information is an emerging field in speech and language processing and it has many potential applications including <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech recognition</a>, speaker identification and verification, <a href=https://en.wikipedia.org/wiki/Emotion_recognition>emotion recognition</a> and accent recognition. Among them, there is a significant interest in <a href=https://en.wikipedia.org/wiki/Emotion_recognition>emotion recognition</a> from <a href=https://en.wikipedia.org/wiki/Speech>speech</a>. A detailed study of paralinguistic information present in speech signal and an overview of research work related to speech emotion for <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil Language</a> is presented in this paper.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dravidianlangtech-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dravidianlangtech-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dravidianlangtech-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.dravidianlangtech-1.13.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.dravidianlangtech-1.13/>Is this Enough?-Evaluation of Malayalam Wordnet<span class=acl-fixed-case>M</span>alayalam <span class=acl-fixed-case>W</span>ordnet</a></strong><br><a href=/people/n/nandu-chandran-nair/>Nandu Chandran Nair</a>
|
<a href=/people/m/maria-chiara-giangregorio/>Maria-chiara Giangregorio</a>
|
<a href=/people/f/fausto-giunchiglia/>Fausto Giunchiglia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dravidianlangtech-1--13><div class="card-body p-3 small">Quality of a product is the degree to which a product meets the customer&#8217;s expectation, which must also be valid for the case of lexical semantic resources. Conducting a periodic evaluation of resources is essential to ensure if the resources meet a native speaker&#8217;s expectations and free from errors. This paper defines the possible mistakes in a lexical semantic resource and explains the steps applied to quantify Malayalam wordnet quality. Malayalam is one of the classical languages of India. We hope to subset the less quality part of the <a href=https://en.wikipedia.org/wiki/Wordnet>wordnet</a> and perform <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing</a> to make it better.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dravidianlangtech-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dravidianlangtech-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dravidianlangtech-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.dravidianlangtech-1.14.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.dravidianlangtech-1.14/>LA-SACo : A Study of Learning Approaches for Sentiments Analysis inCode-Mixing Texts<span class=acl-fixed-case>LA</span>-<span class=acl-fixed-case>SAC</span>o: A Study of Learning Approaches for Sentiments Analysis in<span class=acl-fixed-case>C</span>ode-Mixing Texts</a></strong><br><a href=/people/f/fazlourrahman-balouchzahi/>Fazlourrahman Balouchzahi</a>
|
<a href=/people/h/h-l-shashirekha/>H L Shashirekha</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dravidianlangtech-1--14><div class="card-body p-3 small">Substantial amount of text data which is increasingly being generated and shared on the internet and <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> every second affect the society positively or negatively almost in any aspect of online world and also business and industries. Sentiments / opinions / reviews&#8217; of users posted on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> are the valuable information that have motivated researchers to analyze them to get better insight and feedbacks about any product such as a video in <a href=https://en.wikipedia.org/wiki/Instagram>Instagram</a>, a movie in <a href=https://en.wikipedia.org/wiki/Netflix>Netflix</a>, or even new brand car introduced by BMW. Sentiments are usually written using a combination of languages such as <a href=https://en.wikipedia.org/wiki/English_language>English</a> which is resource rich and regional languages such as <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil</a>, <a href=https://en.wikipedia.org/wiki/Kannada>Kannada</a>, <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam</a>, etc. which are resource poor. However, due to technical constraints, many users prefer to pen their opinions in <a href=https://en.wikipedia.org/wiki/Roman_script>Roman script</a>. These kinds of texts written in two or more languages using a common language script or different language scripts are called code-mixing texts. Code-mixed texts are increasing day-by-day with the increase in the number of users depending on various online platforms. Analyzing such texts pose a real challenge for the researchers. In view of the challenges posed by the code-mixed texts, this paper describes three proposed models namely, SACo-Ensemble, SACo-Keras, and SACo-ULMFiT using Machine Learning (ML), Deep Learning (DL), and Transfer Learning (TL) approaches respectively for the task of Sentiments Analysis in Tamil-English and Malayalam-English code-mixed texts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dravidianlangtech-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dravidianlangtech-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dravidianlangtech-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.dravidianlangtech-1.16/>Findings of the Shared Task on Troll Meme Classification in Tamil<span class=acl-fixed-case>T</span>amil</a></strong><br><a href=/people/s/shardul-suryawanshi/>Shardul Suryawanshi</a>
|
<a href=/people/b/bharathi-raja-chakravarthi/>Bharathi Raja Chakravarthi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dravidianlangtech-1--16><div class="card-body p-3 small">The <a href=https://en.wikipedia.org/wiki/Internet>internet</a> has facilitated its user-base with a platform to communicate and express their views without any censorship. On the other hand, this <a href=https://en.wikipedia.org/wiki/Freedom_of_speech>freedom of expression</a> or <a href=https://en.wikipedia.org/wiki/Freedom_of_speech>free speech</a> can be abused by its user or a troll to demean an individual or a group. Demeaning people based on their gender, <a href=https://en.wikipedia.org/wiki/Sexual_orientation>sexual orientation</a>, religious believes or any other characteristics trolling could cause great distress in the online community. Hence, the content posted by a <a href=https://en.wikipedia.org/wiki/Internet_troll>troll</a> needs to be identified and dealt with before causing any more damage. Amongst all the forms of troll content, <a href=https://en.wikipedia.org/wiki/Meme>memes</a> are most prevalent due to their popularity and ability to propagate across cultures. A <a href=https://en.wikipedia.org/wiki/Internet_troll>troll</a> uses a <a href=https://en.wikipedia.org/wiki/Internet_meme>meme</a> to demean, attack or offend its targetted audience. In this shared task, we provide a resource (TamilMemes) that could be used to train a system capable of identifying a troll meme in the <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil language</a>. In our TamilMemes dataset, each meme has been categorized into either a <a href=https://en.wikipedia.org/wiki/Internet_troll>troll</a> or a not_troll class. Along with the meme images, we also provided the Latin transcripted text from memes. We received 10 system submissions from the participants which were evaluated using the weighted average F1-score. The <a href=https://en.wikipedia.org/wiki/System>system</a> with the weighted average F1-score of 0.55 secured the first rank.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dravidianlangtech-1.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dravidianlangtech-1--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dravidianlangtech-1.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.dravidianlangtech-1.17/>Findings of the Shared Task on Offensive Language Identification in <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil</a>, <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam</a>, and <a href=https://en.wikipedia.org/wiki/Kannada>Kannada</a><span class=acl-fixed-case>T</span>amil, <span class=acl-fixed-case>M</span>alayalam, and <span class=acl-fixed-case>K</span>annada</a></strong><br><a href=/people/b/bharathi-raja-chakravarthi/>Bharathi Raja Chakravarthi</a>
|
<a href=/people/r/ruba-priyadharshini/>Ruba Priyadharshini</a>
|
<a href=/people/n/navya-jose/>Navya Jose</a>
|
<a href=/people/a/anand-kumar-m/>Anand Kumar M</a>
|
<a href=/people/t/thomas-mandl/>Thomas Mandl</a>
|
<a href=/people/p/prasanna-kumar-kumaresan/>Prasanna Kumar Kumaresan</a>
|
<a href=/people/r/rahul-ponnusamy/>Rahul Ponnusamy</a>
|
<a href=/people/h/hariharan-r-l/>Hariharan R L</a>
|
<a href=/people/j/john-philip-mccrae/>John P. McCrae</a>
|
<a href=/people/e/elizabeth-sherly/>Elizabeth Sherly</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dravidianlangtech-1--17><div class="card-body p-3 small">Detecting <a href=https://en.wikipedia.org/wiki/Profanity>offensive language</a> in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> in <a href=https://en.wikipedia.org/wiki/Language_localisation>local languages</a> is critical for moderating user-generated content. Thus, the field of offensive language identification in under-resourced Tamil, <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam</a> and <a href=https://en.wikipedia.org/wiki/Kannada>Kannada languages</a> are essential. As the <a href=https://en.wikipedia.org/wiki/User-generated_content>user-generated content</a> is more code-mixed and not well studied for under-resourced languages, it is imperative to create resources and conduct benchmarking studies to encourage research in under-resourced Dravidian languages. We created a shared task on offensive language detection in <a href=https://en.wikipedia.org/wiki/Dravidian_languages>Dravidian languages</a>. We summarize here the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for this challenge which are openly available at https://competitions.codalab.org/competitions/27654, and present an overview of the <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>methods</a> and the results of the competing systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dravidianlangtech-1.18.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dravidianlangtech-1--18 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dravidianlangtech-1.18 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.dravidianlangtech-1.18.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.dravidianlangtech-1.18.Dataset.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.dravidianlangtech-1.18/>GX@DravidianLangTech-EACL2021 : Multilingual Neural Machine Translation and <a href=https://en.wikipedia.org/wiki/Back-translation>Back-translation</a><span class=acl-fixed-case>GX</span>@<span class=acl-fixed-case>D</span>ravidian<span class=acl-fixed-case>L</span>ang<span class=acl-fixed-case>T</span>ech-<span class=acl-fixed-case>EACL</span>2021: Multilingual Neural Machine Translation and Back-translation</a></strong><br><a href=/people/w/wanying-xie/>Wanying Xie</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dravidianlangtech-1--18><div class="card-body p-3 small">In this paper, we describe the GX system in the EACL2021 shared task on machine translation in <a href=https://en.wikipedia.org/wiki/Dravidian_languages>Dravidian languages</a>. Given the low amount of parallel training data, We adopt two methods to improve the overall performance : (1) multilingual translation, we use a shared encoder-decoder multilingual translation model handling multiple languages simultaneously to facilitate the translation performance of these languages ; (2) back-translation, we collected other open-source parallel and monolingual data and apply back-translation to benefit from the monolingual data. The experimental results show that we can achieve satisfactory <a href=https://en.wikipedia.org/wiki/Translation>translation</a> results in these <a href=https://en.wikipedia.org/wiki/Dravidian_languages>Dravidian languages</a> and rank first in English-Telugu and Tamil-Telugu translation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dravidianlangtech-1.20.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dravidianlangtech-1--20 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dravidianlangtech-1.20 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.dravidianlangtech-1.20.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.dravidianlangtech-1.20/>Simon @ DravidianLangTech-EACL2021 : Detecting Offensive Content in Kannada Language<span class=acl-fixed-case>D</span>ravidian<span class=acl-fixed-case>L</span>ang<span class=acl-fixed-case>T</span>ech-<span class=acl-fixed-case>EACL</span>2021: Detecting Offensive Content in <span class=acl-fixed-case>K</span>annada Language</a></strong><br><a href=/people/q/qinyu-que/>Qinyu Que</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dravidianlangtech-1--20><div class="card-body p-3 small">This article introduces the system for the shared task of Offensive Language Identification in Dravidian Languages-EACL 2021. The world&#8217;s information technology develops at a high speed. People are used to expressing their views and opinions on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. This leads to a lot of <a href=https://en.wikipedia.org/wiki/Profanity>offensive language</a> on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. As people become more dependent on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>, the detection of offensive language becomes more and more necessary. This shared task is in three languages : <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil</a>, <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam</a>, and <a href=https://en.wikipedia.org/wiki/Kannada>Kannada</a>. Our team takes part in the Kannada language task. To accomplish the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, we use the XLM-Roberta model for pre-training. But the capabilities of the XLM-Roberta model do not satisfy us in terms of statement information collection. So we made some tweaks to the output of this <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. In this paper, we describe the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> and experiments for accomplishing the task of the <a href=https://en.wikipedia.org/wiki/Kannada>Kannada language</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dravidianlangtech-1.26.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dravidianlangtech-1--26 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dravidianlangtech-1.26 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.dravidianlangtech-1.26.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.dravidianlangtech-1.26/>Hypers@DravidianLangTech-EACL2021 : Offensive language identification in Dravidian code-mixed YouTube Comments and Posts<span class=acl-fixed-case>D</span>ravidian<span class=acl-fixed-case>L</span>ang<span class=acl-fixed-case>T</span>ech-<span class=acl-fixed-case>EACL</span>2021: Offensive language identification in <span class=acl-fixed-case>D</span>ravidian code-mixed <span class=acl-fixed-case>Y</span>ou<span class=acl-fixed-case>T</span>ube Comments and Posts</a></strong><br><a href=/people/c/charangan-vasantharajan/>Charangan Vasantharajan</a>
|
<a href=/people/u/uthayasanker-thayasivam/>Uthayasanker Thayasivam</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dravidianlangtech-1--26><div class="card-body p-3 small">Code-Mixed Offensive contents are used pervasively in social media posts in the last few years. Consequently, gained the significant attraction of the research community for identifying the different forms of such <a href=https://en.wikipedia.org/wiki/Content_(media)>content</a> (e.g., <a href=https://en.wikipedia.org/wiki/Hate_speech>hate speech</a>, and sentiments) and contributed to the creation of datasets. Most of the recent studies deal with high-resource languages (e.g., English) due to many publicly available datasets, and by the lack of dataset in low-resource anguages, those studies are slightly involved in these <a href=https://en.wikipedia.org/wiki/Language>languages</a>. Therefore, this study has the focus on offensive language identification on code-mixed low-resourced Dravidian languages such as <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil</a>, <a href=https://en.wikipedia.org/wiki/Kannada>Kannada</a>, and <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam</a> using the bidirectional approach and fine-tuning strategies. According to the leaderboard, the proposed model got a 0.96 <a href=https://en.wikipedia.org/wiki/FIVB_World_Rankings>F1-score</a> for <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam</a>, 0.73 <a href=https://en.wikipedia.org/wiki/FIVB_World_Rankings>F1-score</a> for <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil</a>, and 0.70 <a href=https://en.wikipedia.org/wiki/FIVB_World_Rankings>F1-score</a> for <a href=https://en.wikipedia.org/wiki/Kannada>Kannada</a> in the bench-mark. Moreover, in the view of multilingual models, this modal ranked 3rd and achieved favorable results and confirmed the model as the best among all systems submitted to these shared tasks in these three languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dravidianlangtech-1.29.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dravidianlangtech-1--29 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dravidianlangtech-1.29 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.dravidianlangtech-1.29.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.dravidianlangtech-1.29/>ZYJ123@DravidianLangTech-EACL2021 : Offensive Language Identification based on XLM-RoBERTa with DPCNN<span class=acl-fixed-case>ZYJ</span>123@<span class=acl-fixed-case>D</span>ravidian<span class=acl-fixed-case>L</span>ang<span class=acl-fixed-case>T</span>ech-<span class=acl-fixed-case>EACL</span>2021: Offensive Language Identification based on <span class=acl-fixed-case>XLM</span>-<span class=acl-fixed-case>R</span>o<span class=acl-fixed-case>BERT</span>a with <span class=acl-fixed-case>DPCNN</span></a></strong><br><a href=/people/y/yingjia-zhao/>Yingjia Zhao</a>
|
<a href=/people/x/xin-tao/>Xin Tao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dravidianlangtech-1--29><div class="card-body p-3 small">The development of online media platforms has given users more opportunities to post and comment freely, but the negative impact of <a href=https://en.wikipedia.org/wiki/Profanity>offensive language</a> has become increasingly apparent. It is very necessary for the automatic identification system of offensive language. This paper describes our work on the task of Offensive Language Identification in Dravidian language-EACL 2021. To complete this task, we propose a <a href=https://en.wikipedia.org/wiki/System>system</a> based on the multilingual model XLM-Roberta and DPCNN. The test results on the official test data set confirm the effectiveness of our <a href=https://en.wikipedia.org/wiki/System>system</a>. The <a href=https://en.wikipedia.org/wiki/Weighted_arithmetic_mean>weighted average F1-score</a> of <a href=https://en.wikipedia.org/wiki/Kannada>Kannada</a>, <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam</a>, and <a href=https://en.wikipedia.org/wiki/Tami_language>Tami language</a> are 0.69, 0.92, and 0.76 respectively, ranked 6th, 6th, and 3rd</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dravidianlangtech-1.32.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dravidianlangtech-1--32 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dravidianlangtech-1.32 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.dravidianlangtech-1.32.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.dravidianlangtech-1.32/>CUSATNLP@DravidianLangTech-EACL2021 : Language Agnostic Classification of Offensive Content in Tweets<span class=acl-fixed-case>CUSATNLP</span>@<span class=acl-fixed-case>D</span>ravidian<span class=acl-fixed-case>L</span>ang<span class=acl-fixed-case>T</span>ech-<span class=acl-fixed-case>EACL</span>2021:Language Agnostic Classification of Offensive Content in Tweets</a></strong><br><a href=/people/s/sara-renjit/>Sara Renjit</a>
|
<a href=/people/s/sumam-mary-idicula/>Sumam Mary Idicula</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dravidianlangtech-1--32><div class="card-body p-3 small">Identifying offensive information from <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a> is a vital <a href=https://en.wikipedia.org/wiki/Language_processing_in_the_brain>language processing task</a>. This task concentrated more on <a href=https://en.wikipedia.org/wiki/English_language>English</a> and other foreign languages these days. In this shared task on Offensive Language Identification in <a href=https://en.wikipedia.org/wiki/Dravidian_languages>Dravidian Languages</a>, in the First Workshop of Speech and Language Technologies for <a href=https://en.wikipedia.org/wiki/Dravidian_languages>Dravidian Languages</a> in EACL 2021, the aim is to identify offensive content from code mixed Dravidian Languages Kannada, Malayalam, and Tamil. Our team used language agnostic BERT (Bidirectional Encoder Representation from Transformers) for <a href=https://en.wikipedia.org/wiki/Sentence_embedding>sentence embedding</a> and a Softmax classifier. The language-agnostic representation based classification helped obtain good performance for all the three languages, out of which results for the <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam language</a> are good enough to obtain a third position among the participating teams.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dravidianlangtech-1.40.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dravidianlangtech-1--40 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dravidianlangtech-1.40 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.dravidianlangtech-1.40.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.dravidianlangtech-1.40.Dataset.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.dravidianlangtech-1.40/>Maoqin @ DravidianLangTech-EACL2021 : The Application of Transformer-Based Model<span class=acl-fixed-case>D</span>ravidian<span class=acl-fixed-case>L</span>ang<span class=acl-fixed-case>T</span>ech-<span class=acl-fixed-case>EACL</span>2021: The Application of Transformer-Based Model</a></strong><br><a href=/people/m/maoqin-yang/>Maoqin Yang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dravidianlangtech-1--40><div class="card-body p-3 small">This paper describes the result of team-Maoqin at DravidianLangTech-EACL2021. The provided task consists of three languages(Tamil, Malayalam, and Kannada), I only participate in one of the language task-Malayalam. The goal of this task is to identify offensive language content of the code-mixed dataset of comments / posts in Dravidian Languages (Tamil-English, Malayalam-English, and Kannada-English) collected from <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. This is a <a href=https://en.wikipedia.org/wiki/Comparison_and_contrast_of_classification_schemes_in_linguistics_and_metadata>classification task</a> at the comment / post level. Given a Youtube comment, systems have to classify it into Not-offensive, Offensive-untargeted, Offensive-targeted-individual, Offensive-targeted-group, Offensive-targeted-other, or Not-in-indented-language. I use the transformer-based language model with BiGRU-Attention to complete this task. To prove the validity of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>, I also use some other neural network models for comparison. And finally, the team ranks 5th in this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> with a weighted average F1 score of 0.93 on the private leader board.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dravidianlangtech-1.41.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dravidianlangtech-1--41 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dravidianlangtech-1.41 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.dravidianlangtech-1.41.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.dravidianlangtech-1.41/>Simon @ DravidianLangTech-EACL2021 : Meme Classification for Tamil with BERT<span class=acl-fixed-case>D</span>ravidian<span class=acl-fixed-case>L</span>ang<span class=acl-fixed-case>T</span>ech-<span class=acl-fixed-case>EACL</span>2021: Meme Classification for <span class=acl-fixed-case>T</span>amil with <span class=acl-fixed-case>BERT</span></a></strong><br><a href=/people/q/qinyu-que/>Qinyu Que</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dravidianlangtech-1--41><div class="card-body p-3 small">In this paper, we introduce the <a href=https://en.wikipedia.org/wiki/System>system</a> for the task of meme classification for <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil</a>, submitted by our team. In today&#8217;s society, <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> has become an important platform for people to communicate. We use <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> to share information about ourselves and express our views on things. It has gradually developed a unique form of <a href=https://en.wikipedia.org/wiki/Emotional_expression>emotional expression</a> on <a href=https://en.wikipedia.org/wiki/Internet_meme>social media meme</a>. The <a href=https://en.wikipedia.org/wiki/Meme>meme</a> is an expression that is often ironic. This also gives the meme a unique sense of humor. But it&#8217;s not just positive content on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. There&#8217;s also a lot of <a href=https://en.wikipedia.org/wiki/Profanity>offensive content</a>. Meme&#8217;s unique expression makes <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> often used by some users to post offensive content. Therefore, it is very urgent to detect the offensive content of the meme. Our team uses the natural language processing method to classify the offensive content of the meme. Our team combines the BERT model with the CNN to improve the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s ability to collect statement information. Finally, the F1-score of our team in the official test set is 0.49, and our method ranks 5th.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dravidianlangtech-1.45.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dravidianlangtech-1--45 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dravidianlangtech-1.45 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.dravidianlangtech-1.45.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.dravidianlangtech-1.45/>SSNCSE_NLP@DravidianLangTech-EACL2021 : Offensive Language Identification on Multilingual Code Mixing Text<span class=acl-fixed-case>SSNCSE</span>_<span class=acl-fixed-case>NLP</span>@<span class=acl-fixed-case>D</span>ravidian<span class=acl-fixed-case>L</span>ang<span class=acl-fixed-case>T</span>ech-<span class=acl-fixed-case>EACL</span>2021: Offensive Language Identification on Multilingual Code Mixing Text</a></strong><br><a href=/people/b/bharathi-b/>Bharathi B</a>
|
<a href=/people/a/agnusimmaculate-silvia-a/>Agnusimmaculate Silvia A</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dravidianlangtech-1--45><div class="card-body p-3 small">Social networks made a huge impact in almost all fields in recent years. Text messaging through the <a href=https://en.wikipedia.org/wiki/Internet>Internet</a> or <a href=https://en.wikipedia.org/wiki/Mobile_phone>cellular phones</a> has become a major medium of personal and commercial communication. Everyday we have to deal with <a href=https://en.wikipedia.org/wiki/Text_messaging>texts</a>, <a href=https://en.wikipedia.org/wiki/Email>emails</a> or different types of messages in which there are a variety of attacks and abusive phrases. It is the moderator&#8217;s decision which comments to remove from the platform because of violations and which ones to keep but an automatic software for detecting abusive languages would be useful in recent days. In this paper we describe an automatic offensive language identification from <a href=https://en.wikipedia.org/wiki/Dravidian_languages>Dravidian languages</a> with various <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning algorithms</a>. This is work is shared task in DravidanLangTech-EACL2021. The goal of this task is to identify offensive language content of the code-mixed dataset of comments / posts in Dravidian Languages ((Tamil-English, Malayalam-English, and Kannada-English)) collected from <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. This work explains the submissions made by SSNCSE_NLP in DravidanLangTech-EACL2021 Code-mix tasks for Offensive language detection. We achieve F1 scores of 0.95 for <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam</a>, 0.7 for <a href=https://en.wikipedia.org/wiki/Kannada>Kannada</a> and 0.73 for task2-Tamil on the test-set.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dravidianlangtech-1.47.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dravidianlangtech-1--47 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dravidianlangtech-1.47 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.dravidianlangtech-1.47.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.dravidianlangtech-1.47/>MUCS@DravidianLangTech-EACL2021 : COOLI-Code-Mixing Offensive Language Identification<span class=acl-fixed-case>MUCS</span>@<span class=acl-fixed-case>D</span>ravidian<span class=acl-fixed-case>L</span>ang<span class=acl-fixed-case>T</span>ech-<span class=acl-fixed-case>EACL</span>2021:<span class=acl-fixed-case>COOLI</span>-Code-Mixing Offensive Language Identification</a></strong><br><a href=/people/f/fazlourrahman-balouchzahi/>Fazlourrahman Balouchzahi</a>
|
<a href=/people/a/aparna-b-k/>Aparna B K</a>
|
<a href=/people/h/h-l-shashirekha/>H L Shashirekha</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dravidianlangtech-1--47><div class="card-body p-3 small">This paper describes the models submitted by the team MUCS for Offensive Language Identification in Dravidian Languages-EACL 2021 shared task that aims at identifying and classifying code-mixed texts of three language pairs namely, Kannada-English (Kn-En), Malayalam-English (Ma-En), and Tamil-English (Ta-En) into six predefined categories (5 categories in Ma-En language pair). Two models, namely, COOLI-Ensemble and COOLI-Keras are trained with the char sequences extracted from the sentences combined with words as features. Out of the two proposed models, COOLI-Ensemble model (best among our models) obtained first rank for Ma-En language pair with 0.97 weighted F1-score and fourth and sixth ranks with 0.75 and 0.69 weighted F1-score for Ta-En and Kn-En language pairs respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dravidianlangtech-1.51.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dravidianlangtech-1--51 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dravidianlangtech-1.51 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.dravidianlangtech-1.51/>OffTamil@DravideanLangTech-EASL2021 : Offensive Language Identification in Tamil Text<span class=acl-fixed-case>O</span>ff<span class=acl-fixed-case>T</span>amil@<span class=acl-fixed-case>D</span>ravidean<span class=acl-fixed-case>L</span>ang<span class=acl-fixed-case>T</span>ech-<span class=acl-fixed-case>EASL</span>2021: Offensive Language Identification in <span class=acl-fixed-case>T</span>amil Text</a></strong><br><a href=/people/d/disne-sivalingam/>Disne Sivalingam</a>
|
<a href=/people/s/sajeetha-thavareesan/>Sajeetha Thavareesan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dravidianlangtech-1--51><div class="card-body p-3 small">In the last few decades, Code-Mixed Offensive texts are used penetratingly in social media posts. Social media platforms and <a href=https://en.wikipedia.org/wiki/Online_community>online communities</a> showed much interest on offensive text identification in recent years. Consequently, research community is also interested in identifying such content and also contributed to the development of corpora. Many publicly available corpora are there for research on identifying offensive text written in <a href=https://en.wikipedia.org/wiki/English_language>English language</a> but rare for low resourced languages like <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil</a>. The first code-mixed offensive text for <a href=https://en.wikipedia.org/wiki/Dravidian_languages>Dravidian languages</a> are developed by shared task organizers which is used for this study. This study focused on offensive language identification on code-mixed low-resourced Dravidian language Tamil using four classifiers (Support Vector Machine, random forest, k- Nearest Neighbour and Naive Bayes) using chi2 feature selection technique along with BoW and TF-IDF feature representation techniques using different combinations of n-grams. This proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieved an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 76.96 % while using linear SVM with TF-IDF feature representation technique.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright &nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>