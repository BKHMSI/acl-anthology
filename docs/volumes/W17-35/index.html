<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 10th International Conference on Natural Language Generation - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/W17-35.pdf>Proceedings of the 10th International Conference on Natural Language Generation</a></h2><p class=lead><a href=/people/j/jose-m-alonso/>Jose M. Alonso</a>,
<a href=/people/a/alberto-bugarin-diz/>Alberto Bugarín</a>,
<a href=/people/e/ehud-reiter/>Ehud Reiter</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>W17-35</dd><dt>Month:</dt><dd>September</dd><dt>Year:</dt><dd>2017</dd><dt>Address:</dt><dd>Santiago de Compostela, Spain</dd><dt>Venues:</dt><dd><a href=/venues/inlg/>INLG</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd><a href=/sigs/siggen/>SIGGEN</a></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/W17-35>https://aclanthology.org/W17-35</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/W17-35 title="To the current version of the paper by DOI">10.18653/v1/W17-35</a></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/W17-35.pdf>https://aclanthology.org/W17-35.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/W17-35.pdf title="Open PDF of 'Proceedings of the 10th International Conference on Natural Language Generation'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+10th+International+Conference+on+Natural+Language+Generation" title="Search for 'Proceedings of the 10th International Conference on Natural Language Generation' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3500.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3500/>Proceedings of the 10th International Conference on Natural Language Generation</a></strong><br><a href=/people/j/jose-m-alonso/>Jose M. Alonso</a>
|
<a href=/people/a/alberto-bugarin-diz/>Alberto Bugarín</a>
|
<a href=/people/e/ehud-reiter/>Ehud Reiter</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3501.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3501 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3501 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3501/>Linguistic realisation as <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> : Comparing different MT models for AMR-to-text generation<span class=acl-fixed-case>MT</span> models for <span class=acl-fixed-case>AMR</span>-to-text generation</a></strong><br><a href=/people/t/thiago-castro-ferreira/>Thiago Castro Ferreira</a>
|
<a href=/people/i/iacer-calixto/>Iacer Calixto</a>
|
<a href=/people/s/sander-wubben/>Sander Wubben</a>
|
<a href=/people/e/emiel-krahmer/>Emiel Krahmer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3501><div class="card-body p-3 small">In this paper, we study AMR-to-text generation, framing it as a translation task and comparing two different MT approaches (Phrase-based and Neural MT). We systematically study the effects of 3 AMR preprocessing steps (Delexicalisation, <a href=https://en.wikipedia.org/wiki/Data_compression>Compression</a>, and Linearisation) applied before the MT phase. Our results show that <a href=https://en.wikipedia.org/wiki/Data_preprocessing>preprocessing</a> indeed helps, although the benefits differ for the two MT models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3502.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3502 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3502 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3502/>A Survey on Intelligent Poetry Generation : <a href=https://en.wikipedia.org/wiki/Language>Languages</a>, Features, <a href=https://en.wikipedia.org/wiki/Technology>Techniques</a>, Reutilisation and Evaluation</a></strong><br><a href=/people/h/hugo-goncalo-oliveira/>Hugo Gonçalo Oliveira</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3502><div class="card-body p-3 small">Poetry generation is becoming popular among researchers of <a href=https://en.wikipedia.org/wiki/Natural-language_generation>Natural Language Generation</a>, <a href=https://en.wikipedia.org/wiki/Computational_creativity>Computational Creativity</a> and, broadly, <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>Artificial Intelligence</a>. To produce text that may be regarded as <a href=https://en.wikipedia.org/wiki/Poetry>poetry</a>, <a href=https://en.wikipedia.org/wiki/Poetry>poetry generation systems</a> are typically knowledge-intensive and have to deal with several levels of language, from lexical to semantics. Interest on the topic resulted in the development of several <a href=https://en.wikipedia.org/wiki/Poetry_generator>poetry generators</a> described in the literature, with different features covered or handled differently, by a broad range of alternative approaches, as well as different perspectives on <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation</a>, another challenging aspect due the underlying subjectivity. This paper surveys intelligent poetry generators around a set of relevant axis for poetry generation targeted languages, form and content features, techniques, reutilisation of material, and evaluation and aims to organise work developed on this topic so far.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3504.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3504 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3504 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3504/>Content Selection for Real-time Sports News Construction from Commentary Texts</a></strong><br><a href=/people/j/jin-ge-yao/>Jin-ge Yao</a>
|
<a href=/people/j/jianmin-zhang/>Jianmin Zhang</a>
|
<a href=/people/x/xiaojun-wan/>Xiaojun Wan</a>
|
<a href=/people/j/jianguo-xiao/>Jianguo Xiao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3504><div class="card-body p-3 small">We study the task of constructing sports news report automatically from <a href=https://en.wikipedia.org/wiki/Sports_commentator>live commentary</a> and focus on content selection. Rather than receiving every piece of text of a sports match before news construction, as in previous related work, we novelly verify the feasibility of a more challenging but more useful setting to generate news report on the fly by treating live text input as a stream. Specifically, we design various scoring functions to address different requirements of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. The near submodularity of scoring functions makes it possible to adapt efficient <a href=https://en.wikipedia.org/wiki/Greedy_algorithm>greedy algorithms</a> even in stream data settings. Experiments suggest that our proposed framework can already produce comparable results compared with previous work that relies on a supervised learning-to-rank model with heavy feature engineering.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3505.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3505 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3505 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3505/>Improving the Naturalness and Expressivity of <a href=https://en.wikipedia.org/wiki/Language_generation>Language Generation</a> for Spanish<span class=acl-fixed-case>S</span>panish</a></strong><br><a href=/people/c/cristina-barros/>Cristina Barros</a>
|
<a href=/people/d/dimitra-gkatzia/>Dimitra Gkatzia</a>
|
<a href=/people/e/elena-lloret/>Elena Lloret</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3505><div class="card-body p-3 small">We present a flexible Natural Language Generation approach for <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>, focused on the surface realisation stage, which integrates an inflection module in order to improve the naturalness and expressivity of the generated language. This inflection module inflects the verbs using an <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>ensemble of trainable algorithms</a> whereas the other types of words (e.g. nouns, <a href=https://en.wikipedia.org/wiki/Determiner>determiners</a>, etc) are inflected using hand-crafted rules. We show that our approach achieves 2 % higher <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> than two state-of-art inflection generation approaches. Furthermore, our proposed approach also predicts an extra feature : the inflection of the <a href=https://en.wikipedia.org/wiki/Imperative_mood>imperative mood</a>, which was not taken into account by previous work. We also present a user evaluation, where we demonstrate that the proposed method significantly improves the perceived naturalness of the generated language.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3506.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3506 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3506 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-3506" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-3506/>What is the Role of Recurrent Neural Networks (RNNs) in an Image Caption Generator?<span class=acl-fixed-case>RNN</span>s) in an Image Caption Generator?</a></strong><br><a href=/people/m/marc-tanti/>Marc Tanti</a>
|
<a href=/people/a/albert-gatt/>Albert Gatt</a>
|
<a href=/people/k/kenneth-camilleri/>Kenneth Camilleri</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3506><div class="card-body p-3 small">Image captioning has evolved into a core task for Natural Language Generation and has also proved to be an important testbed for deep learning approaches to handling multimodal representations. Most contemporary approaches rely on a combination of a convolutional network to handle image features, and a <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent network</a> to encode linguistic information. The latter is typically viewed as the primary generation component. Beyond this high-level characterisation, a CNN+RNN model supports a variety of architectural designs. The dominant model in the literature is one in which visual features encoded by a CNN are injected as part of the linguistic encoding process, driving the RNN&#8217;s linguistic choices. By contrast, it is possible to envisage an <a href=https://en.wikipedia.org/wiki/Architecture>architecture</a> in which visual and linguistic features are encoded separately, and merged at a subsequent stage. In this paper, we address two related questions : (1) Is direct injection the best way of combining multimodal information, or is a late merging alternative better for the image captioning task? (2) To what extent should a <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent network</a> be viewed as actually generating, rather than simply encoding, linguistic information?</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3507.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3507 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3507 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3507/>Exploring the Behavior of Classic REG Algorithms in the Description of Characters in 3D Images<span class=acl-fixed-case>REG</span> Algorithms in the Description of Characters in 3<span class=acl-fixed-case>D</span> Images</a></strong><br><a href=/people/g/gonzalo-mendez/>Gonzalo Méndez</a>
|
<a href=/people/r/raquel-hervas/>Raquel Hervás</a>
|
<a href=/people/s/susana-bautista/>Susana Bautista</a>
|
<a href=/people/a/adrian-rabadan/>Adrián Rabadán</a>
|
<a href=/people/t/teresa-rodriguez/>Teresa Rodríguez</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3507><div class="card-body p-3 small">Describing people and characters can be very useful in different contexts, such as computational narrative or image description for the visually impaired. However, a review of the existing literature shows that the automatic generation of people descriptions has not received much attention. Our work focuses on the description of people in snapshots from a <a href=https://en.wikipedia.org/wiki/3D_computer_graphics>3D environment</a>. First, we have conducted a survey to identify the way in which people describe other people under different conditions. We have used the information extracted from this survey to design several Referring Expression Generation algorithms which produce similar results. We have evaluated these <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> with users in order to identify which ones generate the best description for specific characters in different situations. The evaluation has shown that, in order to generate good descriptions, a combination of different <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> has to be used depending on the features and situation of the person to be described.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3508.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3508 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3508 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3508/>Co-PoeTryMe : a Co-Creative Interface for the Composition of Poetry<span class=acl-fixed-case>P</span>oe<span class=acl-fixed-case>T</span>ry<span class=acl-fixed-case>M</span>e: a Co-Creative Interface for the Composition of Poetry</a></strong><br><a href=/people/h/hugo-goncalo-oliveira/>Hugo Gonçalo Oliveira</a>
|
<a href=/people/t/tiago-mendes/>Tiago Mendes</a>
|
<a href=/people/a/ana-boavida/>Ana Boavida</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3508><div class="card-body p-3 small">Co-PoeTryMe is a web application for poetry composition, guided by the user, though with the help of automatic features, such as the generation of full (editable) drafts, as well as the acquisition of additional well-formed lines, or semantically-related words, possibly constrained by the number of syllables, <a href=https://en.wikipedia.org/wiki/Rhyme>rhyme</a>, or polarity. Towards the final poem, the latter can replace lines or words in the draft.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3509.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3509 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3509 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3509/>Refer-iTTS : A System for Referring in Spoken Installments to Objects in Real-World Images<span class=acl-fixed-case>TTS</span>: A System for Referring in Spoken Installments to Objects in Real-World Images</a></strong><br><a href=/people/s/sina-zarriess/>Sina Zarrieß</a>
|
<a href=/people/m/m-soledad-lopez-gambino/>M. Soledad López Gambino</a>
|
<a href=/people/d/david-schlangen/>David Schlangen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3509><div class="card-body p-3 small">Current referring expression generation systems mostly deliver their output as one-shot, written expressions. We present on-going work on incremental generation of spoken expressions referring to objects in real-world images. This approach extends upon previous work using the words-as-classifier model for generation. We implement this generator in an incremental dialogue processing framework such that we can exploit an existing interface to incremental text-to-speech synthesis. Our <a href=https://en.wikipedia.org/wiki/System>system</a> generates and synthesizes <a href=https://en.wikipedia.org/wiki/Reference>referring expressions</a> while continuously observing <a href=https://en.wikipedia.org/wiki/Nonverbal_communication>non-verbal user reactions</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3510.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3510 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3510 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3510/>Finding the right answers for customers</a></strong><br><a href=/people/f/frank-schilder/>Frank Schilder</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3510><div class="card-body p-3 small">This talk will present a few NLG systems developed within <a href=https://en.wikipedia.org/wiki/Thomson_Reuters>Thomson Reuters</a> providing information to professionals such as lawyers, accountants or traders. Based on the experience developing these system, I will discuss the usefulness of <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>automatic metrics</a>, <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowd-sourced evaluation</a>, corpora studies and expert reviews. I will conclude with exploring the question of whether developers of NLG systems need to follow ethical guidelines and how those guidelines could be established.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3514.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3514 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3514 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3514/>Evaluation of a Runyankore grammar engine for healthcare messages<span class=acl-fixed-case>R</span>unyankore grammar engine for healthcare messages</a></strong><br><a href=/people/j/joan-byamugisha/>Joan Byamugisha</a>
|
<a href=/people/c/c-maria-keet/>C. Maria Keet</a>
|
<a href=/people/b/brian-derenzi/>Brian DeRenzi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3514><div class="card-body p-3 small">Natural Language Generation (NLG) can be used to generate personalized health information, which is especially useful when provided in one&#8217;s own language. However, the NLG technique widely used in different domains and languagestemplateswas shown to be inapplicable to <a href=https://en.wikipedia.org/wiki/Bantu_languages>Bantu languages</a>, due to their characteristic agglutinative structure. We present here our use of the grammar engine NLG technique to generate text in <a href=https://en.wikipedia.org/wiki/Nkore_language>Runyankore</a>, a Bantu language indigenous to <a href=https://en.wikipedia.org/wiki/Uganda>Uganda</a>. Our grammar engine adds to previous work in this field with new rules for <a href=https://en.wikipedia.org/wiki/Cardinality>cardinality constraints</a>, prepositions in roles, the passive, and phonological conditioning. We evaluated the generated text with linguists and non-linguists, who regarded most text as grammatically correct and understandable ; and over 60 % of them regarded all the text generated by our system to have been authored by a human being.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3518.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3518 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3518 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3518/>The WebNLG Challenge : Generating Text from <a href=https://en.wikipedia.org/wiki/Resource_Description_Framework>RDF Data</a><span class=acl-fixed-case>W</span>eb<span class=acl-fixed-case>NLG</span> Challenge: Generating Text from <span class=acl-fixed-case>RDF</span> Data</a></strong><br><a href=/people/c/claire-gardent/>Claire Gardent</a>
|
<a href=/people/a/anastasia-shimorina/>Anastasia Shimorina</a>
|
<a href=/people/s/shashi-narayan/>Shashi Narayan</a>
|
<a href=/people/l/laura-perez-beltrachini/>Laura Perez-Beltrachini</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3518><div class="card-body p-3 small">The WebNLG challenge consists in mapping sets of <a href=https://en.wikipedia.org/wiki/Resource_Description_Framework>RDF triples</a> to text. It provides a common benchmark on which to train, evaluate and compare <a href=https://en.wikipedia.org/wiki/Microplanners>microplanners</a>, i.e. generation systems that verbalise a given content by making a range of complex interacting choices including referring expression generation, aggregation, <a href=https://en.wikipedia.org/wiki/Lexicalization>lexicalisation</a>, surface realisation and <a href=https://en.wikipedia.org/wiki/Sentence_segmentation>sentence segmentation</a>. In this paper, we introduce the microplanning task, describe data preparation, introduce our evaluation methodology, analyse participant results and provide a brief description of the participating systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3520.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3520 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3520 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3520/>Integrated sentence generation using charts</a></strong><br><a href=/people/a/alexander-koller/>Alexander Koller</a>
|
<a href=/people/n/nikos-engonopoulos/>Nikos Engonopoulos</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3520><div class="card-body p-3 small">Integrating surface realization and the generation of referring expressions into a single <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> can improve the quality of the generated sentences. Existing <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> for doing this, such as <a href=https://en.wikipedia.org/wiki/SPUD>SPUD</a> and CRISP, are search-based and can be slow or incomplete. We offer a chart-based algorithm for integrated sentence generation and demonstrate its runtime efficiency.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3521.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3521 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3521 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3521/>Adapting SimpleNLG to Spanish<span class=acl-fixed-case>S</span>imple<span class=acl-fixed-case>NLG</span> to <span class=acl-fixed-case>S</span>panish</a></strong><br><a href=/people/a/alejandro-ramos-soto/>Alejandro Ramos-Soto</a>
|
<a href=/people/j/julio-janeiro-gallardo/>Julio Janeiro-Gallardo</a>
|
<a href=/people/a/alberto-bugarin-diz/>Alberto Bugarín Diz</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3521><div class="card-body p-3 small">We describe SimpleNLG-ES, an adaptation of the SimpleNLG realization library for the <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish language</a>. Our <a href=https://en.wikipedia.org/wiki/Implementation>implementation</a> is based on the bilingual English-French SimpleNLG-EnFr adaptation. The <a href=https://en.wikipedia.org/wiki/Library_(computing)>library</a> has been tested using a battery of examples that ensure that the most common <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a>, <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphology</a> and orthography rules for <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a> are met. The <a href=https://en.wikipedia.org/wiki/Library_(computing)>library</a> is currently being used in three different projects for the development of data-to-text systems in the meteorological, statistical data information, and business intelligence application domains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3522.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3522 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3522 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3522/>G-TUNA : a corpus of referring expressions in <a href=https://en.wikipedia.org/wiki/German_language>German</a>, including duration information<span class=acl-fixed-case>G</span>-<span class=acl-fixed-case>TUNA</span>: a corpus of referring expressions in <span class=acl-fixed-case>G</span>erman, including duration information</a></strong><br><a href=/people/d/david-m-howcroft/>David Howcroft</a>
|
<a href=/people/j/jorrig-vogels/>Jorrig Vogels</a>
|
<a href=/people/v/vera-demberg/>Vera Demberg</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3522><div class="card-body p-3 small">Corpora of referring expressions elicited from human participants in a controlled environment are an important resource for research on automatic referring expression generation. We here present G-TUNA, a new corpus of referring expressions for <a href=https://en.wikipedia.org/wiki/German_language>German</a>. Using the furniture stimuli set developed for the TUNA and D-TUNA corpora, our corpus extends on these <a href=https://en.wikipedia.org/wiki/Corpus_linguistics>corpora</a> by providing data collected in a simulated driving dual-task setting, and additionally provides exact duration annotations for the spoken referring expressions. This <a href=https://en.wikipedia.org/wiki/Speech_corpus>corpus</a> will hence allow researchers to analyze the interaction between referring expression length and speech rate, under conditions where the listener is under high vs. low cognitive load.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3523.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3523 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3523 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3523/>Toward an NLG System for <a href=https://en.wikipedia.org/wiki/Bantu_languages>Bantu languages</a> : first steps with Runyankore (demo)<span class=acl-fixed-case>NLG</span> System for <span class=acl-fixed-case>B</span>antu languages: first steps with <span class=acl-fixed-case>R</span>unyankore (demo)</a></strong><br><a href=/people/j/joan-byamugisha/>Joan Byamugisha</a>
|
<a href=/people/c/c-maria-keet/>C. Maria Keet</a>
|
<a href=/people/b/brian-derenzi/>Brian DeRenzi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3523><div class="card-body p-3 small">There are many domain-specific and language-specific NLG systems, of which it may be possible to adapt to related domains and languages. The languages in the <a href=https://en.wikipedia.org/wiki/Bantu_languages>Bantu language family</a> have their own set of features distinct from other major groups, which therefore severely limits the options to bootstrap an NLG system from existing ones. We present here our first proof-of-concept application for knowledge-to-text NLG as a plugin to the <a href=https://en.wikipedia.org/wiki/Protege>Protege 5.x ontology development system</a>, tailored to <a href=https://en.wikipedia.org/wiki/Nkore_language>Runyankore</a>, a <a href=https://en.wikipedia.org/wiki/Bantu_languages>Bantu language</a> indigenous to Uganda. It comprises a basic annotation model for linguistic information such as <a href=https://en.wikipedia.org/wiki/Noun_class>noun class</a>, an implementation of existing verbalisation rules and a CFG for verbs, and a basic interface for <a href=https://en.wikipedia.org/wiki/Data_entry_clerk>data entry</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3524.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3524 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3524 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3524/>A working, non-trivial, topically indifferent NLG System for 17 languages<span class=acl-fixed-case>NLG</span> System for 17 languages</a></strong><br><a href=/people/r/robert-weissgraeber/>Robert Weißgraeber</a>
|
<a href=/people/a/andreas-madsack/>Andreas Madsack</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3524><div class="card-body p-3 small">A fully fledged practical working application for a rule-based NLG system is presented that is able to create non-trivial, human sounding narrative from structured data, in any language and for any topic.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3525.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3525 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3525 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3525/>Generating titles for millions of browse pages on an e-Commerce site</a></strong><br><a href=/people/p/prashant-mathur/>Prashant Mathur</a>
|
<a href=/people/n/nicola-ueffing/>Nicola Ueffing</a>
|
<a href=/people/g/gregor-leusch/>Gregor Leusch</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3525><div class="card-body p-3 small">We present two approaches to generate titles for browse pages in five different languages, namely <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/German_language>German</a>, <a href=https://en.wikipedia.org/wiki/French_language>French</a>, <a href=https://en.wikipedia.org/wiki/Italian_language>Italian</a> and <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>. These browse pages are structured search pages in an e-commerce domain. We first present a rule-based approach to generate these browse page titles. In addition, we also present a hybrid approach which uses a phrase-based statistical machine translation engine on top of the rule-based system to assemble the best title. For the two languages <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/German_language>German</a> we have access to a large amount of already available rule-based generated and curated titles. For these languages we present an automatic post-editing approach which learns how to post-edit the rule-based titles into curated titles.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3526.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3526 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3526 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3526/>Towards Automatic Generation of Product Reviews from Aspect-Sentiment Scores</a></strong><br><a href=/people/h/hongyu-zang/>Hongyu Zang</a>
|
<a href=/people/x/xiaojun-wan/>Xiaojun Wan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3526><div class="card-body p-3 small">Data-to-text generation is very essential and important in machine writing applications. The recent <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning models</a>, like <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>Recurrent Neural Networks (RNNs)</a>, have shown a bright future for relevant text generation tasks. However, rare work has been done for automatic generation of long reviews from user opinions. In this paper, we introduce a <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural network model</a> to generate long Chinese reviews from aspect-sentiment scores representing users&#8217; opinions. We conduct our study within the framework of encoder-decoder networks, and we propose a hierarchical structure with aligned attention in the Long-Short Term Memory (LSTM) decoder. Experiments show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms retrieval based baseline methods, and also beats the sequential generation models in qualitative evaluations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3527.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3527 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3527 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3527/>A model of suspense for narrative generation</a></strong><br><a href=/people/r/richard-doust/>Richard Doust</a>
|
<a href=/people/p/paul-piwek/>Paul Piwek</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3527><div class="card-body p-3 small">Most work on automatic generation of narratives, and more specifically <a href=https://en.wikipedia.org/wiki/Suspense>suspenseful narrative</a>, has focused on detailed domain-specific modelling of character psychology and <a href=https://en.wikipedia.org/wiki/Plot_(narrative)>plot structure</a>. Recent work in <a href=https://en.wikipedia.org/wiki/Computational_linguistics>computational linguistics</a> on the automatic learning of narrative schemas suggests an alternative approach that exploits such <a href=https://en.wikipedia.org/wiki/Schema_(psychology)>schemas</a> as a starting point for modelling and measuring <a href=https://en.wikipedia.org/wiki/Suspense>suspense</a>. We propose a domain-independent model for tracking <a href=https://en.wikipedia.org/wiki/Suspense>suspense</a> in a story which can be used to predict the audience&#8217;s suspense response on a sentence-by-sentence basis at the content determination stage of narrative generation. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> lends itself as the theoretical foundation for a <a href=https://en.wikipedia.org/wiki/Suspense>suspense module</a> that is compatible with alternative narrative generation theories. The <a href=https://en.wikipedia.org/wiki/Proposal_(business)>proposal</a> is evaluated by human judges&#8217; normalised average scores correlate strongly with predicted values.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3528.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3528 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3528 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3528/>Data-Driven News Generation for Automated Journalism</a></strong><br><a href=/people/l/leo-leppanen/>Leo Leppänen</a>
|
<a href=/people/m/myriam-munezero/>Myriam Munezero</a>
|
<a href=/people/m/mark-granroth-wilding/>Mark Granroth-Wilding</a>
|
<a href=/people/h/hannu-toivonen/>Hannu Toivonen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3528><div class="card-body p-3 small">Despite increasing amounts of data and ever improving <a href=https://en.wikipedia.org/wiki/Natural-language_generation>natural language generation techniques</a>, work on <a href=https://en.wikipedia.org/wiki/Automated_journalism>automated journalism</a> is still relatively scarce. In this paper, we explore the field and challenges associated with building a journalistic natural language generation system. We present a set of requirements that should guide system design, including <a href=https://en.wikipedia.org/wiki/Transparency_and_translucency>transparency</a>, <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, modifiability and transferability. Guided by the requirements, we present a data-driven architecture for automated journalism that is largely domain and language independent. We illustrate its practical application in the production of <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a> about the 2017 Finnish municipal elections in three languages, demonstrating the successfulness of the data-driven, modular approach of the design. We then draw some lessons for future <a href=https://en.wikipedia.org/wiki/Automated_journalism>automated journalism</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3529.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3529 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3529 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3529/>Data Augmentation for Visual Question Answering</a></strong><br><a href=/people/k/kushal-kafle/>Kushal Kafle</a>
|
<a href=/people/m/mohammed-yousefhussien/>Mohammed Yousefhussien</a>
|
<a href=/people/c/christopher-kanan/>Christopher Kanan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3529><div class="card-body p-3 small">Data augmentation is widely used to train <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural networks</a> for image classification tasks. Simply flipping images can help learning tremendously by increasing the number of training images by a factor of two. However, little work has been done studying <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. Here, we describe two methods for <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> for Visual Question Answering (VQA). The <a href=https://en.wikipedia.org/wiki/First_Amendment_to_the_United_States_Constitution>first</a> uses existing <a href=https://en.wikipedia.org/wiki/Semantic_annotation>semantic annotations</a> to generate new questions. The second method is a generative approach using <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural networks</a>. Experiments show that the proposed <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> improves performance of both <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> and state-of-the-art VQA algorithms.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3531.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3531 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3531 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-3531" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-3531/>A Comparison of Neural Models for Word Ordering</a></strong><br><a href=/people/e/eva-hasler/>Eva Hasler</a>
|
<a href=/people/f/felix-stahlberg/>Felix Stahlberg</a>
|
<a href=/people/m/marcus-tomalin/>Marcus Tomalin</a>
|
<a href=/people/a/adria-de-gispert/>Adrià de Gispert</a>
|
<a href=/people/b/bill-byrne/>Bill Byrne</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3531><div class="card-body p-3 small">We compare several language models for the word-ordering task and propose a new bag-to-sequence neural model based on attention-based sequence-to-sequence models. We evaluate the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on a large German WMT data set where it significantly outperforms existing <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. We also describe a novel search strategy for LM-based word ordering and report results on the English Penn Treebank. Our best model setup outperforms prior work both in terms of speed and quality.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3532.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3532 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3532 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3532/>Investigating the content and form of referring expressions in <a href=https://en.wikipedia.org/wiki/Mandarin_Chinese>Mandarin</a> : introducing the Mtuna corpus<span class=acl-fixed-case>M</span>andarin: introducing the Mtuna corpus</a></strong><br><a href=/people/k/kees-van-deemter/>Kees van Deemter</a>
|
<a href=/people/l/le-sun/>Le Sun</a>
|
<a href=/people/r/rint-sybesma/>Rint Sybesma</a>
|
<a href=/people/x/xiao-li/>Xiao Li</a>
|
<a href=/people/b/bo-chen/>Bo Chen</a>
|
<a href=/people/m/muyun-yang/>Muyun Yang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3532><div class="card-body p-3 small">East Asian languages are thought to handle reference differently from <a href=https://en.wikipedia.org/wiki/Language>languages</a> such as <a href=https://en.wikipedia.org/wiki/English_language>English</a>, particularly in terms of the marking of definiteness and <a href=https://en.wikipedia.org/wiki/Grammatical_number>number</a>. We present the first Data-Text corpus for Referring Expressions in <a href=https://en.wikipedia.org/wiki/Mandarin_Chinese>Mandarin</a>, and we use this <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> to test some initial hypotheses inspired by the theoretical linguistics literature. Our findings suggest that function words deserve more attention in Referring Expressions Generation than they have so far received, and they have a bearing on the debate about whether different languages make different trade-offs between clarity and brevity.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3533.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3533 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3533 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3533/>Realization of long sentences using chunking</a></strong><br><a href=/people/e/ewa-muszynska/>Ewa Muszyńska</a>
|
<a href=/people/a/ann-copestake/>Ann Copestake</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3533><div class="card-body p-3 small">We propose sentence chunking as a way to reduce the time and memory costs of realization of long sentences. During chunking we divide the semantic representation of a sentence into smaller components which can be processed and recombined without loss of information. Our meaning representation of choice is the Dependency Minimal Recursion Semantics (DMRS). We show that realizing chunks of a sentence and combining the results of such realizations increases the coverage for long sentences, significantly reduces the resources required and does not affect the quality of the realization.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3534.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3534 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3534 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3534/>SaToS : Assessing and Summarising Terms of Services from German Webshops<span class=acl-fixed-case>S</span>a<span class=acl-fixed-case>T</span>o<span class=acl-fixed-case>S</span>: Assessing and Summarising Terms of Services from <span class=acl-fixed-case>G</span>erman Webshops</a></strong><br><a href=/people/d/daniel-braun/>Daniel Braun</a>
|
<a href=/people/e/elena-scepankova/>Elena Scepankova</a>
|
<a href=/people/p/patrick-holl/>Patrick Holl</a>
|
<a href=/people/f/florian-matthes/>Florian Matthes</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3534><div class="card-body p-3 small">Every time we buy something online, we are confronted with <a href=https://en.wikipedia.org/wiki/Terms_of_service>Terms of Services</a>. However, only a few people actually read these terms, before accepting them, often to their disadvantage. In this paper, we present the SaToS browser plugin which summarises and simplifies <a href=https://en.wikipedia.org/wiki/Terms_of_service>Terms of Services</a> from German webshops.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3535.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3535 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3535 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3535/>Textually Summarising Incomplete Data</a></strong><br><a href=/people/s/stephanie-inglis/>Stephanie Inglis</a>
|
<a href=/people/e/ehud-reiter/>Ehud Reiter</a>
|
<a href=/people/s/somayajulu-sripada/>Somayajulu Sripada</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3535><div class="card-body p-3 small">Many data-to-text NLG systems work with data sets which are incomplete, ie some of the data is missing. We have worked with data journalists to understand how they describe incomplete data, and are building NLG algorithms based on these insights. A pilot evaluation showed mixed results, and highlighted several areas where we need to improve our <a href=https://en.wikipedia.org/wiki/System>system</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3537.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3537 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3537 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3537/>Analysing Data-To-Text Generation Benchmarks</a></strong><br><a href=/people/l/laura-perez-beltrachini/>Laura Perez-Beltrachini</a>
|
<a href=/people/c/claire-gardent/>Claire Gardent</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3537><div class="card-body p-3 small">A generation system can only be as good as the data it is trained on. In this short paper, we propose a <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> for analysing data-to-text corpora used for training Natural Language Generation (NLG) systems. We apply this <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> to three existing <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmarks</a>. We conclude by eliciting a set of criteria for the creation of a data-to-text benchmark which could help better support the development, evaluation and comparison of linguistically sophisticated data-to-text generators.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3538.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3538 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3538 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3538/>Linguistic Description of Complex Phenomena with the rLDCP R Package<span class=acl-fixed-case>LDCP</span> <span class=acl-fixed-case>R</span> Package</a></strong><br><a href=/people/j/jose-m-alonso/>Jose Alonso</a>
|
<a href=/people/p/patricia-conde-clemente/>Patricia Conde-Clemente</a>
|
<a href=/people/g/gracian-trivino/>Gracian Trivino</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3538><div class="card-body p-3 small">Monitoring and analysis of complex phenomena attract the attention of both academy and industry. Dealing with data produced by <a href=https://en.wikipedia.org/wiki/Complex_system>complex phenomena</a> requires the use of advance <a href=https://en.wikipedia.org/wiki/Computational_intelligence>computational intelligence techniques</a>. Namely, linguistic description of complex phenomena constitutes a mature research line. It is supported by the Computational Theory of Perceptions grounded on the <a href=https://en.wikipedia.org/wiki/Fuzzy_set>Fuzzy Sets Theory</a>. Its aim is the development of computational systems with the ability to generate vague descriptions of the world in a similar way how humans do. This is a human-centric and multi-disciplinary research work. Moreover, its success is a matter of careful design ; thus, developers play a key role. The rLDCP R package was designed to facilitate the development of new applications. This demo introduces the use of rLDCP, for both beginners and advance developers, in practical use cases.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3539.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3539 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3539 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3539/>A demo of FORGe : the Pompeu Fabra Open Rule-based Generator<span class=acl-fixed-case>FORG</span>e: the <span class=acl-fixed-case>P</span>ompeu <span class=acl-fixed-case>F</span>abra Open Rule-based Generator</a></strong><br><a href=/people/s/simon-mille/>Simon Mille</a>
|
<a href=/people/l/leo-wanner/>Leo Wanner</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3539><div class="card-body p-3 small">This demo paper presents the multilingual deep sentence generator developed by the TALN group at Universitat Pompeu Fabra, implemented as a series of rule-based graph-transducers for the syntacticization of the input graphs, the resolution of morphological agreements, and the linearization of the trees.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3540.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3540 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3540 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3540/>Referential Success of Set Referring Expressions with Fuzzy Properties</a></strong><br><a href=/people/n/nicolas-marin/>Nicolás Marín</a>
|
<a href=/people/g/gustavo-rivas-gervilla/>Gustavo Rivas-Gervilla</a>
|
<a href=/people/d/daniel-sanchez-cisneros/>Daniel Sánchez</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3540><div class="card-body p-3 small">We introduce the <a href=https://en.wikipedia.org/wiki/Property_(philosophy)>properties</a> to be satisfied by measures of referential success of set referring expressions with fuzzy properties. We define families of measures on the basis of n-cardinality measures and we illustrate some of them with a toy example.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3541.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3541 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3541 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3541/>Neural Response Generation for <a href=https://en.wikipedia.org/wiki/Customer_service>Customer Service</a> based on Personality Traits</a></strong><br><a href=/people/j/jonathan-herzig/>Jonathan Herzig</a>
|
<a href=/people/m/michal-shmueli-scheuer/>Michal Shmueli-Scheuer</a>
|
<a href=/people/t/tommy-sandbank/>Tommy Sandbank</a>
|
<a href=/people/d/david-konopnicki/>David Konopnicki</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3541><div class="card-body p-3 small">We present a neural response generation model that generates responses conditioned on a target personality. The <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> learns high level features based on the target personality, and uses them to update its hidden state. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves performance improvements in both perplexity and BLEU scores over a baseline sequence-to-sequence model, and is validated by human judges.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-3542.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-3542 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-3542 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-3542/>Neural Paraphrase Generation using <a href=https://en.wikipedia.org/wiki/Transfer_learning>Transfer Learning</a></a></strong><br><a href=/people/f/florin-brad/>Florin Brad</a>
|
<a href=/people/t/traian-rebedea/>Traian Rebedea</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-3542><div class="card-body p-3 small">Progress in statistical paraphrase generation has been hindered for a long time by the lack of large monolingual parallel corpora. In this paper, we adapt the neural machine translation approach to <a href=https://en.wikipedia.org/wiki/Paraphrase_generation>paraphrase generation</a> and perform <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> from the closely related task of <a href=https://en.wikipedia.org/wiki/Logical_consequence>entailment generation</a>. We evaluate the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on the Microsoft Research Paraphrase (MSRP) corpus and show that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is able to generate sentences that capture part of the original meaning, but fails to pick up on important words or to show large lexical variation.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>