<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Computational Linguistics, Volume 44, Issue 4 - December 2018 - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Computational Linguistics, Volume 44, Issue 4 - <span class=acl-fixed-case>D</span>ecember 2018</h2><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>J18-4</dd><dt>Month:</dt><dd>December</dd><dt>Year:</dt><dd>2018</dd><dt>Address:</dt><dd>Cambridge, MA</dd><dt>Venue:</dt><dd><a href=/venues/cl/>CL</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>MIT Press</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/J18-4>https://aclanthology.org/J18-4</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Computational+Linguistics%2C+Volume+44%2C+Issue+4+-+December+2018" title="Search for 'Computational Linguistics, Volume 44, Issue 4 - December 2018' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/J18-4000/>Computational Linguistics, Volume 44, Issue 4 - <span class=acl-fixed-case>D</span>ecember 2018</a></strong><br></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/J18-4002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-J18-4002 data-toggle=collapse aria-expanded=false aria-controls=abstract-J18-4002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/J18-4002/>Squib : The Language Resource Switchboard<span class=acl-fixed-case>S</span>quib: The Language Resource Switchboard</a></strong><br><a href=/people/c/claus-zinn/>Claus Zinn</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-J18-4002><div class="card-body p-3 small">The CLARIN research infrastructure gives users access to an increasingly rich and diverse set of language-related resources and tools. Whereas there is ample support for searching resources using metadata-based search, or <a href=https://en.wikipedia.org/wiki/Full-text_search>full-text search</a>, or for aggregating resources into virtual collections, there is little support for users to help them process resources in one way or another. In spite of the large number of tools that process texts in many different languages, there is no single point of access where users can find tools to fit their needs and the resources they have. In this squib, we present the Language Resource Switchboard (LRS), which helps users to discover tools that can process their resources. For this, the LRS identifies all applicable tools for a given resource, lists the tasks the tools can achieve, and invokes the selected tool in such a way so that processing can start immediately with little or no prior tool parameterization.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/J18-4003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-J18-4003 data-toggle=collapse aria-expanded=false aria-controls=abstract-J18-4003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/J18-4003/>Squib : Reproducibility in Computational Linguistics : Are We Willing to Share?<span class=acl-fixed-case>S</span>quib: Reproducibility in Computational Linguistics: Are We Willing to Share?</a></strong><br><a href=/people/m/martijn-wieling/>Martijn Wieling</a>
|
<a href=/people/j/josine-rawee/>Josine Rawee</a>
|
<a href=/people/g/gertjan-van-noord/>Gertjan van Noord</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-J18-4003><div class="card-body p-3 small">This study focuses on an essential precondition for reproducibility in <a href=https://en.wikipedia.org/wiki/Computational_linguistics>computational linguistics</a> : the willingness of authors to share relevant source code and data. Ten years after Ted Pedersen&#8217;s influential Last Words contribution in <a href=https://en.wikipedia.org/wiki/Computational_linguistics>Computational Linguistics</a>, we investigate to what extent researchers in <a href=https://en.wikipedia.org/wiki/Computational_linguistics>computational linguistics</a> are willing and able to share their data and code. We surveyed all 395 full papers presented at the 2011 and 2016 ACL Annual Meetings, and identified whether links to data and code were provided. If working links were not provided, authors were requested to provide this information. Although data were often available, code was shared less often. When working links to code or data were not provided in the paper, authors provided the <a href=https://en.wikipedia.org/wiki/Source_code>code</a> in about one third of cases. For a selection of ten papers, we attempted to reproduce the results using the provided data and code. We were able to reproduce the results approximately for six papers. For only a single paper did we obtain the exact same results. Our findings show that even though the situation appears to have improved comparing 2016 to 2011, <a href=https://en.wikipedia.org/wiki/Empiricism>empiricism</a> in <a href=https://en.wikipedia.org/wiki/Computational_linguistics>computational linguistics</a> still largely remains a matter of faith. Nevertheless, we are somewhat optimistic about the future. Ensuring reproducibility is not only important for the field as a whole, but also seems worthwhile for individual researchers : The median citation count for studies with working links to the source code is higher.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/J18-4007.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-J18-4007 data-toggle=collapse aria-expanded=false aria-controls=abstract-J18-4007 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/J18-4007/>Interactional Stancetaking in Online Forums</a></strong><br><a href=/people/s/scott-f-kiesling/>Scott F. Kiesling</a>
|
<a href=/people/u/umashanthi-pavalanathan/>Umashanthi Pavalanathan</a>
|
<a href=/people/j/jim-fitzpatrick/>Jim Fitzpatrick</a>
|
<a href=/people/x/xiaochuang-han/>Xiaochuang Han</a>
|
<a href=/people/j/jacob-eisenstein/>Jacob Eisenstein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-J18-4007><div class="card-body p-3 small">Language is shaped by the relationships between the speaker / writer and the audience, the object of discussion, and the talk itself. In turn, <a href=https://en.wikipedia.org/wiki/Language>language</a> is used to reshape these relationships over the course of an interaction. Computational researchers have succeeded in operationalizing <a href=https://en.wikipedia.org/wiki/Sentimentality>sentiment</a>, <a href=https://en.wikipedia.org/wiki/Formality>formality</a>, and <a href=https://en.wikipedia.org/wiki/Politeness>politeness</a>, but each of these constructs captures only some aspects of social and relational meaning. Theories of interactional stancetaking have been put forward as holistic accounts, but until now, these <a href=https://en.wikipedia.org/wiki/Theory>theories</a> have been applied only through detailed qualitative analysis of (portions of) a few individual conversations. In this article, we propose a new computational operationalization of interpersonal stancetaking. We begin with annotations of three linked stance dimensionsaffect, investment, and alignmenton 68 conversation threads from the online platform Reddit. Using these annotations, we investigate thread structure and linguistic properties of stancetaking in online conversations. We identify lexical features that characterize the extremes along each stancetaking dimension, and show that these stancetaking properties can be predicted with moderate accuracy from bag-of-words features, even with a relatively small labeled training set. These <a href=https://en.wikipedia.org/wiki/Quantitative_research>quantitative analyses</a> are supplemented by extensive <a href=https://en.wikipedia.org/wiki/Qualitative_research>qualitative analysis</a>, highlighting the compatibility of computational and qualitative methods in synthesizing evidence about the creation of interactional meaning.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/J18-4008.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-J18-4008 data-toggle=collapse aria-expanded=false aria-controls=abstract-J18-4008 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/J18-4008/>A Joint Model of Conversational Discourse Latent Topics on Microblogs</a></strong><br><a href=/people/j/jing-li/>Jing Li</a>
|
<a href=/people/y/yan-song/>Yan Song</a>
|
<a href=/people/z/zhongyu-wei/>Zhongyu Wei</a>
|
<a href=/people/k/kam-fai-wong/>Kam-Fai Wong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-J18-4008><div class="card-body p-3 small">Conventional <a href=https://en.wikipedia.org/wiki/Topic_model>topic models</a> are ineffective for topic extraction from <a href=https://en.wikipedia.org/wiki/Microblogging>microblog messages</a>, because the data sparseness exhibited in short messages lacking structure and contexts results in poor message-level word co-occurrence patterns. To address this issue, we organize microblog messages as conversation trees based on their reposting and replying relations, and propose an <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised model</a> that jointly learns word distributions to represent : (1) different roles of conversational discourse, and (2) various latent topics in reflecting content information. By explicitly distinguishing the probabilities of messages with varying discourse roles in containing topical words, our model is able to discover clusters of discourse words that are indicative of topical content. In an automatic evaluation on large-scale microblog corpora, our joint model yields topics with better <a href=https://en.wikipedia.org/wiki/Coherence_(statistics)>coherence scores</a> than competitive topic models from previous studies. Qualitative analysis on model outputs indicates that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> induces meaningful <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a> for both discourse and topics. We further present an empirical study on microblog summarization based on the outputs of our joint model. The results show that the jointly modeled discourse and topic representations can effectively indicate summary-worthy content in microblog conversations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/J18-4009.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-J18-4009 data-toggle=collapse aria-expanded=false aria-controls=abstract-J18-4009 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/J18-4009/>Sarcasm Analysis Using Conversation Context</a></strong><br><a href=/people/d/debanjan-ghosh/>Debanjan Ghosh</a>
|
<a href=/people/a/alexander-richard-fabbri/>Alexander R. Fabbri</a>
|
<a href=/people/s/smaranda-muresan/>Smaranda Muresan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-J18-4009><div class="card-body p-3 small">Computational models for sarcasm detection have often relied on the content of utterances in isolation. However, the speaker&#8217;s sarcastic intent is not always apparent without additional context. Focusing on social media discussions, we investigate three issues : (1) does modeling conversation context help in sarcasm detection? (2) can we identify what part of <a href=https://en.wikipedia.org/wiki/Context_(language_use)>conversation context</a> triggered the <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcastic reply</a>? and (3) given a sarcastic post that contains multiple sentences, can we identify the specific sentence that is sarcastic? To address the first issue, we investigate several types of Long Short-Term Memory (LSTM) networks that can model both the conversation context and the current turn. We show that LSTM networks with sentence-level attention on context and current turn, as well as the conditional LSTM network, outperform the LSTM model that reads only the current turn. As <a href=https://en.wikipedia.org/wiki/Context_(language_use)>conversation context</a>, we consider the prior turn, the succeeding turn, or both. Our <a href=https://en.wikipedia.org/wiki/Computational_model>computational models</a> are tested on two types of <a href=https://en.wikipedia.org/wiki/Social_media>social media platforms</a> : <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> and <a href=https://en.wikipedia.org/wiki/Internet_forum>discussion forums</a>. We discuss several differences between these <a href=https://en.wikipedia.org/wiki/Data_set>data sets</a>, ranging from their size to the nature of the gold-label annotations. To address the latter two issues, we present a qualitative analysis of the attention weights produced by the LSTM models (with attention) and discuss the results compared with human performance on the two tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/J18-4010.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-J18-4010 data-toggle=collapse aria-expanded=false aria-controls=abstract-J18-4010 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/J18-4010/>We Usually Do n’t Like Going to the Dentist : Using Common Sense to Detect Irony on Twitter<span class=acl-fixed-case>T</span>witter</a></strong><br><a href=/people/c/cynthia-van-hee/>Cynthia Van Hee</a>
|
<a href=/people/e/els-lefever/>Els Lefever</a>
|
<a href=/people/v/veronique-hoste/>Véronique Hoste</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-J18-4010><div class="card-body p-3 small">Although common sense and connotative knowledge come naturally to most people, computers still struggle to perform well on tasks for which such extratextual information is required. Automatic approaches to <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> and irony detection have revealed that the lack of such <a href=https://en.wikipedia.org/wiki/World_knowledge>world knowledge</a> undermines <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> performance. In this article, we therefore address the challenge of modeling implicit or prototypical sentiment in the framework of automatic irony detection. Starting from <a href=https://en.wikipedia.org/wiki/Lexical_analysis>manually annotated connoted situation phrases</a> (e.g., flight delays, sitting the whole day at the doctor&#8217;s office), we defined the <a href=https://en.wikipedia.org/wiki/Implicit_stereotype>implicit sentiment</a> held towards such situations automatically by using both a <a href=https://en.wikipedia.org/wiki/Lexical_analysis>lexico-semantic knowledge base</a> and a data-driven method. We further investigate how such implicit sentiment information affects irony detection by assessing a state-of-the-art irony classifier before and after it is informed with implicit sentiment information.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/J18-4011.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-J18-4011 data-toggle=collapse aria-expanded=false aria-controls=abstract-J18-4011 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/J18-4011/>Combining <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Learning</a> and Argumentative Reasoning for the Analysis of Social Media Textual Content Using Small Data Sets</a></strong><br><a href=/people/o/oana-cocarascu/>Oana Cocarascu</a>
|
<a href=/people/f/francesca-toni/>Francesca Toni</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-J18-4011><div class="card-body p-3 small">The use of <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> has become a regular habit for many and has changed the way people interact with each other. In this article, we focus on analyzing whether news headlines support tweets and whether reviews are deceptive by analyzing the interaction or the influence that these texts have on the others, thus exploiting contextual information. Concretely, we define a deep learning method for relationbased argument mining to extract argumentative relations of attack and support. We then use this method for determining whether news articles support <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a>, a useful task in fact-checking settings, where determining agreement toward a statement is a useful step toward determining its truthfulness. Furthermore, we use our method for extracting bipolar argumentation frameworks from reviews to help detect whether they are deceptive. We show experimentally that our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> performs well in both settings. In particular, in the case of deception detection, our method contributes a novel argumentative feature that, when used in combination with other <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> in standard <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised classifiers</a>, outperforms the latter even on small data sets.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>