<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/W17-50.pdf>Proceedings of the 12th Workshop on Innovative Use of <span class=acl-fixed-case>NLP</span> for Building Educational Applications</a></h2><p class=lead><a href=/people/j/joel-tetreault/>Joel Tetreault</a>,
<a href=/people/j/jill-burstein/>Jill Burstein</a>,
<a href=/people/c/claudia-leacock/>Claudia Leacock</a>,
<a href=/people/h/helen-yannakoudakis/>Helen Yannakoudakis</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>W17-50</dd><dt>Month:</dt><dd>September</dd><dt>Year:</dt><dd>2017</dd><dt>Address:</dt><dd>Copenhagen, Denmark</dd><dt>Venues:</dt><dd><a href=/venues/bea/>BEA</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd><a href=/sigs/sigedu/>SIGEDU</a></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/W17-50>https://aclanthology.org/W17-50</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/W17-50 title="To the current version of the paper by DOI">10.18653/v1/W17-50</a></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/W17-50.pdf>https://aclanthology.org/W17-50.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/W17-50.pdf title="Open PDF of 'Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+12th+Workshop+on+Innovative+Use+of+NLP+for+Building+Educational+Applications" title="Search for 'Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5000/>Proceedings of the 12th Workshop on Innovative Use of <span class=acl-fixed-case>NLP</span> for Building Educational Applications</a></strong><br><a href=/people/j/joel-tetreault/>Joel Tetreault</a>
|
<a href=/people/j/jill-burstein/>Jill Burstein</a>
|
<a href=/people/c/claudia-leacock/>Claudia Leacock</a>
|
<a href=/people/h/helen-yannakoudakis/>Helen Yannakoudakis</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5001 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5001/>Question Difficulty How to Estimate Without Norming, How to Use for Automated Grading</a></strong><br><a href=/people/u/ulrike-pado/>Ulrike Padó</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5001><div class="card-body p-3 small">Question difficulty estimates guide test creation, but are too costly for small-scale testing. We empirically verify that <a href=https://en.wikipedia.org/wiki/Bloom&#8217;s_taxonomy>Bloom&#8217;s Taxonomy</a>, a standard tool for difficulty estimation during question creation, reliably predicts question difficulty observed after testing in a short-answer corpus. We also find that difficulty is mirrored in the amount of variation in student answers, which can be computed before <a href=https://en.wikipedia.org/wiki/Grading_in_education>grading</a>. We show that question difficulty and its approximations are useful for automated grading, allowing us to identify the optimal feature set for <a href=https://en.wikipedia.org/wiki/Grading_in_education>grading</a> each question even in an unseen-question setting.<i>automated grading</i>, allowing us to identify the optimal feature set for grading each question even in an unseen-question setting.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5002 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5002/>Combining CNNs and Pattern Matching for Question Interpretation in a Virtual Patient Dialogue System<span class=acl-fixed-case>CNN</span>s and Pattern Matching for Question Interpretation in a Virtual Patient Dialogue System</a></strong><br><a href=/people/l/lifeng-jin/>Lifeng Jin</a>
|
<a href=/people/m/michael-white/>Michael White</a>
|
<a href=/people/e/evan-jaffe/>Evan Jaffe</a>
|
<a href=/people/l/laura-zimmerman/>Laura Zimmerman</a>
|
<a href=/people/d/douglas-danforth/>Douglas Danforth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5002><div class="card-body p-3 small">For <a href=https://en.wikipedia.org/wiki/Medical_school>medical students</a>, virtual patient dialogue systems can provide useful training opportunities without the cost of employing actors to portray standardized patients. This work utilizes word- and character-based convolutional neural networks (CNNs) for question identification in a virtual patient dialogue system, outperforming a strong word- and character-based logistic regression baseline. While the CNNs perform well given sufficient training data, the best <a href=https://en.wikipedia.org/wiki/System>system</a> performance is ultimately achieved by combining CNNs with a hand-crafted pattern matching system that is robust to label sparsity, providing a 10 % boost in <a href=https://en.wikipedia.org/wiki/System>system accuracy</a> and an error reduction of 47 % as compared to the pattern-matching system alone.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5003 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5003/>Continuous fluency tracking and the challenges of varying text complexity</a></strong><br><a href=/people/b/beata-beigman-klebanov/>Beata Beigman Klebanov</a>
|
<a href=/people/a/anastassia-loukina/>Anastassia Loukina</a>
|
<a href=/people/j/john-sabatini/>John Sabatini</a>
|
<a href=/people/t/tenaha-oreilly/>Tenaha O’Reilly</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5003><div class="card-body p-3 small">This paper is a preliminary report on using text complexity measurement in the service of a new <a href=https://en.wikipedia.org/wiki/Educational_software>educational application</a>. We describe a reading intervention where a child takes turns reading a book aloud with a virtual reading partner. Our ultimate goal is to provide meaningful feedback to the parent or the teacher by continuously tracking the child&#8217;s improvement in <a href=https://en.wikipedia.org/wiki/Literacy>reading fluency</a>. We show that this would not be a simple endeavor, due to an intricate relationship between text complexity from the point of view of <a href=https://en.wikipedia.org/wiki/Sentence_processing>comprehension</a> and <a href=https://en.wikipedia.org/wiki/Reading_rate>reading rate</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5004.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5004 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5004/>Auxiliary Objectives for Neural Error Detection Models</a></strong><br><a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/h/helen-yannakoudakis/>Helen Yannakoudakis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5004><div class="card-body p-3 small">We investigate the utility of different auxiliary objectives and training strategies within a neural sequence labeling approach to <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error detection</a> in learner writing. Auxiliary costs provide the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> with additional linguistic information, allowing it to learn general-purpose compositional features that can then be exploited for other objectives. Our experiments show that a joint learning approach trained with parallel labels on in-domain data improves performance over the previous best <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error detection system</a>. While the resulting <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> has the same number of parameters, the additional objectives allow <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> to be optimised more efficiently and achieve better performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5005.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5005 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5005 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5005/>Linked Data for Language-Learning Applications</a></strong><br><a href=/people/r/robyn-loughnane/>Robyn Loughnane</a>
|
<a href=/people/k/kate-mccurdy/>Kate McCurdy</a>
|
<a href=/people/p/peter-kolb/>Peter Kolb</a>
|
<a href=/people/s/stefan-selent/>Stefan Selent</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5005><div class="card-body p-3 small">The use of <a href=https://en.wikipedia.org/wiki/Linked_data>linked data</a> within language-learning applications is an open research question. A research prototype is presented that applies linked-data principles to store linguistic annotation generated from language-learning content using a variety of NLP tools. The result is a <a href=https://en.wikipedia.org/wiki/Database>database</a> that links learning content, <a href=https://en.wikipedia.org/wiki/Annotation>linguistic annotation</a> and <a href=https://en.wikipedia.org/wiki/Open-source_software>open-source resources</a>, on top of which a diverse range of tools for language-learning applications can be built.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5006.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5006 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5006 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5006/>Predicting Specificity in Classroom Discussion</a></strong><br><a href=/people/l/luca-lugini/>Luca Lugini</a>
|
<a href=/people/d/diane-litman/>Diane Litman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5006><div class="card-body p-3 small">High quality classroom discussion is important to student development, enhancing abilities to express claims, reason about other students&#8217; claims, and retain information for longer periods of time. Previous small-scale studies have shown that one indicator of classroom discussion quality is <a href=https://en.wikipedia.org/wiki/Sensitivity_and_specificity>specificity</a>. In this paper we tackle the problem of predicting specificity for classroom discussions. We propose several <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> and feature sets capable of outperforming the state of the art in specificity prediction. Additionally, we provide a set of meaningful, interpretable features that can be used to analyze classroom discussions at a pedagogical level.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5007.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5007 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5007 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5007/>A Report on the 2017 Native Language Identification Shared Task</a></strong><br><a href=/people/s/shervin-malmasi/>Shervin Malmasi</a>
|
<a href=/people/k/keelan-evanini/>Keelan Evanini</a>
|
<a href=/people/a/aoife-cahill/>Aoife Cahill</a>
|
<a href=/people/j/joel-tetreault/>Joel Tetreault</a>
|
<a href=/people/r/robert-pugh/>Robert Pugh</a>
|
<a href=/people/c/christopher-hamill/>Christopher Hamill</a>
|
<a href=/people/d/diane-napolitano/>Diane Napolitano</a>
|
<a href=/people/y/yao-qian/>Yao Qian</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5007><div class="card-body p-3 small">Native Language Identification (NLI) is the task of automatically identifying the native language (L1) of an individual based on their language production in a learned language. It is typically framed as a classification task where the set of <a href=https://en.wikipedia.org/wiki/L1_(protein)>L1s</a> is known a priori. Two previous shared tasks on NLI have been organized where the aim was to identify the L1 of learners of <a href=https://en.wikipedia.org/wiki/English_language>English</a> based on essays (2013) and spoken responses (2016) they provided during a standardized assessment of academic English proficiency. The 2017 shared task combines the inputs from the two prior tasks for the first time. There are three tracks : <a href=https://en.wikipedia.org/wiki/Natural_language_understanding>NLI</a> on the essay only, <a href=https://en.wikipedia.org/wiki/Natural_language_understanding>NLI</a> on the spoken response only (based on a transcription of the response and i-vector acoustic features), and <a href=https://en.wikipedia.org/wiki/Natural_language_understanding>NLI</a> using both responses. We believe this makes for a more interesting <a href=https://en.wikipedia.org/wiki/Task_(computing)>shared task</a> while building on the methods and results from the previous two <a href=https://en.wikipedia.org/wiki/Task_(computing)>shared tasks</a>. In this paper, we report the results of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>shared task</a>. A total of 19 teams competed across the three different sub-tasks. The fusion track showed that combining the written and spoken responses provides a large boost in <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>prediction accuracy</a>. Multiple classifier systems (e.g. ensembles and meta-classifiers) were the most effective in all tasks, with most based on traditional <a href=https://en.wikipedia.org/wiki/Classifier_(linguistics)>classifiers</a> (e.g. SVMs) with lexical / syntactic features.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5008.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5008 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5008 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5008/>Evaluation of Automatically Generated Pronoun Reference Questions</a></strong><br><a href=/people/a/arief-yudha-satria/>Arief Yudha Satria</a>
|
<a href=/people/t/takenobu-tokunaga/>Takenobu Tokunaga</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5008><div class="card-body p-3 small">This study provides a detailed analysis of evaluation of English pronoun reference questions which are created automatically by machine. Pronoun reference questions are multiple choice questions that ask test takers to choose an antecedent of a target pronoun in a reading passage from four options. The <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation</a> was performed from two perspectives : the perspective of English teachers and that of English learners. Item analysis suggests that machine-generated questions achieve comparable quality with <a href=https://en.wikipedia.org/wiki/Questionnaire>human-made questions</a>. Correlation analysis revealed a strong correlation between the scores of machine-generated questions and that of human-made questions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5010.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5010 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5010 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5010/>Collecting fluency corrections for spoken learner English<span class=acl-fixed-case>E</span>nglish</a></strong><br><a href=/people/a/andrew-caines/>Andrew Caines</a>
|
<a href=/people/e/emma-flint/>Emma Flint</a>
|
<a href=/people/p/paula-buttery/>Paula Buttery</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5010><div class="card-body p-3 small">We present crowdsourced collection of <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error annotations</a> for <a href=https://en.wikipedia.org/wiki/Transcription_(linguistics)>transcriptions</a> of spoken learner English. Our emphasis in <a href=https://en.wikipedia.org/wiki/Data_collection>data collection</a> is on fluency corrections, a more complete correction than has traditionally been aimed for in grammatical error correction research (GEC). Fluency corrections require improvements to the text, taking discourse and utterance level semantics into account : the result is a more naturalistic, holistic version of the original. We propose that this shifted emphasis be reflected in a new name for the task : &#8216;holistic error correction&#8217; (HEC). We analyse crowdworker behaviour in <a href=https://en.wikipedia.org/wiki/Higher_Education_Commission_(Pakistan)>HEC</a> and conclude that the method is useful with certain amendments for future work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5012 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5012/>An Investigation into the Pedagogical Features of Documents</a></strong><br><a href=/people/e/emily-sheng/>Emily Sheng</a>
|
<a href=/people/p/prem-natarajan/>Prem Natarajan</a>
|
<a href=/people/j/jonathan-gordon/>Jonathan Gordon</a>
|
<a href=/people/g/gully-burns/>Gully Burns</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5012><div class="card-body p-3 small">Characterizing the content of a technical document in terms of its learning utility can be useful for applications related to <a href=https://en.wikipedia.org/wiki/Education>education</a>, such as generating reading lists from large collections of documents. We refer to this learning utility as the pedagogical value of the document to the learner. While pedagogical value is an important concept that has been studied extensively within the education domain, there has been little work exploring it from a computational, i.e., natural language processing (NLP), perspective. To allow a computational exploration of this concept, we introduce the notion of pedagogical roles of documents (e.g., <a href=https://en.wikipedia.org/wiki/Tutorial>Tutorial</a> and Survey) as an intermediary component for the study of pedagogical value. Given the lack of available corpora for our exploration, we create the first annotated corpus of pedagogical roles and use it to test baseline techniques for automatic prediction of such <a href=https://en.wikipedia.org/wiki/Role>roles</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5013.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5013 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5013 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5013/>Combining Multiple Corpora for Readability Assessment for People with Cognitive Disabilities</a></strong><br><a href=/people/v/victoria-yaneva/>Victoria Yaneva</a>
|
<a href=/people/c/constantin-orasan/>Constantin Orăsan</a>
|
<a href=/people/r/richard-evans/>Richard Evans</a>
|
<a href=/people/o/omid-rohanian/>Omid Rohanian</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5013><div class="card-body p-3 small">Given the lack of large user-evaluated corpora in disability-related NLP research (e.g. text simplification or readability assessment for people with cognitive disabilities), the question of choosing suitable training data for NLP models is not straightforward. The use of large generic corpora may be problematic because such <a href=https://en.wikipedia.org/wiki/Data>data</a> may not reflect the needs of the target population. The use of the available user-evaluated corpora may be problematic because these <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> are not large enough to be used as training data. In this paper we explore a third approach, in which a large generic corpus is combined with a smaller population-specific corpus to train a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> which is evaluated using two sets of unseen user-evaluated data. One of these <a href=https://en.wikipedia.org/wiki/Set_(mathematics)>sets</a>, the ASD Comprehension corpus, is developed for the purposes of this study and made freely available. We explore the effects of the size and type of the training data used on the performance of the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a>, and the effects of the type of the unseen test datasets on the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5014.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5014 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W17-5014.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W17-5014/>Automatic Extraction of High-Quality Example Sentences for Word Learning Using a <a href=https://en.wikipedia.org/wiki/Determinantal_point_process>Determinantal Point Process</a></a></strong><br><a href=/people/a/arseny-tolmachev/>Arseny Tolmachev</a>
|
<a href=/people/s/sadao-kurohashi/>Sadao Kurohashi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5014><div class="card-body p-3 small">Flashcard systems are effective tools for learning words but have their limitations in teaching word usage. To overcome this problem, we propose a novel flashcard system that shows a new example sentence on each repetition. This <a href=https://en.wikipedia.org/wiki/Extension_(semantics)>extension</a> requires high-quality example sentences, automatically extracted from a huge corpus. To do this, we use a <a href=https://en.wikipedia.org/wiki/Determinantal_point_process>Determinantal Point Process</a> which scales well to large data and allows to naturally represent sentence similarity and quality as <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a>. Our human evaluation experiment on <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese language</a> indicates that the proposed method successfully extracted high-quality example sentences.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5016.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5016 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5016 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5016/>An Error-Oriented Approach to Word Embedding Pre-Training</a></strong><br><a href=/people/y/youmna-farag/>Youmna Farag</a>
|
<a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/t/ted-briscoe/>Ted Briscoe</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5016><div class="card-body p-3 small">We propose a novel word embedding pre-training approach that exploits writing errors in learners&#8217; scripts. We compare our method to previous models that tune the embeddings based on script scores and the discrimination between correct and corrupt word contexts in addition to the generic commonly-used embeddings pre-trained on large corpora. The comparison is achieved by using the aforementioned models to bootstrap a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> that learns to predict a holistic score for <a href=https://en.wikipedia.org/wiki/Scripting_language>scripts</a>. Furthermore, we investigate augmenting our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> with <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error corrections</a> and monitor the impact on performance. Our results show that our error-oriented approach outperforms other comparable ones which is further demonstrated when training on more data. Additionally, extending the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> with corrections provides further performance gains when data sparsity is an issue.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5017.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5017 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5017 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5017/>Investigating neural architectures for short answer scoring</a></strong><br><a href=/people/b/brian-riordan/>Brian Riordan</a>
|
<a href=/people/a/andrea-horbach/>Andrea Horbach</a>
|
<a href=/people/a/aoife-cahill/>Aoife Cahill</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a>
|
<a href=/people/c/chungmin-lee/>Chong Min Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5017><div class="card-body p-3 small">Neural approaches to <a href=https://en.wikipedia.org/wiki/Automated_essay_scoring>automated essay scoring</a> have recently shown state-of-the-art performance. The automated essay scoring task typically involves a broad notion of writing quality that encompasses <a href=https://en.wikipedia.org/wiki/Content_(media)>content</a>, <a href=https://en.wikipedia.org/wiki/Grammar>grammar</a>, <a href=https://en.wikipedia.org/wiki/Organization>organization</a>, and <a href=https://en.wikipedia.org/wiki/Convention_(norm)>conventions</a>. This differs from the short answer content scoring task, which focuses on content accuracy. The inputs to neural essay scoring models ngrams and embeddings are arguably well-suited to evaluate content in short answer scoring tasks. We investigate how several basic neural approaches similar to those used for automated essay scoring perform on short answer scoring. We show that neural architectures can outperform a strong non-neural baseline, but performance and optimal parameter settings vary across the more diverse types of prompts typical of short answer scoring.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5018.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5018 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5018 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5018/>Human and Automated CEFR-based Grading of Short Answers<span class=acl-fixed-case>CEFR</span>-based Grading of Short Answers</a></strong><br><a href=/people/a/anais-tack/>Anaïs Tack</a>
|
<a href=/people/t/thomas-francois/>Thomas François</a>
|
<a href=/people/s/sophie-roekhaut/>Sophie Roekhaut</a>
|
<a href=/people/c/cedrick-fairon/>Cédrick Fairon</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5018><div class="card-body p-3 small">This paper is concerned with the task of automatically assessing the written proficiency level of non-native (L2) learners of <a href=https://en.wikipedia.org/wiki/English_language>English</a>. Drawing on previous research on automated L2 writing assessment following the Common European Framework of Reference for Languages (CEFR), we investigate the possibilities and difficulties of deriving the CEFR level from short answers to open-ended questions, which has not yet been subjected to numerous studies up to date. The object of our study is twofold : to examine the intricacy involved with both human and automated CEFR-based grading of short answers. On the one hand, we describe the compilation of a learner corpus of short answers graded with CEFR levels by three certified Cambridge examiners. We mainly observe that, although the shortness of the answers is reported as undermining a clear-cut evaluation, the length of the answer does not necessarily correlate with inter-examiner disagreement. On the other hand, we explore the development of a soft-voting system for the automated CEFR-based grading of short answers and draw tentative conclusions about its use in a computer-assisted testing (CAT) setting.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5019.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5019 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5019 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5019/>GEC into the future : Where are we going and how do we get there?<span class=acl-fixed-case>GEC</span> into the future: Where are we going and how do we get there?</a></strong><br><a href=/people/k/keisuke-sakaguchi/>Keisuke Sakaguchi</a>
|
<a href=/people/c/courtney-napoles/>Courtney Napoles</a>
|
<a href=/people/j/joel-tetreault/>Joel Tetreault</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5019><div class="card-body p-3 small">The field of grammatical error correction (GEC) has made tremendous bounds in the last ten years, but new questions and obstacles are revealing themselves. In this position paper, we discuss the issues that need to be addressed and provide recommendations for the field to continue to make progress, and propose a new shared task. We invite suggestions and critiques from the audience to make the new shared task a community-driven venture.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5020.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5020 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5020 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5020/>Detecting Off-topic Responses to Visual Prompts</a></strong><br><a href=/people/m/marek-rei/>Marek Rei</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5020><div class="card-body p-3 small">Automated methods for essay scoring have made great progress in recent years, achieving accuracies very close to human annotators. However, a known weakness of such automated scorers is not taking into account the semantic relevance of the submitted text. While there is existing work on detecting answer relevance given a textual prompt, very little previous research has been done to incorporate visual writing prompts. We propose a neural architecture and several extensions for detecting off-topic responses to visual prompts and evaluate it on a dataset of texts written by <a href=https://en.wikipedia.org/wiki/Language_acquisition>language learners</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5021.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5021 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5021 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5021/>Combining Textual and Speech Features in the NLI Task Using State-of-the-Art Machine Learning Techniques<span class=acl-fixed-case>NLI</span> Task Using State-of-the-Art Machine Learning Techniques</a></strong><br><a href=/people/p/pavel-ircing/>Pavel Ircing</a>
|
<a href=/people/j/jan-svec/>Jan Švec</a>
|
<a href=/people/z/zbynek-zajic/>Zbyněk Zajíc</a>
|
<a href=/people/b/barbora-hladka/>Barbora Hladká</a>
|
<a href=/people/m/martin-holub/>Martin Holub</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5021><div class="card-body p-3 small">We summarize the involvement of our CEMI team in the NLI Shared Task 2017, which deals with both textual and speech input data. We submitted the results achieved by using three different system architectures ; each of them combines multiple <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised learning models</a> trained on various <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature sets</a>. As expected, better results are achieved with the <a href=https://en.wikipedia.org/wiki/System>systems</a> that use both the <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>textual data</a> and the <a href=https://en.wikipedia.org/wiki/Speech>spoken responses</a>. Combining the input data of two different modalities led to a rather dramatic improvement in <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> performance. Our best performing method is based on a set of feed-forward neural networks whose hidden-layer outputs are combined together using a softmax layer. We achieved a macro-averaged F1 score of 0.9257 on the evaluation (unseen) test set and our team placed first in the main task together with other three teams.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5022.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5022 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5022 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W17-5022.Attachment.pdf data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W17-5022/>Native Language Identification Using a Mixture of Character and Word N-grams</a></strong><br><a href=/people/e/elham-mohammadi/>Elham Mohammadi</a>
|
<a href=/people/h/hadi-veisi/>Hadi Veisi</a>
|
<a href=/people/h/hessam-amini/>Hessam Amini</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5022><div class="card-body p-3 small">Native language identification (NLI) is the task of determining an author&#8217;s native language, based on a piece of his / her writing in a second language. In recent years, NLI has received much attention due to its challenging nature and its applications in <a href=https://en.wikipedia.org/wiki/Language_pedagogy>language pedagogy</a> and <a href=https://en.wikipedia.org/wiki/Forensic_linguistics>forensic linguistics</a>. We participated in the NLI2017 shared task under the name UT-DSP. In our effort to implement a method for <a href=https://en.wikipedia.org/wiki/Native-language_identification>native language identification</a>, we made use of a fusion of character and word N-grams, and achieved an optimal <a href=https://en.wikipedia.org/wiki/F-number>F1-Score</a> of 77.64 %, using both essay and speech transcription datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5024 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5024/>Can string kernels pass the test of time in Native Language Identification?</a></strong><br><a href=/people/r/radu-tudor-ionescu/>Radu Tudor Ionescu</a>
|
<a href=/people/m/marius-popescu/>Marius Popescu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5024><div class="card-body p-3 small">We describe a machine learning approach for the 2017 shared task on Native Language Identification (NLI). The proposed approach combines several <a href=https://en.wikipedia.org/wiki/Kernel_(operating_system)>kernels</a> using <a href=https://en.wikipedia.org/wiki/Multiple_kernel_learning>multiple kernel learning</a>. While most of our kernels are based on character p-grams (also known as n-grams) extracted from essays or speech transcripts, we also use a kernel based on i-vectors, a low-dimensional representation of audio recordings, provided by the shared task organizers. For the learning stage, we choose Kernel Discriminant Analysis (KDA) over Kernel Ridge Regression (KRR), because the former <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> obtains better results than the latter one on the development set. In our previous work, we have used a similar machine learning approach to achieve state-of-the-art NLI results. The goal of this paper is to demonstrate that our shallow and simple approach based on string kernels (with minor improvements) can pass the test of time and reach state-of-the-art performance in the 2017 NLI shared task, despite the recent advances in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. We participated in all three tracks, in which the competitors were allowed to use only the essays (essay track), only the speech transcripts (speech track), or both (fusion track). Using only the data provided by the organizers for training our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>, we have reached a macro F1 score of 86.95 % in the closed essay track, a macro F1 score of 87.55 % in the closed speech track, and a macro F1 score of 93.19 % in the closed fusion track.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5025.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5025 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5025 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5025/>Neural Networks and Spelling Features for Native Language Identification</a></strong><br><a href=/people/j/johannes-bjerva/>Johannes Bjerva</a>
|
<a href=/people/g/gintare-grigonyte/>Gintarė Grigonytė</a>
|
<a href=/people/r/robert-ostling/>Robert Östling</a>
|
<a href=/people/b/barbara-plank/>Barbara Plank</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5025><div class="card-body p-3 small">We present the RUG-SU team&#8217;s submission at the Native Language Identification Shared Task 2017. We combine several approaches into an ensemble, based on spelling error features, a simple <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> using word representations, a deep residual network using word and character features, and a system based on a <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network</a>. Our best <a href=https://en.wikipedia.org/wiki/System>system</a> is an ensemble of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>, reaching an F1 score of 0.8323. Although our <a href=https://en.wikipedia.org/wiki/System>system</a> is not the highest ranking one, we do outperform the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> by far.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5026.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5026 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5026 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-5026" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-5026/>A study of N-gram and Embedding Representations for Native Language Identification</a></strong><br><a href=/people/s/sowmya-vajjala/>Sowmya Vajjala</a>
|
<a href=/people/s/sagnik-banerjee/>Sagnik Banerjee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5026><div class="card-body p-3 small">We report on our experiments with N-gram and embedding based feature representations for Native Language Identification (NLI) as a part of the NLI Shared Task 2017 (team name : NLI-ISU). Our best performing system on the test set for written essays had a macro F1 of 0.8264 and was based on word uni, bi and trigram features. We explored <a href=https://en.wikipedia.org/wiki/N-gram>n-grams</a> covering word, character, POS and word-POS mixed representations for this task. For embedding based feature representations, we employed both word and document embeddings. We had a relatively poor performance with all embedding representations compared to n-grams, which could be because of the fact that embeddings capture semantic similarities whereas L1 differences are more stylistic in nature.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5029.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5029 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5029 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5029/>Structured Generation of Technical Reading Lists</a></strong><br><a href=/people/j/jonathan-gordon/>Jonathan Gordon</a>
|
<a href=/people/s/stephen-aguilar/>Stephen Aguilar</a>
|
<a href=/people/e/emily-sheng/>Emily Sheng</a>
|
<a href=/people/g/gully-burns/>Gully Burns</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5029><div class="card-body p-3 small">Learners need to find suitable documents to read and prioritize them in an appropriate order. We present a method of automatically generating reading lists, selecting documents based on their pedagogical value to the learner and ordering them using the structure of concepts in the domain. Resulting reading lists related to <a href=https://en.wikipedia.org/wiki/Computational_linguistics>computational linguistics</a> were evaluated by advanced learners and judged to be near the quality of those generated by domain experts. We provide an open-source implementation of our <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> to enable future work on reading list generation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5030.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5030 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5030 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5030/>Effects of Lexical Properties on Viewing Time per Word in Autistic and Neurotypical Readers</a></strong><br><a href=/people/s/sanja-stajner/>Sanja Štajner</a>
|
<a href=/people/v/victoria-yaneva/>Victoria Yaneva</a>
|
<a href=/people/r/ruslan-mitkov/>Ruslan Mitkov</a>
|
<a href=/people/s/simone-paolo-ponzetto/>Simone Paolo Ponzetto</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5030><div class="card-body p-3 small">Eye tracking studies from the past few decades have shaped the way we think of word complexity and <a href=https://en.wikipedia.org/wiki/Cognitive_load>cognitive load</a> : words that are long, rare and ambiguous are more difficult to read. However, online processing techniques have been scarcely applied to investigating the reading difficulties of people with autism and what vocabulary is challenging for them. We present parallel gaze data obtained from adult readers with autism and a control group of neurotypical readers and show that the former required higher cognitive effort to comprehend the texts as evidenced by three gaze-based measures. We divide all words into four classes based on their viewing times for both groups and investigate the relationship between longer viewing times and word length, word frequency, and four cognitively-based measures (word concreteness, familiarity, age of acquisition and imagability).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5031.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5031 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5031 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5031/>Transparent text quality assessment with <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>convolutional neural networks</a></a></strong><br><a href=/people/r/robert-ostling/>Robert Östling</a>
|
<a href=/people/g/gintare-grigonyte/>Gintare Grigonyte</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5031><div class="card-body p-3 small">We present a very simple model for text quality assessment based on a <a href=https://en.wikipedia.org/wiki/Deep_convolutional_neural_network>deep convolutional neural network</a>, where the only supervision required is one corpus of user-generated text of varying quality, and one contrasting text corpus of consistently high quality. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is able to provide local quality assessments in different parts of a text, which allows visual feedback about where potentially problematic parts of the text are located, as well as a way to evaluate which textual features are captured by our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. We evaluate our method on two corpora : a large corpus of manually graded student essays and a longitudinal corpus of language learner written production, and find that the text quality metric learned by our model is a fairly strong predictor of both essay grade and learner proficiency level.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5032.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5032 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5032 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5032/>Artificial Error Generation with Machine Translation and Syntactic Patterns</a></strong><br><a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/m/mariano-felice/>Mariano Felice</a>
|
<a href=/people/z/zheng-yuan/>Zheng Yuan</a>
|
<a href=/people/t/ted-briscoe/>Ted Briscoe</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5032><div class="card-body p-3 small">Shortage of available training data is holding back progress in the area of automated error detection. This paper investigates two alternative methods for artificially generating writing errors, in order to create additional resources. We propose treating error generation as a machine translation task, where grammatically correct text is translated to contain errors. In addition, we explore a system for extracting textual patterns from an annotated corpus, which can then be used to insert <a href=https://en.wikipedia.org/wiki/Error_(linguistics)>errors</a> into grammatically correct sentences. Our experiments show that the inclusion of <a href=https://en.wikipedia.org/wiki/Errors-in-variables_models>artificially generated errors</a> significantly improves <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error detection accuracy</a> on both FCE and CoNLL 2014 datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5033.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5033 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5033 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5033/>Modelling semantic acquisition in second language learning</a></strong><br><a href=/people/e/ekaterina-kochmar/>Ekaterina Kochmar</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5033><div class="card-body p-3 small">Using methods of <a href=https://en.wikipedia.org/wiki/Statistical_inference>statistical analysis</a>, we investigate how semantic knowledge is acquired in <a href=https://en.wikipedia.org/wiki/English_language>English</a> as a second language and evaluate the pace of development across a number of predicate types and content word combinations, as well as across the levels of language proficiency and native languages. Our exploratory study helps identify the most problematic areas for <a href=https://en.wikipedia.org/wiki/Language_acquisition>language learners</a> with different backgrounds and at different stages of learning.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5034.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5034 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5034 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W17-5034.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W17-5034/>Multiple Choice Question Generation Utilizing An Ontology</a></strong><br><a href=/people/k/katherine-stasaski/>Katherine Stasaski</a>
|
<a href=/people/m/marti-a-hearst/>Marti A. Hearst</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5034><div class="card-body p-3 small">Ontologies provide a structured representation of concepts and the relationships which connect them. This work investigates how a pre-existing educational Biology ontology can be used to generate useful practice questions for students by using the connectivity structure in a novel way. It also introduces a novel way to generate multiple-choice distractors from the <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontology</a>, and compares this to a baseline of using embedding representations of nodes. An assessment by an experienced science teacher shows a significant advantage over a baseline when using the <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontology</a> for distractor generation. A subsequent study with three science teachers on the results of a modified question generation algorithm finds significant improvements. An in-depth analysis of the teachers&#8217; comments yields useful insights for any researcher working on automated question generation for <a href=https://en.wikipedia.org/wiki/Educational_technology>educational applications</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5035.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5035 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5035 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5035/>Simplifying metaphorical language for young readers : A corpus study on news text</a></strong><br><a href=/people/m/magdalena-wolska/>Magdalena Wolska</a>
|
<a href=/people/y/yulia-clausen/>Yulia Clausen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5035><div class="card-body p-3 small">The paper presents first results of an ongoing project on <a href=https://en.wikipedia.org/wiki/Text_simplification>text simplification</a> focusing on <a href=https://en.wikipedia.org/wiki/Metaphor>linguistic metaphors</a>. Based on an analysis of a parallel corpus of news text professionally simplified for different grade levels, we identify six types of simplification choices falling into two broad categories : preserving metaphors or dropping them. An annotation study on almost 300 source sentences with <a href=https://en.wikipedia.org/wiki/Metaphor>metaphors</a> (grade level 12) and their simplified counterparts (grade 4) is conducted. The results show that most <a href=https://en.wikipedia.org/wiki/Metaphor>metaphors</a> are preserved and when they are dropped, the semantic content tends to be preserved rather than dropped, however, it is reworded without metaphorical language. In general, some of the expected tendencies in <a href=https://en.wikipedia.org/wiki/Complexity_reduction>complexity reduction</a>, measured with psycholinguistic variables linked to metaphor comprehension, are observed, suggesting good prospect for machine learning-based metaphor simplification.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5037.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5037 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5037 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5037/>Connecting the Dots : Towards Human-Level Grammatical Error Correction</a></strong><br><a href=/people/s/shamil-chollampatt/>Shamil Chollampatt</a>
|
<a href=/people/h/hwee-tou-ng/>Hwee Tou Ng</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5037><div class="card-body p-3 small">We build a grammatical error correction (GEC) system primarily based on the state-of-the-art statistical machine translation (SMT) approach, using task-specific features and tuning, and further enhance it with the modeling power of neural network joint models. The SMT-based system is weak in generalizing beyond patterns seen during training and lacks granularity below the word level. To address this issue, we incorporate a character-level SMT component targeting the misspelled words that the original SMT-based system fails to correct. Our final <a href=https://en.wikipedia.org/wiki/System>system</a> achieves 53.14 % F 0.5 score on the benchmark CoNLL-2014 test set, an improvement of 3.62 % F 0.5 over the best previous published score.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5038.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5038 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5038 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5038/>Question Generation for <a href=https://en.wikipedia.org/wiki/Language_acquisition>Language Learning</a> : From ensuring texts are read to supporting learning</a></strong><br><a href=/people/m/maria-chinkina/>Maria Chinkina</a>
|
<a href=/people/d/detmar-meurers/>Detmar Meurers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5038><div class="card-body p-3 small">In Foreign Language Teaching and Learning (FLTL), questions are systematically used to assess the learner&#8217;s understanding of a text. Computational linguistic approaches have been developed to generate such <a href=https://en.wikipedia.org/wiki/Question>questions</a> automatically given a text (e.g., Heilman, 2011). In this paper, we want to broaden the perspective on the different functions questions can play in FLTL and discuss how automatic question generation can support the different uses. Complementing the focus on meaning and comprehension, we want to highlight the fact that questions can also be used to make learners notice form aspects of the <a href=https://en.wikipedia.org/wiki/Linguistic_system>linguistic system</a> and their interpretation. Automatically generating questions that target linguistic forms and grammatical categories in a text in essence supports incidental focus-on-form (Loewen, 2005) in a meaning-focused reading task. We discuss two types of questions serving this purpose, how they can be generated automatically ; and we report on a crowd-sourcing evaluation comparing automatically generated to manually written questions targeting particle verbs, a challenging linguistic form for learners of <a href=https://en.wikipedia.org/wiki/English_language>English</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5039.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5039 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5039 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-5039" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-5039/>Systematically Adapting <a href=https://en.wikipedia.org/wiki/Machine_translation>Machine Translation</a> for Grammatical Error Correction</a></strong><br><a href=/people/c/courtney-napoles/>Courtney Napoles</a>
|
<a href=/people/c/chris-callison-burch/>Chris Callison-Burch</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5039><div class="card-body p-3 small">n this work we adapt machine translation (MT) to grammatical error correction, identifying how components of the statistical MT pipeline can be modified for this task and analyzing how each modification impacts system performance. We evaluate the contribution of each of these components with standard evaluation metrics and automatically characterize the morphological and lexical transformations made in system output. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> rivals the current state of the art using a fraction of the training data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5040.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5040 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5040 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5040/>Fine-grained essay scoring of a complex writing task for native speakers</a></strong><br><a href=/people/a/andrea-horbach/>Andrea Horbach</a>
|
<a href=/people/d/dirk-scholten-akoun/>Dirk Scholten-Akoun</a>
|
<a href=/people/y/yuning-ding/>Yuning Ding</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5040><div class="card-body p-3 small">Automatic essay scoring is nowadays successfully used even in high-stakes tests, but this is mainly limited to holistic scoring of learner essays. We present a new dataset of <a href=https://en.wikipedia.org/wiki/Essay>essays</a> written by highly proficient German native speakers that is scored using a fine-grained rubric with the goal to provide detailed feedback. Our experiments with two state-of-the-art scoring systems (a neural and a SVM-based one) show a large drop in performance compared to existing datasets. This demonstrates the need for such <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> that allow to guide research on more elaborate essay scoring methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5042.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5042 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5042 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5042/>CIC-FBK Approach to Native Language Identification<span class=acl-fixed-case>CIC</span>-<span class=acl-fixed-case>FBK</span> Approach to Native Language Identification</a></strong><br><a href=/people/i/ilia-markov/>Ilia Markov</a>
|
<a href=/people/l/lingzhen-chen/>Lingzhen Chen</a>
|
<a href=/people/c/carlo-strapparava/>Carlo Strapparava</a>
|
<a href=/people/g/grigori-sidorov/>Grigori Sidorov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5042><div class="card-body p-3 small">We present the CIC-FBK system, which took part in the Native Language Identification (NLI) Shared Task 2017. Our approach combines <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> commonly used in previous NLI research, i.e., word n-grams, lemma n-grams, part-of-speech n-grams, and function words, with recently introduced character n-grams from misspelled words, and <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> that are novel in this task, such as typed character n-grams, and syntactic n-grams of words and of syntactic relation tags. We use log-entropy weighting scheme and perform <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> using the Support Vector Machines (SVM) algorithm. Our <a href=https://en.wikipedia.org/wiki/System>system</a> achieved 0.8808 macro-averaged F1-score and shared the 1st rank in the NLI Shared Task 2017 scoring.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5043.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5043 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5043 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5043/>The Power of Character N-grams in Native Language Identification</a></strong><br><a href=/people/a/artur-kulmizev/>Artur Kulmizev</a>
|
<a href=/people/b/bo-blankers/>Bo Blankers</a>
|
<a href=/people/j/johannes-bjerva/>Johannes Bjerva</a>
|
<a href=/people/m/malvina-nissim/>Malvina Nissim</a>
|
<a href=/people/g/gertjan-van-noord/>Gertjan van Noord</a>
|
<a href=/people/b/barbara-plank/>Barbara Plank</a>
|
<a href=/people/m/martijn-wieling/>Martijn Wieling</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5043><div class="card-body p-3 small">In this paper, we explore the performance of a linear SVM trained on language independent character features for the NLI Shared Task 2017. Our basic <a href=https://en.wikipedia.org/wiki/System>system</a> (GRONINGEN) achieves the best performance (87.56 F1-score) on the evaluation set using only 1-9 character n-grams as <a href=https://en.wikipedia.org/wiki/Feature_(computer_vision)>features</a>. We compare this against several ensemble and meta-classifiers in order to examine how the <a href=https://en.wikipedia.org/wiki/Linear_system>linear system</a> fares when combined with other, especially non-linear classifiers. Special emphasis is placed on the topic bias that exists by virtue of the assessment essay prompt distribution.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5044.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5044 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5044 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5044/>Classifier Stacking for Native Language Identification</a></strong><br><a href=/people/w/wen-li/>Wen Li</a>
|
<a href=/people/l/liang-zou/>Liang Zou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5044><div class="card-body p-3 small">This paper reports our contribution (team WLZ) to the NLI Shared Task 2017 (essay track). We first extract lexical and syntactic features from the essays, perform feature weighting and selection, and train linear support vector machine (SVM) classifiers each on an individual feature type. The output of base classifiers, as probabilities for each class, are then fed into a <a href=https://en.wikipedia.org/wiki/Multilayer_perceptron>multilayer perceptron</a> to predict the native language of the author. We also report the performance of each feature type, as well as the best <a href=https://en.wikipedia.org/wiki/Software_feature>features</a> of a type. Our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 86.55 %, which is among the best performing <a href=https://en.wikipedia.org/wiki/System>systems</a> of this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>shared task</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5045.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5045 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5045 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5045/>Native Language Identification on Text and Speech</a></strong><br><a href=/people/m/marcos-zampieri/>Marcos Zampieri</a>
|
<a href=/people/a/alina-maria-ciobanu/>Alina Maria Ciobanu</a>
|
<a href=/people/l/liviu-p-dinu/>Liviu P. Dinu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5045><div class="card-body p-3 small">This paper presents an <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensemble system</a> combining the output of multiple SVM classifiers to native language identification (NLI). The system was submitted to the NLI Shared Task 2017 fusion track which featured students essays and spoken responses in form of <a href=https://en.wikipedia.org/wiki/Transcription_(linguistics)>audio transcriptions</a> and iVectors by non-native English speakers of eleven native languages. Our system competed in the challenge under the team name ZCD and was based on an ensemble of SVM classifiers trained on <a href=https://en.wikipedia.org/wiki/Character_(computing)>character n-grams</a> achieving 83.58 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and ranking 3rd in the shared task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5047.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5047 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5047 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5047/>A deep-learning based native-language classification by using a <a href=https://en.wikipedia.org/wiki/Latent_semantic_analysis>latent semantic analysis</a> for the NLI Shared Task 2017<span class=acl-fixed-case>NLI</span> Shared Task 2017</a></strong><br><a href=/people/y/yoo-rhee-oh/>Yoo Rhee Oh</a>
|
<a href=/people/h/hyung-bae-jeon/>Hyung-Bae Jeon</a>
|
<a href=/people/h/hwa-jeon-song/>Hwa Jeon Song</a>
|
<a href=/people/y/yun-kyung-lee/>Yun-Kyung Lee</a>
|
<a href=/people/j/jeon-gue-park/>Jeon-Gue Park</a>
|
<a href=/people/y/yun-keun-lee/>Yun-Keun Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5047><div class="card-body p-3 small">This paper proposes a deep-learning based native-language identification (NLI) using a latent semantic analysis (LSA) as a participant (ETRI-SLP) of the NLI Shared Task 2017 where the NLI Shared Task 2017 aims to detect the native language of an essay or speech response of a standardized assessment of English proficiency for academic purposes. To this end, we use the six unit forms of a text data such as character 4/5/6-grams and word 1/2/3-grams. For each unit form of text data, we convert it into a count-based vector, extract a 2000-rank LSA feature, and perform a linear discriminant analysis (LDA) based dimension reduction. From the count-based vector or the LSA-LDA feature, we also obtain the output prediction values of a support vector machine (SVM) based classifier, the output prediction values of a deep neural network (DNN) based classifier, and the bottleneck values of a DNN based classifier. In order to incorporate the various kinds of text-based features and a speech-based i-vector feature, we design two DNN based ensemble classifiers for late fusion and early fusion, respectively. From the NLI experiments, the F1 (macro) scores are obtained as 0.8601, 0.8664, and 0.9220 for the essay track, the speech track, and the fusion track, respectively. The proposed method has comparable performance to the top-ranked teams for the speech and fusion tracks, although it has slightly lower performance for the essay track.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5048.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5048 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5048 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5048/>Fusion of Simple Models for Native Language Identification</a></strong><br><a href=/people/f/fabio-kepler/>Fabio Kepler</a>
|
<a href=/people/r/ramon-fernandez-astudillo/>Ramon F. Astudillo</a>
|
<a href=/people/a/alberto-abad/>Alberto Abad</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5048><div class="card-body p-3 small">In this paper we describe the approaches we explored for the 2017 Native Language Identification shared task. We focused on simple word and sub-word units avoiding heavy use of hand-crafted features. Following recent trends, we explored linear and neural networks models to attempt to compensate for the lack of rich feature use. Initial efforts yielded <a href=https://en.wikipedia.org/wiki/F-number>f1-scores</a> of 82.39 % and 83.77 % in the development and test sets of the <a href=https://en.wikipedia.org/wiki/Fusion_power>fusion track</a>, and were officially submitted to the task as team L2F. After the task was closed, we carried on further experiments and relied on a late fusion strategy for combining our simple proposed approaches with modifications of the baselines provided by the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. As expected, the i-vectors based sub-system dominates the performance of the system combinations, and results in the major contributor to our achieved scores. Our best combined <a href=https://en.wikipedia.org/wiki/System>system</a> achieves 90.1 % and 90.2 % <a href=https://en.wikipedia.org/wiki/F-number>f1-score</a> in the development and test sets of the <a href=https://en.wikipedia.org/wiki/Fusion_energy>fusion track</a>, respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5050.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5050 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5050 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5050/>Using Gaze to Predict Text Readability</a></strong><br><a href=/people/a/ana-valeria-gonzalez-garduno/>Ana Valeria González-Garduño</a>
|
<a href=/people/a/anders-sogaard/>Anders Søgaard</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5050><div class="card-body p-3 small">We show that text readability prediction improves significantly from hard parameter sharing with models predicting first pass duration, total fixation duration and regression duration. Specifically, we induce multi-task Multilayer Perceptrons and Logistic Regression models over sentence representations that capture various <a href=https://en.wikipedia.org/wiki/Aggregate_statistics>aggregate statistics</a>, from two different text readability corpora for English, as well as the Dundee eye-tracking corpus. Our approach leads to significant improvements over Single task learning and over previous <a href=https://en.wikipedia.org/wiki/System>systems</a>. In addition, our improvements are consistent across <a href=https://en.wikipedia.org/wiki/Sample_size_determination>train sample sizes</a>, making our approach especially applicable to <a href=https://en.wikipedia.org/wiki/Sample_size_determination>small datasets</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5051.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5051 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5051 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5051/>Annotating Orthographic Target Hypotheses in a German L1 Learner Corpus<span class=acl-fixed-case>G</span>erman <span class=acl-fixed-case>L</span>1 Learner Corpus</a></strong><br><a href=/people/r/ronja-laarmann-quante/>Ronja Laarmann-Quante</a>
|
<a href=/people/k/katrin-ortmann/>Katrin Ortmann</a>
|
<a href=/people/a/anna-ehlert/>Anna Ehlert</a>
|
<a href=/people/m/maurice-vogel/>Maurice Vogel</a>
|
<a href=/people/s/stefanie-dipper/>Stefanie Dipper</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5051><div class="card-body p-3 small">NLP applications for learners often rely on annotated learner corpora. Thereby, it is important that the <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a> are both meaningful for the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, and consistent and reliable. We present a new longitudinal L1 learner corpus for <a href=https://en.wikipedia.org/wiki/German_language>German</a> (handwritten texts collected in grade 24), which is transcribed and annotated with a target hypothesis that strictly only corrects orthographic errors, and is thereby tailored to research and tool development for orthographic issues in <a href=https://en.wikipedia.org/wiki/Primary_school>primary school</a>. While for most <a href=https://en.wikipedia.org/wiki/Corpus_linguistics>corpora</a>, <a href=https://en.wikipedia.org/wiki/Transcription_(biology)>transcription</a> and target hypothesis are not evaluated, we conducted a detailed inter-annotator agreement study for both tasks. Although we achieved high agreement, our discussion of cases of disagreement shows that even with detailed guidelines, annotators differ here and there for different reasons, which should also be considered when working with transcriptions and target hypotheses of other corpora, especially if no explicit guidelines for their construction are known.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5052.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5052 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5052 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5052/>A Large Scale Quantitative Exploration of Modeling Strategies for Content Scoring</a></strong><br><a href=/people/n/nitin-madnani/>Nitin Madnani</a>
|
<a href=/people/a/anastassia-loukina/>Anastassia Loukina</a>
|
<a href=/people/a/aoife-cahill/>Aoife Cahill</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5052><div class="card-body p-3 small">We explore various supervised learning strategies for automated scoring of content knowledge for a large corpus of 130 different content-based questions spanning four subject areas (Science, Math, English Language Arts, and Social Studies) and containing over 230,000 responses scored by human raters. Based on our analyses, we provide specific recommendations for content scoring. These are based on patterns observed across multiple questions and assessments and are, therefore, likely to generalize to other scenarios and prove useful to the community as automated content scoring becomes more popular in schools and classrooms.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>