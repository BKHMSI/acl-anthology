<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the Second Workshop on Linguistic and Neurocognitive Resources - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Proceedings of the Second Workshop on Linguistic and Neurocognitive Resources</h2><p class=lead><a href=/people/e/emmanuele-chersoni/>Emmanuele Chersoni</a>,
<a href=/people/b/barry-devereux/>Barry Devereux</a>,
<a href=/people/c/chu-ren-huang/>Chu-Ren Huang</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2020.lincr-1</dd><dt>Month:</dt><dd>May</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Marseille, France</dd><dt>Venues:</dt><dd><a href=/venues/lrec/>LREC</a>
| <a href=/venues/lincr/>LiNCr</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>European Language Resources Association</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.lincr-1>https://aclanthology.org/2020.lincr-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+Second+Workshop+on+Linguistic+and+Neurocognitive+Resources" title="Search for 'Proceedings of the Second Workshop on Linguistic and Neurocognitive Resources' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lincr-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lincr-1.0/>Proceedings of the Second Workshop on Linguistic and Neurocognitive Resources</a></strong><br><a href=/people/e/emmanuele-chersoni/>Emmanuele Chersoni</a>
|
<a href=/people/b/barry-devereux/>Barry Devereux</a>
|
<a href=/people/c/chu-ren-huang/>Chu-Ren Huang</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lincr-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lincr-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lincr-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lincr-1.1/>Extrapolating Binder Style Word Embeddings to New Words</a></strong><br><a href=/people/j/jacob-turton/>Jacob Turton</a>
|
<a href=/people/d/david-vinson/>David Vinson</a>
|
<a href=/people/r/robert-smith/>Robert Smith</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lincr-1--1><div class="card-body p-3 small">Word embeddings such as Word2Vec not only uniquely identify words but also encode important semantic information about them. However, as single entities they are difficult to interpret and their individual dimensions do not have obvious meanings. A more intuitive and interpretable <a href=https://en.wikipedia.org/wiki/Feature_space>feature space</a> based on neural representations of words was presented by Binder and colleagues (2016) but is only available for a very limited vocabulary. Previous research (Utsumi, 2018) indicates that Binder features can be predicted for words from their embedding vectors (such as Word2Vec), but only looked at the original Binder vocabulary. This paper aimed to demonstrate that Binder features can effectively be predicted for a large number of new words and that the predicted values are sensible. The results supported this, showing that correlations between predicted feature values were consistent with those in the original Binder dataset. Additionally, vectors of predicted values performed comparatively to established embedding models in tests of word-pair semantic similarity. Being able to predict Binder feature space vectors for any number of new words opens up many uses not possible with the original vocabulary size.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lincr-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lincr-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lincr-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lincr-1.2/>Towards the First Dyslexic Font in Russian<span class=acl-fixed-case>R</span>ussian</a></strong><br><a href=/people/s/svetlana-alexeeva/>Svetlana Alexeeva</a>
|
<a href=/people/a/aleksandra-dobrego/>Aleksandra Dobrego</a>
|
<a href=/people/v/vladislav-zubov/>Vladislav Zubov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lincr-1--2><div class="card-body p-3 small">Texts comprise a large part of visual information that we process every day, so one of the tasks of <a href=https://en.wikipedia.org/wiki/Language_science>language science</a> is to make them more accessible. However, often the text design process is focused on the font size, but not on its type ; which might be crucial especially for the people with reading disabilities. The current paper represents a study on <a href=https://en.wikipedia.org/wiki/Accessibility>text accessibility</a> and the first attempt to create a research-based accessible font for <a href=https://en.wikipedia.org/wiki/Cyrillic_script>Cyrillic letters</a>. This resulted in the dyslexic-specific font, LexiaD. Its design rests on the reduction of inter-letter similarity of the <a href=https://en.wikipedia.org/wiki/Russian_alphabet>Russian alphabet</a>. In evaluation stage, dyslexic and non-dyslexic children were asked to read sentences from the Children version of the Russian Sentence Corpus. We tested the readability of LexiaD compared to PT Sans and PT Serif fonts. The results showed that all children had some advantage in letter feature extraction and information integration while reading in LexiaD, but <a href=https://en.wikipedia.org/wiki/Lexical_access>lexical access</a> was improved when sentences were rendered in <a href=https://en.wikipedia.org/wiki/PT_Sans>PT Sans</a> or <a href=https://en.wikipedia.org/wiki/PT_Serif>PT Serif</a>. Therefore, in several aspects, LexiaD proved to be faster to read and could be recommended to use by <a href=https://en.wikipedia.org/wiki/Dyslexia>dyslexics</a> who have visual deficiency or those who struggle with text understanding resulting in re-reading.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lincr-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lincr-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lincr-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lincr-1.6/>The Little Prince in 26 Languages : Towards a Multilingual Neuro-Cognitive Corpus</a></strong><br><a href=/people/s/sabrina-stehwien/>Sabrina Stehwien</a>
|
<a href=/people/l/lena-henke/>Lena Henke</a>
|
<a href=/people/j/john-hale/>John Hale</a>
|
<a href=/people/j/jonathan-brennan/>Jonathan Brennan</a>
|
<a href=/people/l/lars-meyer/>Lars Meyer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lincr-1--6><div class="card-body p-3 small">We present the Le Petit Prince Corpus (LPPC), a multi-lingual resource for research in (computational) psycho- and neurolinguistics. The <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> consists of the children&#8217;s story The Little Prince in 26 languages. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> is in the process of being built using state-of-the-art methods for <a href=https://en.wikipedia.org/wiki/Speech_processing>speech and language processing</a> and <a href=https://en.wikipedia.org/wiki/Electroencephalography>electroencephalography (EEG)</a>. The planned release of LPPC dataset will include raw text annotated with dependency graphs in the Universal Dependencies standard, a near-natural-sounding synthetic spoken subset as well as <a href=https://en.wikipedia.org/wiki/Electroencephalography>EEG recordings</a>. We will use this <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> for conducting <a href=https://en.wikipedia.org/wiki/Neurolinguistics>neurolinguistic studies</a> that generalize across a wide range of languages, overcoming <a href=https://en.wikipedia.org/wiki/Linguistic_typology>typological constraints</a> to traditional approaches. The planned release of the LPPC combines linguistic and EEG data for many languages using fully automatic methods, and thus constitutes a readily extendable resource that supports cross-linguistic and cross-disciplinary research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lincr-1.8.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lincr-1--8 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lincr-1.8 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lincr-1.8/>Sensorimotor Norms for 506 Russian Nouns<span class=acl-fixed-case>R</span>ussian Nouns</a></strong><br><a href=/people/a/alex-miklashevsky/>Alex Miklashevsky</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lincr-1--8><div class="card-body p-3 small">Embodied cognitive science suggested a number of <a href=https://en.wikipedia.org/wiki/Variable_(mathematics)>variables</a> describing our sensorimotor experience associated with different concepts : modality experience rating (i.e., relationship between words and images of a particular perceptive modalityvisual, auditory, haptic etc.), manipulability (the necessity for an object to interact with human hands in order to perform its function), vertical spatial localization. According to the embodied cognition theory, these semantic variables capture our <a href=https://en.wikipedia.org/wiki/Mental_representation>mental representations</a> and thus should influence <a href=https://en.wikipedia.org/wiki/Word_formation>word learning</a>, processing and <a href=https://en.wikipedia.org/wiki/Word_formation>production</a>. However, it is not clear how these new <a href=https://en.wikipedia.org/wiki/Variable_and_attribute_(research)>variables</a> are related to such traditional <a href=https://en.wikipedia.org/wiki/Variable_and_attribute_(research)>variables</a> as imageability, age of acquisition (AoA) and <a href=https://en.wikipedia.org/wiki/Word_frequency>word frequency</a>. In the presented database, normative data on the modality (visual, auditory, haptic, olfactory, and gustatory) ratings, vertical spatial localization of the object, manipulability, imageability, age of acquisition, and subjective frequency for 506 Russian nouns are collected. Factor analysis revealed four factors : (1) visual and haptic modality ratings were combined with imageability, manipulability and AoA ; (2) word length, frequency and AoA ; (3) olfactory modality was united with gustatory ; (4) spatial localization only was included in the fourth factor. The database is available online together with a publication describing the method of data collection and data parameters (Miklashevsky, 2018).</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>