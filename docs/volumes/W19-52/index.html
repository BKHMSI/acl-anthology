<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the Fourth Conference on Machine Translation (Volume 1: Research Papers) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/W19-52.pdf>Proceedings of the Fourth Conference on Machine Translation (Volume 1: Research Papers)</a></h2><p class=lead><a href=/people/o/ondrej-bojar/>Ondřej Bojar</a>,
<a href=/people/r/rajen-chatterjee/>Rajen Chatterjee</a>,
<a href=/people/c/christian-federmann/>Christian Federmann</a>,
<a href=/people/m/mark-fishel/>Mark Fishel</a>,
<a href=/people/y/yvette-graham/>Yvette Graham</a>,
<a href=/people/b/barry-haddow/>Barry Haddow</a>,
<a href=/people/m/matthias-huck/>Matthias Huck</a>,
<a href=/people/a/antonio-jimeno-yepes/>Antonio Jimeno Yepes</a>,
<a href=/people/p/philipp-koehn/>Philipp Koehn</a>,
<a href=/people/a/andre-f-t-martins/>André Martins</a>,
<a href=/people/c/christof-monz/>Christof Monz</a>,
<a href=/people/m/matteo-negri/>Matteo Negri</a>,
<a href=/people/a/aurelie-neveol/>Aurélie Névéol</a>,
<a href=/people/m/mariana-neves/>Mariana Neves</a>,
<a href=/people/m/matt-post/>Matt Post</a>,
<a href=/people/m/marco-turchi/>Marco Turchi</a>,
<a href=/people/k/karin-verspoor/>Karin Verspoor</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>W19-52</dd><dt>Month:</dt><dd>August</dd><dt>Year:</dt><dd>2019</dd><dt>Address:</dt><dd>Florence, Italy</dd><dt>Venues:</dt><dd><a href=/venues/acl/>ACL</a>
| <a href=/venues/wmt/>WMT</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd><a href=/sigs/sigmt/>SIGMT</a></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/W19-52>https://aclanthology.org/W19-52</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/W19-52.pdf>https://aclanthology.org/W19-52.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/W19-52.pdf title="Open PDF of 'Proceedings of the Fourth Conference on Machine Translation (Volume 1: Research Papers)'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+Fourth+Conference+on+Machine+Translation+%28Volume+1%3A+Research+Papers%29" title="Search for 'Proceedings of the Fourth Conference on Machine Translation (Volume 1: Research Papers)' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5200.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5200/>Proceedings of the Fourth Conference on Machine Translation (Volume 1: Research Papers)</a></strong><br><a href=/people/o/ondrej-bojar/>Ondřej Bojar</a>
|
<a href=/people/r/rajen-chatterjee/>Rajen Chatterjee</a>
|
<a href=/people/c/christian-federmann/>Christian Federmann</a>
|
<a href=/people/m/mark-fishel/>Mark Fishel</a>
|
<a href=/people/y/yvette-graham/>Yvette Graham</a>
|
<a href=/people/b/barry-haddow/>Barry Haddow</a>
|
<a href=/people/m/matthias-huck/>Matthias Huck</a>
|
<a href=/people/a/antonio-jimeno-yepes/>Antonio Jimeno Yepes</a>
|
<a href=/people/p/philipp-koehn/>Philipp Koehn</a>
|
<a href=/people/a/andre-f-t-martins/>André Martins</a>
|
<a href=/people/c/christof-monz/>Christof Monz</a>
|
<a href=/people/m/matteo-negri/>Matteo Negri</a>
|
<a href=/people/a/aurelie-neveol/>Aurélie Névéol</a>
|
<a href=/people/m/mariana-neves/>Mariana Neves</a>
|
<a href=/people/m/matt-post/>Matt Post</a>
|
<a href=/people/m/marco-turchi/>Marco Turchi</a>
|
<a href=/people/k/karin-verspoor/>Karin Verspoor</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5203.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5203 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5203 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5203/>Incorporating <a href=https://en.wikipedia.org/wiki/Source_code>Source Syntax</a> into Transformer-Based Neural Machine Translation</a></strong><br><a href=/people/a/anna-currey/>Anna Currey</a>
|
<a href=/people/k/kenneth-heafield/>Kenneth Heafield</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5203><div class="card-body p-3 small">Transformer-based neural machine translation (NMT) has recently achieved state-of-the-art performance on many machine translation tasks. However, recent work (Raganato and Tiedemann, 2018 ; Tang et al., 2018 ; Tran et al., 2018) has indicated that Transformer models may not learn syntactic structures as well as their recurrent neural network-based counterparts, particularly in low-resource cases. In this paper, we incorporate constituency parse information into a Transformer NMT model. We leverage linearized parses of the source training sentences in order to inject <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a> into the Transformer architecture without modifying it. We introduce two methods : a multi-task machine translation and parsing model with a single encoder and decoder, and a mixed encoder model that learns to translate directly from parsed and unparsed source sentences. We evaluate our methods on low-resource translation from <a href=https://en.wikipedia.org/wiki/English_language>English</a> into twenty target languages, showing consistent improvements of 1.3 <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a> on average across diverse target languages for the multi-task technique. We further evaluate the models on full-scale WMT tasks, finding that the multi-task model aids low- and medium-resource NMT but degenerates high-resource English-German translation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5205.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5205 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5205 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5205/>Generalizing Back-Translation in <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a></a></strong><br><a href=/people/m/miguel-graca/>Miguel Graça</a>
|
<a href=/people/y/yunsu-kim/>Yunsu Kim</a>
|
<a href=/people/j/julian-schamper/>Julian Schamper</a>
|
<a href=/people/s/shahram-khadivi/>Shahram Khadivi</a>
|
<a href=/people/h/hermann-ney/>Hermann Ney</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5205><div class="card-body p-3 small">Back-translation data augmentation by translating target monolingual data is a crucial component in modern neural machine translation (NMT). In this work, we reformulate back-translation in the scope of cross-entropy optimization of an NMT model, clarifying its underlying mathematical assumptions and approximations beyond its heuristic usage. Our formulation covers broader synthetic data generation schemes, including sampling from a target-to-source NMT model. With this formulation, we point out fundamental problems of the <a href=https://en.wikipedia.org/wiki/Sampling_(statistics)>sampling-based approaches</a> and propose to remedy them by (i) disabling label smoothing for the target-to-source model and (ii) sampling from a restricted search space. Our statements are investigated on the WMT 2018 German-English news translation task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5208.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5208 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5208 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W19-5208.Supplementary.zip data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W19-5208.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-5208" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-5208/>The Effect of Translationese in Machine Translation Test Sets</a></strong><br><a href=/people/m/mike-zhang/>Mike Zhang</a>
|
<a href=/people/a/antonio-toral/>Antonio Toral</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5208><div class="card-body p-3 small">The effect of translationese has been studied in the field of <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation (MT)</a>, mostly with respect to training data. We study in depth the effect of translationese on <a href=https://en.wikipedia.org/wiki/Test_data>test data</a>, using the test sets from the last three editions of WMT&#8217;s news shared task, containing 17 translation directions. We show evidence that (i) the use of translationese in test sets results in inflated human evaluation scores for MT systems ; (ii) in some cases system rankings do change and (iii) the impact translationese has on a translation direction is inversely correlated to the translation quality attainable by state-of-the-art MT systems for that direction.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5209.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5209 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5209 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5209/>Customizing Neural Machine Translation for <a href=https://en.wikipedia.org/wiki/Subtitling>Subtitling</a></a></strong><br><a href=/people/e/evgeny-matusov/>Evgeny Matusov</a>
|
<a href=/people/p/patrick-wilken/>Patrick Wilken</a>
|
<a href=/people/y/yota-georgakopoulou/>Yota Georgakopoulou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5209><div class="card-body p-3 small">In this work, we customized a neural machine translation system for translation of subtitles in the domain of <a href=https://en.wikipedia.org/wiki/Entertainment>entertainment</a>. The neural translation model was adapted to the subtitling content and style and extended by a simple, yet effective technique for utilizing inter-sentence context for short sentences such as dialog turns. The main contribution of the paper is a novel subtitle segmentation algorithm that predicts the end of a subtitle line given the previous word-level context using a <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network</a> learned from human segmentation decisions. This <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> is combined with subtitle length and duration constraints established in the subtitling industry. We conducted a thorough human evaluation with two post-editors (English-to-Spanish translation of a <a href=https://en.wikipedia.org/wiki/Documentary_film>documentary</a> and a sitcom). It showed a notable productivity increase of up to 37 % as compared to translating from scratch and significant reductions in human translation edit rate in comparison with the post-editing of the baseline non-adapted system without a learned segmentation model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5210.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5210 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5210 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5210/>Integration of Dubbing Constraints into <a href=https://en.wikipedia.org/wiki/Machine_translation>Machine Translation</a></a></strong><br><a href=/people/a/ashutosh-saboo/>Ashutosh Saboo</a>
|
<a href=/people/t/timo-baumann/>Timo Baumann</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5210><div class="card-body p-3 small">Translation systems aim to perform a meaning-preserving conversion of linguistic material (typically text but also speech) from a source to a target language (and, to a lesser degree, the corresponding socio-cultural contexts). Dubbing, i.e., the lip-synchronous translation and revoicing of speech adds to this constraints about the close matching of phonetic and resulting visemic synchrony characteristics of source and target material. There is an inherent conflict between a <a href=https://en.wikipedia.org/wiki/Translation>translation</a>&#8217;s meaning preservation and &#8216;dubbability&#8217; and the resulting trade-off can be controlled by weighing the synchrony constraints. We introduce our work, which to the best of our knowledge is the first of its kind, on integrating synchrony constraints into the machine translation paradigm. We present first results for the integration of synchrony constraints into encoder decoder-based neural machine translation and show that considerably more &#8216;dubbable&#8217; translations can be achieved with only a small impact on <a href=https://en.wikipedia.org/wiki/BLEU>BLEU score</a>, and dubbability improves more steeply than <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a> degrades.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5211.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5211 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5211 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-5211" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-5211/>Widening the Representation Bottleneck in <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a> with Lexical Shortcuts</a></strong><br><a href=/people/d/denis-emelin/>Denis Emelin</a>
|
<a href=/people/i/ivan-titov/>Ivan Titov</a>
|
<a href=/people/r/rico-sennrich/>Rico Sennrich</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5211><div class="card-body p-3 small">The <a href=https://en.wikipedia.org/wiki/Transformer>transformer</a> is a state-of-the-art neural translation model that uses <a href=https://en.wikipedia.org/wiki/Attention>attention</a> to iteratively refine lexical representations with information drawn from the surrounding context. Lexical features are fed into the first layer and propagated through a deep network of hidden layers. We argue that the need to represent and propagate lexical features in each layer limits the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>&#8217;s capacity for learning and representing other information relevant to the task. To alleviate this bottleneck, we introduce gated shortcut connections between the embedding layer and each subsequent layer within the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> and <a href=https://en.wikipedia.org/wiki/Codec>decoder</a>. This enables the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to access relevant lexical content dynamically, without expending limited resources on storing it within intermediate states. We show that the proposed modification yields consistent improvements over a baseline transformer on standard WMT translation tasks in 5 translation directions (0.9 BLEU on average) and reduces the amount of <a href=https://en.wikipedia.org/wiki/Lexical_analysis>lexical information</a> passed along the hidden layers. We furthermore evaluate different ways to integrate lexical connections into the transformer architecture and present ablation experiments exploring the effect of proposed shortcuts on model behavior.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5212.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5212 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5212 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W19-5212.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W19-5212/>A High-Quality Multilingual Dataset for Structured Documentation Translation</a></strong><br><a href=/people/k/kazuma-hashimoto/>Kazuma Hashimoto</a>
|
<a href=/people/r/raffaella-buschiazzo/>Raffaella Buschiazzo</a>
|
<a href=/people/j/james-bradbury/>James Bradbury</a>
|
<a href=/people/t/teresa-marshall/>Teresa Marshall</a>
|
<a href=/people/r/richard-socher/>Richard Socher</a>
|
<a href=/people/c/caiming-xiong/>Caiming Xiong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5212><div class="card-body p-3 small">This paper presents a high-quality multilingual dataset for the documentation domain to advance research on localization of structured text. Unlike widely-used datasets for translation of plain text, we collect XML-structured parallel text segments from the online documentation for an enterprise software platform. These <a href=https://en.wikipedia.org/wiki/Web_page>Web pages</a> have been professionally translated from English into 16 languages and maintained by domain experts, and around 100,000 text segments are available for each language pair. We build and evaluate translation models for seven target languages from <a href=https://en.wikipedia.org/wiki/English_language>English</a>, with several different copy mechanisms and an XML-constrained beam search. We also experiment with a non-English pair to show that our dataset has the potential to explicitly enable 17 16 translation settings. Our experiments show that learning to translate with the <a href=https://en.wikipedia.org/wiki/Tag_(metadata)>XML tags</a> improves translation accuracy, and the <a href=https://en.wikipedia.org/wiki/Beam_search>beam search</a> accurately generates <a href=https://en.wikipedia.org/wiki/XML>XML structures</a>. We also discuss trade-offs of using the copy mechanisms by focusing on translation of numerical words and <a href=https://en.wikipedia.org/wiki/Named_entity>named entities</a>. We further provide a detailed human analysis of gaps between the model output and human translations for real-world applications, including suitability for <a href=https://en.wikipedia.org/wiki/Post-editing>post-editing</a>.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>