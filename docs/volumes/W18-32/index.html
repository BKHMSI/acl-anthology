<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/W18-32.pdf>Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching</a></h2><p class=lead><a href=/people/g/gustavo-aguilar/>Gustavo Aguilar</a>,
<a href=/people/f/fahad-alghamdi/>Fahad AlGhamdi</a>,
<a href=/people/v/victor-soto/>Victor Soto</a>,
<a href=/people/t/thamar-solorio/>Thamar Solorio</a>,
<a href=/people/m/mona-diab/>Mona Diab</a>,
<a href=/people/j/julia-hirschberg/>Julia Hirschberg</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>W18-32</dd><dt>Month:</dt><dd>July</dd><dt>Year:</dt><dd>2018</dd><dt>Address:</dt><dd>Melbourne, Australia</dd><dt>Venues:</dt><dd><a href=/venues/acl/>ACL</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/W18-32>https://aclanthology.org/W18-32</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/W18-32.pdf>https://aclanthology.org/W18-32.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/W18-32.pdf title="Open PDF of 'Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+Third+Workshop+on+Computational+Approaches+to+Linguistic+Code-Switching" title="Search for 'Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3200.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3200/>Proceedings of the Third Workshop on Computational Approaches to Linguistic Code-Switching</a></strong><br><a href=/people/g/gustavo-aguilar/>Gustavo Aguilar</a>
|
<a href=/people/f/fahad-alghamdi/>Fahad AlGhamdi</a>
|
<a href=/people/v/victor-soto/>Victor Soto</a>
|
<a href=/people/t/thamar-solorio/>Thamar Solorio</a>
|
<a href=/people/m/mona-diab/>Mona Diab</a>
|
<a href=/people/j/julia-hirschberg/>Julia Hirschberg</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3201.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3201 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3201 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3201/>Joint Part-of-Speech and Language ID Tagging for Code-Switched Data<span class=acl-fixed-case>ID</span> Tagging for Code-Switched Data</a></strong><br><a href=/people/v/victor-soto/>Victor Soto</a>
|
<a href=/people/j/julia-hirschberg/>Julia Hirschberg</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3201><div class="card-body p-3 small">Code-switching is the fluent alternation between two or more languages in conversation between bilinguals. Large populations of speakers code-switch during communication, but little effort has been made to develop tools for <a href=https://en.wikipedia.org/wiki/Code-switching>code-switching</a>, including <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech taggers</a>. In this paper, we propose an approach to POS tagging of code-switched English-Spanish data based on <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural networks</a>. We test our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on known monolingual benchmarks to demonstrate that our neural POS tagging model is on par with state-of-the-art methods. We next test our code-switched methods on the Miami Bangor corpus of English Spanish conversation, focusing on two types of experiments : <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>POS tagging</a> alone, for which we achieve 96.34 % accuracy, and joint part-of-speech and language ID tagging, which achieves similar <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>POS tagging accuracy</a> (96.39 %) and very high language ID accuracy (98.78 %). Finally, we show that our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> outperform other state-of-the-art code-switched taggers.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3202.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3202 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3202 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3202/>Phone Merging For Code-Switched Speech Recognition</a></strong><br><a href=/people/s/sunit-sivasankaran/>Sunit Sivasankaran</a>
|
<a href=/people/b/brij-mohan-lal-srivastava/>Brij Mohan Lal Srivastava</a>
|
<a href=/people/s/sunayana-sitaram/>Sunayana Sitaram</a>
|
<a href=/people/k/kalika-bali/>Kalika Bali</a>
|
<a href=/people/m/monojit-choudhury/>Monojit Choudhury</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3202><div class="card-body p-3 small">Speakers in multilingual communities often switch between or mix multiple languages in the same conversation. Automatic Speech Recognition (ASR) of code-switched speech faces many challenges including the influence of phones of different languages on each other. This paper shows evidence that phone sharing between languages improves the Acoustic Model performance for Hindi-English code-switched speech. We compare baseline system built with separate phones for <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a> and <a href=https://en.wikipedia.org/wiki/English_language>English</a> with systems where the phones were manually merged based on linguistic knowledge. Encouraged by the improved ASR performance after manually merging the phones, we further investigate multiple data-driven methods to identify phones to be merged across the languages. We show detailed analysis of automatic phone merging in this language pair and the impact it has on individual phone accuracies and WER. Though the best performance gain of 1.2 % <a href=https://en.wikipedia.org/wiki/Effective_radiated_power>WER</a> was observed with manually merged phones, we show experimentally that the manual phone merge is not optimal.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3203.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3203 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3203 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3203/>Improving Neural Network Performance by Injecting Background Knowledge : Detecting Code-switching and Borrowing in Algerian texts<span class=acl-fixed-case>A</span>lgerian texts</a></strong><br><a href=/people/w/wafia-adouane/>Wafia Adouane</a>
|
<a href=/people/j/jean-philippe-bernardy/>Jean-Philippe Bernardy</a>
|
<a href=/people/s/simon-dobnik/>Simon Dobnik</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3203><div class="card-body p-3 small">We explore the effect of injecting background knowledge to different deep neural network (DNN) configurations in order to mitigate the problem of the scarcity of annotated data when applying these models on datasets of low-resourced languages. The background knowledge is encoded in the form of <a href=https://en.wikipedia.org/wiki/Lexicon>lexicons</a> and pre-trained sub-word embeddings. The DNN models are evaluated on the task of detecting code-switching and borrowing points in non-standardised user-generated Algerian texts. Overall results show that DNNs benefit from adding background knowledge. However, the gain varies between models and categories. The proposed DNN architectures are generic and could be applied to other low-resourced languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3204.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3204 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3204 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3204/>Code-Mixed Question Answering Challenge : Crowd-sourcing Data and Techniques</a></strong><br><a href=/people/k/khyathi-chandu/>Khyathi Chandu</a>
|
<a href=/people/e/ekaterina-loginova/>Ekaterina Loginova</a>
|
<a href=/people/v/vishal-gupta/>Vishal Gupta</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a>
|
<a href=/people/g/gunter-neumann/>Günter Neumann</a>
|
<a href=/people/m/manoj-chinnakotla/>Manoj Chinnakotla</a>
|
<a href=/people/e/eric-nyberg/>Eric Nyberg</a>
|
<a href=/people/a/alan-w-black/>Alan W. Black</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3204><div class="card-body p-3 small">Code-Mixing (CM) is the phenomenon of alternating between two or more languages which is prevalent in bi- and multi-lingual communities. Most NLP applications today are still designed with the assumption of a single interaction language and are most likely to break given a CM utterance with multiple languages mixed at a morphological, phrase or sentence level. For example, popular commercial search engines do not yet fully understand the intents expressed in CM queries. As a first step towards fostering research which supports CM in NLP applications, we systematically crowd-sourced and curated an evaluation dataset for factoid question answering in three CM languages-Hinglish (Hindi+English), Tenglish (Telugu+English) and Tamlish (Tamil+English) which belong to two language families (Indo-Aryan and Dravidian). We share the details of our data collection process, techniques which were used to avoid inducing lexical bias amongst the crowd workers and other CM specific linguistic properties of the dataset. Our final dataset, which is available freely for research purposes, has 1,694 <a href=https://en.wikipedia.org/wiki/Hinglish>Hinglish</a>, 2,848 Tamlish and 1,391 Tenglish factoid questions and their answers. We discuss the <a href=https://en.wikipedia.org/wiki/List_of_art_media>techniques</a> used by the participants for the first edition of this ongoing challenge.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3205.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3205 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3205 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3205/>Transliteration Better than <a href=https://en.wikipedia.org/wiki/Translation>Translation</a>? Answering Code-mixed Questions over a Knowledge Base</a></strong><br><a href=/people/v/vishal-gupta/>Vishal Gupta</a>
|
<a href=/people/m/manoj-chinnakotla/>Manoj Chinnakotla</a>
|
<a href=/people/m/manish-shrivastava/>Manish Shrivastava</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3205><div class="card-body p-3 small">Humans can learn multiple languages. If they know a fact in one language, they can answer a question in another language they understand. They can also answer Code-mix (CM) questions : questions which contain both languages. This behavior is attributed to the unique learning ability of humans. Our task aims to study if machines can achieve this. We demonstrate how effectively a <a href=https://en.wikipedia.org/wiki/Machine>machine</a> can answer CM questions. In this work, we adopt a two phase approach : candidate generation and candidate re-ranking to answer questions. We propose a Triplet-Siamese-Hybrid CNN (TSHCNN) to re-rank candidate answers. We show experiments on the SimpleQuestions dataset. Our network is trained only on English questions provided in this dataset and noisy Hindi translations of these questions and can answer English-Hindi CM questions effectively without the need of translation into English. Back-transliterated CM questions outperform their lexical and sentence level translated counterparts by 5 % & 35 % in accuracy respectively, highlighting the efficacy of our approach in a resource constrained setting.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3208.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3208 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3208 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3208/>Predicting the presence of a Matrix Language in <a href=https://en.wikipedia.org/wiki/Code-switching>code-switching</a></a></strong><br><a href=/people/b/barbara-bullock/>Barbara Bullock</a>
|
<a href=/people/w/wally-guzman/>Wally Guzmán</a>
|
<a href=/people/j/jacqueline-serigos/>Jacqueline Serigos</a>
|
<a href=/people/v/vivek-sharath/>Vivek Sharath</a>
|
<a href=/people/a/almeida-jacqueline-toribio/>Almeida Jacqueline Toribio</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3208><div class="card-body p-3 small">One language is often assumed to be dominant in <a href=https://en.wikipedia.org/wiki/Code-switching>code-switching</a> but this assumption has not been empirically tested. We operationalize the matrix language (ML) at the level of the sentence, using three common definitions from <a href=https://en.wikipedia.org/wiki/Linguistics>linguistics</a>. We test whether these converge and then model this <a href=https://en.wikipedia.org/wiki/Convergence_of_random_variables>convergence</a> via a set of <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> that together quantify the nature of C-S. We conduct our experiment on four Spanish-English corpora. Our results demonstrate that our model can separate some corpora according to whether they have a dominant ML or not but that the <a href=https://en.wikipedia.org/wiki/Corpus_linguistics>corpora</a> span a range of mixing types that can not be sorted neatly into an insertional vs. alternational dichotomy.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3210.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3210 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3210 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3210/>Accommodation of Conversational Code-Choice</a></strong><br><a href=/people/a/anshul-bawa/>Anshul Bawa</a>
|
<a href=/people/m/monojit-choudhury/>Monojit Choudhury</a>
|
<a href=/people/k/kalika-bali/>Kalika Bali</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3210><div class="card-body p-3 small">Bilingual speakers often freely mix languages. However, in such bilingual conversations, are the language choices of the speakers coordinated? How much does one speaker&#8217;s choice of language affect other speakers? In this paper, we formulate code-choice as a <a href=https://en.wikipedia.org/wiki/Style_(sociolinguistics)>linguistic style</a>, and show that speakers are indeed sensitive to and accommodating of each other&#8217;s code-choice. We find that the saliency or markedness of a language in context directly affects the degree of accommodation observed. More importantly, we discover that accommodation of code-choices persists over several conversational turns. We also propose an alternative interpretation of conversational accommodation as a retrieval problem, and show that the differences in accommodation characteristics of code-choices are based on their markedness in context.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3211.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3211 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3211 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3211/>Language Informed Modeling of Code-Switched Text</a></strong><br><a href=/people/k/khyathi-chandu/>Khyathi Chandu</a>
|
<a href=/people/t/thomas-manzini/>Thomas Manzini</a>
|
<a href=/people/s/sumeet-singh/>Sumeet Singh</a>
|
<a href=/people/a/alan-w-black/>Alan W. Black</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3211><div class="card-body p-3 small">Code-switching (CS), the practice of alternating between two or more languages in conversations, is pervasive in most <a href=https://en.wikipedia.org/wiki/Multilingualism>multi-lingual communities</a>. CS texts have a complex interplay between languages and occur in informal contexts that make them harder to collect and construct NLP tools for. We approach this problem through Language Modeling (LM) on a new Hindi-English mixed corpus containing 59,189 unique sentences collected from <a href=https://en.wikipedia.org/wiki/Blog>blogging websites</a>. We implement and discuss different <a href=https://en.wikipedia.org/wiki/Language_model>Language Models</a> derived from a multi-layered LSTM architecture. We hypothesize that <a href=https://en.wikipedia.org/wiki/Code-switching>encoding language information</a> strengthens a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> by helping to learn code-switching points. We show that our highest performing <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> achieves a test perplexity of 19.52 on the <a href=https://en.wikipedia.org/wiki/Corpus_linguistics>CS corpus</a> that we collected and processed. On this data we demonstrate that our performance is an improvement over AWD-LSTM LM (a recent state of the art on monolingual English).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3212.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3212 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3212 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3212/>GHHT at CALCS 2018 : Named Entity Recognition for Dialectal Arabic Using Neural Networks<span class=acl-fixed-case>GHHT</span> at <span class=acl-fixed-case>CALCS</span> 2018: Named Entity Recognition for Dialectal <span class=acl-fixed-case>A</span>rabic Using Neural Networks</a></strong><br><a href=/people/m/mohammed-attia/>Mohammed Attia</a>
|
<a href=/people/y/younes-samih/>Younes Samih</a>
|
<a href=/people/w/wolfgang-maier/>Wolfgang Maier</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3212><div class="card-body p-3 small">This paper describes our system submission to the CALCS 2018 shared task on <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a> on code-switched data for the language variant pair of <a href=https://en.wikipedia.org/wiki/Modern_Standard_Arabic>Modern Standard Arabic</a> and <a href=https://en.wikipedia.org/wiki/Egyptian_Arabic>Egyptian dialectal Arabic</a>. We build a a <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Neural Network</a> that combines word and character-based representations in convolutional and recurrent networks with a CRF layer. The model is augmented with stacked layers of enriched information such pre-trained embeddings, Brown clusters and <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity gazetteers</a>. Our <a href=https://en.wikipedia.org/wiki/System>system</a> is ranked second among those participating in the shared task achieving an FB1 average of 70.09 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3213.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3213 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3213 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3213/>Simple Features for Strong Performance on Named Entity Recognition in Code-Switched Twitter Data<span class=acl-fixed-case>T</span>witter Data</a></strong><br><a href=/people/d/devanshu-jain/>Devanshu Jain</a>
|
<a href=/people/m/maria-kustikova/>Maria Kustikova</a>
|
<a href=/people/m/mayank-darbari/>Mayank Darbari</a>
|
<a href=/people/r/rishabh-gupta/>Rishabh Gupta</a>
|
<a href=/people/s/stephen-mayhew/>Stephen Mayhew</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3213><div class="card-body p-3 small">In this work, we address the problem of Named Entity Recognition (NER) in code-switched tweets as a part of the Workshop on Computational Approaches to Linguistic Code-switching (CALCS) at ACL&#8217;18. Code-switching is the phenomenon where a speaker switches between two languages or variants of the same language within or across utterances, known as intra-sentential or inter-sentential code-switching, respectively. Processing such <a href=https://en.wikipedia.org/wiki/Data>data</a> is challenging using state of the art methods since such <a href=https://en.wikipedia.org/wiki/Technology>technology</a> is generally geared towards processing monolingual text. In this paper we explored ways to use <a href=https://en.wikipedia.org/wiki/Language_identification>language identification</a> and <a href=https://en.wikipedia.org/wiki/Translation>translation</a> to recognize named entities in such data, however, utilizing simple features (sans multi-lingual features) with Conditional Random Field (CRF) classifier achieved the best results. Our experiments were mainly aimed at the (ENG-SPA) English-Spanish dataset but we submitted a language-independent version of our system to the (MSA-EGY) Arabic-Egyptian dataset as well and achieved good results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3214.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3214 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3214 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3214/>Bilingual Character Representation for Efficiently Addressing Out-of-Vocabulary Words in Code-Switching Named Entity Recognition</a></strong><br><a href=/people/g/genta-indra-winata/>Genta Indra Winata</a>
|
<a href=/people/c/chien-sheng-wu/>Chien-Sheng Wu</a>
|
<a href=/people/a/andrea-madotto/>Andrea Madotto</a>
|
<a href=/people/p/pascale-fung/>Pascale Fung</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3214><div class="card-body p-3 small">We propose an LSTM-based model with hierarchical architecture on <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a> from code-switching Twitter data. Our model uses bilingual character representation and <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> to address out-of-vocabulary words. In order to mitigate <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>data noise</a>, we propose to use token replacement and normalization. In the 3rd Workshop on Computational Approaches to Linguistic Code-Switching Shared Task, we achieved second place with 62.76 % harmonic mean F1-score for English-Spanish language pair without using any <a href=https://en.wikipedia.org/wiki/Gazetteer>gazetteer</a> and knowledge-based information.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3216.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3216 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3216 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3216/>The University of Texas System Submission for the Code-Switching Workshop Shared Task 2018<span class=acl-fixed-case>U</span>niversity of <span class=acl-fixed-case>T</span>exas System Submission for the Code-Switching Workshop Shared Task 2018</a></strong><br><a href=/people/f/florian-janke/>Florian Janke</a>
|
<a href=/people/t/tongrui-li/>Tongrui Li</a>
|
<a href=/people/e/eric-rincon/>Eric Rincón</a>
|
<a href=/people/g/gualberto-a-guzman/>Gualberto Guzmán</a>
|
<a href=/people/b/barbara-bullock/>Barbara Bullock</a>
|
<a href=/people/a/almeida-jacqueline-toribio/>Almeida Jacqueline Toribio</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3216><div class="card-body p-3 small">This paper describes the system for the Named Entity Recognition Shared Task of the Third Workshop on Computational Approaches to Linguistic Code-Switching (CALCS) submitted by the Bilingual Annotations Tasks (BATs) research group of the University of Texas. Our system uses several features to train a Conditional Random Field (CRF) model for classifying input words as Named Entities (NEs) using the Inside-Outside-Beginning (IOB) tagging scheme. We participated in the Modern Standard Arabic-Egyptian Arabic (MSA-EGY) and English-Spanish (ENG-SPA) tasks, achieving <a href=https://en.wikipedia.org/wiki/Weighted_arithmetic_mean>weighted average F-scores</a> of 65.62 and 54.16 respectively. We also describe the performance of a deep neural network (NN) trained on a subset of the CRF features, which did not surpass CRF performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3217.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3217 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3217 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3217/>Tackling Code-Switched NER : Participation of CMU<span class=acl-fixed-case>NER</span>: Participation of <span class=acl-fixed-case>CMU</span></a></strong><br><a href=/people/p/parvathy-geetha/>Parvathy Geetha</a>
|
<a href=/people/k/khyathi-chandu/>Khyathi Chandu</a>
|
<a href=/people/a/alan-w-black/>Alan W Black</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3217><div class="card-body p-3 small">Named Entity Recognition plays a major role in several downstream applications in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. Though this task has been heavily studied in formal monolingual texts and also <a href=https://en.wikipedia.org/wiki/Noisy_text>noisy texts</a> like Twitter data, it is still an emerging task in code-switched (CS) content on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. This paper describes our participation in the shared task of NER on code-switched data for Spanglish (Spanish + English) and Arabish (Arabic + English). In this paper we describe <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that intuitively developed from the <a href=https://en.wikipedia.org/wiki/Data>data</a> for the shared task Named Entity Recognition on Code-switched Data. Owing to the sparse and non-linear relationships between words in Twitter data, we explored neural architectures that are capable of non-linearities fairly well. In specific, we trained character level models and word level models based on Bidirectional LSTMs (Bi-LSTMs) to perform sequential tagging. We train multiple models to identify nominal mentions and subsequently use this information to predict the labels of named entity in a sequence. Our best <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> is a character level model along with word level pre-trained multilingual embeddings that gave an <a href=https://en.wikipedia.org/wiki/F-score>F-score</a> of 56.72 in <a href=https://en.wikipedia.org/wiki/Spanglish>Spanglish</a> and a word level model that gave an <a href=https://en.wikipedia.org/wiki/F-score>F-score</a> of 65.02 in <a href=https://en.wikipedia.org/wiki/Arabic>Arabish</a> on the test data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3218.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3218 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3218 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3218/>Multilingual Named Entity Recognition on Spanish-English Code-switched Tweets using Support Vector Machines<span class=acl-fixed-case>S</span>panish-<span class=acl-fixed-case>E</span>nglish Code-switched Tweets using Support Vector Machines</a></strong><br><a href=/people/d/daniel-claeser/>Daniel Claeser</a>
|
<a href=/people/s/samantha-kent/>Samantha Kent</a>
|
<a href=/people/d/dennis-felske/>Dennis Felske</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3218><div class="card-body p-3 small">This paper describes our system submission for the ACL 2018 shared task on named entity recognition (NER) in code-switched Twitter data. Our best result (F1 = 53.65) was obtained using a Support Vector Machine (SVM) with 14 <a href=https://en.wikipedia.org/wiki/Software_feature>features</a> combined with rule-based post processing.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3220.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3220 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3220 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3220/>IIT (BHU) Submission for the ACL Shared Task on <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>Named Entity Recognition</a> on Code-switched Data<span class=acl-fixed-case>IIT</span> (<span class=acl-fixed-case>BHU</span>) Submission for the <span class=acl-fixed-case>ACL</span> Shared Task on Named Entity Recognition on Code-switched Data</a></strong><br><a href=/people/s/shashwat-trivedi/>Shashwat Trivedi</a>
|
<a href=/people/h/harsh-rangwani/>Harsh Rangwani</a>
|
<a href=/people/a/anil-kumar-singh/>Anil Kumar Singh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3220><div class="card-body p-3 small">This paper describes the best performing system for the shared task on Named Entity Recognition (NER) on code-switched data for the language pair Spanish-English (ENG-SPA). We introduce a gated neural architecture for the NER task. Our final <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves an <a href=https://en.wikipedia.org/wiki/F-number>F1 score</a> of 63.76 %, outperforming the <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baseline</a> by 10 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-3221.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-3221 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-3221 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-3221/>Code-Switched Named Entity Recognition with Embedding Attention</a></strong><br><a href=/people/c/changhan-wang/>Changhan Wang</a>
|
<a href=/people/k/kyunghyun-cho/>Kyunghyun Cho</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-3221><div class="card-body p-3 small">We describe our work for the CALCS 2018 shared task on <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a> on code-switched data. Our system ranked first place for MS Arabic-Egyptian named entity recognition and third place for English-Spanish.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>