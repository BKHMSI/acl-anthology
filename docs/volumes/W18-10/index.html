<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the Workshop on Generalization in the Age of Deep Learning - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/W18-10.pdf>Proceedings of the Workshop on Generalization in the Age of Deep Learning</a></h2><p class=lead><a href=/people/y/yonatan-bisk/>Yonatan Bisk</a>,
<a href=/people/o/omer-levy/>Omer Levy</a>,
<a href=/people/m/mark-yatskar/>Mark Yatskar</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>W18-10</dd><dt>Month:</dt><dd>June</dd><dt>Year:</dt><dd>2018</dd><dt>Address:</dt><dd>New Orleans, Louisiana</dd><dt>Venues:</dt><dd><a href=/venues/gendeep/>Gen-Deep</a>
| <a href=/venues/naacl/>NAACL</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/W18-10>https://aclanthology.org/W18-10</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/W18-10 title="To the current version of the paper by DOI">10.18653/v1/W18-10</a></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/W18-10.pdf>https://aclanthology.org/W18-10.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/W18-10.pdf title="Open PDF of 'Proceedings of the Workshop on Generalization in the Age of Deep Learning'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+Workshop+on+Generalization+in+the+Age+of+Deep+Learning" title="Search for 'Proceedings of the Workshop on Generalization in the Age of Deep Learning' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-1000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-1000/>Proceedings of the Workshop on Generalization in the Age of Deep Learning</a></strong><br><a href=/people/y/yonatan-bisk/>Yonatan Bisk</a>
|
<a href=/people/o/omer-levy/>Omer Levy</a>
|
<a href=/people/m/mark-yatskar/>Mark Yatskar</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-1002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-1002 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-1002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-1002/>Commonsense mining as knowledge base completion? A study on the impact of <a href=https://en.wikipedia.org/wiki/Novelty>novelty</a></a></strong><br><a href=/people/s/stanislaw-jastrzebski/>Stanislaw Jastrzębski</a>
|
<a href=/people/d/dzmitry-bahdanau/>Dzmitry Bahdanau</a>
|
<a href=/people/s/seyedarian-hosseini/>Seyedarian Hosseini</a>
|
<a href=/people/m/michael-noukhovitch/>Michael Noukhovitch</a>
|
<a href=/people/y/yoshua-bengio/>Yoshua Bengio</a>
|
<a href=/people/j/jackie-chi-kit-cheung/>Jackie Cheung</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-1002><div class="card-body p-3 small">Commonsense knowledge bases such as <a href=https://en.wikipedia.org/wiki/ConceptNet>ConceptNet</a> represent knowledge in the form of relational triples. Inspired by recent work by Li et al., we analyse if knowledge base completion models can be used to mine <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a> from raw text. We propose novelty of predicted triples with respect to the training set as an important factor in interpreting results. We critically analyse the difficulty of mining novel commonsense knowledge, and show that a simple baseline method that outperforms the previous state of the art on predicting more novel triples.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-1003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-1003 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-1003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-1003/>Deep learning evaluation using <a href=https://en.wikipedia.org/wiki/Deep_linguistic_processing>deep linguistic processing</a></a></strong><br><a href=/people/a/alexander-kuhnle/>Alexander Kuhnle</a>
|
<a href=/people/a/ann-copestake/>Ann Copestake</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-1003><div class="card-body p-3 small">We discuss problems with the standard approaches to evaluation for tasks like visual question answering, and argue that artificial data can be used to address these as a complement to current practice. We demonstrate that with the help of existing &#8216;deep&#8217; linguistic processing technology we are able to create challenging abstract datasets, which enable us to investigate the language understanding abilities of multimodal deep learning models in detail, as compared to a single performance value on a static and monolithic dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-1004.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-1004 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-1004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W18-1004" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W18-1004/>The Fine Line between Linguistic Generalization and Failure in Seq2Seq-Attention Models<span class=acl-fixed-case>S</span>eq2<span class=acl-fixed-case>S</span>eq-Attention Models</a></strong><br><a href=/people/n/noah-weber/>Noah Weber</a>
|
<a href=/people/l/leena-shekhar/>Leena Shekhar</a>
|
<a href=/people/n/niranjan-balasubramanian/>Niranjan Balasubramanian</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-1004><div class="card-body p-3 small">Seq2Seq based neural architectures have become the go-to architecture to apply to sequence to sequence language tasks. Despite their excellent performance on these tasks, recent work has noted that these models typically do not fully capture the linguistic structure required to generalize beyond the dense sections of the data distribution (Ettinger et al., 2017), and as such, are likely to fail on examples from the tail end of the distribution (such as inputs that are noisy (Belinkov and Bisk, 2018), or of different length (Bentivogli et al., 2016)). In this paper we look at a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s ability to generalize on a simple symbol rewriting task with a clearly defined structure. We find that the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>&#8217;s ability to generalize this structure beyond the <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training distribution</a> depends greatly on the chosen random seed, even when performance on the test set remains the same. This finding suggests that <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s ability to capture generalizable structure is highly sensitive, and more so, this sensitivity may not be apparent when evaluating the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on standard test sets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-1005.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-1005 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-1005 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-1005/>Extrapolation in NLP<span class=acl-fixed-case>NLP</span></a></strong><br><a href=/people/j/jeff-mitchell/>Jeff Mitchell</a>
|
<a href=/people/p/pontus-stenetorp/>Pontus Stenetorp</a>
|
<a href=/people/p/pasquale-minervini/>Pasquale Minervini</a>
|
<a href=/people/s/sebastian-riedel/>Sebastian Riedel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-1005><div class="card-body p-3 small">We argue that <a href=https://en.wikipedia.org/wiki/Extrapolation>extrapolation</a> to unseen data will often be easier for <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> that capture global structures, rather than just maximise their local fit to the training data. We show that this is true for two popular <a href=https://en.wikipedia.org/wiki/Model_(person)>models</a> : the Decomposable Attention Model and <a href=https://en.wikipedia.org/wiki/Word2vec>word2vec</a>.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>