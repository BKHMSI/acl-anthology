<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Transactions of the Association for Computational Linguistics, Volume 7 - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Transactions of the Association for Computational Linguistics, Volume 7</h2><p class=lead><a href=/people/l/lillian-lee/>Lillian Lee</a>,
<a href=/people/m/mark-johnson/>Mark Johnson</a>,
<a href=/people/b/brian-roark/>Brian Roark</a>,
<a href=/people/a/ani-nenkova/>Ani Nenkova</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>Q19-1</dd><dt>Month:</dt><dd></dd><dt>Year:</dt><dd>2019</dd><dt>Address:</dt><dd>Cambridge, MA</dd><dt>Venue:</dt><dd><a href=/venues/tacl/>TACL</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>MIT Press</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/Q19-1>https://aclanthology.org/Q19-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Transactions+of+the+Association+for+Computational+Linguistics%2C+Volume+7" title="Search for 'Transactions of the Association for Computational Linguistics, Volume 7' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/Q19-1000/>Transactions of the Association for Computational Linguistics, Volume 7</a></strong><br><a href=/people/l/lillian-lee/>Lillian Lee</a>
|
<a href=/people/m/mark-johnson/>Mark Johnson</a>
|
<a href=/people/b/brian-roark/>Brian Roark</a>
|
<a href=/people/a/ani-nenkova/>Ani Nenkova</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q19-1002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q19-1002 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q19-1002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q19-1002" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/Q19-1002/>Semantic Neural Machine Translation Using AMR<span class=acl-fixed-case>AMR</span></a></strong><br><a href=/people/l/linfeng-song/>Linfeng Song</a>
|
<a href=/people/d/daniel-gildea/>Daniel Gildea</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a>
|
<a href=/people/z/zhiguo-wang/>Zhiguo Wang</a>
|
<a href=/people/j/jinsong-su/>Jinsong Su</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q19-1002><div class="card-body p-3 small">It is intuitive that semantic representations can be useful for <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, mainly because they can help in enforcing meaning preservation and handling data sparsity (many sentences correspond to one meaning) of <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation models</a>. On the other hand, little work has been done on leveraging <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> for neural machine translation (NMT). In this work, we study the usefulness of AMR (abstract meaning representation) on NMT. Experiments on a standard English-to-German dataset show that incorporating AMR as additional knowledge can significantly improve a strong attention-based sequence-to-sequence neural translation model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q19-1003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q19-1003 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q19-1003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384777366 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/Q19-1003/>Joint Transition-Based Models for Morpho-Syntactic Parsing : Parsing Strategies for MRLs and a Case Study from Modern Hebrew<span class=acl-fixed-case>MRL</span>s and a Case Study from <span class=acl-fixed-case>M</span>odern <span class=acl-fixed-case>H</span>ebrew</a></strong><br><a href=/people/a/amir-more/>Amir More</a>
|
<a href=/people/a/amit-seker/>Amit Seker</a>
|
<a href=/people/v/victoria-basmova/>Victoria Basmova</a>
|
<a href=/people/r/reut-tsarfaty/>Reut Tsarfaty</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q19-1003><div class="card-body p-3 small">In standard NLP pipelines, morphological analysis and disambiguation (MA&D) precedes syntactic and semantic downstream tasks. However, for <a href=https://en.wikipedia.org/wiki/Language>languages</a> with complex and ambiguous word-internal structure, known as morphologically rich languages (MRLs), it has been hypothesized that <a href=https://en.wikipedia.org/wiki/Context_(language_use)>syntactic context</a> may be crucial for accurate MA&D, and vice versa. In this work we empirically confirm this hypothesis for Modern <a href=https://en.wikipedia.org/wiki/Hebrew_language>Hebrew</a>, an <a href=https://en.wikipedia.org/wiki/Modern_Hebrew_grammar>MRL</a> with complex morphology and severe word-level ambiguity, in a novel transition-based framework. Specifically, we propose a joint morphosyntactic transition-based framework which formally unifies two distinct transition systems, morphological and syntactic, into a single transition-based system with joint training and joint inference. We empirically show that MA&D results obtained in the joint settings outperform MA&D results obtained by the respective standalone components, and that end-to-end parsing results obtained by our joint system present a new state of the art for Hebrew dependency parsing.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q19-1006.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q19-1006 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q19-1006 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385255892 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q19-1006" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/Q19-1006/>Synchronous Bidirectional Neural Machine Translation</a></strong><br><a href=/people/l/long-zhou/>Long Zhou</a>
|
<a href=/people/j/jiajun-zhang/>Jiajun Zhang</a>
|
<a href=/people/c/chengqing-zong/>Chengqing Zong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q19-1006><div class="card-body p-3 small">Existing approaches to neural machine translation (NMT) generate the target language sequence token-by-token from left to right. However, this kind of unidirectional decoding framework can not make full use of the target-side future contexts which can be produced in a right-to-left decoding direction, and thus suffers from the issue of unbalanced outputs. In this paper, we introduce a synchronous bidirectionalneural machine translation (SB-NMT) that predicts its outputs using left-to-right and right-to-left decoding simultaneously and interactively, in order to leverage both of the history and future information at the same time. Specifically, we first propose a new <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> that enables synchronous bidirectional decoding in a single model. Then, we present an interactive decoding model in which left-to-right (right-to-left) generation does not only depend on its previously generated outputs, but also relies on future contexts predicted by right-to-left (left-to-right) decoding. We extensively evaluate the proposed SB-NMT model on large-scale NIST ChineseEnglish, WMT14 EnglishGerman, and WMT18 RussianEnglish translation tasks. Experimental results demonstrate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves significant improvements over the strong Transformer model by 3.92, 1.49, and 1.04 BLEU points, respectively, and obtains the state-of-the-art performance on ChineseEnglish and EnglishGerman translation tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q19-1009.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q19-1009 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q19-1009 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q19-1009" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/Q19-1009/>GILE : A Generalized Input-Label Embedding for Text Classification<span class=acl-fixed-case>GILE</span>: A Generalized Input-Label Embedding for Text Classification</a></strong><br><a href=/people/n/nikolaos-pappas/>Nikolaos Pappas</a>
|
<a href=/people/j/james-henderson/>James Henderson</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q19-1009><div class="card-body p-3 small">Neural text classification models typically treat output labels as <a href=https://en.wikipedia.org/wiki/Categorical_variable>categorical variables</a> that lack description and semantics. This forces their parametrization to be dependent on the label set size, and, hence, they are unable to scale to large label sets and generalize to unseen ones. Existing joint input-label text models overcome these issues by exploiting label descriptions, but they are unable to capture complex label relationships, have rigid parametrization, and their gains on unseen labels happen often at the expense of weak performance on the labels seen during training. In this paper, we propose a new input-label model that generalizes over previous such models, addresses their limitations, and does not compromise performance on seen labels. The model consists of a joint nonlinear input-label embedding with controllable capacity and a joint-space-dependent classification unit that is trained with cross-entropy loss to optimize <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> performance. We evaluate models on full-resource and low- or zero-resource text classification of multilingual news and biomedical text with a large label set. Our model outperforms monolingual and multilingual models that do not leverage label semantics and previous joint input-label space models in both scenarios.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q19-1010.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q19-1010 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q19-1010 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/Q19-1010/>Autosegmental Input Strictly Local Functions</a></strong><br><a href=/people/j/jane-chandlee/>Jane Chandlee</a>
|
<a href=/people/a/adam-jardine/>Adam Jardine</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q19-1010><div class="card-body p-3 small">Autosegmental representations (ARs ; Goldsmith, 1976) are claimed to enable local analyses of otherwise non-local phenomena Odden (1994). Focusing on the domain of tone, we investigate this ability of ARs using a computationally well-defined notion of <a href=https://en.wikipedia.org/wiki/Locality_of_reference>locality</a> extended from Chandlee (2014). The result is a more nuanced understanding of the way in which ARs interact with <a href=https://en.wikipedia.org/wiki/Locality_(linguistics)>phonological locality</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q19-1011.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q19-1011 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q19-1011 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/Q19-1011.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384478902 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q19-1011" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/Q19-1011/>SECTOR : A Neural Model for Coherent Topic Segmentation and Classification<span class=acl-fixed-case>SECTOR</span>: A Neural Model for Coherent Topic Segmentation and Classification</a></strong><br><a href=/people/s/sebastian-arnold/>Sebastian Arnold</a>
|
<a href=/people/r/rudolf-schneider/>Rudolf Schneider</a>
|
<a href=/people/p/philippe-cudre-mauroux/>Philippe Cudré-Mauroux</a>
|
<a href=/people/f/felix-a-gers/>Felix A. Gers</a>
|
<a href=/people/a/alexander-loser/>Alexander Löser</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q19-1011><div class="card-body p-3 small">When searching for information, a human reader first glances over a document, spots relevant sections, and then focuses on a few sentences for resolving her intention. However, the high variance of document structure complicates the identification of the salient topic of a given section at a glance. To tackle this challenge, we present SECTOR, a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to support machine reading systems by segmenting documents into coherent sections and assigning topic labels to each section. Our deep neural network architecture learns a latent topic embedding over the course of a document. This can be leveraged to classify local topics from plain text and segment a document at topic shifts. In addition, we contribute WikiSection, a publicly available data set with 242k labeled sections in <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/German_language>German</a> from two distinct domains : <a href=https://en.wikipedia.org/wiki/Disease>diseases</a> and cities. From our extensive evaluation of 20 architectures, we report a highest score of 71.6 % F1 for the segmentation and classification of 30 topics from the English city domain, scored by our SECTOR long short-term memory model with <a href=https://en.wikipedia.org/wiki/Bloom_filter>Bloom filter embeddings</a> and bidirectional segmentation. This is a significant improvement of 29.5 points F1 over state-of-the-art CNN classifiers with baseline segmentation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q19-1012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q19-1012 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q19-1012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/Q19-1012/>Complex Program Induction for Querying Knowledge Bases in the Absence of Gold Programs</a></strong><br><a href=/people/a/amrita-saha/>Amrita Saha</a>
|
<a href=/people/g/ghulam-ahmed-ansari/>Ghulam Ahmed Ansari</a>
|
<a href=/people/a/abhishek-laddha/>Abhishek Laddha</a>
|
<a href=/people/k/karthik-sankaranarayanan/>Karthik Sankaranarayanan</a>
|
<a href=/people/s/soumen-chakrabarti/>Soumen Chakrabarti</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q19-1012><div class="card-body p-3 small">Recent years have seen increasingly complex question-answering on knowledge bases (KBQA) involving logical, quantitative, and comparative reasoning over KB subgraphs. Neural Program Induction (NPI) is a pragmatic approach toward modularizing the <a href=https://en.wikipedia.org/wiki/Automated_reasoning>reasoning process</a> by translating a complex <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language query</a> into a multi-step executable program. While NPI has been commonly trained with the &#8216;&#8216;gold&#8217;&#8217; program or its sketch, for realistic KBQA applications such gold programs are expensive to obtain. There, practically only <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language queries</a> and the corresponding answers can be provided for training. The resulting combinatorial explosion in program space, along with extremely sparse rewards, makes <a href=https://en.wikipedia.org/wiki/Non-blocking_algorithm>NPI</a> for KBQA ambitious and challenging. We present Complex Imperative Program Induction from Terminal Rewards (CIPITR), an advanced neural programmer that mitigates reward sparsity with auxiliary rewards, and restricts the program space to semantically correct programs using high-level constraints, KB schema, and inferred answer type. CIPITR solves complex KBQA considerably more accurately than key-value memory networks and neural symbolic machines (NSM). For moderately complex queries requiring 2- to 5-step programs, CIPITR scores at least 3 higher F1 than the competing systems. On one of the hardest class of programs (comparative reasoning) with 510 steps, CIPITR outperforms NSM by a factor of 89 and memory networks by 9 times.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q19-1014.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q19-1014 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q19-1014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/Q19-1014/>DREAM : A Challenge Data Set and Models for Dialogue-Based Reading Comprehension<span class=acl-fixed-case>DREAM</span>: A Challenge Data Set and Models for Dialogue-Based Reading Comprehension</a></strong><br><a href=/people/k/kai-sun/>Kai Sun</a>
|
<a href=/people/d/dian-yu/>Dian Yu</a>
|
<a href=/people/j/jianshu-chen/>Jianshu Chen</a>
|
<a href=/people/d/dong-yu/>Dong Yu</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q19-1014><div class="card-body p-3 small">We present <a href=https://en.wikipedia.org/wiki/DREAM>DREAM</a>, the first dialogue-based multiple-choice reading comprehension data set. Collected from English as a Foreign Language examinations designed by human experts to evaluate the comprehension level of Chinese learners of English, our <a href=https://en.wikipedia.org/wiki/Data_set>data set</a> contains 10,197 <a href=https://en.wikipedia.org/wiki/Multiple_choice>multiple-choice questions</a> for 6,444 dialogues. In contrast to existing reading comprehension data sets, DREAM is the first to focus on in-depth multi-turn multi-party dialogue understanding. DREAM is likely to present significant challenges for existing reading comprehension systems : 84 % of answers are non-extractive, 85 % of questions require reasoning beyond a single sentence, and 34 % of questions also involve commonsense knowledge. We apply several popular neural reading comprehension models that primarily exploit surface information within the text and find them to, at best, just barely outperform a rule-based approach. We next investigate the effects of incorporating dialogue structure and different kinds of general world knowledge into both rule-based and (neural and non-neural) machine learning-based reading comprehension models. Experimental results on the DREAM data set show the effectiveness of dialogue structure and <a href=https://en.wikipedia.org/wiki/General_knowledge>general world knowledge</a>. DREAM is available at https://dataset.org/dream/.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q19-1022.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q19-1022 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q19-1022 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384772555 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q19-1022" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/Q19-1022/>Syntax-aware Semantic Role Labeling without Parsing</a></strong><br><a href=/people/r/rui-cai/>Rui Cai</a>
|
<a href=/people/m/mirella-lapata/>Mirella Lapata</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q19-1022><div class="card-body p-3 small">In this paper we focus on learning dependency aware representations for <a href=https://en.wikipedia.org/wiki/Semantic_role_labeling>semantic role labeling</a> without recourse to an external <a href=https://en.wikipedia.org/wiki/Parsing>parser</a>. The backbone of our model is an LSTM-based semantic role labeler jointly trained with two auxiliary tasks : predicting the dependency label of a word and whether there exists an arc linking it to the predicate. The auxiliary tasks provide syntactic information that is specific to <a href=https://en.wikipedia.org/wiki/Semantic_role_labeling>semantic role labeling</a> and are learned from training data (dependency annotations) without relying on existing dependency parsers, which can be noisy (e.g., on out-of-domain data or infrequent constructions). Experimental results on the CoNLL-2009 benchmark dataset show that our model outperforms the state of the art in <a href=https://en.wikipedia.org/wiki/English_language>English</a>, and consistently improves performance in other languages, including <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>, <a href=https://en.wikipedia.org/wiki/German_language>German</a>, and <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q19-1025.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q19-1025 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q19-1025 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384772326 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/Q19-1025/>No Word is an IslandA Transformation Weighting Model for Semantic Composition<span class=acl-fixed-case>I</span>sland—<span class=acl-fixed-case>A</span> Transformation Weighting Model for Semantic Composition</a></strong><br><a href=/people/c/corina-dima/>Corina Dima</a>
|
<a href=/people/d/daniel-de-kok/>Daniël de Kok</a>
|
<a href=/people/n/neele-witte/>Neele Witte</a>
|
<a href=/people/e/erhard-hinrichs/>Erhard Hinrichs</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q19-1025><div class="card-body p-3 small">Composition models of <a href=https://en.wikipedia.org/wiki/Distributional_semantics>distributional semantics</a> are used to construct phrase representations from the representations of their words. Composition models are typically situated on two ends of a spectrum. They either have a small number of parameters but compose all phrases in the same way, or they perform word-specific compositions at the cost of a far larger number of parameters. In this paper we propose transformation weighting (TransWeight), a composition model that consistently outperforms existing models on nominal compounds, adjective-noun phrases, and adverb-adjective phrases in <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/German_language>German</a>, and <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch</a>. TransWeight drastically reduces the number of parameters needed compared with the best <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> in the literature by composing similar words in the same way.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>