<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/2020.emnlp-main.pdf>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></h2><p class=lead><a href=/people/b/bonnie-webber/>Bonnie Webber</a>,
<a href=/people/t/trevor-cohn/>Trevor Cohn</a>,
<a href=/people/y/yulan-he/>Yulan He</a>,
<a href=/people/y/yang-liu-icsi/>Yang Liu</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2020.emnlp-main</dd><dt>Month:</dt><dd>November</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Online</dd><dt>Venue:</dt><dd><a href=/venues/emnlp/>EMNLP</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.emnlp-main>https://aclanthology.org/2020.emnlp-main</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2020.emnlp-main.pdf>https://aclanthology.org/2020.emnlp-main.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2020.emnlp-main.pdf title="Open PDF of 'Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+2020+Conference+on+Empirical+Methods+in+Natural+Language+Processing+%28EMNLP%29" title="Search for 'Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.0/>Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></strong><br><a href=/people/b/bonnie-webber/>Bonnie Webber</a>
|
<a href=/people/t/trevor-cohn/>Trevor Cohn</a>
|
<a href=/people/y/yulan-he/>Yulan He</a>
|
<a href=/people/y/yang-liu-icsi/>Yang Liu</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939172 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.3" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.3/>Quantitative argument summarization and beyond : Cross-domain key point analysis</a></strong><br><a href=/people/r/roy-bar-haim/>Roy Bar-Haim</a>
|
<a href=/people/y/yoav-kantor/>Yoav Kantor</a>
|
<a href=/people/l/lilach-eden/>Lilach Eden</a>
|
<a href=/people/r/roni-friedman/>Roni Friedman</a>
|
<a href=/people/d/dan-lahav/>Dan Lahav</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--3><div class="card-body p-3 small">When summarizing a collection of views, arguments or opinions on some topic, it is often desirable not only to extract the most salient points, but also to quantify their prevalence. Work on <a href=https://en.wikipedia.org/wiki/Multi-document_summarization>multi-document summarization</a> has traditionally focused on creating textual summaries, which lack this quantitative aspect. Recent work has proposed to summarize arguments by mapping them to a small set of expert-generated key points, where the salience of each key point corresponds to the number of its matching arguments. The current work advances key point analysis in two important respects : first, we develop a method for automatic extraction of key points, which enables fully automatic analysis, and is shown to achieve performance comparable to a human expert. Second, we demonstrate that the applicability of key point analysis goes well beyond <a href=https://en.wikipedia.org/wiki/Argumentation_theory>argumentation data</a>. Using <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained on publicly available argumentation datasets, we achieve promising results in two additional domains : <a href=https://en.wikipedia.org/wiki/Survey_methodology>municipal surveys</a> and <a href=https://en.wikipedia.org/wiki/User_review>user reviews</a>. An additional contribution is an in-depth evaluation of argument-to-key point matching models, where we substantially outperform previous results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938647 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.5" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.5/>BLEU might be Guilty but References are not Innocent<span class=acl-fixed-case>BLEU</span> might be Guilty but References are not Innocent</a></strong><br><a href=/people/m/markus-freitag/>Markus Freitag</a>
|
<a href=/people/d/david-grangier/>David Grangier</a>
|
<a href=/people/i/isaac-caswell/>Isaac Caswell</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--5><div class="card-body p-3 small">The quality of automatic metrics for <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> has been increasingly called into question, especially for high-quality systems. This paper demonstrates that, while choice of metric is important, the nature of the references is also critical. We study different methods to collect references and compare their value in automated evaluation by reporting correlation with human evaluation for a variety of systems and metrics. Motivated by the finding that typical references exhibit poor diversity, concentrating around translationese language, we develop a paraphrasing task for linguists to perform on existing reference translations, which counteracts this bias. Our method yields higher correlation with human judgment not only for the submissions of WMT 2019 English to <a href=https://en.wikipedia.org/wiki/German_language>German</a>, but also for <a href=https://en.wikipedia.org/wiki/Back-translation>Back-translation</a> and APE augmented MT output, which have been shown to have low correlation with automatic metrics using standard references. We demonstrate that our methodology improves <a href=https://en.wikipedia.org/wiki/Correlation_and_dependence>correlation</a> with all modern evaluation metrics we look at, including embedding-based methods. To complete this picture, we reveal that multi-reference BLEU does not improve the <a href=https://en.wikipedia.org/wiki/Correlation_and_dependence>correlation</a> for high quality output, and present an alternative multi-reference formulation that is more effective.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938786 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.7/>Simulated multiple reference training improves low-resource machine translation</a></strong><br><a href=/people/h/huda-khayrallah/>Huda Khayrallah</a>
|
<a href=/people/b/brian-thompson/>Brian Thompson</a>
|
<a href=/people/m/matt-post/>Matt Post</a>
|
<a href=/people/p/philipp-koehn/>Philipp Koehn</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--7><div class="card-body p-3 small">Many valid translations exist for a given sentence, yet <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation (MT)</a> is trained with a single reference translation, exacerbating data sparsity in low-resource settings. We introduce Simulated Multiple Reference Training (SMRT), a novel MT training method that approximates the full space of possible translations by sampling a <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrase</a> of the reference sentence from a <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphraser</a> and training the MT model to predict the <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphraser&#8217;s distribution</a> over possible tokens. We demonstrate the effectiveness of <a href=https://en.wikipedia.org/wiki/Speech-language_pathology>SMRT</a> in low-resource settings when translating to <a href=https://en.wikipedia.org/wiki/English_language>English</a>, with improvements of 1.2 to 7.0 BLEU. We also find SMRT is complementary to <a href=https://en.wikipedia.org/wiki/Back-translation>back-translation</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.8.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--8 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.8 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938798 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.8" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.8/>Automatic Machine Translation Evaluation in Many Languages via Zero-Shot Paraphrasing</a></strong><br><a href=/people/b/brian-thompson/>Brian Thompson</a>
|
<a href=/people/m/matt-post/>Matt Post</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--8><div class="card-body p-3 small">We frame the task of machine translation evaluation as one of scoring machine translation output with a sequence-to-sequence paraphraser, conditioned on a human reference. We propose training the <a href=https://en.wikipedia.org/wiki/Paraphraser>paraphraser</a> as a multilingual NMT system, treating <a href=https://en.wikipedia.org/wiki/Paraphrasing>paraphrasing</a> as a zero-shot translation task (e.g., <a href=https://en.wikipedia.org/wiki/Czech_language>Czech</a> to <a href=https://en.wikipedia.org/wiki/Czech_language>Czech</a>). This results in the <a href=https://en.wikipedia.org/wiki/Paraphraser>paraphraser</a>&#8217;s output mode being centered around a copy of the input sequence, which represents the best case scenario where the MT system output matches a human reference. Our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> is simple and intuitive, and does not require human judgements for training. Our single <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> (trained in 39 languages) outperforms or statistically ties with all prior metrics on the WMT 2019 segment-level shared metrics task in all languages (excluding <a href=https://en.wikipedia.org/wiki/Gujarati_language>Gujarati</a> where the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> had no training data). We also explore using our model for the task of <a href=https://en.wikipedia.org/wiki/Quality_assurance>quality estimation</a> as a metricconditioning on the source instead of the referenceand find that it significantly outperforms every submission to the WMT 2019 shared task on <a href=https://en.wikipedia.org/wiki/Quality_assurance>quality estimation</a> in every language pair.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.11.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939163 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.11/>Self-Supervised Knowledge Triplet Learning for Zero-Shot Question Answering</a></strong><br><a href=/people/p/pratyay-banerjee/>Pratyay Banerjee</a>
|
<a href=/people/c/chitta-baral/>Chitta Baral</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--11><div class="card-body p-3 small">The aim of all Question Answering (QA) systems is to generalize to unseen questions. Current supervised methods are reliant on expensive data annotation. Moreover, such annotations can introduce unintended annotator bias, making systems focus more on the bias than the actual task. This work proposes Knowledge Triplet Learning (KTL), a self-supervised task over <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graphs</a>. We propose <a href=https://en.wikipedia.org/wiki/Heuristic>heuristics</a> to create synthetic graphs for commonsense and scientific knowledge. We propose using KTL to perform zero-shot question answering, and our experiments show considerable improvements over large pre-trained transformer language models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939179 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.12/>More Bang for Your Buck : Natural Perturbation for Robust Question Answering</a></strong><br><a href=/people/d/daniel-khashabi/>Daniel Khashabi</a>
|
<a href=/people/t/tushar-khot/>Tushar Khot</a>
|
<a href=/people/a/ashish-sabharwal/>Ashish Sabharwal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--12><div class="card-body p-3 small">Deep learning models for <a href=https://en.wikipedia.org/wiki/Linguistic_description>linguistic tasks</a> require <a href=https://en.wikipedia.org/wiki/Big_data>large training datasets</a>, which are expensive to create. As an alternative to the traditional approach of creating new instances by repeating the process of creating one instance, we propose doing so by first collecting a set of seed examples and then applying human-driven natural perturbations (as opposed to rule-based machine perturbations), which often change the gold label as well. Such <a href=https://en.wikipedia.org/wiki/Perturbation_theory_(quantum_mechanics)>perturbations</a> have the advantage of being relatively easier (and hence cheaper) to create than writing out completely new examples. Further, they help address the issue that even <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> achieving human-level scores on NLP datasets are known to be considerably sensitive to small changes in input. To evaluate the idea, we consider a recent question-answering dataset (BOOLQ) and study our approach as a function of the perturbation cost ratio, the relative cost of perturbing an existing question vs. creating a new one from scratch. We find that when natural perturbations are moderately cheaper to create (cost ratio under 60 %), it is more effective to use them for training BOOLQ models : such <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> exhibit 9 % higher robustness and 4.5 % stronger <a href=https://en.wikipedia.org/wiki/Generalization>generalization</a>, while retaining performance on the original BOOLQ dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938809 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.14" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.14/>Information-Theoretic Probing with Minimum Description Length</a></strong><br><a href=/people/e/elena-voita/>Elena Voita</a>
|
<a href=/people/i/ivan-titov/>Ivan Titov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--14><div class="card-body p-3 small">To measure how well pretrained representations encode some linguistic property, it is common to use <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of a probe, i.e. a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> trained to predict the property from the <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representations</a>. Despite widespread adoption of <a href=https://en.wikipedia.org/wiki/Sensor>probes</a>, differences in their <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> fail to adequately reflect differences in <a href=https://en.wikipedia.org/wiki/Mental_representation>representations</a>. For example, they do not substantially favour pretrained representations over randomly initialized ones. Analogously, their <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> can be similar when probing for genuine linguistic labels and probing for random synthetic tasks. To see reasonable differences in <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> with respect to these random baselines, previous work had to constrain either the amount of probe training data or its model size. Instead, we propose an alternative to the standard probes, information-theoretic probing with minimum description length (MDL). With MDL probing, training a probe to predict labels is recast as teaching it to effectively transmit the data. Therefore, the measure of interest changes from probe accuracy to the description length of labels given representations. In addition to probe quality, the description length evaluates the amount of effort needed to achieve the quality. This amount of effort characterizes either (i) size of a probing model, or (ii) the amount of data needed to achieve the high quality. We consider two methods for estimating MDL which can be easily implemented on top of the standard probing pipelines : variational coding and online coding. We show that these <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> agree in results and are more informative and stable than the standard probes.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938801 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.17/>Repulsive Attention : Rethinking Multi-head Attention as <a href=https://en.wikipedia.org/wiki/Bayesian_inference>Bayesian Inference</a><span class=acl-fixed-case>B</span>ayesian Inference</a></strong><br><a href=/people/b/bang-an/>Bang An</a>
|
<a href=/people/j/jie-lyu/>Jie Lyu</a>
|
<a href=/people/z/zhenyi-wang/>Zhenyi Wang</a>
|
<a href=/people/c/chunyuan-li/>Chunyuan Li</a>
|
<a href=/people/c/changwei-hu/>Changwei Hu</a>
|
<a href=/people/f/fei-tan/>Fei Tan</a>
|
<a href=/people/r/ruiyi-zhang/>Ruiyi Zhang</a>
|
<a href=/people/y/yifan-hu/>Yifan Hu</a>
|
<a href=/people/c/changyou-chen/>Changyou Chen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--17><div class="card-body p-3 small">The neural attention mechanism plays an important role in many <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing applications</a>. In particular, multi-head attention extends single-head attention by allowing a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to jointly attend information from different perspectives. However, without explicit constraining, multi-head attention may suffer from attention collapse, an issue that makes different heads extract similar attentive features, thus limiting the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model&#8217;s representation power</a>. In this paper, for the first time, we provide a novel understanding of multi-head attention from a <a href=https://en.wikipedia.org/wiki/Bayesian_inference>Bayesian perspective</a>. Based on the recently developed particle-optimization sampling techniques, we propose a non-parametric approach that explicitly improves the repulsiveness in multi-head attention and consequently strengthens <a href=https://en.wikipedia.org/wiki/Mathematical_model>model&#8217;s expressiveness</a>. Remarkably, our Bayesian interpretation provides theoretical inspirations on the not-well-understood questions : why and how one uses multi-head attention. Extensive experiments on various attention models and applications demonstrate that the proposed repulsive attention can improve the learned feature diversity, leading to more informative representations with consistent performance improvement on multiple tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.18.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--18 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.18 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938864 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.18" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.18/>KERMIT : Complementing Transformer Architectures with Encoders of Explicit Syntactic Interpretations<span class=acl-fixed-case>KERMIT</span>: Complementing Transformer Architectures with Encoders of Explicit Syntactic Interpretations</a></strong><br><a href=/people/f/fabio-massimo-zanzotto/>Fabio Massimo Zanzotto</a>
|
<a href=/people/a/andrea-santilli/>Andrea Santilli</a>
|
<a href=/people/l/leonardo-ranaldi/>Leonardo Ranaldi</a>
|
<a href=/people/d/dario-onorati/>Dario Onorati</a>
|
<a href=/people/p/pierfrancesco-tommasino/>Pierfrancesco Tommasino</a>
|
<a href=/people/f/francesca-fallucchi/>Francesca Fallucchi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--18><div class="card-body p-3 small">Syntactic parsers have dominated <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a> for decades. Yet, their syntactic interpretations are losing centrality in downstream tasks due to the success of large-scale textual representation learners. In this paper, we propose KERMIT (Kernel-inspired Encoder with Recursive Mechanism for Interpretable Trees) to embed symbolic syntactic parse trees into artificial neural networks and to visualize how <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a> is used in <a href=https://en.wikipedia.org/wiki/Inference>inference</a>. We experimented with KERMIT paired with two state-of-the-art transformer-based universal sentence encoders (BERT and XLNet) and we showed that KERMIT can indeed boost their performance by effectively embedding human-coded universal syntactic representations in neural networks</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.26.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--26 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.26 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938866 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.26" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.26/>Incremental Processing in the Age of Non-Incremental Encoders : An Empirical Assessment of Bidirectional Models for Incremental NLU<span class=acl-fixed-case>NLU</span></a></strong><br><a href=/people/b/brielen-madureira/>Brielen Madureira</a>
|
<a href=/people/d/david-schlangen/>David Schlangen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--26><div class="card-body p-3 small">While humans process language incrementally, the best <a href=https://en.wikipedia.org/wiki/Encoder>language encoders</a> currently used in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> do not. Both bidirectional LSTMs and Transformers assume that the sequence that is to be encoded is available in full, to be processed either forwards and backwards (BiLSTMs) or as a whole (Transformers). We investigate how they behave under incremental interfaces, when partial output must be provided based on partial input seen up to a certain time step, which may happen in interactive systems. We test five <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on various NLU datasets and compare their performance using three incremental evaluation metrics. The results support the possibility of using bidirectional encoders in incremental mode while retaining most of their non-incremental quality. The omni-directional BERT model, which achieves better non-incremental performance, is impacted more by the incremental access. This can be alleviated by adapting the training regime (truncated training), or the testing procedure, by delaying the output until some right context is available or by incorporating hypothetical right contexts generated by a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> like GPT-2.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.28.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--28 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.28 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938970 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.28/>Dialogue Response Ranking Training with Large-Scale Human Feedback Data</a></strong><br><a href=/people/x/xiang-gao/>Xiang Gao</a>
|
<a href=/people/y/yizhe-zhang/>Yizhe Zhang</a>
|
<a href=/people/m/michel-galley/>Michel Galley</a>
|
<a href=/people/c/chris-brockett/>Chris Brockett</a>
|
<a href=/people/w/william-b-dolan/>Bill Dolan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--28><div class="card-body p-3 small">Existing open-domain dialog models are generally trained to minimize the perplexity of target human responses. However, some human replies are more engaging than others, spawning more followup interactions. Current conversational models are increasingly capable of producing turns that are context-relevant, but in order to produce compelling agents, these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> need to be able to predict and optimize for turns that are genuinely engaging. We leverage social media feedback data (number of replies and upvotes) to build a large-scale training dataset for feedback prediction. To alleviate possible distortion between the <a href=https://en.wikipedia.org/wiki/Feedback>feedback</a> and engagingness, we convert the ranking problem to a comparison of response pairs which involve few confounding factors. We trained DialogRPT, a set of GPT-2 based models on 133 M pairs of human feedback data and the resulting ranker outperformed several baselines. Particularly, our <a href=https://en.wikipedia.org/wiki/Ranker>ranker</a> outperforms the conventional dialog perplexity baseline with a large margin on predicting Reddit feedback. We finally combine the feedback prediction models and a human-like scoring model to rank the machine-generated dialog responses. Crowd-sourced human evaluation shows that our ranking method correlates better with real human preferences than baseline models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.31.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--31 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.31 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939351 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.31" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.31/>AutoQA : From Databases To QA Semantic Parsers With Only Synthetic Training Data<span class=acl-fixed-case>A</span>uto<span class=acl-fixed-case>QA</span>: From Databases To <span class=acl-fixed-case>QA</span> Semantic Parsers With Only Synthetic Training Data</a></strong><br><a href=/people/s/silei-xu/>Silei Xu</a>
|
<a href=/people/s/sina-semnani/>Sina Semnani</a>
|
<a href=/people/g/giovanni-campagna/>Giovanni Campagna</a>
|
<a href=/people/m/monica-lam/>Monica Lam</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--31><div class="card-body p-3 small">We propose AutoQA, a <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> and toolkit to generate semantic parsers that answer questions on databases, with no manual effort. Given a <a href=https://en.wikipedia.org/wiki/Database_schema>database schema</a> and its data, AutoQA automatically generates a large set of high-quality questions for training that covers different database operations. It uses <a href=https://en.wikipedia.org/wiki/Automatic_paraphrasing>automatic paraphrasing</a> combined with template-based parsing to find alternative expressions of an attribute in different <a href=https://en.wikipedia.org/wiki/Part_of_speech>parts of speech</a>. It also uses a novel filtered auto-paraphraser to generate correct <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrases</a> of entire sentences. We apply AutoQA to the Schema2QA dataset and obtain an average logical form accuracy of 62.9 % when tested on <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural questions</a>, which is only 6.4 % lower than a model trained with expert natural language annotations and paraphrase data collected from <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdworkers</a>. To demonstrate the generality of AutoQA, we also apply it to the Overnight dataset. AutoQA achieves 69.8 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>answer accuracy</a>, 16.4 % higher than the state-of-the-art zero-shot models and only 5.2 % lower than the same <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> trained with human data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.33.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--33 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.33 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938815 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.33" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.33/>What Have We Achieved on Text Summarization?</a></strong><br><a href=/people/d/dandan-huang/>Dandan Huang</a>
|
<a href=/people/l/leyang-cui/>Leyang Cui</a>
|
<a href=/people/s/sen-yang/>Sen Yang</a>
|
<a href=/people/g/guangsheng-bao/>Guangsheng Bao</a>
|
<a href=/people/k/kun-wang/>Kun Wang</a>
|
<a href=/people/j/jun-xie/>Jun Xie</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--33><div class="card-body p-3 small">Deep learning has led to significant improvement in <a href=https://en.wikipedia.org/wiki/Automatic_summarization>text summarization</a> with various methods investigated and improved ROUGE scores reported over the years. However, gaps still exist between summaries produced by <a href=https://en.wikipedia.org/wiki/Automatic_summarization>automatic summarizers</a> and human professionals. Aiming to gain more understanding of summarization systems with respect to their strengths and limits on a fine-grained syntactic and semantic level, we consult the Multidimensional Quality Metric (MQM) and quantify 8 major sources of errors on 10 representative summarization models manually. Primarily, we find that 1) under similar settings, extractive summarizers are in general better than their abstractive counterparts thanks to strength in faithfulness and factual-consistency ; 2) milestone techniques such as copy, coverage and hybrid extractive / abstractive methods do bring specific improvements but also demonstrate limitations ; 3) pre-training techniques, and in particular sequence-to-sequence pre-training, are highly effective for improving text summarization, with BART giving the best results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.34.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--34 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.34 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938716 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.34" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.34/>Q-learning with <a href=https://en.wikipedia.org/wiki/Language_model>Language Model</a> for Edit-based Unsupervised Summarization<span class=acl-fixed-case>Q</span>-learning with Language Model for Edit-based Unsupervised Summarization</a></strong><br><a href=/people/r/ryosuke-kohita/>Ryosuke Kohita</a>
|
<a href=/people/a/akifumi-wachi/>Akifumi Wachi</a>
|
<a href=/people/y/yang-zhao/>Yang Zhao</a>
|
<a href=/people/r/ryuki-tachibana/>Ryuki Tachibana</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--34><div class="card-body p-3 small">Unsupervised methods are promising for abstractive textsummarization in that the <a href=https://en.wikipedia.org/wiki/Parallel_text>parallel corpora</a> is not required. However, their performance is still far from being satisfied, therefore research on promising solutions is on-going. In this paper, we propose a new approach based on <a href=https://en.wikipedia.org/wiki/Q-learning>Q-learning</a> with an edit-based summarization. The method combines two key <a href=https://en.wikipedia.org/wiki/Modular_programming>modules</a> to form an Editorial Agent and Language Model converter (EALM). The <a href=https://en.wikipedia.org/wiki/Agency_(philosophy)>agent</a> predicts edit actions (e.t., delete, keep, and replace), and then the LM converter deterministically generates a summary on the basis of the action signals. Q-learning is leveraged to train the <a href=https://en.wikipedia.org/wiki/Intelligent_agent>agent</a> to produce proper edit actions. Experimental results show that EALM delivered competitive performance compared with the previous encoder-decoder-based methods, even with truly zero paired data (i.e., no validation set). Defining the task as <a href=https://en.wikipedia.org/wiki/Q-learning>Q-learning</a> enables us not only to develop a competitive method but also to make the latest techniques in <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a> available for unsupervised summarization. We also conduct <a href=https://en.wikipedia.org/wiki/Qualitative_research>qualitative analysis</a>, providing insights into future study on unsupervised summarizers.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.37.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--37 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.37 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939194 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.37" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.37/>TernaryBERT : Distillation-aware Ultra-low Bit BERT<span class=acl-fixed-case>T</span>ernary<span class=acl-fixed-case>BERT</span>: Distillation-aware Ultra-low Bit <span class=acl-fixed-case>BERT</span></a></strong><br><a href=/people/w/wei-zhang/>Wei Zhang</a>
|
<a href=/people/l/lu-hou/>Lu Hou</a>
|
<a href=/people/y/yichun-yin/>Yichun Yin</a>
|
<a href=/people/l/lifeng-shang/>Lifeng Shang</a>
|
<a href=/people/x/xiao-chen/>Xiao Chen</a>
|
<a href=/people/x/xin-jiang/>Xin Jiang</a>
|
<a href=/people/q/qun-liu/>Qun Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--37><div class="card-body p-3 small">Transformer-based pre-training models like <a href=https://en.wikipedia.org/wiki/BERT>BERT</a> have achieved remarkable performance in many natural language processing tasks. However, these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are both computation and memory expensive, hindering their deployment to resource-constrained devices. In this work, we propose TernaryBERT, which ternarizes the weights in a fine-tuned BERT model. Specifically, we use both approximation-based and loss-aware ternarization methods and empirically investigate the ternarization granularity of different parts of BERT. Moreover, to reduce the accuracy degradation caused by lower capacity of low bits, we leverage the knowledge distillation technique in the training process. Experiments on the GLUE benchmark and SQuAD show that our proposed TernaryBERT outperforms the other BERT quantization methods, and even achieves comparable performance as the full-precision model while being 14.9x smaller.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.38.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--38 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.38 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939198 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.38" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.38/>Self-Supervised Meta-Learning for Few-Shot Natural Language Classification Tasks</a></strong><br><a href=/people/t/trapit-bansal/>Trapit Bansal</a>
|
<a href=/people/r/rishikesh-jha/>Rishikesh Jha</a>
|
<a href=/people/t/tsendsuren-munkhdalai/>Tsendsuren Munkhdalai</a>
|
<a href=/people/a/andrew-mccallum/>Andrew McCallum</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--38><div class="card-body p-3 small">Self-supervised pre-training of transformer models has revolutionized NLP applications. Such pre-training with language modeling objectives provides a useful initial point for parameters that generalize well to new tasks with <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a>. However, <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> is still data inefficient when there are few labeled examples, <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> can be low. Data efficiency can be improved by optimizing pre-training directly for future <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> with few examples ; this can be treated as a meta-learning problem. However, standard meta-learning techniques require many training tasks in order to generalize ; unfortunately, finding a diverse set of such supervised tasks is usually difficult. This paper proposes a self-supervised approach to generate a large, rich, meta-learning task distribution from unlabeled text. This is achieved using a cloze-style objective, but creating separate multi-class classification tasks by gathering tokens-to-be blanked from among only a handful of vocabulary terms. This yields as many unique meta-training tasks as the number of subsets of vocabulary terms. We meta-train a transformer model on this distribution of tasks using a recent meta-learning framework. On 17 NLP tasks, we show that this meta-training leads to better few-shot generalization than language-model pre-training followed by <a href=https://en.wikipedia.org/wiki/Finetuning>finetuning</a>. Furthermore, we show how the self-supervised tasks can be combined with <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised tasks</a> for <a href=https://en.wikipedia.org/wiki/Meta-learning>meta-learning</a>, providing substantial accuracy gains over previous supervised meta-learning.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.39.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--39 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.39 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939206 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.39/>Efficient Meta Lifelong-Learning with Limited Memory</a></strong><br><a href=/people/z/zirui-wang/>Zirui Wang</a>
|
<a href=/people/s/sanket-vaibhav-mehta/>Sanket Vaibhav Mehta</a>
|
<a href=/people/b/barnabas-poczos/>Barnabas Poczos</a>
|
<a href=/people/j/jaime-g-carbonell/>Jaime Carbonell</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--39><div class="card-body p-3 small">Current <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language processing models</a> work well on a single <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, yet they often fail to continuously learn new tasks without forgetting previous ones as they are re-trained throughout their lifetime, a challenge known as <a href=https://en.wikipedia.org/wiki/Lifelong_learning>lifelong learning</a>. State-of-the-art lifelong language learning methods store past examples in <a href=https://en.wikipedia.org/wiki/Episodic_memory>episodic memory</a> and replay them at both training and inference time. However, as we show later in our experiments, there are three significant impediments : (1) needing unrealistically large memory module to achieve good performance, (2) suffering from negative transfer, (3) requiring multiple local adaptation steps for each test example that significantly slows down the inference speed. In this paper, we identify three common principles of lifelong learning methods and propose an efficient meta-lifelong framework that combines them in a synergistic fashion. To achieve sample efficiency, our method trains the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> in a manner that it learns a better initialization for local adaptation. Extensive experiments on text classification and question answering benchmarks demonstrate the effectiveness of our framework by achieving state-of-the-art performance using merely 1 % memory size and narrowing the gap with multi-task learning. We further show that our method alleviates both catastrophic forgetting and <a href=https://en.wikipedia.org/wiki/Negative_transfer>negative transfer</a> at the same time.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.40.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--40 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.40 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938787 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.40/>Do nt Use English Dev : On the Zero-Shot Cross-Lingual Evaluation of Contextual Embeddings<span class=acl-fixed-case>E</span>nglish Dev: On the Zero-Shot Cross-Lingual Evaluation of Contextual Embeddings</a></strong><br><a href=/people/p/phillip-keung/>Phillip Keung</a>
|
<a href=/people/y/yichao-lu/>Yichao Lu</a>
|
<a href=/people/j/julian-salazar/>Julian Salazar</a>
|
<a href=/people/v/vikas-bhardwaj/>Vikas Bhardwaj</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--40><div class="card-body p-3 small">Multilingual contextual embeddings have demonstrated state-of-the-art performance in zero-shot cross-lingual transfer learning, where multilingual BERT is fine-tuned on one source language and evaluated on a different target language. However, published results for mBERT zero-shot accuracy vary as much as 17 points on the MLDoc classification task across four papers. We show that the standard practice of using English dev accuracy for <a href=https://en.wikipedia.org/wiki/Model_selection>model selection</a> in the zero-shot setting makes it difficult to obtain reproducible results on the MLDoc and XNLI tasks. English dev accuracy is often uncorrelated (or even anti-correlated) with target language accuracy, and zero-shot performance varies greatly at different points in the same fine-tuning run and between different fine-tuning runs. These reproducibility issues are also present for other <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a> with different pre-trained embeddings (e.g., MLQA with XLM-R). We recommend providing oracle scores alongside zero-shot results : still fine-tune using English data, but choose a checkpoint with the target dev set. Reporting this upper bound makes results more consistent by avoiding arbitrarily bad checkpoints.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.41.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--41 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.41 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938923 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.41/>A Supervised Word Alignment Method based on Cross-Language Span Prediction using Multilingual BERT<span class=acl-fixed-case>BERT</span></a></strong><br><a href=/people/m/masaaki-nagata/>Masaaki Nagata</a>
|
<a href=/people/k/katsuki-chousa/>Katsuki Chousa</a>
|
<a href=/people/m/masaaki-nishino/>Masaaki Nishino</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--41><div class="card-body p-3 small">We present a novel supervised word alignment method based on cross-language span prediction. We first formalize a word alignment problem as a collection of independent predictions from a token in the source sentence to a span in the target sentence. Since this step is equivalent to a SQuAD v2.0 style question answering task, we solve it using the multilingual BERT, which is fine-tuned on manually created gold word alignment data. It is nontrivial to obtain accurate <a href=https://en.wikipedia.org/wiki/Sequence_alignment>alignment</a> from a set of independently predicted spans. We greatly improved the word alignment accuracy by adding to the question the source token&#8217;s context and symmetrizing two directional predictions. In experiments using five word alignment datasets from among <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>, <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a>, <a href=https://en.wikipedia.org/wiki/German_language>German</a>, <a href=https://en.wikipedia.org/wiki/Romanian_language>Romanian</a>, <a href=https://en.wikipedia.org/wiki/French_language>French</a>, and <a href=https://en.wikipedia.org/wiki/English_language>English</a>, we show that our proposed method significantly outperformed previous supervised and unsupervised word alignment methods without any bitexts for pretraining. For example, we achieved 86.7 <a href=https://en.wikipedia.org/wiki/F-number>F1 score</a> for the Chinese-English data, which is 13.3 points higher than the previous state-of-the-art <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised method</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.44.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--44 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.44 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938782 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.44" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.44/>Unsupervised Discovery of Implicit Gender Bias</a></strong><br><a href=/people/a/anjalie-field/>Anjalie Field</a>
|
<a href=/people/y/yulia-tsvetkov/>Yulia Tsvetkov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--44><div class="card-body p-3 small">Despite their prevalence in society, social biases are difficult to identify, primarily because <a href=https://en.wikipedia.org/wiki/Judgement>human judgements</a> in this domain can be unreliable. We take an <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised approach</a> to identifying gender bias against women at a comment level and present a model that can surface text likely to contain <a href=https://en.wikipedia.org/wiki/Bias>bias</a>. Our main challenge is forcing the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to focus on signs of <a href=https://en.wikipedia.org/wiki/Implicit_stereotype>implicit bias</a>, rather than other artifacts in the data. Thus, our <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> involves reducing the influence of <a href=https://en.wikipedia.org/wiki/Confounding>confounds</a> through propensity matching and <a href=https://en.wikipedia.org/wiki/Adversarial_learning>adversarial learning</a>. Our analysis shows how biased comments directed towards female politicians contain mixed criticisms, while comments directed towards other female public figures focus on <a href=https://en.wikipedia.org/wiki/Human_physical_appearance>appearance</a> and <a href=https://en.wikipedia.org/wiki/Sexualization>sexualization</a>. Ultimately, our work offers a way to capture subtle biases in various domains without relying on subjective human judgements.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.45.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--45 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.45 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939143 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.45/>Condolence and Empathy in <a href=https://en.wikipedia.org/wiki/Online_community>Online Communities</a></a></strong><br><a href=/people/n/naitian-zhou/>Naitian Zhou</a>
|
<a href=/people/d/david-jurgens/>David Jurgens</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--45><div class="card-body p-3 small">Offering condolence is a natural reaction to hearing someone&#8217;s distress. Individuals frequently express distress in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>, where some communities can provide support. However, not all <a href=https://en.wikipedia.org/wiki/Condolence>condolence</a> is equaltrite responses offer little actual support despite their good intentions. Here, we develop <a href=https://en.wikipedia.org/wiki/Computer>computational tools</a> to create a massive <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of 11.4 M expressions of distress and 2.8 M corresponding offerings of <a href=https://en.wikipedia.org/wiki/Condolences>condolence</a> in order to examine the dynamics of <a href=https://en.wikipedia.org/wiki/Condolences>condolence</a> online. Our study reveals widespread disparity in what types of distress receive supportive condolence rather than just engagement. Building on studies from <a href=https://en.wikipedia.org/wiki/Social_psychology>social psychology</a>, we analyze the language of condolence and develop a new dataset for quantifying the <a href=https://en.wikipedia.org/wiki/Empathy>empathy</a> in a <a href=https://en.wikipedia.org/wiki/Condolences>condolence</a> using appraisal theory. Finally, we demonstrate that the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> of condolence individuals find most helpful online differ substantially in their <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> from those seen in <a href=https://en.wikipedia.org/wiki/Interpersonal_relationship>interpersonal settings</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.49.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--49 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.49 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938649 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.49" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.49/>Event Extraction by Answering (Almost) Natural Questions</a></strong><br><a href=/people/x/xinya-du/>Xinya Du</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--49><div class="card-body p-3 small">The problem of <a href=https://en.wikipedia.org/wiki/Event_extraction>event extraction</a> requires detecting the event trigger and extracting its corresponding arguments. Existing work in event argument extraction typically relies heavily on <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity recognition</a> as a preprocessing / concurrent step, causing the well-known problem of <a href=https://en.wikipedia.org/wiki/Error_propagation>error propagation</a>. To avoid this issue, we introduce a new <a href=https://en.wikipedia.org/wiki/Paradigm>paradigm</a> for <a href=https://en.wikipedia.org/wiki/Event_extraction>event extraction</a> by formulating it as a question answering (QA) task that extracts the event arguments in an end-to-end manner. Empirical results demonstrate that our framework outperforms <a href=https://en.wikipedia.org/wiki/Prior_probability>prior methods</a> substantially ; in addition, it is capable of extracting <a href=https://en.wikipedia.org/wiki/Event_(probability_theory)>event arguments</a> for roles not seen at training time (i.e., in a zero-shot learning setting).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.50.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--50 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.50 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938669 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.50/>Connecting the Dots : Event Graph Schema Induction with Path Language Modeling</a></strong><br><a href=/people/m/manling-li/>Manling Li</a>
|
<a href=/people/q/qi-zeng/>Qi Zeng</a>
|
<a href=/people/y/ying-lin/>Ying Lin</a>
|
<a href=/people/k/kyunghyun-cho/>Kyunghyun Cho</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/n/nathanael-chambers/>Nathanael Chambers</a>
|
<a href=/people/c/clare-voss/>Clare Voss</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--50><div class="card-body p-3 small">Event schemas can guide our understanding and ability to make predictions with respect to what might happen next. We propose a new Event Graph Schema, where two event types are connected through multiple paths involving entities that fill important roles in a coherent story. We then introduce Path Language Model, an auto-regressive language model trained on event-event paths, and select salient and coherent paths to probabilistically construct these graph schemas. We design two evaluation metrics, instance coverage and instance coherence, to evaluate the quality of graph schema induction, by checking when coherent event instances are covered by the schema graph. Intrinsic evaluations show that our approach is highly effective at inducing salient and coherent schemas. Extrinsic evaluations show the induced schema repository provides significant improvement to downstream end-to-end Information Extraction over a state-of-the-art joint neural extraction model, when used as additional global features to unfold instance graphs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.51.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--51 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.51 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938847 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.51/>Joint Constrained Learning for Event-Event Relation Extraction</a></strong><br><a href=/people/h/haoyu-wang/>Haoyu Wang</a>
|
<a href=/people/m/muhao-chen/>Muhao Chen</a>
|
<a href=/people/h/hongming-zhang/>Hongming Zhang</a>
|
<a href=/people/d/dan-roth/>Dan Roth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--51><div class="card-body p-3 small">Understanding <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a> involves recognizing how multiple event mentions structurally and temporally interact with each other. In this process, one can induce event complexes that organize multi-granular events with temporal order and membership relations interweaving among them. Due to the lack of jointly labeled data for these relational phenomena and the restriction on the structures they articulate, we propose a joint constrained learning framework for modeling event-event relations. Specifically, the framework enforces logical constraints within and across multiple temporal and subevent relations of events by converting these <a href=https://en.wikipedia.org/wiki/Constraint_(mathematics)>constraints</a> into differentiable learning objectives. We show that our joint constrained learning approach effectively compensates for the lack of jointly labeled data, and outperforms SOTA methods on benchmarks for both temporal relation extraction and event hierarchy construction, replacing a commonly used but more expensive global inference process. We also present a promising case study to show the effectiveness of our approach to inducing event complexes on an external corpus.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.53.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--53 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.53 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939118 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.53/>Semi-supervised New Event Type Induction and Event Detection</a></strong><br><a href=/people/l/lifu-huang/>Lifu Huang</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--53><div class="card-body p-3 small">Most previous event extraction studies assume a set of target event types and corresponding event annotations are given, which could be very expensive. In this paper, we work on a new task of semi-supervised event type induction, aiming to automatically discover a set of unseen types from a given corpus by leveraging annotations available for a few seen types. We design a Semi-Supervised Vector Quantized Variational Autoencoder framework to automatically learn a discrete latent type representation for each seen and unseen type and optimize them using seen type event annotations. A variational autoencoder is further introduced to enforce the reconstruction of each event mention conditioned on its latent type distribution. Experiments show that our approach can not only achieve state-of-the-art performance on supervised event detection but also discover high-quality new event types.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.60.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--60 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.60 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938839 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.60/>Learning to Represent Image and Text with Denotation Graph</a></strong><br><a href=/people/b/bowen-zhang/>Bowen Zhang</a>
|
<a href=/people/h/hexiang-hu/>Hexiang Hu</a>
|
<a href=/people/v/vihan-jain/>Vihan Jain</a>
|
<a href=/people/e/eugene-ie/>Eugene Ie</a>
|
<a href=/people/f/fei-sha/>Fei Sha</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--60><div class="card-body p-3 small">Learning to fuse vision and language information and representing them is an important research problem with many applications. Recent progresses have leveraged the ideas of pre-training (from language modeling) and attention layers in Transformers to learn representation from datasets containing <a href=https://en.wikipedia.org/wiki/Digital_image>images</a> aligned with linguistic expressions that describe the <a href=https://en.wikipedia.org/wiki/Digital_image>images</a>. In this paper, we propose learning representations from a set of implied, visually grounded expressions between <a href=https://en.wikipedia.org/wiki/Image>image</a> and text, automatically mined from those <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>. In particular, we use denotation graphs to represent how specific <a href=https://en.wikipedia.org/wiki/Concept>concepts</a> (such as sentences describing images) can be linked to abstract and generic concepts (such as short phrases) that are also visually grounded. This type of generic-to-specific relations can be discovered using <a href=https://en.wikipedia.org/wiki/Semantic_analysis_(linguistics)>linguistic analysis tools</a>. We propose <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> to incorporate such <a href=https://en.wikipedia.org/wiki/Binary_relation>relations</a> into <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>learning representation</a>. We show that state-of-the-art multimodal learning models can be further improved by leveraging automatically harvested structural relations. The representations lead to stronger empirical results on downstream tasks of cross-modal image retrieval, referring expression, and compositional attribute-object recognition. Both our codes and the extracted denotation graphs on the <a href=https://en.wikipedia.org/wiki/Flickr>Flickr30 K</a> and the COCO datasets are publically available on https://sha-lab.github.io/DG.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.62.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--62 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.62 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.62.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938964 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.62/>Does my multimodal model learn cross-modal interactions? Its harder to tell than you might think !</a></strong><br><a href=/people/j/jack-hessel/>Jack Hessel</a>
|
<a href=/people/l/lillian-lee/>Lillian Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--62><div class="card-body p-3 small">Modeling expressive cross-modal interactions seems crucial in <a href=https://en.wikipedia.org/wiki/Multimodal_interaction>multimodal tasks</a>, such as visual question answering. However, sometimes high-performing black-box algorithms turn out to be mostly exploiting unimodal signals in the data. We propose a new diagnostic tool, empirical multimodally-additive function projection (EMAP), for isolating whether or not cross-modal interactions improve performance for a given model on a given task. This <a href=https://en.wikipedia.org/wiki/Projection_(linear_algebra)>function projection</a> modifies model predictions so that cross-modal interactions are eliminated, isolating the additive, unimodal structure. For seven image+text classification tasks (on each of which we set new state-of-the-art benchmarks), we find that, in many cases, removing cross-modal interactions results in little to no performance degradation. Surprisingly, this holds even when expressive models, with capacity to consider interactions, otherwise outperform less expressive models ; thus, performance improvements, even when present, often can not be attributed to consideration of cross-modal feature interactions. We hence recommend that researchers in multimodal machine learning report the performance not only of unimodal baselines, but also the EMAP of their best-performing model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.63.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--63 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.63 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939282 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.63" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.63/>MUTANT : A Training Paradigm for Out-of-Distribution Generalization in Visual Question Answering<span class=acl-fixed-case>MUTANT</span>: A Training Paradigm for Out-of-Distribution Generalization in Visual Question Answering</a></strong><br><a href=/people/t/tejas-gokhale/>Tejas Gokhale</a>
|
<a href=/people/p/pratyay-banerjee/>Pratyay Banerjee</a>
|
<a href=/people/c/chitta-baral/>Chitta Baral</a>
|
<a href=/people/y/yezhou-yang/>Yezhou Yang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--63><div class="card-body p-3 small">While progress has been made on the visual question answering leaderboards, models often utilize spurious correlations and <a href=https://en.wikipedia.org/wiki/Prior_probability>priors</a> in <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> under the i.i.d. setting. As such, evaluation on out-of-distribution (OOD) test samples has emerged as a proxy for <a href=https://en.wikipedia.org/wiki/Generalization>generalization</a>. In this paper, we present MUTANT, a training paradigm that exposes the model to perceptually similar, yet semantically distinct mutations of the input, to improve OOD generalization, such as the VQA-CP challenge. Under this paradigm, models utilize a consistency-constrained training objective to understand the effect of semantic changes in input (question-image pair) on the output (answer). Unlike existing methods on VQA-CP, MUTANT does not rely on the knowledge about the nature of train and test answer distributions. MUTANT establishes a new state-of-the-art <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on VQA-CP with a 10.57 % improvement. Our work opens up avenues for the use of semantic input mutations for OOD generalization in question answering.<i>MUTANT</i>, a training paradigm that exposes the model to perceptually similar, yet semantically distinct <i>mutations</i> of the input, to improve OOD generalization, such as the VQA-CP challenge. Under this paradigm, models utilize a consistency-constrained training objective to understand the effect of semantic changes in input (question-image pair) on the output (answer). Unlike existing methods on VQA-CP, <i>MUTANT</i> does not rely on the knowledge about the nature of train and test answer distributions. <i>MUTANT</i> establishes a new state-of-the-art accuracy on VQA-CP with a 10.57% improvement. Our work opens up avenues for the use of semantic input mutations for OOD generalization in question answering.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.66.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--66 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.66 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938861 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.66" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.66/>TOD-BERT : Pre-trained Natural Language Understanding for Task-Oriented Dialogue<span class=acl-fixed-case>TOD</span>-<span class=acl-fixed-case>BERT</span>: Pre-trained Natural Language Understanding for Task-Oriented Dialogue</a></strong><br><a href=/people/c/chien-sheng-wu/>Chien-Sheng Wu</a>
|
<a href=/people/s/steven-c-h-hoi/>Steven C.H. Hoi</a>
|
<a href=/people/r/richard-socher/>Richard Socher</a>
|
<a href=/people/c/caiming-xiong/>Caiming Xiong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--66><div class="card-body p-3 small">The underlying difference of linguistic patterns between general text and task-oriented dialogue makes existing pre-trained language models less useful in practice. In this work, we unify nine human-human and multi-turn task-oriented dialogue datasets for <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a>. To better model dialogue behavior during pre-training, we incorporate user and system tokens into the masked language modeling. We propose a contrastive objective function to simulate the response selection task. Our pre-trained task-oriented dialogue BERT (TOD-BERT) outperforms strong baselines like BERT on four downstream task-oriented dialogue applications, including intention recognition, dialogue state tracking, dialogue act prediction, and response selection. We also show that TOD-BERT has a stronger few-shot ability that can mitigate the data scarcity problem for task-oriented dialogue.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.69.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--69 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.69 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938993 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.69/>Latent Geographical Factors for Analyzing the Evolution of Dialects in Contact</a></strong><br><a href=/people/y/yugo-murawaki/>Yugo Murawaki</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--69><div class="card-body p-3 small">Analyzing the evolution of dialects remains a challenging problem because <a href=https://en.wikipedia.org/wiki/Language_contact>contact phenomena</a> hinder the application of the standard <a href=https://en.wikipedia.org/wiki/Tree_model>tree model</a>. Previous statistical approaches to this problem resort to <a href=https://en.wikipedia.org/wiki/Genetic_admixture>admixture analysis</a>, where each dialect is seen as a mixture of latent ancestral populations. However, such ancestral populations are hardly interpretable in the context of the <a href=https://en.wikipedia.org/wiki/Tree_model>tree model</a>. In this paper, we propose a probabilistic generative model that represents latent factors as geographical distributions. We argue that the proposed model has higher affinity with the <a href=https://en.wikipedia.org/wiki/Tree_(graph_theory)>tree model</a> because a <a href=https://en.wikipedia.org/wiki/Tree_(graph_theory)>tree</a> can alternatively be represented as a set of geographical distributions. Experiments involving synthetic and real data suggest that the proposed method is both quantitatively and qualitatively superior to the admixture model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.75.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--75 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.75 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938966 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.75/>Multi-task Learning for Multilingual Neural Machine Translation</a></strong><br><a href=/people/y/yiren-wang/>Yiren Wang</a>
|
<a href=/people/c/chengxiang-zhai/>ChengXiang Zhai</a>
|
<a href=/people/h/hany-hassan-awadalla/>Hany Hassan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--75><div class="card-body p-3 small">While monolingual data has been shown to be useful in improving bilingual neural machine translation (NMT), effectively and efficiently leveraging monolingual data for Multilingual NMT (MNMT) systems is a less explored area. In this work, we propose a multi-task learning (MTL) framework that jointly trains the model with the translation task on bitext data and two denoising tasks on the monolingual data. We conduct extensive empirical studies on MNMT systems with 10 language pairs from WMT datasets. We show that the proposed approach can effectively improve the translation quality for both high-resource and low-resource languages with large margin, achieving significantly better results than the individual bilingual models. We also demonstrate the efficacy of the proposed approach in the zero-shot setup for language pairs without bitext training data. Furthermore, we show the effectiveness of MTL over pre-training approaches for both NMT and cross-lingual transfer learning NLU tasks ; the proposed approach outperforms massive scale models trained on single task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.86.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--86 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.86 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939237 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.86/>IIRC : A Dataset of Incomplete Information Reading Comprehension Questions<span class=acl-fixed-case>IIRC</span>: A Dataset of Incomplete Information Reading Comprehension Questions</a></strong><br><a href=/people/j/james-ferguson/>James Ferguson</a>
|
<a href=/people/m/matt-gardner/>Matt Gardner</a>
|
<a href=/people/h/hannaneh-hajishirzi/>Hannaneh Hajishirzi</a>
|
<a href=/people/t/tushar-khot/>Tushar Khot</a>
|
<a href=/people/p/pradeep-dasigi/>Pradeep Dasigi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--86><div class="card-body p-3 small">Humans often have to read multiple documents to address their information needs. However, most existing reading comprehension (RC) tasks only focus on questions for which the contexts provide all the information required to answer them, thus not evaluating a <a href=https://en.wikipedia.org/wiki/System>system</a>&#8217;s performance at identifying a potential lack of sufficient information and locating sources for that information. To fill this gap, we present a dataset, IIRC, with more than 13 K questions over paragraphs from <a href=https://en.wikipedia.org/wiki/English_Wikipedia>English Wikipedia</a> that provide only partial information to answer them, with the missing information occurring in one or more linked documents. The questions were written by crowd workers who did not have access to any of the linked documents, leading to questions that have little lexical overlap with the contexts where the answers appear. This process also gave many questions without answers, and those that require discrete reasoning, increasing the difficulty of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. We follow recent modeling work on various reading comprehension datasets to construct a <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline model</a> for this dataset, finding that <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> achieves 31.1 % <a href=https://en.wikipedia.org/wiki/F-number>F1</a> on this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, while estimated <a href=https://en.wikipedia.org/wiki/Human_factors_and_ergonomics>human performance</a> is 88.4 %. The dataset, code for the baseline system, and a leaderboard can be found at https://allennlp.org/iirc.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.89.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--89 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.89 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.89.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938835 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.89" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.89/>ToTTo : A Controlled Table-To-Text Generation Dataset<span class=acl-fixed-case>ToTTo</span>: A Controlled Table-To-Text Generation Dataset</a></strong><br><a href=/people/a/ankur-parikh/>Ankur Parikh</a>
|
<a href=/people/x/xuezhi-wang/>Xuezhi Wang</a>
|
<a href=/people/s/sebastian-gehrmann/>Sebastian Gehrmann</a>
|
<a href=/people/m/manaal-faruqui/>Manaal Faruqui</a>
|
<a href=/people/b/bhuwan-dhingra/>Bhuwan Dhingra</a>
|
<a href=/people/d/diyi-yang/>Diyi Yang</a>
|
<a href=/people/d/dipanjan-das/>Dipanjan Das</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--89><div class="card-body p-3 small">We present ToTTo, an open-domain English table-to-text dataset with over 120,000 training examples that proposes a controlled generation task : given a Wikipedia table and a set of highlighted table cells, produce a one-sentence description. To obtain generated targets that are natural but also faithful to the source table, we introduce a dataset construction process where annotators directly revise existing candidate sentences from <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>. We present systematic analyses of our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> and annotation process as well as results achieved by several state-of-the-art baselines. While usually fluent, existing methods often hallucinate phrases that are not supported by the table, suggesting that this dataset can serve as a useful research benchmark for high-precision conditional text generation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.90.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--90 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.90 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938972 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.90" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.90/>ENT-DESC : Entity Description Generation by Exploring Knowledge Graph<span class=acl-fixed-case>ENT</span>-<span class=acl-fixed-case>DESC</span>: Entity Description Generation by Exploring Knowledge Graph</a></strong><br><a href=/people/l/liying-cheng/>Liying Cheng</a>
|
<a href=/people/d/dekun-wu/>Dekun Wu</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/y/yan-zhang/>Yan Zhang</a>
|
<a href=/people/z/zhanming-jie/>Zhanming Jie</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a>
|
<a href=/people/l/luo-si/>Luo Si</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--90><div class="card-body p-3 small">Previous works on knowledge-to-text generation take as input a few <a href=https://en.wikipedia.org/wiki/Resource_Description_Framework>RDF triples</a> or key-value pairs conveying the knowledge of some entities to generate a <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language description</a>. Existing datasets, such as WIKIBIO, WebNLG, and <a href=https://en.wikipedia.org/wiki/E2E>E2E</a>, basically have a good alignment between an input triple / pair set and its output text. However, in practice, the input knowledge could be more than enough, since the output description may only cover the most significant knowledge. In this paper, we introduce a large-scale and challenging dataset to facilitate the study of such a practical scenario in KG-to-text. Our dataset involves retrieving abundant knowledge of various types of main entities from a large knowledge graph (KG), which makes the current graph-to-sequence models severely suffer from the problems of <a href=https://en.wikipedia.org/wiki/Information_loss>information loss</a> and parameter explosion while generating the descriptions. We address these challenges by proposing a multi-graph structure that is able to represent the original <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph information</a> more comprehensively. Furthermore, we also incorporate aggregation methods that learn to extract the rich graph information. Extensive experiments demonstrate the effectiveness of our model architecture.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.92.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--92 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.92 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939115 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.92" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.92/>Online Back-Parsing for AMR-to-Text Generation<span class=acl-fixed-case>AMR</span>-to-Text Generation</a></strong><br><a href=/people/x/xuefeng-bai/>Xuefeng Bai</a>
|
<a href=/people/l/linfeng-song/>Linfeng Song</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--92><div class="card-body p-3 small">AMR-to-text generation aims to recover a text containing the same meaning as an input AMR graph. Current research develops increasingly powerful graph encoders to better represent AMR graphs, with decoders based on standard language modeling being used to generate outputs. We propose a <a href=https://en.wikipedia.org/wiki/Code>decoder</a> that back predicts projected AMR graphs on the target sentence during text generation. As the result, our outputs can better preserve the input meaning than standard <a href=https://en.wikipedia.org/wiki/Code>decoders</a>. Experiments on two AMR benchmarks show the superiority of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> over the previous state-of-the-art <a href=https://en.wikipedia.org/wiki/System>system</a> based on graph Transformer.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.93.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--93 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.93 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939186 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.93/>Reading Between the Lines : Exploring Infilling in Visual Narratives</a></strong><br><a href=/people/k/khyathi-raghavi-chandu/>Khyathi Raghavi Chandu</a>
|
<a href=/people/r/ruo-ping-dong/>Ruo-Ping Dong</a>
|
<a href=/people/a/alan-w-black/>Alan W Black</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--93><div class="card-body p-3 small">Generating long form narratives such as <a href=https://en.wikipedia.org/wiki/Narrative>stories</a> and procedures from multiple modalities has been a long standing dream for <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>artificial intelligence</a>. In this regard, there is often crucial subtext that is derived from the surrounding contexts. The general seq2seq training methods render the models shorthanded while attempting to bridge the gap between these neighbouring contexts. In this paper, we tackle this problem by using infilling techniques involving prediction of missing steps in a narrative while generating textual descriptions from a sequence of images. We also present a new large scale visual procedure telling (ViPT) dataset with a total of 46,200 procedures and around 340k pairwise images and textual descriptions that is rich in such contextual dependencies. Generating steps using infilling technique demonstrates the effectiveness in visual procedures with more coherent texts. We conclusively show a METEOR score of 27.51 on <a href=https://en.wikipedia.org/wiki/Procedure_code>procedures</a> which is higher than the state-of-the-art on <a href=https://en.wikipedia.org/wiki/Visual_storytelling>visual storytelling</a>. We also demonstrate the effects of interposing new text with missing images during <a href=https://en.wikipedia.org/wiki/Inference>inference</a>. The code and the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> will be publicly available at https://visual-narratives.github.io/Visual-Narratives/.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.94.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--94 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.94 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938805 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.94/>Acrostic Poem Generation</a></strong><br><a href=/people/r/rajat-agarwal/>Rajat Agarwal</a>
|
<a href=/people/k/katharina-kann/>Katharina Kann</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--94><div class="card-body p-3 small">We propose a new task in the area of <a href=https://en.wikipedia.org/wiki/Computational_creativity>computational creativity</a> : acrostic poem generation in <a href=https://en.wikipedia.org/wiki/English_language>English</a>. Acrostic poems are <a href=https://en.wikipedia.org/wiki/Poetry>poems</a> that contain a <a href=https://en.wikipedia.org/wiki/Hidden_message>hidden message</a> ; typically, the first letter of each line spells out a word or short phrase. We define the task as a generation task with multiple constraints : given an input word, 1) the initial letters of each line should spell out the provided word, 2) the <a href=https://en.wikipedia.org/wiki/Poetry>poem&#8217;s semantics</a> should also relate to it, and 3) the <a href=https://en.wikipedia.org/wiki/Poetry>poem</a> should conform to a <a href=https://en.wikipedia.org/wiki/Rhyme_scheme>rhyming scheme</a>. We further provide a baseline model for the task, which consists of a conditional neural language model in combination with a neural rhyming model. Since no dedicated datasets for acrostic poem generation exist, we create <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training data</a> for our task by first training a separate topic prediction model on a small set of topic-annotated poems and then predicting topics for additional <a href=https://en.wikipedia.org/wiki/Poetry>poems</a>. Our experiments show that the acrostic poems generated by our baseline are received well by humans and do not lose much quality due to the additional constraints. Last, we confirm that <a href=https://en.wikipedia.org/wiki/Poetry>poems</a> generated by our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> are indeed closely related to the provided prompts, and that pretraining on <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a> can boost performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.95.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--95 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.95 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938834 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.95" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.95/>Local Additivity Based Data Augmentation for Semi-supervised NER<span class=acl-fixed-case>NER</span></a></strong><br><a href=/people/j/jiaao-chen/>Jiaao Chen</a>
|
<a href=/people/z/zhenghui-wang/>Zhenghui Wang</a>
|
<a href=/people/r/ran-tian/>Ran Tian</a>
|
<a href=/people/z/zichao-yang/>Zichao Yang</a>
|
<a href=/people/d/diyi-yang/>Diyi Yang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--95><div class="card-body p-3 small">Named Entity Recognition (NER) is one of the first stages in <a href=https://en.wikipedia.org/wiki/Deep_learning>deep language understanding</a> yet current NER models heavily rely on human-annotated data. In this work, to alleviate the dependence on labeled data, we propose a Local Additivity based Data Augmentation (LADA) method for semi-supervised NER, in which we create virtual samples by interpolating sequences close to each other. Our approach has two variations : Intra-LADA and Inter-LADA, where Intra-LADA performs interpolations among tokens within one sentence, and Inter-LADA samples different sentences to interpolate. Through linear additions between <a href=https://en.wikipedia.org/wiki/Sampling_(signal_processing)>sampled training data</a>, LADA creates an infinite amount of <a href=https://en.wikipedia.org/wiki/Labeled_data>labeled data</a> and improves both entity and context learning. We further extend LADA to the semi-supervised setting by designing a novel consistency loss for unlabeled data. Experiments conducted on two NER benchmarks demonstrate the effectiveness of our methods over several strong <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a>. We have publicly released our code at https://github.com/GT-SALT/LADA</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.96.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--96 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.96 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938850 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.96" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.96/>Grounded Compositional Outputs for Adaptive Language Modeling</a></strong><br><a href=/people/n/nikolaos-pappas/>Nikolaos Pappas</a>
|
<a href=/people/p/phoebe-mulcaire/>Phoebe Mulcaire</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--96><div class="card-body p-3 small">Language models have emerged as a central component across <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, and a great deal of progress depends on the ability to cheaply adapt <a href=https://en.wikipedia.org/wiki/Natural_language_processing>them</a> (e.g., through finetuning) to new domains and tasks. A <a href=https://en.wikipedia.org/wiki/Language_model>language model</a>&#8217;s vocabularytypically selected before training and permanently fixed lateraffects its size and is part of what makes it resistant to such <a href=https://en.wikipedia.org/wiki/Adaptation>adaptation</a>. Prior work has used compositional input embeddings based on <a href=https://en.wikipedia.org/wiki/Surface_(mathematics)>surface forms</a> to ameliorate this issue. In this work, we go one step beyond and propose a fully compositional output embedding layer for language models, which is further grounded in information from a structured lexicon (WordNet), namely semantically related words and free-text definitions. To our knowledge, the result is the first word-level language model with a size that does not depend on the training vocabulary. We evaluate the model on conventional <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a> as well as challenging cross-domain settings with an open vocabulary, finding that it matches or outperforms previous state-of-the-art output embedding methods and adaptation approaches. Our analysis attributes the improvements to sample efficiency : our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is more accurate for <a href=https://en.wikipedia.org/wiki/Word_frequency>low-frequency words</a>.<i>vocabulary</i>&#8212;typically selected before training and permanently fixed later&#8212;affects its size and is part of what makes it resistant to such adaptation. Prior work has used compositional input embeddings based on surface forms to ameliorate this issue. In this work, we go one step beyond and propose a fully compositional output embedding layer for language models, which is further grounded in information from a structured lexicon (WordNet), namely semantically related words and free-text definitions. To our knowledge, the result is the first word-level language model with a size that does not depend on the training vocabulary. We evaluate the model on conventional language modeling as well as challenging cross-domain settings with an open vocabulary, finding that it matches or outperforms previous state-of-the-art output embedding methods and adaptation approaches. Our analysis attributes the improvements to sample efficiency: our model is more accurate for low-frequency words.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.98.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--98 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.98 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.98/>SetConv : A New Approach for Learning from Imbalanced Data<span class=acl-fixed-case>S</span>et<span class=acl-fixed-case>C</span>onv: <span class=acl-fixed-case>A</span> <span class=acl-fixed-case>N</span>ew <span class=acl-fixed-case>A</span>pproach for <span class=acl-fixed-case>L</span>earning from <span class=acl-fixed-case>I</span>mbalanced <span class=acl-fixed-case>D</span>ata</a></strong><br><a href=/people/y/yang-gao/>Yang Gao</a>
|
<a href=/people/y/yi-fan-li/>Yi-Fan Li</a>
|
<a href=/people/y/yu-lin/>Yu Lin</a>
|
<a href=/people/c/charu-aggarwal/>Charu Aggarwal</a>
|
<a href=/people/l/latifur-khan/>Latifur Khan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--98><div class="card-body p-3 small">For many real-world classification problems, e.g., sentiment classification, most existing <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning methods</a> are biased towards the majority class when the Imbalance Ratio (IR) is high. To address this problem, we propose a set convolution (SetConv) operation and an episodic training strategy to extract a single representative for each class, so that <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> can later be trained on a balanced class distribution. We prove that our proposed <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> is permutation-invariant despite the order of inputs, and experiments on multiple large-scale benchmark text datasets show the superiority of our proposed framework when compared to other SOTA methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.100.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--100 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.100 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939203 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.100/>Improving Bilingual Lexicon Induction for Low Frequency Words</a></strong><br><a href=/people/j/jiaji-huang/>Jiaji Huang</a>
|
<a href=/people/x/xingyu-cai/>Xingyu Cai</a>
|
<a href=/people/k/kenneth-church/>Kenneth Church</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--100><div class="card-body p-3 small">This paper designs a Monolingual Lexicon Induction task and observes that two factors accompany the degraded accuracy of bilingual lexicon induction for rare words. First, a diminishing margin between similarities in <a href=https://en.wikipedia.org/wiki/Low_frequency>low frequency regime</a>, and secondly, exacerbated hubness at <a href=https://en.wikipedia.org/wiki/Low_frequency>low frequency</a>. Based on the observation, we further propose two <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> to address these two factors, respectively. The larger issue is hubness. Addressing that improves <a href=https://en.wikipedia.org/wiki/Inductive_reasoning>induction accuracy</a> significantly, especially for low-frequency words.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.101.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--101 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.101 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939213 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.101/>Learning VAE-LDA Models with Rounded Reparameterization Trick<span class=acl-fixed-case>VAE</span>-<span class=acl-fixed-case>LDA</span> Models with Rounded Reparameterization Trick</a></strong><br><a href=/people/r/runzhi-tian/>Runzhi Tian</a>
|
<a href=/people/y/yongyi-mao/>Yongyi Mao</a>
|
<a href=/people/r/richong-zhang/>Richong Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--101><div class="card-body p-3 small">The introduction of VAE provides an efficient <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> for the learning of generative models, including generative topic models. However, when the <a href=https://en.wikipedia.org/wiki/Topic_model>topic model</a> is a Latent Dirichlet Allocation (LDA) model, a central technique of VAE, the reparameterization trick, fails to be applicable. This is because no reparameterization form of Dirichlet distributions is known to date that allows the use of the reparameterization trick. In this work, we propose a new method, which we call Rounded Reparameterization Trick (RRT), to reparameterize <a href=https://en.wikipedia.org/wiki/Dirichlet_distribution>Dirichlet distributions</a> for the learning of VAE-LDA models. This method, when applied to a VAE-LDA model, is shown experimentally to outperform the existing neural topic models on several benchmark datasets and on a synthetic dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.103.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--103 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.103 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38940160 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.103" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.103/>Scaling Hidden Markov Language Models<span class=acl-fixed-case>M</span>arkov Language Models</a></strong><br><a href=/people/j/justin-chiu/>Justin Chiu</a>
|
<a href=/people/a/alexander-m-rush/>Alexander Rush</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--103><div class="card-body p-3 small">The hidden Markov model (HMM) is a fundamental tool for sequence modeling that cleanly separates the hidden state from the <a href=https://en.wikipedia.org/wiki/Emission_spectrum>emission structure</a>. However, this separation makes it difficult to fit HMMs to large datasets in modern <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, and they have fallen out of use due to very poor performance compared to fully observed models. This work revisits the challenge of scaling HMMs to language modeling datasets, taking ideas from recent approaches to neural modeling. We propose methods for scaling HMMs to massive state spaces while maintaining efficient <a href=https://en.wikipedia.org/wiki/Exact_inference>exact inference</a>, a compact parameterization, and effective <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularization</a>. Experiments show that this approach leads to <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that are much more accurate than previous HMMs and n-gram-based methods, making progress towards the performance of state-of-the-art NN models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.104.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--104 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.104 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939325 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.104" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.104/>Coding Textual Inputs Boosts the Accuracy of <a href=https://en.wikipedia.org/wiki/Neural_network>Neural Networks</a></a></strong><br><a href=/people/a/abdul-rafae-khan/>Abdul Rafae Khan</a>
|
<a href=/people/j/jia-xu/>Jia Xu</a>
|
<a href=/people/w/weiwei-sun/>Weiwei Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--104><div class="card-body p-3 small">Natural Language Processing (NLP) tasks are usually performed word by word on <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>textual inputs</a>. We can use arbitrary <a href=https://en.wikipedia.org/wiki/Symbol_(formal)>symbols</a> to represent the linguistic meaning of a word and use these <a href=https://en.wikipedia.org/wiki/Symbol_(formal)>symbols</a> as inputs. As alternatives to a text representation, we introduce <a href=https://en.wikipedia.org/wiki/Soundex>Soundex</a>, MetaPhone, <a href=https://en.wikipedia.org/wiki/NYSIIS>NYSIIS</a>, <a href=https://en.wikipedia.org/wiki/Logogram>logogram</a> to <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, and develop fixed-output-length coding and its extension using <a href=https://en.wikipedia.org/wiki/Huffman_coding>Huffman coding</a>. Each of those <a href=https://en.wikipedia.org/wiki/Code_name>codings</a> combines different character / digital sequences and constructs a new <a href=https://en.wikipedia.org/wiki/Vocabulary>vocabulary</a> based on <a href=https://en.wikipedia.org/wiki/Code_name>codewords</a>. We find that the integration of those codewords with text provides more reliable inputs to Neural-Network-based NLP systems through redundancy than text-alone inputs. Experiments demonstrate that our approach outperforms the state-of-the-art models on the application of <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a>, and <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a>. The source code is available at https://github.com/abdulrafae/coding_nmt.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.107.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--107 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.107 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939305 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.107" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.107/>Named Entity Recognition for Social Media Texts with Semantic Augmentation</a></strong><br><a href=/people/y/yuyang-nie/>Yuyang Nie</a>
|
<a href=/people/y/yuanhe-tian/>Yuanhe Tian</a>
|
<a href=/people/x/xiang-wan/>Xiang Wan</a>
|
<a href=/people/y/yan-song/>Yan Song</a>
|
<a href=/people/b/bo-dai/>Bo Dai</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--107><div class="card-body p-3 small">Existing approaches for <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a> suffer from data sparsity problems when conducted on short and informal texts, especially <a href=https://en.wikipedia.org/wiki/User-generated_content>user-generated social media content</a>. Semantic augmentation is a potential way to alleviate this problem. Given that rich semantic information is implicitly preserved in pre-trained word embeddings, they are potential ideal resources for semantic augmentation. In this paper, we propose a neural-based approach to NER for social media texts where both local (from running text) and augmented semantics are taken into account. In particular, we obtain the augmented semantic information from a large-scale corpus, and propose an attentive semantic augmentation module and a gate module to encode and aggregate such <a href=https://en.wikipedia.org/wiki/Information>information</a>, respectively. Extensive experiments are performed on three benchmark datasets collected from English and Chinese social media platforms, where the results demonstrate the superiority of our approach to previous studies across all three datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.108.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--108 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.108 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939330 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.108/>Coupled Hierarchical Transformer for Stance-Aware Rumor Verification in Social Media Conversations</a></strong><br><a href=/people/j/jianfei-yu/>Jianfei Yu</a>
|
<a href=/people/j/jing-jiang/>Jing Jiang</a>
|
<a href=/people/l/ling-min-serena-khoo/>Ling Min Serena Khoo</a>
|
<a href=/people/h/hai-leong-chieu/>Hai Leong Chieu</a>
|
<a href=/people/r/rui-xia/>Rui Xia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--108><div class="card-body p-3 small">The prevalent use of <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> enables rapid spread of rumors on a massive scale, which leads to the emerging need of automatic rumor verification (RV). A number of previous studies focus on leveraging stance classification to enhance RV with multi-task learning (MTL) methods. However, most of these methods failed to employ pre-trained contextualized embeddings such as BERT, and did not exploit inter-task dependencies by using predicted stance labels to improve the RV task. Therefore, in this paper, to extend BERT to obtain thread representations, we first propose a Hierarchical Transformer, which divides each long thread into shorter subthreads, and employs BERT to separately represent each subthread, followed by a global Transformer layer to encode all the subthreads. We further propose a Coupled Transformer Module to capture the inter-task interactions and a Post-Level Attention layer to use the predicted stance labels for RV, respectively. Experiments on two benchmark datasets show the superiority of our Coupled Hierarchical Transformer model over existing MTL approaches.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.109.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--109 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.109 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939332 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.109/>Social Media Attributions in the Context of Water Crisis</a></strong><br><a href=/people/r/rupak-sarkar/>Rupak Sarkar</a>
|
<a href=/people/s/sayantan-mahinder/>Sayantan Mahinder</a>
|
<a href=/people/h/hirak-sarkar/>Hirak Sarkar</a>
|
<a href=/people/a/ashiqur-khudabukhsh/>Ashiqur KhudaBukhsh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--109><div class="card-body p-3 small">Attribution of natural disasters / <a href=https://en.wikipedia.org/wiki/Collective_responsibility>collective misfortune</a> is a widely-studied political science problem. However, such <a href=https://en.wikipedia.org/wiki/Research>studies</a> typically rely on <a href=https://en.wikipedia.org/wiki/Survey_methodology>surveys</a>, or <a href=https://en.wikipedia.org/wiki/Expert_witness>expert opinions</a>, or external signals such as <a href=https://en.wikipedia.org/wiki/Opinion_poll>voting outcomes</a>. In this paper, we explore the viability of using unstructured, noisy social media data to complement traditional surveys through automatically extracting <a href=https://en.wikipedia.org/wiki/Attribution_(psychology)>attribution factors</a>. We present a novel prediction task of attribution tie detection of identifying the <a href=https://en.wikipedia.org/wiki/Correlation_and_dependence>factors</a> (e.g., <a href=https://en.wikipedia.org/wiki/Urban_planning>poor city planning</a>, exploding population etc.) held responsible for the crisis in a social media document. We focus on the 2019 Chennai water crisis that rapidly escalated into a discussion topic with global importance following alarming water-crisis statistics. On a challenging <a href=https://en.wikipedia.org/wiki/Data_set>data set</a> constructed from <a href=https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos>YouTube comments</a> (72,098 comments posted by 43,859 users on 623 videos relevant to the crisis), we present a neural baseline to identify <a href=https://en.wikipedia.org/wiki/Attribution_(psychology)>attribution ties</a> that achieves a reasonable performance (accuracy : 87.34 % on <a href=https://en.wikipedia.org/wiki/Attribution_(psychology)>attribution detection</a> and 81.37 % on attribution resolution). We release the first annotated data set of 2,500 comments in this important domain.<i>attribution tie detection</i> of identifying the factors (e.g., poor city planning, exploding population etc.) held responsible for the crisis in a social media document. We focus on the 2019 Chennai water crisis that rapidly escalated into a discussion topic with global importance following alarming water-crisis statistics. On a challenging data set constructed from YouTube comments (72,098 comments posted by 43,859 users on 623 videos relevant to the crisis), we present a neural baseline to identify attribution ties that achieves a reasonable performance (accuracy: 87.34% on attribution detection and 81.37% on attribution resolution). We release the first annotated data set of 2,500 comments in this important domain.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.110.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--110 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.110 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938774 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.110/>On the Reliability and Validity of Detecting Approval of Political Actors in Tweets</a></strong><br><a href=/people/i/indira-sen/>Indira Sen</a>
|
<a href=/people/f/fabian-flock/>Fabian Flck</a>
|
<a href=/people/c/claudia-wagner/>Claudia Wagner</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--110><div class="card-body p-3 small">Social media sites like <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> possess the potential to complement surveys that measure political opinions and, more specifically, political actors&#8217; approval. However, new challenges related to the reliability and validity of social-media-based estimates arise. Various sentiment analysis and stance detection methods have been developed and used in previous research to measure users&#8217; political opinions based on their content on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. In this work, we attempt to gauge the efficacy of untargeted sentiment, targeted sentiment, and stance detection methods in labeling various political actors&#8217; approval by benchmarking them across several datasets. We also contrast the performance of these pretrained methods that can be used in an off-the-shelf (OTS) manner against a set of <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained on minimal custom data. We find that OTS methods have low generalizability on unseen and familiar targets, while low-resource custom models are more robust. Our work sheds light on the strengths and limitations of existing methods proposed for understanding politicians&#8217; approval from <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.114.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--114 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.114 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939008 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.114" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.114/>Predicting Clinical Trial Results by Implicit Evidence Integration</a></strong><br><a href=/people/q/qiao-jin/>Qiao Jin</a>
|
<a href=/people/c/chuanqi-tan/>Chuanqi Tan</a>
|
<a href=/people/m/mosha-chen/>Mosha Chen</a>
|
<a href=/people/x/xiaozhong-liu/>Xiaozhong Liu</a>
|
<a href=/people/s/songfang-huang/>Songfang Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--114><div class="card-body p-3 small">Clinical trials provide essential guidance for practicing <a href=https://en.wikipedia.org/wiki/Evidence-based_medicine>Evidence-Based Medicine</a>, though often accompanying with unendurable costs and risks. To optimize the design of <a href=https://en.wikipedia.org/wiki/Clinical_trial>clinical trials</a>, we introduce a novel Clinical Trial Result Prediction (CTRP) task. In the CTRP framework, a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> takes a PICO-formatted clinical trial proposal with its background as input and predicts the result, i.e. how the Intervention group compares with the Comparison group in terms of the measured Outcome in the studied Population. While structured clinical evidence is prohibitively expensive for manual collection, we exploit large-scale unstructured sentences from <a href=https://en.wikipedia.org/wiki/Medical_literature>medical literature</a> that implicitly contain PICOs and results as evidence. Specifically, we pre-train a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to predict the disentangled results from such implicit evidence and fine-tune the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> with limited data on the downstream datasets. Experiments on the benchmark Evidence Integration dataset show that the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms the baselines by large margins, e.g., with a 10.7 % relative gain over BioBERT in macro-F1. Moreover, the performance improvement is also validated on another <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> composed of <a href=https://en.wikipedia.org/wiki/Clinical_trial>clinical trials</a> related to COVID-19.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.115.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--115 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.115 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.115.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939013 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.115/>Explainable Clinical Decision Support from Text</a></strong><br><a href=/people/j/jinyue-feng/>Jinyue Feng</a>
|
<a href=/people/c/chantal-shaib/>Chantal Shaib</a>
|
<a href=/people/f/frank-rudzicz/>Frank Rudzicz</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--115><div class="card-body p-3 small">Clinical prediction models often use structured variables and provide outcomes that are not readily interpretable by clinicians. Further, free-text medical notes may contain information not immediately available in structured variables. We propose a hierarchical CNN-transformer model with explicit attention as an interpretable, multi-task clinical language model, which achieves an AUROC of 0.75 and 0.78 on sepsis and mortality prediction, respectively. We also explore the relationships between learned <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> from structured and unstructured variables using projection-weighted canonical correlation analysis. Finally, we outline a protocol to evaluate <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> usability in a clinical decision support context. From domain-expert evaluations, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> generates informative rationales that have promising real-life applications.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.116.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--116 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.116 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939383 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.116/>A Knowledge-driven Generative Model for Multi-implication Chinese Medical Procedure Entity Normalization<span class=acl-fixed-case>C</span>hinese Medical Procedure Entity Normalization</a></strong><br><a href=/people/j/jinghui-yan/>Jinghui Yan</a>
|
<a href=/people/y/yining-wang/>Yining Wang</a>
|
<a href=/people/l/lu-xiang/>Lu Xiang</a>
|
<a href=/people/y/yu-zhou/>Yu Zhou</a>
|
<a href=/people/c/chengqing-zong/>Chengqing Zong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--116><div class="card-body p-3 small">Medical entity normalization, which links medical mentions in the text to entities in <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge bases</a>, is an important research topic in medical natural language processing. In this paper, we focus on Chinese medical procedure entity normalization. However, nonstandard Chinese expressions and combined procedures present challenges in our <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a>. The existing <a href=https://en.wikipedia.org/wiki/Strategy>strategies</a> relying on the <a href=https://en.wikipedia.org/wiki/Discriminative_model>discriminative model</a> are poorly to cope with normalizing combined procedure mentions. We propose a sequence generative framework to directly generate all the corresponding medical procedure entities. we adopt two strategies : category-based constraint decoding and category-based model refining to avoid unrealistic results. The method is capable of linking entities when a mention contains multiple procedure concepts and our comprehensive experiments demonstrate that the proposed model can achieve remarkable improvements over existing baselines, particularly significant in the case of multi-implication Chinese medical procedures.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.117.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--117 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.117 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938643 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.117/>Combining Automatic Labelers and Expert Annotations for Accurate Radiology Report Labeling Using BERT<span class=acl-fixed-case>BERT</span></a></strong><br><a href=/people/a/akshay-smit/>Akshay Smit</a>
|
<a href=/people/s/saahil-jain/>Saahil Jain</a>
|
<a href=/people/p/pranav-rajpurkar/>Pranav Rajpurkar</a>
|
<a href=/people/a/anuj-pareek/>Anuj Pareek</a>
|
<a href=/people/a/andrew-y-ng/>Andrew Ng</a>
|
<a href=/people/m/matthew-lungren/>Matthew Lungren</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--117><div class="card-body p-3 small">The extraction of labels from radiology text reports enables large-scale training of medical imaging models. Existing approaches to report labeling typically rely either on sophisticated <a href=https://en.wikipedia.org/wiki/Feature_engineering>feature engineering</a> based on medical domain knowledge or manual annotations by experts. In this work, we introduce a BERT-based approach to medical image report labeling that exploits both the scale of available rule-based systems and the quality of expert annotations. We demonstrate superior performance of a biomedically pretrained BERT model first trained on annotations of a rule-based labeler and then finetuned on a small set of expert annotations augmented with automated backtranslation. We find that our final model, CheXbert, is able to outperform the previous best rules-based labeler with <a href=https://en.wikipedia.org/wiki/Statistical_significance>statistical significance</a>, setting a new SOTA for report labeling on one of the largest datasets of chest x-rays.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.118.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--118 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.118 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938878 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.118" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.118/>Benchmarking Meaning Representations in Neural Semantic Parsing</a></strong><br><a href=/people/j/jiaqi-guo/>Jiaqi Guo</a>
|
<a href=/people/q/qian-liu/>Qian Liu</a>
|
<a href=/people/j/jian-guang-lou/>Jian-Guang Lou</a>
|
<a href=/people/z/zhenwen-li/>Zhenwen Li</a>
|
<a href=/people/x/xueqing-liu/>Xueqing Liu</a>
|
<a href=/people/t/tao-xie/>Tao Xie</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--118><div class="card-body p-3 small">Meaning representation is an important component of <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a>. Although researchers have designed a lot of meaning representations, recent work focuses on only a few of <a href=https://en.wikipedia.org/wiki/List_of_Latin_phrases_(M)>them</a>. Thus, the impact of meaning representation on <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a> is less understood. Furthermore, existing work&#8217;s performance is often not comprehensively evaluated due to the lack of readily-available execution engines. Upon identifying these gaps, we propose, a new unified benchmark on meaning representations, by integrating existing semantic parsing datasets, completing the missing logical forms, and implementing the missing execution engines. The resulting unified benchmark contains the complete enumeration of <a href=https://en.wikipedia.org/wiki/Logical_form>logical forms</a> and <a href=https://en.wikipedia.org/wiki/Execution_(computing)>execution engines</a> over three datasets four meaning representations. A thorough experimental study on Unimer reveals that neural semantic parsing approaches exhibit notably different performance when they are trained to generate different meaning representations. Also, program alias and <a href=https://en.wikipedia.org/wiki/Formal_grammar>grammar rules</a> heavily impact the performance of different <a href=https://en.wikipedia.org/wiki/Semantics>meaning representations</a>. Our <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark</a>, execution engines and implementation can be found on : https://github.com/JasperGuo/Unimer.<tex-math>\\times</tex-math> four meaning representations. A thorough experimental study on Unimer reveals that neural semantic parsing approaches exhibit notably different performance when they are trained to generate different meaning representations. Also, program alias and grammar rules heavily impact the performance of different meaning representations. Our benchmark, execution engines and implementation can be found on: https://github.com/JasperGuo/Unimer.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.119.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--119 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.119 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938902 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.119/>Analogous Process Structure Induction for Sub-event Sequence Prediction</a></strong><br><a href=/people/h/hongming-zhang/>Hongming Zhang</a>
|
<a href=/people/m/muhao-chen/>Muhao Chen</a>
|
<a href=/people/h/haoyu-wang/>Haoyu Wang</a>
|
<a href=/people/y/yangqiu-song/>Yangqiu Song</a>
|
<a href=/people/d/dan-roth/>Dan Roth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--119><div class="card-body p-3 small">Computational and cognitive studies of event understanding suggest that identifying, comprehending, and predicting events depend on having structured representations of a sequence of events and on conceptualizing (abstracting) its components into (soft) event categories. Thus, knowledge about a known process such as buying a car can be used in the context of a new but analogous process such as buying a house. Nevertheless, most event understanding work in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> is still at the ground level and does not consider <a href=https://en.wikipedia.org/wiki/Abstraction>abstraction</a>. In this paper, we propose an Analogous Process Structure Induction (APSI) framework, which leverages analogies among processes and conceptualization of sub-event instances to predict the whole sub-event sequence of previously unseen open-domain processes. As our experiments and analysis indicate, APSI supports the generation of meaningful sub-event sequences for unseen processes and can help predict missing events.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.123.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--123 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.123 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938691 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.123/>Semantically Inspired AMR Alignment for the <a href=https://en.wikipedia.org/wiki/Portuguese_language>Portuguese Language</a><span class=acl-fixed-case>AMR</span> Alignment for the <span class=acl-fixed-case>P</span>ortuguese Language</a></strong><br><a href=/people/r/rafael-anchieta/>Rafael Anchita</a>
|
<a href=/people/t/thiago-pardo/>Thiago Pardo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--123><div class="card-body p-3 small">Abstract Meaning Representation (AMR) is a graph-based semantic formalism where the <a href=https://en.wikipedia.org/wiki/Vertex_(graph_theory)>nodes</a> are concepts and <a href=https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms>edges</a> are relations among them. Most of AMR parsing methods require alignment between the nodes of the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a> and the words of the sentence. However, this alignment is not provided by manual annotations and available automatic aligners focus only on the <a href=https://en.wikipedia.org/wiki/English_language>English language</a>, not performing well for other languages. Aiming to fulfill this gap, we developed an alignment method for the <a href=https://en.wikipedia.org/wiki/Portuguese_language>Portuguese language</a> based on a more semantically matched word-concept pair. We performed both intrinsic and extrinsic evaluations and showed that our alignment approach outperforms the alignment strategies developed for <a href=https://en.wikipedia.org/wiki/English_language>English</a>, improving AMR parsers, and achieving competitive results with a <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> designed for the <a href=https://en.wikipedia.org/wiki/Portuguese_language>Portuguese language</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.126.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--126 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.126 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938841 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.126/>Table Fact Verification with Structure-Aware Transformer</a></strong><br><a href=/people/h/hongzhi-zhang/>Hongzhi Zhang</a>
|
<a href=/people/y/yingyao-wang/>Yingyao Wang</a>
|
<a href=/people/s/sirui-wang/>Sirui Wang</a>
|
<a href=/people/x/xuezhi-cao/>Xuezhi Cao</a>
|
<a href=/people/f/fuzheng-zhang/>Fuzheng Zhang</a>
|
<a href=/people/z/zhongyuan-wang/>Zhongyuan Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--126><div class="card-body p-3 small">Verifying fact on semi-structured evidence like tables requires the ability to encode structural information and perform <a href=https://en.wikipedia.org/wiki/Symbolic_reasoning>symbolic reasoning</a>. Pre-trained language models trained on <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language</a> could not be directly applied to encode tables, because simply linearizing tables into sequences will lose the cell alignment information. To better utilize pre-trained transformers for table representation, we propose a Structure-Aware Transformer (SAT), which injects the table structural information into the mask of the self-attention layer. A <a href=https://en.wikipedia.org/wiki/Methodology>method</a> to combine symbolic and linguistic reasoning is also explored for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. Our method outperforms <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> with 4.93 % on TabFact, a large scale table verification dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.127.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--127 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.127 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938659 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.127" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.127/>Double Graph Based Reasoning for Document-level Relation Extraction</a></strong><br><a href=/people/s/shuang-zeng/>Shuang Zeng</a>
|
<a href=/people/r/runxin-xu/>Runxin Xu</a>
|
<a href=/people/b/baobao-chang/>Baobao Chang</a>
|
<a href=/people/l/lei-li/>Lei Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--127><div class="card-body p-3 small">Document-level relation extraction aims to extract relations among entities within a document. Different from sentence-level relation extraction, it requires reasoning over multiple sentences across paragraphs. In this paper, we propose Graph Aggregation-and-Inference Network (GAIN), a method to recognize such relations for long paragraphs. GAIN constructs two <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graphs</a>, a heterogeneous mention-level graph (MG) and an entity-level graph (EG). The former captures complex interaction among different mentions and the latter aggregates mentions underlying for the same entities. Based on the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graphs</a> we propose a novel path reasoning mechanism to infer relations between entities. Experiments on the public dataset, DocRED, show GAIN achieves a significant performance improvement (2.85 on F1) over the previous <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a>. Our code is available at https://github.com/PKUnlp-icler/GAIN.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.130.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--130 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.130 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939215 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.130/>Knowledge Graph Alignment with Entity-Pair Embedding</a></strong><br><a href=/people/z/zhichun-wang/>Zhichun Wang</a>
|
<a href=/people/j/jinjian-yang/>Jinjian Yang</a>
|
<a href=/people/x/xiaoju-ye/>Xiaoju Ye</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--130><div class="card-body p-3 small">Knowledge Graph (KG) alignment is to match entities in different <a href=https://en.wikipedia.org/wiki/Knowledge_Graph>KGs</a>, which is important to knowledge fusion and integration. Recently, a number of embedding-based approaches for KG alignment have been proposed and achieved promising results. These approaches first embed <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entities</a> in low-dimensional vector spaces, and then obtain entity alignments by computations on their <a href=https://en.wikipedia.org/wiki/Vector_space>vector representations</a>. Although continuous improvements have been achieved by recent work, the performances of existing <a href=https://en.wikipedia.org/wiki/Methodology>approaches</a> are still not satisfactory. In this work, we present a new approach that directly learns embeddings of entity-pairs for KG alignment. Our approach first generates a pair-wise connectivity graph (PCG) of two KGs, whose nodes are entity-pairs and edges correspond to relation-pairs ; it then learns node (entity-pair) embeddings of the PCG, which are used to predict equivalent relations of entities. To get desirable <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a>, a <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>convolutional neural network</a> is used to generate similarity features of entity-pairs from their attributes ; and a graph neural network is employed to propagate the similarity features and get the final <a href=https://en.wikipedia.org/wiki/Embedding>embeddings of entity-pairs</a>. Experiments on five real-world datasets show that our approach can achieve the state-of-the-art KG alignment results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.134.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--134 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.134 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939015 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.134/>Beyond [ CLS ] through Ranking by Generation<span class=acl-fixed-case>CLS</span>] through Ranking by Generation</a></strong><br><a href=/people/c/cicero-dos-santos/>Cicero Nogueira dos Santos</a>
|
<a href=/people/x/xiaofei-ma/>Xiaofei Ma</a>
|
<a href=/people/r/ramesh-nallapati/>Ramesh Nallapati</a>
|
<a href=/people/z/zhiheng-huang/>Zhiheng Huang</a>
|
<a href=/people/b/bing-xiang/>Bing Xiang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--134><div class="card-body p-3 small">Generative models for <a href=https://en.wikipedia.org/wiki/Information_retrieval>Information Retrieval</a>, where ranking of documents is viewed as the task of generating a query from a document&#8217;s language model, were very successful in various IR tasks in the past. However, with the advent of modern <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural networks</a>, attention has shifted to discriminative ranking functions that model the semantic similarity of documents and queries instead. Recently, deep generative models such as GPT2 and BART have been shown to be excellent text generators, but their effectiveness as rankers have not been demonstrated yet. In this work, we revisit the generative framework for <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval</a> and show that our generative approaches are as effective as state-of-the-art semantic similarity-based discriminative models for the answer selection task. Additionally, we demonstrate the effectiveness of unlikelihood losses for IR.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.136.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--136 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.136 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938676 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.136" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.136/>Multi-document Summarization with Maximal Marginal Relevance-guided Reinforcement Learning</a></strong><br><a href=/people/y/yuning-mao/>Yuning Mao</a>
|
<a href=/people/y/yanru-qu/>Yanru Qu</a>
|
<a href=/people/y/yiqing-xie/>Yiqing Xie</a>
|
<a href=/people/x/xiang-ren/>Xiang Ren</a>
|
<a href=/people/j/jiawei-han/>Jiawei Han</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--136><div class="card-body p-3 small">While neural sequence learning methods have made significant progress in single-document summarization (SDS), they produce unsatisfactory results on <a href=https://en.wikipedia.org/wiki/Multi-document_summarization>multi-document summarization (MDS)</a>. We observe two major challenges when adapting SDS advances to MDS : (1) MDS involves larger search space and yet more limited training data, setting obstacles for neural methods to learn adequate representations ; (2) MDS needs to resolve higher information redundancy among the source documents, which SDS methods are less effective to handle. To close the gap, we present RL-MMR, Maximal Margin Relevance-guided Reinforcement Learning for MDS, which unifies advanced neural SDS methods and statistical measures used in classical MDS. RL-MMR casts MMR guidance on fewer promising candidates, which restrains the search space and thus leads to better <a href=https://en.wikipedia.org/wiki/Representation_learning>representation learning</a>. Additionally, the explicit <a href=https://en.wikipedia.org/wiki/Redundancy_(engineering)>redundancy measure</a> in MMR helps the neural representation of the summary to better capture redundancy. Extensive experiments demonstrate that RL-MMR achieves state-of-the-art performance on benchmark MDS datasets. In particular, we show the benefits of incorporating MMR into end-to-end learning when adapting SDS to MDS in terms of both learning effectiveness and <a href=https://en.wikipedia.org/wiki/Efficiency>efficiency</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.137.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--137 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.137 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939229 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.137" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.137/>Improving Neural Topic Models using Knowledge Distillation<span class=acl-fixed-case>I</span>mproving <span class=acl-fixed-case>N</span>eural <span class=acl-fixed-case>T</span>opic <span class=acl-fixed-case>M</span>odels using <span class=acl-fixed-case>K</span>nowledge <span class=acl-fixed-case>D</span>istillation</a></strong><br><a href=/people/a/alexander-miserlis-hoyle/>Alexander Miserlis Hoyle</a>
|
<a href=/people/p/pranav-goel/>Pranav Goel</a>
|
<a href=/people/p/philip-resnik/>Philip Resnik</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--137><div class="card-body p-3 small">Topic models are often used to identify human-interpretable topics to help make sense of large document collections. We use knowledge distillation to combine the best attributes of probabilistic topic models and pretrained transformers. Our modular method can be straightforwardly applied with any neural topic model to improve topic quality, which we demonstrate using two models having disparate architectures, obtaining state-of-the-art topic coherence. We show that our adaptable framework not only improves performance in the aggregate over all estimated topics, as is commonly reported, but also in head-to-head comparisons of aligned topics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.140.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--140 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.140 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.140.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938750 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.140/>Incorporating <a href=https://en.wikipedia.org/wiki/Multimodal_interaction>Multimodal Information</a> in Open-Domain Web Keyphrase Extraction</a></strong><br><a href=/people/y/yansen-wang/>Yansen Wang</a>
|
<a href=/people/z/zhen-fan/>Zhen Fan</a>
|
<a href=/people/c/carolyn-rose/>Carolyn Rose</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--140><div class="card-body p-3 small">Open-domain Keyphrase extraction (KPE) on the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>Web</a> is a fundamental yet complex NLP task with a wide range of practical applications within the field of <a href=https://en.wikipedia.org/wiki/Information_retrieval>Information Retrieval</a>. In contrast to other document types, <a href=https://en.wikipedia.org/wiki/Web_design>web page designs</a> are intended for easy navigation and <a href=https://en.wikipedia.org/wiki/Information_retrieval>information finding</a>. Effective designs encode within the layout and formatting signals that point to where the important information can be found. In this work, we propose a modeling approach that leverages these multi-modal signals to aid in the KPE task. In particular, we leverage both <a href=https://en.wikipedia.org/wiki/Lexical_analysis>lexical and visual features</a> (e.g., size, <a href=https://en.wikipedia.org/wiki/Font>font</a>, position) at the micro-level to enable effective strategy induction and meta-level features that describe pages at a macro-level to aid in strategy selection. Our evaluation demonstrates that a combination of effective strategy induction and strategy selection within this approach for the KPE task outperforms state-of-the-art models. A qualitative post-hoc analysis illustrates how these <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> function within the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.143.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--143 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.143 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.143.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938697 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.143" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.143/>Multimodal Routing : Improving Local and Global Interpretability of Multimodal Language Analysis</a></strong><br><a href=/people/y/yao-hung-hubert-tsai/>Yao-Hung Hubert Tsai</a>
|
<a href=/people/m/martin-ma/>Martin Ma</a>
|
<a href=/people/m/muqiao-yang/>Muqiao Yang</a>
|
<a href=/people/r/ruslan-salakhutdinov/>Ruslan Salakhutdinov</a>
|
<a href=/people/l/louis-philippe-morency/>Louis-Philippe Morency</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--143><div class="card-body p-3 small">The <a href=https://en.wikipedia.org/wiki/Human_language>human language</a> can be expressed through multiple sources of information known as <a href=https://en.wikipedia.org/wiki/Linguistic_modality>modalities</a>, including <a href=https://en.wikipedia.org/wiki/Tone_(linguistics)>tones of voice</a>, facial gestures, and <a href=https://en.wikipedia.org/wiki/Spoken_language>spoken language</a>. Recent <a href=https://en.wikipedia.org/wiki/Multimodal_learning>multimodal learning</a> with strong performances on human-centric tasks such as <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> and <a href=https://en.wikipedia.org/wiki/Emotion_recognition>emotion recognition</a> are often black-box, with very limited interpretability. In this paper we propose, which dynamically adjusts weights between input modalities and output representations differently for each input sample. Multimodal routing can identify relative importance of both individual modalities and cross-modality factors. Moreover, the weight assignment by <a href=https://en.wikipedia.org/wiki/Routing>routing</a> allows us to interpret modality-prediction relationships not only globally (i.e. general trends over the whole dataset), but also locally for each single input sample, meanwhile keeping competitive performance compared to state-of-the-art methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.145.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--145 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.145 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938824 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.145" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.145/>BiST : Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues<span class=acl-fixed-case>B</span>i<span class=acl-fixed-case>ST</span>: Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues</a></strong><br><a href=/people/h/hung-le/>Hung Le</a>
|
<a href=/people/d/doyen-sahoo/>Doyen Sahoo</a>
|
<a href=/people/n/nancy-chen/>Nancy Chen</a>
|
<a href=/people/s/steven-c-h-hoi/>Steven C.H. Hoi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--145><div class="card-body p-3 small">Video-grounded dialogues are very challenging due to (i) the complexity of videos which contain both spatial and temporal variations, and (ii) the complexity of user utterances which query different segments and/or different objects in videos over multiple dialogue turns. However, existing approaches to video-grounded dialogues often focus on superficial temporal-level visual cues, but neglect more fine-grained spatial signals from videos. To address this drawback, we proposed Bi-directional Spatio-Temporal Learning (BiST), a vision-language neural framework for high-resolution queries in videos based on textual cues. Specifically, our approach not only exploits both spatial and temporal-level information, but also learns dynamic information diffusion between the two feature spaces through spatial-to-temporal and temporal-to-spatial reasoning. The bidirectional strategy aims to tackle the evolving semantics of user queries in the dialogue setting. The retrieved <a href=https://en.wikipedia.org/wiki/Sensory_cue>visual cues</a> are used as <a href=https://en.wikipedia.org/wiki/Context_(language_use)>contextual information</a> to construct relevant responses to the users. Our empirical results and comprehensive qualitative analysis show that BiST achieves competitive performance and generates reasonable responses on a large-scale AVSD benchmark. We also adapt our BiST models to the Video QA setting, and substantially outperform prior approaches on the TGIF-QA benchmark.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.147.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--147 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.147 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938852 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.147" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.147/>GraphDialog : Integrating <a href=https://en.wikipedia.org/wiki/Graph_(abstract_data_type)>Graph Knowledge</a> into End-to-End Task-Oriented Dialogue Systems<span class=acl-fixed-case>G</span>raph<span class=acl-fixed-case>D</span>ialog: Integrating Graph Knowledge into End-to-End Task-Oriented Dialogue Systems</a></strong><br><a href=/people/s/shiquan-yang/>Shiquan Yang</a>
|
<a href=/people/r/rui-zhang/>Rui Zhang</a>
|
<a href=/people/s/sarah-erfani/>Sarah Erfani</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--147><div class="card-body p-3 small">End-to-end task-oriented dialogue systems aim to generate system responses directly from plain text inputs. There are two challenges for such systems : one is how to effectively incorporate external knowledge bases (KBs) into the learning framework ; the other is how to accurately capture the semantics of dialogue history. In this paper, we address these two challenges by exploiting the graph structural information in the <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge base</a> and in the dependency parsing tree of the dialogue. To effectively leverage the structural information in dialogue history, we propose a new recurrent cell architecture which allows representation learning on <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graphs</a>. To exploit the relations between entities in KBs, the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> combines multi-hop reasoning ability based on the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a>. Experimental results show that the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves consistent improvement over state-of-the-art models on two different task-oriented dialogue datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.150.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--150 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.150 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938667 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.150" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.150/>Multi-turn Response Selection using Dialogue Dependency Relations</a></strong><br><a href=/people/q/qi-jia/>Qi Jia</a>
|
<a href=/people/y/yizhu-liu/>Yizhu Liu</a>
|
<a href=/people/s/siyu-ren/>Siyu Ren</a>
|
<a href=/people/k/kenny-zhu/>Kenny Zhu</a>
|
<a href=/people/h/haifeng-tang/>Haifeng Tang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--150><div class="card-body p-3 small">Multi-turn response selection is a task designed for developing dialogue agents. The performance on this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> has a remarkable improvement with pre-trained language models. However, these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> simply concatenate the turns in dialogue history as the input and largely ignore the dependencies between the turns. In this paper, we propose a dialogue extraction algorithm to transform a dialogue history into <a href=https://en.wikipedia.org/wiki/Thread_(computing)>threads</a> based on their dependency relations. Each thread can be regarded as a self-contained sub-dialogue. We also propose Thread-Encoder model to encode <a href=https://en.wikipedia.org/wiki/Thread_(computing)>threads</a> and candidates into compact representations by pre-trained Transformers and finally get the matching score through an attention layer. The experiments show that dependency relations are helpful for dialogue context understanding, and our model outperforms the state-of-the-art baselines on both DSTC7 and DSTC8 *, with competitive results on UbuntuV2.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.155.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--155 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.155 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939216 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.155" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.155/>LOGAN : Local Group Bias Detection by Clustering<span class=acl-fixed-case>LOGAN</span>: Local Group Bias Detection by Clustering</a></strong><br><a href=/people/j/jieyu-zhao/>Jieyu Zhao</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--155><div class="card-body p-3 small">Machine learning techniques have been widely used in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP)</a>. However, as revealed by many recent studies, <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning models</a> often inherit and amplify the societal biases in data. Various metrics have been proposed to quantify biases in model predictions. In particular, several of them evaluate disparity in model performance between <a href=https://en.wikipedia.org/wiki/Protected_group>protected groups</a> and advantaged groups in the test corpus. However, we argue that evaluating bias at the corpus level is not enough for understanding how <a href=https://en.wikipedia.org/wiki/Bias>biases</a> are embedded in a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>. In fact, a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> with similar aggregated performance between different groups on the entire data may behave differently on instances in a <a href=https://en.wikipedia.org/wiki/Region>local region</a>. To analyze and detect such local bias, we propose LOGAN, a new bias detection technique based on <a href=https://en.wikipedia.org/wiki/Cluster_analysis>clustering</a>. Experiments on toxicity classification and object classification tasks show that LOGAN identifies bias in a local region and allows us to better analyze the biases in model predictions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.160.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--160 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.160 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939084 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.160" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.160/>Domain-Specific Lexical Grounding in Noisy Visual-Textual Documents<span class=acl-fixed-case>D</span>omain-<span class=acl-fixed-case>S</span>pecific <span class=acl-fixed-case>L</span>exical <span class=acl-fixed-case>G</span>rounding in <span class=acl-fixed-case>N</span>oisy <span class=acl-fixed-case>V</span>isual-<span class=acl-fixed-case>T</span>extual <span class=acl-fixed-case>D</span>ocuments</a></strong><br><a href=/people/g/gregory-yauney/>Gregory Yauney</a>
|
<a href=/people/j/jack-hessel/>Jack Hessel</a>
|
<a href=/people/d/david-mimno/>David Mimno</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--160><div class="card-body p-3 small">Images can give us insights into the contextual meanings of words, but current image-text grounding approaches require detailed annotations. Such granular annotation is rare, expensive, and unavailable in most domain-specific contexts. In contrast, unlabeled multi-image, multi-sentence documents are abundant. Can lexical grounding be learned from such documents, even though they have significant lexical and visual overlap? Working with a case study dataset of real estate listings, we demonstrate the challenge of distinguishing highly correlated grounded terms, such as kitchen and bedroom, and introduce metrics to assess this document similarity. We present a simple unsupervised clustering-based method that increases precision and recall beyond <a href=https://en.wikipedia.org/wiki/Object_detection>object detection</a> and image tagging baselines when evaluated on labeled subsets of the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. The proposed method is particularly effective for local contextual meanings of a word, for example associating <a href=https://en.wikipedia.org/wiki/Granite>granite</a> with <a href=https://en.wikipedia.org/wiki/Countertop>countertops</a> in the <a href=https://en.wikipedia.org/wiki/Real_estate>real estate dataset</a> and with rocky landscapes in a <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia dataset</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.162.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--162 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.162 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939320 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.162" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.162/>Vokenization : Improving Language Understanding with Contextualized, Visual-Grounded Supervision</a></strong><br><a href=/people/h/hao-tan/>Hao Tan</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--162><div class="card-body p-3 small">Humans learn <a href=https://en.wikipedia.org/wiki/Language>language</a> by listening, <a href=https://en.wikipedia.org/wiki/Speech>speaking</a>, <a href=https://en.wikipedia.org/wiki/Writing>writing</a>, <a href=https://en.wikipedia.org/wiki/Reading>reading</a>, and also, via interaction with the multimodal real world. Existing language pre-training frameworks show the effectiveness of text-only self-supervision while we explore the idea of a visually-supervised language model in this paper. We find that the main reason hindering this exploration is the large divergence in magnitude and distributions between the visually-grounded language datasets and pure-language corpora. Therefore, we develop a technique named vokenization that extrapolates multimodal alignments to language-only data by contextually mapping language tokens to their related images (which we call vokens). The vokenizer is trained on relatively small image captioning datasets and we then apply it to generate vokens for large language corpora. Trained with these contextually generated vokens, our visually-supervised language models show consistent improvements over self-supervised alternatives on multiple pure-language tasks such as GLUE, SQuAD, and SWAG.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.165.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--165 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.165 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939230 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.165/>FedED : Federated Learning via Ensemble Distillation for Medical Relation Extraction<span class=acl-fixed-case>F</span>ed<span class=acl-fixed-case>ED</span>: Federated Learning via Ensemble Distillation for Medical Relation Extraction</a></strong><br><a href=/people/d/dianbo-sui/>Dianbo Sui</a>
|
<a href=/people/y/yubo-chen/>Yubo Chen</a>
|
<a href=/people/j/jun-zhao/>Jun Zhao</a>
|
<a href=/people/y/yantao-jia/>Yantao Jia</a>
|
<a href=/people/y/yuantao-xie/>Yuantao Xie</a>
|
<a href=/people/w/weijian-sun/>Weijian Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--165><div class="card-body p-3 small">Unlike other domains, medical texts are inevitably accompanied by <a href=https://en.wikipedia.org/wiki/Privacy>private information</a>, so sharing or copying these <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>texts</a> is strictly restricted. However, training a medical relation extraction model requires collecting these privacy-sensitive texts and storing them on one machine, which comes in conflict with <a href=https://en.wikipedia.org/wiki/Privacy>privacy protection</a>. In this paper, we propose a privacy-preserving medical relation extraction model based on federated learning, which enables training a central model with no single piece of private local data being shared or exchanged. Though federated learning has distinct advantages in <a href=https://en.wikipedia.org/wiki/Information_privacy>privacy protection</a>, it suffers from the communication bottleneck, which is mainly caused by the need to upload cumbersome local parameters. To overcome this bottleneck, we leverage a <a href=https://en.wikipedia.org/wiki/Strategy>strategy</a> based on knowledge distillation. Such a <a href=https://en.wikipedia.org/wiki/Strategy>strategy</a> uses the uploaded predictions of <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensemble local models</a> to train the central model without requiring uploading local parameters. Experiments on three publicly available medical relation extraction datasets demonstrate the effectiveness of our method.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.167.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--167 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.167 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939349 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.167/>A Predicate-Function-Argument Annotation of Natural Language for Open-Domain Information eXpression<span class=acl-fixed-case>A</span> <span class=acl-fixed-case>P</span>redicate-<span class=acl-fixed-case>F</span>unction-<span class=acl-fixed-case>A</span>rgument <span class=acl-fixed-case>A</span>nnotation of <span class=acl-fixed-case>N</span>atural <span class=acl-fixed-case>L</span>anguage for <span class=acl-fixed-case>O</span>pen-<span class=acl-fixed-case>D</span>omain <span class=acl-fixed-case>I</span>nformation e<span class=acl-fixed-case>X</span>pression</a></strong><br><a href=/people/m/mingming-sun/>Mingming Sun</a>
|
<a href=/people/w/wenyue-hua/>Wenyue Hua</a>
|
<a href=/people/z/zoey-liu/>Zoey Liu</a>
|
<a href=/people/x/xin-wang/>Xin Wang</a>
|
<a href=/people/k/kangjie-zheng/>Kangjie Zheng</a>
|
<a href=/people/p/ping-li/>Ping Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--167><div class="card-body p-3 small">Existing OIE (Open Information Extraction) algorithms are independent of each other such that there exist lots of redundant works ; the featured strategies are not reusable and not adaptive to new tasks. This paper proposes a new <a href=https://en.wikipedia.org/wiki/Pipeline_(computing)>pipeline</a> to build OIE systems, where an Open-domain Information eXpression (OIX) task is proposed to provide a <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a> for all OIE strategies. The <a href=https://en.wikipedia.org/wiki/OIX>OIX</a> is an OIE friendly expression of a sentence without <a href=https://en.wikipedia.org/wiki/Information_loss>information loss</a>. The generation procedure of <a href=https://en.wikipedia.org/wiki/OIX>OIX</a> contains shared works of OIE algorithms so that OIE strategies can be developed on the platform of <a href=https://en.wikipedia.org/wiki/OIX>OIX</a> as inference operations focusing on more critical problems. Based on the same platform of <a href=https://en.wikipedia.org/wiki/OIX>OIX</a>, the OIE strategies are reusable, and people can select a set of <a href=https://en.wikipedia.org/wiki/Strategy>strategies</a> to assemble their <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> for a specific task so that the adaptability may be significantly increased. This paper focuses on the task of OIX and propose a solution Open Information Annotation (OIA). OIA is a predicate-function-argument annotation for sentences. We label a data set of sentence-OIA pairs and propose a dependency-based rule system to generate OIA annotations from sentences. The evaluation results reveal that learning the OIA from a sentence is a challenge owing to the complexity of natural language sentences, and it is worthy of attracting more attention from the research community.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.171.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--171 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.171 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939140 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.171" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.171/>Understanding the Mechanics of SPIGOT : Surrogate Gradients for Latent Structure Learning<span class=acl-fixed-case>SPIGOT</span>: Surrogate Gradients for Latent Structure Learning</a></strong><br><a href=/people/t/tsvetomila-mihaylova/>Tsvetomila Mihaylova</a>
|
<a href=/people/v/vlad-niculae/>Vlad Niculae</a>
|
<a href=/people/a/andre-f-t-martins/>Andr F. T. Martins</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--171><div class="card-body p-3 small">Latent structure models are a powerful tool for modeling language data : they can mitigate the error propagation and annotation bottleneck in pipeline systems, while simultaneously uncovering linguistic insights about the data. One challenge with end-to-end training of these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> is the argmax operation, which has null gradient. In this paper, we focus on surrogate gradients, a popular strategy to deal with this problem. We explore latent structure learning through the angle of pulling back the downstream learning objective. In this paradigm, we discover a principled motivation for both the straight-through estimator (STE) as well as the recently-proposed SPIGOT a variant of STE for structured models. Our perspective leads to new <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> in the same family. We empirically compare the known and the novel pulled-back estimators against the popular alternatives, yielding new insight for practitioners and revealing intriguing failure cases.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.177.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--177 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.177 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939290 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.177" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.177/>Pronoun-Targeted Fine-tuning for NMT with Hybrid Losses<span class=acl-fixed-case>NMT</span> with Hybrid Losses</a></strong><br><a href=/people/p/prathyusha-jwalapuram/>Prathyusha Jwalapuram</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/y/youlin-shen/>Youlin Shen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--177><div class="card-body p-3 small">Popular Neural Machine Translation model training uses strategies like backtranslation to improve BLEU scores, requiring large amounts of additional data and training. We introduce a class of conditional generative-discriminative hybrid losses that we use to fine-tune a trained <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation model</a>. Through a combination of targeted fine-tuning objectives and intuitive re-use of the training data the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> has failed to adequately learn from, we improve the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> performance of both a sentence-level and a contextual model without using any additional data. We target the improvement of pronoun translations through our <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> and evaluate our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on a pronoun benchmark testset. Our sentence-level model shows a 0.5 BLEU improvement on both the WMT14 and the IWSLT13 De-En testsets, while our contextual model achieves the best results, improving from 31.81 to 32 BLEU on WMT14 De-En testset, and from 32.10 to 33.13 on the IWSLT13 De-En testset, with corresponding improvements in pronoun translation. We further show the generalizability of our method by reproducing the improvements on two additional language pairs, Fr-En and Cs-En.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.182.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--182 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.182 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939221 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.182" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.182/>Adversarial Attack and Defense of Structured Prediction Models</a></strong><br><a href=/people/w/wenjuan-han/>Wenjuan Han</a>
|
<a href=/people/l/liwen-zhang/>Liwen Zhang</a>
|
<a href=/people/y/yong-jiang/>Yong Jiang</a>
|
<a href=/people/k/kewei-tu/>Kewei Tu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--182><div class="card-body p-3 small">Building an effective adversarial attacker and elaborating on countermeasures for adversarial attacks for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP)</a> have attracted a lot of research in recent years. However, most of the existing approaches focus on <a href=https://en.wikipedia.org/wiki/Taxonomy_(biology)>classification problems</a>. In this paper, we investigate attacks and defenses for structured prediction tasks in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. Besides the difficulty of perturbing discrete words and the sentence fluency problem faced by attackers in any NLP tasks, there is a specific challenge to attackers of structured prediction models : the structured output of structured prediction models is sensitive to small perturbations in the input. To address these problems, we propose a novel and unified framework that learns to attack a structured prediction model using a sequence-to-sequence model with feedbacks from multiple reference models of the same structured prediction task. Based on the proposed attack, we further reinforce the victim model with <a href=https://en.wikipedia.org/wiki/Adversarial_learning>adversarial training</a>, making its prediction more robust and accurate. We evaluate the proposed <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> in <a href=https://en.wikipedia.org/wiki/Dependency_grammar>dependency parsing</a> and <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a>. Automatic and human evaluations show that our proposed framework succeeds in both attacking state-of-the-art structured prediction models and boosting them with adversarial training.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.183.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--183 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.183 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.183.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939300 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.183" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.183/>Position-Aware Tagging for Aspect Sentiment Triplet Extraction</a></strong><br><a href=/people/l/lu-xu/>Lu Xu</a>
|
<a href=/people/h/hao-li/>Hao Li</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--183><div class="card-body p-3 small">Aspect Sentiment Triplet Extraction (ASTE) is the task of extracting the triplets of target entities, their associated sentiment, and opinion spans explaining the reason for the sentiment. Existing research efforts mostly solve this problem using pipeline approaches, which break the triplet extraction process into several stages. Our observation is that the three elements within a triplet are highly related to each other, and this motivates us to build a joint model to extract such triplets using a sequence tagging approach. However, how to effectively design a tagging approach to extract the triplets that can capture the rich interactions among the elements is a challenging research question. In this work, we propose the first <a href=https://en.wikipedia.org/wiki/End-to-end_principle>end-to-end model</a> with a novel position-aware tagging scheme that is capable of jointly extracting the <a href=https://en.wikipedia.org/wiki/Multiple_birth>triplets</a>. Our experimental results on several existing datasets show that jointly capturing elements in the triplet using our approach leads to improved performance over the existing approaches. We also conducted extensive experiments to investigate the model effectiveness and robustness.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.184.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--184 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.184 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938900 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.184" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.184/>Simultaneous Machine Translation with Visual Context</a></strong><br><a href=/people/o/ozan-caglayan/>Ozan Caglayan</a>
|
<a href=/people/j/julia-ive/>Julia Ive</a>
|
<a href=/people/v/veneta-haralampieva/>Veneta Haralampieva</a>
|
<a href=/people/p/pranava-swaroop-madhyastha/>Pranava Madhyastha</a>
|
<a href=/people/l/loic-barrault/>Loc Barrault</a>
|
<a href=/people/l/lucia-specia/>Lucia Specia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--184><div class="card-body p-3 small">Simultaneous machine translation (SiMT) aims to translate a continuous input text stream into another language with the lowest <a href=https://en.wikipedia.org/wiki/Latency_(engineering)>latency</a> and highest quality possible. The <a href=https://en.wikipedia.org/wiki/Translation>translation</a> thus has to start with an incomplete source text, which is read progressively, creating the need for anticipation. In this paper, we seek to understand whether the addition of <a href=https://en.wikipedia.org/wiki/Visual_system>visual information</a> can compensate for the missing source context. To this end, we analyse the impact of different multimodal approaches and visual features on state-of-the-art SiMT frameworks. Our results show that visual context is helpful and that visually-grounded models based on explicit object region information are much better than commonly used global features, reaching up to 3 BLEU points improvement under low latency scenarios. Our qualitative analysis illustrates cases where only the multimodal systems are able to translate correctly from <a href=https://en.wikipedia.org/wiki/English_language>English</a> into gender-marked languages, as well as deal with differences in word order, such as adjective-noun placement between <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/French_language>French</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.186.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--186 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.186 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.186.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939057 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.186/>The Secret is in the <a href=https://en.wikipedia.org/wiki/Electromagnetic_spectrum>Spectra</a> : Predicting Cross-lingual Task Performance with Spectral Similarity Measures</a></strong><br><a href=/people/h/haim-dubossarsky/>Haim Dubossarsky</a>
|
<a href=/people/i/ivan-vulic/>Ivan Vuli</a>
|
<a href=/people/r/roi-reichart/>Roi Reichart</a>
|
<a href=/people/a/anna-korhonen/>Anna Korhonen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--186><div class="card-body p-3 small">Performance in cross-lingual NLP tasks is impacted by the (dis)similarity of languages at hand : e.g., previous work has suggested there is a connection between the expected success of bilingual lexicon induction (BLI) and the assumption of (approximate) isomorphism between monolingual embedding spaces. In this work we present a large-scale study focused on the correlations between monolingual embedding space similarity and task performance, covering thousands of language pairs and four different tasks : BLI, <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a>, POS tagging and MT. We hypothesize that statistics of the <a href=https://en.wikipedia.org/wiki/Spectrum_(functional_analysis)>spectrum</a> of each monolingual embedding space indicate how well they can be aligned. We then introduce several isomorphism measures between two <a href=https://en.wikipedia.org/wiki/Embedding>embedding spaces</a>, based on the relevant statistics of their individual spectra. We empirically show that (1) language similarity scores derived from such spectral isomorphism measures are strongly associated with performance observed in different cross-lingual tasks, and (2) our spectral-based measures consistently outperform previous standard isomorphism measures, while being computationally more tractable and easier to interpret. Finally, our <a href=https://en.wikipedia.org/wiki/Measure_(mathematics)>measures</a> capture complementary information to typologically driven language distance measures, and the combination of <a href=https://en.wikipedia.org/wiki/Measure_(mathematics)>measures</a> from the two families yields even higher task performance correlations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.188.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--188 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.188 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.188/>AnswerFact : Fact Checking in Product Question Answering<span class=acl-fixed-case>A</span>nswer<span class=acl-fixed-case>F</span>act: Fact Checking in Product Question Answering</a></strong><br><a href=/people/w/wenxuan-zhang/>Wenxuan Zhang</a>
|
<a href=/people/y/yang-deng/>Yang Deng</a>
|
<a href=/people/j/jing-ma/>Jing Ma</a>
|
<a href=/people/w/wai-lam/>Wai Lam</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--188><div class="card-body p-3 small">Product-related question answering platforms nowadays are widely employed in many E-commerce sites, providing a convenient way for potential customers to address their concerns during <a href=https://en.wikipedia.org/wiki/Online_shopping>online shopping</a>. However, the misinformation in the answers on those <a href=https://en.wikipedia.org/wiki/Computing_platform>platforms</a> poses unprecedented challenges for users to obtain reliable and truthful product information, which may even cause a commercial loss in <a href=https://en.wikipedia.org/wiki/E-commerce>E-commerce business</a>. To tackle this issue, we investigate to predict the veracity of answers in this paper and introduce AnswerFact, a large scale fact checking dataset from product question answering forums. Each answer is accompanied by its veracity label and associated evidence sentences, providing a valuable testbed for evidence-based fact checking tasks in QA settings. We further propose a novel neural model with tailored evidence ranking components to handle the concerned answer veracity prediction problem. Extensive experiments are conducted with our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> and various existing fact checking methods, showing that our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> outperforms all baselines on this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.190.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--190 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.190 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939080 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.190" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.190/>What do Models Learn from Question Answering Datasets?</a></strong><br><a href=/people/p/priyanka-sen/>Priyanka Sen</a>
|
<a href=/people/a/amir-saffari/>Amir Saffari</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--190><div class="card-body p-3 small">While models have reached superhuman performance on popular <a href=https://en.wikipedia.org/wiki/Question_answering>question answering (QA) datasets</a> such as SQuAD, they have yet to outperform <a href=https://en.wikipedia.org/wiki/Human>humans</a> on the task of <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a> itself. In this paper, we investigate if <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are learning <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a> from QA datasets by evaluating BERT-based models across five datasets. We evaluate models on their generalizability to out-of-domain examples, responses to missing or incorrect data, and ability to handle question variations. We find that no single <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> is robust to all of our experiments and identify shortcomings in both <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> and evaluation methods. Following our analysis, we make recommendations for building future QA datasets that better evaluate the task of <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a> through <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a>. We also release code to convert QA datasets to a shared format for easier experimentation at https://github.com/amazon-research/qa-dataset-converter</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.193.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--193 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.193 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938858 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.193/>Neural Deepfake Detection with Factual Structure of Text</a></strong><br><a href=/people/w/wanjun-zhong/>Wanjun Zhong</a>
|
<a href=/people/d/duyu-tang/>Duyu Tang</a>
|
<a href=/people/z/zenan-xu/>Zenan Xu</a>
|
<a href=/people/r/ruize-wang/>Ruize Wang</a>
|
<a href=/people/n/nan-duan/>Nan Duan</a>
|
<a href=/people/m/ming-zhou/>Ming Zhou</a>
|
<a href=/people/j/jiahai-wang/>Jiahai Wang</a>
|
<a href=/people/j/jian-yin/>Jian Yin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--193><div class="card-body p-3 small">Deepfake detection, the task of automatically discriminating machine-generated text, is increasingly critical with recent advances in natural language generative models. Existing approaches to deepfake detection typically represent documents with coarse-grained representations. However, they struggle to capture factual structures of documents, which is a discriminative factor between machine-generated and human-written text according to our statistical analysis. To address this, we propose a graph-based model that utilizes the factual structure of a document for deepfake detection of text. Our approach represents the factual structure of a given document as an <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity graph</a>, which is further utilized to learn <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence representations</a> with a graph neural network. Sentence representations are then composed to a document representation for making predictions, where consistent relations between neighboring sentences are sequentially modeled. Results of experiments on two public deepfake datasets show that our approach significantly improves strong base models built with RoBERTa. Model analysis further indicates that our model can distinguish the difference in the factual structure between machine-generated text and <a href=https://en.wikipedia.org/wiki/Written_language>human-written text</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.194.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--194 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.194 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938833 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.194" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.194/>MultiCQA : Zero-Shot Transfer of Self-Supervised Text Matching Models on a Massive Scale<span class=acl-fixed-case>M</span>ulti<span class=acl-fixed-case>CQA</span>: Zero-Shot Transfer of Self-Supervised Text Matching Models on a Massive Scale</a></strong><br><a href=/people/a/andreas-ruckle/>Andreas Rckl</a>
|
<a href=/people/j/jonas-pfeiffer/>Jonas Pfeiffer</a>
|
<a href=/people/i/iryna-gurevych/>Iryna Gurevych</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--194><div class="card-body p-3 small">We study the zero-shot transfer capabilities of text matching models on a massive scale, by self-supervised training on 140 source domains from community question answering forums in English. We investigate the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performances on nine benchmarks of answer selection and question similarity tasks, and show that all 140 models transfer surprisingly well, where the large majority of <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> substantially outperforms common IR baselines. We also demonstrate that considering a broad selection of source domains is crucial for obtaining the best zero-shot transfer performances, which contrasts the standard procedure that merely relies on the largest and most similar domains. In addition, we extensively study how to best combine multiple source domains. We propose to incorporate self-supervised with supervised multi-task learning on all available source domains. Our best zero-shot transfer model considerably outperforms in-domain BERT and the previous state of the art on six benchmarks. Fine-tuning of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> with in-domain data results in additional large gains and achieves the new state of the art on all nine benchmarks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.195.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--195 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.195 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938960 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.195" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.195/>XL-AMR : Enabling Cross-Lingual AMR Parsing with Transfer Learning Techniques<span class=acl-fixed-case>XL</span>-<span class=acl-fixed-case>AMR</span>: Enabling Cross-Lingual <span class=acl-fixed-case>AMR</span> Parsing with Transfer Learning Techniques</a></strong><br><a href=/people/r/rexhina-blloshmi/>Rexhina Blloshmi</a>
|
<a href=/people/r/rocco-tripodi/>Rocco Tripodi</a>
|
<a href=/people/r/roberto-navigli/>Roberto Navigli</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--195><div class="card-body p-3 small">Abstract Meaning Representation (AMR) is a popular formalism of natural language that represents the meaning of a sentence as a semantic graph. It is agnostic about how to derive meanings from strings and for this reason it lends itself well to the encoding of semantics across languages. However, cross-lingual AMR parsing is a hard task, because training data are scarce in languages other than <a href=https://en.wikipedia.org/wiki/English_language>English</a> and the existing <a href=https://en.wikipedia.org/wiki/English_language>English AMR parsers</a> are not directly suited to being used in a cross-lingual setting. In this work we tackle these two problems so as to enable cross-lingual AMR parsing : we explore different transfer learning techniques for producing automatic AMR annotations across languages and develop a cross-lingual AMR parser, XL-AMR. This can be trained on the produced data and does not rely on AMR aligners or source-copy mechanisms as is commonly the case in English AMR parsing. The results of XL-AMR significantly surpass those previously reported in <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>, <a href=https://en.wikipedia.org/wiki/German_language>German</a>, <a href=https://en.wikipedia.org/wiki/Italian_language>Italian</a> and <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>. Finally we provide a qualitative analysis which sheds light on the suitability of AMR across languages. We release XL-AMR at github.com/SapienzaNLP/xl-amr.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.196.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--196 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.196 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939049 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.196" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.196/>Improving AMR Parsing with Sequence-to-Sequence Pre-training<span class=acl-fixed-case>AMR</span> Parsing with Sequence-to-Sequence Pre-training</a></strong><br><a href=/people/d/dongqin-xu/>Dongqin Xu</a>
|
<a href=/people/j/junhui-li/>Junhui Li</a>
|
<a href=/people/m/muhua-zhu/>Muhua Zhu</a>
|
<a href=/people/m/min-zhang/>Min Zhang</a>
|
<a href=/people/g/guodong-zhou/>Guodong Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--196><div class="card-body p-3 small">In the literature, the research on abstract meaning representation (AMR) parsing is much restricted by the size of human-curated dataset which is critical to build an AMR parser with good performance. To alleviate such data size restriction, pre-trained models have been drawing more and more attention in AMR parsing. However, previous pre-trained models, like BERT, are implemented for general purpose which may not work as expected for the specific task of AMR parsing. In this paper, we focus on sequence-to-sequence (seq2seq) AMR parsing and propose a seq2seq pre-training approach to build pre-trained models in both single and joint way on three relevant <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>, i.e., <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, <a href=https://en.wikipedia.org/wiki/Syntactic_parsing>syntactic parsing</a>, and AMR parsing itself. Moreover, we extend the vanilla fine-tuning method to a multi-task learning fine-tuning method that optimizes for the performance of AMR parsing while endeavors to preserve the response of pre-trained models. Extensive experimental results on two English benchmark datasets show that both the single and joint pre-trained models significantly improve the performance (e.g., from 71.5 to 80.2 on AMR 2.0), which reaches the state of the art. The result is very encouraging since we achieve this with seq2seq models rather than <a href=https://en.wikipedia.org/wiki/Complex_analysis>complex models</a>. We make our code and model available at https:// github.com/xdqkid/S2S-AMR-Parser.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.197.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--197 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.197 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938955 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.197/>Hate-Speech and Offensive Language Detection in <a href=https://en.wikipedia.org/wiki/Roman_Urdu>Roman Urdu</a><span class=acl-fixed-case>R</span>oman <span class=acl-fixed-case>U</span>rdu</a></strong><br><a href=/people/h/hammad-rizwan/>Hammad Rizwan</a>
|
<a href=/people/m/muhammad-haroon-shakeel/>Muhammad Haroon Shakeel</a>
|
<a href=/people/a/asim-karim/>Asim Karim</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--197><div class="card-body p-3 small">The task of automatic hate-speech and offensive language detection in social media content is of utmost importance due to its implications in unprejudiced society concerning race, gender, or religion. Existing research in this area, however, is mainly focused on the <a href=https://en.wikipedia.org/wiki/English_language>English language</a>, limiting the applicability to particular demographics. Despite its prevalence, Roman Urdu (RU) lacks language resources, <a href=https://en.wikipedia.org/wiki/Annotation>annotated datasets</a>, and <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> for this task. In this study, we : (1) Present a lexicon of hateful words in RU, (2) Develop an annotated dataset called RUHSOLD consisting of 10,012 tweets in RU with both coarse-grained and fine-grained labels of hate-speech and offensive language, (3) Explore the feasibility of transfer learning of five existing embedding models to RU, (4) Propose a novel deep learning architecture called CNN-gram for hate-speech and offensive language detection and compare its performance with seven current baseline approaches on RUHSOLD dataset, and (5) Train domain-specific embeddings on more than 4.7 million tweets and make them publicly available. We conclude that <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> is more beneficial as compared to training embedding from scratch and that the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> exhibits greater <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> as compared to the baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.199.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--199 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.199 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939035 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.199/>Comparative Evaluation of Label-Agnostic Selection Bias in Multilingual Hate Speech Datasets</a></strong><br><a href=/people/n/nedjma-ousidhoum/>Nedjma Ousidhoum</a>
|
<a href=/people/y/yangqiu-song/>Yangqiu Song</a>
|
<a href=/people/d/dit-yan-yeung/>Dit-Yan Yeung</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--199><div class="card-body p-3 small">Work on bias in <a href=https://en.wikipedia.org/wiki/Hate_speech>hate speech</a> typically aims to improve <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> performance while relatively overlooking the quality of the data. We examine <a href=https://en.wikipedia.org/wiki/Selection_bias>selection bias</a> in <a href=https://en.wikipedia.org/wiki/Hate_speech>hate speech</a> in a language and label independent fashion. We first use topic models to discover latent semantics in eleven hate speech corpora, then, we present two bias evaluation metrics based on the semantic similarity between topics and search words frequently used to build corpora. We discuss the possibility of revising the data collection process by comparing datasets and analyzing contrastive case studies.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.203.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--203 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.203 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.203.OptionalSupplementaryMaterial.tgz data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938871 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.203" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.203/>Towards Reasonably-Sized Character-Level Transformer NMT by Finetuning Subword Systems<span class=acl-fixed-case>NMT</span> by Finetuning Subword Systems</a></strong><br><a href=/people/j/jindrich-libovicky/>Jindich Libovick</a>
|
<a href=/people/a/alexander-fraser/>Alexander Fraser</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--203><div class="card-body p-3 small">Applying the Transformer architecture on the character level usually requires very deep architectures that are difficult and slow to train. These problems can be partially overcome by incorporating a segmentation into tokens in the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>. We show that by initially training a subword model and then finetuning it on characters, we can obtain a neural machine translation model that works at the character level without requiring token segmentation. We use only the vanilla 6-layer Transformer Base architecture. Our character-level models better capture morphological phenomena and show more robustness to <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noise</a> at the expense of somewhat worse overall translation quality. Our study is a significant step towards high-performance and easy to train character-based models that are not extremely large.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.207.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--207 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.207 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939088 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.207" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.207/>Not Low-Resource Anymore : Aligner Ensembling, Batch Filtering, and New Datasets for Bengali-English Machine Translation<span class=acl-fixed-case>B</span>engali-<span class=acl-fixed-case>E</span>nglish Machine Translation</a></strong><br><a href=/people/t/tahmid-hasan/>Tahmid Hasan</a>
|
<a href=/people/a/abhik-bhattacharjee/>Abhik Bhattacharjee</a>
|
<a href=/people/k/kazi-samin/>Kazi Samin</a>
|
<a href=/people/m/masum-hasan/>Masum Hasan</a>
|
<a href=/people/m/madhusudan-basak/>Madhusudan Basak</a>
|
<a href=/people/m/m-sohel-rahman/>M. Sohel Rahman</a>
|
<a href=/people/r/rifat-shahriyar/>Rifat Shahriyar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--207><div class="card-body p-3 small">Despite being the seventh most widely spoken language in the world, <a href=https://en.wikipedia.org/wiki/Bengali_language>Bengali</a> has received much less attention in machine translation literature due to being low in resources. Most publicly available <a href=https://en.wikipedia.org/wiki/Parallel_text>parallel corpora</a> for <a href=https://en.wikipedia.org/wiki/Bengali_language>Bengali</a> are not large enough ; and have rather poor quality, mostly because of incorrect sentence alignments resulting from erroneous sentence segmentation, and also because of a high volume of noise present in them. In this work, we build a customized sentence segmenter for <a href=https://en.wikipedia.org/wiki/Bengali_language>Bengali</a> and propose two novel methods for parallel corpus creation on low-resource setups : aligner ensembling and batch filtering. With the segmenter and the two methods combined, we compile a high-quality Bengali-English parallel corpus comprising of 2.75 million sentence pairs, more than 2 million of which were not available before. Training on <a href=https://en.wikipedia.org/wiki/Artificial_neural_network>neural models</a>, we achieve an improvement of more than 9 <a href=https://en.wikipedia.org/wiki/BLEU>BLEU score</a> over previous approaches to Bengali-English machine translation. We also evaluate on a new test set of 1000 pairs made with extensive <a href=https://en.wikipedia.org/wiki/Quality_control>quality control</a>. We release the segmenter, <a href=https://en.wikipedia.org/wiki/Parallel_text>parallel corpus</a>, and the evaluation set, thus elevating <a href=https://en.wikipedia.org/wiki/Bengali_language>Bengali</a> from its low-resource status. To the best of our knowledge, this is the first ever large scale study on Bengali-English machine translation. We believe our study will pave the way for future research on Bengali-English machine translation as well as other low-resource languages. Our data and code are available at https://github.com/csebuetnlp/banglanmt.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.210.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--210 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.210 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939388 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.210" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.210/>Pre-training Multilingual Neural Machine Translation by Leveraging Alignment Information</a></strong><br><a href=/people/z/zehui-lin/>Zehui Lin</a>
|
<a href=/people/x/xiao-pan/>Xiao Pan</a>
|
<a href=/people/m/mingxuan-wang/>Mingxuan Wang</a>
|
<a href=/people/x/xipeng-qiu/>Xipeng Qiu</a>
|
<a href=/people/j/jiangtao-feng/>Jiangtao Feng</a>
|
<a href=/people/h/hao-zhou/>Hao Zhou</a>
|
<a href=/people/l/lei-li/>Lei Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--210><div class="card-body p-3 small">We investigate the following question for machine translation (MT): can we develop a single universal MT model to serve as the common seed and obtain derivative and improved models on arbitrary language pairs? We propose mRASP, an approach to pre-train a universal multilingual neural machine translation model. Our key idea in mRASP is its novel technique of random aligned substitution, which brings words and phrases with similar meanings across multiple languages closer in the representation space. We pre-train a mRASP model on 32 language pairs jointly with only public datasets. The <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> is then fine-tuned on downstream language pairs to obtain specialized MT models. We carry out extensive experiments on 42 translation directions across a diverse settings, including low, medium, rich resource, and as well as transferring to exotic language pairs. Experimental results demonstrate that mRASP achieves significant performance improvement compared to directly training on those target pairs. It is the first time to verify that multiple lowresource language pairs can be utilized to improve rich resource MT. Surprisingly, mRASP is even able to improve the translation quality on exotic languages that never occur in the pretraining corpus. Code, data, and pre-trained models are available at https://github. com / linzehui / mRASP.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.211.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--211 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.211 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938739 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.211/>Losing Heads in the Lottery : Pruning Transformer Attention in Neural Machine Translation</a></strong><br><a href=/people/m/maximiliana-behnke/>Maximiliana Behnke</a>
|
<a href=/people/k/kenneth-heafield/>Kenneth Heafield</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--211><div class="card-body p-3 small">The attention mechanism is the crucial component of the transformer architecture. Recent research shows that most <a href=https://en.wikipedia.org/wiki/Attentional_control>attention heads</a> are not confident in their decisions and can be pruned. However, removing them before training a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> results in lower quality. In this paper, we apply the lottery ticket hypothesis to prune heads in the early stages of training. Our experiments on <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> show that it is possible to remove up to three-quarters of attention heads from transformer-big during early training with an average -0.1 change in <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a> for <a href=https://en.wikipedia.org/wiki/Turkish_language>TurkishEnglish</a>. The pruned model is 1.5 times as fast at <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference</a>, albeit at the cost of longer training. Our method is complementary to other approaches, such as teacher-student, with EnglishGerman student model gaining an additional 10 % speed-up with 75 % encoder attention removed and 0.2 BLEU loss.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.212.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--212 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.212 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938760 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.212/>Towards Enhancing <a href=https://en.wikipedia.org/wiki/Faithfulness>Faithfulness</a> for Neural Machine Translation</a></strong><br><a href=/people/r/rongxiang-weng/>Rongxiang Weng</a>
|
<a href=/people/h/heng-yu/>Heng Yu</a>
|
<a href=/people/x/xiangpeng-wei/>Xiangpeng Wei</a>
|
<a href=/people/w/weihua-luo/>Weihua Luo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--212><div class="card-body p-3 small">Neural machine translation (NMT) has achieved great success due to the ability to generate high-quality sentences. Compared with human translations, one of the drawbacks of current NMT is that translations are not usually faithful to the input, e.g., omitting information or generating unrelated fragments, which inevitably decreases the overall quality, especially for human readers. In this paper, we propose a novel <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training strategy</a> with a multi-task learning paradigm to build a faithfulness enhanced NMT model (named FEnmt). During the NMT training process, we sample a subset from the training set and translate them to get fragments that have been mistranslated. Afterward, the proposed multi-task learning paradigm is employed on both <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> and decoder to guide <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NMT</a> to correctly translate these fragments. Both automatic and human evaluations verify that our FEnmt could improve translation quality by effectively reducing unfaithful translations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.217.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--217 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.217 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938800 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.217" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.217/>Can Automatic Post-Editing Improve NMT?<span class=acl-fixed-case>NMT</span>?</a></strong><br><a href=/people/s/shamil-chollampatt/>Shamil Chollampatt</a>
|
<a href=/people/r/raymond-hendy-susanto/>Raymond Hendy Susanto</a>
|
<a href=/people/l/liling-tan/>Liling Tan</a>
|
<a href=/people/e/ewa-szymanska/>Ewa Szymanska</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--217><div class="card-body p-3 small">Automatic post-editing (APE) aims to improve <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translations</a>, thereby reducing human post-editing effort. APE has had notable success when used with statistical machine translation (SMT) systems but has not been as successful over neural machine translation (NMT) systems. This has raised questions on the relevance of APE task in the current scenario. However, the training of APE models has been heavily reliant on large-scale artificial corpora combined with only limited human post-edited data. We hypothesize that APE models have been underperforming in improving NMT translations due to the lack of adequate supervision. To ascertain our hypothesis, we compile a larger corpus of human post-edits of English to German NMT. We empirically show that a state-of-art neural APE model trained on this <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> can significantly improve a strong in-domain NMT system, challenging the current understanding in the field. We further investigate the effects of varying training data sizes, using <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>artificial training data</a>, and <a href=https://en.wikipedia.org/wiki/Domain_specificity>domain specificity</a> for the APE task. We release this new <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> under CC BY-NC-SA 4.0 license at https://github.com/shamilcm/pedra.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.220.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--220 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.220 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.220.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938710 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.220/>Some Languages Seem Easier to Parse Because Their Treebanks Leak</a></strong><br><a href=/people/a/anders-sogaard/>Anders Sgaard</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--220><div class="card-body p-3 small">Cross-language differences in (universal) dependency parsing performance are mostly attributed to treebank size, average sentence length, average dependency length, morphological complexity, and domain differences. We point at a factor not previously discussed : If we abstract away from words and dependency labels, how many <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graphs</a> in the test data were seen in the training data? We compute graph isomorphisms, and show that, treebank size aside, overlap between training and test graphs explain more of the observed variation than standard explanations such as the above.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.222.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--222 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.222 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938796 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.222/>Modularized Syntactic Neural Networks for Sentence Classification</a></strong><br><a href=/people/h/haiyan-wu/>Haiyan Wu</a>
|
<a href=/people/y/ying-liu/>Ying Liu</a>
|
<a href=/people/s/shaoyun-shi/>Shaoyun Shi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--222><div class="card-body p-3 small">This paper focuses on tree-based modeling for the sentence classification task. In existing works, aggregating on a <a href=https://en.wikipedia.org/wiki/Syntax_tree>syntax tree</a> usually considers local information of sub-trees. In contrast, in addition to the local information, our proposed Modularized Syntactic Neural Network (MSNN) utilizes the syntax category labels and takes advantage of the global context while modeling sub-trees. In MSNN, each <a href=https://en.wikipedia.org/wiki/Node_(computer_science)>node</a> of a <a href=https://en.wikipedia.org/wiki/Syntax_tree>syntax tree</a> is modeled by a label-related syntax module. Each syntax module aggregates the outputs of lower-level modules, and finally, the root module provides the <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence representation</a>. We design a tree-parallel mini-batch strategy for efficient <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training</a> and predicting. Experimental results on four benchmark datasets show that our MSNN significantly outperforms previous state-of-the-art tree-based methods on the sentence classification task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.226.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--226 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.226 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938958 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.226/>MEGATRON-CNTRL : Controllable Story Generation with External Knowledge Using Large-Scale Language Models<span class=acl-fixed-case>MEGATRON</span>-<span class=acl-fixed-case>CNTRL</span>: Controllable Story Generation with External Knowledge Using Large-Scale Language Models</a></strong><br><a href=/people/p/peng-xu/>Peng Xu</a>
|
<a href=/people/m/mostofa-patwary/>Mostofa Patwary</a>
|
<a href=/people/m/mohammad-shoeybi/>Mohammad Shoeybi</a>
|
<a href=/people/r/raul-puri/>Raul Puri</a>
|
<a href=/people/p/pascale-fung/>Pascale Fung</a>
|
<a href=/people/a/animashree-anandkumar/>Anima Anandkumar</a>
|
<a href=/people/b/bryan-catanzaro/>Bryan Catanzaro</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--226><div class="card-body p-3 small">Existing pre-trained large language models have shown unparalleled generative capabilities. However, <a href=https://en.wikipedia.org/wiki/Copula_(linguistics)>they</a> are not controllable. In this paper, we propose MEGATRON-CNTRL, a novel framework that uses large-scale language models and adds control to text generation by incorporating an external knowledge base. Our framework consists of a keyword predictor, a <a href=https://en.wikipedia.org/wiki/Knowledge_retrieval>knowledge retriever</a>, a contextual knowledge ranker, and a conditional text generator. As we do not have access to ground-truth supervision for the knowledge ranker, we make use of weak supervision from <a href=https://en.wikipedia.org/wiki/Sentence_embedding>sentence embedding</a>. The empirical results show that our model generates more fluent, consistent, and coherent stories with less <a href=https://en.wikipedia.org/wiki/Repetition_(rhetorical_device)>repetition</a> and higher <a href=https://en.wikipedia.org/wiki/Multiculturalism>diversity</a> compared to prior work on the ROC story dataset. We showcase the controllability of our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> by replacing the <a href=https://en.wikipedia.org/wiki/Index_term>keywords</a> used to generate stories and re-running the generation process. Human evaluation results show that 77.5 % of these stories are successfully controlled by the new <a href=https://en.wikipedia.org/wiki/Index_term>keywords</a>. Furthermore, by scaling our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> from 124 million to 8.3 billion parameters we demonstrate that larger models improve both the <a href=https://en.wikipedia.org/wiki/Quality_(business)>quality of generation</a> (from 74.5 % to 93.0 % for <a href=https://en.wikipedia.org/wiki/Consistency_(statistics)>consistency</a>) and <a href=https://en.wikipedia.org/wiki/Controllability>controllability</a> (from 77.5 % to 91.5 %).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.228.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--228 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.228 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939097 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.228/>Improving Grammatical Error Correction Models with Purpose-Built Adversarial Examples</a></strong><br><a href=/people/l/lihao-wang/>Lihao Wang</a>
|
<a href=/people/x/xiaoqing-zheng/>Xiaoqing Zheng</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--228><div class="card-body p-3 small">A sequence-to-sequence (seq2seq) learning with <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> empirically shows to be an effective framework for grammatical error correction (GEC), which takes a sentence with errors as input and outputs the corrected one. However, the performance of GEC models with the seq2seq framework heavily relies on the size and quality of the corpus on hand. We propose a method inspired by adversarial training to generate more meaningful and valuable training examples by continually identifying the weak spots of a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>, and to enhance the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> by gradually adding the generated adversarial examples to the training set. Extensive experimental results show that such adversarial training can improve both the generalization and robustness of GEC models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.231.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--231 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.231 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938791 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.231/>Multilingual AMR-to-Text Generation<span class=acl-fixed-case>AMR</span>-to-Text Generation</a></strong><br><a href=/people/a/angela-fan/>Angela Fan</a>
|
<a href=/people/c/claire-gardent/>Claire Gardent</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--231><div class="card-body p-3 small">Generating text from <a href=https://en.wikipedia.org/wiki/Structured_data>structured data</a> is challenging because it requires bridging the gap between (i) structure and natural language (NL) and (ii) semantically underspecified input and fully specified NL output. Multilingual generation brings in an additional challenge : that of generating into languages with varied word order and <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphological properties</a>. In this work, we focus on Abstract Meaning Representations (AMRs) as structured input, where previous research has overwhelmingly focused on generating only into <a href=https://en.wikipedia.org/wiki/English_language>English</a>. We leverage advances in cross-lingual embeddings, pretraining, and multilingual models to create multilingual AMR-to-text models that generate in twenty one different languages. Our multilingual models surpass <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> that generate into one language in eighteen languages, based on <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>automatic metrics</a>. We analyze the ability of our multilingual models to accurately capture <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphology</a> and word order using human evaluation, and find that <a href=https://en.wikipedia.org/wiki/First_language>native speakers</a> judge our generations to be fluent.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.232.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--232 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.232 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.232.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938828 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.232" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.232/>Exploring the Linear Subspace Hypothesis in Gender Bias Mitigation</a></strong><br><a href=/people/f/francisco-vargas/>Francisco Vargas</a>
|
<a href=/people/r/ryan-cotterell/>Ryan Cotterell</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--232><div class="card-body p-3 small">Bolukbasi et al. (2016) presents one of the first gender bias mitigation techniques for <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a>. Their method takes pre-trained <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> as input and attempts to isolate a <a href=https://en.wikipedia.org/wiki/Linear_subspace>linear subspace</a> that captures most of the <a href=https://en.wikipedia.org/wiki/Gender_bias>gender bias</a> in the embeddings. As judged by an analogical evaluation task, their method virtually eliminates <a href=https://en.wikipedia.org/wiki/Sexism>gender bias</a> in the <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a>. However, an implicit and untested assumption of their method is that the bias subspace is actually linear. In this work, we generalize their method to a kernelized, non-linear version. We take inspiration from kernel principal component analysis and derive a non-linear bias isolation technique. We discuss and overcome some of the practical drawbacks of our method for non-linear gender bias mitigation in <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> and analyze empirically whether the bias subspace is actually linear. Our analysis shows that <a href=https://en.wikipedia.org/wiki/Gender_bias>gender bias</a> is in fact well captured by a <a href=https://en.wikipedia.org/wiki/Linear_subspace>linear subspace</a>, justifying the assumption of Bolukbasi et al.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.234.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--234 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.234 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.234.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938922 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.234" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.234/>Sparse Parallel Training of Hierarchical Dirichlet Process Topic Models<span class=acl-fixed-case>D</span>irichlet Process Topic Models</a></strong><br><a href=/people/a/alexander-terenin/>Alexander Terenin</a>
|
<a href=/people/m/mans-magnusson/>Mns Magnusson</a>
|
<a href=/people/l/leif-jonsson/>Leif Jonsson</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--234><div class="card-body p-3 small">To scale non-parametric extensions of probabilistic topic models such as <a href=https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation>Latent Dirichlet allocation</a> to larger data sets, practitioners rely increasingly on parallel and distributed systems. In this work, we study <a href=https://en.wikipedia.org/wiki/Data_parallelism>data-parallel training</a> for the hierarchical Dirichlet process (HDP) topic model. Based upon a representation of certain conditional distributions within an HDP, we propose a doubly sparse data-parallel sampler for the HDP topic model. This <a href=https://en.wikipedia.org/wiki/Sampler_(musical_instrument)>sampler</a> utilizes all available sources of sparsity found in natural language-an important way to make computation efficient. We benchmark our method on a well-known corpus (PubMed) with 8 m documents and 768 m tokens, using a single multi-core machine in under four days.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.238.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--238 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.238 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.238.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939286 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.238" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.238/>Semi-Supervised Bilingual Lexicon Induction with Two-way Interaction</a></strong><br><a href=/people/x/xu-zhao/>Xu Zhao</a>
|
<a href=/people/z/zihao-wang/>Zihao Wang</a>
|
<a href=/people/h/hao-wu/>Hao Wu</a>
|
<a href=/people/y/yong-zhang/>Yong Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--238><div class="card-body p-3 small">Semi-supervision is a promising paradigm for Bilingual Lexicon Induction (BLI) with limited annotations. However, previous semisupervised methods do not fully utilize the knowledge hidden in annotated and nonannotated data, which hinders further improvement of their performance. In this paper, we propose a new semi-supervised BLI framework to encourage the interaction between the <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised signal</a> and <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised alignment</a>. We design two message-passing mechanisms to transfer knowledge between annotated and non-annotated data, named prior optimal transport and bi-directional lexicon update respectively. Then, we perform <a href=https://en.wikipedia.org/wiki/Semi-supervised_learning>semi-supervised learning</a> based on a cyclic or a parallel parameter feeding routine to update our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. Our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> is a general framework that can incorporate any supervised and unsupervised BLI methods based on <a href=https://en.wikipedia.org/wiki/Optimal_transport>optimal transport</a>. Experimental results on MUSE and VecMap datasets show significant improvement of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. Ablation study also proves that the two-way interaction between the supervised signal and unsupervised alignment accounts for the gain of the overall performance. Results on distant language pairs further illustrate the advantage and robustness of our proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.242.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--242 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.242 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938812 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.242" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.242/>BERT-EMD : Many-to-Many Layer Mapping for BERT Compression with Earth Movers Distance<span class=acl-fixed-case>BERT</span>-<span class=acl-fixed-case>EMD</span>: Many-to-Many Layer Mapping for <span class=acl-fixed-case>BERT</span> Compression with Earth Movers Distance</a></strong><br><a href=/people/j/jianquan-li/>Jianquan Li</a>
|
<a href=/people/x/xiaokang-liu/>Xiaokang Liu</a>
|
<a href=/people/h/honghong-zhao/>Honghong Zhao</a>
|
<a href=/people/r/ruifeng-xu/>Ruifeng Xu</a>
|
<a href=/people/m/min-yang/>Min Yang</a>
|
<a href=/people/y/yaohong-jin/>Yaohong Jin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--242><div class="card-body p-3 small">Pre-trained language models (e.g., BERT) have achieved significant success in various <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP) tasks</a>. However, high storage and computational costs obstruct pre-trained language models to be effectively deployed on resource-constrained devices. In this paper, we propose a novel BERT distillation method based on many-to-many layer mapping, which allows each intermediate student layer to learn from any intermediate teacher layers. In this way, our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> can learn from different teacher layers adaptively for different NLP tasks. In addition, we leverage Earth Mover&#8217;s Distance (EMD) to compute the minimum cumulative cost that must be paid to transform knowledge from teacher network to student network. EMD enables effective <a href=https://en.wikipedia.org/wiki/Matching_(graph_theory)>matching</a> for the many-to-many layer mapping. Furthermore, we propose a cost attention mechanism to learn the layer weights used in EMD automatically, which is supposed to further improve the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s performance and accelerate convergence time. Extensive experiments on GLUE benchmark demonstrate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves competitive performance compared to strong competitors in terms of both <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and <a href=https://en.wikipedia.org/wiki/Mathematical_model>model compression</a></div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.243.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--243 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.243 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938817 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.243/>Slot Attention with Value Normalization for Multi-Domain Dialogue State Tracking</a></strong><br><a href=/people/y/yexiang-wang/>Yexiang Wang</a>
|
<a href=/people/y/yi-guo/>Yi Guo</a>
|
<a href=/people/s/siqi-zhu/>Siqi Zhu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--243><div class="card-body p-3 small">Incompleteness of domain ontology and unavailability of some values are two inevitable problems of dialogue state tracking (DST). Existing approaches generally fall into two extremes : choosing <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> without <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontology</a> or embedding <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontology</a> in <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> leading to over-dependence. In this paper, we propose a new architecture to cleverly exploit <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontology</a>, which consists of Slot Attention (SA) and Value Normalization (VN), referred to as SAVN. Moreover, we supplement the annotation of supporting span for MultiWOZ 2.1, which is the shortest span in utterances to support the labeled value. SA shares knowledge between slots and utterances and only needs a simple structure to predict the supporting span. VN is designed specifically for the use of <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontology</a>, which can convert supporting spans to the values. Empirical results demonstrate that SAVN achieves the state-of-the-art <a href=https://en.wikipedia.org/wiki/Common_cause_and_special_cause_(statistics)>joint accuracy</a> of 54.52 % on MultiWOZ 2.0 and 54.86 % on MultiWOZ 2.1. Besides, we evaluate VN with incomplete ontology. The results show that even if only 30 % <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontology</a> is used, VN can also contribute to our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.246.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--246 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.246 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.246" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.246/>Learning a Cost-Effective Annotation Policy for Question Answering<span class=acl-fixed-case>C</span>ost-<span class=acl-fixed-case>E</span>ffective <span class=acl-fixed-case>A</span>nnotation <span class=acl-fixed-case>P</span>olicy for <span class=acl-fixed-case>Q</span>uestion <span class=acl-fixed-case>A</span>nswering</a></strong><br><a href=/people/b/bernhard-kratzwald/>Bernhard Kratzwald</a>
|
<a href=/people/s/stefan-feuerriegel/>Stefan Feuerriegel</a>
|
<a href=/people/h/huan-sun/>Huan Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--246><div class="card-body p-3 small">State-of-the-art question answering (QA) relies upon large amounts of training data for which labeling is time consuming and thus expensive. For this reason, customizing <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA systems</a> is challenging. As a remedy, we propose a novel framework for annotating QA datasets that entails learning a cost-effective annotation policy and a semi-supervised annotation scheme. The latter reduces the human effort : <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> leverages the underlying <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA system</a> to suggest potential candidate annotations. Human annotators then simply provide binary feedback on these candidates. Our <a href=https://en.wikipedia.org/wiki/System>system</a> is designed such that past annotations continuously improve the future performance and thus overall annotation cost. To the best of our knowledge, this is the first paper to address the problem of annotating questions with minimal annotation cost. We compare our <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> against traditional manual annotations in an extensive set of experiments. We find that our <a href=https://en.wikipedia.org/wiki/Software_development_process>approach</a> can reduce up to 21.1 % of the annotation cost.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.247.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--247 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.247 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.247/>Scene Restoring for Narrative Machine Reading Comprehension</a></strong><br><a href=/people/z/zhixing-tian/>Zhixing Tian</a>
|
<a href=/people/y/yuanzhe-zhang/>Yuanzhe Zhang</a>
|
<a href=/people/k/kang-liu/>Kang Liu</a>
|
<a href=/people/j/jun-zhao/>Jun Zhao</a>
|
<a href=/people/y/yantao-jia/>Yantao Jia</a>
|
<a href=/people/z/zhicheng-sheng/>Zhicheng Sheng</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--247><div class="card-body p-3 small">This paper focuses on machine reading comprehension for <a href=https://en.wikipedia.org/wiki/Narrative>narrative passages</a>. Narrative passages usually describe a <a href=https://en.wikipedia.org/wiki/Chain_of_events>chain of events</a>. When reading this kind of passage, humans tend to restore a scene according to the text with their prior knowledge, which helps them understand the passage comprehensively. Inspired by this behavior of humans, we propose a method to let the machine imagine a scene during reading narrative for better comprehension. Specifically, we build a scene graph by utilizing Atomic as the external knowledge and propose a novel Graph Dimensional-Iteration Network (GDIN) to encode the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a>. We conduct experiments on the ROCStories, a dataset of Story Cloze Test (SCT), and CosmosQA, a dataset of multiple choice. Our <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> achieves state-of-the-art.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.251.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--251 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.251 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939310 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.251/>Incorporating Behavioral Hypotheses for Query Generation</a></strong><br><a href=/people/r/ruey-cheng-chen/>Ruey-Cheng Chen</a>
|
<a href=/people/c/chia-jung-lee/>Chia-Jung Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--251><div class="card-body p-3 small">Generative neural networks have been shown effective on query suggestion. Commonly posed as a conditional generation problem, the task aims to leverage earlier inputs from users in a search session to predict queries that they will likely issue at a later time. User inputs come in various forms such as querying and clicking, each of which can imply different semantic signals channeled through the corresponding behavioral patterns. This paper induces these behavioral biases as hypotheses for query generation, where a generic encoder-decoder Transformer framework is presented to aggregate arbitrary hypotheses of choice. Our experimental results show that the proposed approach leads to significant improvements on top-k word error rate and Bert F1 Score compared to a recent BART model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.252.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--252 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.252 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.252.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938729 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.252/>Conditional Causal Relationships between Emotions and Causes in Texts</a></strong><br><a href=/people/x/xinhong-chen/>Xinhong Chen</a>
|
<a href=/people/q/qing-li/>Qing Li</a>
|
<a href=/people/j/jianping-wang/>Jianping Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--252><div class="card-body p-3 small">The <a href=https://en.wikipedia.org/wiki/Causality>causal relationships</a> between emotions and causes in text have recently received a lot of attention. Most of the existing works focus on the extraction of the causally related clauses from <a href=https://en.wikipedia.org/wiki/Document>documents</a>. However, none of these works has considered the possibility that the <a href=https://en.wikipedia.org/wiki/Causality>causal relationships</a> among the extracted emotion and cause clauses may only be valid under a specific context, without which the extracted clauses may not be causally related. To address such an issue, we propose a new task of determining whether or not an input pair of emotion and cause has a valid causal relationship under different contexts, and construct a corresponding <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> via manual annotation and negative sampling based on an existing benchmark dataset. Furthermore, we propose a prediction aggregation module with low <a href=https://en.wikipedia.org/wiki/Overhead_(computing)>computational overhead</a> to fine-tune the prediction results based on the characteristics of the input clauses. Experiments demonstrate the effectiveness and generality of our aggregation module.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.261.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--261 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.261 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939356 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.261" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.261/>Towards Interpreting BERT for Reading Comprehension Based QA<span class=acl-fixed-case>BERT</span> for Reading Comprehension Based <span class=acl-fixed-case>QA</span></a></strong><br><a href=/people/s/sahana-ramnath/>Sahana Ramnath</a>
|
<a href=/people/p/preksha-nema/>Preksha Nema</a>
|
<a href=/people/d/deep-sahni/>Deep Sahni</a>
|
<a href=/people/m/mitesh-m-khapra/>Mitesh M. Khapra</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--261><div class="card-body p-3 small">BERT and its variants have achieved state-of-the-art performance in various NLP tasks. Since then, various works have been proposed to analyze the <a href=https://en.wikipedia.org/wiki/Linguistic_description>linguistic information</a> being captured in BERT. However, the current works do not provide an insight into how BERT is able to achieve near human-level performance on the task of Reading Comprehension based Question Answering. In this work, we attempt to interpret BERT for RCQA. Since BERT layers do not have predefined roles, we define a layer&#8217;s role or functionality using Integrated Gradients. Based on the defined roles, we perform a preliminary analysis across all layers. We observed that the initial <a href=https://en.wikipedia.org/wiki/Abstraction_layer>layers</a> focus on query-passage interaction, whereas later layers focus more on contextual understanding and enhancing the answer prediction. Specifically for quantifier questions (how much / how many), we notice that BERT focuses on <a href=https://en.wikipedia.org/wiki/Word_sense>confusing words</a> (i.e., on other numerical quantities in the passage) in the later <a href=https://en.wikipedia.org/wiki/Complexity>layers</a>, but still manages to predict the answer correctly. The fine-tuning and analysis scripts will be publicly available at https://github.com/iitmnlp/BERT-Analysis-RCQA.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.262.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--262 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.262 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.262.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938648 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.262" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.262/>How do Decisions Emerge across Layers in Neural Models? Interpretation with Differentiable Masking</a></strong><br><a href=/people/n/nicola-de-cao/>Nicola De Cao</a>
|
<a href=/people/m/michael-sejr-schlichtkrull/>Michael Sejr Schlichtkrull</a>
|
<a href=/people/w/wilker-aziz/>Wilker Aziz</a>
|
<a href=/people/i/ivan-titov/>Ivan Titov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--262><div class="card-body p-3 small">Attribution methods assess the contribution of inputs to the <a href=https://en.wikipedia.org/wiki/Prediction>model prediction</a>. One way to do so is erasure : a subset of inputs is considered irrelevant if it can be removed without affecting the prediction. Though conceptually simple, erasure&#8217;s objective is intractable and approximate search remains expensive with modern deep NLP models. Erasure is also susceptible to the <a href=https://en.wikipedia.org/wiki/Hindsight_bias>hindsight bias</a> : the fact that an input can be dropped does not mean that the model &#8216;knows&#8217; it can be dropped. The resulting <a href=https://en.wikipedia.org/wiki/Pruning>pruning</a> is over-aggressive and does not reflect how the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> arrives at the prediction. To deal with these challenges, we introduce Differentiable Masking. DiffMask learns to mask-out subsets of the input while maintaining differentiability. The decision to include or disregard an input token is made with a simple <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> based on intermediate hidden layers of the analyzed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. First, this makes the approach efficient because we predict rather than <a href=https://en.wikipedia.org/wiki/Search_algorithm>search</a>. Second, as with probing classifiers, this reveals what the network &#8216;knows&#8217; at the corresponding layers. This lets us not only plot attribution heatmaps but also analyze how decisions are formed across <a href=https://en.wikipedia.org/wiki/Network_layer>network layers</a>. We use DiffMask to study BERT models on sentiment classification and <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.263.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--263 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.263 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938813 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.263" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.263/>A Diagnostic Study of Explainability Techniques for Text Classification</a></strong><br><a href=/people/p/pepa-atanasova/>Pepa Atanasova</a>
|
<a href=/people/j/jakob-grue-simonsen/>Jakob Grue Simonsen</a>
|
<a href=/people/c/christina-lioma/>Christina Lioma</a>
|
<a href=/people/i/isabelle-augenstein/>Isabelle Augenstein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--263><div class="card-body p-3 small">Recent developments in <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning</a> have introduced <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that approach human performance at the cost of increased architectural complexity. Efforts to make the rationales behind the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>&#8217; predictions transparent have inspired an abundance of new explainability techniques. Provided with an already trained <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>, they compute saliency scores for the words of an input instance. However, there exists no definitive guide on (i) how to choose such a <a href=https://en.wikipedia.org/wiki/Software_development_process>technique</a> given a particular application task and model architecture, and (ii) the benefits and drawbacks of using each such <a href=https://en.wikipedia.org/wiki/Software_development_process>technique</a>. In this paper, we develop a comprehensive list of diagnostic properties for evaluating existing explainability techniques. We then employ the proposed <a href=https://en.wikipedia.org/wiki/List_(abstract_data_type)>list</a> to compare a set of diverse explainability techniques on downstream text classification tasks and neural network architectures. We also compare the saliency scores assigned by the explainability techniques with human annotations of salient input regions to find relations between a model&#8217;s performance and the agreement of its rationales with human ones. Overall, we find that the gradient-based explanations perform best across tasks and model architectures, and we present further insights into the properties of the reviewed explainability techniques.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.265.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--265 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.265 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938860 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.265" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.265/>Learning to Contrast the Counterfactual Samples for Robust Visual Question Answering</a></strong><br><a href=/people/z/zujie-liang/>Zujie Liang</a>
|
<a href=/people/w/weitao-jiang/>Weitao Jiang</a>
|
<a href=/people/h/haifeng-hu/>Haifeng Hu</a>
|
<a href=/people/j/jiaying-zhu/>Jiaying Zhu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--265><div class="card-body p-3 small">In the task of Visual Question Answering (VQA), most state-of-the-art models tend to learn spurious correlations in the training set and achieve poor performance in out-of-distribution test data. Some methods of generating counterfactual samples have been proposed to alleviate this problem. However, the counterfactual samples generated by most previous methods are simply added to the training data for augmentation and are not fully utilized. Therefore, we introduce a novel self-supervised contrastive learning mechanism to learn the relationship between original samples, factual samples and counterfactual samples. With the better cross-modal joint embeddings learned from the auxiliary training objective, the reasoning capability and <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> of the VQA model are boosted significantly. We evaluate the effectiveness of our method by surpassing current state-of-the-art models on the VQA-CP dataset, a diagnostic benchmark for assessing the VQA model&#8217;s robustness.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.266.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--266 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.266 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938674 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.266/>Learning Physical Common Sense as Knowledge Graph Completion via BERT Data Augmentation and Constrained Tucker Factorization<span class=acl-fixed-case>P</span>hysical <span class=acl-fixed-case>C</span>ommon <span class=acl-fixed-case>S</span>ense as <span class=acl-fixed-case>K</span>nowledge <span class=acl-fixed-case>G</span>raph <span class=acl-fixed-case>C</span>ompletion via <span class=acl-fixed-case>BERT</span> <span class=acl-fixed-case>D</span>ata <span class=acl-fixed-case>A</span>ugmentation and <span class=acl-fixed-case>C</span>onstrained <span class=acl-fixed-case>T</span>ucker <span class=acl-fixed-case>F</span>actorization</a></strong><br><a href=/people/z/zhenjie-zhao/>Zhenjie Zhao</a>
|
<a href=/people/e/evangelos-papalexakis/>Evangelos Papalexakis</a>
|
<a href=/people/x/xiaojuan-ma/>Xiaojuan Ma</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--266><div class="card-body p-3 small">Physical common sense plays an essential role in the cognition abilities of robots for <a href=https://en.wikipedia.org/wiki/Human&#8211;robot_interaction>human-robot interaction</a>. Machine learning methods have shown promising results on physical commonsense learning in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> but still suffer from model generalization. In this paper, we formulate physical commonsense learning as a knowledge graph completion problem to better use the <a href=https://en.wikipedia.org/wiki/Latent_variable>latent relationships</a> among training samples. Compared with completing general knowledge graphs, completing a physical commonsense knowledge graph has three unique characteristics : training data are scarce, not all facts can be mined from existing texts, and the number of relationships is small. To deal with these problems, we first use a pre-training language model BERT to augment training data, and then employ constrained tucker factorization to model complex relationships by constraining types and adding negative relationships. We compare our <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> with existing state-of-the-art knowledge graph embedding methods and show its superior performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.267.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--267 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.267 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939228 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.267/>A Visually-grounded First-person Dialogue Dataset with Verbal and Non-verbal Responses</a></strong><br><a href=/people/h/hisashi-kamezawa/>Hisashi Kamezawa</a>
|
<a href=/people/n/noriki-nishida/>Noriki Nishida</a>
|
<a href=/people/n/nobuyuki-shimizu/>Nobuyuki Shimizu</a>
|
<a href=/people/t/takashi-miyazaki/>Takashi Miyazaki</a>
|
<a href=/people/h/hideki-nakayama/>Hideki Nakayama</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--267><div class="card-body p-3 small">In real-world dialogue, first-person visual information about where the other speakers are and what they are paying attention to is crucial to understand their intentions. Non-verbal responses also play an important role in <a href=https://en.wikipedia.org/wiki/Social_relation>social interactions</a>. In this paper, we propose a visually-grounded first-person dialogue (VFD) dataset with verbal and non-verbal responses. The VFD dataset provides manually annotated (1) first-person images of agents, (2) utterances of human speakers, (3) eye-gaze locations of the speakers, and (4) the agents&#8217; verbal and non-verbal responses. We present experimental results obtained using the proposed VFD dataset and recent <a href=https://en.wikipedia.org/wiki/Neural_network>neural network models</a> (e.g., BERT, ResNet). The results demonstrate that first-person vision helps <a href=https://en.wikipedia.org/wiki/Neural_circuit>neural network models</a> correctly understand human intentions, and the production of non-verbal responses is a challenging task like that of verbal responses. Our dataset is publicly available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.271.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--271 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.271 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938820 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.271" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.271/>Sub-Instruction Aware Vision-and-Language Navigation</a></strong><br><a href=/people/y/yicong-hong/>Yicong Hong</a>
|
<a href=/people/c/cristian-rodriguez/>Cristian Rodriguez</a>
|
<a href=/people/q/qi-wu/>Qi Wu</a>
|
<a href=/people/s/stephen-gould/>Stephen Gould</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--271><div class="card-body p-3 small">Vision-and-language navigation requires an agent to navigate through a real 3D environment following <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language instructions</a>. Despite significant advances, few previous works are able to fully utilize the strong correspondence between the visual and textual sequences. Meanwhile, due to the lack of intermediate supervision, the <a href=https://en.wikipedia.org/wiki/Intelligent_agent>agent</a>&#8217;s performance at following each part of the instruction can not be assessed during <a href=https://en.wikipedia.org/wiki/Navigation>navigation</a>. In this work, we focus on the granularity of the visual and language sequences as well as the traceability of agents through the completion of an instruction. We provide <a href=https://en.wikipedia.org/wiki/Intelligent_agent>agents</a> with fine-grained annotations during training and find that they are able to follow the instruction better and have a higher chance of reaching the target at test time. We enrich the benchmark dataset Room-to-Room (R2R) with sub-instructions and their corresponding paths. To make use of this data, we propose effective <a href=https://en.wikipedia.org/wiki/Instruction_set_architecture>sub-instruction attention and shifting modules</a> that select and attend to a single <a href=https://en.wikipedia.org/wiki/Instruction_set_architecture>sub-instruction</a> at each time-step. We implement our sub-instruction modules in four state-of-the-art agents, compare with their baseline models, and show that our proposed method improves the performance of all four agents. We release the Fine-Grained R2R dataset (FGR2R) and the code at https://github.com/YicongHong/Fine-Grained-R2R.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.278.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--278 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.278 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938752 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.278/>Task-Completion Dialogue Policy Learning via <a href=https://en.wikipedia.org/wiki/Monte_Carlo_tree_search>Monte Carlo Tree Search</a> with Dueling Network<span class=acl-fixed-case>M</span>onte <span class=acl-fixed-case>C</span>arlo Tree Search with Dueling Network</a></strong><br><a href=/people/s/sihan-wang/>Sihan Wang</a>
|
<a href=/people/k/kaijie-zhou/>Kaijie Zhou</a>
|
<a href=/people/k/kunfeng-lai/>Kunfeng Lai</a>
|
<a href=/people/j/jianping-shen/>Jianping Shen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--278><div class="card-body p-3 small">We introduce a framework of <a href=https://en.wikipedia.org/wiki/Monte_Carlo_tree_search>Monte Carlo Tree Search</a> with Double-q Dueling network (MCTS-DDU) for task-completion dialogue policy learning. Different from the previous deep model-based reinforcement learning methods, which uses background planning and may suffer from low-quality simulated experiences, MCTS-DDU performs decision-time planning based on dialogue state search trees built by <a href=https://en.wikipedia.org/wiki/Monte_Carlo_method>Monte Carlo simulations</a> and is robust to the simulation errors. Such idea arises naturally in <a href=https://en.wikipedia.org/wiki/Human_behavior>human behaviors</a>, e.g. predicting others&#8217; responses and then deciding our own actions. In the simulated movie-ticket booking task, our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> outperforms the background planning approaches significantly. We demonstrate the effectiveness of MCTS and the dueling network in detailed ablation studies, and also compare the performance upper bounds of these two planning methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.289.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--289 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.289 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939311 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.289/>Emotion-Cause Pair Extraction as Sequence Labeling Based on A Novel Tagging Scheme</a></strong><br><a href=/people/c/chaofa-yuan/>Chaofa Yuan</a>
|
<a href=/people/c/chuang-fan/>Chuang Fan</a>
|
<a href=/people/j/jianzhu-bao/>Jianzhu Bao</a>
|
<a href=/people/r/ruifeng-xu/>Ruifeng Xu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--289><div class="card-body p-3 small">The task of emotion-cause pair extraction deals with finding all <a href=https://en.wikipedia.org/wiki/Emotion>emotions</a> and the corresponding causes in unannotated emotion texts. Most recent studies are based on the likelihood of Cartesian product among all clause candidates, resulting in a high computational cost. Targeting this issue, we regard the task as a sequence labeling problem and propose a novel tagging scheme with coding the distance between linked components into the tags, so that <a href=https://en.wikipedia.org/wiki/Emotion>emotions</a> and the corresponding causes can be extracted simultaneously. Accordingly, an end-to-end model is presented to process the input texts from left to right, always with <a href=https://en.wikipedia.org/wiki/Time_complexity>linear time complexity</a>, leading to a speed up. Experimental results show that our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves the best performance, outperforming the state-of-the-art <a href=https://en.wikipedia.org/wiki/Scientific_method>method</a> by 2.26 % (p0.001) in <a href=https://en.wikipedia.org/wiki/F-number>F1 measure</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.291.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--291 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.291 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938701 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.291/>Multi-modal Multi-label Emotion Detection with Modality and Label Dependence</a></strong><br><a href=/people/d/dong-zhang/>Dong Zhang</a>
|
<a href=/people/x/xincheng-ju/>Xincheng Ju</a>
|
<a href=/people/j/junhui-li/>Junhui Li</a>
|
<a href=/people/s/shoushan-li/>Shoushan Li</a>
|
<a href=/people/q/qiaoming-zhu/>Qiaoming Zhu</a>
|
<a href=/people/g/guodong-zhou/>Guodong Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--291><div class="card-body p-3 small">As an important research issue in the natural language processing community, multi-label emotion detection has been drawing more and more attention in the last few years. However, almost all existing studies focus on one modality (e.g., textual modality). In this paper, we focus on multi-label emotion detection in a <a href=https://en.wikipedia.org/wiki/Multimodal_interaction>multi-modal scenario</a>. In this scenario, we need to consider both the dependence among different labels (label dependence) and the dependence between each predicting label and different modalities (modality dependence). Particularly, we propose a multi-modal sequence-to-set approach to effectively model both kinds of dependence in multi-modal multi-label emotion detection. The detailed evaluation demonstrates the effectiveness of our <a href=https://en.wikipedia.org/wiki/Software_development_process>approach</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.303.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--303 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.303 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.303.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938684 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.303" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.303/>Global-to-Local Neural Networks for Document-Level Relation Extraction</a></strong><br><a href=/people/d/difeng-wang/>Difeng Wang</a>
|
<a href=/people/w/wei-hu/>Wei Hu</a>
|
<a href=/people/e/ermei-cao/>Ermei Cao</a>
|
<a href=/people/w/weijian-sun/>Weijian Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--303><div class="card-body p-3 small">Relation extraction (RE) aims to identify the semantic relations between named entities in text. Recent years have witnessed it raised to the document level, which requires complex reasoning with entities and mentions throughout an entire document. In this paper, we propose a novel model to document-level RE, by encoding the document information in terms of entity global and local representations as well as context relation representations. Entity global representations model the semantic information of all entities in the document, entity local representations aggregate the contextual information of multiple mentions of specific entities, and context relation representations encode the topic information of other relations. Experimental results demonstrate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves superior performance on two public datasets for document-level RE. It is particularly effective in extracting relations between entities of long distance and having multiple mentions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.304.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--304 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.304 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939355 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.304/>Recurrent Interaction Network for Jointly Extracting Entities and Classifying Relations</a></strong><br><a href=/people/k/kai-sun/>Kai Sun</a>
|
<a href=/people/r/richong-zhang/>Richong Zhang</a>
|
<a href=/people/s/samuel-mensah/>Samuel Mensah</a>
|
<a href=/people/y/yongyi-mao/>Yongyi Mao</a>
|
<a href=/people/x/xudong-liu/>Xudong Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--304><div class="card-body p-3 small">The idea of using multi-task learning approaches to address the joint extraction of entity and relation is motivated by the relatedness between the entity recognition task and the relation classification task. Existing methods using multi-task learning techniques to address the problem learn interactions among the two tasks through a shared network, where the shared information is passed into the task-specific networks for prediction. However, such an approach hinders the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> from learning explicit interactions between the two tasks to improve the performance on the individual <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. As a solution, we design a multi-task learning model which we refer to as recurrent interaction network which allows the learning of interactions dynamically, to effectively model task-specific features for <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a>. Empirical studies on two real-world datasets confirm the superiority of the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.308.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--308 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.308 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.308.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938978 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.308/>Point to the Expression : Solving Algebraic Word Problems using the Expression-Pointer Transformer Model<span class=acl-fixed-case>P</span>oint to the <span class=acl-fixed-case>E</span>xpression: <span class=acl-fixed-case>S</span>olving <span class=acl-fixed-case>A</span>lgebraic <span class=acl-fixed-case>W</span>ord <span class=acl-fixed-case>P</span>roblems using the <span class=acl-fixed-case>E</span>xpression-<span class=acl-fixed-case>P</span>ointer <span class=acl-fixed-case>T</span>ransformer <span class=acl-fixed-case>M</span>odel</a></strong><br><a href=/people/b/bugeun-kim/>Bugeun Kim</a>
|
<a href=/people/k/kyung-seo-ki/>Kyung Seo Ki</a>
|
<a href=/people/d/donggeon-lee/>Donggeon Lee</a>
|
<a href=/people/g/gahgene-gweon/>Gahgene Gweon</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--308><div class="card-body p-3 small">Solving algebraic word problems has recently emerged as an important natural language processing task. To solve algebraic word problems, recent studies suggested neural models that generate solution equations by using &#8216;Op (operator / operand)&#8217; tokens as a unit of input / output. However, such a neural model suffered two issues : expression fragmentation and operand-context separation. To address each of these two issues, we propose a pure neural model, Expression-Pointer Transformer (EPT), which uses (1) &#8216;Expression&#8217; token and (2) operand-context pointers when generating solution equations. The performance of the EPT model is tested on three datasets : ALG514, DRAW-1 K, and MAWPS. Compared to the state-of-the-art (SoTA) models, the EPT model achieved a comparable performance accuracy in each of the three <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> ; 81.3 % on ALG514, 59.5 % on DRAW-1 K, and 84.5 % on MAWPS. The contribution of this paper is two-fold ; (1) We propose a pure neural model, EPT, which can address the expression fragmentation and the operand-context separation. (2) The fully automatic EPT model, which does not use hand-crafted features, yields comparable performance to existing models using hand-crafted features, and achieves better performance than existing pure neural models by at most 40 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.311.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--311 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.311 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939193 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.311/>Routing Enforced <a href=https://en.wikipedia.org/wiki/Generative_model>Generative Model</a> for Recipe Generation</a></strong><br><a href=/people/z/zhiwei-yu/>Zhiwei Yu</a>
|
<a href=/people/h/hongyu-zang/>Hongyu Zang</a>
|
<a href=/people/x/xiaojun-wan/>Xiaojun Wan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--311><div class="card-body p-3 small">One of the most challenging part of recipe generation is to deal with the complex restrictions among the input ingredients. Previous researches simplify the problem by treating the inputs independently and generating recipes containing as much information as possible. In this work, we propose a routing method to dive into the content selection under the internal restrictions. The routing enforced generative model (RGM) can generate appropriate <a href=https://en.wikipedia.org/wiki/Recipe>recipes</a> according to the given ingredients and user preferences. Our model yields new state-of-the-art results on the recipe generation task with significant improvements on BLEU, <a href=https://en.wikipedia.org/wiki/F-number>F1</a> and human evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.316.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--316 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.316 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939116 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.316" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.316/>DagoBERT : Generating Derivational Morphology with a Pretrained Language Model<span class=acl-fixed-case>D</span>ago<span class=acl-fixed-case>BERT</span>: <span class=acl-fixed-case>G</span>enerating Derivational Morphology with a Pretrained Language Model</a></strong><br><a href=/people/v/valentin-hofmann/>Valentin Hofmann</a>
|
<a href=/people/j/janet-pierrehumbert/>Janet Pierrehumbert</a>
|
<a href=/people/h/hinrich-schutze/>Hinrich Schtze</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--316><div class="card-body p-3 small">Can pretrained language models (PLMs) generate derivationally complex words? We present the first study investigating this question, taking BERT as the example PLM. We examine BERT&#8217;s derivational capabilities in different settings, ranging from using the unmodified pretrained model to full finetuning. Our best model, DagoBERT (Derivationally and generatively optimized BERT), clearly outperforms the previous state of the art in derivation generation (DG). Furthermore, our experiments show that the input segmentation crucially impacts BERT&#8217;s derivational knowledge, suggesting that the performance of PLMs could be further improved if a morphologically informed vocabulary of units were used.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.318.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--318 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.318 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938808 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.318/>A Joint Multiple Criteria Model in <a href=https://en.wikipedia.org/wiki/Transfer_learning>Transfer Learning</a> for Cross-domain Chinese Word Segmentation<span class=acl-fixed-case>C</span>hinese Word Segmentation</a></strong><br><a href=/people/k/kaiyu-huang/>Kaiyu Huang</a>
|
<a href=/people/d/degen-huang/>Degen Huang</a>
|
<a href=/people/z/zhuang-liu/>Zhuang Liu</a>
|
<a href=/people/f/fengran-mo/>Fengran Mo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--318><div class="card-body p-3 small">Word-level information is important in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP)</a>, especially for the <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese language</a> due to its high linguistic complexity. Chinese word segmentation (CWS) is an essential task for Chinese downstream NLP tasks. Existing methods have already achieved a competitive performance for CWS on large-scale annotated corpora. However, the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of the method will drop dramatically when it handles an unsegmented text with lots of out-of-vocabulary (OOV) words. In addition, there are many different segmentation criteria for addressing different requirements of downstream NLP tasks. Excessive amounts of <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> with saving different criteria will generate the explosive growth of the total parameters. To this end, we propose a joint multiple criteria model that shares all parameters to integrate different segmentation criteria into one <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. Besides, we utilize a transfer learning method to improve the performance of <a href=https://en.wikipedia.org/wiki/Object-oriented_programming>OOV words</a>. Our proposed method is evaluated by designing comprehensive experiments on multiple benchmark datasets (e.g., Bakeoff 2005, Bakeoff 2008 and SIGHAN 2010). Our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> achieves the state-of-the-art performances on all datasets. Importantly, our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> also shows a competitive practicability and generalization ability for the CWS task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.322.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--322 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.322 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.322" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.322/>Graph Convolutions over Constituent Trees for Syntax-Aware Semantic Role Labeling</a></strong><br><a href=/people/d/diego-marcheggiani/>Diego Marcheggiani</a>
|
<a href=/people/i/ivan-titov/>Ivan Titov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--322><div class="card-body p-3 small">Semantic role labeling (SRL) is the task of identifying predicates and labeling argument spans with <a href=https://en.wikipedia.org/wiki/Semantic_role>semantic roles</a>. Even though most semantic-role formalisms are built upon <a href=https://en.wikipedia.org/wiki/Constituent_(linguistics)>constituent syntax</a>, and only <a href=https://en.wikipedia.org/wiki/Constituent_(linguistics)>syntactic constituents</a> can be labeled as arguments (e.g., <a href=https://en.wikipedia.org/wiki/FrameNet>FrameNet</a> and PropBank), all the recent work on syntax-aware SRL relies on dependency representations of syntax. In contrast, we show how graph convolutional networks (GCNs) can be used to encode constituent structures and inform an SRL system. Nodes in our SpanGCN correspond to <a href=https://en.wikipedia.org/wiki/Constituent_(linguistics)>constituents</a>. The computation is done in 3 stages. First, initial node representations are produced by &#8216;composing&#8217; word representations of the first and last words in the <a href=https://en.wikipedia.org/wiki/Constituent_(linguistics)>constituent</a>. Second, graph convolutions relying on the constituent tree are performed, yielding syntactically-informed constituent representations. Finally, the constituent representations are &#8216;decomposed&#8217; back into word representations, which are used as input to the SRL classifier. We evaluate SpanGCN against alternatives, including a model using GCNs over dependency trees, and show its effectiveness on standard English SRL benchmarks CoNLL-2005, CoNLL-2012, and FrameNet.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.325.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--325 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.325 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939148 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.325/>Supervised Seeded Iterated Learning for Interactive Language Learning</a></strong><br><a href=/people/y/yuchen-lu/>Yuchen Lu</a>
|
<a href=/people/s/soumye-singhal/>Soumye Singhal</a>
|
<a href=/people/f/florian-strub/>Florian Strub</a>
|
<a href=/people/o/olivier-pietquin/>Olivier Pietquin</a>
|
<a href=/people/a/aaron-courville/>Aaron Courville</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--325><div class="card-body p-3 small">Language drift has been one of the major obstacles to train <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> through <a href=https://en.wikipedia.org/wiki/Interaction>interaction</a>. When word-based conversational agents are trained towards completing a task, they tend to invent their language rather than leveraging <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>. In recent literature, two general methods partially counter this phenomenon : Supervised Selfplay (S2P) and Seeded Iterated Learning (SIL). While S2P jointly trains interactive and supervised losses to counter the drift, <a href=https://en.wikipedia.org/wiki/SIL_International>SIL</a> changes the training dynamics to prevent <a href=https://en.wikipedia.org/wiki/Language_drift>language drift</a> from occurring. In this paper, we first highlight their respective weaknesses, i.e., late-stage training collapses and higher negative likelihood when evaluated on <a href=https://en.wikipedia.org/wiki/Text_corpus>human corpus</a>. Given these observations, we introduce Supervised Seeded Iterated Learning (SSIL) to combine both methods to minimize their respective weaknesses. We then show the effectiveness of in the language-drift translation game.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.334.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--334 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.334 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939153 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.334" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.334/>Compositional Demographic Word Embeddings</a></strong><br><a href=/people/c/charles-welch/>Charles Welch</a>
|
<a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a>
|
<a href=/people/v/veronica-perez-rosas/>Vernica Prez-Rosas</a>
|
<a href=/people/r/rada-mihalcea/>Rada Mihalcea</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--334><div class="card-body p-3 small">Word embeddings are usually derived from corpora containing text from many individuals, thus leading to general purpose representations rather than individually personalized representations. While personalized embeddings can be useful to improve <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> performance and other language processing tasks, they can only be computed for people with a large amount of <a href=https://en.wikipedia.org/wiki/Panel_data>longitudinal data</a>, which is not the case for new users. We propose a new form of personalized word embeddings that use demographic-specific word representations derived compositionally from full or partial demographic information for a user (i.e., gender, age, location, religion). We show that the resulting demographic-aware word representations outperform generic word representations on two tasks for <a href=https://en.wikipedia.org/wiki/English_language>English</a> : <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a> and word associations. We further explore the trade-off between the number of available attributes and their relative effectiveness and discuss the ethical implications of using them.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.335.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--335 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.335 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939226 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.335/>Are Undocumented Workers the Same as Illegal Aliens? Disentangling Denotation and Connotation in Vector Spaces<span class=acl-fixed-case>D</span>isentangling Denotation and Connotation in Vector Spaces</a></strong><br><a href=/people/a/albert-webson/>Albert Webson</a>
|
<a href=/people/z/zhizhong-chen/>Zhizhong Chen</a>
|
<a href=/people/c/carsten-eickhoff/>Carsten Eickhoff</a>
|
<a href=/people/e/ellie-pavlick/>Ellie Pavlick</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--335><div class="card-body p-3 small">In <a href=https://en.wikipedia.org/wiki/Politics>politics</a>, <a href=https://en.wikipedia.org/wiki/Neologism>neologisms</a> are frequently invented for partisan objectives. For example, <a href=https://en.wikipedia.org/wiki/Illegal_immigration_to_the_United_States>undocumented workers</a> and illegal aliens refer to the same group of people (i.e., they have the same denotation), but they carry clearly different <a href=https://en.wikipedia.org/wiki/Connotation>connotations</a>. Examples like these have traditionally posed a challenge to reference-based semantic theories and led to increasing acceptance of alternative theories (e.g., Two-Factor Semantics) among philosophers and cognitive scientists. In <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, however, popular pretrained models encode both <a href=https://en.wikipedia.org/wiki/Denotation>denotation</a> and <a href=https://en.wikipedia.org/wiki/Connotation>connotation</a> as one entangled representation. In this study, we propose an adversarial nerual netowrk that decomposes a pretrained representation as independent denotation and connotation representations. For intrinsic interpretability, we show that words with the same denotation but different connotations (e.g., immigrants vs. aliens, estate tax vs. death tax) move closer to each other in denotation space while moving further apart in connotation space. For extrinsic application, we train an <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval system</a> with our disentangled representations and show that the denotation vectors improve the viewpoint diversity of document rankings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.341.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--341 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.341 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939204 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.341/>SLEDGE-Z : A Zero-Shot Baseline for COVID-19 Literature Search<span class=acl-fixed-case>SLEDGE-Z</span>: A Zero-Shot Baseline for <span class=acl-fixed-case>COVID</span>-19 Literature Search</a></strong><br><a href=/people/s/sean-macavaney/>Sean MacAvaney</a>
|
<a href=/people/a/arman-cohan/>Arman Cohan</a>
|
<a href=/people/n/nazli-goharian/>Nazli Goharian</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--341><div class="card-body p-3 small">With worldwide concerns surrounding the Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2), there is a rapidly growing body of scientific literature on the virus. Clinicians, researchers, and policy-makers need to be able to search these articles effectively. In this work, we present a zero-shot ranking algorithm that adapts to COVID-related scientific literature. Our approach filters training data from another <a href=https://en.wikipedia.org/wiki/Collection_(abstract_data_type)>collection</a> down to medical-related queries, uses a neural re-ranking model pre-trained on scientific text (SciBERT), and filters the target document collection. This approach ranks top among zero-shot methods on the TREC COVID Round 1 leaderboard, and exhibits a P@5 of 0.80 and an nDCG@10 of 0.68 when evaluated on both Round 1 and 2 judgments. Despite not relying on TREC-COVID data, our method outperforms models that do. As one of the first search methods to thoroughly evaluate COVID-19 search, we hope that this serves as a strong baseline and helps in the global crisis.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.344.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--344 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.344 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939027 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.344" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.344/>Adversarial Semantic Collisions</a></strong><br><a href=/people/c/congzheng-song/>Congzheng Song</a>
|
<a href=/people/a/alexander-m-rush/>Alexander Rush</a>
|
<a href=/people/v/vitaly-shmatikov/>Vitaly Shmatikov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--344><div class="card-body p-3 small">We study semantic collisions : texts that are semantically unrelated but judged as similar by <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP models</a>. We develop gradient-based approaches for generating semantic collisions and demonstrate that state-of-the-art models for many tasks which rely on analyzing the meaning and similarity of textsincluding paraphrase identification, <a href=https://en.wikipedia.org/wiki/Document_retrieval>document retrieval</a>, response suggestion, and extractive summarizationare vulnerable to semantic collisions. For example, given a target query, inserting a crafted collision into an irrelevant document can shift its retrieval rank from 1000 to top 3. We show how to generate semantic collisions that evade perplexity-based filtering and discuss other potential mitigations. Our code is available at.<i>semantic collisions</i>: texts that are semantically unrelated but judged as similar by NLP models. We develop gradient-based approaches for generating semantic collisions and demonstrate that state-of-the-art models for many tasks which rely on analyzing the meaning and similarity of texts&#8212;including paraphrase identification, document retrieval, response suggestion, and extractive summarization&#8212;are vulnerable to semantic collisions. For example, given a target query, inserting a crafted collision into an irrelevant document can shift its retrieval rank from 1000 to top 3. We show how to generate semantic collisions that evade perplexity-based filtering and discuss other potential mitigations. Our code is available at <url>https://github.com/csong27/collision-bert</url>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.345.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--345 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.345 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.345/>Learning Explainable Linguistic Expressions with Neural Inductive Logic Programming for Sentence Classification</a></strong><br><a href=/people/p/prithviraj-sen/>Prithviraj Sen</a>
|
<a href=/people/m/marina-danilevsky/>Marina Danilevsky</a>
|
<a href=/people/y/yunyao-li/>Yunyao Li</a>
|
<a href=/people/s/siddhartha-brahma/>Siddhartha Brahma</a>
|
<a href=/people/m/matthias-boehm/>Matthias Boehm</a>
|
<a href=/people/l/laura-chiticariu/>Laura Chiticariu</a>
|
<a href=/people/r/rajasekar-krishnamurthy/>Rajasekar Krishnamurthy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--345><div class="card-body p-3 small">Interpretability of <a href=https://en.wikipedia.org/wiki/Predictive_modelling>predictive models</a> is becoming increasingly important with growing adoption in the real-world. We present RuleNN, a neural network architecture for learning transparent models for sentence classification. The models are in the form of rules expressed in <a href=https://en.wikipedia.org/wiki/First-order_logic>first-order logic</a>, a <a href=https://en.wikipedia.org/wiki/Dialect>dialect</a> with well-defined, human-understandable semantics. More precisely, RuleNN learns linguistic expressions (LE) built on top of <a href=https://en.wikipedia.org/wiki/Predicate_(grammar)>predicates</a> extracted using shallow natural language understanding. Our experimental results show that RuleNN outperforms statistical relational learning and other neuro-symbolic methods, and performs comparably with black-box recurrent neural networks. Our user studies confirm that the learned LEs are explainable and capture domain semantics. Moreover, allowing domain experts to modify LEs and instill more <a href=https://en.wikipedia.org/wiki/Domain_knowledge>domain knowledge</a> leads to human-machine co-creation of models with better performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.346.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--346 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.346 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939188 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.346" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.346/>AutoPrompt : Eliciting Knowledge from Language Models with Automatically Generated Prompts<span class=acl-fixed-case>A</span>uto<span class=acl-fixed-case>P</span>rompt: <span class=acl-fixed-case>E</span>liciting <span class=acl-fixed-case>K</span>nowledge from <span class=acl-fixed-case>L</span>anguage <span class=acl-fixed-case>M</span>odels with <span class=acl-fixed-case>A</span>utomatically <span class=acl-fixed-case>G</span>enerated <span class=acl-fixed-case>P</span>rompts</a></strong><br><a href=/people/t/taylor-shin/>Taylor Shin</a>
|
<a href=/people/y/yasaman-razeghi/>Yasaman Razeghi</a>
|
<a href=/people/r/robert-l-logan-iv/>Robert L. Logan IV</a>
|
<a href=/people/e/eric-wallace/>Eric Wallace</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--346><div class="card-body p-3 small">The remarkable success of pretrained language models has motivated the study of what kinds of knowledge these <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> learn during pretraining. Reformulating tasks as fill-in-the-blanks problems (e.g., cloze tests) is a natural approach for gauging such <a href=https://en.wikipedia.org/wiki/Knowledge>knowledge</a>, however, its usage is limited by the manual effort and guesswork required to write suitable prompts. To address this, we develop AutoPrompt, an automated method to create prompts for a diverse set of tasks, based on a gradient-guided search. Using AutoPrompt, we show that masked language models (MLMs) have an inherent capability to perform <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> and natural language inference without additional parameters or <a href=https://en.wikipedia.org/wiki/Finetuning>finetuning</a>, sometimes achieving performance on par with recent state-of-the-art supervised models. We also show that our prompts elicit more accurate factual knowledge from MLMs than the manually created prompts on the LAMA benchmark, and that MLMs can be used as relation extractors more effectively than supervised relation extraction models. These results demonstrate that automatically generated prompts are a viable parameter-free alternative to existing probing methods, and as pretrained LMs become more sophisticated and capable, potentially a replacement for <a href=https://en.wikipedia.org/wiki/Finetuning>finetuning</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.352.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--352 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.352 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939280 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.352/>Generating Dialogue Responses from a Semantic Latent Space</a></strong><br><a href=/people/w/wei-jen-ko/>Wei-Jen Ko</a>
|
<a href=/people/a/avik-ray/>Avik Ray</a>
|
<a href=/people/y/yilin-shen/>Yilin Shen</a>
|
<a href=/people/h/hongxia-jin/>Hongxia Jin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--352><div class="card-body p-3 small">Existing open-domain dialogue generation models are usually trained to mimic the gold response in the training set using cross-entropy loss on the vocabulary. However, a good response does not need to resemble the gold response, since there are multiple possible responses to a given prompt. In this work, we hypothesize that the current models are unable to integrate information from multiple semantically similar valid responses of a prompt, resulting in the generation of generic and uninformative responses. To address this issue, we propose an alternative to the end-to-end classification on <a href=https://en.wikipedia.org/wiki/Vocabulary>vocabulary</a>. We learn the pair relationship between the prompts and responses as a <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression task</a> on a latent space instead. In our novel dialog generation model, the representations of semantically related sentences are close to each other on the latent space. Human evaluation showed that learning the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> on a <a href=https://en.wikipedia.org/wiki/Continuous_or_discrete_variable>continuous space</a> can generate responses that are both relevant and informative.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.355.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--355 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.355 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938646 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.355/>ALICE : <a href=https://en.wikipedia.org/wiki/Active_learning>Active Learning</a> with Contrastive Natural Language Explanations<span class=acl-fixed-case>ALICE</span>: Active Learning with Contrastive Natural Language Explanations</a></strong><br><a href=/people/w/weixin-liang/>Weixin Liang</a>
|
<a href=/people/j/james-zou/>James Zou</a>
|
<a href=/people/z/zhou-yu/>Zhou Yu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--355><div class="card-body p-3 small">Training a supervised neural network classifier typically requires many annotated training samples. Collecting and annotating a large number of data points are costly and sometimes even infeasible. Traditional annotation process uses a low-bandwidth human-machine communication interface : classification labels, each of which only provides a few bits of information. We propose Active Learning with Contrastive Explanations (ALICE), an expert-in-the-loop training framework that utilizes contrastive natural language explanations to improve data efficiency in learning. AL-ICE learns to first use active learning to select the most informative pairs of label classes to elicit contrastive natural language explanations from experts. Then <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> extracts knowledge from these <a href=https://en.wikipedia.org/wiki/Explanation>explanations</a> using a <a href=https://en.wikipedia.org/wiki/Semantic_parser>semantic parser</a>. Finally, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> incorporates the extracted knowledge through dynamically changing the <a href=https://en.wikipedia.org/wiki/Machine_learning>learning model</a>&#8217;s structure. We applied ALICEin two visual recognition tasks, bird species classification and <a href=https://en.wikipedia.org/wiki/Social_relation>social relationship classification</a>. We found by incorporating contrastive explanations, our <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> outperform baseline models that are trained with 40-100 % more training data. We found that adding1expla-nation leads to similar performance gain as adding 13-30 labeled training data points.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.366.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--366 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.366 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939191 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.366" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.366/>A Streaming Approach For Efficient Batched Beam Search</a></strong><br><a href=/people/k/kevin-yang/>Kevin Yang</a>
|
<a href=/people/v/violet-yao/>Violet Yao</a>
|
<a href=/people/j/john-denero/>John DeNero</a>
|
<a href=/people/d/dan-klein/>Dan Klein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--366><div class="card-body p-3 small">We propose an efficient <a href=https://en.wikipedia.org/wiki/Batch_processing>batching strategy</a> for variable-length decoding on <a href=https://en.wikipedia.org/wiki/Graphics_processing_unit>GPU architectures</a>. During decoding, when candidates terminate or are pruned according to <a href=https://en.wikipedia.org/wiki/Heuristic>heuristics</a>, our streaming approach periodically refills the batch before proceeding with a selected subset of candidates. We apply our method to variable-width beam search on a state-of-the-art machine translation model. Our method decreases <a href=https://en.wikipedia.org/wiki/Run_time_(program_lifecycle_phase)>runtime</a> by up to 71 % compared to a fixed-width beam search baseline and 17 % compared to a variable-width baseline, while matching baselines&#8217; BLEU. Finally, experiments show that our <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> can speed up decoding in other domains, such as <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic and syntactic parsing</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.375.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--375 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.375 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939210 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.375/>Structural Supervision Improves Few-Shot Learning and Syntactic Generalization in Neural Language Models</a></strong><br><a href=/people/e/ethan-wilcox/>Ethan Wilcox</a>
|
<a href=/people/p/peng-qian/>Peng Qian</a>
|
<a href=/people/r/richard-futrell/>Richard Futrell</a>
|
<a href=/people/r/ryosuke-kohita/>Ryosuke Kohita</a>
|
<a href=/people/r/roger-levy/>Roger Levy</a>
|
<a href=/people/m/miguel-ballesteros/>Miguel Ballesteros</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--375><div class="card-body p-3 small">Humans can learn structural properties about a word from minimal experience, and deploy their learned syntactic representations uniformly in different grammatical contexts. We assess the ability of modern neural language models to reproduce this behavior in <a href=https://en.wikipedia.org/wiki/English_language>English</a> and evaluate the effect of structural supervision on learning outcomes. First, we assess few-shot learning capabilities by developing controlled experiments that probe models&#8217; syntactic nominal number and verbal argument structure generalizations for tokens seen as few as two times during training. Second, we assess invariance properties of learned representation : the ability of a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to transfer syntactic generalizations from a base context (e.g., a simple declarative active-voice sentence) to a transformed context (e.g., an interrogative sentence). We test four models trained on the same dataset : an n-gram baseline, an LSTM, and two LSTM-variants trained with explicit structural supervision. We find that in most cases, the neural models are able to induce the proper syntactic generalizations after minimal exposure, often from just two examples during training, and that the two structurally supervised models generalize more accurately than the LSTM model. All neural models are able to leverage information learned in base contexts to drive expectations in transformed contexts, indicating that they have learned some invariance properties of syntax.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.378.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--378 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.378 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938906 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.378" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.378/>Optimus : Organizing Sentences via Pre-trained Modeling of a Latent Space</a></strong><br><a href=/people/c/chunyuan-li/>Chunyuan Li</a>
|
<a href=/people/x/xiang-gao/>Xiang Gao</a>
|
<a href=/people/y/yuan-li/>Yuan Li</a>
|
<a href=/people/b/baolin-peng/>Baolin Peng</a>
|
<a href=/people/x/xiujun-li/>Xiujun Li</a>
|
<a href=/people/y/yizhe-zhang/>Yizhe Zhang</a>
|
<a href=/people/j/jianfeng-gao/>Jianfeng Gao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--378><div class="card-body p-3 small">When trained effectively, the Variational Autoencoder (VAE) can be both a powerful <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a> and an effective representation learning framework for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language</a>. In this paper, we propose the first large-scale language VAE model Optimus (Organizing sentences via Pre-Trained Modeling of a Universal Space). A universal latent embedding space for sentences is first pre-trained on large text corpus, and then fine-tuned for various language generation and understanding tasks. Compared with GPT-2, Optimus enables guided language generation from an abstract level using the <a href=https://en.wikipedia.org/wiki/Latent_vector>latent vectors</a>. Compared with BERT, Optimus can generalize better on low-resource language understanding tasks due to the smooth latent space structure. Extensive experimental results on a wide range of language tasks demonstrate the effectiveness of Optimus. It achieves new state-of-the-art on VAE language modeling benchmarks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.381.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--381 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.381 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939106 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.381" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.381/>RussianSuperGLUE : A Russian Language Understanding Evaluation Benchmark<span class=acl-fixed-case>R</span>ussian<span class=acl-fixed-case>S</span>uper<span class=acl-fixed-case>GLUE</span>: A <span class=acl-fixed-case>R</span>ussian Language Understanding Evaluation Benchmark</a></strong><br><a href=/people/t/tatiana-shavrina/>Tatiana Shavrina</a>
|
<a href=/people/a/alena-fenogenova/>Alena Fenogenova</a>
|
<a href=/people/e/emelyanov-anton/>Emelyanov Anton</a>
|
<a href=/people/d/denis-shevelev/>Denis Shevelev</a>
|
<a href=/people/e/ekaterina-artemova/>Ekaterina Artemova</a>
|
<a href=/people/v/valentin-malykh/>Valentin Malykh</a>
|
<a href=/people/v/vladislav-mikhailov/>Vladislav Mikhailov</a>
|
<a href=/people/m/maria-tikhonova/>Maria Tikhonova</a>
|
<a href=/people/a/andrey-chertok/>Andrey Chertok</a>
|
<a href=/people/a/andrey-evlampiev/>Andrey Evlampiev</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--381><div class="card-body p-3 small">In this paper, we introduce an advanced Russian general language understanding evaluation benchmark Russian SuperGLUE. Recent advances in the field of universal language models and transformers require the development of a methodology for their broad diagnostics and testing for general intellectual skills-detection of natural language inference, commonsense reasoning, ability to perform simple logical operations regardless of text subject or lexicon. For the first time, a <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark</a> of nine tasks, collected and organized analogically to the SuperGLUE methodology, was developed from scratch for the <a href=https://en.wikipedia.org/wiki/Russian_language>Russian language</a>. We also provide baselines, human level evaluation, open-source framework for evaluating <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>, and an overall leaderboard of transformer models for the <a href=https://en.wikipedia.org/wiki/Russian_language>Russian language</a>. Besides, we present the first results of comparing multilingual models in the translated diagnostic test set and offer the first steps to further expanding or assessing State-of-the-art <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> independently of language.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.382.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--382 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.382 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939107 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.382" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.382/>An Empirical Study of Pre-trained Transformers for Arabic Information Extraction<span class=acl-fixed-case>A</span>rabic Information Extraction</a></strong><br><a href=/people/w/wuwei-lan/>Wuwei Lan</a>
|
<a href=/people/y/yang-chen/>Yang Chen</a>
|
<a href=/people/w/wei-xu/>Wei Xu</a>
|
<a href=/people/a/alan-ritter/>Alan Ritter</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--382><div class="card-body p-3 small">Multilingual pre-trained Transformers, such as mBERT (Devlin et al., 2019) and XLM-RoBERTa (Conneau et al., 2020a), have been shown to enable effective cross-lingual zero-shot transfer. However, their performance on Arabic information extraction (IE) tasks is not very well studied. In this paper, we pre-train a customized bilingual BERT, dubbed GigaBERT, that is designed specifically for Arabic NLP and English-to-Arabic zero-shot transfer learning. We study GigaBERT&#8217;s effectiveness on zero-short transfer across four IE tasks : <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>, <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a>, argument role labeling, and relation extraction. Our best model significantly outperforms mBERT, XLM-RoBERTa, and AraBERT (Antoun et al., 2020) in both the supervised and zero-shot transfer settings. We have made our pre-trained models publicly available at : https://github.com/lanwuwei/GigaBERT.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.383.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--383 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.383 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939136 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.383/>TNT : Text Normalization based Pre-training of Transformers for Content Moderation<span class=acl-fixed-case>TNT</span>: Text Normalization based Pre-training of Transformers for Content Moderation</a></strong><br><a href=/people/f/fei-tan/>Fei Tan</a>
|
<a href=/people/y/yifan-hu/>Yifan Hu</a>
|
<a href=/people/c/changwei-hu/>Changwei Hu</a>
|
<a href=/people/k/keqian-li/>Keqian Li</a>
|
<a href=/people/k/kevin-yen/>Kevin Yen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--383><div class="card-body p-3 small">In this work, we present a new language pre-training model TNT (Text Normalization based pre-training of Transformers) for content moderation. Inspired by the masking strategy and <a href=https://en.wikipedia.org/wiki/Text_normalization>text normalization</a>, TNT is developed to learn language representation by training transformers to reconstruct text from four operation types typically seen in text manipulation : substitution, transposition, <a href=https://en.wikipedia.org/wiki/Deletion_(linguistics)>deletion</a>, and insertion. Furthermore, the <a href=https://en.wikipedia.org/wiki/Data_normalization>normalization</a> involves the prediction of both operation types and token labels, enabling TNT to learn from more challenging tasks than the standard task of masked word recovery. As a result, the experiments demonstrate that <a href=https://en.wikipedia.org/wiki/TNT>TNT</a> outperforms strong <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> on the hate speech classification task. Additional <a href=https://en.wikipedia.org/wiki/Text_normalization>text normalization</a> experiments and case studies show that TNT is a new potential approach to misspelling correction.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.384.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--384 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.384 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939268 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.384/>Methods for Numeracy-Preserving Word Embeddings</a></strong><br><a href=/people/d/dhanasekar-sundararaman/>Dhanasekar Sundararaman</a>
|
<a href=/people/s/shijing-si/>Shijing Si</a>
|
<a href=/people/v/vivek-subramanian/>Vivek Subramanian</a>
|
<a href=/people/g/guoyin-wang/>Guoyin Wang</a>
|
<a href=/people/d/devamanyu-hazarika/>Devamanyu Hazarika</a>
|
<a href=/people/l/lawrence-carin/>Lawrence Carin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--384><div class="card-body p-3 small">Word embedding models are typically able to capture the semantics of words via the <a href=https://en.wikipedia.org/wiki/Distributional_hypothesis>distributional hypothesis</a>, but fail to capture the numerical properties of numbers that appear in the text. This leads to problems with <a href=https://en.wikipedia.org/wiki/Numerical_reasoning>numerical reasoning</a> involving <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> such as <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>. We propose a new <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> to assign and learn <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> for numbers. Our approach creates Deterministic, Independent-of-Corpus Embeddings (the model is referred to as DICE) for numbers, such that their cosine similarity reflects the actual distance on the number line. DICE outperforms a wide range of pre-trained word embedding models across multiple examples of two tasks : (i) evaluating the ability to capture numeration and magnitude ; and (ii) to perform list maximum, decoding, and <a href=https://en.wikipedia.org/wiki/Addition>addition</a>. We further explore the utility of these embeddings in downstream tasks, by initializing numbers with our approach for the task of magnitude prediction. We also introduce a regularization approach to learn model-based embeddings of numbers in a contextual setting.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.385.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--385 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.385 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939346 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.385/>An Empirical Investigation of Contextualized Number Prediction</a></strong><br><a href=/people/t/taylor-berg-kirkpatrick/>Taylor Berg-Kirkpatrick</a>
|
<a href=/people/d/daniel-spokoyny/>Daniel Spokoyny</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--385><div class="card-body p-3 small">We conduct a large scale empirical investigation of contextualized number prediction in <a href=https://en.wikipedia.org/wiki/Running_text>running text</a>. Specifically, we consider two tasks : (1)masked number prediction predict-ing a missing numerical value within a sentence, and (2)numerical anomaly detectiondetecting an errorful numeric value within a sentence. We experiment with novel combinations of contextual encoders and output distributions over the <a href=https://en.wikipedia.org/wiki/Real_number_line>real number line</a>. Specifically, we introduce a suite of output distribution parameterizations that incorporate <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variables</a> to add expressivity and better fit the natural distribution of numeric values in running text, and combine them with both recur-rent and transformer-based encoder architectures. We evaluate these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on two <a href=https://en.wikipedia.org/wiki/Data_set>numeric datasets</a> in the financial and scientific domain. Our findings show that output distributions that incorporate discrete latent variables and allow for multiple modes outperform simple flow-based counterparts on all datasets, yielding more accurate numerical pre-diction and anomaly detection. We also show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> effectively utilize textual con-text and benefit from general-purpose unsupervised pretraining.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.389.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--389 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.389 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938920 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.389/>Unsupervised Parsing via Constituency Tests</a></strong><br><a href=/people/s/steven-cao/>Steven Cao</a>
|
<a href=/people/n/nikita-kitaev/>Nikita Kitaev</a>
|
<a href=/people/d/dan-klein/>Dan Klein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--389><div class="card-body p-3 small">We propose a method for unsupervised parsing based on the linguistic notion of a constituency test. One type of constituency test involves modifying the sentence via some <a href=https://en.wikipedia.org/wiki/Transformation_(function)>transformation</a> (e.g. replacing the span with a pronoun) and then judging the result (e.g. checking if it is grammatical). Motivated by this idea, we design an unsupervised parser by specifying a set of <a href=https://en.wikipedia.org/wiki/Transformation_(function)>transformations</a> and using an unsupervised neural acceptability model to make grammaticality decisions. To produce a <a href=https://en.wikipedia.org/wiki/Tree_(graph_theory)>tree</a> given a sentence, we score each span by aggregating its constituency test judgments, and we choose the binary tree with the highest total score. While this approach already achieves performance in the range of current methods, we further improve accuracy by fine-tuning the grammaticality model through a refinement procedure, where we alternate between improving the estimated trees and improving the grammaticality model. The refined <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves 62.8 F1 on the Penn Treebank test set, an absolute improvement of 7.6 points over the previously best published result.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.391.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--391 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.391 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939256 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.391/>Unsupervised Cross-Lingual Part-of-Speech Tagging for Truly Low-Resource Scenarios</a></strong><br><a href=/people/r/ramy-eskander/>Ramy Eskander</a>
|
<a href=/people/s/smaranda-muresan/>Smaranda Muresan</a>
|
<a href=/people/m/michael-collins/>Michael Collins</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--391><div class="card-body p-3 small">We describe a fully unsupervised cross-lingual transfer approach for part-of-speech (POS) tagging under a truly low resource scenario. We assume access to parallel translations between the target language and one or more source languages for which POS taggers are available. We use the <a href=https://en.wikipedia.org/wiki/Bible>Bible</a> as parallel data in our experiments : small size, out-of-domain and covering many diverse languages. Our approach innovates in three ways : 1) a robust approach of selecting training instances via cross-lingual annotation projection that exploits best practices of unsupervised type and token constraints, word-alignment confidence and density of projected POS, 2) a Bi-LSTM architecture that uses contextualized word embeddings, affix embeddings and hierarchical Brown clusters, and 3) an evaluation on 12 diverse languages in terms of language family and morphological typology. In spite of the use of limited and out-of-domain parallel data, our experiments demonstrate significant improvements in <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> over previous work. In addition, we show that using multi-source information, either via <a href=https://en.wikipedia.org/wiki/Projection_(linear_algebra)>projection</a> or output combination, improves the performance for most target languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.392.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--392 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.392 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939296 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.392/>Unsupervised Parsing with S-DIORA : Single Tree Encoding for Deep Inside-Outside Recursive Autoencoders<span class=acl-fixed-case>S</span>-<span class=acl-fixed-case>DIORA</span>: Single Tree Encoding for Deep Inside-Outside Recursive Autoencoders</a></strong><br><a href=/people/a/andrew-drozdov/>Andrew Drozdov</a>
|
<a href=/people/s/subendhu-rongali/>Subendhu Rongali</a>
|
<a href=/people/y/yi-pei-chen/>Yi-Pei Chen</a>
|
<a href=/people/t/tim-ogorman/>Tim OGorman</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a>
|
<a href=/people/a/andrew-mccallum/>Andrew McCallum</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--392><div class="card-body p-3 small">The deep inside-outside recursive autoencoder (DIORA ; Drozdov et al. 2019) is a self-supervised neural model that learns to induce syntactic tree structures for input sentences * without access to labeled training data *. In this paper, we discover that while DIORA exhaustively encodes all possible binary trees of a sentence with a soft dynamic program, its vector averaging approach is locally greedy and can not recover from errors when computing the highest scoring parse tree in bottom-up chart parsing. To fix this issue, we introduce S-DIORA, an improved variant of DIORA that encodes a single tree rather than a softly-weighted mixture of trees by employing a hard argmax operation and a beam at each cell in the chart. Our experiments show that through * fine-tuning * a pre-trained DIORA with our new <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a>, we improve the state of the art in * unsupervised * constituency parsing on the English WSJ Penn Treebank by 2.2-6 % F1, depending on the data used for <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.393.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--393 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.393 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938914 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.393/>Utility is in the Eye of the User : A Critique of NLP Leaderboards<span class=acl-fixed-case>NLP</span> Leaderboards</a></strong><br><a href=/people/k/kawin-ethayarajh/>Kawin Ethayarajh</a>
|
<a href=/people/d/dan-jurafsky/>Dan Jurafsky</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--393><div class="card-body p-3 small">Benchmarks such as GLUE have helped drive advances in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> by incentivizing the creation of more accurate models. While this leaderboard paradigm has been remarkably successful, a historical focus on performance-based evaluation has been at the expense of other qualities that the NLP community values in models, such as compactness, fairness, and <a href=https://en.wikipedia.org/wiki/Efficient_energy_use>energy efficiency</a>. In this opinion paper, we study the divergence between what is incentivized by leaderboards and what is useful in practice through the lens of <a href=https://en.wikipedia.org/wiki/Microeconomics>microeconomic theory</a>. We frame both the leaderboard and NLP practitioners as consumers and the benefit they get from a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> as its utility to them. With this framing, we formalize how leaderboards in their current form can be poor proxies for the NLP community at large. For example, a highly inefficient model would provide less utility to practitioners but not to a <a href=https://en.wikipedia.org/wiki/Glossary_of_economics>leaderboard</a>, since it is a cost that only the former must bear. To allow practitioners to better estimate a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s utility to them, we advocate for more transparency on leaderboards, such as the reporting of statistics that are of practical concern (e.g., <a href=https://en.wikipedia.org/wiki/Mathematical_model>model size</a>, <a href=https://en.wikipedia.org/wiki/Efficient_energy_use>energy efficiency</a>, and inference latency).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.394.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--394 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.394 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938956 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.394" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.394/>An Empirical Investigation Towards Efficient Multi-Domain Language Model Pre-training</a></strong><br><a href=/people/k/kristjan-arumae/>Kristjan Arumae</a>
|
<a href=/people/q/qing-sun/>Qing Sun</a>
|
<a href=/people/p/parminder-bhatia/>Parminder Bhatia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--394><div class="card-body p-3 small">Pre-training large language models has become a standard in the <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing community</a>. Such <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> are pre-trained on generic data (e.g. BookCorpus and English Wikipedia) and often fine-tuned on <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a> in the same domain. However, in order to achieve state-of-the-art performance on out of domain tasks such as clinical named entity recognition and relation extraction, additional in domain pre-training is required. In practice, staged multi-domain pre-training presents performance deterioration in the form of catastrophic forgetting (CF) when evaluated on a generic benchmark such as GLUE. In this paper we conduct an empirical investigation into known methods to mitigate <a href=https://en.wikipedia.org/wiki/Cytomegalovirus>CF</a>. We find that elastic weight consolidation provides best overall scores yielding only a 0.33 % drop in performance across seven generic tasks while remaining competitive in bio-medical tasks. Furthermore, we explore gradient and latent clustering based data selection techniques to improve coverage when using elastic weight consolidation and experience replay methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.402.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--402 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.402 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939083 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.402" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.402/>Does the Objective Matter? Comparing Training Objectives for Pronoun Resolution<span class=acl-fixed-case>O</span>bjective <span class=acl-fixed-case>M</span>atter? <span class=acl-fixed-case>C</span>omparing <span class=acl-fixed-case>T</span>raining <span class=acl-fixed-case>O</span>bjectives for <span class=acl-fixed-case>P</span>ronoun <span class=acl-fixed-case>R</span>esolution</a></strong><br><a href=/people/y/yordan-yordanov/>Yordan Yordanov</a>
|
<a href=/people/o/oana-maria-camburu/>Oana-Maria Camburu</a>
|
<a href=/people/v/vid-kocijan/>Vid Kocijan</a>
|
<a href=/people/t/thomas-lukasiewicz/>Thomas Lukasiewicz</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--402><div class="card-body p-3 small">Hard cases of pronoun resolution have been used as a long-standing benchmark for <a href=https://en.wikipedia.org/wiki/Commonsense_reasoning>commonsense reasoning</a>. In the recent literature, pre-trained language models have been used to obtain state-of-the-art results on pronoun resolution. Overall, four categories of training and evaluation objectives have been introduced. The variety of training datasets and pre-trained language models used in these works makes it unclear whether the choice of <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training objective</a> is critical. In this work, we make a fair comparison of the performance and seed-wise stability of four <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that represent the four categories of objectives. Our experiments show that the objective of sequence ranking performs the best in-domain, while the objective of semantic similarity between candidates and <a href=https://en.wikipedia.org/wiki/Pronoun>pronoun</a> performs the best out-of-domain. We also observe a seed-wise instability of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> using sequence ranking, which is not the case when the other objectives are used.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.406.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--406 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.406 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939315 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.406/>Training for <a href=https://en.wikipedia.org/wiki/Gibbs_sampling>Gibbs Sampling</a> on <a href=https://en.wikipedia.org/wiki/Conditional_random_field>Conditional Random Fields</a> with Neural Scoring Factors<span class=acl-fixed-case>G</span>ibbs Sampling on Conditional Random Fields with Neural Scoring Factors</a></strong><br><a href=/people/s/sida-gao/>Sida Gao</a>
|
<a href=/people/m/matthew-r-gormley/>Matthew R. Gormley</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--406><div class="card-body p-3 small">Most recent improvements in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> come from changes to the neural network architectures modeling the text input. Yet, state-of-the-art <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> often rely on simple approaches to model the label space, e.g. bigram Conditional Random Fields (CRFs) in sequence tagging. More expressive <a href=https://en.wikipedia.org/wiki/Graphical_model>graphical models</a> are rarely used due to their prohibitive computational cost. In this work, we present an approach for efficiently training and decoding hybrids of <a href=https://en.wikipedia.org/wiki/Graphical_model>graphical models</a> and <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> based on <a href=https://en.wikipedia.org/wiki/Gibbs_sampling>Gibbs sampling</a>. Our approach is the natural adaptation of SampleRank (Wick et al., 2011) to neural models, and is widely applicable to tasks beyond sequence tagging. We apply our approach to <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a> and present a neural skip-chain CRF model, for which exact inference is impractical. The skip-chain model improves over a strong <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> on three languages from CoNLL-02/03. We obtain new state-of-the-art results on <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.412.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--412 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.412 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939326 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.412/>Simple Data Augmentation with the Mask Token Improves Domain Adaptation for Dialog Act Tagging</a></strong><br><a href=/people/s/semih-yavuz/>Semih Yavuz</a>
|
<a href=/people/k/kazuma-hashimoto/>Kazuma Hashimoto</a>
|
<a href=/people/w/wenhao-liu/>Wenhao Liu</a>
|
<a href=/people/n/nitish-shirish-keskar/>Nitish Shirish Keskar</a>
|
<a href=/people/r/richard-socher/>Richard Socher</a>
|
<a href=/people/c/caiming-xiong/>Caiming Xiong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--412><div class="card-body p-3 small">The concept of Dialogue Act (DA) is universal across different task-oriented dialogue domains-the act of request carries the same speaker intention whether it is for <a href=https://en.wikipedia.org/wiki/Table_reservation>restaurant reservation</a> or flight booking. However, DA taggers trained on one domain do not generalize well to other domains, which leaves us with the expensive need for a large amount of annotated data in the target domain. In this work, we investigate how to better adapt DA taggers to desired target domains with only unlabeled data. We propose MaskAugment, a controllable mechanism that augments text input by leveraging the pre-trained Mask token from BERT model. Inspired by consistency regularization, we use MaskAugment to introduce an unsupervised teacher-student learning scheme to examine the <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> of DA taggers. Our extensive experiments on the Simulated Dialogue (GSim) and Schema-Guided Dialogue (SGD) datasets show that MaskAugment is useful in improving the cross-domain generalization for DA tagging.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.413.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--413 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.413 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938783 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.413/>Low-Resource Domain Adaptation for Compositional Task-Oriented Semantic Parsing</a></strong><br><a href=/people/x/xilun-chen/>Xilun Chen</a>
|
<a href=/people/a/asish-ghoshal/>Asish Ghoshal</a>
|
<a href=/people/y/yashar-mehdad/>Yashar Mehdad</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a>
|
<a href=/people/s/sonal-gupta/>Sonal Gupta</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--413><div class="card-body p-3 small">Task-oriented semantic parsing is a critical component of virtual assistants, which is responsible for understanding the user&#8217;s intents (set reminder, play music, etc.). Recent advances in <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> have enabled several approaches to successfully parse more complex queries (Gupta et al., 2018 ; Rongali et al.,2020), but these models require a large amount of annotated training data to parse queries on new domains (e.g. reminder, music). In this paper, we focus on adapting task-oriented semantic parsers to low-resource domains, and propose a novel method that outperforms a <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised neural model</a> at a 10-fold <a href=https://en.wikipedia.org/wiki/Data_reduction>data reduction</a>. In particular, we identify two fundamental factors for low-resource domain adaptation : better <a href=https://en.wikipedia.org/wiki/Representation_learning>representation learning</a> and better <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training techniques</a>. Our <a href=https://en.wikipedia.org/wiki/Representation_learning>representation learning</a> uses BART (Lewis et al., 2019) to initialize our model which outperforms encoder-only pre-trained representations used in previous work. Furthermore, we train with optimization-based meta-learning (Finn et al., 2017) to improve generalization to low-resource domains. This approach significantly outperforms all baseline methods in the experiments on a newly collected multi-domain task-oriented semantic parsing dataset (TOPv2), which we release to the public.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.416.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--416 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.416 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938661 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.416" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.416/>Facilitating the Communication of Politeness through Fine-Grained Paraphrasing</a></strong><br><a href=/people/l/liye-fu/>Liye Fu</a>
|
<a href=/people/s/susan-fussell/>Susan Fussell</a>
|
<a href=/people/c/cristian-danescu-niculescu-mizil/>Cristian Danescu-Niculescu-Mizil</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--416><div class="card-body p-3 small">Aided by <a href=https://en.wikipedia.org/wiki/Technology>technology</a>, people are increasingly able to communicate across geographical, cultural, and language barriers. This ability also results in new challenges, as interlocutors need to adapt their communication approaches to increasingly diverse circumstances. In this work, we take the first steps towards automatically assisting people in adjusting their language to a specific communication circumstance. As a case study, we focus on facilitating the accurate transmission of pragmatic intentions and introduce a <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> for suggesting paraphrases that achieve the intended level of <a href=https://en.wikipedia.org/wiki/Politeness>politeness</a> under a given communication circumstance. We demonstrate the feasibility of this approach by evaluating our method in two realistic communication scenarios and show that it can reduce the potential for misalignment between the speaker&#8217;s intentions and the listener&#8217;s perceptions in both cases.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.418.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--418 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.418 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.418.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939123 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.418" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.418/>Seq2Edits : Sequence Transduction Using Span-level Edit Operations<span class=acl-fixed-case>S</span>eq2<span class=acl-fixed-case>E</span>dits: Sequence Transduction Using Span-level Edit Operations</a></strong><br><a href=/people/f/felix-stahlberg/>Felix Stahlberg</a>
|
<a href=/people/s/shankar-kumar/>Shankar Kumar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--418><div class="card-body p-3 small">We propose Seq2Edits, an open-vocabulary approach to sequence editing for natural language processing (NLP) tasks with a high degree of overlap between input and output texts. In this approach, each sequence-to-sequence transduction is represented as a sequence of edit operations, where each operation either replaces an entire source span with target tokens or keeps it unchanged. We evaluate our method on five NLP tasks (text normalization, sentence fusion, sentence splitting & rephrasing, text simplification, and grammatical error correction) and report competitive results across the board. For <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>grammatical error correction</a>, our method speeds up <a href=https://en.wikipedia.org/wiki/Inference>inference</a> by up to 5.2x compared to full sequence models because <a href=https://en.wikipedia.org/wiki/Inference>inference time</a> depends on the number of edits rather than the number of target tokens. For <a href=https://en.wikipedia.org/wiki/Text_normalization>text normalization</a>, sentence fusion, and <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>grammatical error correction</a>, our approach improves explainability by associating each edit operation with a <a href=https://en.wikipedia.org/wiki/Tag_(metadata)>human-readable tag</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.420.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--420 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.420 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939329 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.420" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.420/>Blank Language Models</a></strong><br><a href=/people/t/tianxiao-shen/>Tianxiao Shen</a>
|
<a href=/people/v/victor-quach/>Victor Quach</a>
|
<a href=/people/r/regina-barzilay/>Regina Barzilay</a>
|
<a href=/people/t/tommi-jaakkola/>Tommi Jaakkola</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--420><div class="card-body p-3 small">We propose Blank Language Model (BLM), a model that generates sequences by dynamically creating and filling in blanks. The blanks control which part of the sequence to expand, making BLM ideal for a variety of text editing and rewriting tasks. The <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> can start from a single blank or partially completed text with blanks at specified locations. It iteratively determines which word to place in a blank and whether to insert new blanks, and stops generating when no blanks are left to fill. BLM can be efficiently trained using a <a href=https://en.wikipedia.org/wiki/Upper_and_lower_bounds>lower bound</a> of the <a href=https://en.wikipedia.org/wiki/Marginal_distribution>marginal data likelihood</a>. On the task of filling missing text snippets, BLM significantly outperforms all other <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baselines</a> in terms of both <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and <a href=https://en.wikipedia.org/wiki/Fluency>fluency</a>. Experiments on style transfer and damaged ancient text restoration demonstrate the potential of this <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> for a wide range of <a href=https://en.wikipedia.org/wiki/Application_software>applications</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.421.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--421 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.421 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939341 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.421" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.421/>COD3S : Diverse Generation with Discrete Semantic Signatures<span class=acl-fixed-case>COD3S</span>: Diverse Generation with Discrete Semantic Signatures</a></strong><br><a href=/people/n/nathaniel-weir/>Nathaniel Weir</a>
|
<a href=/people/j/joao-sedoc/>Joo Sedoc</a>
|
<a href=/people/b/benjamin-van-durme/>Benjamin Van Durme</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--421><div class="card-body p-3 small">We present COD3S, a novel method for generating semantically diverse sentences using neural sequence-to-sequence (seq2seq) models. Conditioned on an input, seq2seqs typically produce semantically and syntactically homogeneous sets of sentences and thus perform poorly on one-to-many sequence generation tasks. Our two-stage approach improves output diversity by conditioning generation on locality-sensitive hash (LSH)-based semantic sentence codes whose <a href=https://en.wikipedia.org/wiki/Hamming_distance>Hamming distances</a> highly correlate with human judgments of semantic textual similarity. Though it is generally applicable, we apply to causal generation, the task of predicting a proposition&#8217;s plausible causes or effects. We demonstrate through automatic and human evaluation that responses produced using our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> exhibit improved <a href=https://en.wikipedia.org/wiki/Multiculturalism>diversity</a> without degrading task performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.422.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--422 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.422 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939038 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.422" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.422/>Automatic Extraction of <a href=https://en.wikipedia.org/wiki/Rule_of_inference>Rules</a> Governing Morphological Agreement</a></strong><br><a href=/people/a/aditi-chaudhary/>Aditi Chaudhary</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a>
|
<a href=/people/a/adithya-pratapa/>Adithya Pratapa</a>
|
<a href=/people/d/david-r-mortensen/>David R. Mortensen</a>
|
<a href=/people/z/zaid-sheikh/>Zaid Sheikh</a>
|
<a href=/people/y/yulia-tsvetkov/>Yulia Tsvetkov</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--422><div class="card-body p-3 small">Creating a <a href=https://en.wikipedia.org/wiki/Descriptive_grammar>descriptive grammar</a> of a language is an indispensable step for language documentation and preservation. However, at the same time it is a tedious, time-consuming task. In this paper, we take steps towards automating this process by devising an automated framework for extracting a first-pass grammatical specification from raw text in a concise, human- and machine-readable format. We focus on extracting rules describing <a href=https://en.wikipedia.org/wiki/Agreement_(linguistics)>agreement</a>, a morphosyntactic phenomenon at the core of the <a href=https://en.wikipedia.org/wiki/Grammar>grammars</a> of many of the world&#8217;s languages. We apply our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> to all languages included in the Universal Dependencies project, with promising results. Using cross-lingual transfer, even with no expert annotations in the language of interest, our framework extracts a grammatical specification which is nearly equivalent to those created with large amounts of gold-standard annotated data. We confirm this finding with human expert evaluations of the <a href=https://en.wikipedia.org/wiki/Rule_of_inference>rules</a> that our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> produces, which have an average <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 78 %. We release an interface demonstrating the extracted <a href=https://en.wikipedia.org/wiki/Rule-based_programming>rules</a> at https://neulab.github.io/lase/</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.425.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--425 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.425 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939176 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.425" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.425/>A Computational Approach to Understanding Empathy Expressed in Text-Based Mental Health Support</a></strong><br><a href=/people/a/ashish-sharma/>Ashish Sharma</a>
|
<a href=/people/a/adam-miner/>Adam Miner</a>
|
<a href=/people/d/david-atkins/>David Atkins</a>
|
<a href=/people/t/tim-althoff/>Tim Althoff</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--425><div class="card-body p-3 small">Empathy is critical to successful <a href=https://en.wikipedia.org/wiki/Mental_health_professional>mental health support</a>. Empathy measurement has predominantly occurred in synchronous, face-to-face settings, and may not translate to asynchronous, text-based contexts. Because millions of people use <a href=https://en.wikipedia.org/wiki/Text-based_user_interface>text-based platforms</a> for <a href=https://en.wikipedia.org/wiki/Mental_health_professional>mental health support</a>, understanding <a href=https://en.wikipedia.org/wiki/Empathy>empathy</a> in these contexts is crucial. In this work, we present a computational approach to understanding how <a href=https://en.wikipedia.org/wiki/Empathy>empathy</a> is expressed in online mental health platforms. We develop a novel unifying theoretically-grounded framework for characterizing the communication of empathy in text-based conversations. We collect and share a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> of 10k (post, response) pairs annotated using this empathy framework with supporting evidence for annotations (rationales). We develop a multi-task RoBERTa-based bi-encoder model for identifying <a href=https://en.wikipedia.org/wiki/Empathy>empathy</a> in conversations and extracting rationales underlying its predictions. Experiments demonstrate that our approach can effectively identify empathic conversations. We further apply this model to analyze 235k mental health interactions and show that users do not self-learn <a href=https://en.wikipedia.org/wiki/Empathy>empathy</a> over time, revealing opportunities for empathy training and feedback.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.426.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--426 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.426 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939253 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.426" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.426/>Modeling Protagonist Emotions for Emotion-Aware Storytelling</a></strong><br><a href=/people/f/faeze-brahman/>Faeze Brahman</a>
|
<a href=/people/s/snigdha-chaturvedi/>Snigdha Chaturvedi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--426><div class="card-body p-3 small">Emotions and their evolution play a central role in creating a captivating story. In this paper, we present the first study on modeling the emotional trajectory of the protagonist in neural storytelling. We design methods that generate stories that adhere to given story titles and desired emotion arcs for the protagonist. Our <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> include Emotion Supervision (EmoSup) and two Emotion-Reinforced (EmoRL) models. The EmoRL models use special rewards designed to regularize the story generation process through <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a>. Our automatic and manual evaluations demonstrate that these models are significantly better at generating stories that follow the desired emotion arcs compared to baseline methods, without sacrificing story quality.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.428.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--428 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.428 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939316 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.428/>Quantifying Intimacy in Language</a></strong><br><a href=/people/j/jiaxin-pei/>Jiaxin Pei</a>
|
<a href=/people/d/david-jurgens/>David Jurgens</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--428><div class="card-body p-3 small">Intimacy is a fundamental aspect of how we relate to others in social settings. Language encodes the social information of intimacy through both topics and other more subtle cues (such as linguistic hedging and swearing). Here, we introduce a new computational framework for studying expressions of the intimacy in language with an accompanying <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> and <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning model</a> for accurately predicting the intimacy level of questions (Pearson r = 0.87). Through analyzing a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of 80.5 M questions across <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>, <a href=https://en.wikipedia.org/wiki/Book>books</a>, and <a href=https://en.wikipedia.org/wiki/Film>films</a>, we show that individuals employ interpersonal pragmatic moves in their language to align their intimacy with social settings. Then, in three studies, we further demonstrate how individuals modulate their intimacy to match <a href=https://en.wikipedia.org/wiki/Social_norm>social norms</a> around <a href=https://en.wikipedia.org/wiki/Gender>gender</a>, <a href=https://en.wikipedia.org/wiki/Social_distance>social distance</a>, and audience, each validating key findings from studies in <a href=https://en.wikipedia.org/wiki/Social_psychology>social psychology</a>. Our work demonstrates that <a href=https://en.wikipedia.org/wiki/Intimate_relationship>intimacy</a> is a pervasive and impactful social dimension of language.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.430.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--430 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.430 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939132 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.430/>Weakly Supervised Subevent Knowledge Acquisition<span class=acl-fixed-case>S</span>upervised <span class=acl-fixed-case>S</span>ubevent <span class=acl-fixed-case>K</span>nowledge <span class=acl-fixed-case>A</span>cquisition</a></strong><br><a href=/people/w/wenlin-yao/>Wenlin Yao</a>
|
<a href=/people/z/zeyu-dai/>Zeyu Dai</a>
|
<a href=/people/m/maitreyi-ramaswamy/>Maitreyi Ramaswamy</a>
|
<a href=/people/b/bonan-min/>Bonan Min</a>
|
<a href=/people/r/ruihong-huang/>Ruihong Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--430><div class="card-body p-3 small">Subevents elaborate an event and widely exist in <a href=https://en.wikipedia.org/wiki/Event_(probability_theory)>event descriptions</a>. Subevent knowledge is useful for <a href=https://en.wikipedia.org/wiki/Discourse_analysis>discourse analysis</a> and event-centric applications. Acknowledging the scarcity of subevent knowledge, we propose a weakly supervised approach to extract subevent relation tuples from text and build the first large scale subevent knowledge base. We first obtain the initial set of event pairs that are likely to have the subevent relation, by exploiting two observations that 1) subevents are temporally contained by the parent event, and 2) the definitions of the parent event can be used to further guide the identification of subevents. Then, we collect rich weak supervision using the initial seed subevent pairs to train a contextual classifier using BERT and apply the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> to identify new subevent pairs. The evaluation showed that the acquired subevent tuples (239 K) are of high quality (90.1 % accuracy) and cover a wide range of event types. The acquired subevent knowledge has been shown useful for <a href=https://en.wikipedia.org/wiki/Discourse_analysis>discourse analysis</a> and identifying a range of event-event relations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.431.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--431 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.431 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939154 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.431/>Biomedical Event Extraction as Sequence Labeling</a></strong><br><a href=/people/a/alan-ramponi/>Alan Ramponi</a>
|
<a href=/people/r/rob-van-der-goot/>Rob van der Goot</a>
|
<a href=/people/r/rosario-lombardo/>Rosario Lombardo</a>
|
<a href=/people/b/barbara-plank/>Barbara Plank</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--431><div class="card-body p-3 small">We introduce Biomedical Event Extraction as Sequence Labeling (BeeSL), a joint end-to-end neural information extraction model. BeeSL recasts the task as <a href=https://en.wikipedia.org/wiki/Sequence_labeling>sequence labeling</a>, taking advantage of a multi-label aware encoding strategy and jointly modeling the intermediate tasks via <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a>. BeeSL is fast, accurate, end-to-end, and unlike current methods does not require any external knowledge base or preprocessing tools. BeeSL outperforms the current best <a href=https://en.wikipedia.org/wiki/System>system</a> (Li et al., 2019) on the Genia 2011 benchmark by 1.57 % absolute <a href=https://en.wikipedia.org/wiki/Free_and_open-source_software>F1 score</a> reaching 60.22 % <a href=https://en.wikipedia.org/wiki/Free_and_open-source_software>F1</a>, establishing a new state of the art for the task. Importantly, we also provide first results on biomedical event extraction without gold entity information. Empirical results show that BeeSL&#8217;s speed and <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> makes it a viable approach for large-scale real-world scenarios.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.432.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--432 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.432 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.432/>Annotating Temporal Dependency Graphs via <a href=https://en.wikipedia.org/wiki/Crowdsourcing>Crowdsourcing</a><span class=acl-fixed-case>A</span>nnotating <span class=acl-fixed-case>T</span>emporal <span class=acl-fixed-case>D</span>ependency <span class=acl-fixed-case>G</span>raphs via <span class=acl-fixed-case>C</span>rowdsourcing</a></strong><br><a href=/people/j/jiarui-yao/>Jiarui Yao</a>
|
<a href=/people/h/haoling-qiu/>Haoling Qiu</a>
|
<a href=/people/b/bonan-min/>Bonan Min</a>
|
<a href=/people/n/nianwen-xue/>Nianwen Xue</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--432><div class="card-body p-3 small">We present the construction of a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> of 500 Wikinews articles annotated with temporal dependency graphs (TDGs) that can be used to train systems to understand temporal relations in text. We argue that temporal dependency graphs, built on previous research on narrative times and temporal anaphora, provide a representation scheme that achieves a good trade-off between completeness and practicality in temporal annotation. We also provide a crowdsourcing strategy to annotate TDGs, and demonstrate the feasibility of this approach with an evaluation of the quality of the annotation, and the utility of the resulting <a href=https://en.wikipedia.org/wiki/Data_set>data set</a> by training a <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning model</a> on this <a href=https://en.wikipedia.org/wiki/Data_set>data set</a>. The data set is publicly available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.434.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--434 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.434 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.434.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939312 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.434/>CHARM : Inferring Personal Attributes from Conversations<span class=acl-fixed-case>CHARM</span>: Inferring Personal Attributes from Conversations</a></strong><br><a href=/people/a/anna-tigunova/>Anna Tigunova</a>
|
<a href=/people/a/andrew-yates/>Andrew Yates</a>
|
<a href=/people/p/paramita-mirza/>Paramita Mirza</a>
|
<a href=/people/g/gerhard-weikum/>Gerhard Weikum</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--434><div class="card-body p-3 small">Personal knowledge about users&#8217; professions, hobbies, favorite food, and travel preferences, among others, is a valuable asset for individualized AI, such as <a href=https://en.wikipedia.org/wiki/Recommender_system>recommenders</a> or <a href=https://en.wikipedia.org/wiki/Chatbot>chatbots</a>. Conversations in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>, such as <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a>, are a rich source of data for inferring personal facts. Prior work developed supervised methods to extract this knowledge, but these approaches can not generalize beyond attribute values with ample labeled training samples. This paper overcomes this limitation by devising CHARM : a zero-shot learning method that creatively leverages keyword extraction and document retrieval in order to predict attribute values that were never seen during training. Experiments with large datasets from <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a> show the viability of CHARM for open-ended attributes, such as <a href=https://en.wikipedia.org/wiki/Profession>professions</a> and <a href=https://en.wikipedia.org/wiki/Hobby>hobbies</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.437.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--437 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.437 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938651 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.437" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.437/>How Much Knowledge Can You Pack Into the Parameters of a <a href=https://en.wikipedia.org/wiki/Language_model>Language Model</a>?</a></strong><br><a href=/people/a/adam-roberts/>Adam Roberts</a>
|
<a href=/people/c/colin-raffel/>Colin Raffel</a>
|
<a href=/people/n/noam-shazeer/>Noam Shazeer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--437><div class="card-body p-3 small">It has recently been observed that neural language models trained on <a href=https://en.wikipedia.org/wiki/Unstructured_data>unstructured text</a> can implicitly store and retrieve knowledge using <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language queries</a>. In this short paper, we measure the practical utility of this approach by fine-tuning pre-trained <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> to answer questions without access to any external context or knowledge. We show that this approach scales with model size and performs competitively with open-domain systems that explicitly retrieve answers from an external knowledge source when answering questions. To facilitate reproducibility and future work, we release our code and trained <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.438.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--438 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.438 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938985 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.438" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.438/>EXAMS : A Multi-subject High School Examinations Dataset for Cross-lingual and Multilingual Question Answering<span class=acl-fixed-case>EXAMS</span>: A Multi-subject High School Examinations Dataset for Cross-lingual and Multilingual Question Answering</a></strong><br><a href=/people/m/momchil-hardalov/>Momchil Hardalov</a>
|
<a href=/people/t/todor-mihaylov/>Todor Mihaylov</a>
|
<a href=/people/d/dimitrina-zlatkova/>Dimitrina Zlatkova</a>
|
<a href=/people/y/yoan-dinkov/>Yoan Dinkov</a>
|
<a href=/people/i/ivan-koychev/>Ivan Koychev</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--438><div class="card-body p-3 small">We propose EXAMS a new benchmark dataset for cross-lingual and multilingual question answering for high school examinations. We collected more than 24,000 high-quality high school exam questions in 16 languages, covering 8 language families and 24 school subjects from Natural Sciences and Social Sciences, among others. EXAMS offers unique fine-grained evaluation framework across multiple languages and subjects, which allows precise analysis and comparison of the proposed models. We perform various experiments with existing top-performing multilingual pre-trained models and show that EXAMS offers multiple challenges that require multilingual knowledge and reasoning in multiple domains. We hope that EXAMS will enable researchers to explore challenging reasoning and knowledge transfer methods and pre-trained models for school question answering in various languages which was not possible by now. The data, code, pre-trained models, and evaluation are available at http://github.com/mhardalov/exams-qa.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.447.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--447 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.447 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.447.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938890 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.447/>Sequence-Level Mixed Sample Data Augmentation</a></strong><br><a href=/people/d/demi-guo/>Demi Guo</a>
|
<a href=/people/y/yoon-kim/>Yoon Kim</a>
|
<a href=/people/a/alexander-m-rush/>Alexander Rush</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--447><div class="card-body p-3 small">Despite their empirical success, <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> still have difficulty capturing compositional aspects of natural language. This work proposes a simple data augmentation approach to encourage compositional behavior in neural models for sequence-to-sequence problems. Our approach, SeqMix, creates new synthetic examples by softly combining input / output sequences from the training set. We connect this approach to existing techniques such as SwitchOut and word dropout, and show that these techniques are all essentially approximating variants of a single objective. SeqMix consistently yields approximately 1.0 BLEU improvement on five different <a href=https://en.wikipedia.org/wiki/Translation_(biology)>translation datasets</a> over strong Transformer baselines. On tasks that require strong compositional generalization such as SCAN and semantic parsing, SeqMix also offers further improvements.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.448.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--448 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.448 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939066 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.448" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.448/>Consistency of a Recurrent Language Model With Respect to Incomplete Decoding</a></strong><br><a href=/people/s/sean-welleck/>Sean Welleck</a>
|
<a href=/people/i/ilia-kulikov/>Ilia Kulikov</a>
|
<a href=/people/j/jaedeok-kim/>Jaedeok Kim</a>
|
<a href=/people/r/richard-yuanzhe-pang/>Richard Yuanzhe Pang</a>
|
<a href=/people/k/kyunghyun-cho/>Kyunghyun Cho</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--448><div class="card-body p-3 small">Despite strong performance on a variety of tasks, neural sequence models trained with <a href=https://en.wikipedia.org/wiki/Maximum_likelihood_estimation>maximum likelihood</a> have been shown to exhibit issues such as length bias and degenerate repetition. We study the related issue of receiving infinite-length sequences from a recurrent language model when using common decoding algorithms. To analyze this issue, we first define inconsistency of a decoding algorithm, meaning that the <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> can yield an infinite-length sequence that has zero probability under the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. We prove that commonly used incomplete decoding algorithms <a href=https://en.wikipedia.org/wiki/Greedy_search>greedy search</a>, <a href=https://en.wikipedia.org/wiki/Beam_search>beam search</a>, top-k sampling, and nucleus sampling are inconsistent, despite the fact that recurrent language models are trained to produce sequences of finite length. Based on these insights, we propose two remedies which address inconsistency : consistent variants of top-k and nucleus sampling, and a self-terminating recurrent language model. Empirical results show that <a href=https://en.wikipedia.org/wiki/Inconsistency>inconsistency</a> occurs in practice, and that the proposed <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> prevent <a href=https://en.wikipedia.org/wiki/Inconsistency>inconsistency</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.451.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--451 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.451 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938882 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.451/>Inducing Target-Specific Latent Structures for Aspect Sentiment Classification</a></strong><br><a href=/people/c/chenhua-chen/>Chenhua Chen</a>
|
<a href=/people/z/zhiyang-teng/>Zhiyang Teng</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--451><div class="card-body p-3 small">Aspect-level sentiment analysis aims to recognize the sentiment polarity of an aspect or a target in a comment. Recently, graph convolutional networks based on linguistic dependency trees have been studied for this task. However, the dependency parsing accuracy of commercial product comments or <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a> might be unsatisfactory. To tackle this problem, we associate linguistic dependency trees with automatically induced aspectspecific graphs. We propose gating mechanisms to dynamically combine information from word dependency graphs and latent graphs which are learned by self-attention networks. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can complement supervised syntactic features with latent semantic dependencies. Experimental results on five <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmarks</a> show the effectiveness of our proposed latent models, giving significantly better results than <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> without using latent graphs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.459.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--459 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.459 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938756 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.459" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.459/>Dynamic Anticipation and Completion for Multi-Hop Reasoning over Sparse Knowledge Graph</a></strong><br><a href=/people/x/xin-lv/>Xin Lv</a>
|
<a href=/people/x/xu-han/>Xu Han</a>
|
<a href=/people/l/lei-hou/>Lei Hou</a>
|
<a href=/people/j/juanzi-li/>Juanzi Li</a>
|
<a href=/people/z/zhiyuan-liu/>Zhiyuan Liu</a>
|
<a href=/people/w/wei-zhang/>Wei Zhang</a>
|
<a href=/people/y/yichi-zhang/>Yichi Zhang</a>
|
<a href=/people/h/hao-kong/>Hao Kong</a>
|
<a href=/people/s/suhui-wu/>Suhui Wu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--459><div class="card-body p-3 small">Multi-hop reasoning has been widely studied in recent years to seek an effective and interpretable method for knowledge graph (KG) completion. Most previous <a href=https://en.wikipedia.org/wiki/Automated_reasoning>reasoning methods</a> are designed for dense KGs with enough paths between entities, but can not work well on those sparse KGs that only contain sparse paths for <a href=https://en.wikipedia.org/wiki/Automated_reasoning>reasoning</a>. On the one hand, sparse KGs contain less information, which makes it difficult for the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to choose correct paths. On the other hand, the lack of evidential paths to target entities also makes the reasoning process difficult. To solve these problems, we propose a multi-hop reasoning model over sparse KGs, by applying novel dynamic anticipation and completion strategies : (1) The anticipation strategy utilizes the latent prediction of embedding-based models to make our model perform more potential path search over sparse KGs. (2) Based on the anticipation information, the completion strategy dynamically adds edges as additional actions during the path search, which further alleviates the sparseness problem of KGs. The experimental results on five datasets sampled from <a href=https://en.wikipedia.org/wiki/Freebase>Freebase</a>, <a href=https://en.wikipedia.org/wiki/NELL>NELL</a> and <a href=https://en.wikipedia.org/wiki/Wikidata>Wikidata</a> show that our method outperforms state-of-the-art baselines. Our codes and datasets can be obtained from https://github.com/THU-KEG/DacKGR.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.460.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--460 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.460 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938826 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.460" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.460/>Knowledge Association with Hyperbolic Knowledge Graph Embeddings</a></strong><br><a href=/people/z/zequn-sun/>Zequn Sun</a>
|
<a href=/people/m/muhao-chen/>Muhao Chen</a>
|
<a href=/people/w/wei-hu/>Wei Hu</a>
|
<a href=/people/c/chengming-wang/>Chengming Wang</a>
|
<a href=/people/j/jian-dai/>Jian Dai</a>
|
<a href=/people/w/wei-zhang/>Wei Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--460><div class="card-body p-3 small">Capturing associations for knowledge graphs (KGs) through <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity alignment</a>, <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity type inference</a> and other related tasks benefits NLP applications with comprehensive knowledge representations. Recent related methods built on Euclidean embeddings are challenged by the hierarchical structures and different scales of KGs. They also depend on high embedding dimensions to realize enough expressiveness. Differently, we explore with low-dimensional hyperbolic embeddings for knowledge association. We propose a hyperbolic relational graph neural network for KG embedding and capture knowledge associations with a hyperbolic transformation. Extensive experiments on entity alignment and type inference demonstrate the effectiveness and efficiency of our method.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.461.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--461 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.461 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939236 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.461" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.461/>Domain Knowledge Empowered Structured Neural Net for End-to-End Event Temporal Relation Extraction</a></strong><br><a href=/people/r/rujun-han/>Rujun Han</a>
|
<a href=/people/y/yichao-zhou/>Yichao Zhou</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--461><div class="card-body p-3 small">Extracting event temporal relations is a critical task for <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction</a> and plays an important role in <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a>. Prior systems leverage <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> and pre-trained <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> to improve the performance of the task. However, these systems often suffer from two shortcomings : 1) when performing maximum a posteriori (MAP) inference based on neural models, previous systems only used structured knowledge that is assumed to be absolutely correct, i.e., hard constraints ; 2) biased predictions on dominant temporal relations when training with a limited amount of data. To address these issues, we propose a framework that enhances <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural network</a> with <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>distributional constraints</a> constructed by probabilistic domain knowledge. We solve the constrained inference problem via <a href=https://en.wikipedia.org/wiki/Lagrangian_and_Eulerian_specification_of_the_flow_field>Lagrangian Relaxation</a> and apply it to end-to-end event temporal relation extraction tasks. Experimental results show our framework is able to improve the baseline neural network models with strong <a href=https://en.wikipedia.org/wiki/Statistical_significance>statistical significance</a> on two widely used datasets in news and clinical domains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.463.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--463 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.463 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.463.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938933 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.463" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.463/>Understanding the Difficulty of Training Transformers</a></strong><br><a href=/people/l/liyuan-liu/>Liyuan Liu</a>
|
<a href=/people/x/xiaodong-liu/>Xiaodong Liu</a>
|
<a href=/people/j/jianfeng-gao/>Jianfeng Gao</a>
|
<a href=/people/w/weizhu-chen/>Weizhu Chen</a>
|
<a href=/people/j/jiawei-han/>Jiawei Han</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--463><div class="card-body p-3 small">Transformers have proved effective in many NLP tasks. However, their training requires non-trivial efforts regarding carefully designing cutting-edge optimizers and learning rate schedulers (e.g., conventional SGD fails to train <a href=https://en.wikipedia.org/wiki/Transformers_(TV_series)>Transformers</a> effectively). Our objective here is to understand _ _ what complicates Transformer training _ _ from both empirical and theoretical perspectives. Our analysis reveals that unbalanced gradients are not the root cause of the instability of training. Instead, we identify an amplification effect that influences <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training</a> substantiallyfor each layer in a multi-layer Transformer model, heavy dependency on its residual branch makes training unstable, since it amplifies <a href=https://en.wikipedia.org/wiki/Perturbation_theory_(quantum_mechanics)>small parameter perturbations</a> (e.g., parameter updates) and results in significant disturbances in the model output. Yet we observe that a light dependency limits the model potential and leads to inferior trained models. Inspired by our analysis, we propose Admin (Adaptive model initialization) to stabilize the early stage&#8217;s training and unleash its full potential in the late stage. Extensive experiments show that Admin is more stable, converges faster, and leads to better performance</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.464.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--464 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.464 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.464.OptionalSupplementaryMaterial.pdf data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939147 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.464/>An Empirical Study of Generation Order for Machine Translation</a></strong><br><a href=/people/w/william-chan/>William Chan</a>
|
<a href=/people/m/mitchell-stern/>Mitchell Stern</a>
|
<a href=/people/j/jamie-kiros/>Jamie Kiros</a>
|
<a href=/people/j/jakob-uszkoreit/>Jakob Uszkoreit</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--464><div class="card-body p-3 small">In this work, we present an empirical study of generation order for <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. Building on recent advances in insertion-based modeling, we first introduce a soft order-reward framework that enables us to train models to follow arbitrary oracle generation policies. We then make use of this framework to explore a large variety of generation orders, including uninformed orders, location-based orders, frequency-based orders, content-based orders, and model-based orders. Curiously, we find that for the WMT&#8217;14 English German and WMT&#8217;18 English Chinese translation tasks, order does not have a substantial impact on output quality. Moreover, for English German, we even discover that unintuitive orderings such as alphabetical and shortest-first can match the performance of a standard Transformer, suggesting that traditional left-to-right generation may not be necessary to achieve high performance.<tex-math>\\to</tex-math> German and WMT&#8217;18 English <tex-math>\\to</tex-math> Chinese translation tasks, order does not have a substantial impact on output quality. Moreover, for English <tex-math>\\to</tex-math> German, we even discover that unintuitive orderings such as alphabetical and shortest-first can match the performance of a standard Transformer, suggesting that traditional left-to-right generation may not be necessary to achieve high performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.469.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--469 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.469 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939385 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.469" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.469/>Few-Shot Complex Knowledge Base Question Answering via Meta Reinforcement Learning</a></strong><br><a href=/people/y/yuncheng-hua/>Yuncheng Hua</a>
|
<a href=/people/y/yuan-fang-li/>Yuan-Fang Li</a>
|
<a href=/people/g/gholamreza-haffari/>Gholamreza Haffari</a>
|
<a href=/people/g/guilin-qi/>Guilin Qi</a>
|
<a href=/people/t/tongtong-wu/>Tongtong Wu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--469><div class="card-body p-3 small">Complex question-answering (CQA) involves answering complex <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural-language questions</a> on a <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge base (KB)</a>. However, the conventional neural program induction (NPI) approach exhibits uneven performance when the questions have different types, harboring inherently different characteristics, e.g., difficulty level. This paper proposes a meta-reinforcement learning approach to program induction in CQA to tackle the potential distributional bias in questions. Our method quickly and effectively adapts the meta-learned programmer to new questions based on the most similar questions retrieved from the training data. The meta-learned policy is then used to learn a good programming policy, utilizing the trial trajectories and their rewards for similar questions in the support set. Our method achieves state-of-the-art performance on the CQA dataset (Saha et al., 2018) while using only five trial trajectories for the top-5 retrieved questions in each support set, and meta-training on tasks constructed from only 1 % of the training set. We have released our code at https://github.com/DevinJake/MRL-CQA.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.477.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--477 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.477 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939085 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.477/>LAReQA : Language-Agnostic Answer Retrieval from a Multilingual Pool<span class=acl-fixed-case>LAR</span>e<span class=acl-fixed-case>QA</span>: Language-Agnostic Answer Retrieval from a Multilingual Pool</a></strong><br><a href=/people/u/uma-roy/>Uma Roy</a>
|
<a href=/people/n/noah-constant/>Noah Constant</a>
|
<a href=/people/r/rami-al-rfou/>Rami Al-Rfou</a>
|
<a href=/people/a/aditya-barua/>Aditya Barua</a>
|
<a href=/people/a/aaron-phillips/>Aaron Phillips</a>
|
<a href=/people/y/yinfei-yang/>Yinfei Yang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--477><div class="card-body p-3 small">We present LAReQA, a challenging new benchmark for language-agnostic answer retrieval from a multilingual candidate pool. Unlike previous cross-lingual tasks, LAReQA tests for strong cross-lingual alignment, requiring semantically related cross-language pairs to be closer in representation space than unrelated same-language pairs. This level of <a href=https://en.wikipedia.org/wiki/Sequence_alignment>alignment</a> is important for the practical task of <a href=https://en.wikipedia.org/wiki/Cross-lingual_information_retrieval>cross-lingual information retrieval</a>. Building on multilingual BERT (mBERT), we study different strategies for achieving strong alignment. We find that augmenting training data via <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> is effective, and improves significantly over using mBERT out-of-the-box. Interestingly, <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performance on zero-shot variants of our task that only target weak alignment is not predictive of performance on LAReQA. This finding underscores our claim that language-agnostic retrieval is a substantively new kind of cross-lingual evaluation, and suggests that measuring both weak and strong alignment will be important for improving cross-lingual systems going forward. We release our dataset and evaluation code at.<i>cross</i>-language pairs to be closer in representation space than unrelated <i>same</i>-language pairs. This level of alignment is important for the practical task of cross-lingual information retrieval. Building on multilingual BERT (mBERT), we study different strategies for achieving strong alignment. We find that augmenting training data via machine translation is effective, and improves significantly over using mBERT out-of-the-box. Interestingly, model performance on zero-shot variants of our task that only target &#8220;weak&#8221; alignment is not predictive of performance on LAReQA. This finding underscores our claim that language-agnostic retrieval is a substantively new kind of cross-lingual evaluation, and suggests that measuring both weak and strong alignment will be important for improving cross-lingual systems going forward. We release our dataset and evaluation code at <url>https://github.com/google-research-datasets/lareqa</url>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.478.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--478 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.478 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939129 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.478" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.478/>OCR Post Correction for Endangered Language Texts<span class=acl-fixed-case>OCR</span> <span class=acl-fixed-case>P</span>ost <span class=acl-fixed-case>C</span>orrection for <span class=acl-fixed-case>E</span>ndangered <span class=acl-fixed-case>L</span>anguage <span class=acl-fixed-case>T</span>exts</a></strong><br><a href=/people/s/shruti-rijhwani/>Shruti Rijhwani</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--478><div class="card-body p-3 small">There is little to no data available to build <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language processing models</a> for most <a href=https://en.wikipedia.org/wiki/Endangered_language>endangered languages</a>. However, <a href=https://en.wikipedia.org/wiki/Text-based_user_interface>textual data</a> in these languages often exists in formats that are not machine-readable, such as <a href=https://en.wikipedia.org/wiki/Paperback>paper books</a> and <a href=https://en.wikipedia.org/wiki/Image_scanner>scanned images</a>. In this work, we address the task of extracting text from these <a href=https://en.wikipedia.org/wiki/Resource_(computing)>resources</a>. We create a benchmark dataset of transcriptions for scanned books in three critically endangered languages and present a systematic analysis of how general-purpose OCR tools are not robust to the data-scarce setting of endangered languages. We develop an OCR post-correction method tailored to ease training in this data-scarce setting, reducing the recognition error rate by 34 % on average across the three languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.479.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--479 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.479 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939158 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.479/>X-FACTR : Multilingual Factual Knowledge Retrieval from Pretrained Language Models<span class=acl-fixed-case>X</span>-<span class=acl-fixed-case>FACTR</span>: Multilingual Factual Knowledge Retrieval from Pretrained Language Models</a></strong><br><a href=/people/z/zhengbao-jiang/>Zhengbao Jiang</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a>
|
<a href=/people/j/jun-araki/>Jun Araki</a>
|
<a href=/people/h/haibo-ding/>Haibo Ding</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--479><div class="card-body p-3 small">Language models (LMs) have proven surprisingly successful at capturing factual knowledge by completing cloze-style fill-in-the-blank questions such as Punta Cana is located in _. However, while knowledge is both written and queried in many languages, studies on LMs&#8217; factual representation ability have almost invariably been performed on <a href=https://en.wikipedia.org/wiki/English_language>English</a>. To assess factual knowledge retrieval in LMs in different languages, we create a multilingual benchmark of cloze-style probes for typologically diverse languages. To properly handle language variations, we expand probing methods from single- to multi-word entities, and develop several decoding algorithms to generate multi-token predictions. Extensive experimental results provide insights about how well (or poorly) current state-of-the-art LMs perform at this task in languages with more or fewer available resources. We further propose a code-switching-based method to improve the ability of multilingual LMs to access knowledge, and verify its effectiveness on several benchmark languages. Benchmark data and code have be released at https://x-factr.github.io.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.487.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--487 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.487 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.487.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939138 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.487" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.487/>Supertagging Combinatory Categorial Grammar with Attentive Graph Convolutional Networks<span class=acl-fixed-case>C</span>ombinatory <span class=acl-fixed-case>C</span>ategorial <span class=acl-fixed-case>G</span>rammar with Attentive Graph Convolutional Networks</a></strong><br><a href=/people/y/yuanhe-tian/>Yuanhe Tian</a>
|
<a href=/people/y/yan-song/>Yan Song</a>
|
<a href=/people/f/fei-xia/>Fei Xia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--487><div class="card-body p-3 small">Supertagging is conventionally regarded as an important task for combinatory categorial grammar (CCG) parsing, where effective modeling of contextual information is highly important to this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. However, existing studies have made limited efforts to leverage contextual features except for applying powerful encoders (e.g., bi-LSTM). In this paper, we propose attentive graph convolutional networks to enhance neural CCG supertagging through a novel solution of leveraging contextual information. Specifically, we build the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a> from chunks (n-grams) extracted from a lexicon and apply <a href=https://en.wikipedia.org/wiki/Attention>attention</a> over the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a>, so that different word pairs from the contexts within and across chunks are weighted in the model and facilitate the supertagging accordingly. The experiments performed on the CCGbank demonstrate that our approach outperforms all previous studies in terms of both supertagging and <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a>. Further analyses illustrate the effectiveness of each component in our approach to discriminatively learn from word pairs to enhance CCG supertagging.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.490.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--490 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.490 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938765 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.490/>Adversarial Semantic Decoupling for Recognizing Open-Vocabulary Slots</a></strong><br><a href=/people/y/yuanmeng-yan/>Yuanmeng Yan</a>
|
<a href=/people/k/keqing-he/>Keqing He</a>
|
<a href=/people/h/hong-xu/>Hong Xu</a>
|
<a href=/people/s/sihong-liu/>Sihong Liu</a>
|
<a href=/people/f/fanyu-meng/>Fanyu Meng</a>
|
<a href=/people/m/min-hu/>Min Hu</a>
|
<a href=/people/w/weiran-xu/>Weiran Xu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--490><div class="card-body p-3 small">Open-vocabulary slots, such as file name, album name, or schedule title, significantly degrade the performance of neural-based slot filling models since these slots can take on values from a virtually unlimited set and have no semantic restriction nor a length limit. In this paper, we propose a robust adversarial model-agnostic slot filling method that explicitly decouples local semantics inherent in open-vocabulary slot words from the global context. We aim to depart entangled contextual semantics and focus more on the holistic context at the level of the whole sentence. Experiments on two public datasets show that our method consistently outperforms other methods with a statistically significant margin on all the open-vocabulary slots without deteriorating the performance of normal slots.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.492.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--492 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.492 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.492.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938925 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.492" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.492/>Structure Aware Negative Sampling in <a href=https://en.wikipedia.org/wiki/Knowledge_graph>Knowledge Graphs</a></a></strong><br><a href=/people/k/kian-ahrabian/>Kian Ahrabian</a>
|
<a href=/people/a/aarash-feizi/>Aarash Feizi</a>
|
<a href=/people/y/yasmin-salehi/>Yasmin Salehi</a>
|
<a href=/people/w/william-l-hamilton/>William L. Hamilton</a>
|
<a href=/people/a/avishek-joey-bose/>Avishek Joey Bose</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--492><div class="card-body p-3 small">Learning low-dimensional representations for entities and relations in <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graphs</a> using contrastive estimation represents a scalable and effective method for inferring connectivity patterns. A crucial aspect of contrastive learning approaches is the choice of corruption distribution that generates hard negative samples, which force the <a href=https://en.wikipedia.org/wiki/Embedding>embedding model</a> to learn discriminative representations and find critical characteristics of observed data. While earlier <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> either employ too simple <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>corruption distributions</a>, i.e. uniform, yielding easy uninformative negatives or sophisticated adversarial distributions with challenging optimization schemes, they do not explicitly incorporate known graph structure resulting in suboptimal negatives. In this paper, we propose Structure Aware Negative Sampling (SANS), an inexpensive negative sampling strategy that utilizes the rich graph structure by selecting negative samples from a node&#8217;s k-hop neighborhood. Empirically, we demonstrate that SANS finds semantically meaningful negatives and is competitive with SOTA approaches while requires no additional parameters nor difficult adversarial optimization.<tex-math>k</tex-math>-hop neighborhood. Empirically, we demonstrate that SANS finds semantically meaningful negatives and is competitive with SOTA approaches while requires no additional parameters nor difficult adversarial optimization.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.493.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--493 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.493 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938671 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.493" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.493/>Neural Mask Generator : Learning to Generate Adaptive Word Maskings for Language Model Adaptation</a></strong><br><a href=/people/m/minki-kang/>Minki Kang</a>
|
<a href=/people/m/moonsu-han/>Moonsu Han</a>
|
<a href=/people/s/sung-ju-hwang/>Sung Ju Hwang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--493><div class="card-body p-3 small">We propose a method to automatically generate a domain- and task-adaptive maskings of the given text for self-supervised pre-training, such that we can effectively adapt the <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> to a particular target task (e.g. question answering). Specifically, we present a novel reinforcement learning-based framework which learns the masking policy, such that using the generated masks for further pre-training of the target <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> helps improve task performance on unseen texts. We use off-policy actor-critic with entropy regularization and experience replay for <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a>, and propose a Transformer-based policy network that can consider the relative importance of words in a given text. We validate our Neural Mask Generator (NMG) on several question answering and text classification datasets using BERT and DistilBERT as the language models, on which it outperforms rule-based masking strategies, by automatically learning optimal adaptive maskings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.498.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--498 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.498 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938695 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.498" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.498/>BAE : BERT-based Adversarial Examples for Text Classification<span class=acl-fixed-case>BAE</span>: <span class=acl-fixed-case>BERT</span>-based Adversarial Examples for Text Classification</a></strong><br><a href=/people/s/siddhant-garg/>Siddhant Garg</a>
|
<a href=/people/g/goutham-ramakrishnan/>Goutham Ramakrishnan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--498><div class="card-body p-3 small">Modern text classification models are susceptible to adversarial examples, perturbed versions of the original text indiscernible by humans which get misclassified by the model. Recent works in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> use rule-based synonym replacement strategies to generate adversarial examples. These strategies can lead to out-of-context and unnaturally complex token replacements, which are easily identifiable by humans. We present BAE, a black box attack for generating adversarial examples using contextual perturbations from a BERT masked language model. BAE replaces and inserts tokens in the original text by masking a portion of the text and leveraging the BERT-MLM to generate alternatives for the masked tokens. Through automatic and human evaluations, we show that BAE performs a stronger attack, in addition to generating adversarial examples with improved <a href=https://en.wikipedia.org/wiki/Grammaticality>grammaticality</a> and semantic coherence as compared to prior work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.499.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--499 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.499 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.499.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938706 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.499/>Adversarial Self-Supervised Data-Free Distillation for Text Classification<span class=acl-fixed-case>A</span>dversarial <span class=acl-fixed-case>S</span>elf-<span class=acl-fixed-case>S</span>upervised <span class=acl-fixed-case>D</span>ata-<span class=acl-fixed-case>F</span>ree <span class=acl-fixed-case>D</span>istillation for <span class=acl-fixed-case>T</span>ext <span class=acl-fixed-case>C</span>lassification</a></strong><br><a href=/people/x/xinyin-ma/>Xinyin Ma</a>
|
<a href=/people/y/yongliang-shen/>Yongliang Shen</a>
|
<a href=/people/g/gongfan-fang/>Gongfan Fang</a>
|
<a href=/people/c/chen-chen/>Chen Chen</a>
|
<a href=/people/c/chenghao-jia/>Chenghao Jia</a>
|
<a href=/people/w/weiming-lu/>Weiming Lu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--499><div class="card-body p-3 small">Large pre-trained transformer-based language models have achieved impressive results on a wide range of NLP tasks. In the past few years, Knowledge Distillation(KD) has become a popular paradigm to compress a computationally expensive <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to a resource-efficient lightweight model. However, most KD algorithms, especially in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, rely on the accessibility of the original training dataset, which may be unavailable due to privacy issues. To tackle this problem, we propose a novel two-stage data-free distillation method, named Adversarial self-Supervised Data-Free Distillation (AS-DFD), which is designed for compressing large-scale transformer-based models (e.g., BERT). To avoid text generation in discrete space, we introduce a Plug & Play Embedding Guessing method to craft pseudo embeddings from the teacher&#8217;s hidden knowledge. Meanwhile, with a self-supervised module to quantify the student&#8217;s ability, we adapt the difficulty of pseudo embeddings in an adversarial training manner. To the best of our knowledge, our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> is the first data-free distillation framework designed for NLP tasks. We verify the effectiveness of our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> on several text classification datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.501.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--501 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.501 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938724 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.501/>The Thieves on Sesame Street are Polyglots-Extracting Multilingual Models from Monolingual APIs<span class=acl-fixed-case>API</span>s</a></strong><br><a href=/people/n/nitish-shirish-keskar/>Nitish Shirish Keskar</a>
|
<a href=/people/b/bryan-mccann/>Bryan McCann</a>
|
<a href=/people/c/caiming-xiong/>Caiming Xiong</a>
|
<a href=/people/r/richard-socher/>Richard Socher</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--501><div class="card-body p-3 small">Pre-training in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> makes it easier for an adversary with only query access to a victim model to reconstruct a local copy of the victim by training with gibberish input data paired with the victim&#8217;s labels for that data. We discover that this extraction process extends to local copies initialized from a pre-trained, multilingual model while the victim remains monolingual. The extracted <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> learns the task from the monolingual victim, but it generalizes far better than the victim to several other languages. This is done without ever showing the multilingual, extracted model a well-formed input in any of the languages for the target <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. We also demonstrate that a few real examples can greatly improve performance, and we analyze how these results shed light on how such extraction methods succeed.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.502.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--502 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.502 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939044 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.502" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.502/>When Hearst Is not Enough : Improving Hypernymy Detection from Corpus with Distributional Models</a></strong><br><a href=/people/c/changlong-yu/>Changlong Yu</a>
|
<a href=/people/j/jialong-han/>Jialong Han</a>
|
<a href=/people/p/peifeng-wang/>Peifeng Wang</a>
|
<a href=/people/y/yangqiu-song/>Yangqiu Song</a>
|
<a href=/people/h/hongming-zhang/>Hongming Zhang</a>
|
<a href=/people/w/wilfred-ng/>Wilfred Ng</a>
|
<a href=/people/s/shuming-shi/>Shuming Shi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--502><div class="card-body p-3 small">We address hypernymy detection, i.e., whether an is-a relationship exists between words (x, y), with the help of large textual corpora. Most conventional approaches to this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> have been categorized to be either pattern-based or distributional. Recent studies suggest that pattern-based ones are superior, if large-scale Hearst pairs are extracted and fed, with the sparsity of unseen (x, y) pairs relieved. However, they become invalid in some specific sparsity cases, where x or y is not involved in any pattern. For the first time, this paper quantifies the non-negligible existence of those specific cases. We also demonstrate that <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>distributional methods</a> are ideal to make up for pattern-based ones in such cases. We devise a complementary framework, under which a pattern-based and a distributional model collaborate seamlessly in cases which they each prefer. On several <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark datasets</a>, our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> demonstrates improvements that are both competitive and explainable.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.510.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--510 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.510 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939371 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.510" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.510/>Summarizing Text on Any Aspects : A Knowledge-Informed Weakly-Supervised Approach</a></strong><br><a href=/people/b/bowen-tan/>Bowen Tan</a>
|
<a href=/people/l/lianhui-qin/>Lianhui Qin</a>
|
<a href=/people/e/eric-xing/>Eric Xing</a>
|
<a href=/people/z/zhiting-hu/>Zhiting Hu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--510><div class="card-body p-3 small">Given a document and a target aspect (e.g., a topic of interest), aspect-based abstractive summarization attempts to generate a summary with respect to the aspect. Previous studies usually assume a small pre-defined set of aspects and fall short of summarizing on other diverse topics. In this work, we study summarizing on arbitrary aspects relevant to the document, which significantly expands the application of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> in practice. Due to the lack of supervision data, we develop a new weak supervision construction method and an aspect modeling scheme, both of which integrate rich external knowledge sources such as <a href=https://en.wikipedia.org/wiki/ConceptNet>ConceptNet</a> and <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>. Experiments show our approach achieves performance boosts on summarizing both real and synthetic documents given pre-defined or arbitrary aspects.<i>arbitrary</i> aspects relevant to the document, which significantly expands the application of the task in practice. Due to the lack of supervision data, we develop a new weak supervision construction method and an aspect modeling scheme, both of which integrate rich external knowledge sources such as ConceptNet and Wikipedia. Experiments show our approach achieves performance boosts on summarizing both real and synthetic documents given pre-defined or arbitrary aspects.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.514.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--514 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.514 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938977 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.514" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.514/>Coarse-to-Fine Pre-training for Named Entity Recognition<span class=acl-fixed-case>C</span>oarse-to-<span class=acl-fixed-case>F</span>ine <span class=acl-fixed-case>P</span>re-training for <span class=acl-fixed-case>N</span>amed <span class=acl-fixed-case>E</span>ntity <span class=acl-fixed-case>R</span>ecognition</a></strong><br><a href=/people/x/xue-mengge/>Xue Mengge</a>
|
<a href=/people/b/bowen-yu/>Bowen Yu</a>
|
<a href=/people/z/zhenyu-zhang/>Zhenyu Zhang</a>
|
<a href=/people/t/tingwen-liu/>Tingwen Liu</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a>
|
<a href=/people/b/bin-wang/>Bin Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--514><div class="card-body p-3 small">More recently, <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>Named Entity Recognition</a> hasachieved great advances aided by pre-trainingapproaches such as <a href=https://en.wikipedia.org/wiki/BERT>BERT</a>. However, currentpre-training techniques focus on building lan-guage modeling objectives to learn a gen-eral representation, ignoring the named entity-related knowledge. To this end, we proposea NER-specific pre-training framework to in-ject coarse-to-fine automatically mined entityknowledge into pre-trained models. Specifi-cally, we first warm-up the model via an en-tity span identification task by training it withWikipedia anchors, which can be deemed asgeneral-typed entities. Then we leverage thegazetteer-based distant supervision strategy totrain the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> extract coarse-grained typedentities. Finally, we devise a self-supervisedauxiliary task to mine the fine-grained namedentity knowledge via clustering. Empiricalstudies on three public NER datasets demon-strate that our framework achieves significantimprovements against several pre-trained base-lines, establishing the new state-of-the-art per-formance on three benchmarks. Besides, weshow that our <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> gains promising re-sults without using human-labeled trainingdata, demonstrating its effectiveness in label-few and low-resource scenarios.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.515.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--515 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.515 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938987 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.515" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.515/>Exploring and Evaluating Attributes, Values, and Structures for Entity Alignment</a></strong><br><a href=/people/z/zhiyuan-liu/>Zhiyuan Liu</a>
|
<a href=/people/y/yixin-cao/>Yixin Cao</a>
|
<a href=/people/l/liangming-pan/>Liangming Pan</a>
|
<a href=/people/j/juanzi-li/>Juanzi Li</a>
|
<a href=/people/z/zhiyuan-liu/>Zhiyuan Liu</a>
|
<a href=/people/t/tat-seng-chua/>Tat-Seng Chua</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--515><div class="card-body p-3 small">Entity alignment (EA) aims at building a unified Knowledge Graph (KG) of rich content by linking the equivalent entities from various KGs. GNN-based EA methods present promising performance by modeling the KG structure defined by relation triples. However, attribute triples can also provide crucial alignment signal but have not been well explored yet. In this paper, we propose to utilize an attributed value encoder and partition the KG into subgraphs to model the various types of attribute triples efficiently. Besides, the performances of current EA methods are overestimated because of the name-bias of existing EA datasets. To make an objective evaluation, we propose a hard experimental setting where we select equivalent entity pairs with very different names as the test set. Under both the regular and hard settings, our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> achieves significant improvements (5.10 % on average Hits@1 in DBP15k) over 12 baselines in cross-lingual and monolingual datasets. Ablation studies on different subgraphs and a case study about attribute types further demonstrate the effectiveness of our method. Source code and data can be found at.<url>https://github.com/thunlp/explore-and-evaluate</url>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.516.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--516 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.516 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939200 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.516" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.516/>Simple and Effective Few-Shot Named Entity Recognition with Structured Nearest Neighbor Learning</a></strong><br><a href=/people/y/yi-yang/>Yi Yang</a>
|
<a href=/people/a/arzoo-katiyar/>Arzoo Katiyar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--516><div class="card-body p-3 small">We present a simple few-shot named entity recognition (NER) system based on nearest neighbor learning and structured inference. Our system uses a supervised NER model trained on the source domain, as a <a href=https://en.wikipedia.org/wiki/Feature_extraction>feature extractor</a>. Across several test domains, we show that a <a href=https://en.wikipedia.org/wiki/Nearest_neighbor_search>nearest neighbor classifier</a> in this <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature-space</a> is far more effective than the standard meta-learning approaches. We further propose a cheap but effective method to capture the label dependencies between entity tags without expensive CRF training. We show that our method of combining structured decoding with nearest neighbor learning achieves state-of-the-art performance on standard few-shot NER evaluation tasks, improving F1 scores by 6 % to 16 % absolute points over prior meta-learning based systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.517.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--517 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.517 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938677 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.517" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.517/>Learning Structured Representations of Entity Names using Active Learning and Weak Supervision<span class=acl-fixed-case>A</span>ctive <span class=acl-fixed-case>L</span>earning and Weak Supervision</a></strong><br><a href=/people/k/kun-qian/>Kun Qian</a>
|
<a href=/people/p/poornima-chozhiyath-raman/>Poornima Chozhiyath Raman</a>
|
<a href=/people/y/yunyao-li/>Yunyao Li</a>
|
<a href=/people/l/lucian-popa/>Lucian Popa</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--517><div class="card-body p-3 small">Structured representations of entity names are useful for many entity-related tasks such as <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity normalization</a> and variant generation. Learning the implicit structured representations of entity names without context and external knowledge is particularly challenging. In this paper, we present a novel learning framework that combines <a href=https://en.wikipedia.org/wiki/Active_learning>active learning</a> and weak supervision to solve this problem. Our experimental evaluation show that this <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> enables the learning of high-quality models from merely a dozen or so labeled examples.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.518.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--518 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.518 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939232 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.518/>Entity Enhanced BERT Pre-training for Chinese NER<span class=acl-fixed-case>BERT</span> Pre-training for <span class=acl-fixed-case>C</span>hinese <span class=acl-fixed-case>NER</span></a></strong><br><a href=/people/c/chen-jia/>Chen Jia</a>
|
<a href=/people/y/yuefeng-shi/>Yuefeng Shi</a>
|
<a href=/people/q/qinrong-yang/>Qinrong Yang</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--518><div class="card-body p-3 small">Character-level BERT pre-trained in <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a> suffers a limitation of lacking lexicon information, which shows effectiveness for <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese NER</a>. To integrate the <a href=https://en.wikipedia.org/wiki/Lexicon>lexicon</a> into pre-trained LMs for Chinese NER, we investigate a semi-supervised entity enhanced BERT pre-training method. In particular, we first extract an entity lexicon from the relevant raw text using a new-word discovery method. We then integrate the entity information into BERT using Char-Entity-Transformer, which augments the self-attention using a combination of character and entity representations. In addition, an entity classification task helps inject the entity information into <a href=https://en.wikipedia.org/wiki/Parameter>model parameters</a> in pre-training. The pre-trained models are used for NER fine-tuning. Experiments on a news dataset and two datasets annotated by ourselves for NER in long-text show that our method is highly effective and achieves the best results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.519.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--519 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.519 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939238 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.519" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.519/>Scalable Zero-shot Entity Linking with Dense Entity Retrieval</a></strong><br><a href=/people/l/ledell-wu/>Ledell Wu</a>
|
<a href=/people/f/fabio-petroni/>Fabio Petroni</a>
|
<a href=/people/m/martin-josifoski/>Martin Josifoski</a>
|
<a href=/people/s/sebastian-riedel/>Sebastian Riedel</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--519><div class="card-body p-3 small">This paper introduces a conceptually simple, scalable, and highly effective BERT-based entity linking model, along with an extensive evaluation of its accuracy-speed trade-off. We present a two-stage zero-shot linking algorithm, where each entity is defined only by a short textual description. The first stage does retrieval in a dense space defined by a bi-encoder that independently embeds the <a href=https://en.wikipedia.org/wiki/Context_(language_use)>mention context</a> and the <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity descriptions</a>. Each candidate is then re-ranked with a cross-encoder, that concatenates the mention and entity text. Experiments demonstrate that this <a href=https://en.wikipedia.org/wiki/Software_development_process>approach</a> is state of the art on recent zero-shot benchmarks (6 point absolute gains) and also on more established non-zero-shot evaluations (e.g. TACKBP-2010), despite its relative simplicity (e.g. no explicit entity embeddings or manually engineered mention tables). We also show that bi-encoder linking is very fast with <a href=https://en.wikipedia.org/wiki/Nearest_neighbor_search>nearest neighbor search</a> (e.g. linking with 5.9 million candidates in 2 milliseconds), and that much of the accuracy gain from the more expensive cross-encoder can be transferred to the bi-encoder via knowledge distillation. Our code and models are available at https://github.com/facebookresearch/BLINK.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.520.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--520 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.520 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939254 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.520/>A Dataset for Tracking Entities in Open Domain Procedural Text</a></strong><br><a href=/people/n/niket-tandon/>Niket Tandon</a>
|
<a href=/people/k/keisuke-sakaguchi/>Keisuke Sakaguchi</a>
|
<a href=/people/b/bhavana-dalvi/>Bhavana Dalvi</a>
|
<a href=/people/d/dheeraj-rajagopal/>Dheeraj Rajagopal</a>
|
<a href=/people/p/peter-clark/>Peter Clark</a>
|
<a href=/people/m/michal-guerquin/>Michal Guerquin</a>
|
<a href=/people/k/kyle-richardson/>Kyle Richardson</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--520><div class="card-body p-3 small">We present the first <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for tracking state changes in procedural text from arbitrary domains by using an unrestricted (open) vocabulary. For example, in a text describing fog removal using <a href=https://en.wikipedia.org/wiki/Potato>potatoes</a>, a car window may transition between being foggy, sticky, opaque, and clear. Previous formulations of this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> provide the text and entities involved, and ask how those entities change for just a small, pre-defined set of attributes (e.g., location), limiting their fidelity. Our solution is a new task formulation where given just a procedural text as input, the task is to generate a set of state change tuples (entity, attribute, before-state, after-state) for each step, where the entity, attribute, and state values must be predicted from an open vocabulary. Using <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing</a>, we create OPENPI, a high-quality (91.5 % coverage as judged by humans and completely vetted), and large-scale dataset comprising 29,928 state changes over 4,050 sentences from 810 procedural real-world paragraphs from <a href=https://en.wikipedia.org/wiki/WikiHow>WikiHow.com</a>. A current state-of-the-art generation model on this <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a> achieves 16.1 % <a href=https://en.wikipedia.org/wiki/F-number>F1</a> based on BLEU metric, leaving enough room for novel model architectures.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.521.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--521 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.521 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939339 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.521/>Design Challenges in Low-resource Cross-lingual Entity Linking</a></strong><br><a href=/people/x/xingyu-fu/>Xingyu Fu</a>
|
<a href=/people/w/weijia-shi/>Weijia Shi</a>
|
<a href=/people/x/xiaodong-yu/>Xiaodong Yu</a>
|
<a href=/people/z/zian-zhao/>Zian Zhao</a>
|
<a href=/people/d/dan-roth/>Dan Roth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--521><div class="card-body p-3 small">Cross-lingual Entity Linking (XEL), the problem of grounding mentions of entities in a foreign language text into an English knowledge base such as <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>, has seen a lot of research in recent years, with a range of promising techniques. However, current techniques do not rise to the challenges introduced by text in low-resource languages (LRL) and, surprisingly, fail to generalize to text not taken from <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>, on which they are usually trained. This paper provides a thorough analysis of low-resource XEL techniques, focusing on the key step of identifying candidate English Wikipedia titles that correspond to a given foreign language mention. Our analysis indicates that current methods are limited by their reliance on Wikipedia&#8217;s interlanguage links and thus suffer when the foreign language&#8217;s Wikipedia is small. We conclude that the LRL setting requires the use of outside-Wikipedia cross-lingual resources and present a simple yet effective zero-shot XEL system, QuEL, that utilizes search engines query logs. With experiments on 25 languages, QuEL shows an average increase of 25 % in gold candidate recall and of 13 % in end-to-end linking accuracy over state-of-the-art baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.523.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--523 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.523 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938803 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.523" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.523/>LUKE : Deep Contextualized Entity Representations with Entity-aware Self-attention<span class=acl-fixed-case>LUKE</span>: Deep Contextualized Entity Representations with Entity-aware Self-attention</a></strong><br><a href=/people/i/ikuya-yamada/>Ikuya Yamada</a>
|
<a href=/people/a/akari-asai/>Akari Asai</a>
|
<a href=/people/h/hiroyuki-shindo/>Hiroyuki Shindo</a>
|
<a href=/people/h/hideaki-takeda/>Hideaki Takeda</a>
|
<a href=/people/y/yuji-matsumoto/>Yuji Matsumoto</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--523><div class="card-body p-3 small">Entity representations are useful in <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language tasks</a> involving entities. In this paper, we propose new pretrained contextualized representations of words and entities based on the bidirectional transformer. The proposed <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> treats words and entities in a given text as independent tokens, and outputs contextualized representations of them. Our <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> is trained using a new pretraining task based on the masked language model of BERT. The task involves predicting randomly masked words and entities in a large entity-annotated corpus retrieved from <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>. We also propose an entity-aware self-attention mechanism that is an extension of the self-attention mechanism of the transformer, and considers the types of tokens (words or entities) when computing attention scores. The proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves impressive empirical performance on a wide range of entity-related tasks. In particular, it obtains state-of-the-art results on five well-known datasets : Open Entity (entity typing), TACRED (relation classification), <a href=https://en.wikipedia.org/wiki/Named_entity_recognition>CoNLL-2003 (named entity recognition)</a>, ReCoRD (cloze-style question answering), and SQuAD 1.1 (extractive question answering). Our source code and pretrained representations are available at https://github.com/studio-ousia/luke.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.527.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--527 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.527 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939152 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.527/>Template Guided Text Generation for Task-Oriented Dialogue</a></strong><br><a href=/people/m/mihir-kale/>Mihir Kale</a>
|
<a href=/people/a/abhinav-rastogi/>Abhinav Rastogi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--527><div class="card-body p-3 small">Virtual assistants such as <a href=https://en.wikipedia.org/wiki/Google_Assistant>Google Assistant</a>, <a href=https://en.wikipedia.org/wiki/Amazon_Alexa>Amazon Alexa</a>, and <a href=https://en.wikipedia.org/wiki/Siri>Apple Siri</a> enable users to interact with a large number of services and APIs on the web using <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language</a>. In this work, we investigate two methods for Natural Language Generation (NLG) using a single domain-independent model across a large number of <a href=https://en.wikipedia.org/wiki/Application_programming_interface>APIs</a>. First, we propose a schema-guided approach which conditions the generation on a schema describing the <a href=https://en.wikipedia.org/wiki/Application_programming_interface>API</a> in <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>. Our second method investigates the use of a small number of <a href=https://en.wikipedia.org/wiki/Template_processor>templates</a>, growing linearly in number of slots, to convey the <a href=https://en.wikipedia.org/wiki/Semantics_(computer_science)>semantics</a> of the <a href=https://en.wikipedia.org/wiki/Application_programming_interface>API</a>. To generate utterances for an arbitrary slot combination, a few simple templates are first concatenated to give a semantically correct, but possibly incoherent and ungrammatical utterance. A pre-trained language model is subsequently employed to rewrite it into coherent, natural sounding text. Through automatic metrics and human evaluation, we show that our method improves over strong baselines, is robust to out-of-domain inputs and shows improved sample efficiency.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.528.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--528 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.528 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939212 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.528" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.528/>MOCHA : A Dataset for Training and Evaluating Generative Reading Comprehension Metrics<span class=acl-fixed-case>MOCHA</span>: A Dataset for Training and Evaluating Generative Reading Comprehension Metrics</a></strong><br><a href=/people/a/anthony-chen/>Anthony Chen</a>
|
<a href=/people/g/gabriel-stanovsky/>Gabriel Stanovsky</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a>
|
<a href=/people/m/matt-gardner/>Matt Gardner</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--528><div class="card-body p-3 small">Posing <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a> as a generation problem provides a great deal of flexibility, allowing for open-ended questions with few restrictions on possible answers. However, progress is impeded by existing generation metrics, which rely on token overlap and are agnostic to the nuances of <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a>. To address this, we introduce a <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmark</a> for training and evaluating generative reading comprehension metrics : MOdeling Correctness with Human Annotations. MOCHA contains 40 K human judgement scores on model outputs from 6 diverse question answering datasets and an additional set of minimal pairs for evaluation. Using MOCHA, we train a Learned Evaluation metric for Reading Comprehension, LERC, to mimic human judgement scores. LERC outperforms baseline metrics by 10 to 36 absolute Pearson points on held-out annotations. When we evaluate robustness on minimal pairs, LERC achieves 80 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, outperforming baselines by 14 to 26 absolute percentage points while leaving significant room for improvement. MOCHA presents a challenging problem for developing accurate and robust generative reading comprehension metrics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.529.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--529 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.529 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.529.OptionalSupplementaryMaterial.pdf data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939248 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.529/>Plan ahead : Self-Supervised Text Planning for Paragraph Completion Task</a></strong><br><a href=/people/d/dongyeop-kang/>Dongyeop Kang</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--529><div class="card-body p-3 small">Despite the recent success of contextualized language models on various NLP tasks, <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> itself can not capture textual coherence of a long, multi-sentence document (e.g., a paragraph). Humans often make structural decisions on what and how to say about before making utterances. Guiding surface realization with such high-level decisions and structuring text in a coherent way is essentially called a <a href=https://en.wikipedia.org/wiki/Planning>planning process</a>. Where can the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> learn such high-level coherence? A paragraph itself contains various forms of inductive coherence signals called self-supervision in this work, such as sentence orders, topical keywords, rhetorical structures, and so on. Motivated by that, this work proposes a new paragraph completion task PARCOM ; predicting masked sentences in a paragraph. However, the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> suffers from predicting and selecting appropriate topical content with respect to the given context. To address that, we propose a self-supervised text planner SSPlanner that predicts what to say first (content prediction), then guides the pretrained language model (surface realization) using the predicted content. SSPlanner outperforms the baseline generation models on the paragraph completion task in both automatic and human evaluation. We also find that a combination of noun and verb types of keywords is the most effective for content selection. As more number of <a href=https://en.wikipedia.org/wiki/Index_term>content keywords</a> are provided, overall generation quality also increases.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.531.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--531 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.531 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938660 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.531" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.531/>Towards Persona-Based Empathetic Conversational Models</a></strong><br><a href=/people/p/peixiang-zhong/>Peixiang Zhong</a>
|
<a href=/people/c/chen-zhang/>Chen Zhang</a>
|
<a href=/people/h/hao-wang/>Hao Wang</a>
|
<a href=/people/y/yong-liu/>Yong Liu</a>
|
<a href=/people/c/chunyan-miao/>Chunyan Miao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--531><div class="card-body p-3 small">Empathetic conversational models have been shown to improve user satisfaction and task outcomes in numerous domains. In <a href=https://en.wikipedia.org/wiki/Psychology>Psychology</a>, <a href=https://en.wikipedia.org/wiki/Persona>persona</a> has been shown to be highly correlated to <a href=https://en.wikipedia.org/wiki/Personality>personality</a>, which in turn influences <a href=https://en.wikipedia.org/wiki/Empathy>empathy</a>. In addition, our empirical analysis also suggests that <a href=https://en.wikipedia.org/wiki/Persona>persona</a> plays an important role in empathetic conversations. To this end, we propose a new task towards persona-based empathetic conversations and present the first empirical study on the impact of <a href=https://en.wikipedia.org/wiki/Persona>persona</a> on empathetic responding. Specifically, we first present a novel large-scale multi-domain dataset for persona-based empathetic conversations. We then propose CoBERT, an efficient BERT-based response selection model that obtains the state-of-the-art performance on our dataset. Finally, we conduct extensive experiments to investigate the impact of <a href=https://en.wikipedia.org/wiki/Persona>persona</a> on empathetic responding. Notably, our results show that <a href=https://en.wikipedia.org/wiki/Persona>persona</a> improves empathetic responding more when CoBERT is trained on empathetic conversations than non-empathetic ones, establishing an empirical link between <a href=https://en.wikipedia.org/wiki/Persona>persona</a> and <a href=https://en.wikipedia.org/wiki/Empathy>empathy</a> in human conversations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.539.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--539 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.539 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938821 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.539" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.539/>Profile Consistency Identification for Open-domain Dialogue Agents</a></strong><br><a href=/people/h/haoyu-song/>Haoyu Song</a>
|
<a href=/people/y/yan-wang/>Yan Wang</a>
|
<a href=/people/w/weinan-zhang/>Wei-Nan Zhang</a>
|
<a href=/people/z/zhengyu-zhao/>Zhengyu Zhao</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/x/xiaojiang-liu/>Xiaojiang Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--539><div class="card-body p-3 small">Maintaining a consistent attribute profile is crucial for dialogue agents to naturally converse with humans. Existing studies on improving attribute consistency mainly explored how to incorporate <a href=https://en.wikipedia.org/wiki/Attribute_(computing)>attribute information</a> in the responses, but few efforts have been made to identify the <a href=https://en.wikipedia.org/wiki/Consistency_(database_systems)>consistency relations</a> between response and attribute profile. To facilitate the study of profile consistency identification, we create a large-scale human-annotated dataset with over 110 K single-turn conversations and their key-value attribute profiles. Explicit relation between <a href=https://en.wikipedia.org/wiki/Information_retrieval>response</a> and profile is manually labeled. We also propose a key-value structure information enriched BERT model to identify the profile consistency, and it gained improvements over strong baselines. Further evaluations on <a href=https://en.wikipedia.org/wiki/Downstream_(networking)>downstream tasks</a> demonstrate that the profile consistency identification model is conducive for improving dialogue consistency.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.540.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--540 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.540 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938872 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.540/>An Element-aware Multi-representation Model for Law Article Prediction</a></strong><br><a href=/people/h/huilin-zhong/>Huilin Zhong</a>
|
<a href=/people/j/junsheng-zhou/>Junsheng Zhou</a>
|
<a href=/people/w/weiguang-qu/>Weiguang Qu</a>
|
<a href=/people/y/yunfei-long/>Yunfei Long</a>
|
<a href=/people/y/yanhui-gu/>Yanhui Gu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--540><div class="card-body p-3 small">Existing works have proved that using law articles as external knowledge can improve the performance of the Legal Judgment Prediction. However, they do not fully use law article information and most of the current work is only for single label samples. In this paper, we propose a Law Article Element-aware Multi-representation Model (LEMM), which can make full use of law article information and can be used for multi-label samples. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> uses the labeled elements of law articles to extract fact description features from multiple angles. It generates multiple representations of a fact for <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a>. Every label has a law-aware fact representation to encode more information. To capture the dependencies between law articles, the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> also introduces a self-attention mechanism between multiple representations. Compared with baseline models like TopJudge, this <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> improves the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 5.84 %, the <a href=https://en.wikipedia.org/wiki/Macroeconomic_model>macro F1</a> of 6.42 %, and the micro F1 of 4.28 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.541.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--541 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.541 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938911 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.541/>Recurrent Event Network : Autoregressive Structure Inferenceover Temporal Knowledge Graphs</a></strong><br><a href=/people/w/woojeong-jin/>Woojeong Jin</a>
|
<a href=/people/m/meng-qu/>Meng Qu</a>
|
<a href=/people/x/xisen-jin/>Xisen Jin</a>
|
<a href=/people/x/xiang-ren/>Xiang Ren</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--541><div class="card-body p-3 small">Knowledge graph reasoning is a critical task in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. The <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a> becomes more challenging on temporal knowledge graphs, where each fact is associated with a timestamp. Most existing methods focus on reasoning at past timestamps and they are not able to predict facts happening in the future. This paper proposes Recurrent Event Network (RE-Net), a novel autoregressive architecture for predicting future interactions. The occurrence of a fact (event) is modeled as a <a href=https://en.wikipedia.org/wiki/Probability_distribution>probability distribution</a> conditioned on temporal sequences of past knowledge graphs. Specifically, our RE-Net employs a recurrent event encoder to encode past facts, and uses a neighborhood aggregator to model the connection of facts at the same timestamp. Future facts can then be inferred in a sequential manner based on the two <a href=https://en.wikipedia.org/wiki/Module_(mathematics)>modules</a>. We evaluate our proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a> via link prediction at future times on five public datasets. Through extensive experiments, we demonstrate the strength of RE-Net, especially on multi-step inference over future timestamps, and achieve state-of-the-art performance on all five datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.543.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--543 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.543 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939245 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.543/>Less is More : <a href=https://en.wikipedia.org/wiki/Attentional_control>Attention Supervision</a> with Counterfactuals for Text Classification</a></strong><br><a href=/people/s/seungtaek-choi/>Seungtaek Choi</a>
|
<a href=/people/h/haeju-park/>Haeju Park</a>
|
<a href=/people/j/jinyoung-yeo/>Jinyoung Yeo</a>
|
<a href=/people/s/seung-won-hwang/>Seung-won Hwang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--543><div class="card-body p-3 small">We aim to leverage <a href=https://en.wikipedia.org/wiki/Human&#8211;computer_interaction>human and machine intelligence</a> together for <a href=https://en.wikipedia.org/wiki/Attentional_control>attention supervision</a>. Specifically, we show that human annotation cost can be kept reasonably low, while its <a href=https://en.wikipedia.org/wiki/Quality_(business)>quality</a> can be enhanced by <a href=https://en.wikipedia.org/wiki/Machine_vision>machine self-supervision</a>. Specifically, for this goal, we explore the advantage of counterfactual reasoning, over associative reasoning typically used in attention supervision. Our empirical results show that this machine-augmented human attention supervision is more effective than existing methods requiring a higher annotation cost, in text classification tasks, including <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> and news categorization.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.544.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--544 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.544 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939250 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.544/>MODE-LSTM : A Parameter-efficient Recurrent Network with Multi-Scale for Sentence Classification<span class=acl-fixed-case>MODE</span>-<span class=acl-fixed-case>LSTM</span>: A Parameter-efficient Recurrent Network with Multi-Scale for Sentence Classification</a></strong><br><a href=/people/q/qianli-ma/>Qianli Ma</a>
|
<a href=/people/z/zhenxi-lin/>Zhenxi Lin</a>
|
<a href=/people/j/jiangyue-yan/>Jiangyue Yan</a>
|
<a href=/people/z/zipeng-chen/>Zipeng Chen</a>
|
<a href=/people/l/liuhong-yu/>Liuhong Yu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--544><div class="card-body p-3 small">The central problem of sentence classification is to extract multi-scale n-gram features for understanding the semantic meaning of sentences. Most existing <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> tackle this problem by stacking CNN and RNN models, which easily leads to feature redundancy and <a href=https://en.wikipedia.org/wiki/Overfitting>overfitting</a> because of relatively limited datasets. In this paper, we propose a simple yet effective model called Multi-scale Orthogonal inDependEnt LSTM (MODE-LSTM), which not only has effective parameters and good generalization ability, but also considers multiscale n-gram features. We disentangle the hidden state of the LSTM into several independently updated small hidden states and apply an orthogonal constraint on their recurrent matrices. We then equip this <a href=https://en.wikipedia.org/wiki/Biomolecular_structure>structure</a> with sliding windows of different sizes for extracting multi-scale n-gram features. Extensive experiments demonstrate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves better or competitive performance against state-of-the-art baselines on eight benchmark datasets. We also combine our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> with BERT to further boost the generalization performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.545.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--545 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.545 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.545/>HSCNN : A Hybrid-Siamese Convolutional Neural Network for Extremely Imbalanced Multi-label Text Classification<span class=acl-fixed-case>HSCNN</span>: A Hybrid-<span class=acl-fixed-case>S</span>iamese Convolutional Neural Network for Extremely Imbalanced Multi-label Text Classification</a></strong><br><a href=/people/w/wenshuo-yang/>Wenshuo Yang</a>
|
<a href=/people/j/jiyi-li/>Jiyi Li</a>
|
<a href=/people/f/fumiyo-fukumoto/>Fumiyo Fukumoto</a>
|
<a href=/people/y/yanming-ye/>Yanming Ye</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--545><div class="card-body p-3 small">The data imbalance problem is a crucial issue for the multi-label text classification. Some existing works tackle it by proposing imbalanced loss objectives instead of the vanilla cross-entropy loss, but their performances remain limited in the cases of extremely imbalanced data. We propose a hybrid solution which adapts general networks for the head categories, and few-shot techniques for the tail categories. We propose a Hybrid-Siamese Convolutional Neural Network (HSCNN) with additional technical attributes, i.e., a multi-task architecture based on Single and Siamese networks ; a category-specific similarity in the Siamese structure ; a specific sampling method for training HSCNN. The results using two benchmark datasets and three <a href=https://en.wikipedia.org/wiki/Loss_function>loss objectives</a> show that our method can improve the performance of Single networks with diverse loss objectives on the tail or entire categories.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.546.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--546 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.546 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939367 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.546/>Multi-Stage Pre-training for Automated Chinese Essay Scoring<span class=acl-fixed-case>C</span>hinese Essay Scoring</a></strong><br><a href=/people/w/wei-song/>Wei Song</a>
|
<a href=/people/k/kai-zhang/>Kai Zhang</a>
|
<a href=/people/r/ruiji-fu/>Ruiji Fu</a>
|
<a href=/people/l/lizhen-liu/>Lizhen Liu</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/m/miaomiao-cheng/>Miaomiao Cheng</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--546><div class="card-body p-3 small">This paper proposes a pre-training based automated Chinese essay scoring method. The method involves three components : weakly supervised pre-training, supervised cross- prompt fine-tuning and supervised target- prompt fine-tuning. An essay scorer is first pre- trained on a large essay dataset covering diverse topics and with coarse ratings, i.e., good and poor, which are used as a kind of weak supervision. The pre-trained essay scorer would be further fine-tuned on previously rated es- says from existing prompts, which have the same score range with the target prompt and provide extra supervision. At last, the <a href=https://en.wikipedia.org/wiki/Score_(sport)>scorer</a> is fine-tuned on the target-prompt training data. The evaluation on four prompts shows that this method can improve a state-of-the-art neural essay scorer in terms of <a href=https://en.wikipedia.org/wiki/Effectiveness>effectiveness</a> and domain adaptation ability, while in-depth analysis also reveals its limitations..</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.547.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--547 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.547 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.547" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.547/>Multi-hop Inference for Question-driven Summarization</a></strong><br><a href=/people/y/yang-deng/>Yang Deng</a>
|
<a href=/people/w/wenxuan-zhang/>Wenxuan Zhang</a>
|
<a href=/people/w/wai-lam/>Wai Lam</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--547><div class="card-body p-3 small">Question-driven summarization has been recently studied as an effective approach to summarizing the source document to produce concise but informative answers for non-factoid questions. In this work, we propose a novel question-driven abstractive summarization method, Multi-hop Selective Generator (MSG), to incorporate multi-hop reasoning into question-driven summarization and, meanwhile, provide justifications for the generated summaries. Specifically, we jointly model the relevance to the question and the interrelation among different sentences via a human-like multi-hop inference module, which captures important sentences for justifying the summarized answer. A gated selective pointer generator network with a multi-view coverage mechanism is designed to integrate diverse information from different perspectives. Experimental results show that the proposed method consistently outperforms state-of-the-art methods on two non-factoid QA datasets, namely <a href=https://en.wikipedia.org/wiki/WikiHow>WikiHow</a> and PubMedQA.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.548.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--548 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.548 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938859 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.548" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.548/>Towards Interpretable Reasoning over Paragraph Effects in Situation</a></strong><br><a href=/people/m/mucheng-ren/>Mucheng Ren</a>
|
<a href=/people/x/xiubo-geng/>Xiubo Geng</a>
|
<a href=/people/t/tao-qin/>Tao Qin</a>
|
<a href=/people/h/he-yan-huang/>Heyan Huang</a>
|
<a href=/people/d/daxin-jiang/>Daxin Jiang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--548><div class="card-body p-3 small">We focus on the task of reasoning over paragraph effects in situation, which requires a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to understand the cause and effect described in a background paragraph, and apply the <a href=https://en.wikipedia.org/wiki/Knowledge>knowledge</a> to a novel situation. Existing works ignore the complicated reasoning process and solve it with a one-step black box model. Inspired by <a href=https://en.wikipedia.org/wiki/Cognition>human cognitive processes</a>, in this paper we propose a sequential approach for this task which explicitly models each step of the <a href=https://en.wikipedia.org/wiki/Reason>reasoning process</a> with <a href=https://en.wikipedia.org/wiki/Modular_programming>neural network modules</a>. In particular, five reasoning modules are designed and learned in an end-to-end manner, which leads to a more interpretable model. Experimental results on the ROPES dataset demonstrate the effectiveness and explainability of our proposed approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.549.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--549 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.549 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939022 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.549/>Question Directed Graph Attention Network for <a href=https://en.wikipedia.org/wiki/Numerical_analysis>Numerical Reasoning</a> over Text</a></strong><br><a href=/people/k/kunlong-chen/>Kunlong Chen</a>
|
<a href=/people/w/weidi-xu/>Weidi Xu</a>
|
<a href=/people/x/xingyi-cheng/>Xingyi Cheng</a>
|
<a href=/people/z/zou-xiaochuan/>Zou Xiaochuan</a>
|
<a href=/people/y/yuyu-zhang/>Yuyu Zhang</a>
|
<a href=/people/l/le-song/>Le Song</a>
|
<a href=/people/t/taifeng-wang/>Taifeng Wang</a>
|
<a href=/people/y/yuan-qi/>Yuan Qi</a>
|
<a href=/people/w/wei-chu/>Wei Chu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--549><div class="card-body p-3 small">Numerical reasoning over texts, such as <a href=https://en.wikipedia.org/wiki/Addition>addition</a>, <a href=https://en.wikipedia.org/wiki/Subtraction>subtraction</a>, sorting and counting, is a challenging machine reading comprehension task, since it requires both <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a> and <a href=https://en.wikipedia.org/wiki/Arithmetic>arithmetic computation</a>. To address this challenge, we propose a heterogeneous graph representation for the context of the passage and question needed for such <a href=https://en.wikipedia.org/wiki/Reason>reasoning</a>, and design a question directed graph attention network to drive multi-step numerical reasoning over this context graph. Our model, which combines deep learning and graph reasoning, achieves remarkable results in benchmark datasets such as DROP.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.550.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--550 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.550 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939151 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.550" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.550/>Dense Passage Retrieval for Open-Domain Question Answering</a></strong><br><a href=/people/v/vladimir-karpukhin/>Vladimir Karpukhin</a>
|
<a href=/people/b/barlas-oguz/>Barlas Oguz</a>
|
<a href=/people/s/sewon-min/>Sewon Min</a>
|
<a href=/people/p/patrick-lewis/>Patrick Lewis</a>
|
<a href=/people/l/ledell-wu/>Ledell Wu</a>
|
<a href=/people/s/sergey-edunov/>Sergey Edunov</a>
|
<a href=/people/d/danqi-chen/>Danqi Chen</a>
|
<a href=/people/w/wen-tau-yih/>Wen-tau Yih</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--550><div class="card-body p-3 small">Open-domain question answering relies on efficient passage retrieval to select candidate contexts, where traditional sparse vector space models, such as <a href=https://en.wikipedia.org/wiki/TF-IDF>TF-IDF</a> or <a href=https://en.wikipedia.org/wiki/BM25>BM25</a>, are the de facto method. In this work, we show that retrieval can be practically implemented using dense representations alone, where embeddings are learned from a small number of questions and passages by a simple dual-encoder framework. When evaluated on a wide range of open-domain QA datasets, our dense retriever outperforms a strong Lucene-BM25 system greatly by 9%-19 % absolute in terms of top-20 passage retrieval accuracy, and helps our end-to-end QA system establish new state-of-the-art on multiple open-domain QA benchmarks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.551.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--551 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.551 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938727 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.551/>Distilling Structured Knowledge for Text-Based Relational Reasoning</a></strong><br><a href=/people/j/jin-dong/>Jin Dong</a>
|
<a href=/people/m/marc-antoine-rondeau/>Marc-Antoine Rondeau</a>
|
<a href=/people/w/william-l-hamilton/>William L. Hamilton</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--551><div class="card-body p-3 small">There is an increasing interest in developing text-based relational reasoning systems, which are capable of systematically reasoning about the relationships between entities mentioned in a text. However, there remains a substantial performance gap between NLP models for relational reasoning and models based on graph neural networks (GNNs), which have access to an underlying symbolic representation of the text. In this work, we investigate how the structured knowledge of a GNN can be distilled into various NLP models in order to improve their performance. We first pre-train a GNN on a reasoning task using structured inputs and then incorporate its knowledge into an <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP model</a> (e.g., an LSTM) via knowledge distillation. To overcome the difficulty of cross-modal knowledge transfer, we also employ a contrastive learning based module to align the latent representations of NLP models and the GNN. We test our approach with two state-of-the-art NLP models on 13 different inductive reasoning datasets from the CLUTRR benchmark and obtain significant improvements.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.552.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--552 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.552 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938836 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.552/>Asking without Telling : Exploring Latent Ontologies in Contextual Representations</a></strong><br><a href=/people/j/julian-michael/>Julian Michael</a>
|
<a href=/people/j/jan-a-botha/>Jan A. Botha</a>
|
<a href=/people/i/ian-tenney/>Ian Tenney</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--552><div class="card-body p-3 small">The success of pretrained contextual encoders, such as ELMo and BERT, has brought a great deal of interest in what these models learn : do they, without explicit supervision, learn to encode meaningful notions of linguistic structure? If so, how is this structure encoded? To investigate this, we introduce latent subclass learning (LSL): a modification to classifier-based probing that induces a latent categorization (or ontology) of the probe&#8217;s inputs. Without access to fine-grained gold labels, LSL extracts <a href=https://en.wikipedia.org/wiki/Emergence>emergent structure</a> from input representations in an interpretable and quantifiable form. In experiments, we find strong evidence of familiar categories, such as a notion of personhood in ELMo, as well as novel ontological distinctions, such as a preference for fine-grained semantic roles on core arguments. Our results provide unique new evidence of <a href=https://en.wikipedia.org/wiki/Emergence>emergent structure</a> in pretrained encoders, including departures from existing annotations which are inaccessible to earlier methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.553.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--553 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.553 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.553.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938879 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.553" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.553/>Pretrained Language Model <a href=https://en.wikipedia.org/wiki/Embryology>Embryology</a> : The Birth of ALBERT<span class=acl-fixed-case>P</span>retrained Language Model Embryology: <span class=acl-fixed-case>T</span>he Birth of <span class=acl-fixed-case>ALBERT</span></a></strong><br><a href=/people/c/cheng-han-chiang/>Cheng-Han Chiang</a>
|
<a href=/people/s/sung-feng-huang/>Sung-Feng Huang</a>
|
<a href=/people/h/hung-yi-lee/>Hung-yi Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--553><div class="card-body p-3 small">While behaviors of pretrained language models (LMs) have been thoroughly examined, what happened during pretraining is rarely studied. We thus investigate the developmental process from a set of randomly initialized parameters to a totipotent language model, which we refer to as the <a href=https://en.wikipedia.org/wiki/Embryology>embryology</a> of a pretrained language model. Our results show that ALBERT learns to reconstruct and predict tokens of different parts of speech (POS) in different learning speeds during pretraining. We also find that linguistic knowledge and <a href=https://en.wikipedia.org/wiki/World_knowledge>world knowledge</a> do not generally improve as pretraining proceeds, nor do downstream tasks&#8217; performance. These findings suggest that knowledge of a pretrained model varies during pretraining, and having more pretrain steps does not necessarily provide a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> with more comprehensive knowledge. We provide <a href=https://en.wikipedia.org/wiki/Source_code>source codes</a> and pretrained models to reproduce our results at.<i>embryology</i> of a pretrained language model. Our results show that ALBERT learns to reconstruct and predict tokens of different parts of speech (POS) in different learning speeds during pretraining. We also find that linguistic knowledge and world knowledge do not generally improve as pretraining proceeds, nor do downstream tasks&#8217; performance. These findings suggest that knowledge of a pretrained model varies during pretraining, and having more pretrain steps does not necessarily provide a model with more comprehensive knowledge. We provide source codes and pretrained models to reproduce our results at <url>https://github.com/d223302/albert-embryology</url>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.556.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--556 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.556 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938640 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.556/>You are grounded ! : Latent Name Artifacts in Pre-trained Language Models</a></strong><br><a href=/people/v/vered-shwartz/>Vered Shwartz</a>
|
<a href=/people/r/rachel-rudinger/>Rachel Rudinger</a>
|
<a href=/people/o/oyvind-tafjord/>Oyvind Tafjord</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--556><div class="card-body p-3 small">Pre-trained language models (LMs) may perpetuate biases originating in their training corpus to downstream models. We focus on artifacts associated with the representation of given names (e.g., Donald), which, depending on the corpus, may be associated with specific <a href=https://en.wikipedia.org/wiki/Non-physical_entity>entities</a>, as indicated by next token prediction (e.g., Trump). While helpful in some contexts, grounding happens also in under-specified or inappropriate contexts. For example, endings generated for &#8216;Donald is a&#8217; substantially differ from those of other names, and often have more-than-average negative sentiment. We demonstrate the potential effect on downstream tasks with reading comprehension probes where name perturbation changes the model answers. As a silver lining, our experiments suggest that additional <a href=https://en.wikipedia.org/wiki/Training>pre-training</a> on different corpora may mitigate this bias.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.558.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--558 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.558 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.558.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938845 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.558/>Grounded Adaptation for Zero-shot Executable Semantic Parsing</a></strong><br><a href=/people/v/victor-zhong/>Victor Zhong</a>
|
<a href=/people/m/mike-lewis/>Mike Lewis</a>
|
<a href=/people/s/sida-i-wang/>Sida I. Wang</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--558><div class="card-body p-3 small">We propose Grounded Adaptation for Zeroshot Executable Semantic Parsing (GAZP) to adapt an existing semantic parser to new environments (e.g. new database schemas). GAZP combines a forward semantic parser with a backward utterance generator to synthesize data (e.g. utterances and SQL queries) in the new environment, then selects cycle-consistent examples to adapt the <a href=https://en.wikipedia.org/wiki/Parsing>parser</a>. Unlike data-augmentation, which typically synthesizes unverified examples in the training environment, GAZP synthesizes examples in the new environment whose input-output consistency are verified through execution. On the Spider, Sparc, and CoSQL zero-shot semantic parsing tasks, GAZP improves logical form and execution accuracy of the baseline parser. Our analyses show that GAZP outperforms data-augmentation in the training environment, performance increases with the amount of GAZP-synthesized data, and cycle-consistency is central to successful adaptation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.561.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--561 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.561 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939001 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.561/>What Do You Mean by That? A Parser-Independent Interactive Approach for Enhancing Text-to-SQL<span class=acl-fixed-case>SQL</span></a></strong><br><a href=/people/y/yuntao-li/>Yuntao Li</a>
|
<a href=/people/b/bei-chen/>Bei Chen</a>
|
<a href=/people/q/qian-liu/>Qian Liu</a>
|
<a href=/people/y/yan-gao/>Yan Gao</a>
|
<a href=/people/j/jian-guang-lou/>Jian-Guang Lou</a>
|
<a href=/people/y/yan-zhang/>Yan Zhang</a>
|
<a href=/people/d/dongmei-zhang/>Dongmei Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--561><div class="card-body p-3 small">In Natural Language Interfaces to Databases systems, the text-to-SQL technique allows users to query databases by using natural language questions. Though significant progress in this area has been made recently, most <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a> may fall short when they are deployed in real systems. One main reason stems from the difficulty of fully understanding the users&#8217; natural language questions. In this paper, we include human in the loop and present a novel parser-independent interactive approach (PIIA) that interacts with users using multi-choice questions and can easily work with arbitrary parsers. Experiments were conducted on two cross-domain datasets, the WikiSQL and the more complex Spider, with five state-of-the-art <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a>. These demonstrated that PIIA is capable of enhancing the text-to-SQL performance with limited interaction turns by using both simulation and human evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.562.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--562 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.562 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938688 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.562/>DuSQL : A Large-Scale and Pragmatic Chinese Text-to-SQL Dataset<span class=acl-fixed-case>D</span>u<span class=acl-fixed-case>SQL</span>: A Large-Scale and Pragmatic <span class=acl-fixed-case>C</span>hinese Text-to-<span class=acl-fixed-case>SQL</span> Dataset</a></strong><br><a href=/people/l/lijie-wang/>Lijie Wang</a>
|
<a href=/people/a/ao-zhang/>Ao Zhang</a>
|
<a href=/people/k/kun-wu/>Kun Wu</a>
|
<a href=/people/k/ke-sun/>Ke Sun</a>
|
<a href=/people/z/zhenghua-li/>Zhenghua Li</a>
|
<a href=/people/h/hua-wu/>Hua Wu</a>
|
<a href=/people/m/min-zhang/>Min Zhang</a>
|
<a href=/people/h/haifeng-wang/>Haifeng Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--562><div class="card-body p-3 small">Due to the lack of <a href=https://en.wikipedia.org/wiki/Data>labeled data</a>, previous research on text-to-SQL parsing mainly focuses on <a href=https://en.wikipedia.org/wiki/English_language>English</a>. Representative English datasets include ATIS, WikiSQL, Spider, etc. This paper presents DuSQL, a larges-scale and pragmatic Chinese dataset for the cross-domain text-to-SQL task, containing 200 databases, 813 tables, and 23,797 question / SQL pairs. Our new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> has three major characteristics. First, by manually analyzing questions from several representative applications, we try to figure out the true distribution of SQL queries in real-life needs. Second, DuSQL contains a considerable proportion of SQL queries involving row or column calculations, motivated by our analysis on the SQL query distributions. Finally, we adopt an effective data construction framework via <a href=https://en.wikipedia.org/wiki/Human&#8211;computer_interaction>human-computer collaboration</a>. The basic idea is automatically generating <a href=https://en.wikipedia.org/wiki/SQL>SQL queries</a> based on the SQL grammar and constrained by the given database. This paper describes in detail the construction process and <a href=https://en.wikipedia.org/wiki/Data_analysis>data statistics</a> of DuSQL. Moreover, we present and compare performance of several open-source text-to-SQL parsers with minor modification to accommodate <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>, including a simple yet effective extension to IRNet for handling calculation SQL queries.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.563.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--563 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.563 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939352 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.563/>Mention Extraction and Linking for SQL Query Generation<span class=acl-fixed-case>SQL</span> Query Generation</a></strong><br><a href=/people/j/jianqiang-ma/>Jianqiang Ma</a>
|
<a href=/people/z/zeyu-yan/>Zeyu Yan</a>
|
<a href=/people/s/shuai-pang/>Shuai Pang</a>
|
<a href=/people/y/yang-zhang/>Yang Zhang</a>
|
<a href=/people/j/jianping-shen/>Jianping Shen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--563><div class="card-body p-3 small">On the WikiSQL benchmark, state-of-the-art text-to-SQL systems typically take a slot- filling approach by building several dedicated models for each type of slots. Such modularized systems are not only complex but also of limited capacity for capturing inter-dependencies among SQL clauses. To solve these problems, this paper proposes a novel extraction-linking approach, where a unified extractor recognizes all types of slot mentions appearing in the question sentence before a linker maps the recognized columns to the table schema to generate executable SQL queries. Trained with automatically generated annotations, the proposed <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> achieves the first place on the WikiSQL benchmark.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.565.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--565 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.565 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.565.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938865 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.565" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.565/>A Multi-Task Incremental Learning Framework with Category Name Embedding for Aspect-Category Sentiment Analysis</a></strong><br><a href=/people/z/zehui-dai/>Zehui Dai</a>
|
<a href=/people/c/cheng-peng/>Cheng Peng</a>
|
<a href=/people/h/huajie-chen/>Huajie Chen</a>
|
<a href=/people/y/yadong-ding/>Yadong Ding</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--565><div class="card-body p-3 small">(T)ACSA tasks, including aspect-category sentiment analysis (ACSA) and targeted aspect-category sentiment analysis (TACSA), aims at identifying sentiment polarity on predefined categories. Incremental learning on new categories is necessary for (T)ACSA real applications. Though current multi-task learning models achieve good performance in (T)ACSA tasks, they suffer from catastrophic forgetting problems in (T)ACSA incremental learning tasks. In this paper, to make <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a> feasible for <a href=https://en.wikipedia.org/wiki/Incremental_learning>incremental learning</a>, we proposed Category Name Embedding network (CNE-net). We set both encoder and decoder shared among all categories to weaken the catastrophic forgetting problem. Besides the origin input sentence, we applied another input feature, i.e., <a href=https://en.wikipedia.org/wiki/Category_(mathematics)>category name</a>, for task discrimination. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieved state-of-the-art on two (T)ACSA benchmark datasets. Furthermore, we proposed a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for (T)ACSA incremental learning and achieved the best performance compared with other strong baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.566.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--566 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.566 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938884 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.566" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.566/>Train No Evil : Selective Masking for Task-Guided Pre-Training</a></strong><br><a href=/people/y/yuxian-gu/>Yuxian Gu</a>
|
<a href=/people/z/zhengyan-zhang/>Zhengyan Zhang</a>
|
<a href=/people/x/xiaozhi-wang/>Xiaozhi Wang</a>
|
<a href=/people/z/zhiyuan-liu/>Zhiyuan Liu</a>
|
<a href=/people/m/maosong-sun/>Maosong Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--566><div class="card-body p-3 small">Recently, pre-trained language models mostly follow the pre-train-then-fine-tuning paradigm and have achieved great performance on various downstream tasks. However, since the pre-training stage is typically task-agnostic and the fine-tuning stage usually suffers from insufficient supervised data, the models can not always well capture the domain-specific and task-specific patterns. In this paper, we propose a three-stage framework by adding a task-guided pre-training stage with selective masking between general pre-training and fine-tuning. In this stage, the model is trained by masked language modeling on in-domain unsupervised data to learn domain-specific patterns and we propose a novel selective masking strategy to learn task-specific patterns. Specifically, we design a method to measure the importance of each token in sequences and selectively mask the important tokens. Experimental results on two sentiment analysis tasks show that our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> can achieve comparable or even better performance with less than 50 % of computation cost, which indicates our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> is both effective and efficient. The source code of this paper can be obtained from.<url>https://github.com/thunlp/SelectiveMasking</url>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.569.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--569 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.569 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939058 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.569" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.569/>APE : Argument Pair Extraction from Peer Review and Rebuttal via <a href=https://en.wikipedia.org/wiki/Multi-task_learning>Multi-task Learning</a><span class=acl-fixed-case>APE</span>: Argument Pair Extraction from Peer Review and Rebuttal via Multi-task Learning</a></strong><br><a href=/people/l/liying-cheng/>Liying Cheng</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/q/qian-yu/>Qian Yu</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a>
|
<a href=/people/l/luo-si/>Luo Si</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--569><div class="card-body p-3 small">Peer review and rebuttal, with rich interactions and argumentative discussions in between, are naturally a good resource to mine arguments. However, few works study both of <a href=https://en.wikipedia.org/wiki/List_of_Latin_phrases_(I)>them</a> simultaneously. In this paper, we introduce a new argument pair extraction (APE) task on peer review and rebuttal in order to study the contents, the structure and the connections between them. We prepare a challenging <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> that contains 4,764 fully annotated review-rebuttal passage pairs from an open review platform to facilitate the study of this task. To automatically detect argumentative propositions and extract argument pairs from this <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>, we cast it as the combination of a sequence labeling task and a text relation classification task. Thus, we propose a multitask learning framework based on hierarchical LSTM networks. Extensive experiments and analysis demonstrate the effectiveness of our multi-task framework, and also show the challenges of the new <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> as well as motivate future research directions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.576.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--576 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.576 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.576.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939173 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.576" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.576/>On the Ability and Limitations of Transformers to Recognize <a href=https://en.wikipedia.org/wiki/Formal_language>Formal Languages</a><span class=acl-fixed-case>A</span>bility and <span class=acl-fixed-case>L</span>imitations of <span class=acl-fixed-case>T</span>ransformers to <span class=acl-fixed-case>R</span>ecognize <span class=acl-fixed-case>F</span>ormal <span class=acl-fixed-case>L</span>anguages</a></strong><br><a href=/people/s/satwik-bhattamishra/>Satwik Bhattamishra</a>
|
<a href=/people/k/kabir-ahuja/>Kabir Ahuja</a>
|
<a href=/people/n/navin-goyal/>Navin Goyal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--576><div class="card-body p-3 small">Transformers have supplanted <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent models</a> in a large number of <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP tasks</a>. However, the differences in their abilities to model different <a href=https://en.wikipedia.org/wiki/Syntax>syntactic properties</a> remain largely unknown. Past works suggest that LSTMs generalize very well on <a href=https://en.wikipedia.org/wiki/Regular_language>regular languages</a> and have close connections with counter languages. In this work, we systematically study the ability of Transformers to model such <a href=https://en.wikipedia.org/wiki/Programming_language>languages</a> as well as the role of its individual components in doing so. We first provide a construction of Transformers for a subclass of counter languages, including well-studied languages such as n-ary Boolean Expressions, Dyck-1, and its generalizations. In experiments, we find that Transformers do well on this <a href=https://en.wikipedia.org/wiki/Class_(biology)>subclass</a>, and their learned mechanism strongly correlates with our construction. Perhaps surprisingly, in contrast to LSTMs, Transformers do well only on a subset of <a href=https://en.wikipedia.org/wiki/Regular_language>regular languages</a> with degrading performance as we make languages more complex according to a well-known measure of <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a>. Our analysis also provides insights on the role of self-attention mechanism in modeling certain behaviors and the influence of positional encoding schemes on the learning and generalization abilities of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.583.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--583 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.583 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938772 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.583/>Is <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>Graph Structure</a> Necessary for Multi-hop Question Answering?<span class=acl-fixed-case>G</span>raph <span class=acl-fixed-case>S</span>tructure <span class=acl-fixed-case>N</span>ecessary for <span class=acl-fixed-case>M</span>ulti-hop <span class=acl-fixed-case>Q</span>uestion <span class=acl-fixed-case>A</span>nswering?</a></strong><br><a href=/people/n/nan-shao/>Nan Shao</a>
|
<a href=/people/y/yiming-cui/>Yiming Cui</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/s/shijin-wang/>Shijin Wang</a>
|
<a href=/people/g/guoping-hu/>Guoping Hu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--583><div class="card-body p-3 small">Recently, attempting to model texts as <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a> and introducing graph neural networks to deal with it has become a trend in many <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP research areas</a>. In this paper, we investigate whether the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a> is necessary for textual multi-hop reasoning. Our analysis is centered on HotpotQA. We construct a strong baseline model to establish that, with the proper use of pre-trained models, <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a> may not be necessary for textual multi-hop reasoning. We point out that both <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a> and <a href=https://en.wikipedia.org/wiki/Adjacency_matrix>adjacency matrix</a> are task-related prior knowledge, and graph-attention can be considered as a special case of self-attention. Experiments demonstrate that graph-attention or the entire <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a> can be replaced by self-attention or Transformers.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.588.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--588 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.588 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939295 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.588" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.588/>SLURP : A Spoken Language Understanding Resource Package<span class=acl-fixed-case>SLURP</span>: A Spoken Language Understanding Resource Package</a></strong><br><a href=/people/e/emanuele-bastianelli/>Emanuele Bastianelli</a>
|
<a href=/people/a/andrea-vanzo/>Andrea Vanzo</a>
|
<a href=/people/p/pawel-swietojanski/>Pawel Swietojanski</a>
|
<a href=/people/v/verena-rieser/>Verena Rieser</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--588><div class="card-body p-3 small">Spoken Language Understanding infers <a href=https://en.wikipedia.org/wiki/Semantics>semantic meaning</a> directly from audio data, and thus promises to reduce <a href=https://en.wikipedia.org/wiki/Error_propagation>error propagation</a> and misunderstandings in <a href=https://en.wikipedia.org/wiki/End_user>end-user applications</a>. However, publicly available SLU resources are limited. In this paper, we release SLURP, a new SLU package containing the following : (1) A new challenging dataset in English spanning 18 domains, which is substantially bigger and linguistically more diverse than existing datasets ; (2) Competitive baselines based on state-of-the-art NLU and ASR systems ; (3) A new transparent metric for entity labelling which enables a detailed error analysis for identifying potential areas of improvement. SLURP is available at https://github.com/pswietojanski/slurp.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.593.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--593 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.593 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938751 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.593" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.593/>DyERNIE : Dynamic Evolution of Riemannian Manifold Embeddings for Temporal Knowledge Graph Completion<span class=acl-fixed-case>D</span>y<span class=acl-fixed-case>ERNIE</span>: <span class=acl-fixed-case>D</span>ynamic <span class=acl-fixed-case>E</span>volution of <span class=acl-fixed-case>R</span>iemannian <span class=acl-fixed-case>M</span>anifold <span class=acl-fixed-case>E</span>mbeddings for <span class=acl-fixed-case>T</span>emporal <span class=acl-fixed-case>K</span>nowledge <span class=acl-fixed-case>G</span>raph <span class=acl-fixed-case>C</span>ompletion</a></strong><br><a href=/people/z/zhen-han/>Zhen Han</a>
|
<a href=/people/p/peng-chen/>Peng Chen</a>
|
<a href=/people/y/yunpu-ma/>Yunpu Ma</a>
|
<a href=/people/v/volker-tresp/>Volker Tresp</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--593><div class="card-body p-3 small">There has recently been increasing interest in learning representations of temporal knowledge graphs (KGs), which record the dynamic relationships between entities over time. Temporal KGs often exhibit multiple simultaneous non-Euclidean structures, such as hierarchical and cyclic structures. However, existing embedding approaches for temporal KGs typically learn entity representations and their dynamic evolution in the <a href=https://en.wikipedia.org/wiki/Euclidean_space>Euclidean space</a>, which might not capture such intrinsic structures very well. To this end, we propose DyERNIE, a non-Euclidean embedding approach that learns evolving entity representations in a product of Riemannian manifolds, where the composed spaces are estimated from the sectional curvatures of underlying data. Product manifolds enable our approach to better reflect a wide variety of geometric structures on temporal KGs. Besides, to capture the evolutionary dynamics of temporal KGs, we let the <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity representations</a> evolve according to a <a href=https://en.wikipedia.org/wiki/Velocity_vector>velocity vector</a> defined in the <a href=https://en.wikipedia.org/wiki/Tangent_space>tangent space</a> at each timestamp. We analyze in detail the contribution of geometric spaces to representation learning of temporal KGs and evaluate our model on temporal knowledge graph completion tasks. Extensive experiments on three real-world datasets demonstrate significantly improved performance, indicating that the dynamics of multi-relational graph data can be more properly modeled by the evolution of embeddings on <a href=https://en.wikipedia.org/wiki/Riemannian_manifold>Riemannian manifolds</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.596.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--596 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.596 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.596.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939108 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.596" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.596/>Message Passing for Hyper-Relational Knowledge Graphs</a></strong><br><a href=/people/m/mikhail-galkin/>Mikhail Galkin</a>
|
<a href=/people/p/priyansh-trivedi/>Priyansh Trivedi</a>
|
<a href=/people/g/gaurav-maheshwari/>Gaurav Maheshwari</a>
|
<a href=/people/r/ricardo-usbeck/>Ricardo Usbeck</a>
|
<a href=/people/j/jens-lehmann/>Jens Lehmann</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--596><div class="card-body p-3 small">Hyper-relational knowledge graphs (KGs) (e.g., Wikidata) enable associating additional <a href=https://en.wikipedia.org/wiki/Attribute&#8211;value_pair>key-value pairs</a> along with the main triple to disambiguate, or restrict the validity of a fact. In this work, we propose a message passing based graph encoder-StarE capable of modeling such hyper-relational KGs. Unlike existing approaches, StarE can encode an arbitrary number of additional information (qualifiers) along with the main triple while keeping the semantic roles of qualifiers and triples intact. We also demonstrate that existing benchmarks for evaluating link prediction (LP) performance on hyper-relational KGs suffer from fundamental flaws and thus develop a new Wikidata-based dataset-WD50K. Our experiments demonstrate that StarE based LP model outperforms existing approaches across multiple benchmarks. We also confirm that leveraging qualifiers is vital for link prediction with gains up to 25 MRR points compared to triple-based representations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.602.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--602 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.602 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939042 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.602/>PowerTransformer : Unsupervised Controllable Revision for Biased Language Correction<span class=acl-fixed-case>P</span>ower<span class=acl-fixed-case>T</span>ransformer: Unsupervised Controllable Revision for Biased Language Correction</a></strong><br><a href=/people/x/xinyao-ma/>Xinyao Ma</a>
|
<a href=/people/m/maarten-sap/>Maarten Sap</a>
|
<a href=/people/h/hannah-rashkin/>Hannah Rashkin</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--602><div class="card-body p-3 small">Unconscious biases continue to be prevalent in modern text and media, calling for <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> that can assist writers with bias correction. For example, a female character in a story is often portrayed as passive and powerless (_ She daydreams about being a doctor _) while a man is portrayed as more proactive and powerful (_ He pursues his dream of being a doctor _). We formulate * * Controllable Debiasing * *, a new revision task that aims to rewrite a given text to correct the implicit and potentially undesirable bias in character portrayals. We then introduce PowerTransformer as an approach that debiases text through the lens of connotation frames (Sap et al., 2017), which encode pragmatic knowledge of implied power dynamics with respect to verb predicates. One key challenge of our <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is the lack of parallel corpora. To address this challenge, we adopt an unsupervised approach using auxiliary supervision with related tasks such as <a href=https://en.wikipedia.org/wiki/Paraphrasing>paraphrasing</a> and self-supervision based on a reconstruction loss, building on pretrained language models. Through comprehensive experiments based on automatic and human evaluations, we demonstrate that our approach outperforms <a href=https://en.wikipedia.org/wiki/Ablation>ablations</a> and existing <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> from related <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. Furthermore, we demonstrate the use of PowerTransformer as a step toward mitigating the well-documented gender bias in character portrayal in movie scripts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.604.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--604 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.604 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939101 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.604/>Centering-based Neural Coherence Modeling with Hierarchical Discourse Segments</a></strong><br><a href=/people/s/sungho-jeon/>Sungho Jeon</a>
|
<a href=/people/m/michael-strube/>Michael Strube</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--604><div class="card-body p-3 small">Previous neural coherence models have focused on identifying semantic relations between adjacent sentences. However, <a href=https://en.wikipedia.org/wiki/Information_technology>they</a> do not have the means to exploit structural information. In this work, we propose a coherence model which takes discourse structural information into account without relying on human annotations. We approximate a linguistic theory of coherence, Centering theory, which we use to track the changes of focus between discourse segments. Our model first identifies the focus of each sentence, recognized with regards to the context, and constructs the structural relationship for discourse segments by tracking the changes of the focus. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> then incorporates this <a href=https://en.wikipedia.org/wiki/Structural_analysis>structural information</a> into a structure-aware transformer. We evaluate our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on two tasks, automated essay scoring and assessing writing quality. Our results demonstrate that our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>, built on top of a pretrained language model, achieves state-of-the-art performance on both tasks. We next statistically examine the identified trees of texts assigned to different <a href=https://en.wikipedia.org/wiki/Quality_(philosophy)>quality scores</a>. Finally, we investigate what our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> learns in terms of theoretical claims.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.608.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--608 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.608 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939146 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.608/>Which * BERT? A Survey Organizing Contextualized Encoders<span class=acl-fixed-case>BERT</span>? <span class=acl-fixed-case>A</span> Survey Organizing Contextualized Encoders</a></strong><br><a href=/people/p/patrick-xia/>Patrick Xia</a>
|
<a href=/people/s/shijie-wu/>Shijie Wu</a>
|
<a href=/people/b/benjamin-van-durme/>Benjamin Van Durme</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--608><div class="card-body p-3 small">Pretrained contextualized text encoders are now a staple of the NLP community. We present a survey on language representation learning with the aim of consolidating a series of shared lessons learned across a variety of recent efforts. While significant advancements continue at a rapid pace, we find that enough has now been discovered, in different directions, that we can begin to organize advances according to common themes. Through this organization, we highlight important considerations when interpreting recent contributions and choosing which <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to use.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.609.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--609 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.609 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939235 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.609" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.609/>Fact or Fiction : Verifying Scientific Claims</a></strong><br><a href=/people/d/david-wadden/>David Wadden</a>
|
<a href=/people/s/shanchuan-lin/>Shanchuan Lin</a>
|
<a href=/people/k/kyle-lo/>Kyle Lo</a>
|
<a href=/people/l/lucy-lu-wang/>Lucy Lu Wang</a>
|
<a href=/people/m/madeleine-van-zuylen/>Madeleine van Zuylen</a>
|
<a href=/people/a/arman-cohan/>Arman Cohan</a>
|
<a href=/people/h/hannaneh-hajishirzi/>Hannaneh Hajishirzi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--609><div class="card-body p-3 small">We introduce scientific claim verification, a new task to select abstracts from the research literature containing evidence that SUPPORTS or REFUTES a given scientific claim, and to identify rationales justifying each decision. To study this task, we construct SciFact, a dataset of 1.4 K expert-written scientific claims paired with evidence-containing abstracts annotated with labels and rationales. We develop baseline models for SciFact, and demonstrate that simple domain adaptation techniques substantially improve performance compared to <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> trained on <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a> or political news. We show that our system is able to verify claims related to COVID-19 by identifying evidence from the CORD-19 corpus. Our experiments indicate that SciFact will provide a challenging testbed for the development of new systems designed to retrieve and reason over corpora containing specialized domain knowledge. Data and code for this new task are publicly available at https://github.com/allenai/scifact. A <a href=https://en.wikipedia.org/wiki/Glossary_of_video_game_terms>leaderboard</a> and COVID-19 fact-checking demo are available at https://scifact.apps.allenai.org.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.612.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--612 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.612 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939303 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.612/>Causal Inference of Script Knowledge</a></strong><br><a href=/people/n/noah-weber/>Noah Weber</a>
|
<a href=/people/r/rachel-rudinger/>Rachel Rudinger</a>
|
<a href=/people/b/benjamin-van-durme/>Benjamin Van Durme</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--612><div class="card-body p-3 small">When does a sequence of events define an everyday scenario and how can this knowledge be induced from text? Prior works in inducing such scripts have relied on, in one form or another, measures of correlation between instances of events in a corpus. We argue from both a conceptual and practical sense that a purely correlation-based approach is insufficient, and instead propose an approach to script induction based on the causal effect between events, formally defined via interventions. Through both human and automatic evaluations, we show that the output of our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> based on <a href=https://en.wikipedia.org/wiki/Causality>causal effects</a> better matches the intuition of what a script represents.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.616.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--616 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.616 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939052 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.616" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.616/>Detecting Word Sense Disambiguation Biases in <a href=https://en.wikipedia.org/wiki/Machine_translation>Machine Translation</a> for Model-Agnostic Adversarial Attacks</a></strong><br><a href=/people/d/denis-emelin/>Denis Emelin</a>
|
<a href=/people/i/ivan-titov/>Ivan Titov</a>
|
<a href=/people/r/rico-sennrich/>Rico Sennrich</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--616><div class="card-body p-3 small">Word sense disambiguation is a well-known source of translation errors in <a href=https://en.wikipedia.org/wiki/NMT>NMT</a>. We posit that some of the incorrect disambiguation choices are due to models&#8217; over-reliance on dataset artifacts found in training data, specifically superficial word co-occurrences, rather than a deeper understanding of the source text. We introduce a method for the prediction of disambiguation errors based on statistical data properties, demonstrating its effectiveness across several domains and model types. Moreover, we develop a simple adversarial attack strategy that minimally perturbs sentences in order to elicit disambiguation errors to further probe the <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> of translation models. Our findings indicate that disambiguation robustness varies substantially between domains and that different <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained on the same data are vulnerable to different attacks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.620.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--620 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.620 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.620.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939379 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.620" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.620/>Weakly Supervised Learning of Nuanced Frames for Analyzing Polarization in <a href=https://en.wikipedia.org/wiki/News_media>News Media</a></a></strong><br><a href=/people/s/shamik-roy/>Shamik Roy</a>
|
<a href=/people/d/dan-goldwasser/>Dan Goldwasser</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--620><div class="card-body p-3 small">In this paper, we suggest a minimally supervised approach for identifying nuanced frames in news article coverage of politically divisive topics. We suggest to break the broad policy frames suggested by Boydstun et al., 2014 into fine-grained subframes which can capture differences in <a href=https://en.wikipedia.org/wiki/Ideology>political ideology</a> in a better way. We evaluate the suggested subframes and their embedding, learned using minimal supervision, over three topics, namely, <a href=https://en.wikipedia.org/wiki/Immigration>immigration</a>, <a href=https://en.wikipedia.org/wiki/Gun_politics_in_the_United_States>gun-control</a>, and <a href=https://en.wikipedia.org/wiki/Abortion>abortion</a>. We demonstrate the ability of the subframes to capture <a href=https://en.wikipedia.org/wiki/Ideology>ideological differences</a> and analyze <a href=https://en.wikipedia.org/wiki/Discourse_analysis>political discourse</a> in <a href=https://en.wikipedia.org/wiki/News_media>news media</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.623.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--623 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.623 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939277 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.623" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.623/>Explainable Automated Fact-Checking for Public Health Claims</a></strong><br><a href=/people/n/neema-kotonya/>Neema Kotonya</a>
|
<a href=/people/f/francesca-toni/>Francesca Toni</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--623><div class="card-body p-3 small">Fact-checking is the task of verifying the veracity of claims by assessing their assertions against credible evidence. The vast majority of <a href=https://en.wikipedia.org/wiki/Fact-checking>fact-checking studies</a> focus exclusively on <a href=https://en.wikipedia.org/wiki/Politics>political claims</a>. Very little research explores <a href=https://en.wikipedia.org/wiki/Fact-checking>fact-checking</a> for other topics, specifically subject matters for which expertise is required. We present the first study of explainable fact-checking for claims which require specific expertise. For our case study we choose the setting of <a href=https://en.wikipedia.org/wiki/Public_health>public health</a>. To support this case study we construct a new dataset PUBHEALTH of 11.8 K claims accompanied by journalist crafted, gold standard explanations (i.e., judgments) to support the fact-check labels for claims. We explore two <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> : veracity prediction and explanation generation. We also define and evaluate, with humans and computationally, three <a href=https://en.wikipedia.org/wiki/Coherence_(physics)>coherence properties</a> of explanation quality. Our results indicate that, by training on in-domain data, gains can be made in explainable, automated fact-checking for claims which require specific expertise.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.627.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--627 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.627 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939144 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.627" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.627/>Hierarchical Evidence Set Modeling for Automated Fact Extraction and Verification<span class=acl-fixed-case>H</span>ierarchical <span class=acl-fixed-case>E</span>vidence <span class=acl-fixed-case>S</span>et <span class=acl-fixed-case>M</span>odeling for Automated Fact Extraction and Verification</a></strong><br><a href=/people/s/shyam-subramanian/>Shyam Subramanian</a>
|
<a href=/people/k/kyumin-lee/>Kyumin Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--627><div class="card-body p-3 small">Automated fact extraction and verification is a challenging task that involves finding relevant evidence sentences from a reliable corpus to verify the truthfulness of a claim. Existing models either (i) concatenate all the evidence sentences, leading to the inclusion of redundant and noisy information ; or (ii) process each claim-evidence sentence pair separately and aggregate all of them later, missing the early combination of related sentences for more accurate claim verification. Unlike the prior works, in this paper, we propose Hierarchical Evidence Set Modeling (HESM), a framework to extract evidence sets (each of which may contain multiple evidence sentences), and verify a claim to be supported, refuted or not enough info, by encoding and attending the claim and evidence sets at different levels of hierarchy. Our experimental results show that HESM outperforms 7 state-of-the-art methods for fact extraction and <a href=https://en.wikipedia.org/wiki/Verification_and_validation>claim verification</a>. Our source code is available at https://github.com/ShyamSubramanian/HESM.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.635.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--635 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.635 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939047 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.635" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.635/>Exploring and Predicting Transferability across NLP Tasks<span class=acl-fixed-case>NLP</span> Tasks</a></strong><br><a href=/people/t/tu-vu/>Tu Vu</a>
|
<a href=/people/t/tong-wang/>Tong Wang</a>
|
<a href=/people/t/tsendsuren-munkhdalai/>Tsendsuren Munkhdalai</a>
|
<a href=/people/a/alessandro-sordoni/>Alessandro Sordoni</a>
|
<a href=/people/a/adam-trischler/>Adam Trischler</a>
|
<a href=/people/a/andrew-mattarella-micke/>Andrew Mattarella-Micke</a>
|
<a href=/people/s/subhransu-maji/>Subhransu Maji</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--635><div class="card-body p-3 small">Recent advances in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> demonstrate the effectiveness of training large-scale language models and transferring them to downstream tasks. Can fine-tuning these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> other than <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a> further improve performance? In this paper, we conduct an extensive study of the transferability between 33 NLP tasks across three broad classes of problems (text classification, <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>, and sequence labeling). Our results show that <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> is more beneficial than previously thought, especially when target task data is scarce, and can improve performance even with low-data source tasks that differ substantially from the target task (e.g., <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a> transfers well to the DROP QA dataset). We also develop task embeddings that can be used to predict the most transferable source tasks for a given target task, and we validate their effectiveness in experiments controlled for source and target data size. Overall, our experiments reveal that factors such as data size, task and domain similarity, and task complexity all play a role in determining transferability.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.637.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--637 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.637 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938687 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.637" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.637/>Cold-start Active Learning through Self-supervised Language Modeling</a></strong><br><a href=/people/m/michelle-yuan/>Michelle Yuan</a>
|
<a href=/people/h/hsuan-tien-lin/>Hsuan-Tien Lin</a>
|
<a href=/people/j/jordan-boyd-graber/>Jordan Boyd-Graber</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--637><div class="card-body p-3 small">Active learning strives to reduce annotation costs by choosing the most critical examples to label. Typically, the active learning strategy is contingent on the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification model</a>. For instance, uncertainty sampling depends on poorly calibrated model confidence scores. In the cold-start setting, <a href=https://en.wikipedia.org/wiki/Active_learning>active learning</a> is impractical because of model instability and data scarcity. Fortunately, modern <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> provides an additional source of information : pre-trained language models. The pre-training loss can find examples that surprise the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> and should be labeled for efficient <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a>. Therefore, we treat the language modeling loss as a proxy for classification uncertainty. With BERT, we develop a simple strategy based on the masked language modeling loss that minimizes labeling costs for <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a>. Compared to other baselines, our approach reaches higher <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> within less <a href=https://en.wikipedia.org/wiki/Sampling_(statistics)>sampling iterations</a> and <a href=https://en.wikipedia.org/wiki/Time_complexity>computation time</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.641.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--641 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.641 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938831 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.641/>The importance of fillers for text representations of speech transcripts</a></strong><br><a href=/people/t/tanvi-dinkar/>Tanvi Dinkar</a>
|
<a href=/people/p/pierre-colombo/>Pierre Colombo</a>
|
<a href=/people/m/matthieu-labeau/>Matthieu Labeau</a>
|
<a href=/people/c/chloe-clavel/>Chlo Clavel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--641><div class="card-body p-3 small">While being an essential component of <a href=https://en.wikipedia.org/wiki/Spoken_language>spoken language</a>, fillers (e.g. um or uh) often remain overlooked in Spoken Language Understanding (SLU) tasks. We explore the possibility of representing them with deep contextualised embeddings, showing improvements on modelling <a href=https://en.wikipedia.org/wiki/Spoken_language>spoken language</a> and two downstream tasks predicting a speaker&#8217;s stance and expressed confidence.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.643.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--643 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.643 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939137 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.643/>VolTAGE : Volatility Forecasting via Text Audio Fusion with Graph Convolution Networks for Earnings Calls<span class=acl-fixed-case>V</span>ol<span class=acl-fixed-case>TAGE</span>: Volatility Forecasting via Text Audio Fusion with Graph Convolution Networks for Earnings Calls</a></strong><br><a href=/people/r/ramit-sawhney/>Ramit Sawhney</a>
|
<a href=/people/p/piyush-khanna/>Piyush Khanna</a>
|
<a href=/people/a/arshiya-aggarwal/>Arshiya Aggarwal</a>
|
<a href=/people/t/taru-jain/>Taru Jain</a>
|
<a href=/people/p/puneet-mathur/>Puneet Mathur</a>
|
<a href=/people/r/rajiv-shah/>Rajiv Ratn Shah</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--643><div class="card-body p-3 small">Natural language processing has recently made stock movement forecasting and volatility forecasting advances, leading to improved <a href=https://en.wikipedia.org/wiki/Financial_forecasting>financial forecasting</a>. Transcripts of companies&#8217; earnings calls are well studied for <a href=https://en.wikipedia.org/wiki/Financial_risk_modeling>risk modeling</a>, offering unique investment insight into stock performance. However, <a href=https://en.wikipedia.org/wiki/Speech_recognition>vocal cues</a> in the speech of company executives present an underexplored rich source of <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language data</a> for estimating <a href=https://en.wikipedia.org/wiki/Financial_risk>financial risk</a>. Additionally, most existing <a href=https://en.wikipedia.org/wiki/Portfolio_(finance)>approaches</a> ignore the correlations between stocks. Building on existing work, we introduce a neural model for stock volatility prediction that accounts for stock interdependence via graph convolutions while fusing verbal, vocal, and financial features in a semi-supervised multi-task risk forecasting formulation. Our proposed model, VolTAGE, outperforms existing methods demonstrating the effectiveness of <a href=https://en.wikipedia.org/wiki/Multimodal_learning>multimodal learning</a> for volatility prediction.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.644.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--644 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.644 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939224 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.644/>Effectively pretraining a speech translation decoder with Machine Translation data</a></strong><br><a href=/people/a/ashkan-alinejad/>Ashkan Alinejad</a>
|
<a href=/people/a/anoop-sarkar/>Anoop Sarkar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--644><div class="card-body p-3 small">Directly translating from <a href=https://en.wikipedia.org/wiki/Speech>speech</a> to text using an <a href=https://en.wikipedia.org/wiki/End-to-end_principle>end-to-end approach</a> is still challenging for many language pairs due to insufficient data. Although pretraining the encoder parameters using the Automatic Speech Recognition (ASR) task improves the results in low resource settings, attempting to use pretrained parameters from the Neural Machine Translation (NMT) task has been largely unsuccessful in previous works. In this paper, we will show that by using an adversarial regularizer, we can bring the encoder representations of the ASR and NMT tasks closer even though they are in different modalities, and how this helps us effectively use a pretrained NMT decoder for <a href=https://en.wikipedia.org/wiki/Speech_translation>speech translation</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.646.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--646 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.646 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939209 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.646/>TESA : A Task in Entity Semantic Aggregation for Abstractive Summarization<span class=acl-fixed-case>TESA</span>: A <span class=acl-fixed-case>T</span>ask in <span class=acl-fixed-case>E</span>ntity <span class=acl-fixed-case>S</span>emantic <span class=acl-fixed-case>A</span>ggregation for Abstractive Summarization</a></strong><br><a href=/people/c/clement-jumel/>Clment Jumel</a>
|
<a href=/people/a/annie-louis/>Annie Louis</a>
|
<a href=/people/j/jackie-chi-kit-cheung/>Jackie Chi Kit Cheung</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--646><div class="card-body p-3 small">Human-written texts contain frequent generalizations and semantic aggregation of content. In a document, they may refer to a pair of named entities such as &#8216;London&#8217; and &#8216;Paris&#8217; with different expressions : the major cities, the capital cities and two European cities. Yet generation, especially, abstractive summarization systems have so far focused heavily on <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrasing</a> and simplifying the source content, to the exclusion of such semantic abstraction capabilities. In this paper, we present a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> and <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> aimed at the semantic aggregation of entities. TESA contains a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of 5.3 K crowd-sourced entity aggregations of Person, Organization, and Location named entities. The aggregations are document-appropriate, meaning that they are produced by annotators to match the situational context of a given news article from the <a href=https://en.wikipedia.org/wiki/The_New_York_Times>New York Times</a>. We then build <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline models</a> for generating aggregations given a tuple of entities and <a href=https://en.wikipedia.org/wiki/Context_(language_use)>document context</a>. We finetune on TESA an encoder-decoder language model and compare it with simpler <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification methods</a> based on linguistically informed features. Our quantitative and qualitative evaluations show reasonable performance in making a choice from a given list of expressions, but free-form expressions are understandably harder to generate and evaluate.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.650.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--650 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.650 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.emnlp-main.650.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938895 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.650/>Iterative Feature Mining for Constraint-Based Data Collection to Increase Data Diversity and Model Robustness</a></strong><br><a href=/people/s/stefan-larson/>Stefan Larson</a>
|
<a href=/people/a/anthony-zheng/>Anthony Zheng</a>
|
<a href=/people/a/anish-mahendran/>Anish Mahendran</a>
|
<a href=/people/r/rishi-tekriwal/>Rishi Tekriwal</a>
|
<a href=/people/a/adrian-cheung/>Adrian Cheung</a>
|
<a href=/people/e/eric-guldan/>Eric Guldan</a>
|
<a href=/people/k/kevin-leach/>Kevin Leach</a>
|
<a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--650><div class="card-body p-3 small">Diverse data is crucial for training robust models, but crowdsourced text often lacks diversity as workers tend to write simple variations from prompts. We propose a general approach for guiding workers to write more diverse text by iteratively constraining their writing. We show how prior workflows are special cases of our approach, and present a way to apply the approach to dialog tasks such as intent classification and slot-filling. Using our <a href=https://en.wikipedia.org/wiki/Methodology>method</a>, we create more challenging versions of test sets from prior dialog datasets and find dramatic performance drops for standard <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. Finally, we show that our approach is complementary to recent work on improving <a href=https://en.wikipedia.org/wiki/Data>data diversity</a>, and training on <a href=https://en.wikipedia.org/wiki/Data>data</a> collected with our approach leads to more robust models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.658.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--658 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.658 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939009 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.658" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.658/>New Protocols and Negative Results for Textual Entailment Data Collection</a></strong><br><a href=/people/s/samuel-bowman/>Samuel R. Bowman</a>
|
<a href=/people/j/jennimaria-palomaki/>Jennimaria Palomaki</a>
|
<a href=/people/l/livio-baldini-soares/>Livio Baldini Soares</a>
|
<a href=/people/e/emily-pitler/>Emily Pitler</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--658><div class="card-body p-3 small">Natural language inference (NLI) data has proven useful in <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmarking</a> and, especially, as pretraining data for tasks requiring <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>language understanding</a>. However, the crowdsourcing protocol that was used to collect this <a href=https://en.wikipedia.org/wiki/Data>data</a> has known issues and was not explicitly optimized for either of these purposes, so it is likely far from ideal. We propose four alternative protocols, each aimed at improving either the ease with which annotators can produce sound training examples or the quality and diversity of those examples. Using these alternatives and a fifth <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baseline protocol</a>, we collect and compare five new 8.5k-example training sets. In evaluations focused on transfer learning applications, our results are solidly negative, with models trained on our <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline dataset</a> yielding good transfer performance to downstream tasks, but none of our four new methods (nor the recent ANLI) showing any improvements over that <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a>. In a small silver lining, we observe that all four new <a href=https://en.wikipedia.org/wiki/Communication_protocol>protocols</a>, especially those where annotators edit * pre-filled * text boxes, reduce previously observed issues with annotation artifacts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.664.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--664 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.664 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939247 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.664" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.664/>Precise Task Formalization Matters in Winograd Schema Evaluations<span class=acl-fixed-case>W</span>inograd Schema Evaluations</a></strong><br><a href=/people/h/haokun-liu/>Haokun Liu</a>
|
<a href=/people/w/william-huang/>William Huang</a>
|
<a href=/people/d/dhara-mungra/>Dhara Mungra</a>
|
<a href=/people/s/samuel-bowman/>Samuel R. Bowman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--664><div class="card-body p-3 small">Performance on the Winograd Schema Challenge (WSC), a respected English commonsense reasoning benchmark, recently rocketed from chance accuracy to 89 % on the SuperGLUE leaderboard, with relatively little corroborating evidence of a correspondingly large improvement in reasoning ability. We hypothesize that much of this improvement comes from recent changes in task formalizationthe combination of input specification, <a href=https://en.wikipedia.org/wiki/Loss_function>loss function</a>, and reuse of pretrained parametersby users of the dataset, rather than improvements in the pretrained model&#8217;s reasoning ability. We perform an ablation on two Winograd Schema datasets that interpolates between the formalizations used before and after this surge, and find (i) framing the task as multiple choice improves performance dramatically and (ii)several additional techniques, including the reuse of a pretrained language modeling head, can mitigate the model&#8217;s extreme sensitivity to hyperparameters. We urge future benchmark creators to impose additional structure to minimize the impact of formalization decisions on reported results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.667.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--667 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.667 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.667/>Evaluating the Calibration of Knowledge Graph Embeddings for Trustworthy Link Prediction<span class=acl-fixed-case>E</span>valuating the <span class=acl-fixed-case>C</span>alibration of <span class=acl-fixed-case>K</span>nowledge <span class=acl-fixed-case>G</span>raph <span class=acl-fixed-case>E</span>mbeddings for <span class=acl-fixed-case>T</span>rustworthy <span class=acl-fixed-case>L</span>ink <span class=acl-fixed-case>P</span>rediction</a></strong><br><a href=/people/t/tara-safavi/>Tara Safavi</a>
|
<a href=/people/d/danai-koutra/>Danai Koutra</a>
|
<a href=/people/e/edgar-meij/>Edgar Meij</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--667><div class="card-body p-3 small">Little is known about the trustworthiness of predictions made by knowledge graph embedding (KGE) models. In this paper we take initial steps toward this direction by investigating the calibration of KGE models, or the extent to which they output <a href=https://en.wikipedia.org/wiki/Confidence_interval>confidence scores</a> that reflect the expected correctness of predicted knowledge graph triples. We first conduct an evaluation under the standard closed-world assumption (CWA), in which predicted triples not already in the <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graph</a> are considered false, and show that existing calibration techniques are effective for KGE under this common but narrow assumption. Next, we introduce the more realistic but challenging open-world assumption (OWA), in which unobserved predictions are not considered true or false until ground-truth labels are obtained. Here, we show that existing calibration techniques are much less effective under the OWA than the CWA, and provide explanations for this discrepancy. Finally, to motivate the utility of <a href=https://en.wikipedia.org/wiki/Calibration>calibration</a> for KGE from a practitioner&#8217;s perspective, we conduct a unique case study of human-AI collaboration, showing that calibrated predictions can improve human performance in a knowledge graph completion task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.669.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--669 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.669 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.669" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.669/>CoDEx : A Comprehensive Knowledge Graph Completion Benchmark<span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>DE</span>x: A <span class=acl-fixed-case>C</span>omprehensive <span class=acl-fixed-case>K</span>nowledge <span class=acl-fixed-case>G</span>raph <span class=acl-fixed-case>C</span>ompletion <span class=acl-fixed-case>B</span>enchmark</a></strong><br><a href=/people/t/tara-safavi/>Tara Safavi</a>
|
<a href=/people/d/danai-koutra/>Danai Koutra</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--669><div class="card-body p-3 small">We present CoDEx, a set of knowledge graph completion datasets extracted from <a href=https://en.wikipedia.org/wiki/Wikidata>Wikidata</a> and <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a> that improve upon existing knowledge graph completion benchmarks in scope and level of difficulty. In terms of scope, CoDEx comprises three <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graphs</a> varying in size and structure, multilingual descriptions of entities and relations, and tens of thousands of hard negative triples that are plausible but verified to be false. To characterize CoDEx, we contribute thorough empirical analyses and benchmarking experiments. First, we analyze each CoDEx dataset in terms of logical relation patterns. Next, we report baseline link prediction and triple classification results on CoDEx for five extensively tuned embedding models. Finally, we differentiate CoDEx from the popular FB15K-237 knowledge graph completion dataset by showing that CoDEx covers more diverse and interpretable content, and is a more difficult link prediction benchmark. Data, code, and pretrained models are available at https://bit.ly/2EPbrJs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.675.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--675 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.675 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939007 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.675/>Towards Modeling Revision Requirements in wikiHow Instructions<span class=acl-fixed-case>H</span>ow Instructions</a></strong><br><a href=/people/i/irshad-bhat/>Irshad Bhat</a>
|
<a href=/people/t/talita-anthonio/>Talita Anthonio</a>
|
<a href=/people/m/michael-roth/>Michael Roth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--675><div class="card-body p-3 small">wikiHow is a resource of how-to guidesthat describe the steps necessary to accomplish a goal. Guides in this resource are regularly edited by a community of users, who try to improve instructions in terms of style, clarity and correctness. In this work, we test whether the need for such <a href=https://en.wikipedia.org/wiki/Editing>edits</a> can be predicted automatically. For this <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>, we extend an existing <a href=https://en.wikipedia.org/wiki/Resource>resource</a> of textual edits with a complementary set of approx. 4 million sentences that remain unedited over time and report on the outcome of two revision modeling experiments.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.677.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--677 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.677 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939257 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.677/>Natural Language Processing for Achieving <a href=https://en.wikipedia.org/wiki/Sustainable_development>Sustainable Development</a> : the Case of Neural Labelling to Enhance Community Profiling</a></strong><br><a href=/people/c/costanza-conforti/>Costanza Conforti</a>
|
<a href=/people/s/stephanie-hirmer/>Stephanie Hirmer</a>
|
<a href=/people/d/dai-morgan/>Dai Morgan</a>
|
<a href=/people/m/marco-basaldella/>Marco Basaldella</a>
|
<a href=/people/y/yau-ben-or/>Yau Ben Or</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--677><div class="card-body p-3 small">In recent years, there has been an increasing interest in the application of <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>Artificial Intelligence</a> and especially <a href=https://en.wikipedia.org/wiki/Machine_learning>Machine Learning</a> to the field of Sustainable Development (SD). However, until now, <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP</a> has not been systematically applied in this context. In this paper, we show the high potential of <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP</a> to enhance project sustainability. In particular, we focus on the case of community profiling in <a href=https://en.wikipedia.org/wiki/Developing_country>developing countries</a>, where, in contrast to the developed world, a notable data gap exists. Here, <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> could help to address the cost and time barrier of structuring <a href=https://en.wikipedia.org/wiki/Qualitative_data>qualitative data</a> that prohibits its widespread use and associated benefits. We propose the new extreme multi-class multi-label Automatic UserPerceived Value classification task. We release Stories2Insights, an expert-annotated dataset of interviews carried out in Uganda, we provide a detailed corpus analysis, and we implement a number of strong neural baselines to address the task. Experimental results show that the problem is challenging, and leaves considerable room for future research at the intersection of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> and <a href=https://en.wikipedia.org/wiki/Sensory_processing>SD</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.678.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--678 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.678 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939368 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.678/>To Schedule or not to Schedule : Extracting Task Specific Temporal Entities and Associated Negation Constraints</a></strong><br><a href=/people/b/barun-patra/>Barun Patra</a>
|
<a href=/people/c/chala-fufa/>Chala Fufa</a>
|
<a href=/people/p/pamela-bhattacharya/>Pamela Bhattacharya</a>
|
<a href=/people/c/charles-c-lee/>Charles Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--678><div class="card-body p-3 small">State of the art research for date-time entity extraction from text is task agnostic. Consequently, while the methods proposed in literature perform well for generic date-time extraction from texts, they do n&#8217;t fare as well on task specific date-time entity extraction where only a subset of the date-time entities present in the text are pertinent to solving the task. Furthermore, some <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> require identifying negation constraints associated with the date-time entities to correctly reason over time. We showcase a novel <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> for extracting task-specific date-time entities along with their negation constraints. We show the efficacy of our method on the task of date-time understanding in the context of scheduling meetings for an email-based digital AI scheduling assistant. Our method achieves an absolute gain of 19 % f-score points compared to baseline methods in detecting the date-time entities relevant to scheduling meetings and a 4 % improvement over baseline methods for detecting negation constraints over date-time entities.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.684.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--684 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.684 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938735 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.684" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.684/>Exploring Semantic Capacity of Terms</a></strong><br><a href=/people/j/jie-huang/>Jie Huang</a>
|
<a href=/people/z/zilong-wang/>Zilong Wang</a>
|
<a href=/people/k/kevin-chang/>Kevin Chang</a>
|
<a href=/people/w/wen-mei-hwu/>Wen-mei Hwu</a>
|
<a href=/people/j/jinjun-xiong/>JinJun Xiong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--684><div class="card-body p-3 small">We introduce and study semantic capacity of terms. For example, the semantic capacity of <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>artificial intelligence</a> is higher than that of <a href=https://en.wikipedia.org/wiki/Linear_regression>linear regression</a> since <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>artificial intelligence</a> possesses a broader meaning scope. Understanding semantic capacity of terms will help many downstream tasks in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. For this purpose, we propose a two-step model to investigate semantic capacity of terms, which takes a large text corpus as input and can evaluate semantic capacity of terms if the <a href=https://en.wikipedia.org/wiki/Text_corpus>text corpus</a> can provide enough co-occurrence information of terms. Extensive experiments in three fields demonstrate the effectiveness and rationality of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> compared with well-designed baselines and human-level evaluations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.689.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--689 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.689 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938936 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.689" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.689/>Exploring Contextualized Neural Language Models for Temporal Dependency Parsing<span class=acl-fixed-case>E</span>xploring <span class=acl-fixed-case>C</span>ontextualized <span class=acl-fixed-case>N</span>eural <span class=acl-fixed-case>L</span>anguage <span class=acl-fixed-case>M</span>odels for <span class=acl-fixed-case>T</span>emporal <span class=acl-fixed-case>D</span>ependency <span class=acl-fixed-case>P</span>arsing</a></strong><br><a href=/people/h/hayley-ross/>Hayley Ross</a>
|
<a href=/people/j/jonathon-cai/>Jonathon Cai</a>
|
<a href=/people/b/bonan-min/>Bonan Min</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--689><div class="card-body p-3 small">Extracting temporal relations between events and time expressions has many applications such as constructing event timelines and time-related question answering. It is a challenging problem which requires syntactic and semantic information at sentence or discourse levels, which may be captured by deep contextualized language models (LMs) such as BERT (Devlin et al., 2019). In this paper, we develop several variants of BERT-based temporal dependency parser, and show that BERT significantly improves temporal dependency parsing (Zhang and Xue, 2018a). We also present a detailed analysis on why deep contextualized neural LMs help and where they may fall short. Source code and resources are made available at https://github.com/bnmin/tdp_ranking.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.692.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--692 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.692 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938992 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.692" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.692/>AxCell : Automatic Extraction of Results from Machine Learning Papers<span class=acl-fixed-case>AxCell</span>: Automatic Extraction of Results from Machine Learning Papers</a></strong><br><a href=/people/m/marcin-kardas/>Marcin Kardas</a>
|
<a href=/people/p/piotr-czapla/>Piotr Czapla</a>
|
<a href=/people/p/pontus-stenetorp/>Pontus Stenetorp</a>
|
<a href=/people/s/sebastian-ruder/>Sebastian Ruder</a>
|
<a href=/people/s/sebastian-riedel/>Sebastian Riedel</a>
|
<a href=/people/r/ross-taylor/>Ross Taylor</a>
|
<a href=/people/r/robert-stojnic/>Robert Stojnic</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--692><div class="card-body p-3 small">Tracking progress in <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning</a> has become increasingly difficult with the recent explosion in the number of papers. In this paper, we present AxCell, an automatic machine learning pipeline for extracting results from papers. AxCell uses several novel components, including a table segmentation subtask, to learn relevant structural knowledge that aids extraction. When compared with existing <a href=https://en.wikipedia.org/wiki/Methodology>methods</a>, our approach significantly improves the state of the art for results extraction. We also release a structured, annotated dataset for training <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> for results extraction, and a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for evaluating the performance of <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> on this task. Lastly, we show the viability of our approach enables it to be used for semi-automated results extraction in production, suggesting our improvements make this task practically viable for the first time. Code is available on GitHub.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.695.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--695 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.695 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939421 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.695/>Incremental Neural Coreference Resolution in Constant Memory</a></strong><br><a href=/people/p/patrick-xia/>Patrick Xia</a>
|
<a href=/people/j/joao-sedoc/>Joo Sedoc</a>
|
<a href=/people/b/benjamin-van-durme/>Benjamin Van Durme</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--695><div class="card-body p-3 small">We investigate modeling coreference resolution under a fixed memory constraint by extending an incremental clustering algorithm to utilize contextualized encoders and neural components. Given a new sentence, our <a href=https://en.wikipedia.org/wiki/End-to-end_principle>end-to-end algorithm</a> proposes and scores each mention span against explicit entity representations created from the earlier document context (if any). These spans are then used to update the entity&#8217;s representations before being forgotten ; we only retain a fixed set of salient entities throughout the document. In this work, we successfully convert a high-performing model (Joshi et al., 2020), asymptotically reducing its memory usage to constant space with only a 0.3 % relative loss in F1 on OntoNotes 5.0.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.697.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--697 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.697 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938913 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.697" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.697/>KGPT : Knowledge-Grounded Pre-Training for Data-to-Text Generation<span class=acl-fixed-case>KGPT</span>: Knowledge-Grounded Pre-Training for Data-to-Text Generation</a></strong><br><a href=/people/w/wenhu-chen/>Wenhu Chen</a>
|
<a href=/people/y/yu-su/>Yu Su</a>
|
<a href=/people/x/xifeng-yan/>Xifeng Yan</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--697><div class="card-body p-3 small">Data-to-text generation has recently attracted substantial interests due to its wide applications. Existing methods have shown impressive performance on an array of <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a>. However, they rely on a significant amount of labeled data for each <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>, which is costly to acquire and thus limits their application to new <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a> and domains. In this paper, we propose to leverage pre-training and transfer learning to address this issue. We propose a knowledge-grounded pre-training (KGPT), which consists of two parts, 1) a general knowledge-grounded generation model to generate knowledge-enriched text. 2) a pre-training paradigm on a massive knowledge-grounded text corpus crawled from the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>web</a>. The pre-trained model can be fine-tuned on various data-to-text generation tasks to generate task-specific text. We adopt three settings, namely fully-supervised, zero-shot, few-shot to evaluate its effectiveness. Under the fully-supervised setting, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can achieve remarkable gains over the known baselines. Under zero-shot setting, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> without seeing any examples achieves over 30 ROUGE-L on WebNLG while all other baselines fail. Under the few-shot setting, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> only needs about one-fifteenth as many labeled examples to achieve the same level of performance as baseline models. These experiments consistently prove the strong generalization ability of our proposed <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.698.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--698 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.698 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938973 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.698" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.698/>POINTER : Constrained Progressive Text Generation via Insertion-based Generative Pre-training<span class=acl-fixed-case>POINTER</span>: Constrained Progressive Text Generation via Insertion-based Generative Pre-training</a></strong><br><a href=/people/y/yizhe-zhang/>Yizhe Zhang</a>
|
<a href=/people/g/guoyin-wang/>Guoyin Wang</a>
|
<a href=/people/c/chunyuan-li/>Chunyuan Li</a>
|
<a href=/people/z/zhe-gan/>Zhe Gan</a>
|
<a href=/people/c/chris-brockett/>Chris Brockett</a>
|
<a href=/people/w/william-b-dolan/>Bill Dolan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--698><div class="card-body p-3 small">Large-scale pre-trained language models, such as BERT and GPT-2, have achieved excellent performance in language representation learning and free-form text generation. However, these <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> can not be directly employed to generate text under specified <a href=https://en.wikipedia.org/wiki/Lexical_analysis>lexical constraints</a>. To address this challenge, we present POINTER (PrOgressive INsertion-based TransformER), a simple yet novel insertion-based approach for hard-constrained text generation. The proposed <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> operates by progressively inserting new tokens between existing tokens in a parallel manner. This procedure is recursively applied until a sequence is completed. The resulting coarse-to-fine hierarchy makes the generation process intuitive and interpretable. We pre-train our model with the proposed progressive insertion-based objective on a 12 GB Wikipedia dataset, and fine-tune it on downstream hard-constrained generation tasks. Non-autoregressive decoding yields a <a href=https://en.wikipedia.org/wiki/Time_complexity>logarithmic time complexity</a> during <a href=https://en.wikipedia.org/wiki/Time_complexity>inference time</a>. Experimental results on both News and Yelp datasets demonstrate that Pointer achieves state-of-the-art performance on constrained text generation. We released the <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>pre-trained models</a> and the source code to facilitate future research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.706.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--706 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.706 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939207 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.706" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.706/>What is More Likely to Happen Next? Video-and-Language Future Event Prediction</a></strong><br><a href=/people/j/jie-lei/>Jie Lei</a>
|
<a href=/people/l/licheng-yu/>Licheng Yu</a>
|
<a href=/people/t/tamara-berg/>Tamara Berg</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--706><div class="card-body p-3 small">Given a video with aligned dialogue, people can often infer what is more likely to happen next. Making such predictions requires not only a deep understanding of the rich dynamics underlying the <a href=https://en.wikipedia.org/wiki/Video>video</a> and dialogue, but also a significant amount of <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a>. In this work, we explore whether <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>AI models</a> are able to learn to make such multimodal commonsense next-event predictions. To support research in this direction, we collect a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, named Video-and-Language Event Prediction (VLEP), with 28,726 future event prediction examples (along with their rationales) from 10,234 diverse <a href=https://en.wikipedia.org/wiki/Television_show>TV Show</a> and <a href=https://en.wikipedia.org/wiki/Vlog>YouTube Lifestyle Vlog video clips</a>. In order to promote the collection of non-trivial challenging examples, we employ an adversarial human-and-model-in-the-loop data collection procedure. We also present a strong <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> incorporating information from <a href=https://en.wikipedia.org/wiki/Video>video</a>, <a href=https://en.wikipedia.org/wiki/Dialogue>dialogue</a>, and <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a>. Experiments show that each type of <a href=https://en.wikipedia.org/wiki/Information>information</a> is useful for this challenging task, and that compared to the high human performance on VLEP, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> provides a good starting point but leaves large room for future work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.708.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--708 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.708 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939350 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.708/>Towards Understanding Sample Variance in Visually Grounded Language Generation : Evaluations and Observations</a></strong><br><a href=/people/w/wanrong-zhu/>Wanrong Zhu</a>
|
<a href=/people/x/xin-wang/>Xin Wang</a>
|
<a href=/people/p/pradyumna-narayana/>Pradyumna Narayana</a>
|
<a href=/people/k/kazoo-sone/>Kazoo Sone</a>
|
<a href=/people/s/sugato-basu/>Sugato Basu</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--708><div class="card-body p-3 small">A major challenge in visually grounded language generation is to build robust benchmark datasets and <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that can generalize well in real-world settings. To do this, it is critical to ensure that our evaluation protocols are correct, and <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmarks</a> are reliable. In this work, we set forth to design a set of experiments to understand an important but often ignored problem in visually grounded language generation : given that humans have different utilities and <a href=https://en.wikipedia.org/wiki/Attention>visual attention</a>, how will the <a href=https://en.wikipedia.org/wiki/Variance>sample variance</a> in multi-reference datasets affect the models&#8217; performance? Empirically, we study several multi-reference datasets and corresponding vision-and-language tasks. We show that it is of paramount importance to report variance in experiments ; that human-generated references could vary drastically in different datasets / tasks, revealing the nature of each task ; that metric-wise, CIDEr has shown systematically larger variances than others. Our evaluations on reference-per-instance shed light on the design of reliable datasets in the future.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.714.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--714 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.714 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938731 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.714" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.714/>SRLGRN : Semantic Role Labeling Graph Reasoning Network<span class=acl-fixed-case>SRLGRN</span>: Semantic Role Labeling Graph Reasoning Network</a></strong><br><a href=/people/c/chen-zheng/>Chen Zheng</a>
|
<a href=/people/p/parisa-kordjamshidi/>Parisa Kordjamshidi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--714><div class="card-body p-3 small">This work deals with the challenge of learning and reasoning over multi-hop question answering (QA). We propose a graph reasoning network based on the semantic structure of the sentences to learn cross paragraph reasoning paths and find the supporting facts and the answer jointly. The proposed <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a> is a heterogeneous document-level graph that contains nodes of type sentence (question, title, and other sentences), and semantic role labeling sub-graphs per sentence that contain arguments as nodes and predicates as edges. Incorporating the argument types, the argument phrases, and the semantics of the edges originated from SRL predicates into the graph encoder helps in finding and also the explainability of the reasoning paths. Our proposed approach shows competitive performance on the HotpotQA distractor setting benchmark compared to the recent state-of-the-art models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.723.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--723 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.723 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938819 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.723/>Named Entity Recognition Only from Word Embeddings</a></strong><br><a href=/people/y/ying-luo/>Ying Luo</a>
|
<a href=/people/h/hai-zhao/>Hai Zhao</a>
|
<a href=/people/j/junlang-zhan/>Junlang Zhan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--723><div class="card-body p-3 small">Deep neural network models have helped <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a> achieve amazing performance without handcrafting features. However, existing <a href=https://en.wikipedia.org/wiki/System>systems</a> require large amounts of human annotated training data. Efforts have been made to replace <a href=https://en.wikipedia.org/wiki/Annotation>human annotations</a> with external knowledge (e.g., NE dictionary, <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tags</a>), while it is another challenge to obtain such effective resources. In this work, we propose a fully unsupervised NE recognition model which only needs to take informative clues from pre-trained word embeddings. We first apply Gaussian Hidden Markov Model and Deep Autoencoding Gaussian Mixture Model on word embeddings for entity span detection and type prediction, and then further design an instance selector based on <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a> to distinguish positive sentences from noisy sentences and then refine these coarse-grained annotations through neural networks. Extensive experiments on two CoNLL benchmark NER datasets (CoNLL-2003 English dataset and CoNLL-2002 Spanish dataset) demonstrate that our proposed light NE recognition model achieves remarkable performance without using any annotated lexicon or corpus.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.724.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--724 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.724 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938946 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.724" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.724/>Text Classification Using Label Names Only : A Language Model Self-Training Approach</a></strong><br><a href=/people/y/yu-meng/>Yu Meng</a>
|
<a href=/people/y/yunyi-zhang/>Yunyi Zhang</a>
|
<a href=/people/j/jiaxin-huang/>Jiaxin Huang</a>
|
<a href=/people/c/chenyan-xiong/>Chenyan Xiong</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/c/chao-zhang/>Chao Zhang</a>
|
<a href=/people/j/jiawei-han/>Jiawei Han</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--724><div class="card-body p-3 small">Current text classification methods typically require a good number of human-labeled documents as training data, which can be costly and difficult to obtain in real applications. Humans can perform <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> without seeing any labeled examples but only based on a small set of words describing the categories to be classified. In this paper, we explore the potential of only using the label name of each class to train <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification models</a> on unlabeled data, without using any labeled documents. We use pre-trained neural language models both as general linguistic knowledge sources for <a href=https://en.wikipedia.org/wiki/Categorization>category understanding</a> and as <a href=https://en.wikipedia.org/wiki/Representation_learning>representation learning models</a> for <a href=https://en.wikipedia.org/wiki/Document_classification>document classification</a>. Our method (1) associates semantically related words with the label names, (2) finds category-indicative words and trains the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to predict their implied categories, and (3) generalizes the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> via self-training. We show that our model achieves around 90 % accuracy on four benchmark datasets including topic and sentiment classification without using any labeled documents but learning from unlabeled data supervised by at most 3 words (1 in most cases) per class as the label name.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.728.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--728 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.728 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939242 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.728/>PyMT5 : multi-mode translation of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language</a> and <a href=https://en.wikipedia.org/wiki/Python_(programming_language)>Python code</a> with transformers<span class=acl-fixed-case>P</span>y<span class=acl-fixed-case>MT</span>5: multi-mode translation of natural language and Python code with transformers</a></strong><br><a href=/people/c/colin-clement/>Colin Clement</a>
|
<a href=/people/d/dawn-drain/>Dawn Drain</a>
|
<a href=/people/j/jonathan-timcheck/>Jonathan Timcheck</a>
|
<a href=/people/a/alexey-svyatkovskiy/>Alexey Svyatkovskiy</a>
|
<a href=/people/n/neel-sundaresan/>Neel Sundaresan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--728><div class="card-body p-3 small">Simultaneously modeling <a href=https://en.wikipedia.org/wiki/Source_code>source code</a> and <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a> has many exciting applications in automated software development and understanding. Pursuant to achieving such technology, we introduce PyMT5, the Python method text-to-text transfer transformer, which is trained to translate between all pairs of Python method feature combinations : a single model that can both predict whole methods from natural language documentation strings (docstrings) and summarize code into docstrings of any common style. We present an analysis and modeling effort of a large-scale parallel corpus of 26 million <a href=https://en.wikipedia.org/wiki/Python_(programming_language)>Python methods</a> and 7.7 million method-docstring pairs, demonstrating that for docstring and method generation, PyMT5 outperforms similarly-sized auto-regressive language models (GPT2) which were English pre-trained or randomly initialized. On the CodeSearchNet test set, our best model predicts 92.1 % syntactically correct method bodies, achieved a <a href=https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms>BLEU score</a> of 8.59 for method generation and 16.3 for <a href=https://en.wikipedia.org/wiki/Docstring>docstring generation (summarization)</a>, and achieved a ROUGE-L F-score of 24.8 for method generation and 36.7 for <a href=https://en.wikipedia.org/wiki/Docstring>docstring generation</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.731.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--731 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.731 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939064 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.731" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.731/>COGS : A Compositional Generalization Challenge Based on Semantic Interpretation<span class=acl-fixed-case>COGS</span>: A Compositional Generalization Challenge Based on Semantic Interpretation</a></strong><br><a href=/people/n/najoung-kim/>Najoung Kim</a>
|
<a href=/people/t/tal-linzen/>Tal Linzen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--731><div class="card-body p-3 small">Natural language is characterized by <a href=https://en.wikipedia.org/wiki/Compositionality>compositionality</a> : the meaning of a complex expression is constructed from the meanings of its constituent parts. To facilitate the evaluation of the compositional abilities of language processing architectures, we introduce COGS, a semantic parsing dataset based on a fragment of English. The evaluation portion of COGS contains multiple systematic gaps that can only be addressed by compositional generalization ; these include new combinations of familiar syntactic structures, or new combinations of familiar words and familiar structures. In experiments with Transformers and LSTMs, we found that in-distribution accuracy on the COGS test set was near-perfect (9699 %), but generalization accuracy was substantially lower (1635 %) and showed high sensitivity to random seed (+ -68 %). These findings indicate that contemporary standard NLP models are limited in their compositional generalization capacity, and position COGS as a good way to measure progress.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.732.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--732 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.732 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939113 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.732/>An Analysis of Natural Language Inference Benchmarks through the Lens of Negation</a></strong><br><a href=/people/m/md-mosharaf-hossain/>Md Mosharaf Hossain</a>
|
<a href=/people/v/venelin-kovatchev/>Venelin Kovatchev</a>
|
<a href=/people/p/pranoy-dutta/>Pranoy Dutta</a>
|
<a href=/people/t/tiffany-kao/>Tiffany Kao</a>
|
<a href=/people/e/elizabeth-wei/>Elizabeth Wei</a>
|
<a href=/people/e/eduardo-blanco/>Eduardo Blanco</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--732><div class="card-body p-3 small">Negation is underrepresented in existing natural language inference benchmarks. Additionally, one can often ignore the few negations in existing <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmarks</a> and still make the right inference judgments. In this paper, we present a new <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmark</a> for <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language inference</a> in which <a href=https://en.wikipedia.org/wiki/Affirmation_and_negation>negation</a> plays a critical role. We also show that state-of-the-art transformers struggle making inference judgments with the new pairs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.733.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--733 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.733 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939378 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.733" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.733/>On the Sentence Embeddings from Pre-trained Language Models</a></strong><br><a href=/people/b/bohan-li/>Bohan Li</a>
|
<a href=/people/h/hao-zhou/>Hao Zhou</a>
|
<a href=/people/j/junxian-he/>Junxian He</a>
|
<a href=/people/m/mingxuan-wang/>Mingxuan Wang</a>
|
<a href=/people/y/yiming-yang/>Yiming Yang</a>
|
<a href=/people/l/lei-li/>Lei Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--733><div class="card-body p-3 small">Pre-trained contextual representations like <a href=https://en.wikipedia.org/wiki/BERT>BERT</a> have achieved great success in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. However, the <a href=https://en.wikipedia.org/wiki/Sentence_embedding>sentence embeddings</a> from the pre-trained language models without <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> have been found to poorly capture semantic meaning of sentences. In this paper, we argue that the <a href=https://en.wikipedia.org/wiki/Semantics>semantic information</a> in the BERT embeddings is not fully exploited. We first reveal the theoretical connection between the masked language model pre-training objective and the semantic similarity task theoretically, and then analyze the BERT sentence embeddings empirically. We find that BERT always induces a non-smooth anisotropic semantic space of sentences, which harms its performance of <a href=https://en.wikipedia.org/wiki/Semantic_similarity>semantic similarity</a>. To address this issue, we propose to transform the anisotropic sentence embedding distribution to a smooth and isotropic Gaussian distribution through normalizing flows that are learned with an <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised objective</a>. Experimental results show that our proposed BERT-flow method obtains significant performance gains over the state-of-the-art sentence embeddings on a variety of semantic textual similarity tasks. The code is available at.<url>https://github.com/bohanli/BERT-flow</url>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.738.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--738 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.738 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939283 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.738" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.738/>Partially-Aligned Data-to-Text Generation with Distant Supervision</a></strong><br><a href=/people/z/zihao-fu/>Zihao Fu</a>
|
<a href=/people/b/bei-shi/>Bei Shi</a>
|
<a href=/people/w/wai-lam/>Wai Lam</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/z/zhiyuan-liu/>Zhiyuan Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--738><div class="card-body p-3 small">The Data-to-Text task aims to generate <a href=https://en.wikipedia.org/wiki/Human-readable_medium>human-readable text</a> for describing some given structured data enabling more interpretability. However, the typical generation task is confined to a few particular domains since it requires well-aligned data which is difficult and expensive to obtain. Using partially-aligned data is an alternative way of solving the dataset scarcity problem. This kind of <a href=https://en.wikipedia.org/wiki/Data>data</a> is much easier to obtain since <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> can be produced automatically. However, using this kind of <a href=https://en.wikipedia.org/wiki/Data>data</a> induces the over-generation problem posing difficulties for existing <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>, which tends to add unrelated excerpts during the generation procedure. In order to effectively utilize automatically annotated partially-aligned datasets, we extend the traditional generation task to a refined task called Partially-Aligned Data-to-Text Generation (PADTG) which is more practical since it utilizes automatically annotated data for training and thus considerably expands the application domains. To tackle this new <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, we propose a novel distant supervision generation framework. It firstly estimates the input data&#8217;s supportiveness for each target word with an <a href=https://en.wikipedia.org/wiki/Estimator>estimator</a> and then applies a supportiveness adaptor and a rebalanced beam search to harness the over-generation problem in the training and generation phases respectively. We also contribute a partially-aligned dataset (The data and source code of this paper can be obtained from https://github.com/fuzihaofzh/distant_supervision_nlg) by sampling sentences from <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a> and automatically extracting corresponding KB triples for each sentence from <a href=https://en.wikipedia.org/wiki/Wikidata>Wikidata</a>. The experimental results show that our <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> outperforms all baseline models as well as verify the feasibility of utilizing partially-aligned data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.739.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--739 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.739 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938989 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.739" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.739/>Like hiking? You probably enjoy nature : Persona-grounded Dialog with Commonsense Expansions</a></strong><br><a href=/people/b/bodhisattwa-prasad-majumder/>Bodhisattwa Prasad Majumder</a>
|
<a href=/people/h/harsh-jhamtani/>Harsh Jhamtani</a>
|
<a href=/people/t/taylor-berg-kirkpatrick/>Taylor Berg-Kirkpatrick</a>
|
<a href=/people/j/julian-mcauley/>Julian McAuley</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--739><div class="card-body p-3 small">Existing persona-grounded dialog models often fail to capture simple implications of given persona descriptions, something which humans are able to do seamlessly. For example, state-of-the-art models can not infer that interest in hiking might imply love for nature or longing for a break. In this paper, we propose to expand available persona sentences using existing commonsense knowledge bases and paraphrasing resources to imbue dialog models with access to an expanded and richer set of persona descriptions. Additionally, we introduce fine-grained grounding on <a href=https://en.wikipedia.org/wiki/Persona>personas</a> by encouraging the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to make a discrete choice among persona sentences while synthesizing a dialog response. Since such a choice is not observed in the data, we model it using a discrete latent random variable and use variational learning to sample from hundreds of persona expansions. Our model outperforms competitive baselines on the Persona-Chat dataset in terms of dialog quality and diversity while achieving persona-consistent and controllable dialog generation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.741.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--741 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.741 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938681 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.741/>The World is Not Binary : Learning to Rank with <a href=https://en.wikipedia.org/wiki/Grayscale>Grayscale Data</a> for Dialogue Response Selection</a></strong><br><a href=/people/z/zibo-lin/>Zibo Lin</a>
|
<a href=/people/d/deng-cai/>Deng Cai</a>
|
<a href=/people/y/yan-wang/>Yan Wang</a>
|
<a href=/people/x/xiaojiang-liu/>Xiaojiang Liu</a>
|
<a href=/people/h/haitao-zheng/>Haitao Zheng</a>
|
<a href=/people/s/shuming-shi/>Shuming Shi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--741><div class="card-body p-3 small">Response selection plays a vital role in building retrieval-based conversation systems. Despite that response selection is naturally a learning-to-rank problem, most prior works take a point-wise view and train binary classifiers for this task : each response candidate is labeled either relevant (one) or irrelevant (zero). On the one hand, this <a href=https://en.wikipedia.org/wiki/Formal_system>formalization</a> can be sub-optimal due to its ignorance of the diversity of response quality. On the other hand, annotating <a href=https://en.wikipedia.org/wiki/Grayscale>grayscale data</a> for learning-to-rank can be prohibitively expensive and challenging. In this work, we show that <a href=https://en.wikipedia.org/wiki/Grayscale>grayscale data</a> can be automatically constructed without human effort. Our method employs off-the-shelf response retrieval models and response generation models as automatic grayscale data generators. With the constructed <a href=https://en.wikipedia.org/wiki/Grayscale>grayscale data</a>, we propose multi-level ranking objectives for training, which can (1) teach a matching model to capture more fine-grained context-response relevance difference and (2) reduce the train-test discrepancy in terms of distractor strength. Our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> is simple, effective, and universal. Experiments on three <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark datasets</a> and four state-of-the-art matching models show that the proposed approach brings significant and consistent performance improvements.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.742.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--742 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.742 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938945 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.742" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.742/>GRADE : Automatic Graph-Enhanced Coherence Metric for Evaluating Open-Domain Dialogue Systems<span class=acl-fixed-case>GRADE</span>: Automatic Graph-Enhanced Coherence Metric for Evaluating Open-Domain Dialogue Systems</a></strong><br><a href=/people/l/lishan-huang/>Lishan Huang</a>
|
<a href=/people/z/zheng-ye/>Zheng Ye</a>
|
<a href=/people/j/jinghui-qin/>Jinghui Qin</a>
|
<a href=/people/l/liang-lin/>Liang Lin</a>
|
<a href=/people/x/xiaodan-liang/>Xiaodan Liang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--742><div class="card-body p-3 small">Automatically evaluating dialogue coherence is a challenging but high-demand ability for developing high-quality open-domain dialogue systems. However, current evaluation metrics consider only surface features or utterance-level semantics, without explicitly considering the fine-grained topic transition dynamics of dialogue flows. Here, we first consider that the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a> constituted with topics in a dialogue can accurately depict the underlying communication logic, which is a more natural way to produce persuasive metrics. Capitalized on the topic-level dialogue graph, we propose a new evaluation metric GRADE, which stands for Graph-enhanced Representations for Automatic Dialogue Evaluation. Specifically, <a href=https://en.wikipedia.org/wiki/GRADE>GRADE</a> incorporates both coarse-grained utterance-level contextualized representations and fine-grained topic-level graph representations to evaluate dialogue coherence. The graph representations are obtained by reasoning over topic-level dialogue graphs enhanced with the evidence from a commonsense graph, including k-hop neighboring representations and hop-attention weights. Experimental results show that our GRADE significantly outperforms other state-of-the-art metrics on measuring diverse dialogue models in terms of the Pearson and Spearman correlations with human judgments. Besides, we release a new large-scale human evaluation benchmark to facilitate future research on <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>automatic metrics</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.748.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--748 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.748 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38938995 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.748/>On Extractive and Abstractive Neural Document Summarization with Transformer Language Models</a></strong><br><a href=/people/j/jonathan-pilault/>Jonathan Pilault</a>
|
<a href=/people/r/raymond-li/>Raymond Li</a>
|
<a href=/people/s/sandeep-subramanian/>Sandeep Subramanian</a>
|
<a href=/people/c/christopher-pal/>Chris Pal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--748><div class="card-body p-3 small">We present a method to produce abstractive summaries of long documents that exceed several thousand words via neural abstractive summarization. We perform a simple extractive step before generating a summary, which is then used to condition the transformer language model on relevant information before being tasked with generating a summary. We also show that this approach produces more abstractive summaries compared to prior work that employs a copy mechanism while still achieving higher ROUGE scores. We provide extensive comparisons with strong baseline methods, prior state of the art work as well as multiple variants of our approach including those using only transformers, only extractive techniques and combinations of the two. We examine these models using four different summarization tasks and datasets : <a href=https://en.wikipedia.org/wiki/ArXiv>arXiv papers</a>, <a href=https://en.wikipedia.org/wiki/PubMed>PubMed papers</a>, the Newsroom and BigPatent datasets. We find that transformer based methods produce summaries with fewer n-gram copies, leading to n-gram copying statistics that are more similar to human generated abstracts. We include a human evaluation, finding that transformers are ranked highly for <a href=https://en.wikipedia.org/wiki/Coherence_(linguistics)>coherence</a> and <a href=https://en.wikipedia.org/wiki/Fluency>fluency</a>, but purely extractive methods score higher for informativeness and <a href=https://en.wikipedia.org/wiki/Relevance>relevance</a>. We hope that these <a href=https://en.wikipedia.org/wiki/Computer_architecture>architectures</a> and experiments may serve as strong points of comparison for future work. Note : The abstract above was collaboratively written by the authors and one of the models presented in this paper based on an earlier draft of this paper.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.emnlp-main.751.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--emnlp-main--751 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.emnlp-main.751 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939364 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.emnlp-main.751" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.emnlp-main.751/>Re-evaluating Evaluation in Text Summarization</a></strong><br><a href=/people/m/manik-bhandari/>Manik Bhandari</a>
|
<a href=/people/p/pranav-narayan-gour/>Pranav Narayan Gour</a>
|
<a href=/people/a/atabak-ashfaq/>Atabak Ashfaq</a>
|
<a href=/people/p/pengfei-liu/>Pengfei Liu</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--emnlp-main--751><div class="card-body p-3 small">Automated evaluation metrics as a stand-in for manual evaluation are an essential part of the development of text-generation tasks such as <a href=https://en.wikipedia.org/wiki/Automatic_summarization>text summarization</a>. However, while the field has progressed, our standard <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> have not for nearly 20 years ROUGE has been the standard evaluation in most summarization papers. In this paper, we make an attempt to re-evaluate the evaluation method for <a href=https://en.wikipedia.org/wiki/Automatic_summarization>text summarization</a> : assessing the reliability of automatic metrics using top-scoring system outputs, both abstractive and extractive, on recently popular datasets for both system-level and summary-level evaluation settings. We find that conclusions about evaluation metrics on older datasets do not necessarily hold on modern datasets and systems. We release a dataset of human judgments that are collected from 25 top-scoring neural summarization systems (14 abstractive and 11 extractive).</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright &nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>