<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/P19-4.pdf>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts</a></h2><p class=lead><a href=/people/p/preslav-nakov/>Preslav Nakov</a>,
<a href=/people/a/alexis-palmer/>Alexis Palmer</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>P19-4</dd><dt>Month:</dt><dd>July</dd><dt>Year:</dt><dd>2019</dd><dt>Address:</dt><dd>Florence, Italy</dd><dt>Venue:</dt><dd><a href=/venues/acl/>ACL</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/P19-4>https://aclanthology.org/P19-4</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/P19-4.pdf>https://aclanthology.org/P19-4.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/P19-4.pdf title="Open PDF of 'Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+57th+Annual+Meeting+of+the+Association+for+Computational+Linguistics%3A+Tutorial+Abstracts" title="Search for 'Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-4000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-4000/>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts</a></strong><br><a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/a/alexis-palmer/>Alexis Palmer</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-4002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-4002 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-4002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-4002" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-4002/>Graph-Based Meaning Representations : Design and Processing</a></strong><br><a href=/people/a/alexander-koller/>Alexander Koller</a>
|
<a href=/people/s/stephan-oepen/>Stephan Oepen</a>
|
<a href=/people/w/weiwei-sun/>Weiwei Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-4002><div class="card-body p-3 small">This tutorial is on representing and processing <a href=https://en.wikipedia.org/wiki/Sentence_(mathematical_logic)>sentence meaning</a> in the form of labeled directed graphs. The tutorial will (a) briefly review relevant background in formal and linguistic semantics ; (b) semi-formally define a unified abstract view on different flavors of semantic graphs and associated terminology ; (c) survey common frameworks for graph-based meaning representation and available graph banks ; and (d) offer a technical overview of a representative selection of different parsing approaches.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-4004.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-4004 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-4004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-4004/>Computational Analysis of Political Texts : Bridging Research Efforts Across Communities</a></strong><br><a href=/people/g/goran-glavas/>Goran Glava≈°</a>
|
<a href=/people/f/federico-nanni/>Federico Nanni</a>
|
<a href=/people/s/simone-paolo-ponzetto/>Simone Paolo Ponzetto</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-4004><div class="card-body p-3 small">In the last twenty years, political scientists started adopting and developing natural language processing (NLP) methods more actively in order to exploit <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>text</a> as an additional source of data in their analyses. Over the last decade the usage of computational methods for analysis of political texts has drastically expanded in scope, allowing for a sustained growth of the text-as-data community in <a href=https://en.wikipedia.org/wiki/Political_science>political science</a>. In <a href=https://en.wikipedia.org/wiki/Political_science>political science</a>, NLP methods have been extensively used for a number of analyses types and tasks, including inferring policy position of actors from textual evidence, detecting topics in <a href=https://en.wikipedia.org/wiki/Political_philosophy>political texts</a>, and analyzing stylistic aspects of <a href=https://en.wikipedia.org/wiki/Political_philosophy>political texts</a> (e.g., assessing the role of <a href=https://en.wikipedia.org/wiki/Ambiguity>language ambiguity</a> in framing the political agenda). Just like in numerous other domains, much of the work on computational analysis of political texts has been enabled and facilitated by the development of resources such as, the topically coded electoral programmes (e.g., the Manifesto Corpus) or topically coded legislative texts (e.g., the Comparative Agenda Project). Political scientists created resources and used available NLP methods to process textual data largely in isolation from the NLP community. At the same time, NLP researchers addressed closely related tasks such as election prediction, ideology classification, and stance detection. In other words, these two communities have been largely agnostic of one another, with NLP researchers mostly unaware of interesting applications in <a href=https://en.wikipedia.org/wiki/Political_science>political science</a> and political scientists not applying cutting-edge NLP methodology to their problems. The main goal of this tutorial is to systematize and analyze the body of research work on political texts from both communities. We aim to provide a gentle, all-round introduction to methods and tasks related to computational analysis of political texts. Our vision is to bring the two research communities closer to each other and contribute to faster and more significant developments in this interdisciplinary research area.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-4005.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-4005 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-4005 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-4005/>Wikipedia as a Resource for Text Analysis and Retrieval<span class=acl-fixed-case>W</span>ikipedia as a Resource for Text Analysis and Retrieval</a></strong><br><a href=/people/m/marius-pasca/>Marius Pasca</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-4005><div class="card-body p-3 small">This tutorial examines the role of <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a> in tasks related to text analysis and retrieval. Text analysis tasks, which take advantage of Wikipedia, include <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a>, <a href=https://en.wikipedia.org/wiki/Word_sense>word sense</a> and <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity disambiguation</a> and <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction</a>. In <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval</a>, a better understanding of the structure and meaning of queries helps in matching queries against documents, clustering search results, answer and entity retrieval and retrieving knowledge panels for queries asking about popular entities.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-4006.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-4006 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-4006 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-4006/>Deep Bayesian Natural Language Processing<span class=acl-fixed-case>B</span>ayesian Natural Language Processing</a></strong><br><a href=/people/j/jen-tzung-chien/>Jen-Tzung Chien</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-4006><div class="card-body p-3 small">This introductory tutorial addresses the advances in deep Bayesian learning for natural language with ubiquitous applications ranging from <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech recognition</a> to <a href=https://en.wikipedia.org/wiki/Document_summarization>document summarization</a>, text classification, <a href=https://en.wikipedia.org/wiki/Text_segmentation>text segmentation</a>, <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction</a>, image caption generation, sentence generation, dialogue control, sentiment classification, <a href=https://en.wikipedia.org/wiki/Recommender_system>recommendation system</a>, <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a> and <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, to name a few. Traditionally, <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> is taken to be a <a href=https://en.wikipedia.org/wiki/Machine_learning>learning process</a> where the inference or optimization is based on the real-valued deterministic model. The semantic structure in words, sentences, entities, actions and documents drawn from a large vocabulary may not be well expressed or correctly optimized in <a href=https://en.wikipedia.org/wiki/Mathematical_logic>mathematical logic</a> or <a href=https://en.wikipedia.org/wiki/Computer_program>computer programs</a>. The <a href=https://en.wikipedia.org/wiki/Cumulative_distribution_function>distribution function</a> in discrete or continuous latent variable model for <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a> may not be properly decomposed or estimated. This tutorial addresses the fundamentals of statistical models and neural networks, and focus on a series of advanced Bayesian models and deep models including <a href=https://en.wikipedia.org/wiki/Hierarchical_Dirichlet_process>hierarchical Dirichlet process</a>, <a href=https://en.wikipedia.org/wiki/Chinese_restaurant_process>Chinese restaurant process</a>, hierarchical Pitman-Yor process, <a href=https://en.wikipedia.org/wiki/Indian_buffet_process>Indian buffet process</a>, <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network</a>, <a href=https://en.wikipedia.org/wiki/Long_short-term_memory>long short-term memory</a>, sequence-to-sequence model, variational auto-encoder, <a href=https://en.wikipedia.org/wiki/Generative_adversarial_network>generative adversarial network</a>, attention mechanism, memory-augmented neural network, skip neural network, <a href=https://en.wikipedia.org/wiki/Stochastic_neural_network>stochastic neural network</a>, predictive state neural network and policy neural network. We present how these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are connected and why they work for a variety of applications on symbolic and complex patterns in natural language. The variational inference and sampling method are formulated to tackle the <a href=https://en.wikipedia.org/wiki/Mathematical_optimization>optimization</a> for complicated models. The <a href=https://en.wikipedia.org/wiki/Word_embedding>word and sentence embeddings</a>, clustering and co-clustering are merged with linguistic and semantic constraints.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-4007.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-4007 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-4007 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-4007/>Unsupervised Cross-Lingual Representation Learning</a></strong><br><a href=/people/s/sebastian-ruder/>Sebastian Ruder</a>
|
<a href=/people/a/anders-sogaard/>Anders S√∏gaard</a>
|
<a href=/people/i/ivan-vulic/>Ivan Vuliƒá</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-4007><div class="card-body p-3 small">In this tutorial, we provide a comprehensive survey of the exciting recent work on cutting-edge weakly-supervised and unsupervised cross-lingual word representations. After providing a brief history of supervised cross-lingual word representations, we focus on : 1) how to induce weakly-supervised and unsupervised cross-lingual word representations in truly resource-poor settings where bilingual supervision can not be guaranteed ; 2) critical examinations of different training conditions and requirements under which unsupervised algorithms can and can not work effectively ; 3) more robust methods for distant language pairs that can mitigate instability issues and low performance for distant language pairs ; 4) how to comprehensively evaluate such representations ; and 5) diverse applications that benefit from cross-lingual word representations (e.g., MT, dialogue, cross-lingual sequence labeling and structured prediction applications, cross-lingual IR).</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ¬©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>