<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the Second Workshop on Gender Bias in Natural Language Processing - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Proceedings of the Second Workshop on Gender Bias in Natural Language Processing</h2><p class=lead><a href=/people/m/marta-r-costa-jussa/>Marta R. Costa-jussà</a>,
<a href=/people/c/christian-hardmeier/>Christian Hardmeier</a>,
<a href=/people/w/will-radford/>Will Radford</a>,
<a href=/people/k/kellie-webster/>Kellie Webster</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2020.gebnlp-1</dd><dt>Month:</dt><dd>December</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Barcelona, Spain (Online)</dd><dt>Venues:</dt><dd><a href=/venues/coling/>COLING</a>
| <a href=/venues/gebnlp/>GeBNLP</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.gebnlp-1>https://aclanthology.org/2020.gebnlp-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+Second+Workshop+on+Gender+Bias+in+Natural+Language+Processing" title="Search for 'Proceedings of the Second Workshop on Gender Bias in Natural Language Processing' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.gebnlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.gebnlp-1.0/>Proceedings of the Second Workshop on Gender Bias in Natural Language Processing</a></strong><br><a href=/people/m/marta-r-costa-jussa/>Marta R. Costa-jussà</a>
|
<a href=/people/c/christian-hardmeier/>Christian Hardmeier</a>
|
<a href=/people/w/will-radford/>Will Radford</a>
|
<a href=/people/k/kellie-webster/>Kellie Webster</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.gebnlp-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--gebnlp-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.gebnlp-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.gebnlp-1.2/>Interdependencies of Gender and Race in Contextualized Word Embeddings</a></strong><br><a href=/people/m/may-jiang/>May Jiang</a>
|
<a href=/people/c/christiane-fellbaum/>Christiane Fellbaum</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--gebnlp-1--2><div class="card-body p-3 small">Recent years have seen a surge in research on the biases in word embeddings with respect to <a href=https://en.wikipedia.org/wiki/Gender>gender</a> and, to a lesser extent, <a href=https://en.wikipedia.org/wiki/Race_(human_categorization)>race</a>. Few of these studies, however, have given attention to the critical intersection of <a href=https://en.wikipedia.org/wiki/Race_(human_categorization)>race</a> and <a href=https://en.wikipedia.org/wiki/Gender>gender</a>. In this case study, we analyze the dimensions of <a href=https://en.wikipedia.org/wiki/Gender>gender</a> and <a href=https://en.wikipedia.org/wiki/Race_(human_categorization)>race</a> in contextualized word embeddings of given names, taken from BERT, and investigate the nature and nuance of their interaction. We find that these demographic axes, though typically treated as physically and conceptually separate, are in fact interdependent and thus inadvisable to consider in isolation. Further, we show that demographic dimensions predicated on default settings in language, such as in <a href=https://en.wikipedia.org/wiki/Pronoun>pronouns</a>, may risk rendering groups with multiple marginalized identities invisible. We conclude by discussing the importance and implications of <a href=https://en.wikipedia.org/wiki/Intersectionality>intersectionality</a> for future studies on <a href=https://en.wikipedia.org/wiki/Bias>bias</a> and debiasing in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.gebnlp-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--gebnlp-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.gebnlp-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.gebnlp-1.3/>Fine-tuning Neural Machine Translation on Gender-Balanced Datasets</a></strong><br><a href=/people/m/marta-r-costa-jussa/>Marta R. Costa-jussà</a>
|
<a href=/people/a/adria-de-jorge/>Adrià de Jorge</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--gebnlp-1--3><div class="card-body p-3 small">Misrepresentation of certain communities in datasets is causing big disruptions in <a href=https://en.wikipedia.org/wiki/List_of_applications_of_artificial_intelligence>artificial intelligence applications</a>. In this paper, we propose using an automatically extracted gender-balanced dataset parallel corpus from <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>. This <a href=https://en.wikipedia.org/wiki/Balanced_set>balanced set</a> is used to perform fine-tuning techniques from a bigger model trained on unbalanced datasets to mitigate gender biases in <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.gebnlp-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--gebnlp-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.gebnlp-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.gebnlp-1.7/>Conversational Assistants and <a href=https://en.wikipedia.org/wiki/Stereotypes_of_East_Asians_in_the_United_States>Gender Stereotypes</a> : Public Perceptions and Desiderata for Voice Personas</a></strong><br><a href=/people/a/amanda-cercas-curry/>Amanda Cercas Curry</a>
|
<a href=/people/j/judy-robertson/>Judy Robertson</a>
|
<a href=/people/v/verena-rieser/>Verena Rieser</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--gebnlp-1--7><div class="card-body p-3 small">Conversational voice assistants are rapidly developing from purely transactional systems to social companions with personality. UNESCO recently stated that the female and submissive personality of current <a href=https://en.wikipedia.org/wiki/Digital_assistant>digital assistants</a> gives rise for concern as it reinforces <a href=https://en.wikipedia.org/wiki/Gender_role>gender stereotypes</a>. In this work, we present results from a participatory design workshop, where we invite people to submit their preferences for a what their ideal persona might look like, both in drawings as well as in a multiple choice questionnaire. We find no clear consensus which suggests that one possible solution is to let people configure / personalise their assistants. We then outline a multi-disciplinary project of how we plan to address the complex question of gender and stereotyping in digital assistants.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>