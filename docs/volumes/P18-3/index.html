<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of ACL 2018, Student Research Workshop - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/P18-3.pdf>Proceedings of <span class=acl-fixed-case>ACL</span> 2018, Student Research Workshop</a></h2><p class=lead><a href=/people/v/vered-shwartz/>Vered Shwartz</a>,
<a href=/people/j/jeniya-tabassum/>Jeniya Tabassum</a>,
<a href=/people/r/rob-voigt/>Rob Voigt</a>,
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>,
<a href=/people/m/marie-catherine-de-marneffe/>Marie-Catherine de Marneffe</a>,
<a href=/people/m/malvina-nissim/>Malvina Nissim</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>P18-3</dd><dt>Month:</dt><dd>July</dd><dt>Year:</dt><dd>2018</dd><dt>Address:</dt><dd>Melbourne, Australia</dd><dt>Venue:</dt><dd><a href=/venues/acl/>ACL</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/P18-3>https://aclanthology.org/P18-3</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/P18-3.pdf>https://aclanthology.org/P18-3.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/P18-3.pdf title="Open PDF of 'Proceedings of ACL 2018, Student Research Workshop'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+ACL+2018%2C+Student+Research+Workshop" title="Search for 'Proceedings of ACL 2018, Student Research Workshop' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-3000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-3000/>Proceedings of <span class=acl-fixed-case>ACL</span> 2018, Student Research Workshop</a></strong><br><a href=/people/v/vered-shwartz/>Vered Shwartz</a>
|
<a href=/people/j/jeniya-tabassum/>Jeniya Tabassum</a>
|
<a href=/people/r/rob-voigt/>Rob Voigt</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/m/marie-catherine-de-marneffe/>Marie-Catherine de Marneffe</a>
|
<a href=/people/m/malvina-nissim/>Malvina Nissim</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-3006.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-3006 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-3006 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-3006/>Recognizing Complex Entity Mentions : A Review and Future Directions</a></strong><br><a href=/people/x/xiang-dai/>Xiang Dai</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-3006><div class="card-body p-3 small">Standard named entity recognizers can effectively recognize entity mentions that consist of contiguous tokens and do not overlap with each other. However, in practice, there are many domains, such as the biomedical domain, in which there are nested, overlapping, and discontinuous entity mentions. These complex mentions can not be directly recognized by conventional sequence tagging models because they may break the assumptions based on which sequence tagging techniques are built. We review the existing methods which are revised to tackle complex entity mentions and categorize them as tokenlevel and sentence-level approaches. We then identify the research gap, and discuss some directions that we are exploring.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-3007.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-3007 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-3007 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-3007/>Automatic Detection of Cross-Disciplinary Knowledge Associations</a></strong><br><a href=/people/m/menasha-thilakaratne/>Menasha Thilakaratne</a>
|
<a href=/people/k/katrina-falkner/>Katrina Falkner</a>
|
<a href=/people/t/thushari-atapattu/>Thushari Atapattu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-3007><div class="card-body p-3 small">Detecting interesting, cross-disciplinary knowledge associations hidden in <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific publications</a> can greatly assist scientists to formulate and validate scientifically sensible novel research hypotheses. This will also introduce new areas of research that can be successfully linked with their research discipline. Currently, this process is mostly performed manually by exploring the <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific publications</a>, requiring a substantial amount of time and effort. Due to the exponential growth of <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific literature</a>, it has become almost impossible for a scientist to keep track of all research advances. As a result, scientists tend to deal with fragments of the literature according to their specialisation. Consequently, important and hidden associations among these fragmented knowledge that can be linked to produce significant scientific discoveries remain unnoticed. This doctoral work aims to develop a novel knowledge discovery approach that suggests most promising research pathways by analysing the existing <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific literature</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-3008.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-3008 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-3008 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-3008/>Language Identification and <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>Named Entity Recognition</a> in Hinglish Code Mixed Tweets<span class=acl-fixed-case>H</span>inglish Code Mixed Tweets</a></strong><br><a href=/people/k/kushagra-singh/>Kushagra Singh</a>
|
<a href=/people/i/indira-sen/>Indira Sen</a>
|
<a href=/people/p/ponnurangam-kumaraguru/>Ponnurangam Kumaraguru</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-3008><div class="card-body p-3 small">While growing code-mixed content on Online Social Networks(OSN) provides a fertile ground for studying various aspects of <a href=https://en.wikipedia.org/wiki/Code-mixing>code-mixing</a>, the lack of automated text analysis tools render such studies challenging. To meet this challenge, a family of tools for analyzing code-mixed data such as language identifiers, parts-of-speech (POS) taggers, chunkers have been developed. Named Entity Recognition (NER) is an important text analysis task which is not only informative by itself, but is also needed for downstream NLP tasks such as <a href=https://en.wikipedia.org/wiki/Semantic_role_labeling>semantic role labeling</a>. In this work, we present an exploration of automatic NER of code-mixed data. We compare our method with existing off-the-shelf NER tools for <a href=https://en.wikipedia.org/wiki/Social_media>social media content</a>, and find that our systems outperforms the best <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> by 33.18 % (F1 score).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-3010.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-3010 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-3010 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-3010/>SuperNMT : <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a> with Semantic Supersenses and Syntactic Supertags<span class=acl-fixed-case>S</span>uper<span class=acl-fixed-case>NMT</span>: Neural Machine Translation with Semantic Supersenses and Syntactic Supertags</a></strong><br><a href=/people/e/eva-vanmassenhove/>Eva Vanmassenhove</a>
|
<a href=/people/a/andy-way/>Andy Way</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-3010><div class="card-body p-3 small">In this paper we incorporate semantic supersensetags and syntactic supertag features into ENFR and ENDE factored NMT systems. In experiments on various test sets, we observe that such <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> (and particularly when combined) help the NMT model training to converge faster and improve the model quality according to the BLEU scores.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-3012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-3012 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-3012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-3012/>Biomedical Document Retrieval for Clinical Decision Support System</a></strong><br><a href=/people/j/jainisha-sankhavara/>Jainisha Sankhavara</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-3012><div class="card-body p-3 small">The availability of huge amount of biomedical literature have opened up new possibilities to apply <a href=https://en.wikipedia.org/wiki/Information_retrieval>Information Retrieval</a> and <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> for mining documents from them. In this work, we are focusing on biomedical document retrieval from literature for <a href=https://en.wikipedia.org/wiki/Clinical_decision_support_system>clinical decision support systems</a>. We compare statistical and NLP based approaches of query reformulation for biomedical document retrieval. Also, we have modeled the biomedical document retrieval as a learning to rank problem. We report initial results for statistical and NLP based query reformulation approaches and learning to rank approach with future direction of research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-3013.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-3013 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-3013 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-3013/>A Computational Approach to <a href=https://en.wikipedia.org/wiki/Feature_extraction>Feature Extraction</a> for Identification of Suicidal Ideation in Tweets</a></strong><br><a href=/people/r/ramit-sawhney/>Ramit Sawhney</a>
|
<a href=/people/p/prachi-manchanda/>Prachi Manchanda</a>
|
<a href=/people/r/raj-singh/>Raj Singh</a>
|
<a href=/people/s/swati-aggarwal/>Swati Aggarwal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-3013><div class="card-body p-3 small">Technological advancements in the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>World Wide Web</a> and <a href=https://en.wikipedia.org/wiki/List_of_social_networking_websites>social networks</a> in particular coupled with an increase in social media usage has led to a positive correlation between the exhibition of <a href=https://en.wikipedia.org/wiki/Suicidal_ideation>Suicidal ideation</a> on websites such as <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> and cases of suicide. This paper proposes a novel supervised approach for detecting <a href=https://en.wikipedia.org/wiki/Suicidal_ideation>suicidal ideation</a> in content on <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>. A set of <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> is proposed for training both linear and ensemble classifiers over a dataset of manually annotated tweets. The performance of the proposed <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> is compared against four <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> that utilize varying approaches to validate its utility. The results are finally summarized by reflecting on the effect of the inclusion of the proposed features one by one for suicidal ideation detection.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-3014.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-3014 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-3014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-3014/>BCSAT : A Benchmark Corpus for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a> in <a href=https://en.wikipedia.org/wiki/Telugu_language>Telugu</a> Using Word-level Annotations<span class=acl-fixed-case>BCSAT</span> : A Benchmark Corpus for Sentiment Analysis in <span class=acl-fixed-case>T</span>elugu Using Word-level Annotations</a></strong><br><a href=/people/s/sreekavitha-parupalli/>Sreekavitha Parupalli</a>
|
<a href=/people/v/vijjini-anvesh-rao/>Vijjini Anvesh Rao</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-3014><div class="card-body p-3 small">The presented work aims at generating a systematically annotated corpus that can support the enhancement of sentiment analysis tasks in <a href=https://en.wikipedia.org/wiki/Telugu_language>Telugu</a> using word-level sentiment annotations. From OntoSenseNet, we extracted 11,000 <a href=https://en.wikipedia.org/wiki/Adjective>adjectives</a>, 253 <a href=https://en.wikipedia.org/wiki/Adverb>adverbs</a>, 8483 verbs and <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment annotation</a> is being done by language experts. We discuss the <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> followed for the polarity annotations and validate the developed <a href=https://en.wikipedia.org/wiki/Resource>resource</a>. This work aims at developing a benchmark corpus, as an extension to SentiWordNet, and baseline accuracy for a model where lexeme annotations are applied for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment predictions</a>. The fundamental aim of this paper is to validate and study the possibility of utilizing <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning algorithms</a>, <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>word-level sentiment annotations</a> in the task of automated sentiment identification. Furthermore, <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> is improved by annotating the bi-grams extracted from the target corpus.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-3015.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-3015 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-3015 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-3015.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-3015/>Reinforced Extractive Summarization with Question-Focused Rewards</a></strong><br><a href=/people/k/kristjan-arumae/>Kristjan Arumae</a>
|
<a href=/people/f/fei-liu-utdallas/>Fei Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-3015><div class="card-body p-3 small">We investigate a new training paradigm for extractive summarization. Traditionally, human abstracts are used to derive goldstandard labels for extraction units. However, the labels are often inaccurate, because <a href=https://en.wikipedia.org/wiki/Abstract_(summary)>human abstracts</a> and source documents can not be easily aligned at the word level. In this paper we convert <a href=https://en.wikipedia.org/wiki/Abstract_(summary)>human abstracts</a> to a set of Cloze-style comprehension questions. System summaries are encouraged to preserve salient source content useful for answering questions and share common words with the <a href=https://en.wikipedia.org/wiki/Abstract_(summary)>abstracts</a>. We use <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a> to explore the space of possible extractive summaries and introduce a question-focused reward function to promote concise, fluent, and informative summaries. Our experiments show that the proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a> is effective. It surpasses state-of-the-art <a href=https://en.wikipedia.org/wiki/System>systems</a> on the standard summarization dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-3016.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-3016 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-3016 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-3016" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-3016/>Graph-based Filtering of Out-of-Vocabulary Words for Encoder-Decoder Models</a></strong><br><a href=/people/s/satoru-katsumata/>Satoru Katsumata</a>
|
<a href=/people/y/yukio-matsumura/>Yukio Matsumura</a>
|
<a href=/people/h/hayahide-yamagishi/>Hayahide Yamagishi</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-3016><div class="card-body p-3 small">Encoder-decoder models typically only employ words that are frequently used in the training corpus because of the computational costs and/or to exclude noisy words. However, this vocabulary set may still include words that interfere with learning in encoder-decoder models. This paper proposes a method for selecting more suitable words for learning encoders by utilizing not only <a href=https://en.wikipedia.org/wiki/Frequency>frequency</a>, but also <a href=https://en.wikipedia.org/wiki/Co-occurrence>co-occurrence information</a>, which we capture using the <a href=https://en.wikipedia.org/wiki/HITS_algorithm>HITS algorithm</a>. The proposed method is applied to two <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> : <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> and <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>grammatical error correction</a>. For Japanese-to-English translation, this method achieved a BLEU score that was 0.56 points more than that of a <a href=https://en.wikipedia.org/wiki/Baseline_(typography)>baseline</a>. It also outperformed the baseline method for English grammatical error correction, with an <a href=https://en.wikipedia.org/wiki/F-measure>F-measure</a> that was 1.48 points higher.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-3020.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-3020 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-3020 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-3020/>Mixed Feelings : Natural Text Generation with Variable, Coexistent Affective Categories</a></strong><br><a href=/people/l/lee-kezar/>Lee Kezar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-3020><div class="card-body p-3 small">Conversational agents, having the goal of <a href=https://en.wikipedia.org/wiki/Natural-language_generation>natural language generation</a>, must rely on <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> which can integrate <a href=https://en.wikipedia.org/wiki/Emotion>emotion</a> into their responses. Recent projects outline <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> which can produce emotional sentences, but unlike <a href=https://en.wikipedia.org/wiki/Human_language>human language</a>, they tend to be restricted to one affective category out of a few. To my knowledge, none allow for the intentional coexistence of multiple emotions on the <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>word or sentence level</a>. Building on prior research which allows for variation in the intensity of a singular emotion, this research proposal outlines an LSTM (Long Short-Term Memory) language model which allows for variation in multiple emotions simultaneously.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-3021.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-3021 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-3021 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-3021/>Automatic Spelling Correction for Resource-Scarce Languages using <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Learning</a></a></strong><br><a href=/people/p/pravallika-etoori/>Pravallika Etoori</a>
|
<a href=/people/m/manoj-chinnakotla/>Manoj Chinnakotla</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-3021><div class="card-body p-3 small">Spelling correction is a well-known task in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing (NLP)</a>. Automatic spelling correction is important for many NLP applications like <a href=https://en.wikipedia.org/wiki/Web_search_engine>web search engines</a>, <a href=https://en.wikipedia.org/wiki/Automatic_summarization>text summarization</a>, <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> etc. Most approaches use parallel data of noisy and correct word mappings from different sources as training data for automatic spelling correction. Indic languages are resource-scarce and do not have such parallel data due to low volume of queries and non-existence of such prior implementations. In this paper, we show how to build an automatic spelling corrector for resource-scarce languages. We propose a sequence-to-sequence deep learning model which trains <a href=https://en.wikipedia.org/wiki/End-to-end_principle>end-to-end</a>. We perform experiments on synthetic datasets created for <a href=https://en.wikipedia.org/wiki/Languages_of_India>Indic languages</a>, <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a> and <a href=https://en.wikipedia.org/wiki/Telugu_language>Telugu</a>, by incorporating the spelling mistakes committed at character level. A comparative evaluation shows that our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> is competitive with the existing <a href=https://en.wikipedia.org/wiki/Spell_checker>spell checking and correction techniques</a> for <a href=https://en.wikipedia.org/wiki/Languages_of_India>Indic languages</a>.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>