<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 3rd Workshop on Noisy User-generated Text - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/W17-44.pdf>Proceedings of the 3rd Workshop on Noisy User-generated Text</a></h2><p class=lead><a href=/people/l/leon-derczynski/>Leon Derczynski</a>,
<a href=/people/w/wei-xu/>Wei Xu</a>,
<a href=/people/a/alan-ritter/>Alan Ritter</a>,
<a href=/people/t/timothy-baldwin/>Tim Baldwin</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>W17-44</dd><dt>Month:</dt><dd>September</dd><dt>Year:</dt><dd>2017</dd><dt>Address:</dt><dd>Copenhagen, Denmark</dd><dt>Venues:</dt><dd><a href=/venues/wnut/>WNUT</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/W17-44>https://aclanthology.org/W17-44</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/W17-44 title="To the current version of the paper by DOI">10.18653/v1/W17-44</a></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/W17-44.pdf>https://aclanthology.org/W17-44.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/W17-44.pdf title="Open PDF of 'Proceedings of the 3rd Workshop on Noisy User-generated Text'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+3rd+Workshop+on+Noisy+User-generated+Text" title="Search for 'Proceedings of the 3rd Workshop on Noisy User-generated Text' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4400.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4400/>Proceedings of the 3rd Workshop on Noisy User-generated Text</a></strong><br><a href=/people/l/leon-derczynski/>Leon Derczynski</a>
|
<a href=/people/w/wei-xu/>Wei Xu</a>
|
<a href=/people/a/alan-ritter/>Alan Ritter</a>
|
<a href=/people/t/timothy-baldwin/>Tim Baldwin</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4401.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4401 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4401 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4401/>Boundary-based MWE segmentation with text partitioning<span class=acl-fixed-case>MWE</span> segmentation with text partitioning</a></strong><br><a href=/people/j/jake-williams/>Jake Williams</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4401><div class="card-body p-3 small">This submission describes the development of a fine-grained, text-chunking algorithm for the task of comprehensive MWE segmentation. This <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> notably focuses on the identification of colloquial and idiomatic language. The submission also includes a thorough model evaluation in the context of two recent shared tasks, spanning 19 different languages and many text domains, including noisy, user-generated text. Evaluations exhibit the presented model as the best overall for purposes of MWE segmentation, and <a href=https://en.wikipedia.org/wiki/Open-source_software>open-source software</a> is released with the submission (although links are withheld for purposes of anonymity). Additionally, the authors acknowledge the existence of a pre-print document on arxiv.org, which should be avoided to maintain anonymity in review.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4402.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4402 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4402 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4402/>Towards the Understanding of Gaming Audiences by Modeling Twitch Emotes</a></strong><br><a href=/people/f/francesco-barbieri/>Francesco Barbieri</a>
|
<a href=/people/l/luis-espinosa-anke/>Luis Espinosa-Anke</a>
|
<a href=/people/m/miguel-ballesteros/>Miguel Ballesteros</a>
|
<a href=/people/j/juan-soler-company/>Juan Soler-Company</a>
|
<a href=/people/h/horacio-saggion/>Horacio Saggion</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4402><div class="card-body p-3 small">Videogame streaming platforms have become a paramount example of noisy user-generated text. These are websites where <a href=https://en.wikipedia.org/wiki/Video_game>gaming</a> is broadcasted, and allows interaction with viewers via integrated chatrooms. Probably the best known <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a> of this kind is <a href=https://en.wikipedia.org/wiki/Twitch.tv>Twitch</a>, which has more than 100 million monthly viewers. Despite these numbers, and unlike other <a href=https://en.wikipedia.org/wiki/Computing_platform>platforms</a> featuring short messages (e.g. Twitter), <a href=https://en.wikipedia.org/wiki/Twitch.tv>Twitch</a> has not received much attention from the Natural Language Processing community. In this paper we aim at bridging this gap by proposing two important tasks specific to the Twitch platform, namely (1) Emote prediction ; and (2) Trolling detection. In our experiments, we evaluate three models : a BOW baseline, a logistic supervised classifiers based on word embeddings, and a bidirectional long short-term memory recurrent neural network (LSTM). Our results show that the LSTM model outperforms the other two models, where explicit features with proven effectiveness for similar tasks were encoded.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4404.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4404 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4404 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-4404" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-4404/>To normalize, or not to normalize : The impact of <a href=https://en.wikipedia.org/wiki/Normalization_(image_processing)>normalization</a> on Part-of-Speech tagging</a></strong><br><a href=/people/r/rob-van-der-goot/>Rob van der Goot</a>
|
<a href=/people/b/barbara-plank/>Barbara Plank</a>
|
<a href=/people/m/malvina-nissim/>Malvina Nissim</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4404><div class="card-body p-3 small">Does <a href=https://en.wikipedia.org/wiki/Normalization_(statistics)>normalization</a> help Part-of-Speech (POS) tagging accuracy on noisy, non-canonical data? To the best of our knowledge, little is known on the actual impact of <a href=https://en.wikipedia.org/wiki/Normalization_(statistics)>normalization</a> in a real-world scenario, where gold error detection is not available. We investigate the effect of automatic normalization on POS tagging of tweets. We also compare <a href=https://en.wikipedia.org/wiki/Normalization_(statistics)>normalization</a> to strategies that leverage large amounts of unlabeled data kept in its raw form. Our results show that <a href=https://en.wikipedia.org/wiki/Normalization_(statistics)>normalization</a> helps, but does not add consistently beyond just word embedding layer initialization. The latter approach yields a tagging model that is competitive with a Twitter state-of-the-art <a href=https://en.wikipedia.org/wiki/Tag_(metadata)>tagger</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4405.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4405 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4405 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4405/>Constructing an Alias List for Named Entities during an Event</a></strong><br><a href=/people/a/anietie-andy/>Anietie Andy</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a>
|
<a href=/people/m/mugizi-rwebangira/>Mugizi Rwebangira</a>
|
<a href=/people/c/chris-callison-burch/>Chris Callison-Burch</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4405><div class="card-body p-3 small">In certain fields, real-time knowledge from events can help in making informed decisions. In order to extract pertinent real-time knowledge related to an event, it is important to identify the <a href=https://en.wikipedia.org/wiki/Named_entity>named entities</a> and their corresponding <a href=https://en.wikipedia.org/wiki/Pseudonym>aliases</a> related to the event. The problem of identifying aliases of named entities that spike has remained unexplored. In this paper, we introduce an <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a>, EntitySpike, that identifies entities that spike in popularity in tweets from a given time period, and constructs an alias list for these spiked entities. EntitySpike uses a temporal heuristic to identify named entities with similar context that occur in the same time period (within minutes) during an event. Each entity is encoded as a vector using this temporal heuristic. We show how these entity-vectors can be used to create a named entity alias list. We evaluated our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> on a dataset of temporally ordered tweets from a single event, the 2013 <a href=https://en.wikipedia.org/wiki/55th_Annual_Grammy_Awards>Grammy Awards show</a>. We carried out various experiments on tweets that were published in the same time period and show that our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> identifies most entity name aliases and outperforms a competitive baseline.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4406.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4406 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4406 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4406/>Incorporating <a href=https://en.wikipedia.org/wiki/Metadata>Metadata</a> into Content-Based User Embeddings</a></strong><br><a href=/people/l/linzi-xing/>Linzi Xing</a>
|
<a href=/people/m/michael-paul/>Michael J. Paul</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4406><div class="card-body p-3 small">Low-dimensional vector representations of social media users can benefit applications like <a href=https://en.wikipedia.org/wiki/Recommender_system>recommendation systems</a> and user attribute inference. Recent work has shown that user embeddings can be improved by combining different types of <a href=https://en.wikipedia.org/wiki/Information>information</a>, such as text and network data. We propose a data augmentation method that allows novel feature types to be used within off-the-shelf embedding models. Experimenting with the task of <a href=https://en.wikipedia.org/wiki/Recommender_system>friend recommendation</a> on a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of 5,019 <a href=https://en.wikipedia.org/wiki/Twitter>Twitter users</a>, we show that our approach can lead to substantial performance gains with the simple addition of network and geographic features.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4407.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4407 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4407 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4407/>Simple Queries as Distant Labels for Predicting Gender on Twitter<span class=acl-fixed-case>T</span>witter</a></strong><br><a href=/people/c/chris-emmery/>Chris Emmery</a>
|
<a href=/people/g/grzegorz-chrupala/>Grzegorz Chrupała</a>
|
<a href=/people/w/walter-daelemans/>Walter Daelemans</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4407><div class="card-body p-3 small">The majority of research on extracting missing user attributes from <a href=https://en.wikipedia.org/wiki/User_profile>social media profiles</a> use costly hand-annotated labels for <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised learning</a>. Distantly supervised methods exist, although these generally rely on knowledge gathered using external sources. This paper demonstrates the effectiveness of gathering distant labels for self-reported gender on <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> using simple queries. We confirm the reliability of this query heuristic by comparing with <a href=https://en.wikipedia.org/wiki/Annotation>manual annotation</a>. Moreover, using these labels for distant supervision, we demonstrate competitive model performance on the same data as <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained on manual annotations. As such, we offer a cheap, extensible, and fast alternative that can be employed beyond the task of <a href=https://en.wikipedia.org/wiki/Gender>gender classification</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4408.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4408 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4408 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4408/>A <a href=https://en.wikipedia.org/wiki/Dataset>Dataset</a> and Classifier for Recognizing Social Media English<span class=acl-fixed-case>E</span>nglish</a></strong><br><a href=/people/s/su-lin-blodgett/>Su Lin Blodgett</a>
|
<a href=/people/j/johnny-wei/>Johnny Wei</a>
|
<a href=/people/b/brendan-oconnor/>Brendan O’Connor</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4408><div class="card-body p-3 small">While <a href=https://en.wikipedia.org/wiki/Language_identification>language identification</a> works well on standard texts, it performs much worse on social media language, in particular dialectal languageeven for <a href=https://en.wikipedia.org/wiki/English_language>English</a>. First, to support work on English language identification, we contribute a new dataset of <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a> annotated for English versus non-English, with attention to <a href=https://en.wikipedia.org/wiki/Ambiguity>ambiguity</a>, <a href=https://en.wikipedia.org/wiki/Code-switching>code-switching</a>, and automatic generation issues. It is randomly sampled from all public messages, avoiding biases towards pre-existing <a href=https://en.wikipedia.org/wiki/Classifier_(linguistics)>language classifiers</a>. Second, we find that a demographic language modelwhich identifies messages with language similar to that used by several <a href=https://en.wikipedia.org/wiki/Race_and_ethnicity_in_the_United_States>U.S. ethnic populations</a> on Twittercan be used to improve English language identification performance when combined with a traditional supervised language identifier. It increases <a href=https://en.wikipedia.org/wiki/Recall_(memory)>recall</a> with almost no loss of <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a>, including, surprisingly, for <a href=https://en.wikipedia.org/wiki/English_language>English messages</a> written by non-U.S. authors. Our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> and identifier ensemble are available online.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4409.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4409 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4409 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4409/>Evaluating hypotheses in <a href=https://en.wikipedia.org/wiki/Geolocation>geolocation</a> on a very large sample of Twitter<span class=acl-fixed-case>T</span>witter</a></strong><br><a href=/people/b/bahar-salehi/>Bahar Salehi</a>
|
<a href=/people/a/anders-sogaard/>Anders Søgaard</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4409><div class="card-body p-3 small">Recent work in <a href=https://en.wikipedia.org/wiki/Geolocation>geolocation</a> has made several hypotheses about what <a href=https://en.wikipedia.org/wiki/Marker_(linguistics)>linguistic markers</a> are relevant to detect where people write from. In this paper, we examine six hypotheses against a corpus consisting of all geo-tagged tweets from the US, or whose geo-tags could be inferred, in a 19 % sample of Twitter history. Our experiments lend support to all six hypotheses, including that spelling variants and <a href=https://en.wikipedia.org/wiki/Hashtag>hashtags</a> are strong predictors of <a href=https://en.wikipedia.org/wiki/Location>location</a>. We also study what kinds of common nouns are predictive of location after controlling for named entities such as <a href=https://en.wikipedia.org/wiki/Dolphin>dolphins</a> or <a href=https://en.wikipedia.org/wiki/Shark>sharks</a></div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4410.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4410 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4410 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4410/>The Effect of <a href=https://en.wikipedia.org/wiki/Error_rate>Error Rate</a> in Artificially Generated Data for Automatic Preposition and Determiner Correction</a></strong><br><a href=/people/f/fraser-bowen/>Fraser Bowen</a>
|
<a href=/people/j/jon-dehdari/>Jon Dehdari</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4410><div class="card-body p-3 small">In this research we investigate the impact of mismatches in the density and type of error between training and test data on a <a href=https://en.wikipedia.org/wiki/Nervous_system>neural system</a> correcting preposition and determiner errors. We use synthetically produced training data to control error density and type, and real error data for testing. Our results show it is possible to combine error types, although <a href=https://en.wikipedia.org/wiki/Preposition_and_postposition>prepositions</a> and <a href=https://en.wikipedia.org/wiki/Determiner>determiners</a> behave differently in terms of how much error should be artificially introduced into the training data in order to get the best results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4411.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4411 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4411 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4411/>An Entity Resolution Approach to Isolate Instances of Human Trafficking Online</a></strong><br><a href=/people/c/chirag-nagpal/>Chirag Nagpal</a>
|
<a href=/people/k/kyle-miller/>Kyle Miller</a>
|
<a href=/people/b/benedikt-boecking/>Benedikt Boecking</a>
|
<a href=/people/a/artur-dubrawski/>Artur Dubrawski</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4411><div class="card-body p-3 small">Human trafficking is a challenging law enforcement problem, and traces of victims of such activity manifest as &#8216;escort advertisements&#8217; on various online forums. Given the large, heterogeneous and noisy structure of this <a href=https://en.wikipedia.org/wiki/Data>data</a>, building <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> to predict instances of <a href=https://en.wikipedia.org/wiki/Smuggling>trafficking</a> is a convoluted task. In this paper we propose an entity resolution pipeline using a notion of proxy labels, in order to extract clusters from this data with prior history of human trafficking activity. We apply this <a href=https://en.wikipedia.org/wiki/Pipeline_(software)>pipeline</a> to 5 M records from <a href=https://en.wikipedia.org/wiki/Backpage>backpage.com</a> and report on the performance of this approach, challenges in terms of <a href=https://en.wikipedia.org/wiki/Scalability>scalability</a>, and some significant domain specific characteristics of our resolved entities.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4412.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4412 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4412 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4412/>Noisy Uyghur Text Normalization<span class=acl-fixed-case>U</span>yghur Text Normalization</a></strong><br><a href=/people/o/osman-tursun/>Osman Tursun</a>
|
<a href=/people/r/ruket-cakici/>Ruket Cakici</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4412><div class="card-body p-3 small">Uyghur is the second largest and most actively used social media language in China. However, a non-negligible part of <a href=https://en.wikipedia.org/wiki/Uyghur_language>Uyghur text</a> appearing in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> is unsystematically written with the <a href=https://en.wikipedia.org/wiki/Latin_alphabet>Latin alphabet</a>, and it continues to increase in size. Uyghur text in this format is incomprehensible and ambiguous even to native Uyghur speakers. In addition, Uyghur texts in this form lack the potential for any kind of advancement for the <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP tasks</a> related to the <a href=https://en.wikipedia.org/wiki/Uyghur_language>Uyghur language</a>. Restoring and preventing noisy Uyghur text written with unsystematic Latin alphabets will be essential to the protection of Uyghur language and improving the accuracy of Uyghur NLP tasks. To this purpose, in this work we propose and compare the noisy channel model and the neural encoder-decoder model as <a href=https://en.wikipedia.org/wiki/Normalization_(statistics)>normalizing methods</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4413.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4413 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4413 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4413/>Crowdsourcing Multiple Choice Science Questions</a></strong><br><a href=/people/j/johannes-welbl/>Johannes Welbl</a>
|
<a href=/people/n/nelson-f-liu/>Nelson F. Liu</a>
|
<a href=/people/m/matt-gardner/>Matt Gardner</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4413><div class="card-body p-3 small">We present a novel method for obtaining high-quality, domain-targeted multiple choice questions from crowd workers. Generating these questions can be difficult without trading away originality, <a href=https://en.wikipedia.org/wiki/Relevance>relevance</a> or diversity in the answer options. Our method addresses these problems by leveraging a large corpus of domain-specific text and a small set of existing questions. It produces model suggestions for document selection and answer distractor choice which aid the human question generation process. With this <a href=https://en.wikipedia.org/wiki/Methodology>method</a> we have assembled SciQ, a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of 13.7 K multiple choice science exam questions. We demonstrate that the method produces in-domain questions by providing an analysis of this new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> and by showing that humans can not distinguish the crowdsourced questions from original questions. When using SciQ as additional training data to existing questions, we observe accuracy improvements on real science exams.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4414.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4414 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4414 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4414/>A Text Normalisation System for Non-Standard English Words<span class=acl-fixed-case>E</span>nglish Words</a></strong><br><a href=/people/e/emma-flint/>Emma Flint</a>
|
<a href=/people/e/elliot-ford/>Elliot Ford</a>
|
<a href=/people/o/olivia-thomas/>Olivia Thomas</a>
|
<a href=/people/a/andrew-caines/>Andrew Caines</a>
|
<a href=/people/p/paula-buttery/>Paula Buttery</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4414><div class="card-body p-3 small">This paper investigates the problem of text normalisation ; specifically, the normalisation of non-standard words (NSWs) in <a href=https://en.wikipedia.org/wiki/English_language>English</a>. Non-standard words can be defined as those word tokens which do not have a dictionary entry, and can not be pronounced using the usual letter-to-phoneme conversion rules ; e.g. lbs, 99.3 %, # EMNLP2017. NSWs pose a challenge to the proper functioning of text-to-speech technology, and the solution is to spell them out in such a way that they can be pronounced appropriately. We describe our four-stage normalisation system made up of components for <a href=https://en.wikipedia.org/wiki/Detection>detection</a>, <a href=https://en.wikipedia.org/wiki/Taxonomy_(biology)>classification</a>, division and expansion of NSWs. Performance is favourabe compared to previous work in the field (Sproat et al. 2001, Normalization of non-standard words), as well as state-of-the-art text-to-speech software. Further, we update Sproat et al.&#8217;s NSW taxonomy, and create a more customisable system where users are able to input their own abbreviations and specify into which variety of English (currently available : British or American) they wish to normalise.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4415.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4415 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4415 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4415/>Huntsville, hospitals, and hockey teams : Names can reveal your location</a></strong><br><a href=/people/b/bahar-salehi/>Bahar Salehi</a>
|
<a href=/people/d/dirk-hovy/>Dirk Hovy</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a>
|
<a href=/people/a/anders-sogaard/>Anders Søgaard</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4415><div class="card-body p-3 small">Geolocation is the task of identifying a social media user&#8217;s primary location, and in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>, there is a growing literature on to what extent automated analysis of social media posts can help. However, not all content features are equally revealing of a user&#8217;s location. In this paper, we evaluate nine name entity (NE) types. Using various metrics, we find that GEO-LOC, FACILITY and SPORT-TEAM are more informative for <a href=https://en.wikipedia.org/wiki/Geolocation>geolocation</a> than other NE types. Using these types, we improve geolocation accuracy and reduce <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>distance error</a> over various famous text-based methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4416.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4416 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4416 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4416/>Improving Document Clustering by Removing Unnatural Language</a></strong><br><a href=/people/m/myungha-jang/>Myungha Jang</a>
|
<a href=/people/j/jinho-d-choi/>Jinho D. Choi</a>
|
<a href=/people/j/james-allan/>James Allan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4416><div class="card-body p-3 small">Technical documents contain a fair amount of unnatural language, such as tables, <a href=https://en.wikipedia.org/wiki/Formula>formulas</a>, and <a href=https://en.wikipedia.org/wiki/Pseudo-code>pseudo-code</a>. Unnatural language can bean important factor of confusing existing NLP tools. This paper presents an effective method of distinguishing unnatural language from <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>, and evaluates the impact of un-natural language detection on NLP tasks such as <a href=https://en.wikipedia.org/wiki/Document_clustering>document clustering</a>. We view this problem as an information extraction task and build a multiclass classification model identifying unnatural language components into four categories. First, we create a new annotated corpus by collecting slides and papers in various for-mats, <a href=https://en.wikipedia.org/wiki/PDF>PPT</a>, <a href=https://en.wikipedia.org/wiki/PDF>PDF</a>, and <a href=https://en.wikipedia.org/wiki/HTML>HTML</a>, where unnatural language components are annotated into four categories. We then explore features available from <a href=https://en.wikipedia.org/wiki/Plain_text>plain text</a> to build a <a href=https://en.wikipedia.org/wiki/Statistical_model>statistical model</a> that can handle any format as long as it is converted into plain text. Our experiments show that re-moving unnatural language components gives an absolute improvement in document cluster-ing by up to 15 %. Our corpus and tool are publicly available</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4417.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4417 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4417 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4417/>Lithium NLP : A System for Rich Information Extraction from Noisy User Generated Text on <a href=https://en.wikipedia.org/wiki/Social_media>Social Media</a><span class=acl-fixed-case>NLP</span>: A System for Rich Information Extraction from Noisy User Generated Text on Social Media</a></strong><br><a href=/people/p/preeti-bhargava/>Preeti Bhargava</a>
|
<a href=/people/n/nemanja-spasojevic/>Nemanja Spasojevic</a>
|
<a href=/people/g/guoning-hu/>Guoning Hu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4417><div class="card-body p-3 small">In this paper, we describe the Lithium Natural Language Processing (NLP) system-a resource-constrained, high-throughput and language-agnostic system for information extraction from noisy user generated text on social media. Lithium NLP extracts a rich set of information including entities, topics, <a href=https://en.wikipedia.org/wiki/Hashtag>hashtags</a> and <a href=https://en.wikipedia.org/wiki/Sentimentality>sentiment</a> from text. We discuss several real world applications of the <a href=https://en.wikipedia.org/wiki/System>system</a> currently incorporated in Lithium products. We also compare our <a href=https://en.wikipedia.org/wiki/System>system</a> with existing commercial and academic NLP systems in terms of performance, information extracted and languages supported. We show that Lithium NLP is at par with and in some cases, outperforms state-of-the-art commercial NLP systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4418.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4418 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4418 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4418/>Results of the WNUT2017 Shared Task on Novel and Emerging Entity Recognition<span class=acl-fixed-case>WNUT</span>2017 Shared Task on Novel and Emerging Entity Recognition</a></strong><br><a href=/people/l/leon-derczynski/>Leon Derczynski</a>
|
<a href=/people/e/eric-nichols/>Eric Nichols</a>
|
<a href=/people/m/marieke-van-erp/>Marieke van Erp</a>
|
<a href=/people/n/nut-limsopatham/>Nut Limsopatham</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4418><div class="card-body p-3 small">This shared <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> focuses on identifying unusual, previously-unseen entities in the context of emerging discussions. Named entities form the basis of many modern approaches to other tasks (like event clustering and summarization), but recall on them is a real problem in noisy text-even among annotators. This drop tends to be due to novel entities and <a href=https://en.wikipedia.org/wiki/Surface_(topology)>surface forms</a>. Take for example the tweet so.. kktny in 30 mins? ! even human experts find the entity &#8216;kktny&#8217; hard to detect and resolve. The goal of this task is to provide a definition of emerging and of rare entities, and based on that, also datasets for detecting these <a href=https://en.wikipedia.org/wiki/Non-physical_entity>entities</a>. The task as described in this paper evaluated the ability of participating entries to detect and classify novel and emerging <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entities</a> in noisy text.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4419.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4419 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4419 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-4419" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-4419/>A Multi-task Approach for <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>Named Entity Recognition</a> in Social Media Data</a></strong><br><a href=/people/g/gustavo-aguilar/>Gustavo Aguilar</a>
|
<a href=/people/s/suraj-maharjan/>Suraj Maharjan</a>
|
<a href=/people/a/adrian-pastor-lopez-monroy/>Adrian Pastor López-Monroy</a>
|
<a href=/people/t/thamar-solorio/>Thamar Solorio</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4419><div class="card-body p-3 small">Named Entity Recognition for <a href=https://en.wikipedia.org/wiki/Social_media>social media data</a> is challenging because of its inherent noisiness. In addition to improper grammatical structures, it contains <a href=https://en.wikipedia.org/wiki/Orthographic_error>spelling inconsistencies</a> and numerous <a href=https://en.wikipedia.org/wiki/Abbreviation>informal abbreviations</a>. We propose a novel multi-task approach by employing a more general secondary task of Named Entity (NE) segmentation together with the primary task of fine-grained NE categorization. The multi-task neural network architecture learns higher order feature representations from word and character sequences along with basic Part-of-Speech tags and gazetteer information. This <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> acts as a <a href=https://en.wikipedia.org/wiki/Feature_extraction>feature extractor</a> to feed a Conditional Random Fields classifier. We were able to obtain the first position in the 3rd Workshop on Noisy User-generated Text (WNUT-2017) with a 41.86 % entity F1-score and a 40.24 % surface F1-score.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4421.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4421 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4421 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4421/>Multi-channel BiLSTM-CRF Model for Emerging Named Entity Recognition in <a href=https://en.wikipedia.org/wiki/Social_media>Social Media</a><span class=acl-fixed-case>B</span>i<span class=acl-fixed-case>LSTM</span>-<span class=acl-fixed-case>CRF</span> Model for Emerging Named Entity Recognition in Social Media</a></strong><br><a href=/people/b/bill-yuchen-lin/>Bill Y. Lin</a>
|
<a href=/people/f/frank-f-xu/>Frank Xu</a>
|
<a href=/people/z/zhiyi-luo/>Zhiyi Luo</a>
|
<a href=/people/k/kenny-zhu/>Kenny Zhu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4421><div class="card-body p-3 small">In this paper, we present our multi-channel neural architecture for recognizing emerging named entity in social media messages, which we applied in the Novel and Emerging Named Entity Recognition shared task at the EMNLP 2017 Workshop on Noisy User-generated Text (W-NUT). We propose a novel approach, which incorporates comprehensive word representations with multi-channel information and Conditional Random Fields (CRF) into a traditional Bidirectional Long Short-Term Memory (BiLSTM) neural network without using any additional hand-craft features such as gazetteers. In comparison with other <a href=https://en.wikipedia.org/wiki/System>systems</a> participating in the shared task, our <a href=https://en.wikipedia.org/wiki/System>system</a> won the 2nd place.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4422.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4422 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4422 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4422/>Transfer Learning and Sentence Level Features for Named Entity Recognition on Tweets</a></strong><br><a href=/people/p/pius-von-daniken/>Pius von Däniken</a>
|
<a href=/people/m/mark-cieliebak/>Mark Cieliebak</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4422><div class="card-body p-3 small">We present our system for the WNUT 2017 Named Entity Recognition challenge on Twitter data. We describe two modifications of a basic neural network architecture for sequence tagging. First, we show how we exploit additional labeled data, where the Named Entity tags differ from the target task. Then, we propose a way to incorporate <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence level features</a>. Our system uses both methods and ranked second for entity level annotations, achieving an F1-score of 40.78, and <a href=https://en.wikipedia.org/wiki/Second>second</a> for surface form annotations, achieving an F1-score of 39.33.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4424.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4424 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4424 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4424/>A Feature-based Ensemble Approach to Recognition of Emerging and Rare Named Entities</a></strong><br><a href=/people/u/utpal-kumar-sikdar/>Utpal Kumar Sikdar</a>
|
<a href=/people/b/bjorn-gamback/>Björn Gambäck</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4424><div class="card-body p-3 small">Detecting previously unseen named entities in text is a challenging task. The paper describes how three initial classifier models were built using Conditional Random Fields (CRFs), Support Vector Machines (SVMs) and a Long Short-Term Memory (LSTM) recurrent neural network. The outputs of these three <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> were then used as <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> to train another CRF classifier working as an <a href=https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)>ensemble</a>. 5-fold cross-validation based on training and development data for the emerging and rare named entity recognition shared task showed <a href=https://en.wikipedia.org/wiki/Precision_(statistics)>precision</a>, <a href=https://en.wikipedia.org/wiki/Recall_(memory)>recall</a> and <a href=https://en.wikipedia.org/wiki/F-number>F1-score</a> of 66.87 %, 46.75 % and 54.97 %, respectively. For surface form evaluation, the CRF ensemble-based system achieved precision, <a href=https://en.wikipedia.org/wiki/Recall_(memory)>recall</a> and F1 scores of 65.18 %, 45.20 % and 53.30 %. When applied to unseen test data, the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> reached 47.92 % <a href=https://en.wikipedia.org/wiki/Precision_(statistics)>precision</a>, 31.97 % recall and 38.55 % <a href=https://en.wikipedia.org/wiki/F-number>F1-score</a> for entity level evaluation, with the corresponding surface form evaluation values of 44.91 %, 30.47 % and 36.31 %.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>