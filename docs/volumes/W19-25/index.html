<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 3rd Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/W19-25.pdf>Proceedings of the 3rd Joint <span class=acl-fixed-case>SIGHUM</span> Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature</a></h2><p class=lead><a href=/people/b/beatrice-alex/>Beatrice Alex</a>,
<a href=/people/s/stefania-degaetano-ortlieb/>Stefania Degaetano-Ortlieb</a>,
<a href=/people/a/anna-kazantseva/>Anna Kazantseva</a>,
<a href=/people/n/nils-reiter/>Nils Reiter</a>,
<a href=/people/s/stan-szpakowicz/>Stan Szpakowicz</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>W19-25</dd><dt>Month:</dt><dd>June</dd><dt>Year:</dt><dd>2019</dd><dt>Address:</dt><dd>Minneapolis, USA</dd><dt>Venues:</dt><dd><a href=/venues/latech/>LaTeCH</a>
| <a href=/venues/naacl/>NAACL</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd><a href=/sigs/sighum/>SIGHUM</a></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/W19-25>https://aclanthology.org/W19-25</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/W19-25.pdf>https://aclanthology.org/W19-25.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/W19-25.pdf title="Open PDF of 'Proceedings of the 3rd Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+3rd+Joint+SIGHUM+Workshop+on+Computational+Linguistics+for+Cultural+Heritage%2C+Social+Sciences%2C+Humanities+and+Literature" title="Search for 'Proceedings of the 3rd Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2500.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-2500/>Proceedings of the 3rd Joint <span class=acl-fixed-case>SIGHUM</span> Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature</a></strong><br><a href=/people/b/beatrice-alex/>Beatrice Alex</a>
|
<a href=/people/s/stefania-degaetano-ortlieb/>Stefania Degaetano-Ortlieb</a>
|
<a href=/people/a/anna-kazantseva/>Anna Kazantseva</a>
|
<a href=/people/n/nils-reiter/>Nils Reiter</a>
|
<a href=/people/s/stan-szpakowicz/>Stan Szpakowicz</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2501.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-2501 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-2501 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-2501/>Modeling Word Emotion in Historical Language : Quantity Beats Supposed Stability in Seed Word Selection</a></strong><br><a href=/people/j/johannes-hellrich/>Johannes Hellrich</a>
|
<a href=/people/s/sven-buechel/>Sven Buechel</a>
|
<a href=/people/u/udo-hahn/>Udo Hahn</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-2501><div class="card-body p-3 small">To understand historical texts, we must be aware that languageincluding the emotional connotation attached to wordschanges over time. In this paper, we aim at estimating the <a href=https://en.wikipedia.org/wiki/Emotion>emotion</a> which is associated with a given word in former language stages of <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/German_language>German</a>. Emotion is represented following the popular Valence-Arousal-Dominance (VAD) annotation scheme. While being more expressive than <a href=https://en.wikipedia.org/wiki/Affirmation_and_negation>polarity</a> alone, existing word emotion induction methods are typically not suited for addressing it. To overcome this limitation, we present adaptations of two popular <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> to VAD. To measure their effectiveness in diachronic settings, we present the first <a href=https://en.wikipedia.org/wiki/Gold_standard_(test)>gold standard</a> for historical word emotions, which was created by scholars with proficiency in the respective language stages and covers both <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/German_language>German</a>. In contrast to claims in previous work, our findings indicate that hand-selecting small sets of seed words with supposedly stable emotional meaning is actually harm- rather than helpful.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2504.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-2504 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-2504 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-2504/>Are Fictional Voices Distinguishable? Classifying Character Voices in Modern Drama</a></strong><br><a href=/people/k/krishnapriya-vishnubhotla/>Krishnapriya Vishnubhotla</a>
|
<a href=/people/a/adam-hammond/>Adam Hammond</a>
|
<a href=/people/g/graeme-hirst/>Graeme Hirst</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-2504><div class="card-body p-3 small">According to the <a href=https://en.wikipedia.org/wiki/Literary_theory>literary theory</a> of Mikhail Bakhtin, a dialogic novel is one in which characters speak in their own distinct voices, rather than serving as mouthpieces for their authors. We use <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a> to determine which authors best achieve <a href=https://en.wikipedia.org/wiki/Dialogism>dialogism</a>, looking at a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus of plays</a> from the late nineteenth and early twentieth centuries. We find that the SAGE model of text generation, which highlights deviations from a background lexical distribution, is an effective method of weighting the words of characters&#8217; utterances. Our results show that it is indeed possible to distinguish characters by their speech in the plays of canonical writers such as George Bernard Shaw, whereas characters are clustered more closely in the works of lesser-known playwrights.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2505.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-2505 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-2505 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-2505/>Automatic Alignment and Annotation Projection for Literary Texts</a></strong><br><a href=/people/u/uli-steinbach/>Uli Steinbach</a>
|
<a href=/people/i/ines-rehbein/>Ines Rehbein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-2505><div class="card-body p-3 small">This paper presents a modular NLP pipeline for the creation of a parallel literature corpus, followed by annotation transfer from the source to the target language. The test case we use to evaluate our <a href=https://en.wikipedia.org/wiki/Pipeline_(software)>pipeline</a> is the automatic transfer of quote and speaker mention annotations from <a href=https://en.wikipedia.org/wiki/English_language>English</a> to <a href=https://en.wikipedia.org/wiki/German_language>German</a>. We evaluate the different components of the <a href=https://en.wikipedia.org/wiki/Pipeline_transport>pipeline</a> and discuss challenges specific to <a href=https://en.wikipedia.org/wiki/Literature>literary texts</a>. Our experiments show that after applying a reasonable amount of semi-automatic postprocessing we can obtain high-quality aligned and annotated resources for a new language.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2506.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-2506 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-2506 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-2506/>Inferring missing metadata from environmental policy texts</a></strong><br><a href=/people/s/steven-bethard/>Steven Bethard</a>
|
<a href=/people/e/egoitz-laparra/>Egoitz Laparra</a>
|
<a href=/people/s/sophia-wang/>Sophia Wang</a>
|
<a href=/people/y/yiyun-zhao/>Yiyun Zhao</a>
|
<a href=/people/r/ragheb-al-ghezi/>Ragheb Al-Ghezi</a>
|
<a href=/people/a/aaron-lien/>Aaron Lien</a>
|
<a href=/people/l/laura-lopez-hoffman/>Laura López-Hoffman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-2506><div class="card-body p-3 small">The National Environmental Policy Act (NEPA) provides a trove of data on how environmental policy decisions have been made in the United States over the last 50 years. Unfortunately, there is no central database for this information and it is too voluminous to assess manually. We describe our efforts to enable systematic research over <a href=https://en.wikipedia.org/wiki/Environmental_policy_of_the_United_States>US environmental policy</a> by extracting and organizing <a href=https://en.wikipedia.org/wiki/Metadata>metadata</a> from the text of NEPA documents. Our contributions include collecting more than 40,000 NEPA-related documents, and evaluating rule-based baselines that establish the difficulty of three important tasks : identifying lead agencies, aligning document versions, and detecting reused text.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2508.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-2508 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-2508 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-2508/>A framework for streamlined statistical prediction using <a href=https://en.wikipedia.org/wiki/Topic_model>topic models</a></a></strong><br><a href=/people/v/vanessa-glenny/>Vanessa Glenny</a>
|
<a href=/people/j/jonathan-tuke/>Jonathan Tuke</a>
|
<a href=/people/n/nigel-bean/>Nigel Bean</a>
|
<a href=/people/l/lewis-mitchell/>Lewis Mitchell</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-2508><div class="card-body p-3 small">In the Humanities and Social Sciences, there is increasing interest in approaches to <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction</a>, <a href=https://en.wikipedia.org/wiki/Prediction>prediction</a>, intelligent linkage, and <a href=https://en.wikipedia.org/wiki/Dimension_reduction>dimension reduction</a> applicable to large text corpora. With approaches in these fields being grounded in traditional <a href=https://en.wikipedia.org/wiki/Statistics>statistical techniques</a>, the need arises for frameworks whereby advanced NLP techniques such as topic modelling may be incorporated within classical methodologies. This paper provides a classical, supervised, statistical learning framework for prediction from text, using topic models as a data reduction method and the topics themselves as predictors, alongside typical statistical tools for predictive modelling. We apply this <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> in a Social Sciences context (applied animal behaviour) as well as a Humanities context (narrative analysis) as examples of this <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a>. The results show that topic regression models perform comparably to their much less efficient equivalents that use individual words as predictors.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2510.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-2510 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-2510 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-2510/>Graph convolutional networks for exploring authorship hypotheses</a></strong><br><a href=/people/t/tom-lippincott/>Tom Lippincott</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-2510><div class="card-body p-3 small">This work considers a task from traditional <a href=https://en.wikipedia.org/wiki/Literary_criticism>literary criticism</a> : annotating a structured, composite document with information about its sources. We take the <a href=https://en.wikipedia.org/wiki/Documentary_hypothesis>Documentary Hypothesis</a>, a prominent theory regarding the composition of the first five books of the <a href=https://en.wikipedia.org/wiki/Hebrew_Bible>Hebrew bible</a>, extract stylistic features designed to avoid bias or overfitting, and train several classification models. Our main result is that the recently-introduced graph convolutional network architecture outperforms structurally-uninformed models. We also find that including information about the granularity of text spans is a crucial ingredient when employing hidden layers, in contrast to simple <a href=https://en.wikipedia.org/wiki/Logistic_regression>logistic regression</a>. We perform error analysis at several levels, noting how some characteristic limitations of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> and simple <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> lead to <a href=https://en.wikipedia.org/wiki/Statistical_classification>misclassifications</a>, and conclude with an overview of future work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2511.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-2511 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-2511 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-2511/>Semantics and Homothetic Clustering of Hafez Poetry</a></strong><br><a href=/people/a/arya-rahgozar/>Arya Rahgozar</a>
|
<a href=/people/d/diana-inkpen/>Diana Inkpen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-2511><div class="card-body p-3 small">We have created two sets of labels for Hafez (1315-1390) poems, using <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised learning</a>. Our labels are the only semantic clustering alternative to the previously existing, hand-labeled, gold-standard classification of Hafez poems, to be used for <a href=https://en.wikipedia.org/wiki/Literary_criticism>literary research</a>. We have cross-referenced, measured and analyzed the agreements of our clustering labels with Houman&#8217;s chronological classes. Our <a href=https://en.wikipedia.org/wiki/Software_feature>features</a> are based on <a href=https://en.wikipedia.org/wiki/Topic_modeling>topic modeling</a> and <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a>. We also introduced a similarity of similarities&#8217; features, we called homothetic clustering approach that proved effective, in case of Hafez&#8217;s small corpus of ghazals2. Although all our experiments showed different clusters when compared with Houman&#8217;s classes, we think they were valid in their own right to have provided further insights, and have proved useful as a contrasting alternative to Houman&#8217;s classes. Our homothetic clusterer and its feature design and engineering framework can be used for further semantic analysis of Hafez&#8217;s poetry and other similar literary research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2512.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-2512 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-2512 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-2512/>Computational Linguistics Applications for Multimedia Services</a></strong><br><a href=/people/k/kyeongmin-rim/>Kyeongmin Rim</a>
|
<a href=/people/k/kelley-lynch/>Kelley Lynch</a>
|
<a href=/people/j/james-pustejovsky/>James Pustejovsky</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-2512><div class="card-body p-3 small">We present Computational Linguistics Applications for Multimedia Services (CLAMS), a platform that provides access to computational content analysis tools for archival multimedia material that appear in different media, such as <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>text</a>, <a href=https://en.wikipedia.org/wiki/Sound>audio</a>, <a href=https://en.wikipedia.org/wiki/Image>image</a>, and <a href=https://en.wikipedia.org/wiki/Video>video</a>. The primary goal of CLAMS is : (1) to develop an interchange format between multimodal metadata generation tools to ensure interoperability between tools ; (2) to provide users with a portable, user-friendly workflow engine to chain selected tools to extract meaningful analyses ; and (3) to create a public software development kit (SDK) for developers that eases deployment of analysis tools within the CLAMS platform. CLAMS is designed to help archives and libraries enrich the <a href=https://en.wikipedia.org/wiki/Metadata>metadata</a> associated with their mass-digitized multimedia collections, that would otherwise be largely unsearchable.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2514.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-2514 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-2514 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-2514/>On the Feasibility of Automated Detection of Allusive Text Reuse</a></strong><br><a href=/people/e/enrique-manjavacas/>Enrique Manjavacas</a>
|
<a href=/people/b/brian-long/>Brian Long</a>
|
<a href=/people/m/mike-kestemont/>Mike Kestemont</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-2514><div class="card-body p-3 small">The detection of allusive text reuse is particularly challenging due to the sparse evidence on which allusive references rely commonly based on none or very few shared words. Arguably, <a href=https://en.wikipedia.org/wiki/Lexical_semantics>lexical semantics</a> can be resorted to since uncovering semantic relations between words has the potential to increase the support underlying the allusion and alleviate the lexical sparsity. A further obstacle is the lack of evaluation benchmark corpora, largely due to the highly interpretative character of the annotation process. In the present paper, we aim to elucidate the feasibility of automated allusion detection. We approach the matter from an Information Retrieval perspective in which referencing texts act as queries and referenced texts as relevant documents to be retrieved, and estimate the difficulty of benchmark corpus compilation by a novel inter-annotator agreement study on query segmentation. Furthermore, we investigate to what extent the integration of lexical semantic information derived from distributional models and <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontologies</a> can aid retrieving cases of allusive reuse. The results show that (i) despite low agreement scores, using manual queries considerably improves <a href=https://en.wikipedia.org/wiki/Information_retrieval>retrieval</a> performance with respect to a windowing approach, and that (ii) <a href=https://en.wikipedia.org/wiki/Information_retrieval>retrieval</a> performance can be moderately boosted with <a href=https://en.wikipedia.org/wiki/Distributional_semantics>distributional semantics</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-2516.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-2516 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-2516 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-2516" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-2516/>Sign Clustering and Topic Extraction in Proto-Elamite<span class=acl-fixed-case>P</span>roto-<span class=acl-fixed-case>E</span>lamite</a></strong><br><a href=/people/l/logan-born/>Logan Born</a>
|
<a href=/people/k/kate-kelley/>Kate Kelley</a>
|
<a href=/people/n/nishant-kambhatla/>Nishant Kambhatla</a>
|
<a href=/people/c/carolyn-chen/>Carolyn Chen</a>
|
<a href=/people/a/anoop-sarkar/>Anoop Sarkar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-2516><div class="card-body p-3 small">We describe a first attempt at using techniques from <a href=https://en.wikipedia.org/wiki/Computational_linguistics>computational linguistics</a> to analyze the undeciphered proto-Elamite script. Using <a href=https://en.wikipedia.org/wiki/Hierarchical_clustering>hierarchical clustering</a>, n-gram frequencies, and LDA topic models, we both replicate results obtained by manual decipherment and reveal previously-unobserved relationships between signs. This demonstrates the utility of these techniques as an aid to manual decipherment.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>