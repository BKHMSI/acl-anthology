<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Computational Linguistics, Volume 47, Issue 1 - March 2021 - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Computational Linguistics, Volume 47, Issue 1 - March 2021</h2><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2021.cl-1</dd><dt>Month:</dt><dd>March</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Cambridge, MA</dd><dt>Venue:</dt><dd><a href=/venues/cl/>CL</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>MIT Press</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.cl-1>https://aclanthology.org/2021.cl-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Computational+Linguistics%2C+Volume+47%2C+Issue+1+-+March+2021" title="Search for 'Computational Linguistics, Volume 47, Issue 1 - March 2021' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.cl-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--cl-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.cl-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.cl-1.2/>Formal Basis of a Language Universal</a></strong><br><a href=/people/m/milos-stanojevic/>Miloš Stanojević</a>
|
<a href=/people/m/mark-steedman/>Mark Steedman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--cl-1--2><div class="card-body p-3 small">Abstract Steedman (2020) proposes as a formal universal of natural language grammar that grammatical permutations of the kind that have given rise to transformational rules are limited to a class known to mathematicians and computer scientists as the separable permutations. This <a href=https://en.wikipedia.org/wiki/Class_(set_theory)>class of permutations</a> is exactly the <a href=https://en.wikipedia.org/wiki/Class_(set_theory)>class</a> that can be expressed in combinatory categorial grammars (CCGs). The excluded non-separable permutations do in fact seem to be absent in a number of studies of crosslinguistic variation in <a href=https://en.wikipedia.org/wiki/Word_order>word order</a> in nominal and verbal constructions. The number of <a href=https://en.wikipedia.org/wiki/Permutation>permutations</a> that are separable grows in the number n of lexical elements in the construction as the Large Schrder Number Sn1. Because that <a href=https://en.wikipedia.org/wiki/Number>number</a> grows much more slowly than the n ! number of all permutations, this <a href=https://en.wikipedia.org/wiki/Generalization>generalization</a> is also of considerable practical interest for computational applications such as <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a> and <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. The present article examines the mathematical and computational origins of this <a href=https://en.wikipedia.org/wiki/Restriction_(mathematics)>restriction</a>, and the reason it is exactly captured in CCG without the imposition of any further constraints.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.cl-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--cl-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.cl-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.cl-1.4/>Semantic Data Set Construction from Human Clustering and <a href=https://en.wikipedia.org/wiki/Spatial_analysis>Spatial Arrangement</a></a></strong><br><a href=/people/o/olga-majewska/>Olga Majewska</a>
|
<a href=/people/d/diana-mccarthy/>Diana McCarthy</a>
|
<a href=/people/j/jasper-j-f-van-den-bosch/>Jasper J. F. van den Bosch</a>
|
<a href=/people/n/nikolaus-kriegeskorte/>Nikolaus Kriegeskorte</a>
|
<a href=/people/i/ivan-vulic/>Ivan Vulić</a>
|
<a href=/people/a/anna-korhonen/>Anna Korhonen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--cl-1--4><div class="card-body p-3 small">Abstract Research into representation learning models of <a href=https://en.wikipedia.org/wiki/Lexical_semantics>lexical semantics</a> usually utilizes some form of intrinsic evaluation to ensure that the learned representations reflect human semantic judgments. Lexical semantic similarity estimation is a widely used evaluation method, but efforts have typically focused on pairwise judgments of words in isolation, or are limited to specific contexts and lexical stimuli. There are limitations with these approaches that either do not provide any context for judgments, and thereby ignore <a href=https://en.wikipedia.org/wiki/Ambiguity>ambiguity</a>, or provide very specific sentential contexts that can not then be used to generate a larger lexical resource. Furthermore, <a href=https://en.wikipedia.org/wiki/Similarity_(psychology)>similarity</a> between more than two items is not considered. We provide a full description and analysis of our recently proposed methodology for large-scale data set construction that produces a semantic classification of a large sample of verbs in the first phase, as well as multi-way similarity judgments made within the resultant semantic classes in the second phase. The <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> uses a spatial multi-arrangement approach proposed in the field of <a href=https://en.wikipedia.org/wiki/Cognitive_neuroscience>cognitive neuroscience</a> for capturing multi-way similarity judgments of visual stimuli. We have adapted this <a href=https://en.wikipedia.org/wiki/Methodology>method</a> to handle polysemous linguistic stimuli and much larger samples than previous work. We specifically target verbs, but the method can equally be applied to other parts of speech. We perform <a href=https://en.wikipedia.org/wiki/Cluster_analysis>cluster analysis</a> on the data from the first phase and demonstrate how this might be useful in the construction of a comprehensive verb resource. We also analyze the semantic information captured by the second phase and discuss the potential of the spatially induced similarity judgments to better reflect human notions of word similarity. We demonstrate how the resultant data set can be used for fine-grained analyses and evaluation of representation learning models on the intrinsic tasks of semantic clustering and <a href=https://en.wikipedia.org/wiki/Semantic_similarity>semantic similarity</a>. In particular, we find that stronger static word embedding methods still outperform lexical representations emerging from more recent pre-training methods, both on word-level similarity and <a href=https://en.wikipedia.org/wiki/Cluster_analysis>clustering</a>. Moreover, thanks to the data set&#8217;s vast coverage, we are able to compare the benefits of specializing vector representations for a particular type of external knowledge by evaluating FrameNet- and VerbNet-retrofitted models on specific semantic domains such as Heat or Motion.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.cl-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--cl-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.cl-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.cl-1.6" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.cl-1.6/>Supervised and Unsupervised Neural Approaches to Text Readability</a></strong><br><a href=/people/m/matej-martinc/>Matej Martinc</a>
|
<a href=/people/s/senja-pollak/>Senja Pollak</a>
|
<a href=/people/m/marko-robnik-sikonja/>Marko Robnik-Šikonja</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--cl-1--6><div class="card-body p-3 small">Abstract We present a set of novel neural supervised and unsupervised approaches for determining the readability of documents. In the <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised setting</a>, we leverage neural language models, whereas in the <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised setting</a>, three different neural classification architectures are tested. We show that the proposed neural unsupervised approach is robust, transferable across languages, and allows adaptation to a specific readability task and <a href=https://en.wikipedia.org/wiki/Data_set>data set</a>. By systematic comparison of several neural architectures on a number of benchmark and new labeled readability data sets in two languages, this study also offers a comprehensive analysis of different neural approaches to readability classification. We expose their strengths and weaknesses, compare their performance to current state-of-the-art classification approaches to <a href=https://en.wikipedia.org/wiki/Readability>readability</a>, which in most cases still rely on extensive <a href=https://en.wikipedia.org/wiki/Feature_engineering>feature engineering</a>, and propose possibilities for improvements.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.cl-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--cl-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.cl-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.cl-1.7/>Depth-Bounded Statistical PCFG Induction as a Model of Human Grammar Acquisition<span class=acl-fixed-case>PCFG</span> Induction as a Model of Human Grammar Acquisition</a></strong><br><a href=/people/l/lifeng-jin/>Lifeng Jin</a>
|
<a href=/people/l/lane-schwartz/>Lane Schwartz</a>
|
<a href=/people/f/finale-doshi-velez/>Finale Doshi-Velez</a>
|
<a href=/people/t/timothy-miller/>Timothy Miller</a>
|
<a href=/people/w/william-schuler/>William Schuler</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--cl-1--7><div class="card-body p-3 small">Abstract This article describes a simple PCFG induction model with a fixed category domain that predicts a large majority of attested constituent boundaries, and predicts labels consistent with nearly half of attested constituent labels on a standard evaluation data set of child-directed speech. The article then explores the idea that the difference between simple grammars exhibited by child learners and fully <a href=https://en.wikipedia.org/wiki/Recursive_grammar>recursive grammars</a> exhibited by adult learners may be an effect of increasing working memory capacity, where the shallow grammars are constrained images of the <a href=https://en.wikipedia.org/wiki/Recursive_grammar>recursive grammars</a>. An implementation of these memory bounds as limits on <a href=https://en.wikipedia.org/wiki/Center_embedding>center embedding</a> in a depth-specific transform of a <a href=https://en.wikipedia.org/wiki/Recursive_grammar>recursive grammar</a> yields a significant improvement over an equivalent but unbounded baseline, suggesting that this arrangement may indeed confer a learning advantage.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>