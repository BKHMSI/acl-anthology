<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the Workshop on Speech-Centric Natural Language Processing - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/W17-46.pdf>Proceedings of the Workshop on Speech-Centric Natural Language Processing</a></h2><p class=lead><a href=/people/n/nicholas-ruiz/>Nicholas Ruiz</a>,
<a href=/people/s/srinivas-bangalore/>Srinivas Bangalore</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>W17-46</dd><dt>Month:</dt><dd>September</dd><dt>Year:</dt><dd>2017</dd><dt>Address:</dt><dd>Copenhagen, Denmark</dd><dt>Venue:</dt><dd><a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/W17-46>https://aclanthology.org/W17-46</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/W17-46 title="To the current version of the paper by DOI">10.18653/v1/W17-46</a></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/W17-46.pdf>https://aclanthology.org/W17-46.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/W17-46.pdf title="Open PDF of 'Proceedings of the Workshop on Speech-Centric Natural Language Processing'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+Workshop+on+Speech-Centric+Natural+Language+Processing" title="Search for 'Proceedings of the Workshop on Speech-Centric Natural Language Processing' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4600.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4600/>Proceedings of the Workshop on Speech-Centric Natural Language Processing</a></strong><br><a href=/people/n/nicholas-ruiz/>Nicholas Ruiz</a>
|
<a href=/people/s/srinivas-bangalore/>Srinivas Bangalore</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4603.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4603 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4603 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W17-4603.Attachment.zip data-toggle=tooltip data-placement=top title=Attachment><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W17-4603/>Analyzing Human and Machine Performance In Resolving Ambiguous Spoken Sentences</a></strong><br><a href=/people/h/hussein-ghaly/>Hussein Ghaly</a>
|
<a href=/people/m/michael-mandel/>Michael Mandel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4603><div class="card-body p-3 small">Written sentences can be more ambiguous than <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>spoken sentences</a>. We investigate this difference for two different types of <a href=https://en.wikipedia.org/wiki/Ambiguity>ambiguity</a> : prepositional phrase (PP) attachment and sentences where the addition of commas changes the meaning. We recorded a native English speaker saying several of each type of sentence both with and without disambiguating contextual information. These <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentences</a> were then presented either as text or audio and either with or without context to subjects who were asked to select the proper interpretation of the sentence. Results suggest that comma-ambiguous sentences are easier to disambiguate than PP-attachment-ambiguous sentences, possibly due to the presence of clear prosodic boundaries, namely silent pauses. Subject performance for sentences with PP-attachment ambiguity without context was 52 % for text only while it was 72.4 % for <a href=https://en.wikipedia.org/wiki/Sound_recording_and_reproduction>audio only</a>, suggesting that <a href=https://en.wikipedia.org/wiki/Sound_recording_and_reproduction>audio</a> has more disambiguating information than <a href=https://en.wikipedia.org/wiki/Written_language>text</a>. Using an analysis of acoustic features of two PP-attachment sentences, a simple classifier was implemented to resolve the PP-attachment ambiguity being early or late closure with a mean accuracy of 80 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4604.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4604 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4604 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4604/>Parsing transcripts of speech</a></strong><br><a href=/people/a/andrew-caines/>Andrew Caines</a>
|
<a href=/people/m/michael-mccarthy/>Michael McCarthy</a>
|
<a href=/people/p/paula-buttery/>Paula Buttery</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4604><div class="card-body p-3 small">We present an analysis of <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> performance on speech data, comparing word type and token frequency distributions with written data, and evaluating parse accuracy by length of input string. We find that <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> performance tends to deteriorate with increasing length of string, more so for spoken than for written texts. We train an alternative parsing model with added <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech data</a> and demonstrate improvements in <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on speech-units, with no deterioration in performance on <a href=https://en.wikipedia.org/wiki/Written_language>written text</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4606.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4606 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4606 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-4606" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-4606/>End-to-End Information Extraction without Token-Level Supervision</a></strong><br><a href=/people/r/rasmus-berg-palm/>Rasmus Berg Palm</a>
|
<a href=/people/d/dirk-hovy/>Dirk Hovy</a>
|
<a href=/people/f/florian-laws/>Florian Laws</a>
|
<a href=/people/o/ole-winther/>Ole Winther</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4606><div class="card-body p-3 small">Most state-of-the-art information extraction approaches rely on token-level labels to find the areas of interest in text. Unfortunately, these labels are time-consuming and costly to create, and consequently, not available for many real-life IE tasks. To make matters worse, token-level labels are usually not the desired output, but just an intermediary step. End-to-end (E2E) models, which take raw text as input and produce the desired output directly, need not depend on token-level labels. We propose an E2E model based on pointer networks, which can be trained directly on pairs of raw input and output text. We evaluate our model on the ATIS data set, MIT restaurant corpus and the MIT movie corpus and compare to neural baselines that do use token-level labels. We achieve competitive results, within a few percentage points of the baselines, showing the feasibility of E2E information extraction without the need for token-level labels. This opens up new possibilities, as for many tasks currently addressed by human extractors, raw input and output data are available, but not token-level labels.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4607.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4607 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4607 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4607/>Spoken Term Discovery for <a href=https://en.wikipedia.org/wiki/Language_documentation>Language Documentation</a> using Translations</a></strong><br><a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a>
|
<a href=/people/s/sameer-bansal/>Sameer Bansal</a>
|
<a href=/people/d/david-chiang/>David Chiang</a>
|
<a href=/people/s/sharon-goldwater/>Sharon Goldwater</a>
|
<a href=/people/a/adam-lopez/>Adam Lopez</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4607><div class="card-body p-3 small">Vast amounts of speech data collected for <a href=https://en.wikipedia.org/wiki/Language_documentation>language documentation</a> and research remain untranscribed and unsearchable, but often a small amount of speech may have text translations available. We present a <a href=https://en.wikipedia.org/wiki/Methodology>method</a> for partially labeling additional speech with translations in this <a href=https://en.wikipedia.org/wiki/Scenario>scenario</a>. We modify an unsupervised speech-to-translation alignment model and obtain prototype speech segments that match the translation words, which are in turn used to discover terms in the unlabelled data. We evaluate our method on a Spanish-English speech translation corpus and on two corpora of endangered languages, <a href=https://en.wikipedia.org/wiki/Arapaho_language>Arapaho</a> and Ainu, demonstrating its appropriateness and applicability in an actual very-low-resource scenario.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4608.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4608 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4608 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4608/>Amharic-English Speech Translation in Tourism Domain<span class=acl-fixed-case>A</span>mharic-<span class=acl-fixed-case>E</span>nglish Speech Translation in Tourism Domain</a></strong><br><a href=/people/m/michael-melese/>Michael Melese</a>
|
<a href=/people/l/laurent-besacier/>Laurent Besacier</a>
|
<a href=/people/m/million-meshesha/>Million Meshesha</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4608><div class="card-body p-3 small">This paper describes speech translation from Amharic-to-English, particularly Automatic Speech Recognition (ASR) with post-editing feature and Amharic-English Statistical Machine Translation (SMT). ASR experiment is conducted using morpheme language model (LM) and phoneme acoustic model(AM). Likewise, SMT conducted using word and morpheme as unit. Morpheme based translation shows a 6.29 BLEU score at a 76.4 % of recognition accuracy while word based translation shows a 12.83 BLEU score using 77.4 % word recognition accuracy. Further, after post-edit on Amharic ASR using <a href=https://en.wikipedia.org/wiki/Corpus_linguistics>corpus based n-gram</a>, the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>word recognition accuracy</a> increased by 1.42 %. Since post-edit approach reduces <a href=https://en.wikipedia.org/wiki/Propagation_of_uncertainty>error propagation</a>, the word based translation accuracy improved by 0.25 (1.95 %) BLEU score. We are now working towards further improving propagated errors through different <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> at each unit of speech translation cascading component.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-4609.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-4609 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-4609 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-4609/>Speech- and Text-driven Features for Automated Scoring of English Speaking Tasks<span class=acl-fixed-case>E</span>nglish Speaking Tasks</a></strong><br><a href=/people/a/anastassia-loukina/>Anastassia Loukina</a>
|
<a href=/people/n/nitin-madnani/>Nitin Madnani</a>
|
<a href=/people/a/aoife-cahill/>Aoife Cahill</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-4609><div class="card-body p-3 small">We consider the automatic scoring of a <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> for which both the content of the response as well its spoken fluency are important. We combine <a href=https://en.wikipedia.org/wiki/Software_feature>features</a> from a text-only content scoring system originally designed for written responses with several categories of acoustic features. Although adding any single category of acoustic features to the text-only system on its own does not significantly improve performance, adding all acoustic features together does yield a small but significant improvement. These results are consistent for responses to open-ended questions and to questions focused on some given source material.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>