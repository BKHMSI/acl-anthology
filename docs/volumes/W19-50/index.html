<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 18th BioNLP Workshop and Shared Task - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/W19-50.pdf>Proceedings of the 18th BioNLP Workshop and Shared Task</a></h2><p class=lead><a href=/people/d/dina-demner-fushman/>Dina Demner-Fushman</a>,
<a href=/people/k/k-bretonnel-cohen/>Kevin Bretonnel Cohen</a>,
<a href=/people/s/sophia-ananiadou/>Sophia Ananiadou</a>,
<a href=/people/j/junichi-tsujii/>Junichi Tsujii</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>W19-50</dd><dt>Month:</dt><dd>August</dd><dt>Year:</dt><dd>2019</dd><dt>Address:</dt><dd>Florence, Italy</dd><dt>Venues:</dt><dd><a href=/venues/acl/>ACL</a>
| <a href=/venues/bionlp/>BioNLP</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd><a href=/sigs/sigbiomed/>SIGBIOMED</a></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/W19-50>https://aclanthology.org/W19-50</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/W19-50.pdf>https://aclanthology.org/W19-50.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/W19-50.pdf title="Open PDF of 'Proceedings of the 18th BioNLP Workshop and Shared Task'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+18th+BioNLP+Workshop+and+Shared+Task" title="Search for 'Proceedings of the 18th BioNLP Workshop and Shared Task' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5000/>Proceedings of the 18th BioNLP Workshop and Shared Task</a></strong><br><a href=/people/d/dina-demner-fushman/>Dina Demner-Fushman</a>
|
<a href=/people/k/k-bretonnel-cohen/>Kevin Bretonnel Cohen</a>
|
<a href=/people/s/sophia-ananiadou/>Sophia Ananiadou</a>
|
<a href=/people/j/junichi-tsujii/>Junichi Tsujii</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5002 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5002/>Learning from the Experience of Doctors : Automated Diagnosis of Appendicitis Based on Clinical Notes</a></strong><br><a href=/people/s/steven-kester-yuwono/>Steven Kester Yuwono</a>
|
<a href=/people/h/hwee-tou-ng/>Hwee Tou Ng</a>
|
<a href=/people/k/kee-yuan-ngiam/>Kee Yuan Ngiam</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5002><div class="card-body p-3 small">The objective of this work is to develop an automated diagnosis system that is able to predict the probability of appendicitis given a free-text emergency department (ED) note and additional structured information (e.g., lab test results). Our clinical corpus consists of about 180,000 ED notes based on ten years of patient visits to the Accident and Emergency (A&E) Department of the National University Hospital (NUH), Singapore. We propose a novel neural network approach that learns to diagnose <a href=https://en.wikipedia.org/wiki/Appendicitis>acute appendicitis</a> based on doctors&#8217; free-text ED notes without any <a href=https://en.wikipedia.org/wiki/Feature_engineering>feature engineering</a>. On a test set of 2,000 ED notes with equal number of appendicitis (positive) and non-appendicitis (negative) diagnosis and in which all the negative ED notes only consist of abdominal-related diagnosis, our model is able to achieve a promising F_0.5-score of 0.895 while <a href=https://en.wikipedia.org/wiki/Emergency_department>ED doctors</a> achieve F_0.5-score of 0.900. Visualization shows that our model is able to learn important features, signs, and symptoms of patients from unstructured free-text ED notes, which will help doctors to make better diagnosis.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5003 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5003/>A Paraphrase Generation System for EHR Question Answering<span class=acl-fixed-case>EHR</span> Question Answering</a></strong><br><a href=/people/s/sarvesh-soni/>Sarvesh Soni</a>
|
<a href=/people/k/kirk-roberts/>Kirk Roberts</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5003><div class="card-body p-3 small">This paper proposes a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> and method for automatically generating paraphrases for clinical questions relating to patient-specific information in electronic health records (EHRs). Crowdsourcing is used to collect 10,578 unique questions across 946 semantically distinct paraphrase clusters. This <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> is then used with a deep learning-based question paraphrasing method utilizing variational autoencoder and LSTM encoder / decoder. The ultimate use of such a <a href=https://en.wikipedia.org/wiki/Methodology>method</a> is to improve the performance of automatic question answering methods for <a href=https://en.wikipedia.org/wiki/Electronic_health_record>EHRs</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5006.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5006 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5006 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-5006" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-5006/>Transfer Learning in Biomedical Natural Language Processing : An Evaluation of BERT and ELMo on Ten Benchmarking Datasets<span class=acl-fixed-case>BERT</span> and <span class=acl-fixed-case>ELM</span>o on Ten Benchmarking Datasets</a></strong><br><a href=/people/y/yifan-peng/>Yifan Peng</a>
|
<a href=/people/s/shankai-yan/>Shankai Yan</a>
|
<a href=/people/z/zhiyong-lu/>Zhiyong Lu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5006><div class="card-body p-3 small">Inspired by the success of the General Language Understanding Evaluation benchmark, we introduce the Biomedical Language Understanding Evaluation (BLUE) benchmark to facilitate research in the development of pre-training language representations in the biomedicine domain. The <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark</a> consists of five tasks with ten <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> that cover both biomedical and clinical texts with different dataset sizes and difficulties. We also evaluate several baselines based on <a href=https://en.wikipedia.org/wiki/Brain-derived_neurotrophic_factor>BERT</a> and ELMo and find that the <a href=https://en.wikipedia.org/wiki/Brain-derived_neurotrophic_factor>BERT model</a> pre-trained on PubMed abstracts and MIMIC-III clinical notes achieves the best results. We make the datasets, pre-trained models, and codes publicly available at https://github.com/ ncbi-nlp / BLUE_Benchmark.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5007.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5007 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5007 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-5007" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-5007/>Combining Structured and Free-text Electronic Medical Record Data for Real-time Clinical Decision Support</a></strong><br><a href=/people/e/emilia-apostolova/>Emilia Apostolova</a>
|
<a href=/people/t/tony-wang/>Tony Wang</a>
|
<a href=/people/t/tim-tschampel/>Tim Tschampel</a>
|
<a href=/people/i/ioannis-koutroulis/>Ioannis Koutroulis</a>
|
<a href=/people/t/tom-velez/>Tom Velez</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5007><div class="card-body p-3 small">The goal of this work is to utilize Electronic Medical Record (EMR) data for real-time Clinical Decision Support (CDS). We present a deep learning approach to combining in real time available diagnosis codes (ICD codes) and free-text notes : Patient Context Vectors. Patient Context Vectors are created by averaging ICD code embeddings, and by predicting the same from free-text notes via a <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>Convolutional Neural Network</a>. The Patient Context Vectors were then simply appended to available structured data (vital signs and lab results) to build prediction models for a specific condition. Experiments on predicting ARDS, a rare and complex condition, demonstrate the utility of Patient Context Vectors as a means of summarizing the patient history and overall condition, and improve significantly the prediction model results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5010.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5010 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5010 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5010/>Deep Contextualized Biomedical Abbreviation Expansion</a></strong><br><a href=/people/q/qiao-jin/>Qiao Jin</a>
|
<a href=/people/j/jinling-liu/>Jinling Liu</a>
|
<a href=/people/x/xinghua-lu/>Xinghua Lu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5010><div class="card-body p-3 small">Automatic identification and expansion of ambiguous abbreviations are essential for biomedical natural language processing applications, such as <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval</a> and question answering systems. In this paper, we present DEep Contextualized Biomedical Abbreviation Expansion (DECBAE) model. DECBAE automatically collects substantial and relatively clean annotated contexts for 950 ambiguous abbreviations from PubMed abstracts using a simple <a href=https://en.wikipedia.org/wiki/Heuristic>heuristic</a>. Then it utilizes BioELMo to extract the contextualized features of words, and feed those <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> to abbreviation-specific bidirectional LSTMs, where the hidden states of the ambiguous abbreviations are used to assign the exact definitions. Our DECBAE model outperforms other baselines by large margins, achieving average accuracy of 0.961 and macro-F1 of 0.917 on the dataset. It also surpasses human performance for expanding a sample abbreviation, and remains robust in imbalanced, low-resources and clinical settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5011.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5011 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5011 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-5011" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-5011/>RNN Embeddings for Identifying Difficult to Understand Medical Words<span class=acl-fixed-case>RNN</span> Embeddings for Identifying Difficult to Understand Medical Words</a></strong><br><a href=/people/h/hanna-pylieva/>Hanna Pylieva</a>
|
<a href=/people/a/artem-chernodub/>Artem Chernodub</a>
|
<a href=/people/n/natalia-grabar/>Natalia Grabar</a>
|
<a href=/people/t/thierry-hamon/>Thierry Hamon</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5011><div class="card-body p-3 small">Patients and their families often require a better understanding of medical information provided by doctors. We currently address this issue by improving the identification of difficult to understand medical words. We introduce novel embeddings received from RNN-FrnnMUTE (French RNN Medical Understandability Text Embeddings) which allow to reach up to 87.0 F1 score in identification of difficult words. We also note that adding pre-trained FastText word embeddings to the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature set</a> substantially improves the performance of the model which classifies words according to their difficulty. We study the generalizability of different <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> through three cross-validation scenarios which allow testing <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> in real-world conditions : understanding of medical words by new users, and classification of new unseen words by the automatic models. The RNN-FrnnMUTE embeddings and the categorization code are being made available for the research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5012 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5012/>A distantly supervised dataset for <a href=https://en.wikipedia.org/wiki/Data_extraction>automated data extraction</a> from diagnostic studies</a></strong><br><a href=/people/c/christopher-norman/>Christopher Norman</a>
|
<a href=/people/m/mariska-leeflang/>Mariska Leeflang</a>
|
<a href=/people/r/rene-spijker/>René Spijker</a>
|
<a href=/people/e/evangelos-kanoulas/>Evangelos Kanoulas</a>
|
<a href=/people/a/aurelie-neveol/>Aurélie Névéol</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5012><div class="card-body p-3 small">Systematic reviews are important in <a href=https://en.wikipedia.org/wiki/Evidence-based_medicine>evidence based medicine</a>, but are expensive to produce. Automating or semi-automating the data extraction of index test, target condition, and reference standard from articles has the potential to decrease the cost of conducting <a href=https://en.wikipedia.org/wiki/Systematic_review>systematic reviews</a> of diagnostic test accuracy, but relevant training data is not available. We create a distantly supervised dataset of approximately 90,000 sentences, and let two experts manually annotate a small subset of around 1,000 sentences for evaluation. We evaluate the performance of BioBERT and logistic regression for <a href=https://en.wikipedia.org/wiki/Ranking>ranking</a> the sentences, and compare the performance for distant and direct supervision. Our results suggest that distant supervision can work as well as, or better than direct supervision on this problem, and that distantly trained models can perform as well as, or better than human annotators.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5015.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5015 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5015 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5015/>A Comparison of Word-based and Context-based Representations for Classification Problems in Health Informatics</a></strong><br><a href=/people/a/aditya-joshi/>Aditya Joshi</a>
|
<a href=/people/s/sarvnaz-karimi/>Sarvnaz Karimi</a>
|
<a href=/people/r/ross-sparks/>Ross Sparks</a>
|
<a href=/people/c/cecile-paris/>Cecile Paris</a>
|
<a href=/people/c/c-raina-macintyre/>C Raina MacIntyre</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5015><div class="card-body p-3 small">Distributed representations of text can be used as <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> when training a <a href=https://en.wikipedia.org/wiki/Statistical_classification>statistical classifier</a>. These <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a> may be created as a composition of word vectors or as context-based sentence vectors. We compare the two kinds of representations (word versus context) for three classification problems : influenza infection classification, drug usage classification and personal health mention classification. For statistical classifiers trained for each of these problems, context-based representations based on ELMo, Universal Sentence Encoder, Neural-Net Language Model and <a href=https://en.wikipedia.org/wiki/FLAIR>FLAIR</a> are better than Word2Vec, <a href=https://en.wikipedia.org/wiki/GloVe_(machine_learning)>GloVe</a> and the two adapted using the MESH ontology. There is an improvement of 2-4 % in the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> when these context-based representations are used instead of word-based representations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5021.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5021 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5021 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-5021" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-5021/>Annotating Temporal Information in Clinical Notes for Timeline Reconstruction : Towards the Definition of Calendar Expressions</a></strong><br><a href=/people/n/natalia-viani/>Natalia Viani</a>
|
<a href=/people/h/hegler-tissot/>Hegler Tissot</a>
|
<a href=/people/a/ariane-bernardino/>Ariane Bernardino</a>
|
<a href=/people/s/sumithra-velupillai/>Sumithra Velupillai</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5021><div class="card-body p-3 small">To automatically analyse complex trajectory information enclosed in clinical text (e.g. timing of symptoms, duration of treatment), it is important to understand the related temporal aspects, anchoring each event on an absolute point in time. In the clinical domain, few temporally annotated corpora are currently available. Moreover, underlying annotation schemas-which mainly rely on the TimeML standard-are not necessarily easily applicable for applications such as patient timeline reconstruction. In this work, we investigated how temporal information is documented in clinical text by annotating a corpus of medical reports with time expressions (TIMEXes), based on <a href=https://en.wikipedia.org/wiki/TimeML>TimeML</a>. The developed <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> is available to the NLP community. Starting from our annotations, we analysed the suitability of the TimeML TIMEX schema for capturing timeline information, identifying challenges and possible solutions. As a result, we propose a novel annotation schema that could be useful for timeline reconstruction : CALendar EXpression (CALEX).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5023.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5023 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5023 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5023/>Enhancing PIO Element Detection in Medical Text Using Contextualized Embedding<span class=acl-fixed-case>PIO</span> Element Detection in Medical Text Using Contextualized Embedding</a></strong><br><a href=/people/h/hichem-mezaoui/>Hichem Mezaoui</a>
|
<a href=/people/i/isuru-gunasekara/>Isuru Gunasekara</a>
|
<a href=/people/a/aleksandr-gontcharov/>Aleksandr Gontcharov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5023><div class="card-body p-3 small">In this paper, we presented an improved <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> to extract PIO elements, from abstracts of medical papers, that reduces <a href=https://en.wikipedia.org/wiki/Ambiguity>ambiguity</a>. The proposed technique was used to build a dataset of PIO elements that we call <a href=https://en.wikipedia.org/wiki/Piconet>PICONET</a>. We further proposed a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> of PIO elements classification using state of the art BERT embedding. In addition, we investigated a contextualized embedding, BioBERT, trained on medical corpora. It has been found that using the BioBERT embedding improved the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification accuracy</a>, outperforming the BERT-based model. This result reinforces the idea of the importance of embedding contextualization in subsequent classification tasks in this specific context. Furthermore, to enhance the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of the model, we have investigated an <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensemble method</a> based on the LGBM algorithm. We trained the LGBM model, with the above models as base learners, to learn a linear combination of the predicted probabilities for the 3 classes with the TF-IDF score and the QIEF that optimizes the classification. The results indicate that these <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>text features</a> were good features to consider in order to boost the deeply contextualized classification model. We compared the performance of the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> when using the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> with one of the base learners and the case where we combine the base learners along with the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a>. We obtained the highest score in terms of <a href=https://en.wikipedia.org/wiki/Analysis_of_covariance>AUC</a> when we combine the base learners. The present work resulted in the creation of a PIO element dataset, PICONET, and a classification tool. These constitute and important component of our system of automatic mining of medical abstracts. We intend to extend the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> to <a href=https://en.wikipedia.org/wiki/Medical_literature>full medical articles</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5025.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5025 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5025 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5025/>Can Character Embeddings Improve Cause-of-Death Classification for Verbal Autopsy Narratives?</a></strong><br><a href=/people/z/zhaodong-yan/>Zhaodong Yan</a>
|
<a href=/people/s/serena-jeblee/>Serena Jeblee</a>
|
<a href=/people/g/graeme-hirst/>Graeme Hirst</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5025><div class="card-body p-3 small">We present two models for combining word and character embeddings for cause-of-death classification of verbal autopsy reports using the text of the narratives. We find that for smaller datasets (500 to 1000 records), adding character information to the model improves <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a>, making character-based CNNs a promising method for automated verbal autopsy coding.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5026.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5026 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5026 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5026/>Is artificial data useful for biomedical Natural Language Processing algorithms?</a></strong><br><a href=/people/z/zixu-wang/>Zixu Wang</a>
|
<a href=/people/j/julia-ive/>Julia Ive</a>
|
<a href=/people/s/sumithra-velupillai/>Sumithra Velupillai</a>
|
<a href=/people/l/lucia-specia/>Lucia Specia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5026><div class="card-body p-3 small">A major obstacle to the development of Natural Language Processing (NLP) methods in the biomedical domain is data accessibility. This problem can be addressed by generating medical data artificially. Most previous studies have focused on the generation of short clinical text, and evaluation of the data utility has been limited. We propose a generic <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> to guide the generation of clinical text with key phrases. We use the artificial data as additional training data in two key biomedical NLP tasks : <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a> and temporal relation extraction. We show that artificially generated training data used in conjunction with real training data can lead to performance boosts for data-greedy neural network algorithms. We also demonstrate the usefulness of the generated data for NLP setups where it fully replaces real training data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5027.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5027 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5027 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-5027" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-5027/>ChiMed : A Chinese Medical Corpus for <a href=https://en.wikipedia.org/wiki/Question_answering>Question Answering</a><span class=acl-fixed-case>C</span>hi<span class=acl-fixed-case>M</span>ed: A <span class=acl-fixed-case>C</span>hinese Medical Corpus for Question Answering</a></strong><br><a href=/people/y/yuanhe-tian/>Yuanhe Tian</a>
|
<a href=/people/w/weicheng-ma/>Weicheng Ma</a>
|
<a href=/people/f/fei-xia/>Fei Xia</a>
|
<a href=/people/y/yan-song/>Yan Song</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5027><div class="card-body p-3 small">Question answering (QA) is a challenging task in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP)</a>, especially when it is applied to specific domains. While <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> trained in the <a href=https://en.wikipedia.org/wiki/Domain_(biology)>general domain</a> can be adapted to a new target domain, their performance often degrades significantly due to domain mismatch. Alternatively, one can require a large amount of domain-specific QA data, but such <a href=https://en.wikipedia.org/wiki/Data>data</a> are rare, especially for the medical domain. In this study, we first collect a large-scale Chinese medical QA corpus called ChiMed ; second we annotate a small fraction of the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> to check the quality of the answers ; third, we extract two datasets from the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> and use them for the relevancy prediction task and the adoption prediction task. Several <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark models</a> are applied to the <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, producing good results for both <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5038.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5038 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5038 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5038/>Extracting relations between outcomes and <a href=https://en.wikipedia.org/wiki/Statistical_significance>significance levels</a> in Randomized Controlled Trials (RCTs) publications<span class=acl-fixed-case>RCT</span>s) publications</a></strong><br><a href=/people/a/anna-koroleva/>Anna Koroleva</a>
|
<a href=/people/p/patrick-paroubek/>Patrick Paroubek</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5038><div class="card-body p-3 small">Randomized controlled trials assess the effects of an experimental intervention by comparing it to a control intervention with regard to some variables-trial outcomes. Statistical hypothesis testing is used to test if the <a href=https://en.wikipedia.org/wiki/Design_of_experiments>experimental intervention</a> is superior to the <a href=https://en.wikipedia.org/wiki/Scientific_control>control</a>. Statistical significance is typically reported for the measured outcomes and is an important characteristic of the results. We propose a machine learning approach to automatically extract reported outcomes, <a href=https://en.wikipedia.org/wiki/Statistical_significance>significance levels</a> and the relation between them. We annotated a corpus of 663 sentences with 2,552 outcome-significance level relations (1,372 positive and 1,180 negative relations). We compared several <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a>, using a manually crafted feature set, and a number of <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning models</a>. The best performance (F-measure of 94 %) was shown by the BioBERT fine-tuned model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5039.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5039 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5039 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-5039" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-5039/>Overview of the MEDIQA 2019 Shared Task on Textual Inference, <a href=https://en.wikipedia.org/wiki/Question_answering>Question Entailment</a> and <a href=https://en.wikipedia.org/wiki/Question_answering>Question Answering</a><span class=acl-fixed-case>MEDIQA</span> 2019 Shared Task on Textual Inference, Question Entailment and Question Answering</a></strong><br><a href=/people/a/asma-ben-abacha/>Asma Ben Abacha</a>
|
<a href=/people/c/chaitanya-shivade/>Chaitanya Shivade</a>
|
<a href=/people/d/dina-demner-fushman/>Dina Demner-Fushman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5039><div class="card-body p-3 small">This paper presents the MEDIQA 2019 shared task organized at the ACL-BioNLP workshop. The shared task is motivated by a need to develop relevant methods, techniques and gold standards for <a href=https://en.wikipedia.org/wiki/Inference>inference</a> and entailment in the medical domain, and their application to improve domain specific information retrieval and question answering systems. MEDIQA 2019 includes three tasks : Natural Language Inference (NLI), Recognizing Question Entailment (RQE), and Question Answering (QA) in the medical domain. 72 teams participated in the challenge, achieving an accuracy of 98 % in the NLI task, 74.9 % in the RQE task, and 78.3 % in the QA task. In this paper, we describe the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>, the <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, and the participants&#8217; approaches and results. We hope that this shared task will attract further research efforts in textual inference, question entailment, and <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a> in the medical domain.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5043.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5043 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5043 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5043/>Surf at MEDIQA 2019 : Improving Performance of Natural Language Inference in the Clinical Domain by Adopting Pre-trained Language Model<span class=acl-fixed-case>MEDIQA</span> 2019: Improving Performance of Natural Language Inference in the Clinical Domain by Adopting Pre-trained Language Model</a></strong><br><a href=/people/j/jiin-nam/>Jiin Nam</a>
|
<a href=/people/s/seunghyun-yoon/>Seunghyun Yoon</a>
|
<a href=/people/k/kyomin-jung/>Kyomin Jung</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5043><div class="card-body p-3 small">While deep learning techniques have shown promising results in many natural language processing (NLP) tasks, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> has not been widely applied to the clinical domain. The lack of <a href=https://en.wikipedia.org/wiki/Data_set>large datasets</a> and the pervasive use of <a href=https://en.wikipedia.org/wiki/Domain-specific_language>domain-specific language</a> (i.e. abbreviations and acronyms) in the clinical domain causes slower progress in NLP tasks than that of the general NLP tasks. To fill this gap, we employ word / subword-level based models that adopt large-scale data-driven methods such as pre-trained language models and <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> in analyzing text for the clinical domain. Empirical results demonstrate the superiority of the proposed <a href=https://en.wikipedia.org/wiki/Numerical_methods_for_ordinary_differential_equations>methods</a> by achieving 90.6 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> in <a href=https://en.wikipedia.org/wiki/Numerical_methods_for_ordinary_differential_equations>medical domain natural language inference task</a>. Furthermore, we inspect the independent strengths of the proposed approaches in quantitative and qualitative manners. This analysis will help researchers to select necessary components in building <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> for the <a href=https://en.wikipedia.org/wiki/Medicine>medical domain</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5044.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5044 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5044 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W19-5044" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W19-5044/>WTMED at MEDIQA 2019 : A Hybrid Approach to Biomedical Natural Language Inference<span class=acl-fixed-case>WTMED</span> at <span class=acl-fixed-case>MEDIQA</span> 2019: A Hybrid Approach to Biomedical Natural Language Inference</a></strong><br><a href=/people/z/zhaofeng-wu/>Zhaofeng Wu</a>
|
<a href=/people/y/yan-song/>Yan Song</a>
|
<a href=/people/s/sicong-huang/>Sicong Huang</a>
|
<a href=/people/y/yuanhe-tian/>Yuanhe Tian</a>
|
<a href=/people/f/fei-xia/>Fei Xia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5044><div class="card-body p-3 small">Natural language inference (NLI) is challenging, especially when <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> is applied to technical domains such as <a href=https://en.wikipedia.org/wiki/Biomedical_sciences>biomedical settings</a>. In this paper, we propose a hybrid approach to biomedical NLI where different types of information are exploited for this task. Our base model includes a pre-trained text encoder as the core component, and a syntax encoder and a feature encoder to capture syntactic and domain-specific information. Then we combine the output of different base models to form more powerful ensemble models. Finally, we design two conflict resolution strategies when the test data contain multiple (premise, hypothesis) pairs with the same premise. We train our <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> on the MedNLI dataset, yielding the best performance on the test set of the MEDIQA 2019 Task 1.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5045.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5045 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5045 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5045/>KU_ai at MEDIQA 2019 : Domain-specific Pre-training and Transfer Learning for Medical NLI<span class=acl-fixed-case>KU</span>_ai at <span class=acl-fixed-case>MEDIQA</span> 2019: Domain-specific Pre-training and Transfer Learning for Medical <span class=acl-fixed-case>NLI</span></a></strong><br><a href=/people/c/cemil-cengiz/>Cemil Cengiz</a>
|
<a href=/people/u/ulas-sert/>Ulaş Sert</a>
|
<a href=/people/d/deniz-yuret/>Deniz Yuret</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5045><div class="card-body p-3 small">In this paper, we describe our <a href=https://en.wikipedia.org/wiki/System>system</a> and results submitted for the Natural Language Inference (NLI) track of the MEDIQA 2019 Shared Task. As KU_ai team, we used BERT as our baseline model and pre-processed the MedNLI dataset to mitigate the negative impact of de-identification artifacts. Moreover, we investigated different pre-training and transfer learning approaches to improve the performance. We show that pre-training the <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> on rich biomedical corpora has a significant effect in teaching the model domain-specific language. In addition, training the model on large NLI datasets such as MultiNLI and SNLI helps in learning task-specific reasoning. Finally, we ensembled our highest-performing <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>, and achieved 84.7 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on the unseen test dataset and ranked 10th out of 17 teams in the official results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5048.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5048 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5048 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5048/>Dr. Quad at MEDIQA 2019 : Towards Textual Inference and Question Entailment using contextualized representations<span class=acl-fixed-case>D</span>r.<span class=acl-fixed-case>Q</span>uad at <span class=acl-fixed-case>MEDIQA</span> 2019: Towards Textual Inference and Question Entailment using contextualized representations</a></strong><br><a href=/people/v/vinayshekhar-bannihatti-kumar/>Vinayshekhar Bannihatti Kumar</a>
|
<a href=/people/a/ashwin-srinivasan/>Ashwin Srinivasan</a>
|
<a href=/people/a/aditi-chaudhary/>Aditi Chaudhary</a>
|
<a href=/people/j/james-route/>James Route</a>
|
<a href=/people/t/teruko-mitamura/>Teruko Mitamura</a>
|
<a href=/people/e/eric-nyberg/>Eric Nyberg</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5048><div class="card-body p-3 small">This paper presents the submissions by TeamDr. Quad to the ACL-BioNLP 2019 shared task on Textual Inference and Question Entailment in the Medical Domain. Our <a href=https://en.wikipedia.org/wiki/System>system</a> is based on the prior work Liu et al. (2019) which uses a multi-task objective function for <a href=https://en.wikipedia.org/wiki/Textual_entailment>textual entailment</a>. In this work, we explore different strategies for generalizing state-of-the-art language understanding models to the specialized medical domain. Our results on the shared task demonstrate that incorporating <a href=https://en.wikipedia.org/wiki/Domain_knowledge>domain knowledge</a> through <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> is a powerful strategy for addressing challenges posed specialized domains such as <a href=https://en.wikipedia.org/wiki/Medicine>medicine</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5049.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5049 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5049 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5049/>Sieg at MEDIQA 2019 : Multi-task Neural Ensemble for Biomedical Inference and Entailment<span class=acl-fixed-case>MEDIQA</span> 2019: Multi-task Neural Ensemble for Biomedical Inference and Entailment</a></strong><br><a href=/people/s/sai-abishek-bhaskar/>Sai Abishek Bhaskar</a>
|
<a href=/people/r/rashi-rungta/>Rashi Rungta</a>
|
<a href=/people/j/james-route/>James Route</a>
|
<a href=/people/e/eric-nyberg/>Eric Nyberg</a>
|
<a href=/people/t/teruko-mitamura/>Teruko Mitamura</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5049><div class="card-body p-3 small">This paper presents a multi-task learning approach to natural language inference (NLI) and question entailment (RQE) in the biomedical domain. Recognizing textual inference relations and question similarity can address the issue of answering new consumer health questions by mapping them to Frequently Asked Questions on reputed websites like the NIH. We show that leveraging information from parallel tasks across domains along with medical knowledge integration allows our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to learn better biomedical feature representations. Our final models for the NLI and RQE tasks achieve the 4th and 2nd rank on the shared-task leaderboard respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5052.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5052 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5052 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5052/>MSIT_SRIB at MEDIQA 2019 : Knowledge Directed Multi-task Framework for Natural Language Inference in Clinical Domain.<span class=acl-fixed-case>MSIT</span>_<span class=acl-fixed-case>SRIB</span> at <span class=acl-fixed-case>MEDIQA</span> 2019: Knowledge Directed Multi-task Framework for Natural Language Inference in Clinical Domain.</a></strong><br><a href=/people/s/sahil-chopra/>Sahil Chopra</a>
|
<a href=/people/a/ankita-gupta/>Ankita Gupta</a>
|
<a href=/people/a/anupama-kaushik/>Anupama Kaushik</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5052><div class="card-body p-3 small">In this paper, we present Biomedical Multi-Task Deep Neural Network (Bio-MTDNN) on the NLI task of MediQA 2019 challenge. Bio-MTDNN utilizes transfer learning based paradigm where not only the source and target domains are different but also the source and target tasks are varied, although related. Further, Bio-MTDNN integrates knowledge from external sources such as clinical databases (UMLS) enhancing its performance on the clinical domain. Our proposed method outperformed the official baseline and other prior models (such as ESIM and Infersent on dev set) by a considerable margin as evident from our experimental results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5056.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5056 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5056 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5056/>IITP at MEDIQA 2019 : Systems Report for Natural Language Inference, Question Entailment and Question Answering<span class=acl-fixed-case>IITP</span> at <span class=acl-fixed-case>MEDIQA</span> 2019: Systems Report for Natural Language Inference, Question Entailment and Question Answering</a></strong><br><a href=/people/d/dibyanayan-bandyopadhyay/>Dibyanayan Bandyopadhyay</a>
|
<a href=/people/b/baban-gain/>Baban Gain</a>
|
<a href=/people/t/tanik-saikh/>Tanik Saikh</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5056><div class="card-body p-3 small">This paper presents the experiments accomplished as a part of our participation in the MEDIQA challenge, an (Abacha et al., 2019) shared task. We participated in all the three <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> defined in this particular <a href=https://en.wikipedia.org/wiki/Task_(project_management)>shared task</a>. The <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> are viz. i. Natural Language Inference (NLI) ii. Recognizing Question Entailment(RQE) and their application in medical Question Answering (QA). We submitted runs using multiple deep learning based systems (runs) for each of these three tasks. We submitted five <a href=https://en.wikipedia.org/wiki/System>system</a> results in each of the NLI and RQE tasks, and four system results for the QA task. The <a href=https://en.wikipedia.org/wiki/System>systems</a> yield encouraging results in all the three <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. The highest performance obtained in NLI, RQE and QA tasks are 81.8 %, 53.2 %, and 71.7 %, respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-5057.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-5057 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-5057 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-5057/>LasigeBioTM at MEDIQA 2019 : Biomedical Question Answering using Bidirectional Transformers and Named Entity Recognition<span class=acl-fixed-case>L</span>asige<span class=acl-fixed-case>B</span>io<span class=acl-fixed-case>TM</span> at <span class=acl-fixed-case>MEDIQA</span> 2019: Biomedical Question Answering using Bidirectional Transformers and Named Entity Recognition</a></strong><br><a href=/people/a/andre-lamurias/>Andre Lamurias</a>
|
<a href=/people/f/francisco-m-couto/>Francisco M Couto</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-5057><div class="card-body p-3 small">Biomedical Question Answering (QA) aims at providing automated answers to user questions, regarding a variety of biomedical topics. For example, these questions may ask for related to <a href=https://en.wikipedia.org/wiki/Disease>diseases</a>, <a href=https://en.wikipedia.org/wiki/Drug>drugs</a>, <a href=https://en.wikipedia.org/wiki/Symptom>symptoms</a>, or <a href=https://en.wikipedia.org/wiki/Medical_procedure>medical procedures</a>. Automated biomedical QA systems could improve the retrieval of information necessary to answer these questions. The MEDIQA challenge consisted of three <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> concerning various aspects of biomedical QA. This challenge aimed at advancing approaches to Natural Language Inference (NLI) and Recognizing Question Entailment (RQE), which would then result in enhanced approaches to biomedical QA. Our approach explored a common Transformer-based architecture that could be applied to each <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>. This approach shared the same pre-trained weights, but which were then fine-tuned for each task using the provided training data. Furthermore, we augmented the training data with external datasets and enriched the question and answer texts using MER, a named entity recognition tool. Our approach obtained high levels of <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, in particular on the NLI task, which classified pairs of text according to their relation. For the QA task, we obtained higher Spearman&#8217;s rank correlation values using the entities recognized by MER.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>