<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 20th Chinese National Conference on Computational Linguistics - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Proceedings of the 20th Chinese National Conference on Computational Linguistics</h2><p class=lead><a href=/people/s/sheng-li/>Sheng Li (李生)</a>,
<a href=/people/m/maosong-sun/>Maosong Sun (孙茂松)</a>,
<a href=/people/y/yang-liu-ict/>Yang Liu (刘洋)</a>,
<a href=/people/h/hua-wu/>Hua Wu (吴华)</a>,
<a href=/people/k/kang-liu/>Kang Liu (刘康)</a>,
<a href=/people/w/wanxiang-che/>Wanxiang Che (车万翔)</a>,
<a href=/people/s/shizhu-he/>Shizhu He (何世柱)</a>,
<a href=/people/g/gaoqi-rao/>Gaoqi Rao (饶高琦)</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2021.ccl-1</dd><dt>Month:</dt><dd>August</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Huhhot, China</dd><dt>Venue:</dt><dd><a href=/venues/ccl/>CCL</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Chinese Information Processing Society of China</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.ccl-1>https://aclanthology.org/2021.ccl-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+20th+Chinese+National+Conference+on+Computational+Linguistics" title="Search for 'Proceedings of the 20th Chinese National Conference on Computational Linguistics' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ccl-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ccl-1.0/>Proceedings of the 20th Chinese National Conference on Computational Linguistics</a></strong><br><a href=/people/s/sheng-li/>Sheng Li (李生)</a>
|
<a href=/people/m/maosong-sun/>Maosong Sun (孙茂松)</a>
|
<a href=/people/y/yang-liu-ict/>Yang Liu (刘洋)</a>
|
<a href=/people/h/hua-wu/>Hua Wu (吴华)</a>
|
<a href=/people/k/kang-liu/>Kang Liu (刘康)</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che (车万翔)</a>
|
<a href=/people/s/shizhu-he/>Shizhu He (何世柱)</a>
|
<a href=/people/g/gaoqi-rao/>Gaoqi Rao (饶高琦)</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ccl-1.80.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ccl-1--80 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ccl-1.80 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ccl-1.80/>Uyghur Metaphor Detection Via Considering Emotional Consistency<span class=acl-fixed-case>U</span>yghur Metaphor Detection Via Considering Emotional Consistency</a></strong><br><a href=/people/y/yang-qimeng/>Yang Qimeng</a>
|
<a href=/people/y/yu-long/>Yu Long</a>
|
<a href=/people/t/tian-shengwei/>Tian Shengwei</a>
|
<a href=/people/s/song-jinmiao/>Song Jinmiao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ccl-1--80><div class="card-body p-3 small">Metaphor detection plays an important role in tasks such as <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> and <a href=https://en.wikipedia.org/wiki/Human&#8211;machine_interaction>human-machine dialogue</a>. As more users express their opinions on products or other topics on <a href=https://en.wikipedia.org/wiki/Social_media>socialmedia</a> through metaphorical expressions this task is particularly especially topical. Most of the research in this field focuses on <a href=https://en.wikipedia.org/wiki/English_language>English</a> and there are few studies on <a href=https://en.wikipedia.org/wiki/Minority_language>minority languages</a> thatlack language resources and tools. Moreover <a href=https://en.wikipedia.org/wiki/Metaphor>metaphorical expressions</a> have different meaningsin different language environments. We therefore established a deep neural network (DNN)framework for Uyghur metaphor detection tasks. The proposed method can focus on the multi-level semantic information of the text from word embedding part of speech and location which makes the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature representation</a> more complete. We also use the emotional information of words to learn the emotional consistency features of metaphorical words and their context. A qualitative analysis further confirms the need for broader emotional information in metaphor detection. Ourresults indicate the performance of Uyghur metaphor detection can be effectively improved withthe help of multi-attention and emotional information.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ccl-1.83.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ccl-1--83 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ccl-1.83 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ccl-1.83/>Multi-level Emotion Cause Analysis by Multi-head Attention Based Multi-task Learning</a></strong><br><a href=/people/l/li-xiangju/>Li Xiangju</a>
|
<a href=/people/f/feng-shi/>Feng Shi</a>
|
<a href=/people/z/zhang-yifei/>Zhang Yifei</a>
|
<a href=/people/w/wang-daling/>Wang Daling</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ccl-1--83><div class="card-body p-3 small">Emotion cause analysis (ECA) aims to identify the potential causes behind certain emotions intext. Lots of ECA models have been designed to extract the emotion cause at the clause level. However in many scenarios only extracting the cause clause is ambiguous. To ease the problemin this paper we introduce multi-level emotion cause analysis which focuses on identifying emotion cause clause (ECC) and emotion cause keywords (ECK) simultaneously. ECK is a more challenging task since it not only requires capturing the specific understanding of the role of eachword in the clause but also the relation between each word and emotion expression. We observethat ECK task can incorporate the contextual information from the ECC task while ECC taskcan be improved by learning the correlation between <a href=https://en.wikipedia.org/wiki/Emotion>emotion cause keywords</a> and <a href=https://en.wikipedia.org/wiki/Emotion>emotion</a> fromthe ECK task. To fulfill the goal of joint learning we propose a multi-head attention basedmulti-task learning method which utilizes a series of mechanisms including shared and privatefeature extractor multi-head attention emotion attention and label embedding to capture featuresand correlations between the two tasks. Experimental results show that the proposed method consistently outperforms the state-of-the-art methods on a benchmark emotion cause dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ccl-1.84.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ccl-1--84 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ccl-1.84 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.ccl-1.84" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.ccl-1.84/>Using Query Expansion in Manifold Ranking for Query-Oriented Multi-Document Summarization</a></strong><br><a href=/people/j/jia-quanye/>Jia Quanye</a>
|
<a href=/people/l/liu-rui/>Liu Rui</a>
|
<a href=/people/l/lin-jianying/>Lin Jianying</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ccl-1--84><div class="card-body p-3 small">Manifold ranking has been successfully applied in query-oriented multi-document summariza-tion. It not only makes use of the relationships among the sentences but also the relationships between the given query and the sentences. However the information of original query is often insufficient. So we present a query expansion method which is combined in the manifold rank-ing to resolve this problem. Our method not only utilizes the information of the query term itselfand the knowledge base WordNet to expand it by synonyms but also uses the information of the document set itself to expand the query in various ways (mean expansion variance expansionand TextRank expansion). Compared with the previous <a href=https://en.wikipedia.org/wiki/Query_expansion>query expansion methods</a> our methodcombines multiple query expansion methods to better represent query information and at the same time it makes a useful attempt on manifold ranking. In addition we use the degree of wordoverlap and the proximity between words to calculate the similarity between sentences. We per-formed experiments on the datasets of DUC 2006 and DUC2007 and the evaluation results showthat the proposed query expansion method can significantly improve the <a href=https://en.wikipedia.org/wiki/System>system</a> performance andmake our <a href=https://en.wikipedia.org/wiki/System>system</a> comparable to the state-of-the-art systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ccl-1.106.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ccl-1--106 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ccl-1.106 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.ccl-1.106/>GCN with External Knowledge for Clinical Event Detection<span class=acl-fixed-case>GCN</span> with External Knowledge for Clinical Event Detection</a></strong><br><a href=/people/l/liu-dan/>Liu Dan</a>
|
<a href=/people/z/zhang-zhichang/>Zhang Zhichang</a>
|
<a href=/people/p/peng-hui/>Peng Hui</a>
|
<a href=/people/h/han-ruirui/>Han Ruirui</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ccl-1--106><div class="card-body p-3 small">In recent years with the development of <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> and the increasing demand for medical information acquisition in medical information technology applications such as clinical decision support Clinical Event Detection has been widely studied as its subtask. However directly applying advances in <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> to Clinical Event Detection tasks often produces undesirable results. This paper proposes a multi-granularity information fusion encoder-decoder frameworkthat introduces <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>external knowledge</a>. First the <a href=https://en.wikipedia.org/wiki/Word_embedding>word embedding</a> generated by the pre-trained biomedical language representation model (BioBERT) and the character embedding generatedby the <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>Convolutional Neural Network</a> are spliced. And then perform Part-of-Speech attention coding for character-level embedding perform semantic Graph Convolutional Network codingfor the spliced character-word embedding. Finally the information of these three parts is fusedas Conditional Random Field input to generate the sequence label of the word. The experimental results on the 2012 i2b2 data set show that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> in this paper is superior to other existingmodels. In addition the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> in this paper alleviates the problem that occurrence event typeseem more difficult to detect than other event types.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.ccl-1.107.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--ccl-1--107 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.ccl-1.107 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.ccl-1.107" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.ccl-1.107/>A Prompt-independent and Interpretable Automated Essay Scoring Method for Chinese Second Language Writing<span class=acl-fixed-case>C</span>hinese Second Language Writing</a></strong><br><a href=/people/w/wang-yupei/>Wang Yupei</a>
|
<a href=/people/h/hu-renfen/>Hu Renfen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--ccl-1--107><div class="card-body p-3 small">With the increasing popularity of learning <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a> as a second language (L2) the development of an automatic essay scoring (AES) method specially for <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese L2 essays</a> has become animportant task. To build a robust model that could easily adapt to prompt changes we propose 90linguistic features with consideration of both language complexity and correctness and introducethe Ordinal Logistic Regression model that explicitly combines these linguistic features and low-level textual representations. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> obtains a high <a href=https://en.wikipedia.org/wiki/Receiver_operating_characteristic>QWK</a> of 0.714 a low <a href=https://en.wikipedia.org/wiki/Receiver_operating_characteristic>RMSE</a> of 1.516 anda considerable <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>Pearson correlation</a> of 0.734. With a simple linear model we further analyze the contribution of the linguistic features to score prediction revealing the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s interpretability and its potential to give writing feedback to users. This work provides insights and establishes asolid baseline for Chinese L2 AES studies.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>