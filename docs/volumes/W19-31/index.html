<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 14th International Conference on Finite-State Methods and Natural Language Processing - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/W19-31.pdf>Proceedings of the 14th International Conference on Finite-State Methods and Natural Language Processing</a></h2><p class=lead><a href=/people/h/heiko-vogler/>Heiko Vogler</a>,
<a href=/people/a/andreas-maletti/>Andreas Maletti</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>W19-31</dd><dt>Month:</dt><dd>September</dd><dt>Year:</dt><dd>2019</dd><dt>Address:</dt><dd>Dresden, Germany</dd><dt>Venues:</dt><dd><a href=/venues/fsmnlp/>FSMNLP</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd><a href=/sigs/sigfsm/>SIGFSM</a></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/W19-31>https://aclanthology.org/W19-31</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/W19-31.pdf>https://aclanthology.org/W19-31.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/W19-31.pdf title="Open PDF of 'Proceedings of the 14th International Conference on Finite-State Methods and Natural Language Processing'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+14th+International+Conference+on+Finite-State+Methods+and+Natural+Language+Processing" title="Search for 'Proceedings of the 14th International Conference on Finite-State Methods and Natural Language Processing' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3100.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3100/>Proceedings of the 14th International Conference on Finite-State Methods and Natural Language Processing</a></strong><br><a href=/people/h/heiko-vogler/>Heiko Vogler</a>
|
<a href=/people/a/andreas-maletti/>Andreas Maletti</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3105.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3105 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3105 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3105/>On the Compression of Lexicon Transducers</a></strong><br><a href=/people/m/marco-cognetta/>Marco Cognetta</a>
|
<a href=/people/c/cyril-allauzen/>Cyril Allauzen</a>
|
<a href=/people/m/michael-riley/>Michael Riley</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3105><div class="card-body p-3 small">In finite-state language processing pipelines, a <a href=https://en.wikipedia.org/wiki/Lexicon>lexicon</a> is often a key component. It needs to be comprehensive to ensure <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, reducing out-of-vocabulary misses. However, in memory-constrained environments (e.g., <a href=https://en.wikipedia.org/wiki/Mobile_phone>mobile phones</a>), the size of the <a href=https://en.wikipedia.org/wiki/Component-based_software_engineering>component automata</a> must be kept small. Indeed, a delicate balance between comprehensiveness, speed, and memory must be struck to conform to device requirements while providing a good user experience. In this paper, we describe a compression scheme for <a href=https://en.wikipedia.org/wiki/Lexicon>lexicons</a> when represented as finite-state transducers. We efficiently encode the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a> of the <a href=https://en.wikipedia.org/wiki/Transducer>transducer</a> while storing transition labels separately. The graph encoding scheme is based on the LOUDS (Level Order Unary Degree Sequence) tree representation, which has constant time tree traversal for queries while being information-theoretically optimal in space. We find that our encoding is near the theoretical lower bound for such <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graphs</a> and substantially outperforms more traditional representations in space while remaining competitive in latency benchmarks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3107.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3107 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3107 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3107/>Finite State Transducer Calculus for Whole Word Morphology</a></strong><br><a href=/people/m/maciej-janicki/>Maciej Janicki</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3107><div class="card-body p-3 small">The research on machine learning of morphology often involves formulating <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphological descriptions</a> directly on <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>surface forms of words</a>. As the established two-level morphology paradigm requires the knowledge of the underlying structure, it is not widely used in such settings. In this paper, we propose a formalism describing structural relationships between words based on theories of <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphology</a> that reject the notions of internal word structure and <a href=https://en.wikipedia.org/wiki/Morpheme>morpheme</a>. The formalism covers a wide variety of morphological phenomena (including non-concatenative ones like stem vowel alternation) without the need of workarounds and extensions. Furthermore, we show that morphological rules formulated in such way can be easily translated to FSTs, which enables us to derive performant approaches to morphological analysis, generation and automatic rule discovery.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3108.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3108 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3108 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W19-3108.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W19-3108/>Weighted parsing for grammar-based language models</a></strong><br><a href=/people/r/richard-morbitz/>Richard Mörbitz</a>
|
<a href=/people/h/heiko-vogler/>Heiko Vogler</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3108><div class="card-body p-3 small">We develop a general <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> for weighted parsing which is built on top of grammar-based language models and employs flexible weight algebras. It generalizes previous work in that area (semiring parsing, weighted deductive parsing) and also covers applications outside the classical scope of <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a>, e.g., algebraic dynamic programming. We show an <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> which terminates and is correct for a large class of weighted grammar-based language models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3111.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3111 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3111 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3111/>Using Meta-Morph Rules to develop Morphological Analysers : A case study concerning Tamil<span class=acl-fixed-case>T</span>amil</a></strong><br><a href=/people/k/kengatharaiyer-sarveswaran/>Kengatharaiyer Sarveswaran</a>
|
<a href=/people/g/gihan-dias/>Gihan Dias</a>
|
<a href=/people/m/miriam-butt/>Miriam Butt</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3111><div class="card-body p-3 small">This paper describes a new and larger coverage Finite-State Morphological Analyser (FSM) and Generator for the Dravidian language Tamil. The FSM has been developed in the context of computational grammar engineering, adhering to the standards of the ParGram effort. Tamil is a morphologically rich language and the interaction between <a href=https://en.wikipedia.org/wiki/Linguistic_description>linguistic analysis</a> and <a href=https://en.wikipedia.org/wiki/Formal_methods>formal implementation</a> is complex, resulting in a challenging task. In order to allow the development of the <a href=https://en.wikipedia.org/wiki/Formal_semantics_(linguistics)>FSM</a> to focus more on the linguistic analysis and less on the formal details, we have developed a system of meta-morph(ology) rules along with a script which translates these rules into <a href=https://en.wikipedia.org/wiki/Formal_semantics_(linguistics)>FSM processable representations</a>. The introduction of meta-morph rules makes it possible for computationally naive linguists to interact with the <a href=https://en.wikipedia.org/wiki/System>system</a> and to expand <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> in future work. We found that the meta-morph rules help to express linguistic generalisations and reduce the manual effort of writing lexical classes for <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphological analysis</a>. Our Tamil FSM currently handles mainly the <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>inflectional morphology</a> of 3,300 verb roots and their 260 forms. Further, it also has a lexicon of approximately 100,000 nouns along with a guesser to handle out-of-vocabulary items. Although the Tamil FSM was primarily developed to be part of a computational grammar, it can also be used as a web or stand-alone application for other NLP tasks, as per general ParGram practice.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3112.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3112 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3112 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3112/>Distilling weighted finite automata from arbitrary probabilistic models</a></strong><br><a href=/people/a/ananda-theertha-suresh/>Ananda Theertha Suresh</a>
|
<a href=/people/b/brian-roark/>Brian Roark</a>
|
<a href=/people/m/michael-riley/>Michael Riley</a>
|
<a href=/people/v/vlad-schogol/>Vlad Schogol</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3112><div class="card-body p-3 small">Weighted finite automata (WFA) are often used to represent probabilistic models, such as n-gram language models, since they are efficient for recognition tasks in time and space. The probabilistic source to be represented as a WFA, however, may come in many forms. Given a generic probabilistic model over sequences, we propose an <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> to approximate it as a weighted finite automaton such that the <a href=https://en.wikipedia.org/wiki/Kullback&#8211;Leibler_divergence>Kullback-Leibler divergence</a> between the source model and the WFA target model is minimized. The proposed <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> involves a counting step and a difference of convex optimization, both of which can be performed efficiently. We demonstrate the usefulness of our approach on some tasks including distilling <a href=https://en.wikipedia.org/wiki/N-gram_model>n-gram models</a> from neural models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3113.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3113 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3113 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3113/>Silent HMMs : Generalized Representation of Hidden Semi-Markov Models and Hierarchical HMMs<span class=acl-fixed-case>HMM</span>s: Generalized Representation of Hidden Semi-<span class=acl-fixed-case>M</span>arkov Models and Hierarchical <span class=acl-fixed-case>HMM</span>s</a></strong><br><a href=/people/k/kei-wakabayashi/>Kei Wakabayashi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3113><div class="card-body p-3 small">Modeling sequence data using probabilistic finite state machines (PFSMs) is a technique that analyzes the underlying dynamics in sequences of symbols. Hidden semi-Markov models (HSMMs) and hierarchical hidden Markov models (HHMMs) are PFSMs that have been successfully applied to a wide variety of applications by extending HMMs to make the extracted patterns easier to interpret. However, these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are independently developed with their own <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training algorithm</a>, so that we can not combine multiple kinds of structures to build a PFSM for a specific application. In this paper, we prove that silent hidden Markov models (silent HMMs) are flexible models that have more expressive power than <a href=https://en.wikipedia.org/wiki/Hidden_Markov_model>HSMMs</a> and <a href=https://en.wikipedia.org/wiki/Hidden_Markov_model>HHMMs</a>. Silent HMMs are HMMs that contain silent states, which do not emit any observations. We show that we can obtain silent HMM equivalent to given HSMMs and HHMMs. We believe that these results form a firm foundation to use silent HMMs as a unified representation for PFSM modeling.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W19-3115.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W19-3115 data-toggle=collapse aria-expanded=false aria-controls=abstract-W19-3115 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W19-3115/>Transition-Based Coding and <a href=https://en.wikipedia.org/wiki/Formal_language_theory>Formal Language Theory</a> for Ordered Digraphs</a></strong><br><a href=/people/a/anssi-yli-jyra/>Anssi Yli-Jyrä</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W19-3115><div class="card-body p-3 small">Transition-based parsing of <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a> uses transition systems to build directed annotation graphs (digraphs) for sentences. In this paper, we define, for an arbitrary ordered digraph, a unique decomposition and a corresponding linear encoding that are associated bijectively with each other via a new transition system. These results give us an efficient and succinct representation for <a href=https://en.wikipedia.org/wiki/Digraph_(orthography)>digraphs</a> and sets of <a href=https://en.wikipedia.org/wiki/Digraph_(orthography)>digraphs</a>. Based on the system and our analysis of its syntactic properties, we give structural bounds under which the set of encoded digraphs is restricted and becomes a context-free or a regular string language. The context-free restriction is essentially a superset of the encodings used previously to characterize properties of noncrossing digraphs and to solve maximal subgraphs problems. The regular restriction with a tight bound is shown to capture the Universal Dependencies v2.4 treebanks in linguistics.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>