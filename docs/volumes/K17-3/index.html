<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/K17-3.pdf>Proceedings of the <span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>NLL</span> 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</a></h2><p class=lead><a href=/people/j/jan-hajic/>Jan Hajič</a>,
<a href=/people/d/daniel-zeman/>Dan Zeman</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>K17-3</dd><dt>Month:</dt><dd>August</dd><dt>Year:</dt><dd>2017</dd><dt>Address:</dt><dd>Vancouver, Canada</dd><dt>Venue:</dt><dd><a href=/venues/conll/>CoNLL</a></dd><dt>SIG:</dt><dd><a href=/sigs/signll/>SIGNLL</a></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/K17-3>https://aclanthology.org/K17-3</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/K17-3 title="To the current version of the paper by DOI">10.18653/v1/K17-3</a></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/K17-3.pdf>https://aclanthology.org/K17-3.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/K17-3.pdf title="Open PDF of 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+CoNLL+2017+Shared+Task%3A+Multilingual+Parsing+from+Raw+Text+to+Universal+Dependencies" title="Search for 'Proceedings of the CoNLL 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3000/>Proceedings of the <span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>NLL</span> 2017 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</a></strong><br><a href=/people/j/jan-hajic/>Jan Hajič</a>
|
<a href=/people/d/daniel-zeman/>Dan Zeman</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3001 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3001/>CoNLL 2017 Shared Task : Multilingual Parsing from Raw Text to Universal Dependencies<span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>NLL</span> 2017 Shared Task: Multilingual Parsing from Raw Text to <span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependencies</a></strong><br><a href=/people/d/daniel-zeman/>Daniel Zeman</a>
|
<a href=/people/m/martin-popel/>Martin Popel</a>
|
<a href=/people/m/milan-straka/>Milan Straka</a>
|
<a href=/people/j/jan-hajic/>Jan Hajič</a>
|
<a href=/people/j/joakim-nivre/>Joakim Nivre</a>
|
<a href=/people/f/filip-ginter/>Filip Ginter</a>
|
<a href=/people/j/juhani-luotolahti/>Juhani Luotolahti</a>
|
<a href=/people/s/sampo-pyysalo/>Sampo Pyysalo</a>
|
<a href=/people/s/slav-petrov/>Slav Petrov</a>
|
<a href=/people/m/martin-potthast/>Martin Potthast</a>
|
<a href=/people/f/francis-tyers/>Francis Tyers</a>
|
<a href=/people/e/elena-badmaeva/>Elena Badmaeva</a>
|
<a href=/people/m/memduh-gokirmak/>Memduh Gokirmak</a>
|
<a href=/people/a/anna-nedoluzhko/>Anna Nedoluzhko</a>
|
<a href=/people/s/silvie-cinkova/>Silvie Cinková</a>
|
<a href=/people/j/jan-hajic-jr/>Jan Hajič jr.</a>
|
<a href=/people/j/jaroslava-hlavacova/>Jaroslava Hlaváčová</a>
|
<a href=/people/v/vaclava-kettnerova/>Václava Kettnerová</a>
|
<a href=/people/z/zdenka-uresova/>Zdeňka Urešová</a>
|
<a href=/people/j/jenna-kanerva/>Jenna Kanerva</a>
|
<a href=/people/s/stina-ojala/>Stina Ojala</a>
|
<a href=/people/a/anna-missila/>Anna Missilä</a>
|
<a href=/people/c/christopher-d-manning/>Christopher D. Manning</a>
|
<a href=/people/s/sebastian-schuster/>Sebastian Schuster</a>
|
<a href=/people/s/siva-reddy/>Siva Reddy</a>
|
<a href=/people/d/dima-taji/>Dima Taji</a>
|
<a href=/people/n/nizar-habash/>Nizar Habash</a>
|
<a href=/people/h/herman-leung/>Herman Leung</a>
|
<a href=/people/m/marie-catherine-de-marneffe/>Marie-Catherine de Marneffe</a>
|
<a href=/people/m/manuela-sanguinetti/>Manuela Sanguinetti</a>
|
<a href=/people/m/maria-simi/>Maria Simi</a>
|
<a href=/people/h/hiroshi-kanayama/>Hiroshi Kanayama</a>
|
<a href=/people/v/valeria-de-paiva/>Valeria de Paiva</a>
|
<a href=/people/k/kira-droganova/>Kira Droganova</a>
|
<a href=/people/h/hector-martinez-alonso/>Héctor Martínez Alonso</a>
|
<a href=/people/c/cagri-coltekin/>Çağrı Çöltekin</a>
|
<a href=/people/u/umut-sulubacak/>Umut Sulubacak</a>
|
<a href=/people/h/hans-uszkoreit/>Hans Uszkoreit</a>
|
<a href=/people/v/vivien-macketanz/>Vivien Macketanz</a>
|
<a href=/people/a/aljoscha-burchardt/>Aljoscha Burchardt</a>
|
<a href=/people/k/kim-harris/>Kim Harris</a>
|
<a href=/people/k/katrin-marheinecke/>Katrin Marheinecke</a>
|
<a href=/people/g/georg-rehm/>Georg Rehm</a>
|
<a href=/people/t/tolga-kayadelen/>Tolga Kayadelen</a>
|
<a href=/people/m/mohammed-attia/>Mohammed Attia</a>
|
<a href=/people/a/ali-elkahky/>Ali Elkahky</a>
|
<a href=/people/z/zhuoran-yu/>Zhuoran Yu</a>
|
<a href=/people/e/emily-pitler/>Emily Pitler</a>
|
<a href=/people/s/saran-lertpradit/>Saran Lertpradit</a>
|
<a href=/people/m/michael-mandel/>Michael Mandl</a>
|
<a href=/people/j/jesse-kirchner/>Jesse Kirchner</a>
|
<a href=/people/h/hector-fernandez-alcalde/>Hector Fernandez Alcalde</a>
|
<a href=/people/j/jana-strnadova/>Jana Strnadová</a>
|
<a href=/people/e/esha-banerjee/>Esha Banerjee</a>
|
<a href=/people/r/ruli-manurung/>Ruli Manurung</a>
|
<a href=/people/a/antonio-stella/>Antonio Stella</a>
|
<a href=/people/a/atsuko-shimada/>Atsuko Shimada</a>
|
<a href=/people/s/sookyoung-kwak/>Sookyoung Kwak</a>
|
<a href=/people/g/gustavo-mendonca/>Gustavo Mendonça</a>
|
<a href=/people/t/tatiana-lando/>Tatiana Lando</a>
|
<a href=/people/r/rattima-nitisaroj/>Rattima Nitisaroj</a>
|
<a href=/people/j/josie-li/>Josie Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3001><div class="card-body p-3 small">The Conference on Computational Natural Language Learning (CoNLL) features a shared task, in which participants train and test their <a href=https://en.wikipedia.org/wiki/Machine_learning>learning systems</a> on the same data sets. In 2017, the task was devoted to learning dependency parsers for a large number of languages, in a real-world setting without any gold-standard annotation on input. All <a href=https://en.wikipedia.org/wiki/Test_set>test sets</a> followed a unified annotation scheme, namely that of Universal Dependencies. In this paper, we define the task and evaluation methodology, describe how the data sets were prepared, report and analyze the main results, and provide a brief categorization of the different approaches of the participating systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3002 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3002/>Stanford’s Graph-based Neural Dependency Parser at the CoNLL 2017 Shared Task<span class=acl-fixed-case>S</span>tanford’s Graph-based Neural Dependency Parser at the <span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>NLL</span> 2017 Shared Task</a></strong><br><a href=/people/t/timothy-dozat/>Timothy Dozat</a>
|
<a href=/people/p/peng-qi/>Peng Qi</a>
|
<a href=/people/c/christopher-d-manning/>Christopher D. Manning</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3002><div class="card-body p-3 small">This paper describes the neural dependency parser submitted by Stanford to the CoNLL 2017 Shared Task on parsing Universal Dependencies. Our system uses relatively simple LSTM networks to produce <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part of speech tags</a> and labeled dependency parses from segmented and tokenized sequences of words. In order to address the rare word problem that abounds in languages with complex morphology, we include a character-based word representation that uses an LSTM to produce embeddings from sequences of characters. Our <a href=https://en.wikipedia.org/wiki/System>system</a> was ranked first according to all five relevant <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> for the <a href=https://en.wikipedia.org/wiki/System>system</a> : UPOS tagging (93.09 %), XPOS tagging (82.27 %), unlabeled attachment score (81.30 %), labeled attachment score (76.30 %), and content word labeled attachment score (72.57 %).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3003 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3003/>Combining Global Models for Parsing Universal Dependencies<span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependencies</a></strong><br><a href=/people/t/tianze-shi/>Tianze Shi</a>
|
<a href=/people/f/felix-g-wu/>Felix G. Wu</a>
|
<a href=/people/x/xilun-chen/>Xilun Chen</a>
|
<a href=/people/y/yao-cheng/>Yao Cheng</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3003><div class="card-body p-3 small">We describe our entry, C2L2, to the CoNLL 2017 shared task on parsing Universal Dependencies from raw text. Our system features an ensemble of three global parsing paradigms, one graph-based and two transition-based. Each <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> leverages character-level bi-directional LSTMs as lexical feature extractors to encode <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphological information</a>. Though relying on baseline tokenizers and focusing only on <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a>, our system ranked second in the official end-to-end evaluation with a <a href=https://en.wikipedia.org/wiki/Macro_(computer_science)>macro-average</a> of 75.00 LAS F1 score over 81 test treebanks. In addition, we had the top average performance on the four surprise languages and on the small treebank subset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3005.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3005 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3005 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3005/>The HIT-SCIR System for End-to-End Parsing of Universal Dependencies<span class=acl-fixed-case>HIT</span>-<span class=acl-fixed-case>SCIR</span> System for End-to-End Parsing of <span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependencies</a></strong><br><a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/j/jiang-guo/>Jiang Guo</a>
|
<a href=/people/y/yuxuan-wang/>Yuxuan Wang</a>
|
<a href=/people/b/bo-zheng/>Bo Zheng</a>
|
<a href=/people/h/huaipeng-zhao/>Huaipeng Zhao</a>
|
<a href=/people/y/yang-liu/>Yang Liu</a>
|
<a href=/people/d/dechuan-teng/>Dechuan Teng</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3005><div class="card-body p-3 small">This paper describes our system (HIT-SCIR) for the CoNLL 2017 shared task : Multilingual Parsing from Raw Text to Universal Dependencies. Our system includes three pipelined components : <a href=https://en.wikipedia.org/wiki/Lexical_analysis>tokenization</a>, Part-of-Speech (POS) tagging and dependency parsing. We use character-based bidirectional long short-term memory (LSTM) networks for both tokenization and POS tagging. Afterwards, we employ a list-based transition-based algorithm for general non-projective parsing and present an improved Stack-LSTM-based architecture for representing each transition state and making predictions. Furthermore, to parse low / zero-resource languages and cross-domain data, we use a model transfer approach to make effective use of existing resources. We demonstrate substantial gains against the UDPipe baseline, with an average improvement of 3.76 % in LAS of all languages. And finally, we rank the 4th place on the official test sets.<i>tokenization</i>,\n <i>Part-of-Speech</i> (POS) <i>tagging</i> and <i>dependency parsing</i>.\n We use character-based bidirectional long short-term memory (LSTM) networks for\n both tokenization and POS tagging.\n Afterwards, we employ a list-based transition-based algorithm for general\n non-projective parsing and present an improved Stack-LSTM-based architecture\n for representing each transition state and making predictions.\n Furthermore, to parse low/zero-resource languages and cross-domain data, we use\n a model transfer approach to make effective use of existing resources.\n We demonstrate substantial gains against the UDPipe baseline, with an average\n improvement of 3.76% in LAS of all languages. And finally, we rank the 4th\n place on the official test sets.\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3006.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3006 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3006 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3006/>A System for Multilingual Dependency Parsing based on Bidirectional LSTM Feature Representations<span class=acl-fixed-case>LSTM</span> Feature Representations</a></strong><br><a href=/people/k/kyungtae-lim/>KyungTae Lim</a>
|
<a href=/people/t/thierry-poibeau/>Thierry Poibeau</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3006><div class="card-body p-3 small">In this paper, we present our multilingual dependency parser developed for the CoNLL 2017 UD Shared Task dealing with Multilingual Parsing from Raw Text to Universal Dependencies. Our <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> extends the monolingual BIST-parser as a multi-source multilingual trainable parser. Thanks to multilingual word embeddings and one hot encodings for languages, our system can use both monolingual and multi-source training. We trained 69 monolingual language models and 13 multilingual models for the shared task. Our multilingual approach making use of different resources yield better results than the monolingual approach for 11 languages. Our <a href=https://en.wikipedia.org/wiki/System>system</a> ranked 5 th and achieved 70.93 overall LAS score over the 81 test corpora (macro-averaged LAS F1 score).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3008.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3008 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3008 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3008/>Parsing with Context Embeddings</a></strong><br><a href=/people/o/omer-kirnap/>Ömer Kırnap</a>
|
<a href=/people/b/berkay-furkan-onder/>Berkay Furkan Önder</a>
|
<a href=/people/d/deniz-yuret/>Deniz Yuret</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3008><div class="card-body p-3 small">We introduce context embeddings, dense vectors derived from a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> that represent the left / right context of a word instance, and demonstrate that context embeddings significantly improve the accuracy of our transition based parser. Our model consists of a bidirectional LSTM (BiLSTM) based language model that is pre-trained to predict words in plain text, and a multi-layer perceptron (MLP) decision model that uses features from the language model to predict the correct actions for an ArcHybrid transition based parser. We participated in the CoNLL 2017 UD Shared Task as the Ko University team and our system was ranked 7th out of 33 systems that parsed 81 treebanks in 49 languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3009.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3009 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3009 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/K17-3009.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/K17-3009/>Tokenizing, POS Tagging, Lemmatizing and Parsing UD 2.0 with UDPipe<span class=acl-fixed-case>POS</span> Tagging, Lemmatizing and Parsing <span class=acl-fixed-case>UD</span> 2.0 with <span class=acl-fixed-case>UDP</span>ipe</a></strong><br><a href=/people/m/milan-straka/>Milan Straka</a>
|
<a href=/people/j/jana-strakova/>Jana Straková</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3009><div class="card-body p-3 small">Many natural language processing tasks, including the most advanced ones, routinely start by several basic processing steps tokenization and segmentation, most likely also POS tagging and <a href=https://en.wikipedia.org/wiki/Lemmatization>lemmatization</a>, and commonly <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a> as well. A multilingual pipeline performing these steps can be trained using the Universal Dependencies project, which contains annotations of the described tasks for 50 languages in the latest release UD 2.0. We present an update to UDPipe, a simple-to-use pipeline processing CoNLL-U version 2.0 files, which performs these tasks for multiple languages without requiring additional external data. We provide <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> for all 50 languages of UD 2.0, and furthermore, the <a href=https://en.wikipedia.org/wiki/Pipeline_(software)>pipeline</a> can be trained easily using data in CoNLL-U format. UDPipe is a standalone application in <a href=https://en.wikipedia.org/wiki/C++>C++</a>, with bindings available for <a href=https://en.wikipedia.org/wiki/Python_(programming_language)>Python</a>, <a href=https://en.wikipedia.org/wiki/Java_(programming_language)>Java</a>, <a href=https://en.wikipedia.org/wiki/C_Sharp_(programming_language)>C #</a> and <a href=https://en.wikipedia.org/wiki/Perl>Perl</a>. In the CoNLL 2017 Shared Task : Multilingual Parsing from Raw Text to Universal Dependencies, UDPipe was the eight best system, while achieving low running times and moderately sized models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3010.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3010 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3010 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3010/>UParse : the Edinburgh system for the CoNLL 2017 UD shared task<span class=acl-fixed-case>UP</span>arse: the <span class=acl-fixed-case>E</span>dinburgh system for the <span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>NLL</span> 2017 <span class=acl-fixed-case>UD</span> shared task</a></strong><br><a href=/people/c/clara-vania/>Clara Vania</a>
|
<a href=/people/x/xingxing-zhang/>Xingxing Zhang</a>
|
<a href=/people/a/adam-lopez/>Adam Lopez</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3010><div class="card-body p-3 small">This paper presents our submissions for the CoNLL 2017 UD Shared Task. Our <a href=https://en.wikipedia.org/wiki/Parsing>parser</a>, called UParse, is based on a neural network graph-based dependency parser. The <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> uses <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> from a bidirectional LSTM to to produce a distribution over possible heads for each word in the sentence. To allow <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> for low-resource treebanks and surprise languages, we train several multilingual models for related languages, grouped by their genus and language families. Out of 33 participants, our system achieves rank 9th in the main results, with 75.49 UAS and 68.87 LAS F-1 scores (average across 81 treebanks).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3011.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3011 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3011 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/K17-3011.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/K17-3011/>Multi-Model and Crosslingual Dependency Analysis</a></strong><br><a href=/people/j/johannes-heinecke/>Johannes Heinecke</a>
|
<a href=/people/m/munshi-asadullah/>Munshi Asadullah</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3011><div class="card-body p-3 small">This paper describes the system of the Team Orange-Deskin, used for the CoNLL 2017 UD Shared Task in Multilingual Dependency Parsing. We based our approach on an existing open source tool (BistParser), which we modified in order to produce the required output. Additionally we added a kind of pseudo-projectivisation. This was needed since some of the task&#8217;s languages have a high percentage of non-projective dependency trees. In most cases we also employed <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a>. For the 4 surprise languages, the data provided seemed too little to train on. Thus we decided to use the training data of typologically close languages instead. Our <a href=https://en.wikipedia.org/wiki/System>system</a> achieved a macro-averaged LAS of 68.61 % (10th in the overall ranking) which improved to 69.38 % after <a href=https://en.wikipedia.org/wiki/Patch_(computing)>bug fixes</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3012 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3012/>TurkuNLP : Delexicalized Pre-training of Word Embeddings for Dependency Parsing<span class=acl-fixed-case>T</span>urku<span class=acl-fixed-case>NLP</span>: Delexicalized Pre-training of Word Embeddings for Dependency Parsing</a></strong><br><a href=/people/j/jenna-kanerva/>Jenna Kanerva</a>
|
<a href=/people/j/juhani-luotolahti/>Juhani Luotolahti</a>
|
<a href=/people/f/filip-ginter/>Filip Ginter</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3012><div class="card-body p-3 small">We present the TurkuNLP entry in the CoNLL 2017 Shared Task on Multilingual Parsing from Raw Text to Universal Dependencies. The system is based on the UDPipe parser with our focus being in exploring various techniques to pre-train the word embeddings used by the <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> in order to improve its performance especially on languages with small training sets. The system ranked 11th among the 33 participants overall, being 8th on the small treebanks, 10th on the large treebanks, 12th on the parallel test sets, and 26th on the surprise languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3013.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3013 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3013 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3013/>The parse is darc and full of errors : Universal dependency parsing with transition-based and graph-based algorithms</a></strong><br><a href=/people/k/kuan-yu/>Kuan Yu</a>
|
<a href=/people/p/pavel-sofroniev/>Pavel Sofroniev</a>
|
<a href=/people/e/erik-schill/>Erik Schill</a>
|
<a href=/people/e/erhard-hinrichs/>Erhard Hinrichs</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3013><div class="card-body p-3 small">We developed two simple systems for dependency parsing : darc, a transition-based parser, and mstnn, a graph-based parser. We tested our <a href=https://en.wikipedia.org/wiki/System>systems</a> in the CoNLL 2017 UD Shared Task, with <a href=https://en.wikipedia.org/wiki/Darc>darc</a> being the official system. Darc ranked 12th among 33 systems, just above the baseline. Mstnn had no official ranking, but its main score was above the 27th. In this paper, we describe our two <a href=https://en.wikipedia.org/wiki/System>systems</a>, examine their strengths and weaknesses, and discuss the lessons we learned.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3014.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3014 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=K17-3014" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/K17-3014/>A Novel Neural Network Model for Joint POS Tagging and Graph-based Dependency Parsing<span class=acl-fixed-case>POS</span> Tagging and Graph-based Dependency Parsing</a></strong><br><a href=/people/d/dat-quoc-nguyen/>Dat Quoc Nguyen</a>
|
<a href=/people/m/mark-dras/>Mark Dras</a>
|
<a href=/people/m/mark-johnson/>Mark Johnson</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3014><div class="card-body p-3 small">We present a novel <a href=https://en.wikipedia.org/wiki/Neural_network>neural network model</a> that learns <a href=https://en.wikipedia.org/wiki/Tag_(metadata)>POS tagging</a> and graph-based dependency parsing jointly. Our model uses bidirectional LSTMs to learn feature representations shared for both POS tagging and dependency parsing tasks, thus handling the feature-engineering problem. Our extensive experiments, on 19 languages from the Universal Dependencies project, show that our model outperforms the state-of-the-art neural network-based Stack-propagation model for joint POS tagging and transition-based dependency parsing, resulting in a new state of the art. Our code is open-source and available together with pre-trained models at :<url>https://github.com/datquocnguyen/jPTDP</url>\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3015.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3015 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3015 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3015/>A non-DNN Feature Engineering Approach to Dependency Parsing FBAML at CoNLL 2017 Shared Task<span class=acl-fixed-case>DNN</span> Feature Engineering Approach to Dependency Parsing – <span class=acl-fixed-case>FBAML</span> at <span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>NLL</span> 2017 Shared Task</a></strong><br><a href=/people/x/xian-qian/>Xian Qian</a>
|
<a href=/people/y/yang-liu-icsi/>Yang Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3015><div class="card-body p-3 small">For this year&#8217;s multilingual dependency parsing shared task, we developed a <a href=https://en.wikipedia.org/wiki/Pipeline_(software)>pipeline system</a>, which uses a variety of features for each of its <a href=https://en.wikipedia.org/wiki/Component-based_software_engineering>components</a>. Unlike the recent popular deep learning approaches that learn low dimensional dense features using non-linear classifier, our system uses structured linear classifiers to learn millions of <a href=https://en.wikipedia.org/wiki/Sparse_matrix>sparse features</a>. Specifically, we trained a <a href=https://en.wikipedia.org/wiki/Linear_classifier>linear classifier</a> for sentence boundary prediction, linear chain conditional random fields (CRFs) for <a href=https://en.wikipedia.org/wiki/Lexical_analysis>tokenization</a>, <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a> and morph analysis. A second order graph based parser learns the tree structure (without relations), and fa linear tree CRF then assigns relations to the dependencies in the <a href=https://en.wikipedia.org/wiki/Tree_(graph_theory)>tree</a>. Our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves reasonable performance 67.87 % official averaged macro F1 score</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3016.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3016 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3016 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=K17-3016" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/K17-3016/>A non-projective greedy dependency parser with bidirectional LSTMs<span class=acl-fixed-case>LSTM</span>s</a></strong><br><a href=/people/d/david-vilares/>David Vilares</a>
|
<a href=/people/c/carlos-gomez-rodriguez/>Carlos Gómez-Rodríguez</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3016><div class="card-body p-3 small">The LyS-FASTPARSE team present BIST-COVINGTON, a neural implementation of the Covington (2001) algorithm for non-projective dependency parsing. The bidirectional LSTM approach by Kiperwasser and Goldberg (2016) is used to train a greedy parser with a dynamic oracle to mitigate error propagation. The <a href=https://en.wikipedia.org/wiki/Model_(person)>model</a> participated in the CoNLL 2017 UD Shared Task. In spite of not using any ensemble methods and using the baseline segmentation and PoS tagging, the <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> obtained good results on both macro-average LAS and UAS in the big treebanks category (55 languages), ranking 7th out of 33 teams. In the all treebanks category (LAS and UAS) we ranked 16th and 12th. The gap between the all and big categories is mainly due to the poor performance on four parallel PUD treebanks, suggesting that some &#8216;suffixed&#8217; treebanks (e.g. Spanish-AnCora) perform poorly on cross-treebank settings, which does not occur with the corresponding &#8216;unsuffixed&#8217; treebank (e.g. Spanish). By changing that, we obtain the 11th best LAS among all runs (official and unofficial). The code is made available at<url>https://github.com/CoNLL-UD-2017/LyS-FASTPARSE</url>\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3017.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3017 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3017 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3017/>LIMSI@CoNLL’17 : UD Shared Task<span class=acl-fixed-case>LIMSI</span>@<span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>NLL</span>’17: <span class=acl-fixed-case>UD</span> Shared Task</a></strong><br><a href=/people/l/lauriane-aufrant/>Lauriane Aufrant</a>
|
<a href=/people/g/guillaume-wisniewski/>Guillaume Wisniewski</a>
|
<a href=/people/f/francois-yvon/>François Yvon</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3017><div class="card-body p-3 small">This paper describes LIMSI&#8217;s submission to the CoNLL 2017 UD Shared Task, which is focused on small treebanks, and how to improve low-resourced parsing only by ad hoc combination of multiple views and resources. We present our approach for low-resourced parsing, together with a detailed analysis of the results for each test treebank. We also report extensive analysis experiments on <a href=https://en.wikipedia.org/wiki/Model_selection>model selection</a> for the PUD treebanks, and on annotation consistency among UD treebanks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3018.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3018 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3018 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3018/>RACAI’s Natural Language Processing pipeline for Universal Dependencies<span class=acl-fixed-case>RACAI</span>’s Natural Language Processing pipeline for <span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependencies</a></strong><br><a href=/people/s/stefan-daniel-dumitrescu/>Stefan Daniel Dumitrescu</a>
|
<a href=/people/t/tiberiu-boros/>Tiberiu Boros</a>
|
<a href=/people/d/dan-tufis/>Dan Tufis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3018><div class="card-body p-3 small">This paper presents RACAI&#8217;s approach, experiments and results at CONLL 2017 Shared Task : Multilingual Parsing from Raw Text to Universal Dependencies. We handle raw text and we cover <a href=https://en.wikipedia.org/wiki/Lexical_analysis>tokenization</a>, sentence splitting, <a href=https://en.wikipedia.org/wiki/Word_segmentation>word segmentation</a>, <a href=https://en.wikipedia.org/wiki/Tag_(metadata)>tagging</a>, <a href=https://en.wikipedia.org/wiki/Lemmatization>lemmatization</a> and <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a>. All results are reported under strict training, development and testing conditions, in which the corpora provided for the shared tasks is used as is, without any modifications to the composition of the train and development sets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3019.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3019 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3019 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3019/>Delexicalized transfer parsing for low-resource languages using transformed and combined treebanks</a></strong><br><a href=/people/a/ayan-das/>Ayan Das</a>
|
<a href=/people/a/affan-zaffar/>Affan Zaffar</a>
|
<a href=/people/s/sudeshna-sarkar/>Sudeshna Sarkar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3019><div class="card-body p-3 small">This paper describes our dependency parsing system in CoNLL-2017 shared task on Multilingual Parsing from Raw Text to Universal Dependencies. We primarily focus on the low-resource languages (surprise languages). We have developed a framework to combine multiple treebanks to train <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a> for low resource languages by delexicalization method. We have applied transformation on source language treebanks based on syntactic features of the low-resource language to improve performance of the <a href=https://en.wikipedia.org/wiki/Parsing>parser</a>. In the official evaluation, our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves an macro-averaged LAS score of 67.61 and 37.16 on the entire <a href=https://en.wikipedia.org/wiki/Blinded_experiment>blind test data</a> and the <a href=https://en.wikipedia.org/wiki/Blinded_experiment>surprise language test data</a> respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3021.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3021 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3021 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=K17-3021" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/K17-3021/>Corpus Selection Approaches for Multilingual Parsing from Raw Text to Universal Dependencies<span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependencies</a></strong><br><a href=/people/r/ryan-hornby/>Ryan Hornby</a>
|
<a href=/people/c/clark-taylor/>Clark Taylor</a>
|
<a href=/people/j/jungyeul-park/>Jungyeul Park</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3021><div class="card-body p-3 small">This paper describes UALing&#8217;s approach to the CoNLL 2017 UD Shared Task using corpus selection techniques to reduce training data size. The methodology is simple : we use similarity measures to select a corpus from available training data (even from multiple corpora for surprise languages) and use the resulting <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> to complete the parsing task. The training and <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a> is done with the baseline UDPipe system (Straka et al., 2016). While our approach reduces the size of training data significantly, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> retains performance within 0.5 % of the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline system</a>. Due to the reduction in training data size, our <a href=https://en.wikipedia.org/wiki/System>system</a> performs faster than the nave, complete corpus method. Specifically, our <a href=https://en.wikipedia.org/wiki/System>system</a> runs in less than 10 minutes, ranking it among the fastest entries for this <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>. Our <a href=https://en.wikipedia.org/wiki/System>system</a> is available at.<i>CoNLL 2017 UD Shared Task</i> using corpus selection techniques to reduce training data size. The methodology is simple: we use similarity measures to select a corpus from available training data (even from multiple corpora for surprise languages) and use the resulting corpus to complete the parsing task. The training and parsing is done with the baseline UDPipe system (Straka et al., 2016). While our approach reduces the size of training data significantly, it retains performance within 0.5% of the baseline system. Due to the reduction in training data size, our system performs faster than the na&#239;ve, complete corpus method. Specifically, our system runs in less than 10 minutes, ranking it among the fastest entries for this task. Our system is available at <url>https://github.com/CoNLL-UD-2017/UALING</url>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3023.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3023 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3023 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3023/>Initial Explorations of CCG Supertagging for Universal Dependency Parsing<span class=acl-fixed-case>CCG</span> Supertagging for <span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependency Parsing</a></strong><br><a href=/people/b/burak-kerim-akkus/>Burak Kerim Akkus</a>
|
<a href=/people/h/heval-azizoglu/>Heval Azizoglu</a>
|
<a href=/people/r/ruket-cakici/>Ruket Cakici</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3023><div class="card-body p-3 small">In this paper we describe the system by METU team for universal dependency parsing of multilingual text. We use a neural network-based dependency parser that has a greedy transition approach to dependency parsing. CCG supertags contain rich structural information that proves useful in certain NLP tasks. We experiment with CCG supertags as additional <a href=https://en.wikipedia.org/wiki/Feature_(computer_vision)>features</a> in our experiments. The neural network parser is trained together with <a href=https://en.wikipedia.org/wiki/Coupling_(computer_programming)>dependencies</a> and simplified CCG tags as well as other <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> provided.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3024 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3024/>CLCL (Geneva) DINN Parser : a Neural Network Dependency Parser Ten Years Later<span class=acl-fixed-case>CLCL</span> (Geneva) <span class=acl-fixed-case>DINN</span> Parser: a Neural Network Dependency Parser Ten Years Later</a></strong><br><a href=/people/c/christophe-moor/>Christophe Moor</a>
|
<a href=/people/p/paola-merlo/>Paola Merlo</a>
|
<a href=/people/j/james-henderson/>James Henderson</a>
|
<a href=/people/h/haozhou-wang/>Haozhou Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3024><div class="card-body p-3 small">This paper describes the University of Geneva&#8217;s submission to the CoNLL 2017 shared task Multilingual Parsing from Raw Text to Universal Dependencies (listed as the CLCL (Geneva) entry). Our submitted parsing system is the grandchild of the first transition-based neural network dependency parser, which was the University of Geneva&#8217;s entry in the CoNLL 2007 multilingual dependency parsing shared task, with some improvements to speed and portability. These results provide a baseline for investigating how far we have come in the past ten years of work on neural network dependency parsing.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3025.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3025 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3025 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3025/>A Fast and Lightweight System for Multilingual Dependency Parsing</a></strong><br><a href=/people/t/tao-ji/>Tao Ji</a>
|
<a href=/people/y/yuanbin-wu/>Yuanbin Wu</a>
|
<a href=/people/m/man-lan/>Man Lan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3025><div class="card-body p-3 small">We present a multilingual dependency parser with a bidirectional-LSTM (BiLSTM) feature extractor and a multi-layer perceptron (MLP) classifier. We trained our transition-based projective parser in UD version 2.0 datasets without any additional data. The <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> is fast, lightweight and effective on <a href=https://en.wikipedia.org/wiki/Treebank>big treebanks</a>. In the CoNLL 2017 Shared Task : Multilingual Parsing from Raw Text to Universal Dependencies, the official results show that the macro-averaged LAS F1 score of our system Mengest is 61.33 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3026.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3026 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3026 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3026/>The ParisNLP entry at the ConLL UD Shared Task 2017 : A Tale of a # ParsingTragedy<span class=acl-fixed-case>P</span>aris<span class=acl-fixed-case>NLP</span> entry at the <span class=acl-fixed-case>C</span>on<span class=acl-fixed-case>LL</span> <span class=acl-fixed-case>UD</span> Shared Task 2017: A Tale of a #<span class=acl-fixed-case>P</span>arsing<span class=acl-fixed-case>T</span>ragedy</a></strong><br><a href=/people/e/eric-villemonte-de-la-clergerie/>Éric de La Clergerie</a>
|
<a href=/people/b/benoit-sagot/>Benoît Sagot</a>
|
<a href=/people/d/djame-seddah/>Djamé Seddah</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3026><div class="card-body p-3 small">We present the ParisNLP entry at the UD CoNLL 2017 parsing shared task. In addition to the UDpipe models provided, we built our own data-driven tokenization models, sentence segmenter and lexicon-based morphological analyzers. All of these were used with a range of different parsing models (neural or not, feature-rich or not, transition or graph-based, etc.) and the best combination for each language was selected. Unfortunately, a glitch in the shared task&#8217;s Matrix led our model selector to run generic, weakly lexicalized models, tailored for surprise languages, instead of our dataset-specific models. Because of this # ParsingTragedy, we officially ranked 27th, whereas our real models finally unofficially ranked 6th.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3027.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3027 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3027 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3027/>Universal Joint Morph-Syntactic Processing : The Open University of Israel’s Submission to The CoNLL 2017 Shared Task<span class=acl-fixed-case>O</span>pen <span class=acl-fixed-case>U</span>niversity of <span class=acl-fixed-case>I</span>srael’s Submission to The <span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>NLL</span> 2017 Shared Task</a></strong><br><a href=/people/a/amir-more/>Amir More</a>
|
<a href=/people/r/reut-tsarfaty/>Reut Tsarfaty</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3027><div class="card-body p-3 small">We present the Open University&#8217;s submission to the CoNLL 2017 Shared Task on multilingual parsing from raw text to Universal Dependencies. The core of our system is a joint morphological disambiguator and syntactic parser which accepts morphologically analyzed surface tokens as input and returns morphologically disambiguated dependency trees as output. Our parser requires a lattice as input, so we generate morphological analyses of surface tokens using a data-driven morphological analyzer that derives its lexicon from the UD training corpora, and we rely on UDPipe for sentence segmentation and surface-level tokenization. We report our official macro-average LAS is 56.56. Although our model is not as performant as many others, it does not make use of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>, therefore we do not rely on <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> or any other data source other than the corpora themselves. In addition, we show the utility of a lexicon-backed morphological analyzer for the <a href=https://en.wikipedia.org/wiki/Modern_Hebrew>MRL Modern Hebrew</a>. We use our results on <a href=https://en.wikipedia.org/wiki/Modern_Hebrew>Modern Hebrew</a> to argue that the UD community should define a UD-compatible standard for access to lexical resources, which we argue is crucial for MRLs and low resource languages in particular.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3028.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3028 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3028 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3028/>A Semi-universal Pipelined Approach to the CoNLL 2017 UD Shared Task<span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>NLL</span> 2017 <span class=acl-fixed-case>UD</span> Shared Task</a></strong><br><a href=/people/h/hiroshi-kanayama/>Hiroshi Kanayama</a>
|
<a href=/people/m/masayasu-muraoka/>Masayasu Muraoka</a>
|
<a href=/people/k/katsumasa-yoshikawa/>Katsumasa Yoshikawa</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3028><div class="card-body p-3 small">This paper presents our system submitted for the CoNLL 2017 Shared Task, Multilingual Parsing from Raw Text to Universal Dependencies. We ran the <a href=https://en.wikipedia.org/wiki/System>system</a> for all languages with our own fully pipelined components without relying on re-trained baseline systems. To train the <a href=https://en.wikipedia.org/wiki/Dependency_grammar>dependency parser</a>, we used only the universal part-of-speech tags and distance between words, and applied deterministic rules to assign dependency labels. The simple and delexicalized models are suitable for cross-lingual transfer approaches and a universal language model. Experimental results show that our model performed well in some metrics and leads discussion on topics such as contribution of each component and on syntactic similarities among languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K17-3029.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K17-3029 data-toggle=collapse aria-expanded=false aria-controls=abstract-K17-3029 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K17-3029/>A rule-based system for cross-lingual parsing of Romance languages with Universal Dependencies<span class=acl-fixed-case>R</span>omance languages with <span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependencies</a></strong><br><a href=/people/m/marcos-garcia/>Marcos Garcia</a>
|
<a href=/people/p/pablo-gamallo/>Pablo Gamallo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K17-3029><div class="card-body p-3 small">This article describes MetaRomance, a rule-based cross-lingual parser for <a href=https://en.wikipedia.org/wiki/Romance_languages>Romance languages</a> submitted to CoNLL 2017 Shared Task : Multilingual Parsing from Raw Text to Universal Dependencies. The <a href=https://en.wikipedia.org/wiki/System>system</a> is an almost delexicalized parser which does not need training data to analyze <a href=https://en.wikipedia.org/wiki/Romance_languages>Romance languages</a>. It contains linguistically motivated rules based on PoS-tag patterns. The rules included in MetaRomance were developed in about 12 hours by one expert with no prior knowledge in Universal Dependencies, and can be easily extended using a transparent formalism. In this paper we compare the performance of MetaRomance with other <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised systems</a> participating in the competition, paying special attention to the <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a> of different <a href=https://en.wikipedia.org/wiki/Treebank>treebanks</a> of the same language. We also compare our system with a delexicalized parser for <a href=https://en.wikipedia.org/wiki/Romance_languages>Romance languages</a>, and take advantage of the harmonized annotation of Universal Dependencies to propose a language ranking based on the syntactic distance each variety has from <a href=https://en.wikipedia.org/wiki/Romance_languages>Romance languages</a>.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>