<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 7th Workshop on Cognitive Modeling and Computational Linguistics (CMCL 2017) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Proceedings of the 7th Workshop on Cognitive Modeling and Computational Linguistics (<span class=acl-fixed-case>CMCL</span> 2017)</h2><p class=lead><a href=/people/t/ted-gibson/>Ted Gibson</a>,
<a href=/people/t/tal-linzen/>Tal Linzen</a>,
<a href=/people/a/asad-sayeed/>Asad Sayeed</a>,
<a href=/people/m/marten-van-schijndel/>Martin van Schijndel</a>,
<a href=/people/w/william-schuler/>William Schuler</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>W17-07</dd><dt>Month:</dt><dd>April</dd><dt>Year:</dt><dd>2017</dd><dt>Address:</dt><dd>Valencia, Spain</dd><dt>Venues:</dt><dd><a href=/venues/cmcl/>CMCL</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/W17-07>https://aclanthology.org/W17-07</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/W17-07 title="To the current version of the paper by DOI">10.18653/v1/W17-07</a></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+7th+Workshop+on+Cognitive+Modeling+and+Computational+Linguistics+%28CMCL+2017%29" title="Search for 'Proceedings of the 7th Workshop on Cognitive Modeling and Computational Linguistics (CMCL 2017)' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-0700.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-0700/>Proceedings of the 7th Workshop on Cognitive Modeling and Computational Linguistics (<span class=acl-fixed-case>CMCL</span> 2017)</a></strong><br><a href=/people/t/ted-gibson/>Ted Gibson</a>
|
<a href=/people/t/tal-linzen/>Tal Linzen</a>
|
<a href=/people/a/asad-sayeed/>Asad Sayeed</a>
|
<a href=/people/m/marten-van-schijndel/>Martin van Schijndel</a>
|
<a href=/people/w/william-schuler/>William Schuler</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-0701.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-0701 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-0701 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-0701/>Entropy Reduction correlates with <a href=https://en.wikipedia.org/wiki/Temporal_lobe>temporal lobe activity</a></a></strong><br><a href=/people/m/matthew-nelson/>Matthew Nelson</a>
|
<a href=/people/s/stanislas-dehaene/>Stanislas Dehaene</a>
|
<a href=/people/c/christophe-pallier/>Christophe Pallier</a>
|
<a href=/people/j/john-hale/>John Hale</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-0701><div class="card-body p-3 small">Using the Entropy Reduction incremental complexity metric, we relate high gamma power signals from the brains of epileptic patients to incremental stages of syntactic analysis in <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/French_language>French</a>. We find that signals recorded intracranially from the anterior Inferior Temporal Sulcus (aITS) and the posterior Inferior Temporal Gyrus (pITG) correlate with word-by-word Entropy Reduction values derived from phrase structure grammars for those languages. In the anterior region, this correlation persists even in combination with surprisal co-predictors from PCFG and ngram models. The result confirms the idea that the brain&#8217;s temporal lobe houses a <a href=https://en.wikipedia.org/wiki/Parsing>parsing function</a>, one whose incremental processing difficulty profile reflects changes in <a href=https://en.wikipedia.org/wiki/Uncertainty_principle>grammatical uncertainty</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-0703.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-0703 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-0703 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-0703/>Grounding sound change in ideal observer models of perception</a></strong><br><a href=/people/z/zachary-burchill/>Zachary Burchill</a>
|
<a href=/people/t/t-florian-jaeger/>T. Florian Jaeger</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-0703><div class="card-body p-3 small">An important predictor of historical sound change, <a href=https://en.wikipedia.org/wiki/Functional_load>functional load</a>, fails to capture insights from <a href=https://en.wikipedia.org/wiki/Speech_perception>speech perception</a>. Building on ideal observer models of word recognition, we devise a new definition of <a href=https://en.wikipedia.org/wiki/Functional_load>functional load</a> that incorporates both a priori predictability and perceptual information. We explore this new <a href=https://en.wikipedia.org/wiki/Measure_(mathematics)>measure</a> with a simple <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> and find that <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> outperforms traditional <a href=https://en.wikipedia.org/wiki/Measure_(mathematics)>measures</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-0704.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-0704 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-0704 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-0704/>Oh, I’ve Heard That Before : Modelling Own-Dialect Bias After <a href=https://en.wikipedia.org/wiki/Perceptual_learning>Perceptual Learning</a> by Weighting Training Data<span class=acl-fixed-case>I</span>’ve Heard That Before”: Modelling Own-Dialect Bias After Perceptual Learning by Weighting Training Data</a></strong><br><a href=/people/r/rachael-tatman/>Rachael Tatman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-0704><div class="card-body p-3 small">Human listeners are able to quickly and robustly adapt to new accents and do so by using information about speaker&#8217;s identities. This paper will present experimental evidence that, even considering information about speaker&#8217;s identities, listeners retain a strong bias towards the acoustics of their own dialect after dialect learning. Participants&#8217; behaviour was accurately mimicked by a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> which was trained on more cases from the base dialect and fewer from the target dialect. This suggests that imbalanced training data may result in automatic speech recognition errors consistent with those of speakers from populations over-represented in the training data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-0705.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-0705 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-0705 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-0705/>Inherent Biases of <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>Recurrent Neural Networks</a> for Phonological Assimilation and Dissimilation</a></strong><br><a href=/people/a/amanda-doucette/>Amanda Doucette</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-0705><div class="card-body p-3 small">A <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network model</a> of phonological pattern learning is proposed. The model is a relatively simple <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> with one <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent layer</a>, and displays biases in learning that mimic observed biases in human learning. Single-feature patterns are learned faster than two-feature patterns, and vowel or consonant-only patterns are learned faster than <a href=https://en.wikipedia.org/wiki/Pattern>patterns</a> involving vowels and consonants, mimicking the results of laboratory learning experiments. In non-recurrent models, capturing these biases requires the use of alpha features or some other representation of repeated features, but with a <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network</a>, these elaborations are not necessary.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>