<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Tutorial Abstracts - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Proceedings of the 15th Conference of the <span class=acl-fixed-case>E</span>uropean Chapter of the Association for Computational Linguistics: Tutorial Abstracts</h2><p class=lead><a href=/people/a/alexandre-klementiev/>Alexandre Klementiev</a>,
<a href=/people/l/lucia-specia/>Lucia Specia</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>E17-5</dd><dt>Month:</dt><dd>April</dd><dt>Year:</dt><dd>2017</dd><dt>Address:</dt><dd>Valencia, Spain</dd><dt>Venue:</dt><dd><a href=/venues/eacl/>EACL</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/E17-5>https://aclanthology.org/E17-5</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+15th+Conference+of+the+European+Chapter+of+the+Association+for+Computational+Linguistics%3A+Tutorial+Abstracts" title="Search for 'Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Tutorial Abstracts' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-5001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-5001 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-5001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-5001/>Universal Dependencies<span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependencies</a></strong><br><a href=/people/j/joakim-nivre/>Joakim Nivre</a>
|
<a href=/people/d/daniel-zeman/>Daniel Zeman</a>
|
<a href=/people/f/filip-ginter/>Filip Ginter</a>
|
<a href=/people/f/francis-tyers/>Francis Tyers</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-5001><div class="card-body p-3 small">Universal Dependencies (UD) is a project that seeks to develop cross-linguistically consistent treebank annotation for many languages. This tutorial gives an introduction to the UD framework and resources, from basic design principles to annotation guidelines and existing <a href=https://en.wikipedia.org/wiki/Treebank>treebanks</a>. We also discuss tools for developing and exploiting UD treebanks and survey applications of UD in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> and <a href=https://en.wikipedia.org/wiki/Linguistics>linguistics</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-5002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-5002 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-5002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-5002/>Practical Neural Machine Translation</a></strong><br><a href=/people/r/rico-sennrich/>Rico Sennrich</a>
|
<a href=/people/b/barry-haddow/>Barry Haddow</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-5002><div class="card-body p-3 small">Neural Machine Translation (NMT) has achieved new breakthroughs in <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> in recent years. It has dominated recent shared translation tasks in machine translation research, and is also being quickly adopted in industry. The technical differences between NMT and the previously dominant phrase-based statistical approach require that practictioners learn new best practices for building MT systems, ranging from different hardware requirements, new techniques for handling rare words and monolingual data, to new opportunities in continued learning and domain adaptation. This tutorial is aimed at researchers and users of <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> interested in working with NMT. The tutorial will cover a basic theoretical introduction to <a href=https://en.wikipedia.org/wiki/Network_topology>NMT</a>, discuss the components of state-of-the-art systems, and provide practical advice for building <a href=https://en.wikipedia.org/wiki/Network_topology>NMT systems</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-5003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-5003 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-5003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-5003/>Imitation learning for <a href=https://en.wikipedia.org/wiki/Structured_prediction>structured prediction</a> in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a></a></strong><br><a href=/people/a/andreas-vlachos/>Andreas Vlachos</a>
|
<a href=/people/g/gerasimos-lampouras/>Gerasimos Lampouras</a>
|
<a href=/people/s/sebastian-riedel/>Sebastian Riedel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-5003><div class="card-body p-3 small">Imitation learning is a learning paradigm originally developed to learn <a href=https://en.wikipedia.org/wiki/Robot_control>robotic controllers</a> from demonstrations by humans, e.g. autonomous flight from pilot demonstrations. Recently, algorithms for <a href=https://en.wikipedia.org/wiki/Structured_prediction>structured prediction</a> were proposed under this paradigm and have been applied successfully to a number of tasks including syntactic dependency parsing, <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction</a>, <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a>, dynamic feature selection, semantic parsing and <a href=https://en.wikipedia.org/wiki/Natural-language_generation>natural language generation</a>. Key advantages are the ability to handle large output search spaces and to learn with non-decomposable loss functions. Our aim in this tutorial is to have a unified presentation of the various imitation algorithms for structure prediction, and show how they can be applied to a variety of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP tasks</a>. All material associated with the tutorial will be made available through https://sheffieldnlp.github.io/ImitationLearningTutorialEACL2017/.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-5005.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-5005 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-5005 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-5005/>Integer Linear Programming formulations in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a></a></strong><br><a href=/people/d/dan-roth/>Dan Roth</a>
|
<a href=/people/v/vivek-srikumar/>Vivek Srikumar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-5005><div class="card-body p-3 small">Making decisions in natural language processing problems often involves assigning values to sets of <a href=https://en.wikipedia.org/wiki/Dependent_and_independent_variables>interdependent variables</a> where the expressive dependency structure can influence, or even dictate what assignments are possible. This setting includes a broad range of structured prediction problems such as <a href=https://en.wikipedia.org/wiki/Semantic_role_labeling>semantic role labeling</a>, <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity and relation recognition</a>, co-reference resolution, dependency parsing and <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a>. The setting is also appropriate for cases that may require making global decisions that involve multiple components, possibly pre-designed or pre-learned, as in event recognition and analysis, <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a>, <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrasing</a>, textual entailment and <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>. In all these cases, it is natural to formulate the <a href=https://en.wikipedia.org/wiki/Decision_problem>decision problem</a> as a constrained optimization problem, with an <a href=https://en.wikipedia.org/wiki/Loss_function>objective function</a> that is composed of learned models, subject to domain or problem specific constraints. Over the last few years, starting with a couple of papers written by (Roth & Yih, 2004, 2005), dozens of papers have been using the Integer linear programming (ILP) formulation developed there, including several award-winning papers (e.g., (Martins, Smith, & Xing, 2009 ; Koo, Rush, Collins, Jaakkola, & Sontag., 2010 ; Berant, Dagan, & Goldberger, 2011)).This tutorial will present the key ingredients of ILP formulations of natural language processing problems, aiming at guiding readers through the key modeling steps, explaining the learning and inference paradigms and exemplifying these by providing examples from the literature. We will cover a range of topics, from the theoretical foundations of learning and inference with ILP models, to practical modeling guides, to software packages and applications. The goal of this tutorial is to introduce the computational framework to broader ACL community, motivate it as a generic framework for learning and inference in global NLP decision problems, present some of the key theoretical and practical issues involved and survey some of the existing applications of it as a way to promote further development of the framework and additional applications. We will also make connections with some of the hot topics in current NLP research and show how they can be used within the general framework proposed here. The tutorial will thus be useful for many of the senior and junior researchers that have interest in global decision problems in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, providing a concise overview of recent perspectives and research results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/E17-5006.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-E17-5006 data-toggle=collapse aria-expanded=false aria-controls=abstract-E17-5006 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/E17-5006/>Building Multimodal Simulations for Natural Language</a></strong><br><a href=/people/j/james-pustejovsky/>James Pustejovsky</a>
|
<a href=/people/n/nikhil-krishnaswamy/>Nikhil Krishnaswamy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-E17-5006><div class="card-body p-3 small">In this tutorial, we introduce a computational framework and modeling language (VoxML) for composing multimodal simulations of natural language expressions within a 3D simulation environment (VoxSim). We demonstrate how to construct voxemes, which are visual object representations of linguistic entities. We also show how to compose events and actions over these <a href=https://en.wikipedia.org/wiki/Object_(computer_science)>objects</a>, within a restricted domain of dynamics. This gives us the building blocks to simulate narratives of multiple events or participate in a multimodal dialogue with synthetic agents in the simulation environment. To our knowledge, this is the first time such material has been presented as a tutorial within the CL community. This will be of relevance to students and researchers interested in modeling actionable language, natural language communication with agents and robots, spatial and temporal constraint solving through language, referring expression generation, embodied cognition, as well as minimal model creation. Multimodal simulation of language, particularly motion expressions, brings together a number of existing lines of research from the computational linguistic, semantics, robotics, and formal logic communities, including action and event representation (Di Eugenio, 1991), modeling gestural correlates to NL expressions (Kipp et al., 2007 ; Neff et al., 2008), and action event modeling (Kipper and Palmer, 2000 ; Yang et al., 2015). We combine an approach to event modeling with a scene generation approach akin to those found in work by (Coyne and Sproat, 2001 ; Siskind, 2011 ; Chang et al., 2015). Mapping natural language expressions through a <a href=https://en.wikipedia.org/wiki/Formal_system>formal model</a> and a dynamic logic interpretation into a visualization of the event described provides an environment for grounding concepts and referring expressions that is interpretable by both a computer and a human user. This opens a variety of avenues for humans to communicate with computerized agents and robots, as in (Matuszek et al., 2013 ; Lauria et al., 2001), (Forbes et al., 2015), and (Deits et al., 2013 ; Walter et al., 2013 ; Tellex et al., 2014). Simulation and automatic visualization of events from natural language descriptions and supplementary modalities, such as gestures, allows humans to use their native capabilities as linguistic and visual interpreters to collaborate on tasks with an artificial agent or to put semantic intuitions to the test in an environment where user and agent share a common context. In previous work (Pustejovsky and Krishnaswamy, 2014 ; Pustejovsky, 2013a), we introduced a method for modeling natural language expressions within a 3D simulation environment built on top of the game development platform Unity (Goldstone, 2009). The goal of that work was to evaluate, through explicit visualizations of linguistic input, the semantic presuppositions inherent in the different lexical choices of an utterance. This work led to two additional lines of research : an explicit encoding for how an object is itself situated relative to its environment ; and an operational characterization of how an object changes its location or how an agent acts on an object over time, e.g., its affordance structure. The former has developed into a semantic notion of situational context, called a habitat (Pustejovsky, 2013a ; McDonald and Pustejovsky, 2014), while the latter is addressed by dynamic interpretations of event structure (Pustejovsky and Moszkowicz, 2011 ; Pustejovsky and Krishnaswamy, 2016b ; Pustejovsky, 2013b).The requirements on building a visual simulation from language include several components. We require a rich type system for lexical items and their composition, as well as a language for modeling the dynamics of events, based on Generative Lexicon (GL). Further, a minimal embedding space (MES) for the <a href=https://en.wikipedia.org/wiki/Simulation>simulation</a> must be determined. This is the <a href=https://en.wikipedia.org/wiki/Three-dimensional_space>3D region</a> within which the state is configured or the event unfolds. Object-based attributes for participants in a situation or event also need to be specified ; e.g., <a href=https://en.wikipedia.org/wiki/Orientation_(geometry)>orientation</a>, relative size, default position or pose, etc. The <a href=https://en.wikipedia.org/wiki/Simulation>simulation</a> establishes an epistemic condition on the object and event rendering, imposing an implicit point of view (POV). Finally, there must be some sort of agent-dependent embodiment ; this determines the relative scaling of an agent and its event participants and their surroundings, as it engages in the environment. In order to construct a robust simulation from linguistic input, an event and its participants must be embedded within an appropriate minimal embedding space. This must sufficiently enclose the <a href=https://en.wikipedia.org/wiki/Event_(computing)>event localization</a>, while optionally including space enough for a frame of reference for the event (the viewers perspective).We first describe the formal multimodal foundations for the <a href=https://en.wikipedia.org/wiki/Modeling_language>modeling language</a>, VoxML, which creates a minimal simulation from the linguistic input interpreted by the multimodal language, DITL. We then describe VoxSim, the compositional modeling and simulation environment, which maps the minimal VoxML model of the linguistic utterance to a simulation in <a href=https://en.wikipedia.org/wiki/Unity_(game_engine)>Unity</a>. This knowledge includes specification of object affordances, e.g., what actions are possible or enabled by use an object. VoxML (Pustejovsky and Krishnaswamy, 2016b ; Pustejovsky and Krishnaswamy, 2016a) encodes semantic knowledge of real-world objects represented as <a href=https://en.wikipedia.org/wiki/3D_modeling>3D models</a>, and of events and attributes related to and enacted over these <a href=https://en.wikipedia.org/wiki/Object_(computer_science)>objects</a>. VoxML goes beyond the limitations of existing 3D visual markup languages by allowing for the encoding of a broad range of semantic knowledge that can be exploited by a simulation platform such as VoxSim. VoxSim (Krishnaswamy and Pustejovsky, 2016a ; Krishnaswamy and Pustejovsky, 2016b) uses object and event semantic knowledge to generate animated scenes in real time without a complex animation interface. It uses the <a href=https://en.wikipedia.org/wiki/Unity_(game_engine)>Unity game engine</a> for graphics and I / O processing and takes as input a simple <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language utterance</a>. The parsed utterance is semantically interpreted and transformed into a hybrid dynamic logic representation (DITL), and used to generate a minimal simulation of the event when composed with VoxML knowledge.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>