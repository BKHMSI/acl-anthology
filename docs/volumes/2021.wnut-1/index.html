<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the Seventh Workshop on Noisy User-generated Text (W-NUT 2021) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Proceedings of the Seventh Workshop on Noisy User-generated Text (W-NUT 2021)</h2><p class=lead><a href=/people/w/wei-xu/>Wei Xu</a>,
<a href=/people/a/alan-ritter/>Alan Ritter</a>,
<a href=/people/t/timothy-baldwin/>Tim Baldwin</a>,
<a href=/people/a/afshin-rahimi/>Afshin Rahimi</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2021.wnut-1</dd><dt>Month:</dt><dd>November</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Online</dd><dt>Venues:</dt><dd><a href=/venues/emnlp/>EMNLP</a>
| <a href=/venues/wnut/>WNUT</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.wnut-1>https://aclanthology.org/2021.wnut-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+Seventh+Workshop+on+Noisy+User-generated+Text+%28W-NUT+2021%29" title="Search for 'Proceedings of the Seventh Workshop on Noisy User-generated Text (W-NUT 2021)' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.0/>Proceedings of the Seventh Workshop on Noisy User-generated Text (W-NUT 2021)</a></strong><br><a href=/people/w/wei-xu/>Wei Xu</a>
|
<a href=/people/a/alan-ritter/>Alan Ritter</a>
|
<a href=/people/t/timothy-baldwin/>Tim Baldwin</a>
|
<a href=/people/a/afshin-rahimi/>Afshin Rahimi</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.wnut-1.1" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.1/>Text Simplification for Comprehension-based Question-Answering</a></strong><br><a href=/people/t/tanvi-dadu/>Tanvi Dadu</a>
|
<a href=/people/k/kartikey-pant/>Kartikey Pant</a>
|
<a href=/people/s/seema-nagar/>Seema Nagar</a>
|
<a href=/people/f/ferdous-barbhuiya/>Ferdous Barbhuiya</a>
|
<a href=/people/k/kuntal-dey/>Kuntal Dey</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--1><div class="card-body p-3 small">Text simplification is the process of splitting and rephrasing a sentence to a sequence of sentences making it easier to read and understand while preserving the content and approximating the original meaning. Text simplification has been exploited in NLP applications like <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a>, <a href=https://en.wikipedia.org/wiki/Semantic_role_labeling>semantic role labeling</a>, and <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction</a>, opening a broad avenue for its exploitation in comprehension-based question-answering downstream tasks. In this work, we investigate the effect of <a href=https://en.wikipedia.org/wiki/Text_simplification>text simplification</a> in the task of <a href=https://en.wikipedia.org/wiki/Question_answering>question-answering</a> using a <a href=https://en.wikipedia.org/wiki/Context_(language_use)>comprehension context</a>. We release Simple-SQuAD, a simplified version of the widely-used SQuAD dataset. Firstly, we outline each step in the dataset creation pipeline, including style transfer, thresholding of sentences showing correct transfer, and offset finding for each answer. Secondly, we verify the quality of the transferred sentences through various <a href=https://en.wikipedia.org/wiki/Methodology>methodologies</a> involving both automated and human evaluation. Thirdly, we benchmark the newly created <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> and perform an ablation study for examining the effect of the simplification process in the SQuAD-based question answering task. Our experiments show that simplification leads to up to 2.04 % and 1.74 % increase in <a href=https://en.wikipedia.org/wiki/Exact_Match>Exact Match</a> and F1, respectively. Finally, we conclude with an analysis of the transfer process, investigating the types of edits made by the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>, and the effect of <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence length</a> on the transfer model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.wnut-1.4.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.wnut-1.4/>Keyphrase Extraction with Incomplete Annotated Training Data</a></strong><br><a href=/people/y/yanfei-lei/>Yanfei Lei</a>
|
<a href=/people/c/chunming-hu/>Chunming Hu</a>
|
<a href=/people/g/guanghui-ma/>Guanghui Ma</a>
|
<a href=/people/r/richong-zhang/>Richong Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--4><div class="card-body p-3 small">Extracting keyphrases that summarize the main points of a document is a fundamental task in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. Supervised approaches to keyphrase extraction(KPE) are largely developed based on the assumption that the training data is fully annotated. However, due to the difficulty of keyphrase annotating, KPE models severely suffer from incomplete annotated problem in many scenarios. To this end, we propose a more robust <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training method</a> that learns to mitigate the misguidance brought by unlabeled keyphrases. We introduce negative sampling to adjust training loss, and conduct experiments under different scenarios. Empirical studies on synthetic datasets and open domain dataset show that our model is robust to incomplete annotated problem and surpasses prior baselines. Extensive experiments on five scientific domain datasets of different scales demonstrate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is competitive with the state-of-the-art method.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.5/>Fine-grained Temporal Relation Extraction with Ordered-Neuron LSTM and Graph Convolutional Networks<span class=acl-fixed-case>LSTM</span> and Graph Convolutional Networks</a></strong><br><a href=/people/m/minh-tran-phu/>Minh Tran Phu</a>
|
<a href=/people/m/minh-van-nguyen/>Minh Van Nguyen</a>
|
<a href=/people/t/thien-huu-nguyen/>Thien Huu Nguyen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--5><div class="card-body p-3 small">Fine-grained temporal relation extraction (FineTempRel) aims to recognize the durations and timeline of event mentions in text. A missing part in the current deep learning models for FineTempRel is their failure to exploit the <a href=https://en.wikipedia.org/wiki/Syntax>syntactic structures</a> of the input sentences to enrich the <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representation vectors</a>. In this work, we propose to fill this gap by introducing novel methods to integrate the <a href=https://en.wikipedia.org/wiki/Syntax>syntactic structures</a> into the <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning models</a> for FineTempRel. The proposed <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> focuses on two types of syntactic information from the <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>dependency trees</a>, i.e., the syntax-based importance scores for representation learning of the words and the syntactic connections to identify important <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context words</a> for the <a href=https://en.wikipedia.org/wiki/Context_(language_use)>event mentions</a>. We also present two novel techniques to facilitate the knowledge transfer between the subtasks of FineTempRel, leading to a novel model with the state-of-the-art performance for this task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.9/>A Text Editing Approach to Joint Japanese Word Segmentation, <a href=https://en.wikipedia.org/wiki/Tag_(metadata)>POS Tagging</a>, and Lexical Normalization<span class=acl-fixed-case>J</span>apanese Word Segmentation, <span class=acl-fixed-case>POS</span> Tagging, and Lexical Normalization</a></strong><br><a href=/people/s/shohei-higashiyama/>Shohei Higashiyama</a>
|
<a href=/people/m/masao-utiyama/>Masao Utiyama</a>
|
<a href=/people/t/taro-watanabe/>Taro Watanabe</a>
|
<a href=/people/e/eiichiro-sumita/>Eiichiro Sumita</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--9><div class="card-body p-3 small">Lexical normalization, in addition to <a href=https://en.wikipedia.org/wiki/Word_segmentation>word segmentation</a> and <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a>, is a fundamental task for Japanese user-generated text processing. In this paper, we propose a text editing model to solve the three task jointly and methods of pseudo-labeled data generation to overcome the problem of data deficiency. Our experiments showed that the proposed <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> achieved better <a href=https://en.wikipedia.org/wiki/Normalization_(statistics)>normalization</a> performance when trained on more diverse pseudo-labeled data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.wnut-1.10" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.10/>Intrinsic evaluation of language models for <a href=https://en.wikipedia.org/wiki/Code-switching>code-switching</a></a></strong><br><a href=/people/s/sik-feng-cheong/>Sik Feng Cheong</a>
|
<a href=/people/h/hai-leong-chieu/>Hai Leong Chieu</a>
|
<a href=/people/j/jing-lim/>Jing Lim</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--10><div class="card-body p-3 small">Language models used in <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech recognition</a> are often either evaluated intrinsically using <a href=https://en.wikipedia.org/wiki/Perplexity>perplexity</a> on test data, or extrinsically with an automatic speech recognition (ASR) system. The former <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation</a> does not always correlate well with <a href=https://en.wikipedia.org/wiki/Signaling_(telecommunications)>ASR</a> performance, while the latter could be specific to particular <a href=https://en.wikipedia.org/wiki/Signaling_(telecommunications)>ASR systems</a>. Recent work proposed to evaluate language models by using them to classify ground truth sentences among alternative phonetically similar sentences generated by a fine state transducer. Underlying such an <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation</a> is the assumption that the generated sentences are linguistically incorrect. In this paper, we first put this assumption into question, and observe that alternatively generated sentences could often be linguistically correct when they differ from the ground truth by only one edit. Secondly, we showed that by using multi-lingual BERT, we can achieve better performance than previous work on two code-switching data sets. Our implementation is publicly available on Github at https://github.com/sikfeng/language-modelling-for-code-switching.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.wnut-1.12" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.12/>Perceived and Intended Sarcasm Detection with Graph Attention Networks</a></strong><br><a href=/people/j/joan-plepi/>Joan Plepi</a>
|
<a href=/people/l/lucie-flek/>Lucie Flek</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--12><div class="card-body p-3 small">Existing sarcasm detection systems focus on exploiting <a href=https://en.wikipedia.org/wiki/Marker_(linguistics)>linguistic markers</a>, <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context</a>, or user-level priors. However, social studies suggest that the relationship between the author and the audience can be equally relevant for the sarcasm usage and interpretation. In this work, we propose a <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> jointly leveraging (1) a user context from their historical tweets together with (2) the social information from a user&#8217;s conversational neighborhood in an interaction graph, to contextualize the interpretation of the post. We use graph attention networks (GAT) over users and tweets in a conversation thread, combined with dense user history representations. Apart from achieving state-of-the-art results on the recently published dataset of 19k Twitter users with 30 K labeled tweets, adding 10 M unlabeled tweets as context, our results indicate that the model contributes to interpreting the sarcastic intentions of an author more than to predicting the sarcasm perception by others.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.18.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--18 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.18 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.18/>Comparing Grammatical Theories of Code-Mixing</a></strong><br><a href=/people/a/adithya-pratapa/>Adithya Pratapa</a>
|
<a href=/people/m/monojit-choudhury/>Monojit Choudhury</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--18><div class="card-body p-3 small">Code-mixed text generation systems have found applications in many downstream tasks, including <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech recognition</a>, <a href=https://en.wikipedia.org/wiki/Translation>translation</a> and <a href=https://en.wikipedia.org/wiki/Dialogue>dialogue</a>. A paradigm of these generation systems relies on well-defined grammatical theories of code-mixing, and there is a lack of comparison of these <a href=https://en.wikipedia.org/wiki/Theory>theories</a>. We present a large-scale human evaluation of two popular grammatical theories, Matrix-Embedded Language (ML) and Equivalence Constraint (EC). We compare them against three heuristic-based models and quantitatively demonstrate the effectiveness of the two <a href=https://en.wikipedia.org/wiki/Grammatical_theory>grammatical theories</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.21/>Mitigation of Diachronic Bias in Fake News Detection Dataset</a></strong><br><a href=/people/t/taichi-murayama/>Taichi Murayama</a>
|
<a href=/people/s/shoko-wakamiya/>Shoko Wakamiya</a>
|
<a href=/people/e/eiji-aramaki/>Eiji Aramaki</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--21><div class="card-body p-3 small">Fake news causes significant damage to society. To deal with these <a href=https://en.wikipedia.org/wiki/Fake_news>fake news</a>, several studies on building detection models and arranging datasets have been conducted. Most of the fake news datasets depend on a specific time period. Consequently, the detection models trained on such a dataset have difficulty detecting novel <a href=https://en.wikipedia.org/wiki/Fake_news>fake news</a> generated by political changes and social changes ; they may possibly result in biased output from the input, including specific person names and organizational names. We refer to this problem as Diachronic Bias because it is caused by the creation date of news in each dataset. In this study, we confirm the <a href=https://en.wikipedia.org/wiki/Bias>bias</a>, especially <a href=https://en.wikipedia.org/wiki/Proper_noun>proper nouns</a> including <a href=https://en.wikipedia.org/wiki/Personal_name>person names</a>, from the deviation of phrase appearances in each dataset. Based on these findings, we propose masking methods using <a href=https://en.wikipedia.org/wiki/Wikidata>Wikidata</a> to mitigate the influence of person names and validate whether they make fake news detection models robust through experiments with in-domain and out-of-domain data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.24.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--24 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.24 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.24/>Changes in Twitter geolocations : Insights and suggestions for future usage<span class=acl-fixed-case>T</span>witter geolocations: Insights and suggestions for future usage</a></strong><br><a href=/people/a/anna-kruspe/>Anna Kruspe</a>
|
<a href=/people/m/matthias-haberle/>Matthias Häberle</a>
|
<a href=/people/e/eike-j-hoffmann/>Eike J. Hoffmann</a>
|
<a href=/people/s/samyo-rode-hasinger/>Samyo Rode-Hasinger</a>
|
<a href=/people/k/karam-abdulahhad/>Karam Abdulahhad</a>
|
<a href=/people/x/xiao-xiang-zhu/>Xiao Xiang Zhu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--24><div class="card-body p-3 small">Twitter data has become established as a valuable source of data for various application scenarios in the past years. For many such <a href=https://en.wikipedia.org/wiki/Application_software>applications</a>, it is necessary to know where Twitter posts (tweets) were sent from or what location they refer to. Researchers have frequently used exact coordinates provided in a small percentage of tweets, but <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> removed the option to share these <a href=https://en.wikipedia.org/wiki/Coordinate_system>coordinates</a> in mid-2019. Moreover, there is reason to suspect that a large share of the provided coordinates did not correspond to <a href=https://en.wikipedia.org/wiki/Global_Positioning_System>GPS coordinates</a> of the user even before that. In this paper, we explain the situation and the 2019 policy change and shed light on the various options of still obtaining location information from <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a>. We provide usage statistics including changes over time, and analyze what the removal of exact coordinates means for various common research tasks performed with Twitter data. Finally, we make suggestions for future research requiring geolocated tweets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.32.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--32 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.32 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.32/>Coping with Noisy Training Data Labels in Paraphrase Detection</a></strong><br><a href=/people/t/teemu-vahtola/>Teemu Vahtola</a>
|
<a href=/people/m/mathias-creutz/>Mathias Creutz</a>
|
<a href=/people/e/eetu-sjoblom/>Eetu Sjöblom</a>
|
<a href=/people/s/sami-itkonen/>Sami Itkonen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--32><div class="card-body p-3 small">We present new state-of-the-art benchmarks for <a href=https://en.wikipedia.org/wiki/Paraphrase_detection>paraphrase detection</a> on all six languages in the Opusparcus sentential paraphrase corpus : <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/Finnish_language>Finnish</a>, <a href=https://en.wikipedia.org/wiki/French_language>French</a>, <a href=https://en.wikipedia.org/wiki/German_language>German</a>, <a href=https://en.wikipedia.org/wiki/Russian_language>Russian</a>, and <a href=https://en.wikipedia.org/wiki/Swedish_language>Swedish</a>. We reach these <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> by fine-tuning BERT. The best results are achieved on smaller and cleaner subsets of the training sets than was observed in previous research. Additionally, we study a translation-based approach that is competitive for the languages with more limited and noisier training data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.35.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--35 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.35 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.35/>Detecting Cross-Geographic Biases in Toxicity Modeling on <a href=https://en.wikipedia.org/wiki/Social_media>Social Media</a></a></strong><br><a href=/people/s/sayan-ghosh/>Sayan Ghosh</a>
|
<a href=/people/d/dylan-baker/>Dylan Baker</a>
|
<a href=/people/d/david-jurgens/>David Jurgens</a>
|
<a href=/people/v/vinodkumar-prabhakaran/>Vinodkumar Prabhakaran</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--35><div class="card-body p-3 small">Online social media platforms increasingly rely on Natural Language Processing (NLP) techniques to detect abusive content at scale in order to mitigate the harms it causes to their users. However, these techniques suffer from various sampling and association biases present in training data, often resulting in sub-par performance on content relevant to <a href=https://en.wikipedia.org/wiki/Social_exclusion>marginalized groups</a>, potentially furthering disproportionate harms towards them. Studies on such biases so far have focused on only a handful of axes of disparities and subgroups that have annotations / lexicons available. Consequently, biases concerning non-Western contexts are largely ignored in the literature. In this paper, we introduce a weakly supervised method to robustly detect lexical biases in broader geo-cultural contexts. Through a case study on a publicly available toxicity detection model, we demonstrate that our method identifies salient groups of cross-geographic errors, and, in a follow up, demonstrate that these groupings reflect human judgments of offensive and inoffensive language in those geographic contexts. We also conduct analysis of a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> trained on a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> with ground truth labels to better understand these biases, and present preliminary mitigation experiments.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.36.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--36 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.36 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.wnut-1.36" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.36/>Detection of Puffery on the <a href=https://en.wikipedia.org/wiki/English_Wikipedia>English Wikipedia</a><span class=acl-fixed-case>E</span>nglish <span class=acl-fixed-case>W</span>ikipedia</a></strong><br><a href=/people/a/amanda-bertsch/>Amanda Bertsch</a>
|
<a href=/people/s/steven-bethard/>Steven Bethard</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--36><div class="card-body p-3 small">On <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>, an online crowdsourced encyclopedia, volunteers enforce the encyclopedia&#8217;s editorial policies. Wikipedia&#8217;s policy on maintaining a neutral point of view has inspired recent research on bias detection, including <a href=https://en.wikipedia.org/wiki/Weasel_word>weasel words</a> and <a href=https://en.wikipedia.org/wiki/Hedge_(finance)>hedges</a>. Yet to date, little work has been done on identifying <a href=https://en.wikipedia.org/wiki/Puffery>puffery</a>, phrases that are overly positive without a verifiable source. We demonstrate that collecting training data for this task requires some care, and construct a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> by combining <a href=https://en.wikipedia.org/wiki/Wikipedia_community>Wikipedia editorial annotations</a> and <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval techniques</a>. We compare several approaches to predicting puffery, and achieve 0.963 <a href=https://en.wikipedia.org/wiki/F-number>f1 score</a> by incorporating <a href=https://en.wikipedia.org/wiki/Citation>citation features</a> into a RoBERTa model. Finally, we demonstrate how to integrate our model with Wikipedia&#8217;s public infrastructure to give back to the Wikipedia editor community.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.37.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--37 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.37 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.37/>Robustness and Sensitivity of BERT Models Predicting Alzheimer’s Disease from Text<span class=acl-fixed-case>BERT</span> Models Predicting <span class=acl-fixed-case>A</span>lzheimer’s Disease from Text</a></strong><br><a href=/people/j/jekaterina-novikova/>Jekaterina Novikova</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--37><div class="card-body p-3 small">Understanding robustness and <a href=https://en.wikipedia.org/wiki/Sensitivity_and_specificity>sensitivity</a> of BERT models predicting Alzheimer&#8217;s disease from text is important for both developing better classification models and for understanding their capabilities and limitations. In this paper, we analyze how a controlled amount of desired and undesired text alterations impacts performance of BERT. We show that BERT is robust to natural linguistic variations in text. On the other hand, we show that BERT is not sensitive to removing clinically important information from text.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.39.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--39 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.39 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.39/>CIDEr-R : Robust Consensus-based Image Description Evaluation<span class=acl-fixed-case>CIDE</span>r-<span class=acl-fixed-case>R</span>: Robust Consensus-based Image Description Evaluation</a></strong><br><a href=/people/g/gabriel-oliveira-dos-santos/>Gabriel Oliveira dos Santos</a>
|
<a href=/people/e/esther-luna-colombini/>Esther Luna Colombini</a>
|
<a href=/people/s/sandra-avila/>Sandra Avila</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--39><div class="card-body p-3 small">This paper shows that CIDEr-D, a traditional evaluation metric for image description, does not work properly on datasets where the number of words in the sentence is significantly greater than those in the MS COCO Captions dataset. We also show that CIDEr-D has performance hampered by the lack of multiple reference sentences and high variance of <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence length</a>. To bypass this problem, we introduce CIDEr-R, which improves CIDEr-D, making it more flexible in dealing with <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> with high sentence length variance. We demonstrate that CIDEr-R is more accurate and closer to human judgment than CIDEr-D ; CIDEr-R is more robust regarding the number of available references. Our results reveal that using Self-Critical Sequence Training to optimize CIDEr-R generates descriptive captions. In contrast, when CIDEr-D is optimized, the generated captions&#8217; length tends to be similar to the reference length. However, the <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> also repeat several times the same word to increase the <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence length</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.42.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--42 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.42 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.42/>Improved Multilingual Language Model Pretraining for Social Media Text via Translation Pair Prediction</a></strong><br><a href=/people/s/shubhanshu-mishra/>Shubhanshu Mishra</a>
|
<a href=/people/a/aria-haghighi/>Aria Haghighi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--42><div class="card-body p-3 small">We evaluate a simple approach to improving zero-shot multilingual transfer of mBERT on social media corpus by adding a pretraining task called translation pair prediction (TPP), which predicts whether a pair of cross-lingual texts are a valid translation. Our approach assumes access to translations (exact or approximate) between source-target language pairs, where we fine-tune a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on source language task data and evaluate the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> in the target language. In particular, we focus on language pairs where <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> is difficult for mBERT : those where source and target languages are different in script, <a href=https://en.wikipedia.org/wiki/Vocabulary>vocabulary</a>, and <a href=https://en.wikipedia.org/wiki/Linguistic_typology>linguistic typology</a>. We show improvements from TPP pretraining over mBERT alone in zero-shot transfer from <a href=https://en.wikipedia.org/wiki/English_language>English</a> to <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a>, <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a>, and <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a> on two social media tasks : NER (a 37 % average relative improvement in F1 across target languages) and sentiment classification (12 % relative improvement in F1) on social media text, while also benchmarking on a non-social media task of Universal Dependency POS tagging (6.7 % relative improvement in accuracy). Our results are promising given the lack of social media bitext corpus. Our code can be found at : https://github.com/twitter-research/multilingual-alignment-tpp.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.46.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--46 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.46 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.wnut-1.46" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.46/>Character Transformations for Non-Autoregressive GEC Tagging<span class=acl-fixed-case>GEC</span> Tagging</a></strong><br><a href=/people/m/milan-straka/>Milan Straka</a>
|
<a href=/people/j/jakub-naplava/>Jakub Náplava</a>
|
<a href=/people/j/jana-strakova/>Jana Straková</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--46><div class="card-body p-3 small">We propose a character-based non-autoregressive GEC approach, with automatically generated character transformations. Recently, per-word classification of correction edits has proven an efficient, parallelizable alternative to current encoder-decoder GEC systems. We show that word replacement edits may be suboptimal and lead to explosion of rules for <a href=https://en.wikipedia.org/wiki/Spelling>spelling</a>, diacritization and errors in morphologically rich languages, and propose a method for generating character transformations from GEC corpus. Finally, we train character transformation models for <a href=https://en.wikipedia.org/wiki/Czech_language>Czech</a>, <a href=https://en.wikipedia.org/wiki/German_language>German</a> and <a href=https://en.wikipedia.org/wiki/Russian_language>Russian</a>, reaching solid results and dramatic speedup compared to autoregressive systems. The source code is released at https://github.com/ufal/wnut2021_character_transformations_gec.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.47.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--47 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.47 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.47/>Can Character-based Language Models Improve Downstream Task Performances In Low-Resource And Noisy Language Scenarios?</a></strong><br><a href=/people/a/arij-riabi/>Arij Riabi</a>
|
<a href=/people/b/benoit-sagot/>Benoît Sagot</a>
|
<a href=/people/d/djame-seddah/>Djamé Seddah</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--47><div class="card-body p-3 small">Recent impressive improvements in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, largely based on the success of contextual neural language models, have been mostly demonstrated on at most a couple dozen high- resource languages. Building language mod- els and, more generally, NLP systems for non- standardized and low-resource languages remains a challenging task. In this work, we fo- cus on North-African colloquial dialectal Arabic written using an extension of the <a href=https://en.wikipedia.org/wiki/Latin_script>Latin script</a>, called NArabizi, found mostly on social media and messaging communication. In this low-resource scenario with data display- ing a high level of variability, we compare the downstream performance of a character-based language model on <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a> and dependency parsing to that of monolingual and multilingual models. We show that a character-based model trained on only 99k sentences of NArabizi and fined-tuned on a small treebank of this language leads to performance close to those obtained with the same architecture pre- trained on large multilingual and monolingual models. Confirming these results a on much larger data set of noisy French user-generated content, we argue that such character-based language models can be an asset for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> in low-resource and high language variability set- tings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.48.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--48 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.48 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.48/>Something Something Hota Hai ! An Explainable Approach towards <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a> on Indian Code-Mixed Data<span class=acl-fixed-case>I</span>ndian Code-Mixed Data</a></strong><br><a href=/people/a/aman-priyanshu/>Aman Priyanshu</a>
|
<a href=/people/a/aleti-vardhan/>Aleti Vardhan</a>
|
<a href=/people/s/sudarshan-sivakumar/>Sudarshan Sivakumar</a>
|
<a href=/people/s/supriti-vijay/>Supriti Vijay</a>
|
<a href=/people/n/nipuna-chhabra/>Nipuna Chhabra</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--48><div class="card-body p-3 small">The increasing use of social media sites in countries like India has given rise to large volumes of code-mixed data. Sentiment analysis of this <a href=https://en.wikipedia.org/wiki/Data>data</a> can provide integral insights into people&#8217;s perspectives and opinions. Code-mixed data is often noisy in nature due to multiple spellings for the same word, lack of definite order of words in a sentence, and random abbreviations. Thus, working with code-mixed data is more challenging than monolingual data. Interpreting a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s predictions allows us to determine the <a href=https://en.wikipedia.org/wiki/Robust_statistics>robustness</a> of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> against different forms of <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noise</a>. In this paper, we propose a <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> to integrate explainable approaches into code-mixed sentiment analysis. By interpreting the predictions of <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis models</a> we evaluate how well the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is able to adapt to the implicit noises present in code-mixed data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.49.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--49 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.49 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.wnut-1.49" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.49/>BERTweetFR : Domain Adaptation of Pre-Trained Language Models for French Tweets<span class=acl-fixed-case>BERT</span>weet<span class=acl-fixed-case>FR</span> : Domain Adaptation of Pre-Trained Language Models for <span class=acl-fixed-case>F</span>rench Tweets</a></strong><br><a href=/people/y/yanzhu-guo/>Yanzhu Guo</a>
|
<a href=/people/v/virgile-rennard/>Virgile Rennard</a>
|
<a href=/people/c/christos-xypolopoulos/>Christos Xypolopoulos</a>
|
<a href=/people/m/michalis-vazirgiannis/>Michalis Vazirgiannis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--49><div class="card-body p-3 small">We introduce BERTweetFR, the first large-scale pre-trained language model for French tweets. Our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> is initialised using a general-domain French language model CamemBERT which follows the base architecture of BERT. Experiments show that BERTweetFR outperforms all previous general-domain French language models on two downstream Twitter NLP tasks of offensiveness identification and <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> used in the offensiveness detection task is first created and annotated by our team, filling in the gap of such analytic datasets in <a href=https://en.wikipedia.org/wiki/French_language>French</a>. We make our model publicly available in the transformers library with the aim of promoting future research in analytic tasks for French tweets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.50.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--50 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.50 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.50/>To What Extent Does Lexical Normalization Help English-as-a-Second Language Learners to Read Noisy English Texts?<span class=acl-fixed-case>E</span>nglish-as-a-Second Language Learners to Read Noisy <span class=acl-fixed-case>E</span>nglish Texts?</a></strong><br><a href=/people/y/yo-ehara/>Yo Ehara</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--50><div class="card-body p-3 small">How difficult is it for English-as-a-second language (ESL) learners to read noisy English texts? Do <a href=https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language>ESL learners</a> need lexical normalization to read noisy English texts? These questions may also affect community formation on <a href=https://en.wikipedia.org/wiki/Social_networking_service>social networking sites</a> where differences can be attributed to <a href=https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language>ESL learners</a> and <a href=https://en.wikipedia.org/wiki/First_language>native English speakers</a>. However, few studies have addressed these questions. To this end, we built highly accurate readability assessors to evaluate the readability of texts for <a href=https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language>ESL learners</a>. We then applied these assessors to noisy English texts to further assess the readability of the texts. The experimental results showed that although intermediate-level ESL learners can read most noisy English texts in the first place, lexical normalization significantly improves the readability of noisy English texts for <a href=https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language>ESL learners</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.51.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--51 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.51 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.51/>Multilingual Sequence Labeling Approach to solve Lexical Normalization</a></strong><br><a href=/people/d/divesh-kubal/>Divesh Kubal</a>
|
<a href=/people/a/apurva-nagvenkar/>Apurva Nagvenkar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--51><div class="card-body p-3 small">The task of converting a <a href=https://en.wikipedia.org/wiki/Nonstandard_dialect>nonstandard text</a> to a standard and readable text is known as lexical normalization. Almost all the Natural Language Processing (NLP) applications require the text data in normalized form to build quality task-specific models. Hence, lexical normalization has been proven to improve the performance of numerous natural language processing tasks on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. This study aims to solve the problem of Lexical Normalization by formulating the Lexical Normalization task as a Sequence Labeling problem. This paper proposes a sequence labeling approach to solve the problem of Lexical Normalization in combination with the word-alignment technique. The goal is to use a single model to normalize text in various languages namely <a href=https://en.wikipedia.org/wiki/Croatian_language>Croatian</a>, <a href=https://en.wikipedia.org/wiki/Danish_language>Danish</a>, <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch</a>, <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/Indonesian_language>Indonesian-English</a>, <a href=https://en.wikipedia.org/wiki/German_language>German</a>, <a href=https://en.wikipedia.org/wiki/Italian_language>Italian</a>, <a href=https://en.wikipedia.org/wiki/Serbian_language>Serbian</a>, <a href=https://en.wikipedia.org/wiki/Slovene_language>Slovenian</a>, <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>, <a href=https://en.wikipedia.org/wiki/Turkish_language>Turkish</a>, and <a href=https://en.wikipedia.org/wiki/Turkish_language>Turkish-German</a>. This is a shared task in 2021 The 7th Workshop on Noisy User-generated Text (W-NUT) in which the participants are expected to create a system / model that performs lexical normalization, which is the translation of non-canonical texts into their canonical equivalents, comprising data from over 12 languages. The proposed single multilingual model achieves an overall ERR score of 43.75 on intrinsic evaluation and an overall Labeled Attachment Score (LAS) score of 63.12 on extrinsic evaluation. Further, the proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a> achieves the highest Error Reduction Rate (ERR) score of 61.33 among the participants in the shared task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.52.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--52 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.52 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.52/>Sesame Street to Mount Sinai : BERT-constrained character-level Moses models for multilingual lexical normalization<span class=acl-fixed-case>BERT</span>-constrained character-level <span class=acl-fixed-case>M</span>oses models for multilingual lexical normalization</a></strong><br><a href=/people/y/yves-scherrer/>Yves Scherrer</a>
|
<a href=/people/n/nikola-ljubesic/>Nikola Ljubešić</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--52><div class="card-body p-3 small">This paper describes the HEL-LJU submissions to the MultiLexNorm shared task on multilingual lexical normalization. Our system is based on a BERT token classification preprocessing step, where for each token the type of the necessary transformation is predicted (none, uppercase, lowercase, capitalize, modify), and a character-level SMT step where the text is translated from original to normalized given the BERT-predicted transformation constraints. For some languages, depending on the results on development data, the <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training data</a> was extended by back-translating OpenSubtitles data. In the final ordering of the ten participating teams, the HEL-LJU team has taken the second place, scoring better than the previous <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.53.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--53 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.53 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.53/>Sequence-to-Sequence Lexical Normalization with Multilingual Transformers</a></strong><br><a href=/people/a/ana-maria-bucur/>Ana-Maria Bucur</a>
|
<a href=/people/a/adrian-cosma/>Adrian Cosma</a>
|
<a href=/people/l/liviu-p-dinu/>Liviu P. Dinu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--53><div class="card-body p-3 small">Current benchmark tasks for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> contain text that is qualitatively different from the text used in informal day to day digital communication. This discrepancy has led to severe performance degradation of state-of-the-art NLP models when fine-tuned on real-world data. One way to resolve this issue is through lexical normalization, which is the process of transforming non-standard text, usually from <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>, into a more standardized form. In this work, we propose a sentence-level sequence-to-sequence model based on mBART, which frames the problem as a <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation problem</a>. As the noisy text is a pervasive problem across languages, not just <a href=https://en.wikipedia.org/wiki/English_language>English</a>, we leverage the multi-lingual pre-training of mBART to fine-tune it to our data. While current approaches mainly operate at the word or subword level, we argue that this approach is straightforward from a technical standpoint and builds upon existing pre-trained transformer networks. Our results show that while word-level, intrinsic, performance evaluation is behind other methods, our model improves performance on extrinsic, downstream tasks through <a href=https://en.wikipedia.org/wiki/Normalization_(statistics)>normalization</a> compared to models operating on raw, unprocessed, social media text.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.wnut-1.54.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--wnut-1--54 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.wnut-1.54 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.wnut-1.54" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.wnut-1.54/>FAL at MultiLexNorm 2021 : Improving Multilingual Lexical Normalization by Fine-tuning ByT5<span class=acl-fixed-case>ÚFAL</span> at <span class=acl-fixed-case>M</span>ulti<span class=acl-fixed-case>L</span>ex<span class=acl-fixed-case>N</span>orm 2021: Improving Multilingual Lexical Normalization by Fine-tuning <span class=acl-fixed-case>B</span>y<span class=acl-fixed-case>T</span>5</a></strong><br><a href=/people/d/david-samuel/>David Samuel</a>
|
<a href=/people/m/milan-straka/>Milan Straka</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--wnut-1--54><div class="card-body p-3 small">We present the winning entry to the Multilingual Lexical Normalization (MultiLexNorm) shared task at W-NUT 2021 (van der Goot et al., 2021a), which evaluates lexical-normalization systems on 12 social media datasets in 11 languages. We base our solution on a pre-trained byte-level language model, ByT5 (Xue et al., 2021a), which we further pre-train on synthetic data and then fine-tune on authentic normalization data. Our system achieves the best performance by a wide margin in intrinsic evaluation, and also the best performance in extrinsic evaluation through dependency parsing. The source code is released at https://github.com/ufal/multilexnorm2021 and the fine-tuned models at https://huggingface.co/ufal.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>