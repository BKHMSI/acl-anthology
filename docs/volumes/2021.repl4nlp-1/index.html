<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/2021.repl4nlp-1.pdf>Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021)</a></h2><p class=lead><a href=/people/a/anna-rogers/>Anna Rogers</a>,
<a href=/people/i/iacer-calixto/>Iacer Calixto</a>,
<a href=/people/i/ivan-vulic/>Ivan Vulić</a>,
<a href=/people/n/naomi-saphra/>Naomi Saphra</a>,
<a href=/people/n/nora-kassner/>Nora Kassner</a>,
<a href=/people/o/oana-maria-camburu/>Oana-Maria Camburu</a>,
<a href=/people/t/trapit-bansal/>Trapit Bansal</a>,
<a href=/people/v/vered-shwartz/>Vered Shwartz</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2021.repl4nlp-1</dd><dt>Month:</dt><dd>August</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Online</dd><dt>Venues:</dt><dd><a href=/venues/acl/>ACL</a>
| <a href=/venues/ijcnlp/>IJCNLP</a>
| <a href=/venues/repl4nlp/>RepL4NLP</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.repl4nlp-1>https://aclanthology.org/2021.repl4nlp-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2021.repl4nlp-1.pdf>https://aclanthology.org/2021.repl4nlp-1.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2021.repl4nlp-1.pdf title="Open PDF of 'Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021)'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+6th+Workshop+on+Representation+Learning+for+NLP+%28RepL4NLP-2021%29" title="Search for 'Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021)' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.repl4nlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.repl4nlp-1.0/>Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021)</a></strong><br><a href=/people/a/anna-rogers/>Anna Rogers</a>
|
<a href=/people/i/iacer-calixto/>Iacer Calixto</a>
|
<a href=/people/i/ivan-vulic/>Ivan Vulić</a>
|
<a href=/people/n/naomi-saphra/>Naomi Saphra</a>
|
<a href=/people/n/nora-kassner/>Nora Kassner</a>
|
<a href=/people/o/oana-maria-camburu/>Oana-Maria Camburu</a>
|
<a href=/people/t/trapit-bansal/>Trapit Bansal</a>
|
<a href=/people/v/vered-shwartz/>Vered Shwartz</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.repl4nlp-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--repl4nlp-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.repl4nlp-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.repl4nlp-1.1/>Improving Cross-lingual Text Classification with Zero-shot Instance-Weighting</a></strong><br><a href=/people/i/irene-li/>Irene Li</a>
|
<a href=/people/p/prithviraj-sen/>Prithviraj Sen</a>
|
<a href=/people/h/huaiyu-zhu/>Huaiyu Zhu</a>
|
<a href=/people/y/yunyao-li/>Yunyao Li</a>
|
<a href=/people/d/dragomir-radev/>Dragomir Radev</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--repl4nlp-1--1><div class="card-body p-3 small">Cross-lingual text classification (CLTC) is a challenging task made even harder still due to the lack of labeled data in low-resource languages. In this paper, we propose zero-shot instance-weighting, a general model-agnostic zero-shot learning framework for improving CLTC by leveraging source instance weighting. It adds a module on top of pre-trained language models for similarity computation of instance weights, thus aligning each source instance to the target language. During <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training</a>, the framework utilizes <a href=https://en.wikipedia.org/wiki/Gradient_descent>gradient descent</a> that is weighted by instance weights to update parameters. We evaluate this <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> over seven target languages on three fundamental tasks and show its effectiveness and extensibility, by improving on F1 score up to 4 % in single-source transfer and 8 % in multi-source transfer. To the best of our knowledge, our method is the first to apply instance weighting in zero-shot CLTC. It is simple yet effective and easily extensible into multi-source transfer.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.repl4nlp-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--repl4nlp-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.repl4nlp-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.repl4nlp-1.3/>Comprehension Based Question Answering using <a href=https://en.wikipedia.org/wiki/Bloom&#8217;s_taxonomy>Bloom’s Taxonomy</a></a></strong><br><a href=/people/p/pritish-sahu/>Pritish Sahu</a>
|
<a href=/people/m/michael-cogswell/>Michael Cogswell</a>
|
<a href=/people/a/ajay-divakaran/>Ajay Divakaran</a>
|
<a href=/people/s/sara-rutherford-quach/>Sara Rutherford-Quach</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--repl4nlp-1--3><div class="card-body p-3 small">Current pre-trained language models have lots of knowledge, but a more limited ability to use that knowledge. Bloom&#8217;s Taxonomy helps educators teach children how to use knowledge by categorizing comprehension skills, so we use it to analyze and improve the <a href=https://en.wikipedia.org/wiki/Sentence_processing>comprehension skills</a> of large pre-trained language models. Our experiments focus on zero-shot question answering, using the <a href=https://en.wikipedia.org/wiki/Taxonomy_(general)>taxonomy</a> to provide proximal context that helps the model answer questions by being relevant to those questions. We show targeting context in this manner improves performance across 4 popular common sense question answer datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.repl4nlp-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--repl4nlp-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.repl4nlp-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.repl4nlp-1.5" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.repl4nlp-1.5/>Learning Sparse Sentence Encoding without Supervision : An Exploration of Sparsity in Variational Autoencoders</a></strong><br><a href=/people/v/victor-prokhorov/>Victor Prokhorov</a>
|
<a href=/people/y/yingzhen-li/>Yingzhen Li</a>
|
<a href=/people/e/ehsan-shareghi/>Ehsan Shareghi</a>
|
<a href=/people/n/nigel-collier/>Nigel Collier</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--repl4nlp-1--5><div class="card-body p-3 small">It has been long known that sparsity is an effective <a href=https://en.wikipedia.org/wiki/Inductive_bias>inductive bias</a> for learning efficient representation of data in vectors with fixed dimensionality, and it has been explored in many areas of <a href=https://en.wikipedia.org/wiki/Representation_learning>representation learning</a>. Of particular interest to this work is the investigation of the sparsity within the VAE framework which has been explored a lot in the image domain, but has been lacking even a basic level of exploration in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. Additionally, <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> is also lagging behind in terms of learning sparse representations of large units of text e.g., sentences. We use the VAEs that induce sparse latent representations of large units of text to address the aforementioned shortcomings. First, we move in this direction by measuring the success of unsupervised state-of-the-art (SOTA) and other strong VAE-based sparsification baselines for text and propose a hierarchical sparse VAE model to address the stability issue of SOTA. Then, we look at the implications of sparsity on text classification across 3 datasets, and highlight a link between performance of sparse latent representations on downstream tasks and its ability to encode task-related information.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.repl4nlp-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--repl4nlp-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.repl4nlp-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.repl4nlp-1.6" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.repl4nlp-1.6/>Temporal-aware Language Representation Learning From Crowdsourced Labels</a></strong><br><a href=/people/y/yang-hao/>Yang Hao</a>
|
<a href=/people/x/xiao-zhai/>Xiao Zhai</a>
|
<a href=/people/w/wenbiao-ding/>Wenbiao Ding</a>
|
<a href=/people/z/zitao-liu/>Zitao Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--repl4nlp-1--6><div class="card-body p-3 small">Learning effective language representations from crowdsourced labels is crucial for many real-world machine learning tasks. A challenging aspect of this problem is that the quality of crowdsourced labels suffer high intra- and inter-observer variability. Since the high-capacity deep neural networks can easily memorize all disagreements among crowdsourced labels, directly applying existing supervised language representation learning algorithms may yield suboptimal solutions. In this paper, we propose TACMA, a temporal-aware language representation learning heuristic for crowdsourced labels with multiple annotators. The proposed approach (1) explicitly models the intra-observer variability with attention mechanism ; (2) computes and aggregates per-sample confidence scores from multiple workers to address the inter-observer disagreements. The proposed <a href=https://en.wikipedia.org/wiki/Heuristic_(computer_science)>heuristic</a> is extremely easy to implement in around 5 lines of code. The proposed <a href=https://en.wikipedia.org/wiki/Heuristics_in_judgment_and_decision-making>heuristic</a> is evaluated on four synthetic and four real-world data sets. The results show that our approach outperforms a wide range of state-of-the-art <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baselines</a> in terms of <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>prediction accuracy</a> and <a href=https://en.wikipedia.org/wiki/Analysis_of_covariance>AUC</a>. To encourage the reproducible results, we make our code publicly available at.<i>TACMA</i>, a temporal-aware language representation learning heuristic for crowdsourced labels with multiple annotators. The proposed approach (1) explicitly models the intra-observer variability with attention mechanism; (2) computes and aggregates per-sample confidence scores from multiple workers to address the inter-observer disagreements. The proposed heuristic is extremely easy to implement in around 5 lines of code. The proposed heuristic is evaluated on four synthetic and four real-world data sets. The results show that our approach outperforms a wide range of state-of-the-art baselines in terms of prediction accuracy and AUC. To encourage the reproducible results, we make our code publicly available at <url>https://github.com/CrowdsourcingMining/TACMA</url>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.repl4nlp-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--repl4nlp-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.repl4nlp-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.repl4nlp-1.12" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.repl4nlp-1.12/>Knodle : Modular Weakly Supervised Learning with PyTorch<span class=acl-fixed-case>P</span>y<span class=acl-fixed-case>T</span>orch</a></strong><br><a href=/people/a/anastasiia-sedova/>Anastasiia Sedova</a>
|
<a href=/people/a/andreas-stephan/>Andreas Stephan</a>
|
<a href=/people/m/marina-speranskaya/>Marina Speranskaya</a>
|
<a href=/people/b/benjamin-roth/>Benjamin Roth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--repl4nlp-1--12><div class="card-body p-3 small">Strategies for improving the <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training and prediction quality</a> of weakly supervised machine learning models vary in how much they are tailored to a specific task or integrated with a specific model architecture. In this work, we introduce Knodle, a <a href=https://en.wikipedia.org/wiki/Software_framework>software framework</a> that treats weak data annotations, <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning models</a>, and methods for improving weakly supervised training as separate, modular components. This modularization gives the training process access to fine-grained information such as data set characteristics, matches of <a href=https://en.wikipedia.org/wiki/Heuristic_(computer_science)>heuristic rules</a>, or elements of the <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning model</a> ultimately used for prediction. Hence, our framework can encompass a wide range of training methods for improving weak supervision, ranging from methods that only look at correlations of rules and output classes (independently of the <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning model</a> trained with the resulting labels), to those that harness the interplay of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> and weakly labeled data. We illustrate the benchmarking potential of the <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> with a performance comparison of several reference implementations on a selection of datasets that are already available in Knodle.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.repl4nlp-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--repl4nlp-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.repl4nlp-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.repl4nlp-1.16" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.repl4nlp-1.16/>Probing Cross-Modal Representations in Multi-Step Relational Reasoning</a></strong><br><a href=/people/i/iuliia-parfenova/>Iuliia Parfenova</a>
|
<a href=/people/d/desmond-elliott/>Desmond Elliott</a>
|
<a href=/people/r/raquel-fernandez/>Raquel Fernández</a>
|
<a href=/people/s/sandro-pezzelle/>Sandro Pezzelle</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--repl4nlp-1--16><div class="card-body p-3 small">We investigate the <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a> learned by vision and language models in tasks that require relational reasoning. Focusing on the problem of assessing the relative size of objects in abstract visual contexts, we analyse both one-step and two-step reasoning. For the latter, we construct a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of three-image scenes and define a task that requires <a href=https://en.wikipedia.org/wiki/Reason>reasoning</a> at the level of the individual images and across images in a scene. We probe the learned model representations using diagnostic classifiers. Our experiments show that pretrained multimodal transformer-based architectures can perform higher-level relational reasoning, and are able to learn representations for novel tasks and data that are very different from what was seen in pretraining.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.repl4nlp-1.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--repl4nlp-1--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.repl4nlp-1.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.repl4nlp-1.21/>Predicting the Success of <a href=https://en.wikipedia.org/wiki/Domain_adaptation>Domain Adaptation</a> in Text Similarity</a></strong><br><a href=/people/n/nick-pogrebnyakov/>Nick Pogrebnyakov</a>
|
<a href=/people/s/shohreh-shaghaghian/>Shohreh Shaghaghian</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--repl4nlp-1--21><div class="card-body p-3 small">Transfer learning methods, and in particular domain adaptation, help exploit labeled data in one domain to improve the performance of a certain task in another domain. However, it is still not clear what factors affect the success of <a href=https://en.wikipedia.org/wiki/Adaptation_(biology)>domain adaptation</a>. This paper models <a href=https://en.wikipedia.org/wiki/Adaptation>adaptation</a> success and selection of the most suitable source domains among several candidates in <a href=https://en.wikipedia.org/wiki/Similarity_measure>text similarity</a>. We use descriptive domain information and cross-domain similarity metrics as <a href=https://en.wikipedia.org/wiki/Predictive_analytics>predictive features</a>. While mostly positive, the results also point to some domains where <a href=https://en.wikipedia.org/wiki/Adaptation>adaptation</a> success was difficult to predict.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.repl4nlp-1.26.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--repl4nlp-1--26 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.repl4nlp-1.26 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.repl4nlp-1.26/>Deriving Contextualised Semantic Features from BERT (and Other Transformer Model) Embeddings<span class=acl-fixed-case>BERT</span> (and Other Transformer Model) Embeddings</a></strong><br><a href=/people/j/jacob-turton/>Jacob Turton</a>
|
<a href=/people/r/robert-elliott-smith/>Robert Elliott Smith</a>
|
<a href=/people/d/david-vinson/>David Vinson</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--repl4nlp-1--26><div class="card-body p-3 small">Models based on the transformer architecture, such as BERT, have marked a crucial step forward in the field of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a>. Importantly, they allow the creation of <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> that capture important semantic information about words in context. However, as single entities, these <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> are difficult to interpret and the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> used to create them have been described as opaque. Binder and colleagues proposed an intuitive embedding space where each dimension is based on one of 65 core semantic features. Unfortunately, the <a href=https://en.wikipedia.org/wiki/Space_(mathematics)>space</a> only exists for a small data-set of 535 words, limiting its uses. Previous work (Utsumi, 2018, 2020 ; Turton et al., 2020) has shown that Binder features can be derived from static embeddings and successfully extrapolated to a large new vocabulary. Taking the next step, this paper demonstrates that Binder features can be derived from the BERT embedding space. This provides two things ; (1) semantic feature values derived from contextualised word embeddings and (2) insights into how semantic features are represented across the different layers of the BERT model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.repl4nlp-1.29.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--repl4nlp-1--29 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.repl4nlp-1.29 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.repl4nlp-1.29/>An Overview of Uncertainty Calibration for <a href=https://en.wikipedia.org/wiki/Text_classification>Text Classification</a> and the Role of Distillation</a></strong><br><a href=/people/h/han-guo/>Han Guo</a>
|
<a href=/people/r/ramakanth-pasunuru/>Ramakanth Pasunuru</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--repl4nlp-1--29><div class="card-body p-3 small">Recent advances in NLP systems, notably the pretraining-and-finetuning paradigm, have achieved great success in predictive accuracy. However, these <a href=https://en.wikipedia.org/wiki/System>systems</a> are usually not well calibrated for uncertainty out-of-the-box. Many recalibration methods have been proposed in the literature for quantifying predictive uncertainty and calibrating model outputs, with varying degrees of <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a>. In this work, we present a systematic study of a few of these <a href=https://en.wikipedia.org/wiki/Methodology>methods</a>. Focusing on the text classification task and finetuned large pretrained language models, we first show that many of the finetuned models are not well calibrated out-of-the-box, especially when the data come from out-of-domain settings. Next, we compare the effectiveness of a few widely-used recalibration methods (such as <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensembles</a>, temperature scaling). Then, we empirically illustrate a connection between <a href=https://en.wikipedia.org/wiki/Distillation>distillation</a> and <a href=https://en.wikipedia.org/wiki/Calibration>calibration</a>. We view <a href=https://en.wikipedia.org/wiki/Distillation>distillation</a> as a regularization term encouraging the student model to output uncertainties that match those of a teacher model. With this insight, we develop simple recalibration methods based on <a href=https://en.wikipedia.org/wiki/Distillation>distillation</a> with no additional inference-time cost. We show on the GLUE benchmark that our simple methods can achieve competitive out-of-domain (OOD) calibration performance w.r.t. more expensive approaches. Finally, we include <a href=https://en.wikipedia.org/wiki/Ablation>ablations</a> to understand the usefulness of components of our proposed method and examine the transferability of <a href=https://en.wikipedia.org/wiki/Calibration>calibration</a> via <a href=https://en.wikipedia.org/wiki/Distillation>distillation</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.repl4nlp-1.32.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--repl4nlp-1--32 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.repl4nlp-1.32 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.repl4nlp-1.32" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.repl4nlp-1.32/>Direction is what you need : Improving Word Embedding Compression in Large Language Models</a></strong><br><a href=/people/k/klaudia-balazy/>Klaudia Bałazy</a>
|
<a href=/people/m/mohammadreza-banaei/>Mohammadreza Banaei</a>
|
<a href=/people/r/remi-lebret/>Rémi Lebret</a>
|
<a href=/people/j/jacek-tabor/>Jacek Tabor</a>
|
<a href=/people/k/karl-aberer/>Karl Aberer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--repl4nlp-1--32><div class="card-body p-3 small">The adoption of Transformer-based models in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP)</a> has led to great success using a massive number of parameters. However, due to deployment constraints in <a href=https://en.wikipedia.org/wiki/Edge_device>edge devices</a>, there has been a rising interest in the <a href=https://en.wikipedia.org/wiki/Data_compression>compression</a> of these models to improve their inference time and memory footprint. This paper presents a novel loss objective to compress token embeddings in the Transformer-based models by leveraging an AutoEncoder architecture. More specifically, we emphasize the importance of the direction of compressed embeddings with respect to original uncompressed embeddings. The proposed method is task-agnostic and does not require further language modeling pre-training. Our method significantly outperforms the commonly used SVD-based matrix-factorization approach in terms of initial language model Perplexity. Moreover, we evaluate our proposed approach over SQuAD v1.1 dataset and several downstream tasks from the GLUE benchmark, where we also outperform the baseline in most scenarios. Our code is public.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>