<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the First Workshop on Commonsense Inference in Natural Language Processing - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/D19-60.pdf>Proceedings of the First Workshop on Commonsense Inference in Natural Language Processing</a></h2><p class=lead><a href=/people/s/simon-ostermann/>Simon Ostermann</a>,
<a href=/people/s/sheng-zhang/>Sheng Zhang</a>,
<a href=/people/m/michael-roth/>Michael Roth</a>,
<a href=/people/p/peter-clark/>Peter Clark</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>D19-60</dd><dt>Month:</dt><dd>November</dd><dt>Year:</dt><dd>2019</dd><dt>Address:</dt><dd>Hong Kong, China</dd><dt>Venues:</dt><dd><a href=/venues/emnlp/>EMNLP</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/D19-60>https://aclanthology.org/D19-60</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/D19-60.pdf>https://aclanthology.org/D19-60.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/D19-60.pdf title="Open PDF of 'Proceedings of the First Workshop on Commonsense Inference in Natural Language Processing'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+First+Workshop+on+Commonsense+Inference+in+Natural+Language+Processing" title="Search for 'Proceedings of the First Workshop on Commonsense Inference in Natural Language Processing' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-6000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-6000/>Proceedings of the First Workshop on Commonsense Inference in Natural Language Processing</a></strong><br><a href=/people/s/simon-ostermann/>Simon Ostermann</a>
|
<a href=/people/s/sheng-zhang/>Sheng Zhang</a>
|
<a href=/people/m/michael-roth/>Michael Roth</a>
|
<a href=/people/p/peter-clark/>Peter Clark</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-6001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-6001 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-6001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-6001/>Cracking the Contextual Commonsense Code : Understanding Commonsense Reasoning Aptitude of Deep Contextual Representations</a></strong><br><a href=/people/j/jeff-da/>Jeff Da</a>
|
<a href=/people/j/jungo-kasai/>Jungo Kasai</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-6001><div class="card-body p-3 small">Pretrained deep contextual representations have advanced the state-of-the-art on various commonsense NLP tasks, but we lack a concrete understanding of the capability of these models. Thus, we investigate and challenge several aspects of BERT&#8217;s commonsense representation abilities. First, we probe BERT&#8217;s ability to classify various object attributes, demonstrating that BERT shows a strong ability in encoding various commonsense features in its embedding space, but is still deficient in many areas. Next, we show that, by augmenting BERT&#8217;s pretraining data with additional data related to the deficient attributes, we are able to improve performance on a downstream commonsense reasoning task while using a minimal amount of data. Finally, we develop a method of fine-tuning knowledge graphs embeddings alongside BERT and show the continued importance of explicit knowledge graphs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-6003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-6003 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-6003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-6003/>Towards Generalizable Neuro-Symbolic Systems for Commonsense Question Answering</a></strong><br><a href=/people/k/kaixin-ma/>Kaixin Ma</a>
|
<a href=/people/j/jonathan-francis/>Jonathan Francis</a>
|
<a href=/people/q/quanyang-lu/>Quanyang Lu</a>
|
<a href=/people/e/eric-nyberg/>Eric Nyberg</a>
|
<a href=/people/a/alessandro-oltramari/>Alessandro Oltramari</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-6003><div class="card-body p-3 small">Non-extractive commonsense QA remains a challenging AI task, as it requires systems to reason about, synthesize, and gather disparate pieces of information, in order to generate responses to queries. Recent approaches on such tasks show increased performance, only when <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are either pre-trained with additional information or when domain-specific heuristics are used, without any special consideration regarding the knowledge resource type. In this paper, we perform a survey of recent commonsense QA methods and we provide a systematic analysis of popular knowledge resources and knowledge-integration methods, across benchmarks from multiple commonsense datasets. Our results and analysis show that attention-based injection seems to be a preferable choice for <a href=https://en.wikipedia.org/wiki/Knowledge_integration>knowledge integration</a> and that the degree of domain overlap, between <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge bases</a> and <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, plays a crucial role in determining model success.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-6005.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-6005 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-6005 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-6005/>Commonsense about Human Senses : Labeled Data Collection Processes</a></strong><br><a href=/people/n/ndapandula-nakashole/>Ndapa Nakashole</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-6005><div class="card-body p-3 small">We consider the problem of extracting from text commonsense knowledge pertaining to <a href=https://en.wikipedia.org/wiki/Sense>human senses</a> such as sound and smell. First, we consider the problem of recognizing mentions of human senses in text. Our contribution is a <a href=https://en.wikipedia.org/wiki/Methodology>method</a> for acquiring <a href=https://en.wikipedia.org/wiki/Labeled_data>labeled data</a>. Experiments show the effectiveness of our proposed data labeling approach when used with standard <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning models</a> on the task of sense recognition in text. Second, we propose to extract novel, common sense relationships pertaining to sense perception concepts. Our contribution is a process for generating <a href=https://en.wikipedia.org/wiki/Labeled_data>labeled data</a> by leveraging large corpora and <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing questionnaires</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-6009.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-6009 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-6009 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-6009/>IIT-KGP at COIN 2019 : Using pre-trained Language Models for modeling Machine Comprehension<span class=acl-fixed-case>IIT</span>-<span class=acl-fixed-case>KGP</span> at <span class=acl-fixed-case>COIN</span> 2019: Using pre-trained Language Models for modeling Machine Comprehension</a></strong><br><a href=/people/p/prakhar-sharma/>Prakhar Sharma</a>
|
<a href=/people/s/sumegh-roychowdhury/>Sumegh Roychowdhury</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-6009><div class="card-body p-3 small">In this paper, we describe our <a href=https://en.wikipedia.org/wiki/System>system</a> for COIN 2019 Shared Task 1 : Commonsense Inference in Everyday Narrations. We show the power of leveraging state-of-the-art pre-trained language models such as BERT(Bidirectional Encoder Representations from Transformers) and XLNet over other Commonsense Knowledge Base Resources such as ConceptNet and NELL for modeling machine comprehension. We used an ensemble of BERT-Large and XLNet-Large. Experimental results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> give substantial improvements over the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> and other <a href=https://en.wikipedia.org/wiki/System>systems</a> incorporating <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge bases</a>. We bagged 2nd position on the final test set leaderboard with an accuracy of 90.5 %</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-6011.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-6011 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-6011 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-6011/>Pingan Smart Health and SJTU at COIN-Shared Task : utilizing Pre-trained Language Models and Common-sense Knowledge in Machine Reading Tasks<span class=acl-fixed-case>SJTU</span> at <span class=acl-fixed-case>COIN</span> - Shared Task: utilizing Pre-trained Language Models and Common-sense Knowledge in Machine Reading Tasks</a></strong><br><a href=/people/x/xiepeng-li/>Xiepeng Li</a>
|
<a href=/people/z/zhexi-zhang/>Zhexi Zhang</a>
|
<a href=/people/w/wei-zhu/>Wei Zhu</a>
|
<a href=/people/z/zheng-li/>Zheng Li</a>
|
<a href=/people/y/yuan-ni/>Yuan Ni</a>
|
<a href=/people/p/peng-gao/>Peng Gao</a>
|
<a href=/people/j/junchi-yan/>Junchi Yan</a>
|
<a href=/people/g/guotong-xie/>Guotong Xie</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-6011><div class="card-body p-3 small">To solve the shared tasks of COIN : COmmonsense INference in Natural Language Processing) Workshop in, we need explore the impact of <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>knowledge representation</a> in modeling commonsense knowledge to boost performance of machine reading comprehension beyond simple text matching. There are two approaches to represent knowledge in the low-dimensional space. The <a href=https://en.wikipedia.org/wiki/First_law_of_thermodynamics>first</a> is to leverage large-scale unsupervised text corpus to train fixed or contextual language representations. The second approach is to explicitly express knowledge into a knowledge graph (KG), and then fit a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to represent the facts in the KG. We have experimented both (a) improving the fine-tuning of pre-trained language models on a task with a small dataset size, by leveraging datasets of similar tasks ; and (b) incorporating the distributional representations of a KG onto the representations of pre-trained language models, via simply <a href=https://en.wikipedia.org/wiki/Concatenation>concatenation</a> or multi-head attention. We find out that : (a) for task 1, first fine-tuning on larger datasets like RACE (Lai et al., 2017) and SWAG (Zellersetal.,2018), and then fine-tuning on the target task improve the performance significantly ; (b) for task 2, we find out the incorporating a KG of commonsense knowledge, WordNet (Miller, 1995) into the Bert model (Devlin et al., 2018) is helpful, however, it will hurts the performace of XLNET (Yangetal.,2019), a more powerful pre-trained model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-6012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-6012 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-6012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-6012/>BLCU-NLP at COIN-Shared Task1 : Stagewise Fine-tuning BERT for Commonsense Inference in Everyday Narrations<span class=acl-fixed-case>BLCU</span>-<span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>COIN</span>-Shared Task1: Stagewise Fine-tuning <span class=acl-fixed-case>BERT</span> for Commonsense Inference in Everyday Narrations</a></strong><br><a href=/people/c/chunhua-liu/>Chunhua Liu</a>
|
<a href=/people/d/dong-yu/>Dong Yu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-6012><div class="card-body p-3 small">This paper describes our <a href=https://en.wikipedia.org/wiki/System>system</a> for COIN Shared Task 1 : Commonsense Inference in Everyday Narrations. To inject more external knowledge to better reason over the narrative passage, question and answer, the <a href=https://en.wikipedia.org/wiki/System>system</a> adopts a stagewise fine-tuning method based on pre-trained BERT model. More specifically, the first stage is to fine-tune on addi- tional machine reading comprehension dataset to learn more <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a>. The second stage is to fine-tune on target-task (MCScript2.0) with MCScript (2018) dataset assisted. Experimental results show that our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves significant improvements over the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline systems</a> with 84.2 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on the official test dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-6014.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-6014 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-6014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-6014/>Diversity-aware Event Prediction based on a Conditional Variational Autoencoder with Reconstruction</a></strong><br><a href=/people/h/hirokazu-kiyomaru/>Hirokazu Kiyomaru</a>
|
<a href=/people/k/kazumasa-omura/>Kazumasa Omura</a>
|
<a href=/people/y/yugo-murawaki/>Yugo Murawaki</a>
|
<a href=/people/d/daisuke-kawahara/>Daisuke Kawahara</a>
|
<a href=/people/s/sadao-kurohashi/>Sadao Kurohashi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-6014><div class="card-body p-3 small">Typical event sequences are an important class of <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a>. Formalizing the task as the generation of a next event conditioned on a current event, previous work in event prediction employs sequence-to-sequence (seq2seq) models. However, what can happen after a given event is usually diverse, a fact that can hardly be captured by deterministic models. In this paper, we propose to incorporate a conditional variational autoencoder (CVAE) into seq2seq for its ability to represent diverse next events as a probabilistic distribution. We further extend the CVAE-based seq2seq with a reconstruction mechanism to prevent the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> from concentrating on highly typical events. To facilitate fair and systematic evaluation of the diversity-aware models, we also extend existing evaluation datasets by tying each current event to multiple next events. Experiments show that the CVAE-based models drastically outperform deterministic models in terms of <a href=https://en.wikipedia.org/wiki/Precision_(statistics)>precision</a> and that the reconstruction mechanism improves the <a href=https://en.wikipedia.org/wiki/Precision_(statistics)>recall</a> of CVAE-based models without sacrificing <a href=https://en.wikipedia.org/wiki/Precision_(statistics)>precision</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/D19-6015.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-D19-6015 data-toggle=collapse aria-expanded=false aria-controls=abstract-D19-6015 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/D19-6015/>Can a Gorilla Ride a Camel? Learning Semantic Plausibility from Text</a></strong><br><a href=/people/i/ian-porada/>Ian Porada</a>
|
<a href=/people/k/kaheer-suleman/>Kaheer Suleman</a>
|
<a href=/people/j/jackie-chi-kit-cheung/>Jackie Chi Kit Cheung</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-D19-6015><div class="card-body p-3 small">Modeling semantic plausibility requires <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a> about the world and has been used as a testbed for exploring various <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>knowledge representations</a>. Previous work has focused specifically on modeling physical plausibility and shown that <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>distributional methods</a> fail when tested in a <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised setting</a>. At the same time, distributional models, namely large pretrained language models, have led to improved results for many natural language understanding tasks. In this work, we show that these pretrained language models are in fact effective at modeling physical plausibility in the <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised setting</a>. We therefore present the more difficult problem of learning to model physical plausibility directly from text. We create a training set by extracting <a href=https://en.wikipedia.org/wiki/Event_(probability_theory)>attested events</a> from a large corpus, and we provide a baseline for training on these <a href=https://en.wikipedia.org/wiki/Event_(probability_theory)>attested events</a> in a self-supervised manner and testing on a physical plausibility task. We believe results could be further improved by injecting explicit <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a> into a <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>distributional model</a>.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>