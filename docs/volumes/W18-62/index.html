<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/W18-62.pdf>Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</a></h2><p class=lead><a href=/people/a/alexandra-balahur/>Alexandra Balahur</a>,
<a href=/people/s/saif-mohammad/>Saif M. Mohammad</a>,
<a href=/people/v/veronique-hoste/>Veronique Hoste</a>,
<a href=/people/r/roman-klinger/>Roman Klinger</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>W18-62</dd><dt>Month:</dt><dd>October</dd><dt>Year:</dt><dd>2018</dd><dt>Address:</dt><dd>Brussels, Belgium</dd><dt>Venues:</dt><dd><a href=/venues/emnlp/>EMNLP</a>
| <a href=/venues/wassa/>WASSA</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/W18-62>https://aclanthology.org/W18-62</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/W18-62.pdf>https://aclanthology.org/W18-62.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/W18-62.pdf title="Open PDF of 'Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+9th+Workshop+on+Computational+Approaches+to+Subjectivity%2C+Sentiment+and+Social+Media+Analysis" title="Search for 'Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6200.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6200/>Proceedings of the 9th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</a></strong><br><a href=/people/a/alexandra-balahur/>Alexandra Balahur</a>
|
<a href=/people/s/saif-mohammad/>Saif M. Mohammad</a>
|
<a href=/people/v/veronique-hoste/>Veronique Hoste</a>
|
<a href=/people/r/roman-klinger/>Roman Klinger</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6201.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6201 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6201 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6201/>Identifying Affective Events and the Reasons for their Polarity</a></strong><br><a href=/people/e/ellen-riloff/>Ellen Riloff</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6201><div class="card-body p-3 small">Many events have a positive or negative impact on our lives (e.g., I bought a house is typically good news, but My house burned down is bad news). Recognizing events that have affective polarity is essential for narrative text understanding, conversational dialogue, and applications such as <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> and sarcasm detection. We will discuss our recent work on identifying <a href=https://en.wikipedia.org/wiki/Affect_(psychology)>affective events</a> and categorizing them based on the underlying reasons for their <a href=https://en.wikipedia.org/wiki/Affect_(psychology)>affective polarity</a>. First, we will describe a weakly supervised learning method to induce a large set of <a href=https://en.wikipedia.org/wiki/Event_(philosophy)>affective events</a> from a <a href=https://en.wikipedia.org/wiki/Text_corpus>text corpus</a> by optimizing for semantic consistency. Second, we will present models to classify affective events based on Human Need Categories, which often explain people&#8217;s motivations and desires. Our best results use a co-training model that consists of event expression and event context classifiers and exploits both labeled and unlabeled texts. We will conclude with a discussion of interesting directions for future work in this area.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6202.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6202 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6202 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W18-6202" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W18-6202/>Deep contextualized word representations for detecting sarcasm and irony</a></strong><br><a href=/people/s/suzana-ilic/>Suzana IliÄ‡</a>
|
<a href=/people/e/edison-marrese-taylor/>Edison Marrese-Taylor</a>
|
<a href=/people/j/jorge-balazs/>Jorge Balazs</a>
|
<a href=/people/y/yutaka-matsuo/>Yutaka Matsuo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6202><div class="card-body p-3 small">Predicting context-dependent and non-literal utterances like sarcastic and ironic expressions still remains a challenging task in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, as it goes beyond linguistic patterns, encompassing <a href=https://en.wikipedia.org/wiki/Common_sense>common sense</a> and shared knowledge as crucial components. To capture complex morpho-syntactic features that can usually serve as indicators for <a href=https://en.wikipedia.org/wiki/Irony>irony</a> or <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> across dynamic contexts, we propose a model that uses character-level vector representations of words, based on ELMo. We test our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on 7 different datasets derived from 3 different data sources, providing state-of-the-art performance in 6 of them, and otherwise offering competitive results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6203.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6203 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6203 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6203/>Implicit Subjective and Sentimental Usages in Multi-sense Word Embeddings</a></strong><br><a href=/people/y/yuqi-sun/>Yuqi Sun</a>
|
<a href=/people/h/haoyue-shi/>Haoyue Shi</a>
|
<a href=/people/j/junfeng-hu/>Junfeng Hu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6203><div class="card-body p-3 small">In multi-sense word embeddings, contextual variations in corpus may cause a univocal word to be embedded into different sense vectors. Shi et al. (2016) show that this kind of pseudo multi-senses can be eliminated by <a href=https://en.wikipedia.org/wiki/Linear_map>linear transformations</a>. In this paper, we show that pseudo multi-senses may come from a uniform and meaningful phenomenon such as subjective and sentimental usage, though they are seemingly redundant. In this paper, we present an unsupervised algorithm to find a <a href=https://en.wikipedia.org/wiki/Linear_map>linear transformation</a> which can minimize the transformed distance of a group of sense pairs. The major shrinking direction of this transformation is found to be related with subjective shift. Therefore, we can not only eliminate pseudo multi-senses in multisense embeddings, but also identify these subjective senses and tag the subjective and sentimental usage of words in the corpus automatically.<i>pseudo multi-senses</i> can be eliminated by linear transformations. In this paper, we show that <i>pseudo multi-senses</i> may come from a uniform and meaningful phenomenon such as subjective and sentimental usage, though they are seemingly redundant. In this paper, we present an unsupervised algorithm to find a linear transformation which can minimize the transformed distance of a group of sense pairs. The major shrinking direction of this transformation is found to be related with subjective shift. Therefore, we can not only eliminate <i>pseudo multi-senses</i> in multisense embeddings, but also identify these subjective senses and tag the subjective and sentimental usage of words in the corpus automatically.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6207.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6207 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6207 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6207/>Amobee at IEST 2018 : Transfer Learning from Language Models<span class=acl-fixed-case>A</span>mobee at <span class=acl-fixed-case>IEST</span> 2018: Transfer Learning from Language Models</a></strong><br><a href=/people/a/alon-rozental/>Alon Rozental</a>
|
<a href=/people/d/daniel-fleischer/>Daniel Fleischer</a>
|
<a href=/people/z/zohar-kelrich/>Zohar Kelrich</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6207><div class="card-body p-3 small">This paper describes the <a href=https://en.wikipedia.org/wiki/System>system</a> developed at Amobee for the WASSA 2018 implicit emotions shared task (IEST). The goal of this task was to predict the <a href=https://en.wikipedia.org/wiki/Emotion>emotion</a> expressed by missing words in tweets without an explicit mention of those words. We developed an <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensemble system</a> consisting of <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> together with LSTM-based networks containing a CNN attention mechanism. Our approach represents a novel use of language modelsspecifically trained on a large Twitter datasetto predict and classify <a href=https://en.wikipedia.org/wiki/Emotion>emotions</a>. Our <a href=https://en.wikipedia.org/wiki/System>system</a> reached 1st place with a macro F1 score of 0.7145.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6208.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6208 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6208 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W18-6208" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W18-6208/>IIIDYT at IEST 2018 : Implicit Emotion Classification With Deep Contextualized Word Representations<span class=acl-fixed-case>IIIDYT</span> at <span class=acl-fixed-case>IEST</span> 2018: Implicit Emotion Classification With Deep Contextualized Word Representations</a></strong><br><a href=/people/j/jorge-balazs/>Jorge Balazs</a>
|
<a href=/people/e/edison-marrese-taylor/>Edison Marrese-Taylor</a>
|
<a href=/people/y/yutaka-matsuo/>Yutaka Matsuo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6208><div class="card-body p-3 small">In this paper we describe our <a href=https://en.wikipedia.org/wiki/System>system</a> designed for the WASSA 2018 Implicit Emotion Shared Task (IEST), which obtained 2nd place out of 30 teams with a test macro F1 score of 0.710. The system is composed of a single pre-trained ELMo layer for encoding words, a Bidirectional Long-Short Memory Network BiLSTM for enriching word representations with context, a max-pooling operation for creating sentence representations from them, and a Dense Layer for projecting the sentence representations into label space. Our official submission was obtained by ensembling 6 of these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> initialized with different <a href=https://en.wikipedia.org/wiki/Random_seed>random seeds</a>. The code for replicating this paper is available at.<url>https://github.com/jabalazs/implicit_emotion</url>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6211.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6211 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6211 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6211/>Not Just Depressed : Bipolar Disorder Prediction on Reddit<span class=acl-fixed-case>R</span>eddit</a></strong><br><a href=/people/i/ivan-sekulic/>Ivan Sekulic</a>
|
<a href=/people/m/matej-gjurkovic/>Matej GjurkoviÄ‡</a>
|
<a href=/people/j/jan-snajder/>Jan Å najder</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6211><div class="card-body p-3 small">Bipolar disorder, an illness characterized by <a href=https://en.wikipedia.org/wiki/Bipolar_disorder>manic and depressive episodes</a>, affects more than 60 million people worldwide. We present a preliminary study on bipolar disorder prediction from <a href=https://en.wikipedia.org/wiki/User-generated_content>user-generated text</a> on <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a>, which relies on users&#8217; self-reported labels. Our benchmark classifiers for bipolar disorder prediction outperform the baselines and reach <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and F1-scores of above 86 %. Feature analysis shows interesting differences in language use between users with <a href=https://en.wikipedia.org/wiki/Bipolar_disorder>bipolar disorders</a> and the <a href=https://en.wikipedia.org/wiki/Treatment_and_control_groups>control group</a>, including differences in the use of emotion-expressive words.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6212.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6212 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6212 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6212/>Topic-Specific Sentiment Analysis Can Help Identify Political Ideology</a></strong><br><a href=/people/s/sumit-bhatia/>Sumit Bhatia</a>
|
<a href=/people/d/deepak-p/>Deepak P</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6212><div class="card-body p-3 small">Ideological leanings of an individual can often be gauged by the sentiment one expresses about different issues. We propose a simple <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> that represents a <a href=https://en.wikipedia.org/wiki/Ideology>political ideology</a> as a distribution of sentiment polarities towards a set of topics. This <a href=https://en.wikipedia.org/wiki/Representation_(arts)>representation</a> can then be used to detect ideological leanings of documents (speeches, <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a>, etc.) based on the sentiments expressed towards different topics. Experiments performed using a widely used dataset show the promise of our proposed approach that achieves comparable performance to other methods despite being much simpler and more interpretable.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6213.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6213 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6213 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6213/>Saying no but meaning yes : negation and <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> in Basque<span class=acl-fixed-case>B</span>asque</a></strong><br><a href=/people/j/jon-alkorta/>Jon Alkorta</a>
|
<a href=/people/k/koldo-gojenola/>Koldo Gojenola</a>
|
<a href=/people/m/mikel-iruskieta/>Mikel Iruskieta</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6213><div class="card-body p-3 small">In this work, we have analyzed the effects of <a href=https://en.wikipedia.org/wiki/Affirmation_and_negation>negation</a> on the semantic orientation in <a href=https://en.wikipedia.org/wiki/Basque_language>Basque</a>. The analysis shows that negation markers can strengthen, weaken or have no effect on sentiment orientation of a word or a group of words. Using the Constraint Grammar formalism, we have designed and evaluated a set of <a href=https://en.wikipedia.org/wiki/Rule_of_inference>linguistic rules</a> to formalize these three <a href=https://en.wikipedia.org/wiki/Phenomenon>phenomena</a>. The results show that two <a href=https://en.wikipedia.org/wiki/Phenomenon>phenomena</a>, strengthening and no change, have been identified accurately and the third one, weakening, with acceptable results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6214.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6214 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6214 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6214/>Leveraging Writing Systems Change for Deep Learning Based Chinese Emotion Analysis<span class=acl-fixed-case>C</span>hinese Emotion Analysis</a></strong><br><a href=/people/r/rong-xiang/>Rong Xiang</a>
|
<a href=/people/y/yunfei-long/>Yunfei Long</a>
|
<a href=/people/q/qin-lu/>Qin Lu</a>
|
<a href=/people/d/dan-xiong/>Dan Xiong</a>
|
<a href=/people/i/i-hsuan-chen/>I-Hsuan Chen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6214><div class="card-body p-3 small">Social media text written in <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese communities</a> contains mixed scripts including major text written in <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>, an ideograph-based writing system, and some minor text using <a href=https://en.wikipedia.org/wiki/Latin_script>Latin letters</a>, an alphabet-based writing system. This phenomenon is called writing systems changes (WSCs). Past studies have shown that WSCs can be used to express emotions, particularly where the social and political environment is more conservative. However, because WSCs can break the <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a> of the major text, it poses more challenges in Natural Language Processing (NLP) tasks like <a href=https://en.wikipedia.org/wiki/Emotion_classification>emotion classification</a>. In this work, we present a novel deep learning based method to include WSCs as an effective <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature</a> for emotion analysis. The method first identifies all WSCs points. Then representation of the major text is learned through an LSTM model whereas the minor text is learned by a separate CNN model. Emotions in the minor text are further highlighted through an <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanism</a> before <a href=https://en.wikipedia.org/wiki/Emotion_classification>emotion classification</a>. Performance evaluation shows that incorporating WSCs features using deep learning models can improve performance measured by F1-scores compared to the state-of-the-art model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6215.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6215 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6215 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6215/>Ternary Twitter Sentiment Classification with Distant Supervision and Sentiment-Specific Word Embeddings<span class=acl-fixed-case>T</span>witter Sentiment Classification with Distant Supervision and Sentiment-Specific Word Embeddings</a></strong><br><a href=/people/m/mats-byrkjeland/>Mats Byrkjeland</a>
|
<a href=/people/f/frederik-gorvell-de-lichtenberg/>Frederik GÃ¸rvell de Lichtenberg</a>
|
<a href=/people/b/bjorn-gamback/>BjÃ¶rn GambÃ¤ck</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6215><div class="card-body p-3 small">The paper proposes the Ternary Sentiment Embedding Model, a new model for creating sentiment embeddings based on the Hybrid Ranking Model of Tang et al. (2016), but trained on ternary-labeled data instead of binary-labeled, utilizing sentiment embeddings from datasets made with different distant supervision methods. The model is used as part of a complete Twitter Sentiment Analysis system and empirically compared to existing systems, showing that it outperforms Hybrid Ranking and that the quality of the distant-supervised dataset has a great impact on the quality of the produced sentiment embeddings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6216.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6216 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6216 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6216/>Linking News Sentiment to <a href=https://en.wikipedia.org/wiki/Microblogging>Microblogs</a> : A Distributional Semantics Approach to Enhance Microblog Sentiment Classification</a></strong><br><a href=/people/t/tobias-daudert/>Tobias Daudert</a>
|
<a href=/people/p/paul-buitelaar/>Paul Buitelaar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6216><div class="card-body p-3 small">Social media&#8217;s popularity in society and research is gaining momentum and simultaneously increasing the importance of short textual content such as <a href=https://en.wikipedia.org/wiki/Microblogging>microblogs</a>. Microblogs are affected by many factors including the <a href=https://en.wikipedia.org/wiki/News_media>news media</a>, therefore, we exploit sentiments conveyed from news to detect and classify sentiment in <a href=https://en.wikipedia.org/wiki/Microblogging>microblogs</a>. Given that texts can deal with the same entity but might not be vastly related when it comes to <a href=https://en.wikipedia.org/wiki/Sentimentality>sentiment</a>, it becomes necessary to introduce further measures ensuring the relatedness of texts while leveraging the contained sentiments. This paper describes ongoing research introducing <a href=https://en.wikipedia.org/wiki/Distributional_semantics>distributional semantics</a> to improve the exploitation of news-contained sentiment to enhance microblog sentiment classification.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6217.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6217 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6217 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6217/>Aspect Based Sentiment Analysis into the Wild</a></strong><br><a href=/people/c/caroline-brun/>Caroline Brun</a>
|
<a href=/people/v/vassilina-nikoulina/>Vassilina Nikoulina</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6217><div class="card-body p-3 small">In this paper, we test state-of-the-art Aspect Based Sentiment Analysis (ABSA) systems trained on a widely used dataset on actual data. We created a new manually annotated dataset of user generated data from the same domain as the training dataset, but from other sources and analyse the differences between the new and the standard ABSA dataset. We then analyse the results in performance of different versions of the same <a href=https://en.wikipedia.org/wiki/System>system</a> on both datasets. We also propose light adaptation methods to increase system robustness.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6219.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6219 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6219 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W18-6219" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W18-6219/>Self-Attention : A Better Building Block for Sentiment Analysis Neural Network Classifiers</a></strong><br><a href=/people/a/artaches-ambartsoumian/>Artaches Ambartsoumian</a>
|
<a href=/people/f/fred-popowich/>Fred Popowich</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6219><div class="card-body p-3 small">Sentiment Analysis has seen much progress in the past two decades. For the past few years, neural network approaches, primarily RNNs and CNNs, have been the most successful for this task. Recently, a new category of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>, self-attention networks (SANs), have been created which utilizes the <a href=https://en.wikipedia.org/wiki/Attention>attention mechanism</a> as the basic building block. Self-attention networks have been shown to be effective for sequence modeling tasks, while having no <a href=https://en.wikipedia.org/wiki/Recurrence_relation>recurrence</a> or <a href=https://en.wikipedia.org/wiki/Convolution>convolutions</a>. In this work we explore the effectiveness of the <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>SANs</a> for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>. We demonstrate that SANs are superior in performance to their RNN and CNN counterparts by comparing their classification accuracy on six datasets as well as their model characteristics such as training speed and memory consumption. Finally, we explore the effects of various SAN modifications such as multi-head attention as well as two methods of incorporating sequence position information into SANs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6220.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6220 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6220 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6220/>Dual Memory Network Model for Biased Product Review Classification</a></strong><br><a href=/people/y/yunfei-long/>Yunfei Long</a>
|
<a href=/people/m/mingyu-ma/>Mingyu Ma</a>
|
<a href=/people/q/qin-lu/>Qin Lu</a>
|
<a href=/people/r/rong-xiang/>Rong Xiang</a>
|
<a href=/people/c/chu-ren-huang/>Chu-Ren Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6220><div class="card-body p-3 small">In sentiment analysis (SA) of product reviews, both user and product information are proven to be useful. Current tasks handle <a href=https://en.wikipedia.org/wiki/User_profile>user profile</a> and product information in a unified model which may not be able to learn salient features of users and products effectively. In this work, we propose a dual user and product memory network (DUPMN) model to learn user profiles and product reviews using separate memory networks. Then, the two <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representations</a> are used jointly for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment prediction</a>. The use of separate <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> aims to capture <a href=https://en.wikipedia.org/wiki/User_profile>user profiles</a> and <a href=https://en.wikipedia.org/wiki/Product_information>product information</a> more effectively. Compared to state-of-the-art unified prediction models, the evaluations on three benchmark datasets, <a href=https://en.wikipedia.org/wiki/Internet_Movie_Database>IMDB</a>, Yelp13, and Yelp14, show that our dual learning model gives performance gain of 0.6 %, 1.2 %, and 0.9 %, respectively. The improvements are also deemed very significant measured by <a href=https://en.wikipedia.org/wiki/P-value>p-values</a>.<i>p-values</i>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6221.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6221 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6221 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6221/>Measuring Issue Ownership using Word Embeddings</a></strong><br><a href=/people/a/amaru-cuba-gyllensten/>Amaru Cuba Gyllensten</a>
|
<a href=/people/m/magnus-sahlgren/>Magnus Sahlgren</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6221><div class="card-body p-3 small">Sentiment and topic analysis are common methods used for <a href=https://en.wikipedia.org/wiki/Social_media_monitoring>social media monitoring</a>. Essentially, these methods answers questions such as, what is being talked about, regarding X, and what do people feel, regarding X. In this paper, we investigate another venue for <a href=https://en.wikipedia.org/wiki/Social_media_monitoring>social media monitoring</a>, namely issue ownership and <a href=https://en.wikipedia.org/wiki/Agenda_setting>agenda setting</a>, which are concepts from <a href=https://en.wikipedia.org/wiki/Political_science>political science</a> that have been used to explain voter choice and electoral outcomes. We argue that issue alignment and <a href=https://en.wikipedia.org/wiki/Agenda_setting>agenda setting</a> can be seen as a kind of semantic source similarity of the kind how similar is source A to issue owner P, when talking about issue X, and as such can be measured using word / document embedding techniques. We present work in progress towards measuring that kind of conditioned similarity, and introduce a new notion of <a href=https://en.wikipedia.org/wiki/Similarity_measure>similarity</a> for predictive embeddings. We then test this method by measuring the similarity between politically aligned media and political parties, conditioned on bloc-specific issues.<i>X</i>&#8221;, and &#8220;what do people feel, regarding <i>X</i>&#8221;. In this paper, we investigate another venue for social media monitoring, namely <i>issue ownership</i> and <i>agenda setting</i>, which are concepts from political science that have been used to explain voter choice and electoral outcomes. We argue that issue alignment and agenda setting can be seen as a kind of semantic source similarity of the kind &#8220;how similar is source <i>A</i> to issue owner <i>P</i>, when talking about issue <i>X</i>&#8221;, and as such can be measured using word/document embedding techniques. We present work in progress towards measuring that kind of conditioned similarity, and introduce a new notion of similarity for predictive embeddings. We then test this method by measuring the similarity between politically aligned media and political parties, conditioned on bloc-specific issues.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6222.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6222 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6222 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6222/>Sentiment Expression Boundaries in Sentiment Polarity Classification</a></strong><br><a href=/people/r/rasoul-kaljahi/>Rasoul Kaljahi</a>
|
<a href=/people/j/jennifer-foster/>Jennifer Foster</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6222><div class="card-body p-3 small">We investigate the effect of using sentiment expression boundaries in predicting sentiment polarity in aspect-level sentiment analysis. We manually annotate a freely available English sentiment polarity dataset with these boundaries and carry out a series of experiments which demonstrate that high quality sentiment expressions can boost the performance of polarity classification. Our experiments with neural architectures also show that CNN networks outperform <a href=https://en.wikipedia.org/wiki/Linear_time-invariant_system>LSTMs</a> on this task and <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6223.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6223 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6223 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6223/>Exploring and Learning Suicidal Ideation Connotations on Social Media with <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Learning</a></a></strong><br><a href=/people/r/ramit-sawhney/>Ramit Sawhney</a>
|
<a href=/people/p/prachi-manchanda/>Prachi Manchanda</a>
|
<a href=/people/p/puneet-mathur/>Puneet Mathur</a>
|
<a href=/people/r/rajiv-shah/>Rajiv Shah</a>
|
<a href=/people/r/raj-singh/>Raj Singh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6223><div class="card-body p-3 small">The increasing suicide rates amongst youth and its high correlation with suicidal ideation expression on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> warrants a deeper investigation into models for the detection of suicidal intent in text such as <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a> to enable <a href=https://en.wikipedia.org/wiki/Suicide_prevention>prevention</a>. However, the complexity of the natural language constructs makes this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> very challenging. Deep Learning architectures such as <a href=https://en.wikipedia.org/wiki/Linear_time-invariant_system>LSTMs</a>, CNNs, and RNNs show promise in sentence level classification problems. This work investigates the ability of deep learning architectures to build an accurate and robust model for suicidal ideation detection and compares their performance with standard baselines in text classification problems. The experimental results reveal the merit in C-LSTM based models as compared to other deep learning and machine learning based classification models for suicidal ideation detection.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6226.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6226 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6226 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6226/>NLP at IEST 2018 : BiLSTM-Attention and LSTM-Attention via Soft Voting in Emotion Classification<span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>IEST</span> 2018: <span class=acl-fixed-case>B</span>i<span class=acl-fixed-case>LSTM</span>-Attention and <span class=acl-fixed-case>LSTM</span>-Attention via Soft Voting in Emotion Classification</a></strong><br><a href=/people/q/qimin-zhou/>Qimin Zhou</a>
|
<a href=/people/h/hao-wu/>Hao Wu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6226><div class="card-body p-3 small">This paper describes our <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> that competed at WASSA2018 Implicit Emotion Shared Task. The goal of this task is to classify the emotions of excluded words in tweets into six different classes : <a href=https://en.wikipedia.org/wiki/Sadness>sad</a>, <a href=https://en.wikipedia.org/wiki/Joy>joy</a>, <a href=https://en.wikipedia.org/wiki/Disgust>disgust</a>, <a href=https://en.wikipedia.org/wiki/Surprise_(emotion)>surprise</a>, <a href=https://en.wikipedia.org/wiki/Anger>anger</a> and fear. For this, we examine a BiLSTM architecture with attention mechanism (BiLSTM-Attention) and a LSTM architecture with attention mechanism (LSTM-Attention), and try different dropout rates based on these two models. We then exploit an <a href=https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)>ensemble</a> of these methods to give the final prediction which improves the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performance significantly compared with the baseline model. The proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a> achieves 7th position out of 30 teams and outperforms the baseline method by 12.5 % in terms of macro F1.<i>Implicit Emotion Shared Task</i>. The goal of this task is to classify the emotions of excluded words in tweets into six different classes: sad, joy, disgust, surprise, anger and fear. For this, we examine a BiLSTM architecture with attention mechanism (BiLSTM-Attention) and a LSTM architecture with attention mechanism (LSTM-Attention), and try different dropout rates based on these two models. We then exploit an ensemble of these methods to give the final prediction which improves the model performance significantly compared with the baseline model. The proposed method achieves 7th position out of 30 teams and outperforms the baseline method by 12.5% in terms of <i>macro F1</i>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6227.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6227 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6227 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6227/>SINAI at IEST 2018 : Neural Encoding of Emotional External Knowledge for Emotion Classification<span class=acl-fixed-case>SINAI</span> at <span class=acl-fixed-case>IEST</span> 2018: Neural Encoding of Emotional External Knowledge for Emotion Classification</a></strong><br><a href=/people/f/flor-miriam-plaza-del-arco/>Flor Miriam Plaza-del-Arco</a>
|
<a href=/people/e/eugenio-martinez-camara/>Eugenio MartÃ­nez-CÃ¡mara</a>
|
<a href=/people/m/m-teresa-martin-valdivia/>Maite Martin</a>
|
<a href=/people/l/l-alfonso-urena-lopez/>L. Alfonso UreÃ±a- LÃ³pez</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6227><div class="card-body p-3 small">In this paper, we describe our participation in WASSA 2018 Implicit Emotion Shared Task (IEST 2018). We claim that the use of emotional external knowledge may enhance the performance and the capacity of <a href=https://en.wikipedia.org/wiki/Generalization>generalization</a> of an <a href=https://en.wikipedia.org/wiki/Emotion_classification>emotion classification system</a> based on <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>. Accordingly, we submitted four <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning systems</a> grounded in a sequence encoding layer. They mainly differ in the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature vector space</a> and the <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network</a> used in the sequence encoding layer. The official results show that the <a href=https://en.wikipedia.org/wiki/System>systems</a> that used emotional external knowledge have a higher capacity of <a href=https://en.wikipedia.org/wiki/Generalization>generalization</a>, hence our claim holds.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6228.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6228 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6228 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6228/>EmoNLP at IEST 2018 : An Ensemble of Deep Learning Models and Gradient Boosting Regression Tree for Implicit Emotion Prediction in Tweets<span class=acl-fixed-case>E</span>mo<span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>IEST</span> 2018: An Ensemble of Deep Learning Models and Gradient Boosting Regression Tree for Implicit Emotion Prediction in Tweets</a></strong><br><a href=/people/m/man-liu/>Man Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6228><div class="card-body p-3 small">This paper describes our system submitted to IEST 2018, a shared task (Klinger et al., 2018) to predict the emotion types. Six emotion types are involved : <a href=https://en.wikipedia.org/wiki/Anger>anger</a>, <a href=https://en.wikipedia.org/wiki/Joy>joy</a>, <a href=https://en.wikipedia.org/wiki/Fear>fear</a>, <a href=https://en.wikipedia.org/wiki/Surprise_(emotion)>surprise</a>, <a href=https://en.wikipedia.org/wiki/Disgust>disgust</a> and <a href=https://en.wikipedia.org/wiki/Sadness>sad</a>. We perform three different approaches : feed forward neural network (FFNN), convolutional BLSTM (ConBLSTM) and Gradient Boosting Regression Tree Method (GBM). Word embeddings used in convolutional BLSTM are pre-trained on 470 million tweets which are filtered using the emotional words and emojis. In addition, broad sets of <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>features</a> (i.e. syntactic features, lexicon features, cluster features) are adopted to train GBM and FFNN. The three approaches are finally ensembled by the <a href=https://en.wikipedia.org/wiki/Weighted_arithmetic_mean>weighted average of predicted probabilities</a> of each emotion label.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6229.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6229 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6229 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6229/>HGSGNLP at IEST 2018 : An Ensemble of Machine Learning and Deep Neural Architectures for Implicit Emotion Classification in Tweets<span class=acl-fixed-case>HGSGNLP</span> at <span class=acl-fixed-case>IEST</span> 2018: An Ensemble of Machine Learning and Deep Neural Architectures for Implicit Emotion Classification in Tweets</a></strong><br><a href=/people/w/wenting-wang/>Wenting Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6229><div class="card-body p-3 small">This paper describes our <a href=https://en.wikipedia.org/wiki/System>system</a> designed for the WASSA-2018 Implicit Emotion Shared Task (IEST). The task is to predict the emotion category expressed in a tweet by removing the terms angry, afraid, happy, sad, surprised, disgusted and their synonyms. Our final submission is an ensemble of one supervised learning model and three deep neural network based models, where each <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> approaches the problem from essentially different directions. Our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves the <a href=https://en.wikipedia.org/wiki/Macro_(computer_science)>macro F1 score</a> of 65.8 %, which is a 5.9 % performance improvement over the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> and is ranked 12 out of 30 participating teams.<i>angry</i>, <i>afraid</i>, <i>happy</i>, <i>sad</i>, <i>surprised</i>, <i>disgusted</i> and their synonyms. Our final submission is an ensemble of one supervised learning model and three deep neural network based models, where each model approaches the problem from essentially different directions. Our system achieves the macro F1 score of 65.8%, which is a 5.9% performance improvement over the baseline and is ranked 12 out of 30 participating teams.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6232.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6232 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6232 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6232/>UWB at IEST 2018 : Emotion Prediction in Tweets with Bidirectional Long Short-Term Memory Neural Network<span class=acl-fixed-case>UWB</span> at <span class=acl-fixed-case>IEST</span> 2018: Emotion Prediction in Tweets with Bidirectional Long Short-Term Memory Neural Network</a></strong><br><a href=/people/p/pavel-priban/>Pavel PÅ™ibÃ¡Åˆ</a>
|
<a href=/people/j/jiri-martinek/>JiÅ™Ã­ MartÃ­nek</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6232><div class="card-body p-3 small">This paper describes our <a href=https://en.wikipedia.org/wiki/System>system</a> created for the WASSA 2018 Implicit Emotion Shared Task. The goal of this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is to predict the emotion of a given tweet, from which a certain emotion word is removed. The removed word can be sad, happy, disgusted, angry, afraid or a synonym of one of them. Our proposed <a href=https://en.wikipedia.org/wiki/System>system</a> is based on <a href=https://en.wikipedia.org/wiki/Deep_learning>deep-learning methods</a>. We use Bidirectional Long Short-Term Memory (BiLSTM) with <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> as an input. Pre-trained DeepMoji model and pre-trained emoji2vec emoji embeddings are also used as additional inputs. Our <a href=https://en.wikipedia.org/wiki/System>System</a> achieves 0.657 macro F1 score and our rank is 13th out of 30.<i>sad</i>, <i>happy</i>, <i>disgusted</i>, <i>angry</i>, <i>afraid</i> or a synonym of one of them. Our proposed system is based on deep-learning methods. We use Bidirectional Long Short-Term Memory (BiLSTM) with word embeddings as an input. Pre-trained DeepMoji model and pre-trained emoji2vec emoji embeddings are also used as additional inputs. Our System achieves 0.657 macro F1 score and our rank is 13th out of 30.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6234.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6234 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6234 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W18-6234" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W18-6234/>EmotiKLUE at IEST 2018 : Topic-Informed Classification of Implicit Emotions<span class=acl-fixed-case>E</span>moti<span class=acl-fixed-case>KLUE</span> at <span class=acl-fixed-case>IEST</span> 2018: Topic-Informed Classification of Implicit Emotions</a></strong><br><a href=/people/t/thomas-proisl/>Thomas Proisl</a>
|
<a href=/people/p/philipp-heinrich/>Philipp Heinrich</a>
|
<a href=/people/b/besim-kabashi/>Besim Kabashi</a>
|
<a href=/people/s/stefan-evert/>Stefan Evert</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6234><div class="card-body p-3 small">EmotiKLUE is a submission to the Implicit Emotion Shared Task. It is a <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning system</a> that combines independent representations of the left and right contexts of the emotion word with the topic distribution of an LDA topic model. EmotiKLUE achieves a macro average Fscore of 67.13 %, significantly outperforming the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> produced by a simple ML classifier. Further enhancements after the evaluation period lead to an improved Fscore of 68.10 %.<i>F&#8321;</i>score of 67.13%, significantly outperforming the baseline produced by a simple ML classifier. Further enhancements after the evaluation period lead to an improved <i>F&#8321;</i>score of 68.10%.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6236.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6236 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6236 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6236/>Disney at IEST 2018 : Predicting Emotions using an Ensemble<span class=acl-fixed-case>IEST</span> 2018: Predicting Emotions using an Ensemble</a></strong><br><a href=/people/w/wojciech-witon/>Wojciech Witon</a>
|
<a href=/people/p/pierre-colombo/>Pierre Colombo</a>
|
<a href=/people/a/ashutosh-modi/>Ashutosh Modi</a>
|
<a href=/people/m/mubbasir-kapadia/>Mubbasir Kapadia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6236><div class="card-body p-3 small">This paper describes our participating <a href=https://en.wikipedia.org/wiki/System>system</a> in the WASSA 2018 shared task on emotion prediction. The <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> focuses on implicit emotion prediction in a tweet. In this task, keywords corresponding to the six emotion labels used (anger, fear, disgust, joy, sad, and surprise) have been removed from the tweet text, making emotion prediction implicit and the task challenging. We propose a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> based on an <a href=https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)>ensemble of classifiers</a> for <a href=https://en.wikipedia.org/wiki/Prediction>prediction</a>. Each <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> uses a sequence of Convolutional Neural Network (CNN) architecture blocks and uses ELMo (Embeddings from Language Model) as an input. Our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves a 66.2 % <a href=https://en.wikipedia.org/wiki/Grading_in_education>F1 score</a> on the test set. The best performing <a href=https://en.wikipedia.org/wiki/System>system</a> in the shared task has reported a 71.4 % <a href=https://en.wikipedia.org/wiki/F1_score>F1 score</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6238.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6238 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6238 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6238/>Fast Approach to Build an Automatic Sentiment Annotator for Legal Domain using Transfer Learning</a></strong><br><a href=/people/v/viraj-salaka/>Viraj Salaka</a>
|
<a href=/people/m/menuka-warushavithana/>Menuka Warushavithana</a>
|
<a href=/people/n/nisansa-de-silva/>Nisansa de Silva</a>
|
<a href=/people/a/amal-shehan-perera/>Amal Shehan Perera</a>
|
<a href=/people/g/gathika-ratnayaka/>Gathika Ratnayaka</a>
|
<a href=/people/t/thejan-rupasinghe/>Thejan Rupasinghe</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6238><div class="card-body p-3 small">This study proposes a novel way of identifying the sentiment of the phrases used in the <a href=https://en.wikipedia.org/wiki/Legal_term>legal domain</a>. The added <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a> of the language used in <a href=https://en.wikipedia.org/wiki/Law>law</a>, and the inability of the existing <a href=https://en.wikipedia.org/wiki/System>systems</a> to accurately predict the sentiments of words in law are the main motivations behind this study. This is a transfer learning approach which can be used for other domain adaptation tasks as well. The proposed <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> achieves an improvement of over 6 % compared to the source model&#8217;s accuracy in the <a href=https://en.wikipedia.org/wiki/Legal_term>legal domain</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6239.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6239 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6239 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6239/>What Makes You Stressed? Finding Reasons From Tweets</a></strong><br><a href=/people/r/reshmi-gopalakrishna-pillai/>Reshmi Gopalakrishna Pillai</a>
|
<a href=/people/m/mike-thelwall/>Mike Thelwall</a>
|
<a href=/people/c/constantin-orasan/>Constantin Orasan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6239><div class="card-body p-3 small">Detecting stress from <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> gives a non-intrusive and inexpensive alternative to traditional tools such as <a href=https://en.wikipedia.org/wiki/Questionnaire>questionnaires</a> or physiological sensors for monitoring mental state of individuals. This paper introduces a novel framework for finding reasons for stress from <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a>, analyzing multiple categories for the first time. Three word-vector based methods are evaluated on collections of tweets about <a href=https://en.wikipedia.org/wiki/Politics>politics</a> or <a href=https://en.wikipedia.org/wiki/Airline>airlines</a> and are found to be more accurate than standard <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning algorithms</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6240.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6240 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6240 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6240/>EmojiGAN : learning emojis distributions with a <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a><span class=acl-fixed-case>E</span>moji<span class=acl-fixed-case>GAN</span>: learning emojis distributions with a generative model</a></strong><br><a href=/people/b/bogdan-mazoure/>Bogdan Mazoure</a>
|
<a href=/people/t/thang-doan/>Thang Doan</a>
|
<a href=/people/s/saibal-ray/>Saibal Ray</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6240><div class="card-body p-3 small">Generative models have recently experienced a surge in popularity due to the development of more efficient <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training algorithms</a> and increasing <a href=https://en.wikipedia.org/wiki/Computational_power>computational power</a>. Models such as adversarial generative networks (GANs) have been successfully used in various areas such as <a href=https://en.wikipedia.org/wiki/Computer_vision>computer vision</a>, <a href=https://en.wikipedia.org/wiki/Medical_imaging>medical imaging</a>, style transfer and <a href=https://en.wikipedia.org/wiki/Natural-language_generation>natural language generation</a>. Adversarial nets were recently shown to yield results in the image-to-text task, where given a set of images, one has to provide their corresponding text description. In this paper, we take a similar approach and propose a image-to-emoji architecture, which is trained on data from <a href=https://en.wikipedia.org/wiki/List_of_social_networking_websites>social networks</a> and can be used to score a given picture using <a href=https://en.wikipedia.org/wiki/Ideogram>ideograms</a>. We show empirical results of our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> on data obtained from the most influential Instagram accounts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6242.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6242 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6242 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6242/>Homonym Detection For Humor Recognition In Short Text</a></strong><br><a href=/people/s/sven-van-den-beukel/>Sven van den Beukel</a>
|
<a href=/people/l/lora-aroyo/>Lora Aroyo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6242><div class="card-body p-3 small">In this paper, automatic homophone- and homograph detection are suggested as new useful <a href=https://en.wikipedia.org/wiki/Feature_detection_(computer_vision)>features</a> for humor recognition systems. The <a href=https://en.wikipedia.org/wiki/System>system</a> combines style-features from previous studies on humor recognition in short text with ambiguity-based features. The performance of two potentially useful homograph detection methods is evaluated using crowdsourced annotations as ground truth. Adding <a href=https://en.wikipedia.org/wiki/Homophone>homophones</a> and <a href=https://en.wikipedia.org/wiki/Homograph>homographs</a> as <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>features</a> to the classifier results in a small but significant improvement over the style-features alone. For the task of humor recognition, <a href=https://en.wikipedia.org/wiki/Recall_(memory)>recall</a> appears to be a more important quality measure than <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a>. Although the <a href=https://en.wikipedia.org/wiki/System>system</a> was designed for humor recognition in <a href=https://en.wikipedia.org/wiki/Oneliner>oneliners</a>, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> also performs well at the classification of longer humorous texts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6243.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6243 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6243 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W18-6243" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W18-6243/>Emo2Vec : Learning Generalized Emotion Representation by Multi-task Training<span class=acl-fixed-case>E</span>mo2<span class=acl-fixed-case>V</span>ec: Learning Generalized Emotion Representation by Multi-task Training</a></strong><br><a href=/people/p/peng-xu/>Peng Xu</a>
|
<a href=/people/a/andrea-madotto/>Andrea Madotto</a>
|
<a href=/people/c/chien-sheng-wu/>Chien-Sheng Wu</a>
|
<a href=/people/j/ji-ho-park/>Ji Ho Park</a>
|
<a href=/people/p/pascale-fung/>Pascale Fung</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6243><div class="card-body p-3 small">In this paper, we propose Emo2Vec which encodes emotional semantics into vectors. We train Emo2Vec by multi-task learning six different emotion-related tasks, including emotion / sentiment analysis, sarcasm classification, stress detection, abusive language classification, insult detection, and personality recognition. Our evaluation of Emo2Vec shows that it outperforms existing affect-related representations, such as Sentiment-Specific Word Embedding and DeepMoji embeddings with much smaller training corpora. When concatenated with <a href=https://en.wikipedia.org/wiki/GloVe_(machine_learning)>GloVe</a>, Emo2Vec achieves competitive performances to state-of-the-art results on several tasks using a simple logistic regression classifier.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6245.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6245 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6245 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6245/>Super Characters : A Conversion from Sentiment Classification to Image Classification</a></strong><br><a href=/people/b/baohua-sun/>Baohua Sun</a>
|
<a href=/people/l/lin-yang/>Lin Yang</a>
|
<a href=/people/p/patrick-dong/>Patrick Dong</a>
|
<a href=/people/w/wenhan-zhang/>Wenhan Zhang</a>
|
<a href=/people/j/jason-dong/>Jason Dong</a>
|
<a href=/people/c/charles-young/>Charles Young</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6245><div class="card-body p-3 small">We propose a <a href=https://en.wikipedia.org/wiki/Methodology>method</a> named Super Characters for sentiment classification. This method converts the sentiment classification problem into image classification problem by projecting texts into images and then applying CNN models for <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a>. Text features are extracted automatically from the generated Super Characters images, hence there is no need of any explicit step of embedding the words or characters into numerical vector representations. Experimental results on large social media corpus show that the Super Characters method consistently outperforms other methods for sentiment classification and topic classification tasks on ten large social media datasets of millions of contents in four different languages, including <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>, <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a>, <a href=https://en.wikipedia.org/wiki/Korean_language>Korean</a> and <a href=https://en.wikipedia.org/wiki/English_language>English</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6246.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6246 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6246 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6246/>Learning Comment Controversy Prediction in Web Discussions Using Incidentally Supervised Multi-Task CNNs<span class=acl-fixed-case>CNN</span>s</a></strong><br><a href=/people/n/nils-rethmeier/>Nils Rethmeier</a>
|
<a href=/people/m/marc-hubner/>Marc HÃ¼bner</a>
|
<a href=/people/l/leonhard-hennig/>Leonhard Hennig</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6246><div class="card-body p-3 small">Comments on <a href=https://en.wikipedia.org/wiki/Online_newspaper>web news</a> contain <a href=https://en.wikipedia.org/wiki/Controversy>controversies</a> that manifest as inter-group agreement-conflicts. Tracking such rapidly evolving controversy could ease <a href=https://en.wikipedia.org/wiki/Conflict_resolution>conflict resolution</a> or journalist-user interaction. However, this presupposes controversy online-prediction that scales to diverse domains using incidental supervision signals instead of manual labeling. To more deeply interpret comment-controversy model decisions we frame prediction as <a href=https://en.wikipedia.org/wiki/Binary_classification>binary classification</a> and evaluate baselines and multi-task CNNs that use an auxiliary news-genre-encoder. Finally, we use ablation and interpretability methods to determine the impacts of topic, discourse and sentiment indicators, contextual vs. global word influence, as well as genre-keywords vs. per-genre-controversy keywords to find that the models learn plausible controversy features using only incidentally supervised signals.<i>rapidly evolving controversy</i> could ease conflict resolution or journalist-user interaction. However, this presupposes controversy online-prediction that scales to diverse domains using incidental supervision signals instead of manual labeling. To more deeply interpret comment-controversy model decisions we frame prediction as binary classification and evaluate baselines and multi-task CNNs that use an auxiliary news-genre-encoder. Finally, we use ablation and interpretability methods to determine the impacts of topic, discourse and sentiment indicators, contextual vs. global word influence, as well as genre-keywords vs. per-genre-controversy keywords &#8211; to find that the models learn plausible controversy features using only incidentally supervised signals.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6248.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6248 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6248 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6248/>Predicting Adolescentsâ€™ Educational Track from Chat Messages on Dutch Social Media<span class=acl-fixed-case>D</span>utch Social Media</a></strong><br><a href=/people/l/lisa-hilte/>Lisa Hilte</a>
|
<a href=/people/w/walter-daelemans/>Walter Daelemans</a>
|
<a href=/people/r/reinhild-vandekerckhove/>Reinhild Vandekerckhove</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6248><div class="card-body p-3 small">We aim to predict Flemish adolescents&#8217; educational track based on their Dutch social media writing. We distinguish between the three main types of Belgian secondary education : General (theory-oriented), Vocational (practice-oriented), and Technical Secondary Education (hybrid). The best results are obtained with a Naive Bayes model, i.e. an F-score of 0.68 (std. dev. 0.05) in <a href=https://en.wikipedia.org/wiki/Cross-validation_(statistics)>10-fold cross-validation</a> experiments on the training data and an <a href=https://en.wikipedia.org/wiki/F-score>F-score</a> of 0.60 on unseen data. Many of the most informative features are character n-grams containing specific occurrences of chatspeak phenomena such as <a href=https://en.wikipedia.org/wiki/Emoticon>emoticons</a>. While the detection of the most theory- and practice-oriented educational tracks seems to be a relatively easy task, the hybrid Technical level appears to be much harder to capture based on online writing style, as expected.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-6249.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-6249 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-6249 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-6249/>Arabizi sentiment analysis based on <a href=https://en.wikipedia.org/wiki/Transliteration>transliteration</a> and automatic corpus annotation<span class=acl-fixed-case>A</span>rabizi sentiment analysis based on transliteration and automatic corpus annotation</a></strong><br><a href=/people/i/imane-guellil/>Imane Guellil</a>
|
<a href=/people/a/ahsan-adeel/>Ahsan Adeel</a>
|
<a href=/people/f/faical-azouaou/>Faical Azouaou</a>
|
<a href=/people/f/fodil-benali/>Fodil Benali</a>
|
<a href=/people/a/ala-eddine-hachani/>Ala-eddine Hachani</a>
|
<a href=/people/a/amir-hussain/>Amir Hussain</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-6249><div class="card-body p-3 small">Arabizi is a form of writing Arabic text which relies on <a href=https://en.wikipedia.org/wiki/Latin_script>Latin letters</a>, <a href=https://en.wikipedia.org/wiki/Arabic_numerals>numerals</a> and <a href=https://en.wikipedia.org/wiki/Punctuation>punctuation</a> rather than <a href=https://en.wikipedia.org/wiki/Arabic_alphabet>Arabic letters</a>. In the literature, the difficulties associated with <a href=https://en.wikipedia.org/wiki/Arabizi>Arabizi sentiment analysis</a> have been underestimated, principally due to the complexity of <a href=https://en.wikipedia.org/wiki/Arabizi>Arabizi</a>. In this paper, we present an approach to automatically classify <a href=https://en.wikipedia.org/wiki/Sentimentality>sentiments</a> of Arabizi messages into positives or negatives. In the proposed approach, Arabizi messages are first transliterated into <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a>. Afterwards, we automatically classify the <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment</a> of the transliterated corpus using an automatically annotated corpus. For <a href=https://en.wikipedia.org/wiki/Corpus_linguistics>corpus validation</a>, shallow machine learning algorithms such as Support Vectors Machine (SVM) and Naive Bays (NB) are used. Simulations results demonstrate the outperformance of NB algorithm over all others. The highest achieved F1-score is up to 78 % and 76 % for manually and automatically transliterated dataset respectively. Ongoing work is aimed at improving the transliterator module and annotated sentiment dataset.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>