<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/I17-2.pdf>Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</a></h2><p class=lead><a href=/people/g/greg-kondrak/>Greg Kondrak</a>,
<a href=/people/t/taro-watanabe/>Taro Watanabe</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>I17-2</dd><dt>Month:</dt><dd>November</dd><dt>Year:</dt><dd>2017</dd><dt>Address:</dt><dd>Taipei, Taiwan</dd><dt>Venue:</dt><dd><a href=/venues/ijcnlp/>IJCNLP</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Asian Federation of Natural Language Processing</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/I17-2>https://aclanthology.org/I17-2</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/I17-2.pdf>https://aclanthology.org/I17-2.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/I17-2.pdf title="Open PDF of 'Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers)'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+Eighth+International+Joint+Conference+on+Natural+Language+Processing+%28Volume+2%3A+Short+Papers%29" title="Search for 'Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers)' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2000/>Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers)</a></strong><br><a href=/people/g/greg-kondrak/>Greg Kondrak</a>
|
<a href=/people/t/taro-watanabe/>Taro Watanabe</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2001 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2001/>CKY-based Convolutional Attention for <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a><span class=acl-fixed-case>CKY</span>-based Convolutional Attention for Neural Machine Translation</a></strong><br><a href=/people/t/taiki-watanabe/>Taiki Watanabe</a>
|
<a href=/people/a/akihiro-tamura/>Akihiro Tamura</a>
|
<a href=/people/t/takashi-ninomiya/>Takashi Ninomiya</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2001><div class="card-body p-3 small">This paper proposes a new attention mechanism for neural machine translation (NMT) based on convolutional neural networks (CNNs), which is inspired by the <a href=https://en.wikipedia.org/wiki/CKY_algorithm>CKY algorithm</a>. The proposed <a href=https://en.wikipedia.org/wiki/Attention>attention</a> represents every possible combination of source words (e.g., phrases and structures) through CNNs, which imitates the CKY table in the <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a>. NMT, incorporating the proposed <a href=https://en.wikipedia.org/wiki/Attention>attention</a>, decodes a target sentence on the basis of the <a href=https://en.wikipedia.org/wiki/Attention>attention scores</a> of the hidden states of CNNs. The proposed <a href=https://en.wikipedia.org/wiki/Attention>attention</a> enables NMT to capture <a href=https://en.wikipedia.org/wiki/Sequence_alignment>alignments</a> from underlying structures of a source sentence without <a href=https://en.wikipedia.org/wiki/Sentence_parsing>sentence parsing</a>. The evaluations on the Asian Scientific Paper Excerpt Corpus (ASPEC) English-Japanese translation task show that the proposed <a href=https://en.wikipedia.org/wiki/Attention>attention</a> gains 0.66 points in <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2002 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2002/>Supervised Attention for Sequence-to-Sequence Constituency Parsing</a></strong><br><a href=/people/h/hidetaka-kamigaito/>Hidetaka Kamigaito</a>
|
<a href=/people/k/katsuhiko-hayashi/>Katsuhiko Hayashi</a>
|
<a href=/people/t/tsutomu-hirao/>Tsutomu Hirao</a>
|
<a href=/people/h/hiroya-takamura/>Hiroya Takamura</a>
|
<a href=/people/m/manabu-okumura/>Manabu Okumura</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2002><div class="card-body p-3 small">The sequence-to-sequence (Seq2Seq) model has been successfully applied to <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation (MT)</a>. Recently, MT performances were improved by incorporating supervised attention into the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. In this paper, we introduce supervised attention to constituency parsing that can be regarded as another translation task. Evaluation results on the PTB corpus showed that the bracketing F-measure was improved by supervised attention.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2003 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2003/>Transferring Semantic Roles Using Translation and Syntactic Information</a></strong><br><a href=/people/m/maryam-aminian/>Maryam Aminian</a>
|
<a href=/people/m/mohammad-sadegh-rasooli/>Mohammad Sadegh Rasooli</a>
|
<a href=/people/m/mona-diab/>Mona Diab</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2003><div class="card-body p-3 small">Our paper addresses the problem of annotation projection for semantic role labeling for resource-poor languages using supervised annotations from a resource-rich language through parallel data. We propose a transfer method that employs information from source and target syntactic dependencies as well as word alignment density to improve the quality of an iterative bootstrapping method. Our experiments yield a 3.5 absolute labeled F-score improvement over a standard annotation projection method.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2005.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2005 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2005 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2005/>Analyzing Well-Formedness of Syllables in <a href=https://en.wikipedia.org/wiki/Japanese_Sign_Language>Japanese Sign Language</a><span class=acl-fixed-case>J</span>apanese <span class=acl-fixed-case>S</span>ign <span class=acl-fixed-case>L</span>anguage</a></strong><br><a href=/people/s/satoshi-yawata/>Satoshi Yawata</a>
|
<a href=/people/m/makoto-miwa/>Makoto Miwa</a>
|
<a href=/people/y/yutaka-sasaki/>Yutaka Sasaki</a>
|
<a href=/people/d/daisuke-hara/>Daisuke Hara</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2005><div class="card-body p-3 small">This paper tackles a problem of analyzing the well-formedness of syllables in <a href=https://en.wikipedia.org/wiki/Japanese_Sign_Language>Japanese Sign Language (JSL)</a>. We formulate the <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> as a classification problem that classifies syllables into well-formed or ill-formed. We build a <a href=https://en.wikipedia.org/wiki/Data_set>data set</a> that contains hand-coded syllables and their <a href=https://en.wikipedia.org/wiki/Well-formedness>well-formedness</a>. We define a fine-grained feature set based on the hand-coded syllables and train a logistic regression classifier on labeled syllables, expecting to find the discriminative features from the trained <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a>. We also perform pseudo active learning to investigate the applicability of <a href=https://en.wikipedia.org/wiki/Active_learning>active learning</a> in analyzing syllables. In the experiments, the best <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> with our combinatorial features achieved the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 87.0 %. The pseudo active learning is also shown to be effective showing that <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> could reduce about 84 % of training instances to achieve the accuracy of 82.0 % when compared to the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> without <a href=https://en.wikipedia.org/wiki/Active_learning_(machine_learning)>active learning</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2006.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2006 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2006 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/I17-2006.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/I17-2006/>Towards Lower Bounds on Number of Dimensions for Word Embeddings</a></strong><br><a href=/people/k/kevin-patel/>Kevin Patel</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2006><div class="card-body p-3 small">Word embeddings are a relatively new addition to the modern NLP researcher&#8217;s toolkit. However, unlike other <a href=https://en.wikipedia.org/wiki/Tool>tools</a>, <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> are used in a black box manner. There are very few studies regarding various <a href=https://en.wikipedia.org/wiki/Hyperparameter>hyperparameters</a>. One such <a href=https://en.wikipedia.org/wiki/Hyperparameter>hyperparameter</a> is the dimension of word embeddings. They are rather decided based on a rule of thumb : in the range 50 to 300. In this paper, we show that the <a href=https://en.wikipedia.org/wiki/Dimension_(vector_space)>dimension</a> should instead be chosen based on <a href=https://en.wikipedia.org/wiki/Corpus_linguistics>corpus statistics</a>. More specifically, we show that the number of pairwise equidistant words of the corpus vocabulary (as defined by some distance / similarity metric) gives a lower bound on the the number of dimensions, and going below this bound results in degradation of quality of learned word embeddings. Through our evaluations on standard word embedding evaluation tasks, we show that for dimensions higher than or equal to the bound, we get better results as compared to the ones below it.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2008.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2008 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2008 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=I17-2008" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/I17-2008/>Input-to-Output Gate to Improve RNN Language Models<span class=acl-fixed-case>RNN</span> Language Models</a></strong><br><a href=/people/s/sho-takase/>Sho Takase</a>
|
<a href=/people/j/jun-suzuki/>Jun Suzuki</a>
|
<a href=/people/m/masaaki-nagata/>Masaaki Nagata</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2008><div class="card-body p-3 small">This paper proposes a reinforcing method that refines the output layers of existing Recurrent Neural Network (RNN) language models. We refer to our proposed <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> as Input-to-Output Gate (IOG). IOG has an extremely simple structure, and thus, can be easily combined with any RNN language models. Our experiments on the <a href=https://en.wikipedia.org/wiki/Penn_Treebank>Penn Treebank</a> and WikiText-2 datasets demonstrate that IOG consistently boosts the performance of several different types of current topline RNN language models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2009.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2009 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2009 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/I17-2009.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=I17-2009" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/I17-2009/>Counterfactual Language Model Adaptation for Suggesting Phrases</a></strong><br><a href=/people/k/kenneth-arnold/>Kenneth Arnold</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/a/adam-kalai/>Adam Kalai</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2009><div class="card-body p-3 small">Mobile devices use <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> to suggest words and phrases for use in <a href=https://en.wikipedia.org/wiki/Computer_terminal>text entry</a>. Traditional <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> are based on contextual word frequency in a static corpus of text. However, certain types of phrases, when offered to writers as suggestions, may be systematically chosen more often than their frequency would predict. In this paper, we propose the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> of generating suggestions that writers accept, a related but distinct <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> to making accurate predictions. Although this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is fundamentally interactive, we propose a counterfactual setting that permits offline training and evaluation. We find that even a simple <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> can capture text characteristics that improve <a href=https://en.wikipedia.org/wiki/Acceptability>acceptability</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2012 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/I17-2012.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/I17-2012/>Learning Kernels over Strings using <a href=https://en.wikipedia.org/wiki/Gaussian_function>Gaussian Processes</a><span class=acl-fixed-case>G</span>aussian Processes</a></strong><br><a href=/people/d/daniel-beck/>Daniel Beck</a>
|
<a href=/people/t/trevor-cohn/>Trevor Cohn</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2012><div class="card-body p-3 small">Non-contiguous word sequences are widely known to be important in <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>modelling natural language</a>. However they not explicitly encoded in <a href=https://en.wikipedia.org/wiki/Universal_Coded_Character_Set>common text representations</a>. In this work we propose a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> for <a href=https://en.wikipedia.org/wiki/Text_processing>text processing</a> using <a href=https://en.wikipedia.org/wiki/String_kernel>string kernels</a>, capable of flexibly representing non-contiguous sequences. Specifically, we derive a vectorised version of the string kernel algorithm and their <a href=https://en.wikipedia.org/wiki/Gradient>gradients</a>, allowing efficient <a href=https://en.wikipedia.org/wiki/Hyperparameter_optimization>hyperparameter optimisation</a> as part of a Gaussian Process framework. Experiments on synthetic data and text regression for emotion analysis show the promise of this technique.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2013.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2013 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2013 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2013/>Substring Frequency Features for Segmentation of Japanese Katakana Words with Unlabeled Corpora<span class=acl-fixed-case>J</span>apanese Katakana Words with Unlabeled Corpora</a></strong><br><a href=/people/y/yoshinari-fujinuma/>Yoshinari Fujinuma</a>
|
<a href=/people/a/alvin-grissom-ii/>Alvin Grissom II</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2013><div class="card-body p-3 small">Word segmentation is crucial in natural language processing tasks for unsegmented languages. In <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a>, many out-of-vocabulary words appear in the <a href=https://en.wikipedia.org/wiki/Katakana>phonetic syllabary katakana</a>, making segmentation more difficult due to the lack of clues found in mixed script settings. In this paper, we propose a straightforward approach based on a variant of tf-idf and apply it to the problem of <a href=https://en.wikipedia.org/wiki/Word_segmentation>word segmentation</a> in <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a>. Even though our method uses only an unlabeled corpus, experimental results show that it achieves performance comparable to existing methods that use manually labeled corpora. Furthermore, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> improves performance of simple <a href=https://en.wikipedia.org/wiki/Word_segmentation>word segmentation models</a> trained on a manually labeled corpus.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2014.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2014 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2014/>MONPA : Multi-objective Named-entity and Part-of-speech Annotator for Chinese using <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>Recurrent Neural Network</a><span class=acl-fixed-case>MONPA</span>: Multi-objective Named-entity and Part-of-speech Annotator for <span class=acl-fixed-case>C</span>hinese using Recurrent Neural Network</a></strong><br><a href=/people/y/yu-lun-hsieh/>Yu-Lun Hsieh</a>
|
<a href=/people/y/yung-chun-chang/>Yung-Chun Chang</a>
|
<a href=/people/y/yi-jie-huang/>Yi-Jie Huang</a>
|
<a href=/people/s/shu-hao-yeh/>Shu-Hao Yeh</a>
|
<a href=/people/c/chun-hung-chen/>Chun-Hung Chen</a>
|
<a href=/people/w/wen-lian-hsu/>Wen-Lian Hsu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2014><div class="card-body p-3 small">Part-of-speech (POS) tagging and named entity recognition (NER) are crucial steps in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. In addition, the difficulty of <a href=https://en.wikipedia.org/wiki/Word_segmentation>word segmentation</a> places additional burden on those who intend to deal with languages such as <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>, and pipelined systems often suffer from <a href=https://en.wikipedia.org/wiki/Propagation_of_error>error propagation</a>. This work proposes an end-to-end model using character-based recurrent neural network (RNN) to jointly accomplish segmentation, POS tagging and NER of a Chinese sentence. Experiments on previous word segmentation and NER datasets show that a single model with the proposed architecture is comparable to those trained specifically for each task, and outperforms freely-available softwares. Moreover, we provide a web-based interface for the public to easily access this resource.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2015.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2015 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2015 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2015/>Recall is the Proper Evaluation Metric for <a href=https://en.wikipedia.org/wiki/Word_segmentation>Word Segmentation</a></a></strong><br><a href=/people/y/yan-shao/>Yan Shao</a>
|
<a href=/people/c/christian-hardmeier/>Christian Hardmeier</a>
|
<a href=/people/j/joakim-nivre/>Joakim Nivre</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2015><div class="card-body p-3 small">We extensively analyse the correlations and drawbacks of conventionally employed evaluation metrics for <a href=https://en.wikipedia.org/wiki/Word_segmentation>word segmentation</a>. Unlike in standard <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval</a>, <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a> favours under-splitting systems and therefore can be misleading in <a href=https://en.wikipedia.org/wiki/Word_segmentation>word segmentation</a>. Overall, based on both theoretical and experimental analysis, we propose that precision should be excluded from the standard evaluation metrics and that the evaluation score obtained by using only <a href=https://en.wikipedia.org/wiki/Recall_(memory)>recall</a> is sufficient and better correlated with the performance of word segmentation systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2016.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2016 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2016 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2016/>Low-Resource Named Entity Recognition with Cross-lingual, Character-Level Neural Conditional Random Fields</a></strong><br><a href=/people/r/ryan-cotterell/>Ryan Cotterell</a>
|
<a href=/people/k/kevin-duh/>Kevin Duh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2016><div class="card-body p-3 small">Low-resource named entity recognition is still an open problem in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. Most state-of-the-art systems require tens of thousands of annotated sentences in order to obtain high performance. However, for most of the world&#8217;s languages it is unfeasible to obtain such annotation. In this paper, we present a transfer learning scheme, whereby we train character-level neural CRFs to predict <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entities</a> for both high-resource languages and low-resource languages jointly. Learning character representations for multiple related languages allows <a href=https://en.wikipedia.org/wiki/Knowledge_transfer>knowledge transfer</a> from the high-resource languages to the low-resource ones, improving F1 by up to 9.8 points.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2017.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2017 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2017 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2017/>Segment-Level Neural Conditional Random Fields for Named Entity Recognition</a></strong><br><a href=/people/m/motoki-sato/>Motoki Sato</a>
|
<a href=/people/h/hiroyuki-shindo/>Hiroyuki Shindo</a>
|
<a href=/people/i/ikuya-yamada/>Ikuya Yamada</a>
|
<a href=/people/y/yuji-matsumoto/>Yuji Matsumoto</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2017><div class="card-body p-3 small">We present Segment-level Neural CRF, which combines <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> with a linear chain CRF for segment-level sequence modeling tasks such as <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition (NER)</a> and syntactic chunking. Our segment-level CRF can consider higher-order label dependencies compared with conventional word-level CRF. Since it is difficult to consider all possible variable length segments, our method uses segment lattice constructed from the word-level tagging model to reduce the search space. Performing experiments on NER and chunking, we demonstrate that our method outperforms conventional word-level CRF with <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2018.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2018 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2018 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2018/>Integrating Vision and Language Datasets to Measure Word Concreteness</a></strong><br><a href=/people/g/gitit-kehat/>Gitit Kehat</a>
|
<a href=/people/j/james-pustejovsky/>James Pustejovsky</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2018><div class="card-body p-3 small">We present and take advantage of the inherent visualizability properties of words in visual corpora (the textual components of vision-language datasets) to compute concreteness scores for <a href=https://en.wikipedia.org/wiki/Word>words</a>. Our simple method does not require hand-annotated concreteness score lists for training, and yields state-of-the-art results when evaluated against concreteness scores lists and previously derived scores, as well as when used for metaphor detection.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2019.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2019 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2019 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2019/>Semantic Features Based on Word Alignments for Estimating Quality of Text Simplification</a></strong><br><a href=/people/t/tomoyuki-kajiwara/>Tomoyuki Kajiwara</a>
|
<a href=/people/a/atsushi-fujita/>Atsushi Fujita</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2019><div class="card-body p-3 small">This paper examines the usefulness of <a href=https://en.wikipedia.org/wiki/Semantic_feature>semantic features</a> based on <a href=https://en.wikipedia.org/wiki/Word_alignment>word alignments</a> for estimating the quality of text simplification. Specifically, we introduce seven types of alignment-based features computed on the basis of <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> and paraphrase lexicons. Through an empirical experiment using the QATS dataset, we confirm that we can achieve the state-of-the-art performance only with these <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2020.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2020 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2020 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2020/>Injecting Word Embeddings with Another Language’s Resource : An Application of Bilingual Embeddings</a></strong><br><a href=/people/p/prakhar-pandey/>Prakhar Pandey</a>
|
<a href=/people/v/vikram-pudi/>Vikram Pudi</a>
|
<a href=/people/m/manish-shrivastava/>Manish Shrivastava</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2020><div class="card-body p-3 small">Word embeddings learned from <a href=https://en.wikipedia.org/wiki/Text_corpus>text corpus</a> can be improved by injecting knowledge from external resources, while at the same time also specializing them for similarity or relatedness. These knowledge resources (like WordNet, Paraphrase Database) may not exist for all languages. In this work we introduce a method to inject <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> of a language with knowledge resource of another language by leveraging bilingual embeddings. First we improve word embeddings of <a href=https://en.wikipedia.org/wiki/German_language>German</a>, <a href=https://en.wikipedia.org/wiki/Italian_language>Italian</a>, <a href=https://en.wikipedia.org/wiki/French_language>French</a> and <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a> using resources of English and test them on variety of word similarity tasks. Then we demonstrate the utility of our method by creating improved embeddings for <a href=https://en.wikipedia.org/wiki/Urdu>Urdu and Telugu languages</a> using Hindi WordNet, beating the previously established baseline for <a href=https://en.wikipedia.org/wiki/Urdu>Urdu</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2021.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2021 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2021 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2021/>Improving Black-box Speech Recognition using Semantic Parsing</a></strong><br><a href=/people/r/rodolfo-corona/>Rodolfo Corona</a>
|
<a href=/people/j/jesse-thomason/>Jesse Thomason</a>
|
<a href=/people/r/raymond-mooney/>Raymond Mooney</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2021><div class="card-body p-3 small">Speech is a natural channel for <a href=https://en.wikipedia.org/wiki/Human&#8211;computer_interaction>human-computer interaction</a> in robotics and consumer applications. Natural language understanding pipelines that start with <a href=https://en.wikipedia.org/wiki/Manner_of_articulation>speech</a> can have trouble recovering from <a href=https://en.wikipedia.org/wiki/Manner_of_articulation>speech recognition errors</a>. Black-box automatic speech recognition (ASR) systems, built for general purpose use, are unable to take advantage of in-domain language models that could otherwise ameliorate these errors. In this work, we present a method for re-ranking black-box ASR hypotheses using an in-domain language model and <a href=https://en.wikipedia.org/wiki/Semantic_parser>semantic parser</a> trained for a particular task. Our re-ranking method significantly improves both transcription accuracy and semantic understanding over a state-of-the-art ASR&#8217;s vanilla output.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2022.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2022 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2022 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2022/>Revisiting the Design Issues of Local Models for Japanese Predicate-Argument Structure Analysis<span class=acl-fixed-case>J</span>apanese Predicate-Argument Structure Analysis</a></strong><br><a href=/people/y/yuichiroh-matsubayashi/>Yuichiroh Matsubayashi</a>
|
<a href=/people/k/kentaro-inui/>Kentaro Inui</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2022><div class="card-body p-3 small">The research trend in Japanese predicate-argument structure (PAS) analysis is shifting from pointwise prediction models with local features to global models designed to search for globally optimal solutions. However, the existing <a href=https://en.wikipedia.org/wiki/General_circulation_model>global models</a> tend to employ only relatively simple local features ; therefore, the overall performance gains are rather limited. The importance of designing a local model is demonstrated in this study by showing that the performance of a sophisticated local model can be considerably improved with recent feature embedding methods and a feature combination learning based on a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a>, outperforming the state-of-the-art global models in F1 on a common benchmark dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2023.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2023 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2023 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2023/>Natural Language Informs the Interpretation of Iconic Gestures : A Computational Approach</a></strong><br><a href=/people/t/ting-han/>Ting Han</a>
|
<a href=/people/j/julian-hough/>Julian Hough</a>
|
<a href=/people/d/david-schlangen/>David Schlangen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2023><div class="card-body p-3 small">When giving descriptions, speakers often signify object shape or size with <a href=https://en.wikipedia.org/wiki/List_of_gestures>hand gestures</a>. Such so-called &#8216;iconic&#8217; gestures represent their meaning through their relevance to referents in the verbal content, rather than having a conventional form. The gesture form on its own is often ambiguous, and the aspect of the referent that it highlights is constrained by what the language makes salient. We show how the verbal content guides gesture interpretation through a computational model that frames the task as a multi-label classification task that maps multimodal utterances to semantic categories, using annotated human-human data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2027.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2027 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2027 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/I17-2027.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/I17-2027.Datasets.tgz data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file-archive"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/I17-2027/>Can <a href=https://en.wikipedia.org/wiki/Discourse_relation>Discourse Relations</a> be Identified Incrementally?</a></strong><br><a href=/people/f/frances-yung/>Frances Yung</a>
|
<a href=/people/h/hiroshi-noji/>Hiroshi Noji</a>
|
<a href=/people/y/yuji-matsumoto/>Yuji Matsumoto</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2027><div class="card-body p-3 small">Humans process language word by word and construct partial linguistic structures on the fly before the end of the sentence is perceived. Inspired by this <a href=https://en.wikipedia.org/wiki/Cognition>cognitive ability</a>, incremental algorithms for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing tasks</a> have been proposed and demonstrated promising performance. For discourse relation (DR) parsing, however, it is not yet clear to what extent humans can recognize DRs incrementally, because the latent &#8216;nodes&#8217; of discourse structure can span clauses and sentences. To answer this question, this work investigates incrementality in discourse processing based on a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> annotated with DR signals. We find that DRs are dominantly signaled at the boundary between the two constituent discourse units. The findings complement existing <a href=https://en.wikipedia.org/wiki/Psycholinguistics>psycholinguistic theories</a> on expectation in discourse processing and provide direction for incremental discourse parsing.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2028.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2028 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2028 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=I17-2028" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/I17-2028/>Speaker Role Contextual Modeling for <a href=https://en.wikipedia.org/wiki/Language_understanding>Language Understanding</a> and Dialogue Policy Learning</a></strong><br><a href=/people/t/ta-chung-chi/>Ta-Chung Chi</a>
|
<a href=/people/p/po-chun-chen/>Po-Chun Chen</a>
|
<a href=/people/s/shang-yu-su/>Shang-Yu Su</a>
|
<a href=/people/y/yun-nung-chen/>Yun-Nung Chen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2028><div class="card-body p-3 small">Language understanding (LU) and dialogue policy learning are two essential components in conversational systems. Human-human dialogues are not well-controlled and often random and unpredictable due to their own goals and speaking habits. This paper proposes a role-based contextual model to consider different speaker roles independently based on the various speaking patterns in the multi-turn dialogues. The experiments on the benchmark dataset show that the proposed role-based model successfully learns role-specific behavioral patterns for contextual encoding and then significantly improves <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>language understanding</a> and dialogue policy learning tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2029.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2029 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2029 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2029/>Diversifying Neural Conversation Model with Maximal Marginal Relevance</a></strong><br><a href=/people/y/yiping-song/>Yiping Song</a>
|
<a href=/people/z/zhiliang-tian/>Zhiliang Tian</a>
|
<a href=/people/d/dongyan-zhao/>Dongyan Zhao</a>
|
<a href=/people/m/ming-zhang/>Ming Zhang</a>
|
<a href=/people/r/rui-yan/>Rui Yan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2029><div class="card-body p-3 small">Neural conversation systems, typically using sequence-to-sequence (seq2seq) models, are showing promising progress recently. However, traditional seq2seq suffer from a severe weakness : during beam search decoding, they tend to rank universal replies at the top of the candidate list, resulting in the lack of diversity among candidate replies. Maximum Marginal Relevance (MMR) is a <a href=https://en.wikipedia.org/wiki/Ranking_(statistics)>ranking algorithm</a> that has been widely used for subset selection. In this paper, we propose the MMR-BS decoding method, which incorporates MMR into the beam search (BS) process of seq2seq. The MMR-BS method improves the diversity of generated replies without sacrificing their high relevance with the user-issued query. Experiments show that our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves the best performance among other comparison methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2030.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2030 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2030 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2030/>Dialog for Language to Code</a></strong><br><a href=/people/s/shobhit-chaurasia/>Shobhit Chaurasia</a>
|
<a href=/people/r/raymond-mooney/>Raymond J. Mooney</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2030><div class="card-body p-3 small">Generating computer code from <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language descriptions</a> has been a long-standing problem. Prior work in this <a href=https://en.wikipedia.org/wiki/Domain_(software_engineering)>domain</a> has restricted itself to <a href=https://en.wikipedia.org/wiki/Code_generation_(compiler)>generating code</a> in one shot from a single description. To overcome this limitation, we propose a system that can engage users in a dialog to clarify their intent until it has all the information to produce correct code. To evaluate the efficacy of dialog in <a href=https://en.wikipedia.org/wiki/Automatic_programming>code generation</a>, we focus on synthesizing <a href=https://en.wikipedia.org/wiki/Conditional_(computer_programming)>conditional statements</a> in the form of IFTTT recipes.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2031.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2031 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2031 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2031/>Using Analytic Scoring Rubrics in the Automatic Assessment of College-Level Summary Writing Tasks in L2<span class=acl-fixed-case>L</span>2</a></strong><br><a href=/people/t/tamara-sladoljev-agejev/>Tamara Sladoljev-Agejev</a>
|
<a href=/people/j/jan-snajder/>Jan Šnajder</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2031><div class="card-body p-3 small">Assessing summaries is a demanding, yet useful task which provides valuable information on <a href=https://en.wikipedia.org/wiki/Linguistic_competence>language competence</a>, especially for <a href=https://en.wikipedia.org/wiki/Second-language_acquisition>second language learners</a>. We consider automated scoring of college-level summary writing task in English as a second language (EL2). We adopt the Reading-for-Understanding (RU) cognitive framework, extended with the Reading-to-Write (RW) element, and use analytic scoring with six rubrics covering content and writing quality. We show that <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression models</a> with reference-based and linguistic features considerably outperform the baselines across all the rubrics. Moreover, we find interesting correlations between summary features and analytic rubrics, revealing the links between the RU and RW constructs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2032.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2032 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2032 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2032/>A Statistical Framework for Product Description Generation</a></strong><br><a href=/people/j/jinpeng-wang/>Jinpeng Wang</a>
|
<a href=/people/y/yutai-hou/>Yutai Hou</a>
|
<a href=/people/j/jing-liu/>Jing Liu</a>
|
<a href=/people/y/yunbo-cao/>Yunbo Cao</a>
|
<a href=/people/c/chin-yew-lin/>Chin-Yew Lin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2032><div class="card-body p-3 small">We present in this paper a statistical framework that generates accurate and fluent product description from product attributes. Specifically, after extracting templates and learning writing knowledge from attribute-description parallel data, we use the learned knowledge to decide what to say and how to say for product description generation. To evaluate accuracy and fluency for the generated descriptions, in addition to BLEU and Recall, we propose to measure what to say (in terms of attribute coverage) and to measure how to say (by attribute-specified generation) separately. Experimental results show that our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> is effective.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2033.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2033 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2033 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2033/>Automatic Text Summarization Using <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>Reinforcement Learning</a> with Embedding Features</a></strong><br><a href=/people/g/gyoung-ho-lee/>Gyoung Ho Lee</a>
|
<a href=/people/k/kong-joo-lee/>Kong Joo Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2033><div class="card-body p-3 small">An automatic text summarization system can automatically generate a short and brief summary that contains a main concept of an original document. In this work, we explore the advantages of simple embedding features in Reinforcement leaning approach to automatic text summarization tasks. In addition, we propose a novel <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning network</a> for estimating Q-values used in <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>Reinforcement learning</a>. We evaluate our model by using ROUGE scores with DUC 2001, 2002, Wikipedia, ACL-ARC data. Evaluation results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is competitive with the previous <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2034.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2034 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2034 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/I17-2034.Datasets.txt data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file-archive"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/I17-2034/>SSAS : <a href=https://en.wikipedia.org/wiki/Semantic_similarity>Semantic Similarity</a> for Abstractive Summarization<span class=acl-fixed-case>SSAS</span>: Semantic Similarity for Abstractive Summarization</a></strong><br><a href=/people/r/raghuram-vadapalli/>Raghuram Vadapalli</a>
|
<a href=/people/l/litton-j-kurisinkel/>Litton J Kurisinkel</a>
|
<a href=/people/m/manish-gupta/>Manish Gupta</a>
|
<a href=/people/v/vasudeva-varma/>Vasudeva Varma</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2034><div class="card-body p-3 small">Ideally a <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> evaluating an abstract system summary should represent the extent to which the system-generated summary approximates the semantic inference conceived by the reader using a human-written reference summary. Most of the previous approaches relied upon word or syntactic sub-sequence overlap to evaluate system-generated summaries. Such <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> can not evaluate the summary at semantic inference level. Through this work we introduce the metric of Semantic Similarity for Abstractive Summarization (SSAS), which leverages natural language inference and paraphrasing techniques to frame a novel approach to evaluate system summaries at semantic inference level. SSAS is based upon a weighted composition of quantities representing the level of agreement, <a href=https://en.wikipedia.org/wiki/Contradiction>contradiction</a>, <a href=https://en.wikipedia.org/wiki/Independence_(probability_theory)>independence</a>, <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrasing</a>, and optionally ROUGE score between a system-generated and a human-written summary.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2035.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2035 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2035 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2035/>Taking into account Inter-sentence Similarity for Update Summarization</a></strong><br><a href=/people/m/maali-mnasri/>Maâli Mnasri</a>
|
<a href=/people/g/gael-de-chalendar/>Gaël de Chalendar</a>
|
<a href=/people/o/olivier-ferret/>Olivier Ferret</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2035><div class="card-body p-3 small">Following Gillick and Favre (2009), a lot of work about extractive summarization has modeled this task by associating two contrary constraints : one aims at maximizing the coverage of the summary with respect to its information content while the other represents its size limit. In this context, the notion of <a href=https://en.wikipedia.org/wiki/Redundancy_(linguistics)>redundancy</a> is only implicitly taken into account. In this article, we extend the framework defined by Gillick and Favre (2009) by examining how and to what extent integrating semantic sentence similarity into an update summarization system can improve its results. We show more precisely the impact of this <a href=https://en.wikipedia.org/wiki/Strategy>strategy</a> through evaluations performed on DUC 2007 and TAC 2008 and 2009 datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2037.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2037 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2037 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2037/>Dual Constrained Question Embeddings with Relational Knowledge Bases for Simple Question Answering</a></strong><br><a href=/people/k/kaustubh-kulkarni/>Kaustubh Kulkarni</a>
|
<a href=/people/r/riku-togashi/>Riku Togashi</a>
|
<a href=/people/h/hideyuki-maeda/>Hideyuki Maeda</a>
|
<a href=/people/s/sumio-fujita/>Sumio Fujita</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2037><div class="card-body p-3 small">Embedding based approaches are shown to be effective for solving simple Question Answering (QA) problems in recent works. The major drawback of current approaches is that they look only at the similarity (constraint) between a question and a head, relation pair. Due to the absence of tail (answer) in the questions, these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> often require paraphrase datasets to obtain adequate <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a>. In this paper, we propose a dual constraint model which exploits the embeddings obtained by Trans * family of algorithms to solve the simple QA problem without using any additional resources such as paraphrase datasets. The results obtained prove that the <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> learned using <a href=https://en.wikipedia.org/wiki/Constraint_(mathematics)>dual constraints</a> are better than those with <a href=https://en.wikipedia.org/wiki/Constraint_(mathematics)>single constraint models</a> having similar architecture.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2038.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2038 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2038 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2038/>Efficiency-aware Answering of Compositional Questions using Answer Type Prediction</a></strong><br><a href=/people/d/david-ziegler/>David Ziegler</a>
|
<a href=/people/a/abdalghani-abujabal/>Abdalghani Abujabal</a>
|
<a href=/people/r/rishiraj-saha-roy/>Rishiraj Saha Roy</a>
|
<a href=/people/g/gerhard-weikum/>Gerhard Weikum</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2038><div class="card-body p-3 small">This paper investigates the problem of answering compositional factoid questions over knowledge bases (KB) under efficiency constraints. The method, called TIPI, (i) decomposes compositional questions, (ii) predicts answer types for individual sub-questions, (iii) reasons over the compatibility of joint types, and finally, (iv) formulates compositional SPARQL queries respecting type constraints. TIPI&#8217;s answer type predictor is trained using distant supervision, and exploits lexical, syntactic and embedding-based features to compute context- and hierarchy-aware candidate answer types for an input question. Experiments on a recent <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark</a> show that TIPI results in state-of-the-art performance under the real-world assumption that only a single SPARQL query can be executed over the <a href=https://en.wikipedia.org/wiki/Kilobyte>KB</a>, and substantial reduction in the number of queries in the more general case.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2039.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2039 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2039 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2039/>High Recall Open IE for Relation Discovery<span class=acl-fixed-case>IE</span> for Relation Discovery</a></strong><br><a href=/people/h/hady-elsahar/>Hady Elsahar</a>
|
<a href=/people/c/christophe-gravier/>Christophe Gravier</a>
|
<a href=/people/f/frederique-laforest/>Frederique Laforest</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2039><div class="card-body p-3 small">Relation Discovery discovers predicates (relation types) from a <a href=https://en.wikipedia.org/wiki/Text_corpus>text corpus</a> relying on the co-occurrence of two named entities in the same sentence. This is a very narrowing constraint : it represents only a small fraction of all <a href=https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms>relation mentions</a> in practice. In this paper we propose a high recall approach for <a href=https://en.wikipedia.org/wiki/Open_IE>Open IE</a>, which enables covering up to 16 times more sentences in a large corpus. Comparison against OpenIE systems shows that our proposed approach achieves 28 % improvement over the highest recall OpenIE system and 6 % improvement in precision than the same system.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2040.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2040 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2040 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2040/>Using Context Events in Neural Network Models for Event Temporal Status Identification</a></strong><br><a href=/people/z/zeyu-dai/>Zeyu Dai</a>
|
<a href=/people/w/wenlin-yao/>Wenlin Yao</a>
|
<a href=/people/r/ruihong-huang/>Ruihong Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2040><div class="card-body p-3 small">Focusing on the task of identifying event temporal status, we find that events directly or indirectly governing the target event in a dependency tree are most important contexts. Therefore, we extract dependency chains containing context events and use them as input in neural network models, which consistently outperform previous models using local context words as input. Visualization verifies that the dependency chain representation can effectively capture the context events which are closely related to the target event and play key roles in predicting event temporal status.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2041.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2041 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2041 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2041/>Identifying Protein-protein Interactions in Biomedical Literature using Recurrent Neural Networks with Long Short-Term Memory</a></strong><br><a href=/people/y/yu-lun-hsieh/>Yu-Lun Hsieh</a>
|
<a href=/people/y/yung-chun-chang/>Yung-Chun Chang</a>
|
<a href=/people/n/nai-wen-chang/>Nai-Wen Chang</a>
|
<a href=/people/w/wen-lian-hsu/>Wen-Lian Hsu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2041><div class="card-body p-3 small">In this paper, we propose a <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network model</a> for identifying protein-protein interactions in <a href=https://en.wikipedia.org/wiki/Medical_literature>biomedical literature</a>. Experiments on two largest public benchmark datasets, AIMed and BioInfer, demonstrate that our approach significantly surpasses state-of-the-art methods with relative improvements of 10 % and 18 %, respectively. Cross-corpus evaluation also demonstrate that the proposed <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> remains robust despite using different training data. These results suggest that RNN can effectively capture semantic relationships among proteins as well as generalizes over different corpora, without any <a href=https://en.wikipedia.org/wiki/Feature_engineering>feature engineering</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2042.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2042 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2042 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2042/>Identifying Empathetic Messages in <a href=https://en.wikipedia.org/wiki/Online_health_communities>Online Health Communities</a></a></strong><br><a href=/people/h/hamed-khanpour/>Hamed Khanpour</a>
|
<a href=/people/c/cornelia-caragea/>Cornelia Caragea</a>
|
<a href=/people/p/prakhar-biyani/>Prakhar Biyani</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2042><div class="card-body p-3 small">Empathy captures one&#8217;s ability to correlate with and understand others&#8217; emotional states and experiences. Messages with empathetic content are considered as one of the main advantages for joining online health communities due to their potential to improve people&#8217;s moods. Unfortunately, to this date, no computational studies exist that automatically identify empathetic messages in online health communities. We propose a combination of Convolutional Neural Networks (CNN) and Long Short Term Memory (LSTM) networks, and show that the proposed model outperforms each individual model (CNN and LSTM) as well as several baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2043.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2043 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2043 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2043/>Fake News Detection Through Multi-Perspective Speaker Profiles</a></strong><br><a href=/people/y/yunfei-long/>Yunfei Long</a>
|
<a href=/people/q/qin-lu/>Qin Lu</a>
|
<a href=/people/r/rong-xiang/>Rong Xiang</a>
|
<a href=/people/m/minglei-li/>Minglei Li</a>
|
<a href=/people/c/chu-ren-huang/>Chu-Ren Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2043><div class="card-body p-3 small">Automatic fake news detection is an important, yet very challenging topic. Traditional <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> using lexical features have only very limited success. This paper proposes a novel method to incorporate <a href=https://en.wikipedia.org/wiki/Public_speaking>speaker profiles</a> into an attention based LSTM model for <a href=https://en.wikipedia.org/wiki/Fake_news>fake news detection</a>. Speaker profiles contribute to the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> in two ways. One is to include <a href=https://en.wikipedia.org/wiki/Them>them</a> in the attention model. The other includes <a href=https://en.wikipedia.org/wiki/List_of_Latin_phrases_(M)>them</a> as additional input data. By adding speaker profiles such as <a href=https://en.wikipedia.org/wiki/Political_party>party affiliation</a>, speaker title, location and <a href=https://en.wikipedia.org/wiki/Credit_history>credit history</a>, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms the <a href=https://en.wikipedia.org/wiki/State-of-the-art>state-of-the-art method</a> by 14.5 % in <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> using a benchmark fake news detection dataset. This proves that speaker profiles provide valuable information to validate the credibility of news articles.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2044.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2044 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2044 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2044/>Improving Neural Text Normalization with Data Augmentation at Character- and Morphological Levels</a></strong><br><a href=/people/i/itsumi-saito/>Itsumi Saito</a>
|
<a href=/people/j/jun-suzuki/>Jun Suzuki</a>
|
<a href=/people/k/kyosuke-nishida/>Kyosuke Nishida</a>
|
<a href=/people/k/kugatsu-sadamitsu/>Kugatsu Sadamitsu</a>
|
<a href=/people/s/satoshi-kobashikawa/>Satoshi Kobashikawa</a>
|
<a href=/people/r/ryo-masumura/>Ryo Masumura</a>
|
<a href=/people/y/yuji-matsumoto/>Yuji Matsumoto</a>
|
<a href=/people/j/junji-tomita/>Junji Tomita</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2044><div class="card-body p-3 small">In this study, we investigated the effectiveness of augmented data for encoder-decoder-based neural normalization models. Attention based encoder-decoder models are greatly effective in generating many natural languages. % such as <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> or machine summarization. In general, we have to prepare for a large amount of training data to train an encoder-decoder model. Unlike <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, there are few training data for text-normalization tasks. In this paper, we propose two <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> for generating augmented data. The experimental results with Japanese dialect normalization indicate that our methods are effective for an encoder-decoder model and achieve higher BLEU score than that of <a href=https://en.wikipedia.org/wiki/Baseline_(typography)>baselines</a>. We also investigated the oracle performance and revealed that there is sufficient room for improving an encoder-decoder model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2045.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2045 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2045 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2045/>Using <a href=https://en.wikipedia.org/wiki/Social_network>Social Networks</a> to Improve Language Variety Identification with Neural Networks</a></strong><br><a href=/people/y/yasuhide-miura/>Yasuhide Miura</a>
|
<a href=/people/t/tomoki-taniguchi/>Tomoki Taniguchi</a>
|
<a href=/people/m/motoki-taniguchi/>Motoki Taniguchi</a>
|
<a href=/people/s/shotaro-misawa/>Shotaro Misawa</a>
|
<a href=/people/t/tomoko-ohkuma/>Tomoko Ohkuma</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2045><div class="card-body p-3 small">We propose a hierarchical neural network model for language variety identification that integrates information from a <a href=https://en.wikipedia.org/wiki/Social_network>social network</a>. Recently, language variety identification has enjoyed heightened popularity as an advanced task of <a href=https://en.wikipedia.org/wiki/Language_identification>language identification</a>. The proposed <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> uses additional texts from a <a href=https://en.wikipedia.org/wiki/Social_network>social network</a> to improve language variety identification from two perspectives. First, they are used to introduce the effects of <a href=https://en.wikipedia.org/wiki/Homophily>homophily</a>. Secondly, they are used as expanded training data for shared layers of the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. By introducing information from <a href=https://en.wikipedia.org/wiki/List_of_social_networking_websites>social networks</a>, the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> improved its <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> by 1.67-5.56. Compared to state-of-the-art baselines, these improved performances are better in <a href=https://en.wikipedia.org/wiki/English_language>English</a> and comparable in <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>. Furthermore, we analyzed the cases of <a href=https://en.wikipedia.org/wiki/Portuguese_language>Portuguese</a> and <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a> when the model showed weak performances, and found that the effect of <a href=https://en.wikipedia.org/wiki/Homophily>homophily</a> is likely to be weak due to sparsity and noises compared to languages with the strong performances.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2046.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2046 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2046 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2046/>Boosting Neural Machine Translation</a></strong><br><a href=/people/d/dakun-zhang/>Dakun Zhang</a>
|
<a href=/people/j/jungi-kim/>Jungi Kim</a>
|
<a href=/people/j/josep-m-crego/>Josep Crego</a>
|
<a href=/people/j/jean-senellart/>Jean Senellart</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2046><div class="card-body p-3 small">Training efficiency is one of the main problems for Neural Machine Translation (NMT). Deep networks need for very large data as well as many training iterations to achieve state-of-the-art performance. This results in very high <a href=https://en.wikipedia.org/wiki/Computational_cost>computation cost</a>, slowing down research and industrialisation. In this paper, we propose to alleviate this problem with several training methods based on data boosting and <a href=https://en.wikipedia.org/wiki/Bootstrapping_(statistics)>bootstrap</a> with no modifications to the <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a>. It imitates the learning process of humans, which typically spend more time when learning difficult concepts than easier ones. We experiment on an English-French translation task showing accuracy improvements of up to 1.63 BLEU while saving 20 % of training time.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2048.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2048 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2048 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2048/>Utilizing Lexical Similarity between Related, Low-resource Languages for Pivot-based SMT<span class=acl-fixed-case>SMT</span></a></strong><br><a href=/people/a/anoop-kunchukuttan/>Anoop Kunchukuttan</a>
|
<a href=/people/m/maulik-shah/>Maulik Shah</a>
|
<a href=/people/p/pradyot-prakash/>Pradyot Prakash</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2048><div class="card-body p-3 small">We investigate pivot-based translation between related languages in a low resource, phrase-based SMT setting. We show that a subword-level pivot-based SMT model using a related pivot language is substantially better than word and morpheme-level pivot models. It is also highly competitive with the best direct translation model, which is encouraging as no direct source-target training corpus is used. We also show that combining multiple related language pivot models can rival a direct translation model. Thus, the use of <a href=https://en.wikipedia.org/wiki/Subword>subwords</a> as translation units coupled with multiple related pivot languages can compensate for the lack of a direct parallel corpus.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2049.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2049 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2049 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2049/>Key-value Attention Mechanism for Neural Machine Translation</a></strong><br><a href=/people/h/hideya-mino/>Hideya Mino</a>
|
<a href=/people/m/masao-utiyama/>Masao Utiyama</a>
|
<a href=/people/e/eiichiro-sumita/>Eiichiro Sumita</a>
|
<a href=/people/t/takenobu-tokunaga/>Takenobu Tokunaga</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2049><div class="card-body p-3 small">In this paper, we propose a neural machine translation (NMT) with a key-value attention mechanism on the source-side encoder. The key-value attention mechanism separates the source-side content vector into two types of <a href=https://en.wikipedia.org/wiki/Computer_data_storage>memory</a> known as the key and the value. The <a href=https://en.wikipedia.org/wiki/Key_(cryptography)>key</a> is used for calculating the <a href=https://en.wikipedia.org/wiki/Attention>attention distribution</a>, and the <a href=https://en.wikipedia.org/wiki/Value_(computer_science)>value</a> is used for encoding the <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context representation</a>. Experiments on three different tasks indicate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms an NMT model with a conventional <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanism</a>. Furthermore, we perform experiments with a conventional NMT framework, in which a part of the initial value of a weight matrix is set to zero so that the matrix is as the same initial-state as the key-value attention mechanism. As a result, we obtain comparable results with the key-value attention mechanism without changing the <a href=https://en.wikipedia.org/wiki/Neural_circuit>network structure</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2054.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2054 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2054 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2054/>Building Large Chinese Corpus for <a href=https://en.wikipedia.org/wiki/Spoken_dialogue>Spoken Dialogue</a> Research in Specific Domains<span class=acl-fixed-case>C</span>hinese Corpus for Spoken Dialogue Research in Specific Domains</a></strong><br><a href=/people/c/changliang-li/>Changliang Li</a>
|
<a href=/people/x/xiuying-wang/>Xiuying Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2054><div class="card-body p-3 small">Corpus is a valuable resource for <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval</a> and data-driven natural language processing systems, especially for spoken dialogue research in specific domains. However, there is little non-English corpora, particular for ones in <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>. Spoken by the nation with the largest population in the world, <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a> become increasingly prevalent and popular among millions of people worldwide. In this paper, we build a large-scale and high-quality Chinese corpus, called CSDC (Chinese Spoken Dialogue Corpus). It contains five domains and more than 140 thousand dialogues in all. Each sentence in this <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> is annotated with slot information additionally compared to other <a href=https://en.wikipedia.org/wiki/Text_corpus>corpora</a>. To our best knowledge, this is the largest Chinese spoken dialogue corpus, as well as the first one with slot information. With this <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>, we proposed a method and did a well-designed experiment. The indicative result is reported at last.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2055.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2055 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2055 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2055/>Identifying Speakers and Listeners of Quoted Speech in Literary Works</a></strong><br><a href=/people/c/chak-yan-yeung/>Chak Yan Yeung</a>
|
<a href=/people/j/john-s-y-lee/>John Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2055><div class="card-body p-3 small">We present the first study that evaluates both speaker and listener identification for direct speech in literary texts. Our approach consists of two steps : identification of speakers and listeners near the quotes, and dialogue chain segmentation. Evaluation results show that this approach outperforms a rule-based approach that is state-of-the-art on a corpus of literary texts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2059.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2059 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2059 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2059/>CVBed : Structuring CVs usingWord Embeddings<span class=acl-fixed-case>CVB</span>ed: Structuring <span class=acl-fixed-case>CV</span>s using<span class=acl-fixed-case>W</span>ord Embeddings</a></strong><br><a href=/people/s/shweta-garg/>Shweta Garg</a>
|
<a href=/people/s/sudhanshu-s-singh/>Sudhanshu S Singh</a>
|
<a href=/people/a/abhijit-mishra/>Abhijit Mishra</a>
|
<a href=/people/k/kuntal-dey/>Kuntal Dey</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2059><div class="card-body p-3 small">Automatic analysis of curriculum vitae (CVs) of applicants is of tremendous importance in recruitment scenarios. The semi-structuredness of <a href=https://en.wikipedia.org/wiki/Curriculum_vitae>CVs</a>, however, makes CV processing a challenging task. We propose a solution towards transforming CVs to follow a unified structure, thereby, paving ways for smoother CV analysis. The problem of <a href=https://en.wikipedia.org/wiki/Restructuring>restructuring</a> is posed as a section relabeling problem, where each section of a given <a href=https://en.wikipedia.org/wiki/Document_type_definition>CV</a> gets reassigned to a predefined label. Our relabeling method relies on semantic relatedness computed between section header, content and labels, based on phrase-embeddings learned from a large pool of <a href=https://en.wikipedia.org/wiki/Curriculum_vitae>CVs</a>. We follow different <a href=https://en.wikipedia.org/wiki/Heuristic>heuristics</a> to measure <a href=https://en.wikipedia.org/wiki/Semantic_similarity>semantic relatedness</a>. Our best <a href=https://en.wikipedia.org/wiki/Heuristics_in_judgment_and_decision-making>heuristic</a> achieves an <a href=https://en.wikipedia.org/wiki/F-score>F-score</a> of 93.17 % on a test dataset with <a href=https://en.wikipedia.org/wiki/Gold_standard_(test)>gold-standard labels</a> obtained using manual annotation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2060.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2060 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2060 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/I17-2060.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/I17-2060.Datasets.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file-archive"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/I17-2060/>Leveraging Diverse Lexical Chains to Construct Essays for Chinese College Entrance Examination<span class=acl-fixed-case>C</span>hinese College Entrance Examination</a></strong><br><a href=/people/l/liunian-li/>Liunian Li</a>
|
<a href=/people/x/xiaojun-wan/>Xiaojun Wan</a>
|
<a href=/people/j/jin-ge-yao/>Jin-ge Yao</a>
|
<a href=/people/s/siming-yan/>Siming Yan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2060><div class="card-body p-3 small">In this work we study the challenging task of automatically constructing essays for Chinese college entrance examination where the topic is specified in advance. We explore a sentence extraction framework based on diversified lexical chains to capture <a href=https://en.wikipedia.org/wiki/Coherence_(linguistics)>coherence</a> and richness. Experimental analysis shows the effectiveness of our approach and reveals the importance of information richness in essay writing.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2061.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2061 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2061 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2061/>Draw and Tell : Multimodal Descriptions Outperform Verbal- or Sketch-Only Descriptions in an Image Retrieval Task</a></strong><br><a href=/people/t/ting-han/>Ting Han</a>
|
<a href=/people/d/david-schlangen/>David Schlangen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2061><div class="card-body p-3 small">While <a href=https://en.wikipedia.org/wiki/Language>language</a> conveys meaning largely symbolically, actual communication acts typically contain iconic elements as well : People gesture while they speak, or may even draw sketches while explaining something. Image retrieval prima facie seems like a task that could profit from combined symbolic and iconic reference, but it is typically set up to work either from <a href=https://en.wikipedia.org/wiki/Language>language</a> only, or via (iconic) sketches with no verbal contribution. Using a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model of grounded language semantics</a> and a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model of sketch-to-image mapping</a>, we show that adding even very reduced iconic information to a verbal image description improves <a href=https://en.wikipedia.org/wiki/Recall_(memory)>recall</a>. Verbal descriptions paired with fully detailed sketches still perform better than these <a href=https://en.wikipedia.org/wiki/Sketch_comedy>sketches</a> alone. We see these results as supporting the assumption that <a href=https://en.wikipedia.org/wiki/Natural_user_interface>natural user interfaces</a> should respond to <a href=https://en.wikipedia.org/wiki/Multimodal_interaction>multimodal input</a>, where possible, rather than just <a href=https://en.wikipedia.org/wiki/Natural_language_processing>language</a> alone.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2062.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2062 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2062 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2062/>Grammatical Error Correction with Neural Reinforcement Learning</a></strong><br><a href=/people/k/keisuke-sakaguchi/>Keisuke Sakaguchi</a>
|
<a href=/people/m/matt-post/>Matt Post</a>
|
<a href=/people/b/benjamin-van-durme/>Benjamin Van Durme</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2062><div class="card-body p-3 small">We propose a neural encoder-decoder model with <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning (NRL)</a> for grammatical error correction (GEC). Unlike conventional <a href=https://en.wikipedia.org/wiki/Maximum_likelihood_estimation>maximum likelihood estimation (MLE)</a>, the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> directly optimizes towards an objective that considers a sentence-level, task-specific evaluation metric, avoiding the exposure bias issue in <a href=https://en.wikipedia.org/wiki/Maximum_likelihood_estimation>MLE</a>. We demonstrate that NRL outperforms <a href=https://en.wikipedia.org/wiki/Machine_learning>MLE</a> both in human and automated evaluation metrics, achieving the state-of-the-art on a fluency-oriented GEC corpus.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2063.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2063 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2063 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2063/>Coreference Resolution on Math Problem Text in Japanese<span class=acl-fixed-case>J</span>apanese</a></strong><br><a href=/people/t/takumi-ito/>Takumi Ito</a>
|
<a href=/people/t/takuya-matsuzaki/>Takuya Matsuzaki</a>
|
<a href=/people/s/satoshi-sato/>Satoshi Sato</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2063><div class="card-body p-3 small">This paper describes a coreference resolution system for math problem text. Case frame dictionaries and a math taxonomy are utilized for supplying <a href=https://en.wikipedia.org/wiki/Domain_knowledge>domain knowledge</a>. The <a href=https://en.wikipedia.org/wiki/System>system</a> deals with various <a href=https://en.wikipedia.org/wiki/Anaphora_(linguistics)>anaphoric phenomena</a> beyond well-studied entity coreferences.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2064.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2064 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2064 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2064/>Utilizing Visual Forms of Japanese Characters for Neural Review Classification<span class=acl-fixed-case>J</span>apanese Characters for Neural Review Classification</a></strong><br><a href=/people/y/yota-toyama/>Yota Toyama</a>
|
<a href=/people/m/makoto-miwa/>Makoto Miwa</a>
|
<a href=/people/y/yutaka-sasaki/>Yutaka Sasaki</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2064><div class="card-body p-3 small">We propose a novel method that exploits visual information of ideograms and logograms in analyzing Japanese review documents. Our method first converts font images of Japanese characters into <a href=https://en.wikipedia.org/wiki/Character_encoding>character embeddings</a> using <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>convolutional neural networks</a>. It then constructs document embeddings from the character embeddings based on Hierarchical Attention Networks, which represent the documents based on attention mechanisms from a character level to a sentence level. The document embeddings are finally used to predict the labels of documents. Our method provides a way to exploit visual features of characters in languages with <a href=https://en.wikipedia.org/wiki/Ideogram>ideograms</a> and <a href=https://en.wikipedia.org/wiki/Logogram>logograms</a>. In the experiments, our method achieved an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> comparable to a character embedding-based model while our method has much fewer parameters since it does not need to keep embeddings of thousands of characters.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2065.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2065 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2065 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2065/>A Multi-task Learning Approach to Adapting Bilingual Word Embeddings for Cross-lingual Named Entity Recognition</a></strong><br><a href=/people/d/dingquan-wang/>Dingquan Wang</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a>
|
<a href=/people/k/kevin-duh/>Kevin Duh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2065><div class="card-body p-3 small">We show how to adapt bilingual word embeddings (BWE&#8217;s) to bootstrap a cross-lingual name-entity recognition (NER) system in a language with no labeled data. We assume a setting where we are given a comparable corpus with NER labels for the source language only ; our goal is to build a <a href=https://en.wikipedia.org/wiki/NER_model>NER model</a> for the target language. The proposed multi-task model jointly trains bilingual word embeddings while optimizing a NER objective. This creates <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> that are both shared between languages and fine-tuned for the NER task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2068.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2068 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2068 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2068/>CWIG3G2-Complex Word Identification Task across Three Text Genres and Two User Groups<span class=acl-fixed-case>CWIG</span>3<span class=acl-fixed-case>G</span>2 - Complex Word Identification Task across Three Text Genres and Two User Groups</a></strong><br><a href=/people/s/seid-muhie-yimam/>Seid Muhie Yimam</a>
|
<a href=/people/s/sanja-stajner/>Sanja Štajner</a>
|
<a href=/people/m/martin-riedl/>Martin Riedl</a>
|
<a href=/people/c/chris-biemann/>Chris Biemann</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2068><div class="card-body p-3 small">Complex word identification (CWI) is an important task in <a href=https://en.wikipedia.org/wiki/Accessibility>text accessibility</a>. However, due to the scarcity of CWI datasets, previous studies have only addressed this problem on Wikipedia sentences and have solely taken into account the needs of non-native English speakers. We collect a new CWI dataset (CWIG3G2) covering three text genres News, WikiNews, and Wikipedia) annotated by both native and non-native English speakers. Unlike previous <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, we cover <a href=https://en.wikipedia.org/wiki/Phrase>single words</a>, as well as <a href=https://en.wikipedia.org/wiki/Phrase>complex phrases</a>, and present them for judgment in a paragraph context. We present the first study on cross-genre and cross-group CWI, showing measurable influences in native language and genre types.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2069.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2069 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2069 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/I17-2069.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/I17-2069/>Generating Stylistically Consistent Dialog Responses with Transfer Learning</a></strong><br><a href=/people/r/reina-akama/>Reina Akama</a>
|
<a href=/people/k/kazuaki-inada/>Kazuaki Inada</a>
|
<a href=/people/n/naoya-inoue/>Naoya Inoue</a>
|
<a href=/people/s/sosuke-kobayashi/>Sosuke Kobayashi</a>
|
<a href=/people/k/kentaro-inui/>Kentaro Inui</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2069><div class="card-body p-3 small">We propose a novel, data-driven, and stylistically consistent dialog response generation system. To create a user-friendly system, it is crucial to make generated responses not only appropriate but also stylistically consistent. For leaning both the properties effectively, our proposed <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> has two training stages inspired by <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a>. First, we train the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to generate appropriate responses, and then we ensure that the responses have a specific style. Experimental results demonstrate that the proposed method produces stylistically consistent responses while maintaining the appropriateness of the responses learned in a general domain.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2071.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2071 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2071 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2071/>Towards Abstractive Multi-Document Summarization Using Submodular Function-Based Framework, Sentence Compression and Merging</a></strong><br><a href=/people/y/yllias-chali/>Yllias Chali</a>
|
<a href=/people/m/moin-tanvee/>Moin Tanvee</a>
|
<a href=/people/m/mir-tafseer-nayeem/>Mir Tafseer Nayeem</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2071><div class="card-body p-3 small">We propose a submodular function-based summarization system which integrates three important measures namely importance, coverage, and non-redundancy to detect the important sentences for the summary. We design monotone and submodular functions which allow us to apply an efficient and scalable <a href=https://en.wikipedia.org/wiki/Greedy_algorithm>greedy algorithm</a> to obtain informative and well-covered summaries. In addition, we integrate two abstraction-based methods namely sentence compression and merging for generating an abstractive sentence set. We design our summarization models for both generic and query-focused summarization. Experimental results on DUC-2004 and DUC-2007 datasets show that our generic and query-focused summarizers have outperformed the state-of-the-art summarization systems in terms of ROUGE-1 and ROUGE-2 recall and <a href=https://en.wikipedia.org/wiki/F-measure>F-measure</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2072.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2072 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2072 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2072/>Domain Adaptation for <a href=https://en.wikipedia.org/wiki/Relation_extraction>Relation Extraction</a> with Domain Adversarial Neural Network</a></strong><br><a href=/people/l/lisheng-fu/>Lisheng Fu</a>
|
<a href=/people/t/thien-huu-nguyen/>Thien Huu Nguyen</a>
|
<a href=/people/b/bonan-min/>Bonan Min</a>
|
<a href=/people/r/ralph-grishman/>Ralph Grishman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2072><div class="card-body p-3 small">Relations are expressed in many domains such as <a href=https://en.wikipedia.org/wiki/News_agency>newswire</a>, <a href=https://en.wikipedia.org/wiki/Blog>weblogs</a> and phone conversations. Trained on a source domain, a relation extractor&#8217;s performance degrades when applied to target domains other than the source. A common yet labor-intensive method for <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> is to construct a target-domain-specific labeled dataset for adapting the extractor. In response, we present an unsupervised domain adaptation method which only requires labels from the source domain. Our method is a joint model consisting of a CNN-based relation classifier and a domain-adversarial classifier. The two <a href=https://en.wikipedia.org/wiki/Component-based_software_engineering>components</a> are optimized jointly to learn a domain-independent representation for <a href=https://en.wikipedia.org/wiki/Prediction>prediction</a> on the target domain. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> on all three test domains of ACE 2005.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2073.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2073 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2073 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2073/>Lexical Simplification with the Deep Structured Similarity Model</a></strong><br><a href=/people/l/lis-pereira/>Lis Pereira</a>
|
<a href=/people/x/xiaodong-liu/>Xiaodong Liu</a>
|
<a href=/people/j/john-s-y-lee/>John Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2073><div class="card-body p-3 small">We explore the application of a Deep Structured Similarity Model (DSSM) to <a href=https://en.wikipedia.org/wiki/Ranking>ranking</a> in <a href=https://en.wikipedia.org/wiki/Lexical_simplification>lexical simplification</a>. Our results show that the DSSM can effectively capture fine-grained features to perform <a href=https://en.wikipedia.org/wiki/Semantic_matching>semantic matching</a> when ranking substitution candidates, outperforming the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> on two standard <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> used for the task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2074.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2074 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2074 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/I17-2074/>Proofread Sentence Generation as Multi-Task Learning with Editing Operation Prediction</a></strong><br><a href=/people/y/yuta-hitomi/>Yuta Hitomi</a>
|
<a href=/people/h/hideaki-tamori/>Hideaki Tamori</a>
|
<a href=/people/n/naoaki-okazaki/>Naoaki Okazaki</a>
|
<a href=/people/k/kentaro-inui/>Kentaro Inui</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2074><div class="card-body p-3 small">This paper explores the idea of robot editors, automated proofreaders that enable journalists to improve the quality of their articles. We propose a novel neural model of multi-task learning that both generates proofread sentences and predicts the editing operations required to rewrite the source sentences and create the proofread ones. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is trained using logs of the revisions made professional editors revising draft newspaper articles written by journalists. Experiments demonstrate the effectiveness of our multi-task learning approach and the potential value of using revision logs for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/I17-2076.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-I17-2076 data-toggle=collapse aria-expanded=false aria-controls=abstract-I17-2076 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/I17-2076.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=I17-2076" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/I17-2076/>Deriving Consensus for Multi-Parallel Corpora : an English Bible Study<span class=acl-fixed-case>E</span>nglish <span class=acl-fixed-case>B</span>ible Study</a></strong><br><a href=/people/p/patrick-xia/>Patrick Xia</a>
|
<a href=/people/d/david-yarowsky/>David Yarowsky</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-I17-2076><div class="card-body p-3 small">What can you do with multiple noisy versions of the same text? We present a <a href=https://en.wikipedia.org/wiki/Scientific_method>method</a> which generates a single <a href=https://en.wikipedia.org/wiki/Consensus_decision-making>consensus</a> between multi-parallel corpora. By maximizing a function of linguistic features between word pairs, we jointly learn a single corpus-wide multiway alignment : a <a href=https://en.wikipedia.org/wiki/Consensus_decision-making>consensus</a> between 27 versions of the <a href=https://en.wikipedia.org/wiki/Bible_translations_into_English>English Bible</a>. We additionally produce English paraphrases, word-level distributions of tags, and consensus dependency parses. Our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> is language independent and applicable to any multi-parallel corpora. Given the Bible&#8217;s unique role as alignable bitext for over 800 of the world&#8217;s languages, this consensus alignment and resulting resources offer value for multilingual annotation projection, and also shed potential insights into the Bible itself.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>