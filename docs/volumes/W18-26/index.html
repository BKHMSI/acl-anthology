<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the Workshop on Machine Reading for Question Answering - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/W18-26.pdf>Proceedings of the Workshop on Machine Reading for Question Answering</a></h2><p class=lead><a href=/people/e/eunsol-choi/>Eunsol Choi</a>,
<a href=/people/m/minjoon-seo/>Minjoon Seo</a>,
<a href=/people/d/danqi-chen/>Danqi Chen</a>,
<a href=/people/r/robin-jia/>Robin Jia</a>,
<a href=/people/j/jonathan-berant/>Jonathan Berant</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>W18-26</dd><dt>Month:</dt><dd>July</dd><dt>Year:</dt><dd>2018</dd><dt>Address:</dt><dd>Melbourne, Australia</dd><dt>Venues:</dt><dd><a href=/venues/acl/>ACL</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/W18-26>https://aclanthology.org/W18-26</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/W18-26.pdf>https://aclanthology.org/W18-26.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/W18-26.pdf title="Open PDF of 'Proceedings of the Workshop on Machine Reading for Question Answering'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+Workshop+on+Machine+Reading+for+Question+Answering" title="Search for 'Proceedings of the Workshop on Machine Reading for Question Answering' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-2600.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-2600/>Proceedings of the Workshop on Machine Reading for Question Answering</a></strong><br><a href=/people/e/eunsol-choi/>Eunsol Choi</a>
|
<a href=/people/m/minjoon-seo/>Minjoon Seo</a>
|
<a href=/people/d/danqi-chen/>Danqi Chen</a>
|
<a href=/people/r/robin-jia/>Robin Jia</a>
|
<a href=/people/j/jonathan-berant/>Jonathan Berant</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-2601.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-2601 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-2601 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-2601/>Ruminating Reader : Reasoning with Gated Multi-hop Attention</a></strong><br><a href=/people/y/yichen-gong/>Yichen Gong</a>
|
<a href=/people/s/samuel-bowman/>Samuel Bowman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-2601><div class="card-body p-3 small">To answer the question in machine comprehension (MC) task, the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> need to establish the interaction between the question and the context. To tackle the problem that the single-pass model can not reflect on and correct its answer, we present Ruminating Reader. Ruminating Reader adds a second pass of attention and a novel information fusion component to the Bi-Directional Attention Flow model (BiDAF). We propose novel layer structures that construct a query aware context vector representation and fuse encoding representation with intermediate representation on top of BiDAF model. We show that a multi-hop attention mechanism can be applied to a bi-directional attention structure. In experiments on SQuAD, we find that the Reader outperforms the BiDAF baseline by 2.1 <a href=https://en.wikipedia.org/wiki/F1_score>F1 score</a> and 2.7 EM score. Our analysis shows that different hops of the attention have different responsibilities in selecting answers.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-2603.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-2603 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-2603 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-2603/>A Multi-Stage Memory Augmented Neural Network for Machine Reading Comprehension</a></strong><br><a href=/people/s/seunghak-yu/>Seunghak Yu</a>
|
<a href=/people/s/sathish-reddy-indurthi/>Sathish Reddy Indurthi</a>
|
<a href=/people/s/seohyun-back/>Seohyun Back</a>
|
<a href=/people/h/haejun-lee/>Haejun Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-2603><div class="card-body p-3 small">Reading Comprehension (RC) of text is one of the fundamental tasks in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. In recent years, several end-to-end neural network models have been proposed to solve RC tasks. However, most of these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> suffer in reasoning over long documents. In this work, we propose a novel Memory Augmented Machine Comprehension Network (MAMCN) to address long-range dependencies present in machine reading comprehension. We perform extensive experiments to evaluate proposed method with the renowned benchmark datasets such as SQuAD, QUASAR-T, and TriviaQA. We achieve the state of the art performance on both the document-level (QUASAR-T, TriviaQA) and paragraph-level (SQuAD) datasets compared to all the previously published approaches.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-2606.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-2606 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-2606 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W18-2606" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W18-2606/>Robust and Scalable Differentiable Neural Computer for <a href=https://en.wikipedia.org/wiki/Question_answering>Question Answering</a></a></strong><br><a href=/people/j/jorg-franke/>JÃ¶rg Franke</a>
|
<a href=/people/j/jan-niehues/>Jan Niehues</a>
|
<a href=/people/a/alex-waibel/>Alex Waibel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-2606><div class="card-body p-3 small">Deep learning models are often not easily adaptable to new <a href=https://en.wikipedia.org/wiki/Computational_complexity_theory>tasks</a> and require task-specific adjustments. The differentiable neural computer (DNC), a memory-augmented neural network, is designed as a general problem solver which can be used in a wide range of tasks. But in reality, it is hard to apply this <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to new <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. We analyze the DNC and identify possible improvements within the application of <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>. This motivates a more robust and scalable DNC (rsDNC). The objective precondition is to keep the general character of this <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> intact while making its application more reliable and speeding up its required training time. The rsDNC is distinguished by a more robust training, a slim memory unit and a bidirectional architecture. We not only achieve new state-of-the-art performance on the bAbI task, but also minimize the performance variance between different initializations. Furthermore, we demonstrate the simplified applicability of the rsDNC to new <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a> with passable results on the CNN RC task without adaptions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-2610.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-2610 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-2610 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-2610/>Comparative Analysis of Neural QA models on SQuAD<span class=acl-fixed-case>QA</span> models on <span class=acl-fixed-case>SQ</span>u<span class=acl-fixed-case>AD</span></a></strong><br><a href=/people/s/soumya-wadhwa/>Soumya Wadhwa</a>
|
<a href=/people/k/khyathi-chandu/>Khyathi Chandu</a>
|
<a href=/people/e/eric-nyberg/>Eric Nyberg</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-2610><div class="card-body p-3 small">The task of <a href=https://en.wikipedia.org/wiki/Question_answering>Question Answering</a> has gained prominence in the past few decades for testing the ability of machines to understand <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>. Large datasets for <a href=https://en.wikipedia.org/wiki/Machine_reading>Machine Reading</a> have led to the development of neural models that cater to deeper language understanding compared to <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval tasks</a>. Different <a href=https://en.wikipedia.org/wiki/Component-based_software_engineering>components</a> in these neural architectures are intended to tackle different challenges. As a first step towards achieving generalization across multiple domains, we attempt to understand and compare the peculiarities of existing end-to-end neural models on the Stanford Question Answering Dataset (SQuAD) by performing quantitative as well as qualitative analysis of the results attained by each of them. We observed that prediction errors reflect certain model-specific biases, which we further discuss in this paper.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W18-2611.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W18-2611 data-toggle=collapse aria-expanded=false aria-controls=abstract-W18-2611 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W18-2611/>Adaptations of ROUGE and BLEU to Better Evaluate Machine Reading Comprehension Task<span class=acl-fixed-case>ROUGE</span> and <span class=acl-fixed-case>BLEU</span> to Better Evaluate Machine Reading Comprehension Task</a></strong><br><a href=/people/a/an-yang/>An Yang</a>
|
<a href=/people/k/kai-liu/>Kai Liu</a>
|
<a href=/people/j/jing-liu/>Jing Liu</a>
|
<a href=/people/y/yajuan-lyu/>Yajuan Lyu</a>
|
<a href=/people/s/sujian-li/>Sujian Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W18-2611><div class="card-body p-3 small">Current evaluation metrics to <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a> based machine reading comprehension (MRC) systems generally focus on the lexical overlap between candidate and reference answers, such as ROUGE and <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>. However, bias may appear when these <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> are used for specific question types, especially questions inquiring yes-no opinions and entity lists. In this paper, we make adaptations on the <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> to better correlate n-gram overlap with the <a href=https://en.wikipedia.org/wiki/Judgement>human judgment</a> for answers to these two question types. Statistical analysis proves the effectiveness of our <a href=https://en.wikipedia.org/wiki/Scientific_method>approach</a>. Our adaptations may provide positive guidance for the development of real-scene MRC systems.<tex-math>n</tex-math>-gram overlap with the human judgment for answers to these two question types. Statistical analysis proves the effectiveness of our approach. Our adaptations may provide positive guidance for the development of real-scene MRC systems.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>