<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the First Workshop on Scholarly Document Processing - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Proceedings of the First Workshop on Scholarly Document Processing</h2><p class=lead><a href=/people/m/muthu-kumar-chandrasekaran/>Muthu Kumar Chandrasekaran</a>,
<a href=/people/a/anita-de-waard/>Anita de Waard</a>,
<a href=/people/g/guy-feigenblat/>Guy Feigenblat</a>,
<a href=/people/d/dayne-freitag/>Dayne Freitag</a>,
<a href=/people/t/tirthankar-ghosal/>Tirthankar Ghosal</a>,
<a href=/people/e/eduard-hovy/>Eduard Hovy</a>,
<a href=/people/p/petr-knoth/>Petr Knoth</a>,
<a href=/people/d/david-konopnicki/>David Konopnicki</a>,
<a href=/people/p/philipp-mayr/>Philipp Mayr</a>,
<a href=/people/r/robert-m-patton/>Robert M. Patton</a>,
<a href=/people/m/michal-shmueli-scheuer/>Michal Shmueli-Scheuer</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2020.sdp-1</dd><dt>Month:</dt><dd>November</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Online</dd><dt>Venues:</dt><dd><a href=/venues/emnlp/>EMNLP</a>
| <a href=/venues/sdp/>sdp</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.sdp-1>https://aclanthology.org/2020.sdp-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+First+Workshop+on+Scholarly+Document+Processing" title="Search for 'Proceedings of the First Workshop on Scholarly Document Processing' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sdp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sdp-1.0/>Proceedings of the First Workshop on Scholarly Document Processing</a></strong><br><a href=/people/m/muthu-kumar-chandrasekaran/>Muthu Kumar Chandrasekaran</a>
|
<a href=/people/a/anita-de-waard/>Anita de Waard</a>
|
<a href=/people/g/guy-feigenblat/>Guy Feigenblat</a>
|
<a href=/people/d/dayne-freitag/>Dayne Freitag</a>
|
<a href=/people/t/tirthankar-ghosal/>Tirthankar Ghosal</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a>
|
<a href=/people/p/petr-knoth/>Petr Knoth</a>
|
<a href=/people/d/david-konopnicki/>David Konopnicki</a>
|
<a href=/people/p/philipp-mayr/>Philipp Mayr</a>
|
<a href=/people/r/robert-m-patton/>Robert M. Patton</a>
|
<a href=/people/m/michal-shmueli-scheuer/>Michal Shmueli-Scheuer</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sdp-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sdp-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sdp-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sdp-1.2/>The future of <a href=https://en.wikipedia.org/wiki/ArXiv>arXiv</a> and <a href=https://en.wikipedia.org/wiki/Discovery_(observation)>knowledge discovery</a> in open science<span class=acl-fixed-case>X</span>iv and knowledge discovery in open science</a></strong><br><a href=/people/s/steinn-sigurdsson/>Steinn Sigurdsson</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sdp-1--2><div class="card-body p-3 small">arXiv, the preprint server for the physical and mathematical sciences, is in its third decade of operation. As the flow of new, open access research increases inexorably, the challenges to keep up with and discover research content also become greater. I will discuss the status and future of <a href=https://en.wikipedia.org/wiki/ArXiv>arXiv</a>, and possibilities and plans to make more effective use of the research database to enhance ongoing research efforts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sdp-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sdp-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sdp-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38940712 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.sdp-1.3" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.sdp-1.3/>Acknowledgement Entity Recognition in CORD-19 Papers<span class=acl-fixed-case>CORD</span>-19 Papers</a></strong><br><a href=/people/j/jian-wu/>Jian Wu</a>
|
<a href=/people/p/pei-wang/>Pei Wang</a>
|
<a href=/people/x/xin-wei/>Xin Wei</a>
|
<a href=/people/s/sarah-rajtmajer/>Sarah Rajtmajer</a>
|
<a href=/people/c/c-lee-giles/>C. Lee Giles</a>
|
<a href=/people/c/christopher-griffin/>Christopher Griffin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sdp-1--3><div class="card-body p-3 small">Acknowledgements are ubiquitous in <a href=https://en.wikipedia.org/wiki/Academic_publishing>scholarly papers</a>. Existing acknowledgement entity recognition methods assume all named entities are acknowledged. Here, we examine the nuances between acknowledged and named entities by analyzing <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence structure</a>. We develop an acknowledgement extraction system, AckExtract based on open-source text mining software and evaluate our method using manually labeled data. AckExtract uses the PDF of a scholarly paper as input and outputs <a href=https://en.wikipedia.org/wiki/Acknowledgement_(data_networks)>acknowledgement entities</a>. Results show an overall performance of F_1=0.92. We built a supplementary database by linking CORD-19 papers with acknowledgement entities extracted by AckExtract including persons and organizations and find that only up to 5060 % of named entities are actually acknowledged. We further analyze chronological trends of acknowledgement entities in CORD-19 papers. All codes and labeled data are publicly available at https://github.com/lamps-lab/ackextract.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sdp-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sdp-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sdp-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38940716 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.sdp-1.7" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.sdp-1.7/>Effective <a href=https://en.wikipedia.org/wiki/Distributed_representation>distributed representations</a> for academic expert search</a></strong><br><a href=/people/m/mark-berger/>Mark Berger</a>
|
<a href=/people/j/jakub-zavrel/>Jakub Zavrel</a>
|
<a href=/people/p/paul-groth/>Paul Groth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sdp-1--7><div class="card-body p-3 small">Expert search aims to find and rank experts based on a user&#8217;s query. In <a href=https://en.wikipedia.org/wiki/Academy>academia</a>, retrieving experts is an efficient way to navigate through a large amount of <a href=https://en.wikipedia.org/wiki/Outline_of_academic_disciplines>academic knowledge</a>. Here, we study how different distributed representations of academic papers (i.e. embeddings) impact academic expert retrieval. We use the Microsoft Academic Graph dataset and experiment with different configurations of a document-centric voting model for retrieval. In particular, we explore the impact of the use of contextualized embeddings on <a href=https://en.wikipedia.org/wiki/Web_search_engine>search</a> performance. We also present results for paper embeddings that incorporate <a href=https://en.wikipedia.org/wiki/Citation>citation information</a> through <a href=https://en.wikipedia.org/wiki/Retrofitting>retrofitting</a>. Additionally, experiments are conducted using different <a href=https://en.wikipedia.org/wiki/Scientific_technique>techniques</a> for assigning author weights based on <a href=https://en.wikipedia.org/wiki/Author_order>author order</a>. We observe that using contextual embeddings produced by a transformer model trained for sentence similarity tasks produces the most effective paper representations for document-centric expert retrieval. However, retrofitting the paper embeddings and using elaborate author contribution weighting strategies did not improve retrieval performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sdp-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sdp-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sdp-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38940727 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.sdp-1.14/>Multi-task Peer-Review Score Prediction</a></strong><br><a href=/people/j/jiyi-li/>Jiyi Li</a>
|
<a href=/people/a/ayaka-sato/>Ayaka Sato</a>
|
<a href=/people/k/kazuya-shimura/>Kazuya Shimura</a>
|
<a href=/people/f/fumiyo-fukumoto/>Fumiyo Fukumoto</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sdp-1--14><div class="card-body p-3 small">Automatic prediction on the peer-review aspect scores of <a href=https://en.wikipedia.org/wiki/Academic_publishing>academic papers</a> can be a useful assistant tool for both reviewers and authors. To handle the small size of published datasets on the target aspect of scores, we propose a multi-task approach to leverage additional information from other aspects of scores for improving the performance of the target. Because one of the problems of building multi-task models is how to select the proper resources of auxiliary tasks and how to select the proper shared structures. We propose a multi-task shared structure encoding approach which automatically selects good shared network structures as well as good auxiliary resources. The experiments based on peer-review datasets show that our approach is effective and has better performance on the target scores than the single-task method and naive multi-task methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sdp-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sdp-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sdp-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38940725 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.sdp-1.15" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.sdp-1.15/>ERLKG : Entity Representation Learning and Knowledge Graph based association analysis of COVID-19 through mining of unstructured biomedical corpora<span class=acl-fixed-case>ERLKG</span>: Entity Representation Learning and Knowledge Graph based association analysis of <span class=acl-fixed-case>COVID</span>-19 through mining of unstructured biomedical corpora</a></strong><br><a href=/people/s/sayantan-basu/>Sayantan Basu</a>
|
<a href=/people/s/sinchani-chakraborty/>Sinchani Chakraborty</a>
|
<a href=/people/a/atif-hassan/>Atif Hassan</a>
|
<a href=/people/s/sana-siddique/>Sana Siddique</a>
|
<a href=/people/a/ashish-anand/>Ashish Anand</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sdp-1--15><div class="card-body p-3 small">We introduce a generic, human-out-of-the-loop pipeline, ERLKG, to perform rapid association analysis of any biomedical entity with other existing entities from a corpora of the same domain. Our pipeline consists of a Knowledge Graph (KG) created from the Open Source CORD-19 dataset by fully automating the procedure of <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction</a> using SciBERT. The best latent entity representations are then found by benchnmarking different KG embedding techniques on the task of link prediction using a Graph Convolution Network Auto Encoder (GCN-AE). We demonstrate the utility of ERLKG with respect to COVID-19 through multiple qualitative evaluations. Due to the lack of a gold standard, we propose a relatively large intrinsic evaluation dataset for COVID-19 and use it for validating the top two performing KG embedding techniques. We find TransD to be the best performing KG embedding technique with Pearson and Spearman correlation scores of 0.4348 and 0.4570 respectively. We demonstrate that a considerable number of ERLKG&#8217;s top protein, chemical and disease predictions are currently in consideration for COVID-19 related research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sdp-1.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sdp-1--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sdp-1.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.sdp-1.21" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.sdp-1.21/>Scaling Systematic Literature Reviews with Machine Learning Pipelines</a></strong><br><a href=/people/s/seraphina-goldfarb-tarrant/>Seraphina Goldfarb-Tarrant</a>
|
<a href=/people/a/alexander-robertson/>Alexander Robertson</a>
|
<a href=/people/j/jasmina-lazic/>Jasmina Lazic</a>
|
<a href=/people/t/theodora-tsouloufi/>Theodora Tsouloufi</a>
|
<a href=/people/l/louise-donnison/>Louise Donnison</a>
|
<a href=/people/k/karen-smyth/>Karen Smyth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sdp-1--21><div class="card-body p-3 small">Systematic reviews, which entail the extraction of data from large numbers of scientific documents, are an ideal avenue for the application of <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning</a>. They are vital to many fields of science and philanthropy, but are very time-consuming and require experts. Yet the three main stages of a <a href=https://en.wikipedia.org/wiki/Systematic_review>systematic review</a> are easily done automatically : searching for documents can be done via <a href=https://en.wikipedia.org/wiki/Application_programming_interface>APIs</a> and scrapers, selection of relevant documents can be done via <a href=https://en.wikipedia.org/wiki/Binary_classification>binary classification</a>, and extraction of data can be done via sequence-labelling classification. Despite the promise of automation for this field, little research exists that examines the various ways to automate each of these <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. We construct a <a href=https://en.wikipedia.org/wiki/Pipeline_(software)>pipeline</a> that automates each of these aspects, and experiment with many human-time vs. system quality trade-offs. We test the ability of <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> to work well on small amounts of data and to generalise to data from countries not represented in the training data. We test different types of <a href=https://en.wikipedia.org/wiki/Data_extraction>data extraction</a> with varying difficulty in <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a>, and five different neural architectures to do the <a href=https://en.wikipedia.org/wiki/Data_extraction>extraction</a>. We find that we can get surprising <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and generalisability of the whole <a href=https://en.wikipedia.org/wiki/Pipeline_(software)>pipeline system</a> with only 2 weeks of human-expert annotation, which is only 15 % of the time it takes to do the whole review manually and can be repeated and extended to new data with no additional effort.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sdp-1.22.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sdp-1--22 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sdp-1.22 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.sdp-1.22.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38940724 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.sdp-1.22" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.sdp-1.22/>Document-Level Definition Detection in Scholarly Documents : Existing Models, Error Analyses, and Future Directions</a></strong><br><a href=/people/d/dongyeop-kang/>Dongyeop Kang</a>
|
<a href=/people/a/andrew-head/>Andrew Head</a>
|
<a href=/people/r/risham-sidhu/>Risham Sidhu</a>
|
<a href=/people/k/kyle-lo/>Kyle Lo</a>
|
<a href=/people/d/daniel-s-weld/>Daniel Weld</a>
|
<a href=/people/m/marti-a-hearst/>Marti A. Hearst</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sdp-1--22><div class="card-body p-3 small">The task of definition detection is important for <a href=https://en.wikipedia.org/wiki/Academic_publishing>scholarly papers</a>, because papers often make use of <a href=https://en.wikipedia.org/wiki/Jargon>technical terminology</a> that may be unfamiliar to readers. Despite prior work on definition detection, current approaches are far from being accurate enough to use in realworld applications. In this paper, we first perform in-depth error analysis of the current best performing definition detection system and discover major causes of errors. Based on this analysis, we develop a new definition detection system, HEDDEx, that utilizes syntactic features, transformer encoders, and <a href=https://en.wikipedia.org/wiki/Heuristic_(computer_science)>heuristic filters</a>, and evaluate it on a standard sentence-level benchmark. Because current <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmarks</a> evaluate <a href=https://en.wikipedia.org/wiki/Sampling_(statistics)>randomly sampled sentences</a>, we propose an alternative <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation</a> that assesses every sentence within a document. This allows for evaluating <a href=https://en.wikipedia.org/wiki/Recall_(memory)>recall</a> in addition to <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a>. HEDDEx outperforms the leading system on both the sentence-level and the document-level tasks, by 12.7 F1 points and 14.4 F1 points, respectively. We note that performance on the high-recall document-level task is much lower than in the standard evaluation approach, due to the necessity of incorporation of document structure as <a href=https://en.wikipedia.org/wiki/Software_feature>features</a>. We discuss remaining challenges in document-level definition detection, ideas for improvements, and potential issues for the development of reading aid applications.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sdp-1.23.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sdp-1--23 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sdp-1.23 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sdp-1.23/>A New Neural Search and Insights Platform for Navigating and Organizing AI Research<span class=acl-fixed-case>AI</span> Research</a></strong><br><a href=/people/m/marzieh-fadaee/>Marzieh Fadaee</a>
|
<a href=/people/o/olga-gureenkova/>Olga Gureenkova</a>
|
<a href=/people/f/fernando-rejon-barrera/>Fernando Rejon Barrera</a>
|
<a href=/people/c/carsten-schnober/>Carsten Schnober</a>
|
<a href=/people/w/wouter-weerkamp/>Wouter Weerkamp</a>
|
<a href=/people/j/jakub-zavrel/>Jakub Zavrel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sdp-1--23><div class="card-body p-3 small">To provide AI researchers with modern tools for dealing with the explosive growth of the research literature in their field, we introduce a new platform, AI Research Navigator, that combines classical <a href=https://en.wikipedia.org/wiki/Keyword_search>keyword search</a> with neural retrieval to discover and organize relevant literature. The system provides <a href=https://en.wikipedia.org/wiki/Search_engine_technology>search</a> at multiple levels of textual granularity, from sentences to aggregations across documents, both in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language</a> and through navigation in a domain specific Knowledge Graph. We give an overview of the overall architecture of the system and of the components for document analysis, <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>, <a href=https://en.wikipedia.org/wiki/Search_engine_technology>search</a>, <a href=https://en.wikipedia.org/wiki/Analytics>analytics</a>, expert search, and recommendations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sdp-1.24.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sdp-1--24 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sdp-1.24 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sdp-1.24/>Overview and Insights from the Shared Tasks at Scholarly Document Processing 2020 : CL-SciSumm, LaySumm and LongSumm<span class=acl-fixed-case>CL</span>-<span class=acl-fixed-case>S</span>ci<span class=acl-fixed-case>S</span>umm, <span class=acl-fixed-case>L</span>ay<span class=acl-fixed-case>S</span>umm and <span class=acl-fixed-case>L</span>ong<span class=acl-fixed-case>S</span>umm</a></strong><br><a href=/people/m/muthu-kumar-chandrasekaran/>Muthu Kumar Chandrasekaran</a>
|
<a href=/people/g/guy-feigenblat/>Guy Feigenblat</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a>
|
<a href=/people/a/abhilasha-ravichander/>Abhilasha Ravichander</a>
|
<a href=/people/m/michal-shmueli-scheuer/>Michal Shmueli-Scheuer</a>
|
<a href=/people/a/anita-de-waard/>Anita de Waard</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sdp-1--24><div class="card-body p-3 small">We present the results of three Shared Tasks held at the Scholarly Document Processing Workshop at EMNLP2020 : CL-SciSumm, LaySumm and LongSumm. We report on each of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>, which received 18 submissions in total, with some submissions addressing two or three of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. In summary, the quality and quantity of the submissions show that there is ample interest in scholarly document summarization, and the state of the art in this domain is at a midway point between being an impossible task and one that is fully resolved.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sdp-1.32.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sdp-1--32 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sdp-1.32 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sdp-1.32/>Team MLU@CL-SciSumm20 : Methods for Computational Linguistics Scientific Citation Linkage<span class=acl-fixed-case>MLU</span>@<span class=acl-fixed-case>CL</span>-<span class=acl-fixed-case>S</span>ci<span class=acl-fixed-case>S</span>umm20: Methods for Computational Linguistics Scientific Citation Linkage</a></strong><br><a href=/people/r/rong-huang/>Rong Huang</a>
|
<a href=/people/k/kseniia-krylova/>Kseniia Krylova</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sdp-1--32><div class="card-body p-3 small">This paper describes our approach to the CL-SciSumm 2020 shared task toward the problem of identifying reference span of the citing article in the referred article. In Task 1a, we apply and compare different methods in combination with similarity scores to identify spans of the reference text for the given citance. In Task 1b, we use a <a href=https://en.wikipedia.org/wiki/Logistic_regression>logistic regression</a> to classifying the discourse facets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sdp-1.36.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sdp-1--36 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sdp-1.36 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sdp-1.36/>ARTU / TU Wien and Artificial Researcher@ LongSumm 20<span class=acl-fixed-case>ARTU</span> / <span class=acl-fixed-case>TU</span> <span class=acl-fixed-case>W</span>ien and Artificial Researcher@ <span class=acl-fixed-case>L</span>ong<span class=acl-fixed-case>S</span>umm 20</a></strong><br><a href=/people/a/alaa-el-ebshihy/>Alaa El-Ebshihy</a>
|
<a href=/people/a/annisa-maulida-ningtyas/>Annisa Maulida Ningtyas</a>
|
<a href=/people/l/linda-andersson/>Linda Andersson</a>
|
<a href=/people/f/florina-piroi/>Florina Piroi</a>
|
<a href=/people/a/andreas-rauber/>Andreas Rauber</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sdp-1--36><div class="card-body p-3 small">In this paper, we present our approach to solve the LongSumm 2020 Shared Task, at the 1st Workshop on Scholarly Document Processing. The objective of the long summaries task is to generate long summaries that cover salient information in <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific articles</a>. The task is to generate abstractive and extractive summaries of a given <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific article</a>. In the proposed approach, we are inspired by the concept of Argumentative Zoning (AZ) that de- fines the main rhetorical structure in scientific articles. We define two aspects that should be covered in scientific paper summary, namely Claim / Method and Conclusion / Result aspects. We use Solr index to expand the sentences of the paper abstract. We formulate each abstract sentence in a given publication as query to retrieve similar sentences from the text body of the document itself. We utilize a sentence selection algorithm described in previous literature to select sentences for the final summary that covers the two aforementioned aspects.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sdp-1.40.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sdp-1--40 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sdp-1.40 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.sdp-1.40.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.sdp-1.40" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.sdp-1.40/>Divide and Conquer : From <a href=https://en.wikipedia.org/wiki/Complexity>Complexity</a> to <a href=https://en.wikipedia.org/wiki/Simplicity>Simplicity</a> for Lay Summarization</a></strong><br><a href=/people/r/rochana-chaturvedi/>Rochana Chaturvedi</a>
|
<a href=/people/s/saachi/>Saachi .</a>
|
<a href=/people/j/jaspreet-singh-dhani/>Jaspreet Singh Dhani</a>
|
<a href=/people/a/anurag-joshi/>Anurag Joshi</a>
|
<a href=/people/a/ankush-khanna/>Ankush Khanna</a>
|
<a href=/people/n/neha-tomar/>Neha Tomar</a>
|
<a href=/people/s/swagata-duari/>Swagata Duari</a>
|
<a href=/people/a/alka-khurana/>Alka Khurana</a>
|
<a href=/people/v/vasudha-bhatnagar/>Vasudha Bhatnagar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sdp-1--40><div class="card-body p-3 small">We describe our approach for the 1st Computational Linguistics Lay Summary Shared Task CL-LaySumm20. The task is to produce non-technical summaries of scholarly documents. The summary should be within easy grasp of a layman who may not be well versed with the domain of the research article. We propose a two step divide-and-conquer approach. First, we judiciously select segments of the documents that are not overly pedantic and are likely to be of interest to the laity, and over-extract sentences from each segment using an unsupervised network based method. Next, we perform abstractive summarization on these <a href=https://en.wikipedia.org/wiki/Abstraction_(computer_science)>extractions</a> and systematically merge the <a href=https://en.wikipedia.org/wiki/Abstraction_(computer_science)>abstractions</a>. We run ablation studies to establish that each step in our pipeline is critical for improvement in the quality of lay summary. Our approach leverages state-of-the-art pre-trained deep neural network based models as zero-shot learners to achieve high scores on the task.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>