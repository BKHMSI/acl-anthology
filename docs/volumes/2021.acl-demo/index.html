<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/2021.acl-demo.pdf>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations</a></h2><p class=lead><a href=/people/h/heng-ji/>Heng Ji</a>,
<a href=/people/j/jong-c-park/>Jong C. Park</a>,
<a href=/people/r/rui-xia/>Rui Xia</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2021.acl-demo</dd><dt>Month:</dt><dd>August</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Online</dd><dt>Venues:</dt><dd><a href=/venues/acl/>ACL</a>
| <a href=/venues/ijcnlp/>IJCNLP</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.acl-demo>https://aclanthology.org/2021.acl-demo</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2021.acl-demo.pdf>https://aclanthology.org/2021.acl-demo.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2021.acl-demo.pdf title="Open PDF of 'Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+59th+Annual+Meeting+of+the+Association+for+Computational+Linguistics+and+the+11th+International+Joint+Conference+on+Natural+Language+Processing%3A+System+Demonstrations" title="Search for 'Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-demo.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-demo.0/>Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing: System Demonstrations</a></strong><br><a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/j/jong-c-park/>Jong C. Park</a>
|
<a href=/people/r/rui-xia/>Rui Xia</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-demo.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-demo--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-demo.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-demo.2/>IntelliCAT : Intelligent Machine Translation Post-Editing with Quality Estimation and Translation Suggestion<span class=acl-fixed-case>I</span>ntelli<span class=acl-fixed-case>CAT</span>: Intelligent Machine Translation Post-Editing with Quality Estimation and Translation Suggestion</a></strong><br><a href=/people/d/dongjun-lee/>Dongjun Lee</a>
|
<a href=/people/j/junhyeong-ahn/>Junhyeong Ahn</a>
|
<a href=/people/h/heesoo-park/>Heesoo Park</a>
|
<a href=/people/j/jaemin-jo/>Jaemin Jo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-demo--2><div class="card-body p-3 small">We present IntelliCAT, an interactive translation interface with neural models that streamline the post-editing process on machine translation output. We leverage two quality estimation (QE) models at different granularities : sentence-level QE, to predict the quality of each machine-translated sentence, and word-level QE, to locate the parts of the machine-translated sentence that need correction. Additionally, we introduce a novel translation suggestion model conditioned on both the left and right contexts, providing alternatives for specific words or phrases for correction. Finally, with word alignments, IntelliCAT automatically preserves the original document&#8217;s styles in the translated document. The experimental results show that <a href=https://en.wikipedia.org/wiki/Post-editing>post-editing</a> based on the proposed QE and translation suggestions can significantly improve translation quality. Furthermore, a user study reveals that three <a href=https://en.wikipedia.org/wiki/Software_feature>features</a> provided in IntelliCAT significantly accelerate the <a href=https://en.wikipedia.org/wiki/Post-editing>post-editing task</a>, achieving a 52.9 % speedup in translation time compared to translating from scratch. The interface is publicly available at https://intellicat.beringlab.com/.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-demo.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-demo--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-demo.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-demo.4" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-demo.4/>TextBox : A Unified, Modularized, and Extensible Framework for Text Generation<span class=acl-fixed-case>T</span>ext<span class=acl-fixed-case>B</span>ox: A Unified, Modularized, and Extensible Framework for Text Generation</a></strong><br><a href=/people/j/junyi-li/>Junyi Li</a>
|
<a href=/people/t/tianyi-tang/>Tianyi Tang</a>
|
<a href=/people/g/gaole-he/>Gaole He</a>
|
<a href=/people/j/jinhao-jiang/>Jinhao Jiang</a>
|
<a href=/people/x/xiaoxuan-hu/>Xiaoxuan Hu</a>
|
<a href=/people/p/puzhao-xie/>Puzhao Xie</a>
|
<a href=/people/z/zhipeng-chen/>Zhipeng Chen</a>
|
<a href=/people/z/zhuohao-yu/>Zhuohao Yu</a>
|
<a href=/people/w/wayne-xin-zhao/>Wayne Xin Zhao</a>
|
<a href=/people/j/ji-rong-wen/>Ji-Rong Wen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-demo--4><div class="card-body p-3 small">In this paper, we release an open-source library, called <a href=https://en.wikipedia.org/wiki/TextBox>TextBox</a>, to provide a unified, modularized, and extensible text generation framework. TextBox aims to support a broad set of text generation tasks and models. In our <a href=https://en.wikipedia.org/wiki/Library_(computing)>library</a>, we implement 21 text generation models on 9 benchmark datasets, covering the categories of VAE, GAN, and pretrained language models. Meanwhile, our <a href=https://en.wikipedia.org/wiki/Library_(computing)>library</a> maintains sufficient modularity and extensibility by properly decomposing the model architecture, <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference</a>, and learning process into highly reusable modules, which allows users to easily incorporate new models into our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a>. The above features make <a href=https://en.wikipedia.org/wiki/TextBox>TextBox</a> especially suitable for researchers and practitioners to quickly reproduce baseline models and develop new <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. TextBox is implemented based on <a href=https://en.wikipedia.org/wiki/PyTorch>PyTorch</a>, and released under Apache License 2.0 at the link.<url>https://github.com/RUCAIBox/TextBox</url>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-demo.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-demo--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-demo.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-demo.5/>Inside ASCENT : Exploring a Deep Commonsense Knowledge Base and its Usage in Question Answering<span class=acl-fixed-case>ASCENT</span>: Exploring a Deep Commonsense Knowledge Base and its Usage in Question Answering</a></strong><br><a href=/people/t/tuan-phong-nguyen/>Tuan-Phong Nguyen</a>
|
<a href=/people/s/simon-razniewski/>Simon Razniewski</a>
|
<a href=/people/g/gerhard-weikum/>Gerhard Weikum</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-demo--5><div class="card-body p-3 small">ASCENT is a fully automated methodology for extracting and consolidating commonsense assertions from web contents (Nguyen et al., 2021). It advances traditional triple-based commonsense knowledge representation by capturing semantic facets like locations and purposes, and <a href=https://en.wikipedia.org/wiki/Compound_(linguistics)>composite concepts</a>, i.e., subgroups and related aspects of subjects. In this demo, we present a <a href=https://en.wikipedia.org/wiki/Web_portal>web portal</a> that allows users to understand its construction process, explore its content, and observe its impact in the use case of <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>. The demo website (https://ascent.mpi-inf.mpg.de) and an introductory video (https://youtu.be/qMkJXqu_Yd4) are both available online.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-demo.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-demo--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-demo.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-demo.7" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-demo.7/>NeurST : Neural Speech Translation Toolkit<span class=acl-fixed-case>N</span>eur<span class=acl-fixed-case>ST</span>: Neural Speech Translation Toolkit</a></strong><br><a href=/people/c/chengqi-zhao/>Chengqi Zhao</a>
|
<a href=/people/m/mingxuan-wang/>Mingxuan Wang</a>
|
<a href=/people/q/qianqian-dong/>Qianqian Dong</a>
|
<a href=/people/r/rong-ye/>Rong Ye</a>
|
<a href=/people/l/lei-li/>Lei Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-demo--7><div class="card-body p-3 small">NeurST is an open-source toolkit for neural speech translation. The <a href=https://en.wikipedia.org/wiki/List_of_toolkits>toolkit</a> mainly focuses on end-to-end speech translation, which is easy to use, modify, and extend to advanced speech translation research and products. NeurST aims at facilitating the speech translation research for NLP researchers and building reliable <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmarks</a> for this field. It provides step-by-step recipes for <a href=https://en.wikipedia.org/wiki/Feature_extraction>feature extraction</a>, <a href=https://en.wikipedia.org/wiki/Data_preprocessing>data preprocessing</a>, distributed training, and <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation</a>. In this paper, we will introduce the framework design of NeurST and show experimental results for different benchmark datasets, which can be regarded as reliable baselines for future research. The <a href=https://en.wikipedia.org/wiki/List_of_toolkits>toolkit</a> is publicly available at and we will continuously update the performance of with other counterparts and studies at.<url>https://github.com/bytedance/neurst</url> and we will continuously update the performance of with other counterparts and studies at <url>https://st-benchmark.github.io/</url>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-demo.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-demo--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-demo.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-demo.9/>MT-Telescope : An interactive platform for contrastive evaluation of MT systems<span class=acl-fixed-case>MT</span>-<span class=acl-fixed-case>T</span>elescope: <span class=acl-fixed-case>A</span>n interactive platform for contrastive evaluation of <span class=acl-fixed-case>MT</span> systems</a></strong><br><a href=/people/r/ricardo-rei/>Ricardo Rei</a>
|
<a href=/people/a/ana-c-farinha/>Ana C Farinha</a>
|
<a href=/people/c/craig-stewart/>Craig Stewart</a>
|
<a href=/people/l/luisa-coheur/>Luisa Coheur</a>
|
<a href=/people/a/alon-lavie/>Alon Lavie</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-demo--9><div class="card-body p-3 small">We present MT-Telescope, a visualization platform designed to facilitate comparative analysis of the output quality of two Machine Translation (MT) systems. While automated MT evaluation metrics are commonly used to evaluate MT systems at a corpus-level, our platform supports fine-grained segment-level analysis and interactive visualisations that expose the fundamental differences in the performance of the compared systems. MT-Telescope also supports dynamic corpus filtering to enable focused analysis on specific phenomena such as ; translation of named entities, handling of terminology, and the impact of input segment length on translation quality. Furthermore, the <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a> provides a bootstrapped t-test for <a href=https://en.wikipedia.org/wiki/Statistical_significance>statistical significance</a> as a means of evaluating the rigor of the resulting system ranking. MT-Telescope is open source, written in <a href=https://en.wikipedia.org/wiki/Python_(programming_language)>Python</a>, and is built around a user friendly and dynamic web interface. Complementing other existing tools, our platform is designed to facilitate and promote the broader adoption of more rigorous analysis practices in the evaluation of MT quality.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-demo.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-demo--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-demo.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-demo.11" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-demo.11/>CogIE : An Information Extraction Toolkit for Bridging Texts and CogNet<span class=acl-fixed-case>C</span>og<span class=acl-fixed-case>IE</span>: An Information Extraction Toolkit for Bridging Texts and <span class=acl-fixed-case>C</span>og<span class=acl-fixed-case>N</span>et</a></strong><br><a href=/people/z/zhuoran-jin/>Zhuoran Jin</a>
|
<a href=/people/y/yubo-chen/>Yubo Chen</a>
|
<a href=/people/d/dianbo-sui/>Dianbo Sui</a>
|
<a href=/people/c/chenhao-wang/>Chenhao Wang</a>
|
<a href=/people/z/zhipeng-xue/>Zhipeng Xue</a>
|
<a href=/people/j/jun-zhao/>Jun Zhao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-demo--11><div class="card-body p-3 small">CogNet is a <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge base</a> that integrates three types of knowledge : <a href=https://en.wikipedia.org/wiki/Linguistics>linguistic knowledge</a>, <a href=https://en.wikipedia.org/wiki/World_knowledge>world knowledge</a> and commonsense knowledge. In this paper, we propose an information extraction toolkit, called CogIE, which is a bridge connecting raw texts and CogNet. CogIE has three features : versatile, knowledge-grounded and extensible. First, CogIE is a versatile toolkit with a rich set of functional modules, including <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>, entity typing, entity linking, relation extraction, event extraction and frame-semantic parsing. Second, as a knowledge-grounded toolkit, CogIE can ground the extracted facts to CogNet and leverage different types of knowledge to enrich extracted results. Third, for <a href=https://en.wikipedia.org/wiki/Extensibility>extensibility</a>, owing to the design of <a href=https://en.wikipedia.org/wiki/Multitier_architecture>three-tier architecture</a>, CogIE is not only a plug-and-play toolkit for developers but also an extensible programming framework for researchers. We release an open-access online system to visually extract information from texts. Source code, datasets and pre-trained models are publicly available at GitHub, with a short instruction video.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-demo.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-demo--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-demo.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-demo.12" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-demo.12/>fastHan : A BERT-based Multi-Task Toolkit for Chinese NLP<span class=acl-fixed-case>H</span>an: A <span class=acl-fixed-case>BERT</span>-based Multi-Task Toolkit for <span class=acl-fixed-case>C</span>hinese <span class=acl-fixed-case>NLP</span></a></strong><br><a href=/people/z/zhichao-geng/>Zhichao Geng</a>
|
<a href=/people/h/hang-yan/>Hang Yan</a>
|
<a href=/people/x/xipeng-qiu/>Xipeng Qiu</a>
|
<a href=/people/x/xuan-jing-huang/>Xuanjing Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-demo--12><div class="card-body p-3 small">We present fastHan, an open-source toolkit for four basic tasks in Chinese natural language processing : Chinese word segmentation (CWS), Part-of-Speech (POS) tagging, named entity recognition (NER), and dependency parsing. The backbone of fastHan is a multi-task model based on a pruned BERT, which uses the first 8 layers in BERT. We also provide a 4-layer base model compressed from the 8-layer model. The joint-model is trained and evaluated on 13 corpora of four tasks, yielding near state-of-the-art (SOTA) performance in dependency parsing and NER, achieving SOTA performance in CWS and POS. Besides, fastHan&#8217;s transferability is also strong, performing much better than popular segmentation tools on a <a href=https://en.wikipedia.org/wiki/Text_corpus>non-training corpus</a>. To better meet the need of practical application, we allow users to use their own labeled data to further fine-tune fastHan. In addition to its small size and excellent performance, fastHan is user-friendly. Implemented as a <a href=https://en.wikipedia.org/wiki/Python_(programming_language)>python package</a>, fastHan isolates users from the internal technical details and is convenient to use. The project is released on Github.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-demo.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-demo--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-demo.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-demo.13/>Erase and Rewind : Manual Correction of NLP Output through a Web Interface<span class=acl-fixed-case>NLP</span> Output through a Web Interface</a></strong><br><a href=/people/v/valentino-frasnelli/>Valentino Frasnelli</a>
|
<a href=/people/l/lorenzo-bocchi/>Lorenzo Bocchi</a>
|
<a href=/people/a/alessio-palmero-aprosio/>Alessio Palmero Aprosio</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-demo--13><div class="card-body p-3 small">In this paper, we present Tintful, an NLP annotation software that can be used both to manually annotate texts and to fix mistakes in NLP pipelines, such as Stanford CoreNLP. Using a <a href=https://en.wikipedia.org/wiki/Paradigm>paradigm</a> similar to wiki-like systems, a user who notices some wrong annotation can easily fix it and submit the resulting (and right) entry back to the tool developers. Moreover, Tintful can be used to easily annotate data from scratch. The input documents do not need to be in a particular format : starting from the plain text, the sentences are first annotated with CoreNLP, then the user can edit the annotations and submit everything back through a user-friendly interface.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-demo.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-demo--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-demo.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><span class="align-middle mr-1" data-toggle=tooltip data-placement=bottom title="Best Demonstration Runner-up"><i class="fas fa-award"></i></span></span>
<span class=d-block><strong><a class=align-middle href=/2021.acl-demo.14/>ESRA : Explainable Scientific Research Assistant<span class=acl-fixed-case>ESRA</span>: Explainable Scientific Research Assistant</a></strong><br><a href=/people/p/pollawat-hongwimol/>Pollawat Hongwimol</a>
|
<a href=/people/p/peeranuth-kehasukcharoen/>Peeranuth Kehasukcharoen</a>
|
<a href=/people/p/pasit-laohawarutchai/>Pasit Laohawarutchai</a>
|
<a href=/people/p/piyawat-lertvittayakumjorn/>Piyawat Lertvittayakumjorn</a>
|
<a href=/people/a/aik-beng-ng/>Aik Beng Ng</a>
|
<a href=/people/z/zhangsheng-lai/>Zhangsheng Lai</a>
|
<a href=/people/t/timothy-liu/>Timothy Liu</a>
|
<a href=/people/p/peerapon-vateekul/>Peerapon Vateekul</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-demo--14><div class="card-body p-3 small">We introduce Explainable Scientific Research Assistant (ESRA), a literature discovery platform that augments search results with relevant details and explanations, aiding users in understanding more about their queries and the returned papers beyond existing literature search systems. Enabled by a knowledge graph we extracted from abstracts of 23k papers on the arXiv&#8217;s cs. CL category, ESRA provides three main features : explanation (for why a paper is returned to the user), list of facts (that are relevant to the query), and graph visualization (drawing connections between the query and each paper with surrounding related entities). The experimental results with humans involved show that ESRA can accelerate the users&#8217; search process with paper explanations and helps them better explore the landscape of the topics of interest by exploiting the underlying <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graph</a>. We provide the ESRA web application at http://esra.cp.eng.chula.ac.th/.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-demo.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-demo--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-demo.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-demo.17/>REM : Efficient Semi-Automated Real-Time Moderation of Online Forums<span class=acl-fixed-case>REM</span>: Efficient Semi-Automated Real-Time Moderation of Online Forums</a></strong><br><a href=/people/j/jakob-smedegaard-andersen/>Jakob Smedegaard Andersen</a>
|
<a href=/people/o/olaf-zukunft/>Olaf Zukunft</a>
|
<a href=/people/w/walid-maalej/>Walid Maalej</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-demo--17><div class="card-body p-3 small">This paper presents REM, a novel tool for the semi-automated real-time moderation of large scale online forums. The growing demand for <a href=https://en.wikipedia.org/wiki/Online_participation>online participation</a> and the increasing number of user comments raise challenges in filtering out harmful and undesirable content from <a href=https://en.wikipedia.org/wiki/Public_debate>public debates</a> in <a href=https://en.wikipedia.org/wiki/Internet_forum>online forums</a>. Since a manual moderation does not scale well and pure automated approaches often lack the required level of <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, we suggest a semi-automated moderation approach. Our approach maximizes the efficiency of manual efforts by targeting only those comments for which human intervention is needed, e.g. due to high <a href=https://en.wikipedia.org/wiki/Taxonomy_(biology)>classification uncertainty</a>. Our <a href=https://en.wikipedia.org/wiki/Tool>tool</a> offers a rich visual interactive environment enabling the exploration of online debates. We conduct a preliminary evaluation experiment to demonstrate the suitability of our approach and publicly release the source code of <a href=https://en.wikipedia.org/wiki/Rapid_eye_movement_sleep>REM</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-demo.19.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-demo--19 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-demo.19 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-demo.19/>A Graphical Interface for Curating Schemas</a></strong><br><a href=/people/p/piyush-mishra/>Piyush Mishra</a>
|
<a href=/people/a/akanksha-malhotra/>Akanksha Malhotra</a>
|
<a href=/people/s/susan-windisch-brown/>Susan Windisch Brown</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a>
|
<a href=/people/g/ghazaleh-kazeminejad/>Ghazaleh Kazeminejad</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-demo--19><div class="card-body p-3 small">Much past work has focused on extracting information like <a href=https://en.wikipedia.org/wiki/Event_(philosophy)>events</a>, <a href=https://en.wikipedia.org/wiki/Legal_person>entities</a>, and <a href=https://en.wikipedia.org/wiki/Interpersonal_relationship>relations</a> from <a href=https://en.wikipedia.org/wiki/Document>documents</a>. Very little work has focused on analyzing these results for better <a href=https://en.wikipedia.org/wiki/Mathematical_model>model understanding</a>. In this paper, we introduce a curation interface that takes an Information Extraction (IE) system&#8217;s output in a pre-defined format and generates a graphical representation of its elements. The <a href=https://en.wikipedia.org/wiki/User_interface>interface</a> supports editing while curating schemas for complex events like Improvised Explosive Device (IED) based scenarios. We identify various schemas that either have linear event chains or contain parallel events with complicated temporal ordering. We iteratively update an induced schema to uniquely identify events specific to it, add optional events around them, and prune unnecessary events. The resulting schemas are improved and enriched versions of the machine-induced versions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-demo.24.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-demo--24 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-demo.24 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-demo.24/>CLTR : An End-to-End, Transformer-Based System for Cell-Level Table Retrieval and Table Question Answering<span class=acl-fixed-case>CLTR</span>: An End-to-End, Transformer-Based System for Cell-Level Table Retrieval and Table Question Answering</a></strong><br><a href=/people/f/feifei-pan/>Feifei Pan</a>
|
<a href=/people/m/mustafa-canim/>Mustafa Canim</a>
|
<a href=/people/m/michael-glass/>Michael Glass</a>
|
<a href=/people/a/alfio-gliozzo/>Alfio Gliozzo</a>
|
<a href=/people/p/peter-fox/>Peter Fox</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-demo--24><div class="card-body p-3 small">We present the first end-to-end, transformer-based table question answering (QA) system that takes natural language questions and massive table corpora as inputs to retrieve the most relevant tables and locate the correct table cells to answer the question. Our system, CLTR, extends the current state-of-the-art QA over tables model to build an end-to-end table QA architecture. This <a href=https://en.wikipedia.org/wiki/System>system</a> has successfully tackled many real-world table QA problems with a simple, unified pipeline. Our proposed system can also generate a <a href=https://en.wikipedia.org/wiki/Heat_map>heatmap</a> of candidate columns and rows over complex tables and allow users to quickly identify the correct cells to answer questions. In addition, we introduce two new open domain benchmarks, E2E_WTQ and E2E_GNQ, consisting of 2,005 <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language questions</a> over 76,242 tables. The <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmarks</a> are designed to validate CLTR as well as accommodate future table retrieval and end-to-end table QA research and experiments. Our experiments demonstrate that our system is the current state-of-the-art model on the table retrieval task and produces promising results for end-to-end table QA.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-demo.26.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-demo--26 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-demo.26 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-demo.26" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-demo.26/>FastSeq : Make Sequence Generation Faster<span class=acl-fixed-case>F</span>ast<span class=acl-fixed-case>S</span>eq: Make Sequence Generation Faster</a></strong><br><a href=/people/y/yu-yan/>Yu Yan</a>
|
<a href=/people/f/fei-hu/>Fei Hu</a>
|
<a href=/people/j/jiusheng-chen/>Jiusheng Chen</a>
|
<a href=/people/n/nikhil-bhendawade/>Nikhil Bhendawade</a>
|
<a href=/people/t/ting-ye/>Ting Ye</a>
|
<a href=/people/y/yeyun-gong/>Yeyun Gong</a>
|
<a href=/people/n/nan-duan/>Nan Duan</a>
|
<a href=/people/d/desheng-cui/>Desheng Cui</a>
|
<a href=/people/b/bingyu-chi/>Bingyu Chi</a>
|
<a href=/people/r/ruofei-zhang/>Ruofei Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-demo--26><div class="card-body p-3 small">Transformer-based models have made tremendous impacts in <a href=https://en.wikipedia.org/wiki/Natural-language_generation>natural language generation</a>. However the inference speed is a bottleneck due to large model size and intensive computing involved in auto-regressive decoding process. We develop FastSeq framework to accelerate sequence generation without <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy loss</a>. The proposed optimization techniques include an attention cache optimization, an efficient <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> for detecting repeated n-grams, and an asynchronous generation pipeline with parallel I / O. These <a href=https://en.wikipedia.org/wiki/Optimizing_compiler>optimizations</a> are general enough to be applicable to Transformer-based models (e.g., T5, GPT2, and UniLM). Our benchmark results on a set of widely used and diverse <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> demonstrate 4-9x inference speed gain. Additionally, FastSeq is easy to use with a simple one-line code change. The source code is available at https://github.com/microsoft/fastseq.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-demo.30.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-demo--30 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-demo.30 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-demo.30" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-demo.30/>Ecco : An Open Source Library for the Explainability of Transformer Language Models</a></strong><br><a href=/people/j/j-alammar/>J Alammar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-demo--30><div class="card-body p-3 small">Our understanding of why Transformer-based NLP models have been achieving their recent success lags behind our ability to continue scaling these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. To increase the transparency of Transformer-based language models, we present Ecco an open-source library for the explainability of Transformer-based NLP models. Ecco provides a set of tools to capture, analyze, visualize, and interactively explore the inner mechanics of these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. This includes (1) gradient-based feature attribution for natural language generation (2) hidden states and their evolution between model layers (3) convenient access and examination tools for neuron activations in the under-explored Feed-Forward Neural Network sublayer of Transformer layers. (4) convenient examination of activation vectors via canonical correlation analysis (CCA), non-negative matrix factorization (NMF), and probing classifiers. We find that <a href=https://en.wikipedia.org/wiki/Syntax>syntactic information</a> can be retrieved from BERT&#8217;s FFNN representations in levels comparable to those in hidden state representations. More curiously, we find that the model builds up <a href=https://en.wikipedia.org/wiki/Syntax>syntactic information</a> in its hidden states even when intermediate FFNNs indicate diminished levels of <a href=https://en.wikipedia.org/wiki/Syntax>syntactic information</a>. Ecco is available at https://www.eccox.io/</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-demo.32.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-demo--32 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-demo.32 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-demo.32/>TweeNLP : A Twitter Exploration Portal for Natural Language Processing<span class=acl-fixed-case>T</span>wee<span class=acl-fixed-case>NLP</span>: A <span class=acl-fixed-case>T</span>witter Exploration Portal for Natural Language Processing</a></strong><br><a href=/people/v/viraj-shah/>Viraj Shah</a>
|
<a href=/people/s/shruti-singh/>Shruti Singh</a>
|
<a href=/people/m/mayank-singh/>Mayank Singh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-demo--32><div class="card-body p-3 small">We present TweeNLP, a one-stop portal that organizes Twitter&#8217;s natural language processing (NLP) data and builds a visualization and exploration platform. It curates 19,395 tweets (as of April 2021) from various NLP conferences and general NLP discussions. It supports multiple features such as TweetExplorer to explore tweets by topics, visualize insights from Twitter activity throughout the organization cycle of conferences, discover popular research papers and researchers. It also builds a timeline of conference and workshop submission deadlines. We envision TweeNLP to function as a collective memory unit for the NLP community by integrating the <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a> pertaining to research papers with the NLPExplorer scientific literature search engine. The current <a href=https://en.wikipedia.org/wiki/System>system</a> is hosted at http://nlpexplorer.org/twitter/CFP.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-demo.39.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-demo--39 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-demo.39 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-demo.39" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-demo.39/>ReTraCk : A Flexible and Efficient Framework for Knowledge Base Question Answering<span class=acl-fixed-case>R</span>e<span class=acl-fixed-case>T</span>ra<span class=acl-fixed-case>C</span>k: A Flexible and Efficient Framework for Knowledge Base Question Answering</a></strong><br><a href=/people/s/shuang-chen/>Shuang Chen</a>
|
<a href=/people/q/qian-liu/>Qian Liu</a>
|
<a href=/people/z/zhiwei-yu/>Zhiwei Yu</a>
|
<a href=/people/c/chin-yew-lin/>Chin-Yew Lin</a>
|
<a href=/people/j/jian-guang-lou/>Jian-Guang Lou</a>
|
<a href=/people/f/feng-jiang/>Feng Jiang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-demo--39><div class="card-body p-3 small">We present Retriever-Transducer-Checker (ReTraCk), a neural semantic parsing framework for large scale knowledge base question answering (KBQA). ReTraCk is designed as a <a href=https://en.wikipedia.org/wiki/Modular_programming>modular framework</a> to maintain high flexibility. It includes a retriever to retrieve relevant KB items efficiently, a transducer to generate <a href=https://en.wikipedia.org/wiki/Logical_form>logical form</a> with syntax correctness guarantees and a checker to improve transduction procedure. ReTraCk is ranked at top1 overall performance on the GrailQA leaderboard and obtains highly competitive performance on the typical WebQuestionsSP benchmark. Our <a href=https://en.wikipedia.org/wiki/System>system</a> can interact with users timely, demonstrating the efficiency of the proposed <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-demo.41.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-demo--41 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-demo.41 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.acl-demo.41/>TextFlint : Unified Multilingual Robustness Evaluation Toolkit for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a><span class=acl-fixed-case>T</span>ext<span class=acl-fixed-case>F</span>lint: Unified Multilingual Robustness Evaluation Toolkit for Natural Language Processing</a></strong><br><a href=/people/x/xiao-wang/>Xiao Wang</a>
|
<a href=/people/q/qin-liu/>Qin Liu</a>
|
<a href=/people/t/tao-gui/>Tao Gui</a>
|
<a href=/people/q/qi-zhang/>Qi Zhang</a>
|
<a href=/people/y/yicheng-zou/>Yicheng Zou</a>
|
<a href=/people/x/xin-zhou/>Xin Zhou</a>
|
<a href=/people/j/jiacheng-ye/>Jiacheng Ye</a>
|
<a href=/people/y/yongxin-zhang/>Yongxin Zhang</a>
|
<a href=/people/r/rui-zheng/>Rui Zheng</a>
|
<a href=/people/z/zexiong-pang/>Zexiong Pang</a>
|
<a href=/people/q/qinzhuo-wu/>Qinzhuo Wu</a>
|
<a href=/people/z/zhengyan-li/>Zhengyan Li</a>
|
<a href=/people/c/chong-zhang/>Chong Zhang</a>
|
<a href=/people/r/ruotian-ma/>Ruotian Ma</a>
|
<a href=/people/z/zichu-fei/>Zichu Fei</a>
|
<a href=/people/r/ruijian-cai/>Ruijian Cai</a>
|
<a href=/people/j/jun-zhao/>Jun Zhao</a>
|
<a href=/people/x/xingwu-hu/>Xingwu Hu</a>
|
<a href=/people/z/zhiheng-yan/>Zhiheng Yan</a>
|
<a href=/people/y/yiding-tan/>Yiding Tan</a>
|
<a href=/people/y/yuan-hu/>Yuan Hu</a>
|
<a href=/people/q/qiyuan-bian/>Qiyuan Bian</a>
|
<a href=/people/z/zhihua-liu/>Zhihua Liu</a>
|
<a href=/people/s/shan-qin/>Shan Qin</a>
|
<a href=/people/b/bolin-zhu/>Bolin Zhu</a>
|
<a href=/people/x/xiaoyu-xing/>Xiaoyu Xing</a>
|
<a href=/people/j/jinlan-fu/>Jinlan Fu</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a>
|
<a href=/people/m/minlong-peng/>Minlong Peng</a>
|
<a href=/people/x/xiaoqing-zheng/>Xiaoqing Zheng</a>
|
<a href=/people/y/yaqian-zhou/>Yaqian Zhou</a>
|
<a href=/people/z/zhongyu-wei/>Zhongyu Wei</a>
|
<a href=/people/x/xipeng-qiu/>Xipeng Qiu</a>
|
<a href=/people/x/xuan-jing-huang/>Xuanjing Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-demo--41><div class="card-body p-3 small">TextFlint is a multilingual robustness evaluation toolkit for NLP tasks that incorporates universal text transformation, task-specific transformation, adversarial attack, subpopulation, and their combinations to provide comprehensive robustness analyses. This enables practitioners to automatically evaluate their <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> from various aspects or to customize their evaluations as desired with just a few lines of code. TextFlint also generates complete analytical reports as well as targeted augmented data to address the shortcomings of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> in terms of its <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a>. To guarantee acceptability, all the text transformations are linguistically based and all the transformed data selected (up to 100,000 texts) scored highly under human evaluation. To validate the utility, we performed large-scale empirical evaluations (over 67,000) on state-of-the-art <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning models</a>, classic <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised methods</a>, and real-world systems. The toolkit is already available at https://github.com/textflint with all the evaluation results demonstrated at textflint.io.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.acl-demo.43.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--acl-demo--43 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.acl-demo.43 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.acl-demo.43" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.acl-demo.43/>OpenAttack : An Open-source Textual Adversarial Attack Toolkit<span class=acl-fixed-case>O</span>pen<span class=acl-fixed-case>A</span>ttack: An Open-source Textual Adversarial Attack Toolkit</a></strong><br><a href=/people/g/guoyang-zeng/>Guoyang Zeng</a>
|
<a href=/people/f/fanchao-qi/>Fanchao Qi</a>
|
<a href=/people/q/qianrui-zhou/>Qianrui Zhou</a>
|
<a href=/people/t/tingji-zhang/>Tingji Zhang</a>
|
<a href=/people/z/zixian-ma/>Zixian Ma</a>
|
<a href=/people/b/bairu-hou/>Bairu Hou</a>
|
<a href=/people/y/yuan-zang/>Yuan Zang</a>
|
<a href=/people/z/zhiyuan-liu/>Zhiyuan Liu</a>
|
<a href=/people/m/maosong-sun/>Maosong Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--acl-demo--43><div class="card-body p-3 small">Textual adversarial attacking has received wide and increasing attention in recent years. Various <a href=https://en.wikipedia.org/wiki/Attack_model>attack models</a> have been proposed, which are enormously distinct and implemented with different programming frameworks and settings. These facts hinder quick utilization and fair comparison of attack models. In this paper, we present an open-source textual adversarial attack toolkit named OpenAttack to solve these issues. Compared with existing other textual adversarial attack toolkits, OpenAttack has its unique strengths in support for all attack types, <a href=https://en.wikipedia.org/wiki/Multilinguality>multilinguality</a>, and <a href=https://en.wikipedia.org/wiki/Parallel_computing>parallel processing</a>. Currently, OpenAttack includes 15 typical attack models that cover all attack types. Its highly inclusive modular design not only supports quick utilization of existing attack models, but also enables great flexibility and extensibility. OpenAttack has broad uses including comparing and evaluating <a href=https://en.wikipedia.org/wiki/Attack_model>attack models</a>, measuring robustness of a model, assisting in developing new <a href=https://en.wikipedia.org/wiki/Attack_model>attack models</a>, and <a href=https://en.wikipedia.org/wiki/Adversarial_system>adversarial training</a>. Source code and documentation can be obtained at https://github.com/thunlp/OpenAttack.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>