<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/N18-3.pdf>Proceedings of the 2018 Conference of the North <span class=acl-fixed-case>A</span>merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)</a></h2><p class=lead><a href=/people/s/srinivas-bangalore/>Srinivas Bangalore</a>,
<a href=/people/j/jennifer-chu-carroll/>Jennifer Chu-Carroll</a>,
<a href=/people/y/yunyao-li/>Yunyao Li</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>N18-3</dd><dt>Month:</dt><dd>June</dd><dt>Year:</dt><dd>2018</dd><dt>Address:</dt><dd>New Orleans - Louisiana</dd><dt>Venue:</dt><dd><a href=/venues/naacl/>NAACL</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/N18-3>https://aclanthology.org/N18-3</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/N18-3 title="To the current version of the paper by DOI">10.18653/v1/N18-3</a></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/N18-3.pdf>https://aclanthology.org/N18-3.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/N18-3.pdf title="Open PDF of 'Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+2018+Conference+of+the+North+American+Chapter+of+the+Association+for+Computational+Linguistics%3A+Human+Language+Technologies%2C+Volume+3+%28Industry+Papers%29" title="Search for 'Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-3000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-3000/>Proceedings of the 2018 Conference of the North <span class=acl-fixed-case>A</span>merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)</a></strong><br><a href=/people/s/srinivas-bangalore/>Srinivas Bangalore</a>
|
<a href=/people/j/jennifer-chu-carroll/>Jennifer Chu-Carroll</a>
|
<a href=/people/y/yunyao-li/>Yunyao Li</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-3001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-3001 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-3001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277630837 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-3001/>Scalable Wide and Deep Learning for Computer Assisted Coding</a></strong><br><a href=/people/m/marilisa-amoia/>Marilisa Amoia</a>
|
<a href=/people/f/frank-diehl/>Frank Diehl</a>
|
<a href=/people/j/jesus-gimenez/>Jesus Gimenez</a>
|
<a href=/people/j/joel-pinto/>Joel Pinto</a>
|
<a href=/people/r/raphael-schumann/>Raphael Schumann</a>
|
<a href=/people/f/fabian-stemmer/>Fabian Stemmer</a>
|
<a href=/people/p/paul-vozila/>Paul Vozila</a>
|
<a href=/people/y/yi-zhang/>Yi Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-3001><div class="card-body p-3 small">In recent years the use of <a href=https://en.wikipedia.org/wiki/Electronic_health_record>electronic medical records</a> has accelerated resulting in large volumes of medical data when a patient visits a healthcare facility. As a first step towards reimbursement healthcare institutions need to associate ICD-10 billing codes to these documents. This is done by trained clinical coders who may use a computer assisted solution for shortlisting of codes. In this work, we present our work to build a machine learning based scalable system for predicting <a href=https://en.wikipedia.org/wiki/ICD-10>ICD-10 codes</a> from <a href=https://en.wikipedia.org/wiki/Electronic_health_record>electronic medical records</a>. We address data imbalance issues by implementing two <a href=https://en.wikipedia.org/wiki/Systems_architecture>system architectures</a> using <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>convolutional neural networks</a> and <a href=https://en.wikipedia.org/wiki/Logistic_regression>logistic regression models</a>. We illustrate the pros and cons of those system designs and show that the best performance can be achieved by leveraging the advantages of both using a system combination approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-3003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-3003 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-3003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277630853 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-3003/>A Scalable Neural Shortlisting-Reranking Approach for Large-Scale Domain Classification in Natural Language Understanding</a></strong><br><a href=/people/y/young-bum-kim/>Young-Bum Kim</a>
|
<a href=/people/d/dongchan-kim/>Dongchan Kim</a>
|
<a href=/people/j/joo-kyung-kim/>Joo-Kyung Kim</a>
|
<a href=/people/r/ruhi-sarikaya/>Ruhi Sarikaya</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-3003><div class="card-body p-3 small">Intelligent personal digital assistants (IPDAs), a popular real-life application with spoken language understanding capabilities, can cover potentially thousands of overlapping domains for <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a>, and the task of finding the best domain to handle an utterance becomes a challenging problem on a large scale. In this paper, we propose a set of efficient and scalable shortlisting-reranking neural models for effective large-scale domain classification for <a href=https://en.wikipedia.org/wiki/Intelligence_quotient>IPDAs</a>. The shortlisting stage focuses on efficiently trimming all domains down to a list of k-best candidate domains, and the reranking stage performs a list-wise reranking of the initial k-best domains with additional contextual information. We show the effectiveness of our <a href=https://en.wikipedia.org/wiki/Software_development_process>approach</a> with extensive experiments on 1,500 IPDA domains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-3005.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-3005 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-3005 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277631102 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-3005/>Data Collection for Dialogue System : A Startup Perspective</a></strong><br><a href=/people/y/yiping-kang/>Yiping Kang</a>
|
<a href=/people/y/yunqi-zhang/>Yunqi Zhang</a>
|
<a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a>
|
<a href=/people/l/lingjia-tang/>Lingjia Tang</a>
|
<a href=/people/j/jason-mars/>Jason Mars</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-3005><div class="card-body p-3 small">Industrial dialogue systems such as Apple Siri and Google Now rely on large scale diverse and robust training data to enable their sophisticated conversation capability. Crowdsourcing provides a scalable and inexpensive way of <a href=https://en.wikipedia.org/wiki/Data_collection>data collection</a> but collecting high quality data efficiently requires thoughtful orchestration of the crowdsourcing jobs. Prior study of this topic have focused on tasks only in the academia settings with limited scope or only provide intrinsic dataset analysis, lacking indication on how it affects the trained <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> performance. In this paper, we present a study of <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing methods</a> for a user intent classification task in our deployed <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue system</a>. Our <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> requires <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> of 47 possible user intents and contains many intent pairs with subtle differences. We consider different crowdsourcing job types and job prompts and analyze quantitatively the quality of the collected data and the downstream model performance on a test set of real user queries from production logs. Our observation provides insights into designing efficient crowdsourcing jobs and provide recommendations for future dialogue system data collection process.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-3006.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-3006 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-3006 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277631118 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-3006/>Bootstrapping a Neural Conversational Agent with Dialogue Self-Play, <a href=https://en.wikipedia.org/wiki/Crowdsourcing>Crowdsourcing</a> and <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>On-Line Reinforcement Learning</a></a></strong><br><a href=/people/p/pararth-shah/>Pararth Shah</a>
|
<a href=/people/d/dilek-hakkani-tur/>Dilek Hakkani-Tür</a>
|
<a href=/people/b/bing-liu/>Bing Liu</a>
|
<a href=/people/g/gokhan-tur/>Gokhan Tür</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-3006><div class="card-body p-3 small">End-to-end neural models show great promise towards building conversational agents that are trained from data and on-line experience using supervised and reinforcement learning. However, these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> require a large corpus of dialogues to learn effectively. For goal-oriented dialogues, such <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> are expensive to collect and annotate, since each task involves a separate schema and <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>database of entities</a>. Further, the Wizard-of-Oz approach commonly used for dialogue collection does not provide sufficient coverage of salient dialogue flows, which is critical for guaranteeing an acceptable task completion rate in consumer-facing conversational agents. In this paper, we study a recently proposed approach for building an <a href=https://en.wikipedia.org/wiki/Intelligent_agent>agent</a> for arbitrary tasks by combining dialogue self-play and <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowd-sourcing</a> to generate fully-annotated dialogues with diverse and natural utterances. We discuss the advantages of this approach for industry applications of conversational agents, wherein an agent can be rapidly bootstrapped to deploy in front of users and further optimized via interactive learning from actual users of the system.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-3008.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-3008 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-3008 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-3008/>Atypical Inputs in Educational Applications</a></strong><br><a href=/people/s/su-youn-yoon/>Su-Youn Yoon</a>
|
<a href=/people/a/aoife-cahill/>Aoife Cahill</a>
|
<a href=/people/a/anastassia-loukina/>Anastassia Loukina</a>
|
<a href=/people/k/klaus-zechner/>Klaus Zechner</a>
|
<a href=/people/b/brian-riordan/>Brian Riordan</a>
|
<a href=/people/n/nitin-madnani/>Nitin Madnani</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-3008><div class="card-body p-3 small">In large-scale educational assessments, the use of automated scoring has recently become quite common. While the majority of student responses can be processed and scored without difficulty, there are a small number of responses that have atypical characteristics that make it difficult for an automated scoring system to assign a correct score. We describe a <a href=https://en.wikipedia.org/wiki/Pipeline_(computing)>pipeline</a> that detects and processes these kinds of responses at run-time. We present the most frequent kinds of what are called non-scorable responses along with effective filtering models based on various NLP and speech processing technologies. We give an overview of two operational automated scoring systems one for essay scoring and one for speech scoring and describe the filtering models they use. Finally, we present an evaluation and analysis of <a href=https://en.wikipedia.org/wiki/Filter_(signal_processing)>filtering models</a> used for spoken responses in an <a href=https://en.wikipedia.org/wiki/Language_proficiency>assessment of language proficiency</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-3013.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-3013 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-3013 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277631374 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-3013/>Accelerating NMT Batched Beam Decoding with LMBR Posteriors for Deployment<span class=acl-fixed-case>NMT</span> Batched Beam Decoding with <span class=acl-fixed-case>LMBR</span> Posteriors for Deployment</a></strong><br><a href=/people/g/gonzalo-iglesias/>Gonzalo Iglesias</a>
|
<a href=/people/w/william-tambellini/>William Tambellini</a>
|
<a href=/people/a/adria-de-gispert/>Adrià De Gispert</a>
|
<a href=/people/e/eva-hasler/>Eva Hasler</a>
|
<a href=/people/b/bill-byrne/>Bill Byrne</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-3013><div class="card-body p-3 small">We describe a batched beam decoding algorithm for NMT with LMBR n-gram posteriors, showing that LMBR techniques still yield gains on top of the best recently reported results with Transformers. We also discuss acceleration strategies for deployment, and the effect of the beam size and <a href=https://en.wikipedia.org/wiki/Batch_processing>batching</a> on <a href=https://en.wikipedia.org/wiki/Computer_memory>memory</a> and <a href=https://en.wikipedia.org/wiki/Speed>speed</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-3015.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-3015 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-3015 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277631480 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-3015/>From dictations to clinical reports using <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a></a></strong><br><a href=/people/g/gregory-finley/>Gregory Finley</a>
|
<a href=/people/w/wael-salloum/>Wael Salloum</a>
|
<a href=/people/n/najmeh-sadoughi/>Najmeh Sadoughi</a>
|
<a href=/people/e/erik-edwards/>Erik Edwards</a>
|
<a href=/people/a/amanda-robinson/>Amanda Robinson</a>
|
<a href=/people/n/nico-axtmann/>Nico Axtmann</a>
|
<a href=/people/m/michael-brenndoerfer/>Michael Brenndoerfer</a>
|
<a href=/people/m/mark-miller/>Mark Miller</a>
|
<a href=/people/d/david-suendermann-oeft/>David Suendermann-Oeft</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-3015><div class="card-body p-3 small">A typical <a href=https://en.wikipedia.org/wiki/Workflow>workflow</a> to document clinical encounters entails dictating a summary, running <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech recognition</a>, and post-processing the resulting text into a formatted letter. Post-processing entails a host of transformations including punctuation restoration, <a href=https://en.wikipedia.org/wiki/Truecasing>truecasing</a>, marking sections and headers, converting dates and numerical expressions, parsing lists, etc. In conventional implementations, most of these <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a> are accomplished by individual <a href=https://en.wikipedia.org/wiki/Modular_programming>modules</a>. We introduce a novel holistic approach to <a href=https://en.wikipedia.org/wiki/Post-processing>post-processing</a> that relies on machine callytranslation. We show how this technique outperforms an alternative conventional systemeven learning to correct speech recognition errors during post-processingwhile being much simpler to maintain.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-3016.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-3016 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-3016 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-3016/>Benchmarks and models for entity-oriented polarity detection</a></strong><br><a href=/people/l/lidia-pivovarova/>Lidia Pivovarova</a>
|
<a href=/people/a/arto-klami/>Arto Klami</a>
|
<a href=/people/r/roman-yangarber/>Roman Yangarber</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-3016><div class="card-body p-3 small">We address the problem of determining entity-oriented polarity in <a href=https://en.wikipedia.org/wiki/Business_journalism>business news</a>. This can be viewed as classifying the polarity of the sentiment expressed toward a given mention of a company in a <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news article</a>. We present a complete, end-to-end approach to the <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a>. We introduce a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of over 17,000 manually labeled documents, which is substantially larger than any currently available resources. We propose a benchmark solution based on <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>convolutional neural networks</a> for classifying entity-oriented polarity. Although our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> is much larger than those currently available, it is small on the scale of datasets commonly used for training robust neural network models. To compensate for this, we use transfer learningpre-train the model on a much larger <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, annotated for a related but different classification task, in order to learn a good representation for business text, and then fine-tune it on the smaller polarity dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-3017.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-3017 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-3017 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277669655 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-3017/>Selecting Machine-Translated Data for Quick Bootstrapping of a Natural Language Understanding System</a></strong><br><a href=/people/j/judith-gaspers/>Judith Gaspers</a>
|
<a href=/people/p/penny-karanasou/>Penny Karanasou</a>
|
<a href=/people/r/rajen-chatterjee/>Rajen Chatterjee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-3017><div class="card-body p-3 small">This paper investigates the use of Machine Translation (MT) to bootstrap a Natural Language Understanding (NLU) system for a new language for the use case of a large-scale voice-controlled device. The goal is to decrease the cost and time needed to get an annotated corpus for the new language, while still having a large enough coverage of user requests. Different methods of filtering MT data in order to keep utterances that improve NLU performance and language-specific post-processing methods are investigated. These methods are tested in a large-scale NLU task with translating around 10 millions training utterances from <a href=https://en.wikipedia.org/wiki/English_language>English</a> to <a href=https://en.wikipedia.org/wiki/German_language>German</a>. The results show a large improvement for using MT data over a grammar-based and over an in-house data collection baseline, while reducing the manual effort greatly. Both filtering and post-processing approaches improve results further.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-3018.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-3018 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-3018 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277669529 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-3018/>Fast and Scalable Expansion of Natural Language Understanding Functionality for <a href=https://en.wikipedia.org/wiki/Intelligent_agent>Intelligent Agents</a></a></strong><br><a href=/people/a/anuj-kumar-goyal/>Anuj Kumar Goyal</a>
|
<a href=/people/a/angeliki-metallinou/>Angeliki Metallinou</a>
|
<a href=/people/s/spyros-matsoukas/>Spyros Matsoukas</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-3018><div class="card-body p-3 small">Fast expansion of <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language functionality</a> of intelligent virtual agents is critical for achieving engaging and informative interactions. However, developing accurate <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> for new <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language domains</a> is a time and data intensive process. We propose efficient deep neural network architectures that maximally re-use available resources through <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a>. Our methods are applied for expanding the understanding capabilities of a popular commercial agent and are evaluated on hundreds of new domains, designed by internal or external developers. We demonstrate that our proposed methods significantly increase <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> in low resource settings and enable rapid development of accurate <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> with less data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-3019.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-3019 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-3019 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277669612 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-3019/>Bag of Experts Architectures for Model Reuse in Conversational Language Understanding</a></strong><br><a href=/people/r/rahul-jha/>Rahul Jha</a>
|
<a href=/people/a/alex-marin/>Alex Marin</a>
|
<a href=/people/s/suvamsh-shivaprasad/>Suvamsh Shivaprasad</a>
|
<a href=/people/i/imed-zitouni/>Imed Zitouni</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-3019><div class="card-body p-3 small">Slot tagging, the task of detecting entities in input user utterances, is a key component of <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding systems</a> for <a href=https://en.wikipedia.org/wiki/Personal_digital_assistant>personal digital assistants</a>. Since each new domain requires a different set of slots, the annotation costs for labeling data for training slot tagging models increases rapidly as the number of domains grow. To tackle this, we describe Bag of Experts (BoE) architectures for model reuse for both LSTM and CRF based models. Extensive experimentation over a dataset of 10 domains drawn from data relevant to our commercial personal digital assistant shows that our BoE models outperform the baseline models with a statistically significant average margin of 5.06 % in absolute F1-score when training with 2000 instances per domain, and achieve an even higher improvement of 12.16 % when only 25 % of the training data is used.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-3020.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-3020 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-3020 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277669567 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-3020/>Multi-lingual neural title generation for e-Commerce browse pages</a></strong><br><a href=/people/p/prashant-mathur/>Prashant Mathur</a>
|
<a href=/people/n/nicola-ueffing/>Nicola Ueffing</a>
|
<a href=/people/g/gregor-leusch/>Gregor Leusch</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-3020><div class="card-body p-3 small">To provide better access of the inventory to buyers and better <a href=https://en.wikipedia.org/wiki/Search_engine_optimization>search engine optimization</a>, e-Commerce websites are automatically generating millions of browse pages. A browse page consists of a set of slot name / value pairs within a given category, grouping multiple items which share some characteristics. These browse pages require a title describing the content of the page. Since the number of browse pages are huge, manual creation of these titles is infeasible. Previous statistical and neural approaches depend heavily on the availability of large amounts of data in a language. In this research, we apply sequence-to-sequence models to generate <a href=https://en.wikipedia.org/wiki/Title_(publishing)>titles</a> for high-resource as well as low-resource languages by leveraging <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a>. We train these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on multi-lingual data, thereby creating one joint model which can generate titles in various different languages. Performance of the title generation system is evaluated on three different languages ; <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/German_language>German</a>, and <a href=https://en.wikipedia.org/wiki/French_language>French</a>, with a particular focus on low-resourced French language.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-3021.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-3021 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-3021 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://vimeo.com/277669493 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/N18-3021/>A Novel Approach to Part Name Discovery in Noisy Text</a></strong><br><a href=/people/n/nobal-bikram-niraula/>Nobal Bikram Niraula</a>
|
<a href=/people/d/daniel-whyatt/>Daniel Whyatt</a>
|
<a href=/people/a/anne-kao/>Anne Kao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-3021><div class="card-body p-3 small">As a specialized example of <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction</a>, part name extraction is an area that presents unique challenges. Part names are typically multi-word terms longer than two words. There is little consistency in how terms are described in noisy free text, with variations spawned by <a href=https://en.wikipedia.org/wiki/Typographical_error>typos</a>, ad hoc abbreviations, <a href=https://en.wikipedia.org/wiki/Acronym>acronyms</a>, and incomplete names. This makes search and analyses of parts in these <a href=https://en.wikipedia.org/wiki/Data>data</a> extremely challenging. In this paper, we present our algorithm, PANDA (Part Name Discovery Analytics), based on a unique method that exploits statistical, linguistic and machine learning techniques to discover part names in noisy text such as that in manufacturing quality documentation, supply chain management records, service communication logs, and maintenance reports. Experiments show that PANDA is scalable and outperforms existing techniques significantly.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N18-3027.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N18-3027 data-toggle=collapse aria-expanded=false aria-controls=abstract-N18-3027 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N18-3027/>Document-based Recommender System for Job Postings using Dense Representations</a></strong><br><a href=/people/a/ahmed-elsafty/>Ahmed Elsafty</a>
|
<a href=/people/m/martin-riedl/>Martin Riedl</a>
|
<a href=/people/c/chris-biemann/>Chris Biemann</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N18-3027><div class="card-body p-3 small">Job boards and professional social networks heavily use <a href=https://en.wikipedia.org/wiki/Recommender_system>recommender systems</a> in order to better support users in exploring job advertisements. Detecting the similarity between job advertisements is important for job recommendation systems as it allows, for example, the application of item-to-item based recommendations. In this work, we research the usage of dense vector representations to enhance a large-scale job recommendation system and to rank German job advertisements regarding their similarity. We follow a two-folded evaluation scheme : (1) we exploit historic user interactions to automatically create a <a href=https://en.wikipedia.org/wiki/Data_set>dataset of similar jobs</a> that enables an offline evaluation. (2) In addition, we conduct an online A / B test and evaluate the best performing method on our platform reaching more than 1 million users. We achieve the best results by combining <a href=https://en.wikipedia.org/wiki/International_Standard_Classification_of_Occupations>job titles</a> with <a href=https://en.wikipedia.org/wiki/International_Standard_Classification_of_Occupations>full-text job descriptions</a>. In particular, this method builds dense document representation using words of the titles to weigh the importance of words of the full-text description. In the online evaluation, this approach allows us to increase the <a href=https://en.wikipedia.org/wiki/Click-through_rate>click-through rate</a> on <a href=https://en.wikipedia.org/wiki/Job_description>job recommendations</a> for active users by 8.0 %.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>