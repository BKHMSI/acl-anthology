<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the Third Workshop on Narrative Understanding - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/2021.nuse-1.pdf>Proceedings of the Third Workshop on Narrative Understanding</a></h2><p class=lead><a href=/people/n/nader-akoury/>Nader Akoury</a>,
<a href=/people/f/faeze-brahman/>Faeze Brahman</a>,
<a href=/people/s/snigdha-chaturvedi/>Snigdha Chaturvedi</a>,
<a href=/people/e/elizabeth-clark/>Elizabeth Clark</a>,
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a>,
<a href=/people/l/lara-j-martin/>Lara J. Martin</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2021.nuse-1</dd><dt>Month:</dt><dd>June</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Virtual</dd><dt>Venues:</dt><dd><a href=/venues/naacl/>NAACL</a>
| <a href=/venues/nuse/>NUSE</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.nuse-1>https://aclanthology.org/2021.nuse-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2021.nuse-1.pdf>https://aclanthology.org/2021.nuse-1.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2021.nuse-1.pdf title="Open PDF of 'Proceedings of the Third Workshop on Narrative Understanding'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+Third+Workshop+on+Narrative+Understanding" title="Search for 'Proceedings of the Third Workshop on Narrative Understanding' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.nuse-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.nuse-1.0/>Proceedings of the Third Workshop on Narrative Understanding</a></strong><br><a href=/people/n/nader-akoury/>Nader Akoury</a>
|
<a href=/people/f/faeze-brahman/>Faeze Brahman</a>
|
<a href=/people/s/snigdha-chaturvedi/>Snigdha Chaturvedi</a>
|
<a href=/people/e/elizabeth-clark/>Elizabeth Clark</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a>
|
<a href=/people/l/lara-j-martin/>Lara J. Martin</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.nuse-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--nuse-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.nuse-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.nuse-1.4/>Document-level Event Extraction with Efficient End-to-end Learning of Cross-event Dependencies</a></strong><br><a href=/people/k/kung-hsiang-huang/>Kung-Hsiang Huang</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--nuse-1--4><div class="card-body p-3 small">Fully understanding narratives often requires identifying events in the context of whole documents and modeling the event relations. However, document-level event extraction is a challenging task as it requires the extraction of event and entity coreference, and capturing arguments that span across different sentences. Existing works on <a href=https://en.wikipedia.org/wiki/Event_extraction>event extraction</a> usually confine on extracting events from single sentences, which fail to capture the relationships between the event mentions at the scale of a document, as well as the event arguments that appear in a different sentence than the event trigger. In this paper, we propose an end-to-end model leveraging Deep Value Networks (DVN), a structured prediction algorithm, to efficiently capture cross-event dependencies for document-level event extraction. Experimental results show that our approach achieves comparable performance to CRF-based models on ACE05, while enjoys significantly higher computational efficiency.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.nuse-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--nuse-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.nuse-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.nuse-1.5" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.nuse-1.5/>Gender and Representation Bias in GPT-3 Generated Stories<span class=acl-fixed-case>GPT</span>-3 Generated Stories</a></strong><br><a href=/people/l/li-lucy/>Li Lucy</a>
|
<a href=/people/d/david-bamman/>David Bamman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--nuse-1--5><div class="card-body p-3 small">Using <a href=https://en.wikipedia.org/wiki/Topic_modeling>topic modeling</a> and lexicon-based word similarity, we find that stories generated by GPT-3 exhibit many known <a href=https://en.wikipedia.org/wiki/Gender_role>gender stereotypes</a>. Generated stories depict different topics and descriptions depending on GPT-3&#8217;s perceived gender of the character in a prompt, with feminine characters more likely to be associated with family and appearance, and described as less powerful than masculine characters, even when associated with high power verbs in a prompt. Our study raises questions on how one can avoid unintended social biases when using large language models for <a href=https://en.wikipedia.org/wiki/Storytelling>storytelling</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.nuse-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--nuse-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.nuse-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.nuse-1.6/>Transformer-based Screenplay Summarization Using Augmented Learning Representation with Dialogue Information</a></strong><br><a href=/people/m/myungji-lee/>Myungji Lee</a>
|
<a href=/people/h/hongseok-kwon/>Hongseok Kwon</a>
|
<a href=/people/j/jaehun-shin/>Jaehun Shin</a>
|
<a href=/people/w/wonkee-lee/>WonKee Lee</a>
|
<a href=/people/b/baikjin-jung/>Baikjin Jung</a>
|
<a href=/people/j/jong-hyeok-lee/>Jong-Hyeok Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--nuse-1--6><div class="card-body p-3 small">Screenplay summarization is the task of extracting informative scenes from a <a href=https://en.wikipedia.org/wiki/Screenplay>screenplay</a>. The <a href=https://en.wikipedia.org/wiki/Screenplay>screenplay</a> contains turning point (TP) events that change the story direction and thus define the <a href=https://en.wikipedia.org/wiki/Story_structure>story structure</a> decisively. Accordingly, this <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a> can be defined as the TP identification task. We suggest using dialogue information, one attribute of <a href=https://en.wikipedia.org/wiki/Screenplay>screenplays</a>, motivated by previous work that discovered that TPs have a relation with <a href=https://en.wikipedia.org/wiki/Dialogue>dialogues</a> appearing in <a href=https://en.wikipedia.org/wiki/Screenplay>screenplays</a>. To teach a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> this characteristic, we add a dialogue feature to the input embedding. Moreover, in an attempt to improve the model architecture of previous studies, we replace LSTM with Transformer. We observed that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can better identify TPs in a <a href=https://en.wikipedia.org/wiki/Screenplay>screenplay</a> by using dialogue information and that a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> adopting Transformer outperforms LSTM-based models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.nuse-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--nuse-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.nuse-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.nuse-1.7" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.nuse-1.7/>Plug-and-Blend : A Framework for Controllable Story Generation with Blended Control Codes</a></strong><br><a href=/people/z/zhiyu-lin/>Zhiyu Lin</a>
|
<a href=/people/m/mark-riedl/>Mark Riedl</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--nuse-1--7><div class="card-body p-3 small">We describe a Plug-and-Play controllable language generation framework, Plug-and-Blend, that allows a human user to input multiple control codes (topics). In the context of automated story generation, this allows a human user lose or fine grained control of the topics that will appear in the generated story, and can even allow for overlapping, blended topics. We show that our framework, working with different generation models, controls the generation towards given continuous-weighted control codes while keeping the generated sentences fluent, demonstrating strong blending capability.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>