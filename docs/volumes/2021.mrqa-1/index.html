<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 3rd Workshop on Machine Reading for Question Answering - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Proceedings of the 3rd Workshop on Machine Reading for Question Answering</h2><p class=lead><a href=/people/a/adam-fisch/>Adam Fisch</a>,
<a href=/people/a/alon-talmor/>Alon Talmor</a>,
<a href=/people/d/danqi-chen/>Danqi Chen</a>,
<a href=/people/e/eunsol-choi/>Eunsol Choi</a>,
<a href=/people/m/minjoon-seo/>Minjoon Seo</a>,
<a href=/people/p/patrick-lewis/>Patrick Lewis</a>,
<a href=/people/r/robin-jia/>Robin Jia</a>,
<a href=/people/s/sewon-min/>Sewon Min</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2021.mrqa-1</dd><dt>Month:</dt><dd>November</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Punta Cana, Dominican Republic</dd><dt>Venues:</dt><dd><a href=/venues/emnlp/>EMNLP</a>
| <a href=/venues/mrqa/>MRQA</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.mrqa-1>https://aclanthology.org/2021.mrqa-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+3rd+Workshop+on+Machine+Reading+for+Question+Answering" title="Search for 'Proceedings of the 3rd Workshop on Machine Reading for Question Answering' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mrqa-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.mrqa-1.0/>Proceedings of the 3rd Workshop on Machine Reading for Question Answering</a></strong><br><a href=/people/a/adam-fisch/>Adam Fisch</a>
|
<a href=/people/a/alon-talmor/>Alon Talmor</a>
|
<a href=/people/d/danqi-chen/>Danqi Chen</a>
|
<a href=/people/e/eunsol-choi/>Eunsol Choi</a>
|
<a href=/people/m/minjoon-seo/>Minjoon Seo</a>
|
<a href=/people/p/patrick-lewis/>Patrick Lewis</a>
|
<a href=/people/r/robin-jia/>Robin Jia</a>
|
<a href=/people/s/sewon-min/>Sewon Min</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mrqa-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--mrqa-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.mrqa-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.mrqa-1.1" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.mrqa-1.1/>MFAQ : a Multilingual FAQ Dataset<span class=acl-fixed-case>MFAQ</span>: a Multilingual <span class=acl-fixed-case>FAQ</span> Dataset</a></strong><br><a href=/people/m/maxime-de-bruyn/>Maxime De Bruyn</a>
|
<a href=/people/e/ehsan-lotfi/>Ehsan Lotfi</a>
|
<a href=/people/j/jeska-buhmann/>Jeska Buhmann</a>
|
<a href=/people/w/walter-daelemans/>Walter Daelemans</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--mrqa-1--1><div class="card-body p-3 small">In this paper, we present the first multilingual FAQ dataset publicly available. We collected around 6 M FAQ pairs from the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>web</a>, in 21 different languages. Although this is significantly larger than existing FAQ retrieval datasets, it comes with its own challenges : duplication of content and uneven distribution of topics. We adopt a similar setup as Dense Passage Retrieval (DPR) and test various bi-encoders on this dataset. Our experiments reveal that a multilingual model based on XLM-RoBERTa achieves the best results, except for <a href=https://en.wikipedia.org/wiki/English_language>English</a>. Lower resources languages seem to learn from one another as a multilingual model achieves a higher MRR than language-specific ones. Our qualitative analysis reveals the brittleness of the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> on simple word changes. We publicly release our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>, and training script.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mrqa-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--mrqa-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.mrqa-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.mrqa-1.6/>Can Question Generation Debias <a href=https://en.wikipedia.org/wiki/Question_answering>Question Answering Models</a>? A Case Study on QuestionContext Lexical Overlap</a></strong><br><a href=/people/k/kazutoshi-shinoda/>Kazutoshi Shinoda</a>
|
<a href=/people/s/saku-sugawara/>Saku Sugawara</a>
|
<a href=/people/a/akiko-aizawa/>Akiko Aizawa</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--mrqa-1--6><div class="card-body p-3 small">Question answering (QA) models for <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a> have been demonstrated to exploit unintended dataset biases such as questioncontext lexical overlap. This hinders QA models from generalizing to <a href=https://en.wikipedia.org/wiki/Underrepresented_group>under-represented samples</a> such as questions with low lexical overlap. Question generation (QG), a method for augmenting QA datasets, can be a solution for such performance degradation if QG can properly debias QA datasets. However, we discover that recent neural QG models are biased towards generating questions with high lexical overlap, which can amplify the dataset bias. Moreover, our analysis reveals that data augmentation with these QG models frequently impairs the performance on questions with low <a href=https://en.wikipedia.org/wiki/Lexical_overlap>lexical overlap</a>, while improving that on questions with high <a href=https://en.wikipedia.org/wiki/Lexical_overlap>lexical overlap</a>. To address this problem, we use a synonym replacement-based approach to augment questions with low lexical overlap. We demonstrate that the proposed data augmentation approach is simple yet effective to mitigate the degradation problem with only 70k synthetic examples.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mrqa-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--mrqa-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.mrqa-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.mrqa-1.9" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.mrqa-1.9/>Eliciting Bias in Question Answering Models through Ambiguity</a></strong><br><a href=/people/a/andrew-mao/>Andrew Mao</a>
|
<a href=/people/n/naveen-raman/>Naveen Raman</a>
|
<a href=/people/m/matthew-shu/>Matthew Shu</a>
|
<a href=/people/e/eric-li/>Eric Li</a>
|
<a href=/people/f/franklin-yang/>Franklin Yang</a>
|
<a href=/people/j/jordan-boyd-graber/>Jordan Boyd-Graber</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--mrqa-1--9><div class="card-body p-3 small">Question answering (QA) models use retriever and reader systems to answer questions. Reliance on training data by <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA systems</a> can amplify or reflect inequity through their responses. Many QA models, such as those for the SQuAD dataset, are trained and tested on a subset of Wikipedia articles which encode their own biases and also reproduce real-world inequality. Understanding how training data affects bias in <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA systems</a> can inform methods to mitigate <a href=https://en.wikipedia.org/wiki/Equity_(economics)>inequity</a>. We develop two sets of questions for closed and open domain questions respectively, which use ambiguous questions to probe QA models for <a href=https://en.wikipedia.org/wiki/Bias>bias</a>. We feed three deep-learning-based QA systems with our question sets and evaluate responses for <a href=https://en.wikipedia.org/wiki/Bias>bias</a> via the <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a>. Using our metrics, we find that open-domain QA models amplify biases more than their closed-domain counterparts and propose that biases in the retriever surface more readily due to greater <a href=https://en.wikipedia.org/wiki/Freedom_of_choice>freedom of choice</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mrqa-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--mrqa-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.mrqa-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.mrqa-1.10/>Bilingual Alignment Pre-Training for Zero-Shot Cross-Lingual Transfer</a></strong><br><a href=/people/z/ziqing-yang/>Ziqing Yang</a>
|
<a href=/people/w/wentao-ma/>Wentao Ma</a>
|
<a href=/people/y/yiming-cui/>Yiming Cui</a>
|
<a href=/people/j/jiani-ye/>Jiani Ye</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/s/shijin-wang/>Shijin Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--mrqa-1--10><div class="card-body p-3 small">Multilingual pre-trained models have achieved remarkable performance on cross-lingual transfer learning. Some multilingual models such as mBERT, have been pre-trained on unlabeled corpora, therefore the embeddings of different languages in the <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> may not be aligned very well. In this paper, we aim to improve the zero-shot cross-lingual transfer performance by proposing a pre-training task named Word-Exchange Aligning Model (WEAM), which uses the statistical alignment information as the prior knowledge to guide cross-lingual word prediction. We evaluate our model on multilingual machine reading comprehension task MLQA and natural language interface task XNLI. The results show that <a href=https://en.wikipedia.org/wiki/WEAM>WEAM</a> can significantly improve the zero-shot performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mrqa-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--mrqa-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.mrqa-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.mrqa-1.14/>Investigating Post-pretraining Representation Alignment for Cross-Lingual Question Answering</a></strong><br><a href=/people/f/fahim-faisal/>Fahim Faisal</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--mrqa-1--14><div class="card-body p-3 small">Human knowledge is collectively encoded in the roughly 6500 languages spoken around the world, but <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> is not distributed equally across languages. Hence, for information-seeking question answering (QA) systems to adequately serve speakers of all languages, they need to operate cross-lingually. In this work we investigate the capabilities of multilingually pretrained language models on cross-lingual QA. We find that explicitly aligning the <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representations</a> across languages with a post-hoc finetuning step generally leads to improved performance. We additionally investigate the effect of data size as well as the language choice in this fine-tuning step, also releasing a dataset for evaluating cross-lingual QA systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.mrqa-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--mrqa-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.mrqa-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.mrqa-1.15/>Semantic Answer Similarity for Evaluating Question Answering Models</a></strong><br><a href=/people/j/julian-risch/>Julian Risch</a>
|
<a href=/people/t/timo-moller/>Timo Möller</a>
|
<a href=/people/j/julian-gutsch/>Julian Gutsch</a>
|
<a href=/people/m/malte-pietsch/>Malte Pietsch</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--mrqa-1--15><div class="card-body p-3 small">The evaluation of question answering models compares <a href=https://en.wikipedia.org/wiki/Ground_truth>ground-truth annotations</a> with <a href=https://en.wikipedia.org/wiki/Prediction>model predictions</a>. However, as of today, this comparison is mostly lexical-based and therefore misses out on answers that have no lexical overlap but are still semantically similar, thus treating correct answers as false. This underestimation of the true performance of <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> hinders user acceptance in applications and complicates a fair comparison of different <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. Therefore, there is a need for an evaluation metric that is based on <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> instead of pure <a href=https://en.wikipedia.org/wiki/String_similarity>string similarity</a>. In this short paper, we present SAS, a cross-encoder-based metric for the estimation of semantic answer similarity, and compare it to seven existing <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a>. To this end, we create an English and a German three-way annotated evaluation dataset containing pairs of answers along with human judgment of their <a href=https://en.wikipedia.org/wiki/Semantic_similarity>semantic similarity</a>, which we release along with an implementation of the SAS metric and the experiments. We find that semantic similarity metrics based on recent transformer models correlate much better with human judgment than traditional lexical similarity metrics on our two newly created datasets and one dataset from related work.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>