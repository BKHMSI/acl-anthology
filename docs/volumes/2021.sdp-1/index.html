<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the Second Workshop on Scholarly Document Processing - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/2021.sdp-1.pdf>Proceedings of the Second Workshop on Scholarly Document Processing</a></h2><p class=lead><a href=/people/i/iz-beltagy/>Iz Beltagy</a>,
<a href=/people/a/arman-cohan/>Arman Cohan</a>,
<a href=/people/g/guy-feigenblat/>Guy Feigenblat</a>,
<a href=/people/d/dayne-freitag/>Dayne Freitag</a>,
<a href=/people/t/tirthankar-ghosal/>Tirthankar Ghosal</a>,
<a href=/people/k/keith-hall/>Keith Hall</a>,
<a href=/people/d/drahomira-herrmannova/>Drahomira Herrmannova</a>,
<a href=/people/p/petr-knoth/>Petr Knoth</a>,
<a href=/people/k/kyle-lo/>Kyle Lo</a>,
<a href=/people/p/philipp-mayr/>Philipp Mayr</a>,
<a href=/people/r/robert-m-patton/>Robert M. Patton</a>,
<a href=/people/m/michal-shmueli-scheuer/>Michal Shmueli-Scheuer</a>,
<a href=/people/a/anita-de-waard/>Anita de Waard</a>,
<a href=/people/k/kuansan-wang/>Kuansan Wang</a>,
<a href=/people/l/lucy-lu-wang/>Lucy Lu Wang</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2021.sdp-1</dd><dt>Month:</dt><dd>June</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Online</dd><dt>Venues:</dt><dd><a href=/venues/naacl/>NAACL</a>
| <a href=/venues/sdp/>sdp</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.sdp-1>https://aclanthology.org/2021.sdp-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2021.sdp-1.pdf>https://aclanthology.org/2021.sdp-1.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2021.sdp-1.pdf title="Open PDF of 'Proceedings of the Second Workshop on Scholarly Document Processing'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+Second+Workshop+on+Scholarly+Document+Processing" title="Search for 'Proceedings of the Second Workshop on Scholarly Document Processing' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.sdp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.sdp-1.0/>Proceedings of the Second Workshop on Scholarly Document Processing</a></strong><br><a href=/people/i/iz-beltagy/>Iz Beltagy</a>
|
<a href=/people/a/arman-cohan/>Arman Cohan</a>
|
<a href=/people/g/guy-feigenblat/>Guy Feigenblat</a>
|
<a href=/people/d/dayne-freitag/>Dayne Freitag</a>
|
<a href=/people/t/tirthankar-ghosal/>Tirthankar Ghosal</a>
|
<a href=/people/k/keith-hall/>Keith Hall</a>
|
<a href=/people/d/drahomira-herrmannova/>Drahomira Herrmannova</a>
|
<a href=/people/p/petr-knoth/>Petr Knoth</a>
|
<a href=/people/k/kyle-lo/>Kyle Lo</a>
|
<a href=/people/p/philipp-mayr/>Philipp Mayr</a>
|
<a href=/people/r/robert-m-patton/>Robert M. Patton</a>
|
<a href=/people/m/michal-shmueli-scheuer/>Michal Shmueli-Scheuer</a>
|
<a href=/people/a/anita-de-waard/>Anita de Waard</a>
|
<a href=/people/k/kuansan-wang/>Kuansan Wang</a>
|
<a href=/people/l/lucy-lu-wang/>Lucy Lu Wang</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.sdp-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--sdp-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.sdp-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.sdp-1.6" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.sdp-1.6/>Keyphrase Extraction from Scientific Articles via Extractive Summarization</a></strong><br><a href=/people/c/chrysovalantis-giorgos-kontoulis/>Chrysovalantis Giorgos Kontoulis</a>
|
<a href=/people/e/eirini-papagiannopoulou/>Eirini Papagiannopoulou</a>
|
<a href=/people/g/grigorios-tsoumakas/>Grigorios Tsoumakas</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--sdp-1--6><div class="card-body p-3 small">Automatically extracting keyphrases from scholarly documents leads to a valuable concise representation that humans can understand and machines can process for tasks, such as <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval</a>, article clustering and article classification. This paper is concerned with the parts of a scientific article that should be given as input to keyphrase extraction methods. Recent deep learning methods take titles and abstracts as input due to the increased <a href=https://en.wikipedia.org/wiki/Computational_complexity_theory>computational complexity</a> in processing long sequences, whereas traditional approaches can also work with <a href=https://en.wikipedia.org/wiki/Text_corpus>full-texts</a>. Titles and abstracts are dense in keyphrases, but often miss important aspects of the articles, while full-texts on the other hand are richer in keyphrases but much noisier. To address this trade-off, we propose the use of extractive summarization models on the full-texts of scholarly documents. Our empirical study on 3 article collections using 3 keyphrase extraction methods shows promising results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.sdp-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--sdp-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.sdp-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.sdp-1.9/>The Effect of Pretraining on Extractive Summarization for Scientific Documents</a></strong><br><a href=/people/y/yash-gupta/>Yash Gupta</a>
|
<a href=/people/p/pawan-sasanka-ammanamanchi/>Pawan Sasanka Ammanamanchi</a>
|
<a href=/people/s/shikha-bordia/>Shikha Bordia</a>
|
<a href=/people/a/arjun-manoharan/>Arjun Manoharan</a>
|
<a href=/people/d/deepak-mittal/>Deepak Mittal</a>
|
<a href=/people/r/ramakanth-pasunuru/>Ramakanth Pasunuru</a>
|
<a href=/people/m/manish-shrivastava/>Manish Shrivastava</a>
|
<a href=/people/m/maneesh-singh/>Maneesh Singh</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a>
|
<a href=/people/p/preethi-jyothi/>Preethi Jyothi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--sdp-1--9><div class="card-body p-3 small">Large pretrained models have seen enormous success in extractive summarization tasks. In this work, we investigate the influence of pretraining on a BERT-based extractive summarization system for <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific documents</a>. We derive significant performance improvements using an intermediate pretraining step that leverages existing summarization datasets and report state-of-the-art results on a recently released scientific summarization dataset, SciTLDR. We systematically analyze the intermediate pretraining step by varying the size and domain of the pretraining corpus, changing the length of the input sequence in the target task and varying target tasks. We also investigate how intermediate pretraining interacts with contextualized word embeddings trained on different domains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.sdp-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--sdp-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.sdp-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.sdp-1.10/>Finding Pragmatic Differences Between Disciplines</a></strong><br><a href=/people/l/lee-kezar/>Lee Kezar</a>
|
<a href=/people/j/jay-pujara/>Jay Pujara</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--sdp-1--10><div class="card-body p-3 small">Scholarly documents have a great degree of variation, both in terms of content (semantics) and structure (pragmatics). Prior work in scholarly document understanding emphasizes <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> through <a href=https://en.wikipedia.org/wiki/Document_summarization>document summarization</a> and corpus topic modeling but tends to omit <a href=https://en.wikipedia.org/wiki/Pragmatics>pragmatics</a> such as document organization and flow. Using a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus of scholarly documents</a> across 19 disciplines and state-of-the-art language modeling techniques, we learn a fixed set of domain-agnostic descriptors for document sections and retrofit the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> to these descriptors (also referred to as normalization). Then, we analyze the position and ordering of these descriptors across documents to understand the relationship between <a href=https://en.wikipedia.org/wiki/Discipline>discipline</a> and <a href=https://en.wikipedia.org/wiki/Structure>structure</a>. We report within-discipline structural archetypes, variability, and between-discipline comparisons, supporting the hypothesis that scholarly communities, despite their size, diversity, and breadth, share similar avenues for expressing their work. Our findings lay the foundation for future work in assessing research quality, domain style transfer, and further pragmatic analysis.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.sdp-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--sdp-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.sdp-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.sdp-1.11" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.sdp-1.11/>Extractive Research Slide Generation Using Windowed Labeling Ranking</a></strong><br><a href=/people/a/athar-sefid/>Athar Sefid</a>
|
<a href=/people/p/prasenjit-mitra/>Prasenjit Mitra</a>
|
<a href=/people/j/jian-wu/>Jian Wu</a>
|
<a href=/people/c/c-lee-giles/>C Lee Giles</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--sdp-1--11><div class="card-body p-3 small">Presentation slides generated from original research papers provide an efficient form to present research innovations. Manually generating presentation slides is labor-intensive. We propose a method to automatically generates slides for scientific articles based on a corpus of 5000 paper-slide pairs compiled from conference proceedings websites. The sentence labeling module of our method is based on SummaRuNNer, a neural sequence model for extractive summarization. Instead of ranking sentences based on semantic similarities in the whole document, our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> measures the importance and novelty of sentences by combining semantic and lexical features within a sentence window. Our method outperforms several baseline methods including SummaRuNNer by a significant margin in terms of ROUGE score.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.sdp-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--sdp-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.sdp-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.sdp-1.14/>Unsupervised document summarization using pre-trained sentence embeddings and graph centrality</a></strong><br><a href=/people/j/juan-ramirez-orta/>Juan Ramirez-Orta</a>
|
<a href=/people/e/evangelos-milios/>Evangelos Milios</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--sdp-1--14><div class="card-body p-3 small">This paper describes our submission for the LongSumm task in SDP 2021. We propose a method for incorporating sentence embeddings produced by deep language models into extractive summarization techniques based on graph centrality in an unsupervised manner. The proposed method is simple, fast, can summarize any kind of document of any size and can satisfy any length constraints for the summaries produced. The method offers competitive performance to more sophisticated <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised methods</a> and can serve as a proxy for abstractive summarization techniques</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.sdp-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--sdp-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.sdp-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.sdp-1.15" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.sdp-1.15/>QMUL-SDS at SCIVER : Step-by-Step Binary Classification for Scientific Claim Verification<span class=acl-fixed-case>QMUL</span>-<span class=acl-fixed-case>SDS</span> at <span class=acl-fixed-case>SCIVER</span>: Step-by-Step Binary Classification for Scientific Claim Verification</a></strong><br><a href=/people/x/xia-zeng/>Xia Zeng</a>
|
<a href=/people/a/arkaitz-zubiaga/>Arkaitz Zubiaga</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--sdp-1--15><div class="card-body p-3 small">Scientific claim verification is a unique challenge that is attracting increasing interest. The SCIVER shared task offers a benchmark scenario to test and compare claim verification approaches by participating teams and consists in three steps : relevant abstract selection, rationale selection and label prediction. In this paper, we present team QMUL-SDS&#8217;s participation in the shared task. We propose an approach that performs scientific claim verification by doing binary classifications step-by-step. We trained a BioBERT-large classifier to select abstracts based on pairwise relevance assessments for each claim, title of the abstract and continued to train it to select rationales out of each retrieved abstract based on claim, sentence. We then propose a two-step setting for label prediction, i.e. first predicting NOT_ENOUGH_INFO or ENOUGH_INFO, then label those marked as ENOUGH_INFO as either SUPPORT or CONTRADICT. Compared to the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline system</a>, we achieve substantial improvements on the dev set. As a result, our team is the No. 4 team on the leaderboard.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright Â©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>