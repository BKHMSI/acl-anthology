<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/W17-55.pdf>Proceedings of the 18th Annual <span class=acl-fixed-case>SIG</span>dial Meeting on Discourse and Dialogue</a></h2><p class=lead><a href=/people/k/kristiina-jokinen/>Kristiina Jokinen</a>,
<a href=/people/m/manfred-stede/>Manfred Stede</a>,
<a href=/people/d/david-devault/>David DeVault</a>,
<a href=/people/a/annie-louis/>Annie Louis</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>W17-55</dd><dt>Month:</dt><dd>August</dd><dt>Year:</dt><dd>2017</dd><dt>Address:</dt><dd>Saarbrücken, Germany</dd><dt>Venues:</dt><dd><a href=/venues/sigdial/>SIGDIAL</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd><a href=/sigs/sigdial/>SIGDIAL</a></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/W17-55>https://aclanthology.org/W17-55</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/W17-55 title="To the current version of the paper by DOI">10.18653/v1/W17-55</a></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/W17-55.pdf>https://aclanthology.org/W17-55.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/W17-55.pdf title="Open PDF of 'Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+18th+Annual+SIGdial+Meeting+on+Discourse+and+Dialogue" title="Search for 'Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5500.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5500/>Proceedings of the 18th Annual <span class=acl-fixed-case>SIG</span>dial Meeting on Discourse and Dialogue</a></strong><br><a href=/people/k/kristiina-jokinen/>Kristiina Jokinen</a>
|
<a href=/people/m/manfred-stede/>Manfred Stede</a>
|
<a href=/people/d/david-devault/>David DeVault</a>
|
<a href=/people/a/annie-louis/>Annie Louis</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5501.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5501 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5501 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-5501" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-5501/>Automatic Mapping of French Discourse Connectives to PDTB Discourse Relations<span class=acl-fixed-case>F</span>rench Discourse Connectives to <span class=acl-fixed-case>PDTB</span> Discourse Relations</a></strong><br><a href=/people/m/majid-laali/>Majid Laali</a>
|
<a href=/people/l/leila-kosseim/>Leila Kosseim</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5501><div class="card-body p-3 small">In this paper, we present an approach to exploit phrase tables generated by <a href=https://en.wikipedia.org/wiki/Statistical_machine_translation>statistical machine translation</a> in order to map French discourse connectives to <a href=https://en.wikipedia.org/wiki/Discourse_analysis>discourse relations</a>. Using this approach, we created DisCoRel, a lexicon of French discourse connectives and their PDTB relations. When evaluated against LEXCONN, DisCoRel achieves a recall of 0.81 and an Average Precision of 0.68 for the Concession and Condition relations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5502.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5502 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5502 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5502/>Towards Full Text Shallow Discourse Relation Annotation : Experiments with Cross-Paragraph Implicit Relations in the PDTB<span class=acl-fixed-case>PDTB</span></a></strong><br><a href=/people/r/rashmi-prasad/>Rashmi Prasad</a>
|
<a href=/people/k/kate-forbes-riley/>Katherine Forbes Riley</a>
|
<a href=/people/a/alan-lee/>Alan Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5502><div class="card-body p-3 small">Full text discourse parsing relies on texts comprehensively annotated with <a href=https://en.wikipedia.org/wiki/Discourse_analysis>discourse relations</a>. To this end, we address a significant gap in the inter-sentential discourse relations annotated in the Penn Discourse Treebank (PDTB), namely the class of cross-paragraph implicit relations, which account for 30 % of inter-sentential relations in the corpus. We present our annotation study to explore the <a href=https://en.wikipedia.org/wiki/Incidence_(epidemiology)>incidence rate</a> of adjacent vs. non-adjacent implicit relations in cross-paragraph contexts, and the relative degree of difficulty in annotating them. Our experiments show a high incidence of non-adjacent relations that are difficult to annotate reliably, suggesting the practicality of backing off from their annotation to reduce noise for corpus-based studies. Our resulting guidelines follow the PDTB adjacency constraint for implicits while employing an underspecified representation of non-adjacent implicits, and yield 62 % inter-annotator agreement on this task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5503.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5503 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5503 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5503/>User-initiated Sub-dialogues in State-of-the-art Dialogue Systems</a></strong><br><a href=/people/s/staffan-larsson/>Staffan Larsson</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5503><div class="card-body p-3 small">We test state of the art <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue systems</a> for their behaviour in response to user-initiated sub-dialogues, i.e. interactions where a system question is responded to with a question or request from the user, who thus initiates a sub-dialogue. We look at sub-dialogues both within a single app (where the sub-dialogue concerns another topic in the original domain) and across apps (where the sub-dialogue concerns a different domain). The overall conclusion of the tests is that none of the <a href=https://en.wikipedia.org/wiki/System>systems</a> can be said to deal appropriately with user-initiated sub-dialogues.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5504.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5504 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5504 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5504/>A Multimodal Dialogue System for Medical Decision Support inside Virtual Reality</a></strong><br><a href=/people/a/alexander-prange/>Alexander Prange</a>
|
<a href=/people/m/margarita-chikobava/>Margarita Chikobava</a>
|
<a href=/people/p/peter-poller/>Peter Poller</a>
|
<a href=/people/m/michael-barz/>Michael Barz</a>
|
<a href=/people/d/daniel-sonntag/>Daniel Sonntag</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5504><div class="card-body p-3 small">We present a multimodal dialogue system that allows doctors to interact with a medical decision support system in <a href=https://en.wikipedia.org/wiki/Virtual_reality>virtual reality (VR)</a>. We integrate an interactive visualization of patient records and radiology image data, as well as therapy predictions. Therapy predictions are computed in real-time using a <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning model</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5505.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5505 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5505 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5505/>Generative Encoder-Decoder Models for Task-Oriented Spoken Dialog Systems with Chatting Capability</a></strong><br><a href=/people/t/tiancheng-zhao/>Tiancheng Zhao</a>
|
<a href=/people/a/allen-lu/>Allen Lu</a>
|
<a href=/people/k/kyusong-lee/>Kyusong Lee</a>
|
<a href=/people/m/maxine-eskenazi/>Maxine Eskenazi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5505><div class="card-body p-3 small">Generative encoder-decoder models offer great promise in developing domain-general dialog systems. However, they have mainly been applied to open-domain conversations. This paper presents a practical and novel <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> for building task-oriented dialog systems based on encoder-decoder models. This <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> enables encoder-decoder models to accomplish slot-value independent decision-making and interact with <a href=https://en.wikipedia.org/wiki/Database>external databases</a>. Moreover, this paper shows the flexibility of the proposed method by interleaving chatting capability with a slot-filling system for better out-of-domain recovery. The models were trained on both <a href=https://en.wikipedia.org/wiki/User_data>real-user data</a> from a bus information system and <a href=https://en.wikipedia.org/wiki/Human&#8211;computer_interaction>human-human chat data</a>. Results show that the proposed <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> achieves good performance in both offline evaluation metrics and in task success rate with <a href=https://en.wikipedia.org/wiki/User_(computing)>human users</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5506.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5506 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5506 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-5506" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-5506/>Key-Value Retrieval Networks for Task-Oriented Dialogue</a></strong><br><a href=/people/m/mihail-eric/>Mihail Eric</a>
|
<a href=/people/l/lakshmi-krishnan/>Lakshmi Krishnan</a>
|
<a href=/people/f/francois-charette/>Francois Charette</a>
|
<a href=/people/c/christopher-d-manning/>Christopher D. Manning</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5506><div class="card-body p-3 small">Neural task-oriented dialogue systems often struggle to smoothly interface with a <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge base</a>. In this work, we seek to address this problem by proposing a new neural dialogue agent that is able to effectively sustain grounded, multi-domain discourse through a novel key-value retrieval mechanism. The <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> is end-to-end differentiable and does not need to explicitly model dialogue state or belief trackers. We also release a new dataset of 3,031 dialogues that are grounded through underlying knowledge bases and span three distinct tasks in the in-car personal assistant space : <a href=https://en.wikipedia.org/wiki/Calendaring_software>calendar scheduling</a>, <a href=https://en.wikipedia.org/wiki/Weather_forecasting>weather information retrieval</a>, and point-of-interest navigation. Our architecture is simultaneously trained on data from all domains and significantly outperforms a competitive rule-based system and other existing neural dialogue architectures on the provided domains according to both automatic and human evaluation metrics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5507.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5507 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5507 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5507/>Lexical Acquisition through Implicit Confirmations over Multiple Dialogues</a></strong><br><a href=/people/k/kohei-ono/>Kohei Ono</a>
|
<a href=/people/r/ryu-takeda/>Ryu Takeda</a>
|
<a href=/people/e/eric-nichols/>Eric Nichols</a>
|
<a href=/people/m/mikio-nakano/>Mikio Nakano</a>
|
<a href=/people/k/kazunori-komatani/>Kazunori Komatani</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5507><div class="card-body p-3 small">We address the problem of acquiring the <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontological categories</a> of unknown terms through implicit confirmation in dialogues. We develop an approach that makes implicit confirmation requests with an unknown term&#8217;s predicted category. Our approach does not degrade user experience with repetitive explicit confirmations, but the <a href=https://en.wikipedia.org/wiki/System>system</a> has difficulty determining if information in the confirmation request can be correctly acquired. To overcome this challenge, we propose a method for determining whether or not the predicted category is correct, which is included in an implicit confirmation request. Our method exploits multiple user responses to implicit confirmation requests containing the same <a href=https://en.wikipedia.org/wiki/Ontological_category>ontological category</a>. Experimental results revealed that the proposed method exhibited a higher precision rate for determining the correctly predicted categories than when only single user responses were considered.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5508.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5508 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5508 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5508/>Utterance Intent Classification of a Spoken Dialogue System with Efficiently Untied Recursive Autoencoders</a></strong><br><a href=/people/t/tsuneo-kato/>Tsuneo Kato</a>
|
<a href=/people/a/atsushi-nagai/>Atsushi Nagai</a>
|
<a href=/people/n/naoki-noda/>Naoki Noda</a>
|
<a href=/people/r/ryosuke-sumitomo/>Ryosuke Sumitomo</a>
|
<a href=/people/j/jianming-wu/>Jianming Wu</a>
|
<a href=/people/s/seiichi-yamamoto/>Seiichi Yamamoto</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5508><div class="card-body p-3 small">Recursive autoencoders (RAEs) for compositionality of a vector space model were applied to utterance intent classification of a smartphone-based Japanese-language spoken dialogue system. Though the RAEs express a nonlinear operation on the vectors of child nodes, the <a href=https://en.wikipedia.org/wiki/Operation_(mathematics)>operation</a> is considered to be different intrinsically depending on types of <a href=https://en.wikipedia.org/wiki/Vertex_(graph_theory)>child nodes</a>. To relax the difference, a data-driven untying of autoencoders (AEs) is proposed. The experimental result of the utterance intent classification showed an improved accuracy with the proposed method compared with the basic tied RAE and untied RAE based on a manual rule.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5509.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5509 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5509 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5509/>Reward-Balancing for Statistical Spoken Dialogue Systems using Multi-objective Reinforcement Learning</a></strong><br><a href=/people/s/stefan-ultes/>Stefan Ultes</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/n/nikola-mrksic/>Nikola Mrkšić</a>
|
<a href=/people/l/lina-m-rojas-barahona/>Lina M. Rojas-Barahona</a>
|
<a href=/people/p/pei-hao-su/>Pei-Hao Su</a>
|
<a href=/people/t/tsung-hsien-wen/>Tsung-Hsien Wen</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a>
|
<a href=/people/s/steve-young/>Steve Young</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5509><div class="card-body p-3 small">Reinforcement learning is widely used for dialogue policy optimization where the <a href=https://en.wikipedia.org/wiki/Reward_system>reward function</a> often consists of more than one <a href=https://en.wikipedia.org/wiki/Function_(mathematics)>component</a>, e.g., the dialogue success and the dialogue length. In this work, we propose a structured method for finding a good balance between these components by searching for the optimal reward component weighting. To render this search feasible, we use multi-objective reinforcement learning to significantly reduce the number of training dialogues required. We apply our proposed method to find optimized component weights for six domains and compare them to a default baseline.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5511.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5511 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5511 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5511/>Demonstration of interactive teaching for end-to-end dialog control with hybrid code networks</a></strong><br><a href=/people/j/jason-d-williams/>Jason D. Williams</a>
|
<a href=/people/l/lars-liden/>Lars Liden</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5511><div class="card-body p-3 small">This is a demonstration of interactive teaching for practical end-to-end dialog systems driven by a <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network</a>. In this approach, a developer teaches the <a href=https://en.wikipedia.org/wiki/Computer_network>network</a> by interacting with the <a href=https://en.wikipedia.org/wiki/System>system</a> and providing on-the-spot corrections. Once a <a href=https://en.wikipedia.org/wiki/System>system</a> is deployed, a developer can also correct mistakes in logged dialogs. This demonstration shows both of these teaching methods applied to dialog systems in three domains : pizza ordering, <a href=https://en.wikipedia.org/wiki/Restaurant>restaurant information</a>, and <a href=https://en.wikipedia.org/wiki/Weather_forecasting>weather forecasts</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5512.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5512 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5512 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5512/>Sub-domain Modelling for <a href=https://en.wikipedia.org/wiki/Dialogue_management>Dialogue Management</a> with Hierarchical Reinforcement Learning</a></strong><br><a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/s/stefan-ultes/>Stefan Ultes</a>
|
<a href=/people/p/pei-hao-su/>Pei-Hao Su</a>
|
<a href=/people/n/nikola-mrksic/>Nikola Mrkšić</a>
|
<a href=/people/t/tsung-hsien-wen/>Tsung-Hsien Wen</a>
|
<a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/l/lina-m-rojas-barahona/>Lina M. Rojas-Barahona</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5512><div class="card-body p-3 small">Human conversation is inherently complex, often spanning many different topics / domains. This makes <a href=https://en.wikipedia.org/wiki/Policy_learning>policy learning</a> for <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue systems</a> very challenging. Standard flat reinforcement learning methods do not provide an efficient <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> for modelling such <a href=https://en.wikipedia.org/wiki/Dialogue>dialogues</a>. In this paper, we focus on the under-explored problem of multi-domain dialogue management. First, we propose a new <a href=https://en.wikipedia.org/wiki/Methodology>method</a> for hierarchical reinforcement learning using the option framework. Next, we show that the proposed <a href=https://en.wikipedia.org/wiki/Architecture>architecture</a> learns faster and arrives at a better <a href=https://en.wikipedia.org/wiki/Policy>policy</a> than the existing flat ones do. Moreover, we show how pretrained policies can be adapted to more complex systems with an additional set of new actions. In doing that, we show that our approach has the potential to facilitate policy optimisation for more sophisticated multi-domain dialogue systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5513.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5513 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5513 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5513/>MACA : A Modular Architecture for Conversational Agents<span class=acl-fixed-case>MACA</span>: A Modular Architecture for Conversational Agents</a></strong><br><a href=/people/h/hoai-phuoc-truong/>Hoai Phuoc Truong</a>
|
<a href=/people/p/prasanna-parthasarathi/>Prasanna Parthasarathi</a>
|
<a href=/people/j/joelle-pineau/>Joelle Pineau</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5513><div class="card-body p-3 small">We propose a <a href=https://en.wikipedia.org/wiki/Software_architecture>software architecture</a> designed to ease the implementation of <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue systems</a>. The Modular Architecture for Conversational Agents (MACA) uses a plug-n-play style that allows quick prototyping, thereby facilitating the development of new techniques and the reproduction of previous work. The <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> separates the domain of the conversation from the agent&#8217;s dialogue strategy, and as such can be easily extended to multiple domains. MACA provides tools to host dialogue agents on Amazon Mechanical Turk (mTurk) for data collection and allows processing of other sources of training data. The current version of the <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> already incorporates several domains and existing <a href=https://en.wikipedia.org/wiki/Dialogue>dialogue strategies</a> from the recent literature.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5514.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5514 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5514 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5514/>Sequential Dialogue Context Modeling for Spoken Language Understanding</a></strong><br><a href=/people/a/ankur-bapna/>Ankur Bapna</a>
|
<a href=/people/g/gokhan-tur/>Gokhan Tür</a>
|
<a href=/people/d/dilek-hakkani-tur/>Dilek Hakkani-Tür</a>
|
<a href=/people/l/larry-heck/>Larry Heck</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5514><div class="card-body p-3 small">Spoken Language Understanding (SLU) is a key component of goal oriented dialogue systems that would parse user utterances into semantic frame representations. Traditionally SLU does not utilize the dialogue history beyond the previous system turn and contextual ambiguities are resolved by the downstream components. In this paper, we explore novel approaches for modeling dialogue context in a recurrent neural network (RNN) based language understanding system. We propose the Sequential Dialogue Encoder Network, that allows <a href=https://en.wikipedia.org/wiki/Context_(language_use)>encoding context</a> from the dialogue history in <a href=https://en.wikipedia.org/wiki/Chronology>chronological order</a>. We compare the performance of our proposed architecture with two context models, one that uses just the previous turn context and another that encodes dialogue context in a memory network, but loses the order of utterances in the dialogue history. Experiments with a multi-domain dialogue dataset demonstrate that the proposed <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> results in reduced semantic frame error rates.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5515.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5515 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5515 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5515/>Redundancy Localization for the Conversationalization of Unstructured Responses</a></strong><br><a href=/people/s/sebastian-krause/>Sebastian Krause</a>
|
<a href=/people/m/mikhail-kozhevnikov/>Mikhail Kozhevnikov</a>
|
<a href=/people/e/eric-malmi/>Eric Malmi</a>
|
<a href=/people/d/daniele-pighin/>Daniele Pighin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5515><div class="card-body p-3 small">Conversational agents offer users a <a href=https://en.wikipedia.org/wiki/Natural-language_user_interface>natural-language interface</a> to accomplish tasks, entertain themselves, or access information. Informational dialogue is particularly challenging in that the agent has to hold a conversation on an open topic, and to achieve a reasonable coverage it generally needs to digest and present <a href=https://en.wikipedia.org/wiki/Unstructured_data>unstructured information</a> from textual sources. Making responses based on such sources sound natural and fit appropriately into the conversation context is a topic of ongoing research, one of the key issues of which is preventing the agent&#8217;s responses from sounding repetitive. Targeting this issue, we propose a new task, known as redundancy localization, which aims to pinpoint semantic overlap between text passages. To help address it systematically, we formalize the task, prepare a public dataset with fine-grained redundancy labels, and propose a model utilizing a weak training signal defined over the results of a passage-retrieval system on web texts. The proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> demonstrates superior performance compared to a state-of-the-art entailment model and yields encouraging results when applied to a real-world dialogue.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5516.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5516 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5516 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5516/>Attentive listening system with backchanneling, response generation and flexible turn-taking</a></strong><br><a href=/people/d/divesh-lala/>Divesh Lala</a>
|
<a href=/people/p/pierrick-milhorat/>Pierrick Milhorat</a>
|
<a href=/people/k/koji-inoue/>Koji Inoue</a>
|
<a href=/people/m/masanari-ishida/>Masanari Ishida</a>
|
<a href=/people/k/katsuya-takanashi/>Katsuya Takanashi</a>
|
<a href=/people/t/tatsuya-kawahara/>Tatsuya Kawahara</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5516><div class="card-body p-3 small">Attentive listening systems are designed to let people, especially senior people, keep talking to maintain <a href=https://en.wikipedia.org/wiki/Communication>communication ability</a> and <a href=https://en.wikipedia.org/wiki/Mental_health>mental health</a>. This paper addresses key components of an attentive listening system which encourages users to talk smoothly. First, we introduce continuous prediction of end-of-utterances and generation of backchannels, rather than generating backchannels after end-point detection of utterances. This improves subjective evaluations of backchannels. Second, we propose an effective statement response mechanism which detects focus words and responds in the form of a question or partial repeat. This can be applied to any statement. Moreover, a flexible turn-taking mechanism is designed which uses backchannels or <a href=https://en.wikipedia.org/wiki/Filler_(materials)>fillers</a> when the turn-switch is ambiguous. These techniques are integrated into a <a href=https://en.wikipedia.org/wiki/Humanoid_robot>humanoid robot</a> to conduct attentive listening. We test the feasibility of the <a href=https://en.wikipedia.org/wiki/System>system</a> in a pilot experiment and show that it can produce coherent dialogues during conversation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5517.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5517 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5517 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5517/>Natural Language Input for In-Car Spoken Dialog Systems : How Natural is Natural?</a></strong><br><a href=/people/p/patricia-braunger/>Patricia Braunger</a>
|
<a href=/people/w/wolfgang-maier/>Wolfgang Maier</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5517><div class="card-body p-3 small">Recent spoken dialog systems are moving away from <a href=https://en.wikipedia.org/wiki/Command_and_control>command and control</a> towards a more intuitive and natural style of interaction. In order to choose an appropriate system design which allows the <a href=https://en.wikipedia.org/wiki/System>system</a> to deal with naturally spoken user input, a definition of what exactly constitutes naturalness in <a href=https://en.wikipedia.org/wiki/Input_(computer_science)>user input</a> is important. In this paper, we examine how different user groups naturally speak to an automotive spoken dialog system (SDS). We conduct a <a href=https://en.wikipedia.org/wiki/User_study>user study</a> in which we collect freely spoken user utterances for a wide range of use cases in <a href=https://en.wikipedia.org/wiki/German_language>German</a>. By means of a comparative study of the utterances from the study with interpersonal utterances, we provide criteria what constitutes naturalness in the user input of an state-of-the-art automotive SDS.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5518.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5518 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5518 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5518/>Sample-efficient Actor-Critic Reinforcement Learning with Supervised Data for Dialogue Management</a></strong><br><a href=/people/p/pei-hao-su/>Pei-Hao Su</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/s/stefan-ultes/>Stefan Ultes</a>
|
<a href=/people/m/milica-gasic/>Milica Gašić</a>
|
<a href=/people/s/steve-young/>Steve Young</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5518><div class="card-body p-3 small">Deep reinforcement learning (RL) methods have significant potential for dialogue policy optimisation. However, <a href=https://en.wikipedia.org/wiki/They_(2017_film)>they</a> suffer from a poor performance in the early stages of learning. This is especially problematic for <a href=https://en.wikipedia.org/wiki/Educational_technology>on-line learning</a> with real users. Two <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>approaches</a> are introduced to tackle this problem. Firstly, to speed up the learning process, two sample-efficient neural networks algorithms : trust region actor-critic with experience replay (TRACER) and episodic natural actor-critic with experience replay (eNACER) are presented. For TRACER, the <a href=https://en.wikipedia.org/wiki/Trust_region>trust region</a> helps to control the learning step size and avoid catastrophic model changes. For eNACER, the natural gradient identifies the steepest ascent direction in policy space to speed up the <a href=https://en.wikipedia.org/wiki/Convergence_of_random_variables>convergence</a>. Both models employ off-policy learning with experience replay to improve sample-efficiency. Secondly, to mitigate the cold start issue, a corpus of demonstration data is utilised to pre-train the models prior to on-line reinforcement learning. Combining these two approaches, we demonstrate a practical approach to learn deep RL-based dialogue policies and demonstrate their effectiveness in a task-oriented information seeking domain.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5519.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5519 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5519 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5519/>A surprisingly effective out-of-the-box char2char model on the E2E NLG Challenge dataset<span class=acl-fixed-case>E</span>2<span class=acl-fixed-case>E</span> <span class=acl-fixed-case>NLG</span> Challenge dataset</a></strong><br><a href=/people/s/shubham-agarwal/>Shubham Agarwal</a>
|
<a href=/people/m/marc-dymetman/>Marc Dymetman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5519><div class="card-body p-3 small">We train a char2char model on the E2E NLG Challenge data, by exploiting out-of-the-box the recently released tfseq2seq framework, using some of the standard options offered by this tool. With minimal effort, and in particular without delexicalization, <a href=https://en.wikipedia.org/wiki/Lexicalization>tokenization</a> or lowercasing, the obtained raw predictions, according to a small scale human evaluation, are excellent on the linguistic side and quite reasonable on the adequacy side, the primary downside being the possible omissions of semantic material. However, in a significant number of cases (more than 70 %), a perfect solution can be found in the top-20 predictions, indicating promising directions for solving the remaining issues.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5520.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5520 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5520 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5520/>Interaction Quality Estimation Using Long Short-Term Memories</a></strong><br><a href=/people/n/niklas-rach/>Niklas Rach</a>
|
<a href=/people/w/wolfgang-minker/>Wolfgang Minker</a>
|
<a href=/people/s/stefan-ultes/>Stefan Ultes</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5520><div class="card-body p-3 small">For estimating the Interaction Quality (IQ) in Spoken Dialogue Systems (SDS), the dialogue history is of significant importance. Previous works included this information manually in the form of precomputed temporal features into the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification process</a>. Here, we employ a deep learning architecture based on Long Short-Term Memories (LSTM) to extract this information automatically from the data, thus estimating <a href=https://en.wikipedia.org/wiki/Intelligence_quotient>IQ</a> solely by using current exchange features. We show that it is thereby possible to achieve competitive results as in a scenario where manually optimized temporal features have been included.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5522.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5522 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5522 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-5522" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-5522/>Evaluating Natural Language Understanding Services for Conversational Question Answering Systems</a></strong><br><a href=/people/d/daniel-braun/>Daniel Braun</a>
|
<a href=/people/a/adrian-hernandez-mendez/>Adrian Hernandez Mendez</a>
|
<a href=/people/f/florian-matthes/>Florian Matthes</a>
|
<a href=/people/m/manfred-langen/>Manfred Langen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5522><div class="card-body p-3 small">Conversational interfaces recently gained a lot of attention. One of the reasons for the current hype is the fact that <a href=https://en.wikipedia.org/wiki/Chatbot>chatbots</a> (one particularly popular form of conversational interfaces) nowadays can be created without any programming knowledge, thanks to different toolkits and so-called Natural Language Understanding (NLU) services. While these NLU services are already widely used in both, industry and science, so far, they have not been analysed systematically. In this paper, we present a method to evaluate the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> performance of NLU services. Moreover, we present two new <a href=https://en.wikipedia.org/wiki/Text_corpus>corpora</a>, one consisting of annotated questions and one consisting of annotated questions with the corresponding answers. Based on these <a href=https://en.wikipedia.org/wiki/Text_corpus>corpora</a>, we conduct an evaluation of some of the most popular NLU services. Thereby we want to enable both, researchers and companies to make more educated decisions about which service they should use.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5523.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5523 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5523 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-5523" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-5523/>The Role of Conversation Context for Sarcasm Detection in Online Interactions</a></strong><br><a href=/people/d/debanjan-ghosh/>Debanjan Ghosh</a>
|
<a href=/people/a/alexander-richard-fabbri/>Alexander Richard Fabbri</a>
|
<a href=/people/s/smaranda-muresan/>Smaranda Muresan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5523><div class="card-body p-3 small">Computational models for sarcasm detection have often relied on the content of utterances in isolation. However, speaker&#8217;s sarcastic intent is not always obvious without additional context. Focusing on social media discussions, we investigate two issues : (1) does modeling of <a href=https://en.wikipedia.org/wiki/Context_(language_use)>conversation context</a> help in sarcasm detection and (2) can we understand what part of <a href=https://en.wikipedia.org/wiki/Context_(language_use)>conversation context</a> triggered the <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcastic reply</a>. To address the first issue, we investigate several types of Long Short-Term Memory (LSTM) networks that can model both the conversation context and the sarcastic response. We show that the conditional LSTM network (Rocktschel et al. 2015) and LSTM networks with sentence level attention on context and response outperform the LSTM model that reads only the response. To address the second issue, we present a qualitative analysis of <a href=https://en.wikipedia.org/wiki/Attention>attention weights</a> produced by the LSTM models with <a href=https://en.wikipedia.org/wiki/Attention>attention</a> and discuss the results compared with human performance on the task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5524.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5524 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5524 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5524/>VOILA : An Optimised Dialogue System for Interactively Learning Visually-Grounded Word Meanings (Demonstration System)<span class=acl-fixed-case>VOILA</span>: An Optimised Dialogue System for Interactively Learning Visually-Grounded Word Meanings (Demonstration System)</a></strong><br><a href=/people/y/yanchao-yu/>Yanchao Yu</a>
|
<a href=/people/a/arash-eshghi/>Arash Eshghi</a>
|
<a href=/people/o/oliver-lemon/>Oliver Lemon</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5524><div class="card-body p-3 small">We present VOILA : an optimised, multi-modal dialogue agent for interactive learning of visually grounded word meanings from a human user. VOILA is : (1) able to learn new visual categories interactively from users from scratch ; (2) trained on real human-human dialogues in the same domain, and so is able to conduct natural spontaneous dialogue ; (3) optimised to find the most effective trade-off between the accuracy of the visual categories it learns and the cost it incurs to users. VOILA is deployed on Furhat, a human-like, multi-modal robot head with back-projection of the face, and a graphical virtual character.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5525.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5525 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5525 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5525/>The E2E Dataset : New Challenges For End-to-End Generation<span class=acl-fixed-case>E</span>2<span class=acl-fixed-case>E</span> Dataset: New Challenges For End-to-End Generation</a></strong><br><a href=/people/j/jekaterina-novikova/>Jekaterina Novikova</a>
|
<a href=/people/o/ondrej-dusek/>Ondřej Dušek</a>
|
<a href=/people/v/verena-rieser/>Verena Rieser</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5525><div class="card-body p-3 small">This paper describes the E2E data, a new dataset for training end-to-end, data-driven natural language generation systems in the restaurant domain, which is ten times bigger than existing, frequently used datasets in this area. The E2E dataset poses new challenges : (1) its human reference texts show more <a href=https://en.wikipedia.org/wiki/Lexicon>lexical richness</a> and <a href=https://en.wikipedia.org/wiki/Syntax>syntactic variation</a>, including <a href=https://en.wikipedia.org/wiki/Discourse>discourse phenomena</a> ; (2) generating from this set requires content selection. As such, learning from this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> promises more natural, varied and less template-like system utterances. We also establish a <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baseline</a> on this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, which illustrates some of the difficulties associated with this <a href=https://en.wikipedia.org/wiki/Data>data</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5526.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5526 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5526 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5526/>Frames : a corpus for adding <a href=https://en.wikipedia.org/wiki/Memory>memory</a> to goal-oriented dialogue systems<span class=acl-fixed-case>F</span>rames: a corpus for adding memory to goal-oriented dialogue systems</a></strong><br><a href=/people/l/layla-el-asri/>Layla El Asri</a>
|
<a href=/people/h/hannes-schulz/>Hannes Schulz</a>
|
<a href=/people/s/shikhar-kr-sarma/>Shikhar Sharma</a>
|
<a href=/people/j/jeremie-zumer/>Jeremie Zumer</a>
|
<a href=/people/j/justin-harris/>Justin Harris</a>
|
<a href=/people/e/emery-fine/>Emery Fine</a>
|
<a href=/people/r/rahul-mehrotra/>Rahul Mehrotra</a>
|
<a href=/people/k/kaheer-suleman/>Kaheer Suleman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5526><div class="card-body p-3 small">This paper proposes a new dataset, Frames, composed of 1369 human-human dialogues with an average of 15 turns per dialogue. This <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> contains goal-oriented dialogues between users who are given some constraints to book a trip and assistants who search a database to find appropriate trips. The users exhibit complex decision-making behaviour which involve comparing trips, exploring different options, and selecting among the trips that were discussed during the dialogue. To drive research on dialogue systems towards handling such <a href=https://en.wikipedia.org/wiki/Behavior>behaviour</a>, we have annotated and released the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> and we propose in this paper a task called frame tracking. This <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> consists of keeping track of different <a href=https://en.wikipedia.org/wiki/Frame_(artificial_intelligence)>semantic frames</a> throughout each dialogue. We propose a rule-based baseline and analyse the frame tracking task through this <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5527.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5527 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5527 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5527/>Towards a General, Continuous Model of Turn-taking in Spoken Dialogue using LSTM Recurrent Neural Networks<span class=acl-fixed-case>LSTM</span> Recurrent Neural Networks</a></strong><br><a href=/people/g/gabriel-skantze/>Gabriel Skantze</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5527><div class="card-body p-3 small">Previous models of turn-taking have mostly been trained for specific turn-taking decisions, such as discriminating between turn shifts and turn retention in pauses. In this paper, we present a predictive, continuous model of turn-taking using Long Short-Term Memory (LSTM) Recurrent Neural Networks (RNN). The <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> is trained on <a href=https://en.wikipedia.org/wiki/Human&#8211;computer_interaction>human-human dialogue data</a> to predict upcoming <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech activity</a> in a future time window. We show how this general <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can be applied to two different <a href=https://en.wikipedia.org/wiki/Computational_complexity_theory>tasks</a> that <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> was not specifically trained for. First, to predict whether a turn-shift will occur or not in pauses, where the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves a better performance than human observers, and better than results achieved with more traditional models. Second, to make a prediction at speech onset whether the utterance will be a short backchannel or a longer utterance. Finally, we show how the hidden layer in the <a href=https://en.wikipedia.org/wiki/Computer_network>network</a> can be used as a <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature vector</a> for turn-taking decisions in a human-robot interaction scenario.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5528.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5528 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5528 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5528/>Neural-based Natural Language Generation in Dialogue using RNN Encoder-Decoder with Semantic Aggregation<span class=acl-fixed-case>RNN</span> Encoder-Decoder with Semantic Aggregation</a></strong><br><a href=/people/v/van-khanh-tran/>Van-Khanh Tran</a>
|
<a href=/people/m/minh-le-nguyen/>Le-Minh Nguyen</a>
|
<a href=/people/s/satoshi-tojo/>Satoshi Tojo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5528><div class="card-body p-3 small">Natural language generation (NLG) is an important component in spoken dialogue systems. This paper presents a model called Encoder-Aggregator-Decoder which is an extension of an Recurrent Neural Network based Encoder-Decoder architecture. The proposed Semantic Aggregator consists of two components : an Aligner and a Refiner. The Aligner is a conventional <a href=https://en.wikipedia.org/wiki/Attention>attention</a> calculated over the encoded input information, while the Refiner is another <a href=https://en.wikipedia.org/wiki/Attention>attention or gating mechanism</a> stacked over the attentive Aligner in order to further select and aggregate the semantic elements. The proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can be jointly trained both sentence planning and surface realization to produce <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language utterances</a>. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> was extensively assessed on four different NLG domains, in which the experimental results showed that the proposed generator consistently outperforms the previous methods on all the NLG domains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5529.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5529 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5529 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5529/>Beyond On-hold Messages : Conversational Time-buying in Task-oriented Dialogue</a></strong><br><a href=/people/m/m-soledad-lopez-gambino/>Soledad López Gambino</a>
|
<a href=/people/s/sina-zarriess/>Sina Zarrieß</a>
|
<a href=/people/d/david-schlangen/>David Schlangen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5529><div class="card-body p-3 small">A common convention in <a href=https://en.wikipedia.org/wiki/Graphical_user_interface>graphical user interfaces</a> is to indicate a <a href=https://en.wikipedia.org/wiki/Wait_state>wait state</a>, for example while a program is preparing a response, through a changed cursor state or a <a href=https://en.wikipedia.org/wiki/Progress_bar>progress bar</a>. What should the analogue be in a spoken conversational system? To address this question, we set up an experiment in which a human information provider (IP) was given their information only in a delayed and incremental manner, which systematically created situations where the IP had the turn but could not provide task-related information. Our data analysis shows that 1) IPs bridge the gap until they can provide information by re-purposing a whole variety of task- and grounding-related communicative actions (e.g. echoing the user&#8217;s request, <a href=https://en.wikipedia.org/wiki/Signaling_(telecommunications)>signaling understanding</a>, asserting partially relevant information), rather than being silent or explicitly asking for time (e.g. please wait), and that 2) IPs combined these actions productively to ensure an ongoing conversation. These results, we argue, indicate that natural conversational interfaces should also be able to manage their time flexibly using a variety of conversational resources.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5530.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5530 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5530 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5530/>Neural-based Context Representation Learning for Dialog Act Classification</a></strong><br><a href=/people/d/daniel-ortega/>Daniel Ortega</a>
|
<a href=/people/n/ngoc-thang-vu/>Ngoc Thang Vu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5530><div class="card-body p-3 small">We explore context representation learning methods in neural-based models for dialog act classification. We propose and compare extensively different methods which combine <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network architectures</a> and attention mechanisms (AMs) at different context levels. Our experimental results on two benchmark datasets show consistent improvements compared to the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> without contextual information and reveal that the most suitable AM in the <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> depends on the nature of the dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5531.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5531 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5531 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5531/>Predicting Success in Goal-Driven Human-Human Dialogues</a></strong><br><a href=/people/m/michael-noseworthy/>Michael Noseworthy</a>
|
<a href=/people/j/jackie-chi-kit-cheung/>Jackie Chi Kit Cheung</a>
|
<a href=/people/j/joelle-pineau/>Joelle Pineau</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5531><div class="card-body p-3 small">In goal-driven dialogue systems, success is often defined based on a structured definition of the goal. This requires that the <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue system</a> be constrained to handle a specific class of goals and that there be a mechanism to measure success with respect to that goal. However, in many human-human dialogues the diversity of goals makes it infeasible to define success in such a way. To address this scenario, we consider the task of automatically predicting success in goal-driven human-human dialogues using only the information communicated between participants in the form of text. We build a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> from <a href=https://en.wikipedia.org/wiki/Stackoverflow>stackoverflow.com</a> which consists of exchanges between two users in the technical domain where ground-truth success labels are available. We then propose a turn-based hierarchical neural network model that can be used to predict success without requiring a structured goal definition. We show this model outperforms <a href=https://en.wikipedia.org/wiki/Heuristics_in_judgment_and_decision-making>rule-based heuristics</a> and other baselines as it is able to detect patterns over the course of a dialogue and capture notions such as <a href=https://en.wikipedia.org/wiki/Gratitude>gratitude</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5532.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5532 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5532 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5532/>Generating and Evaluating Summaries for Partial Email Threads : Conversational Bayesian Surprise and Silver Standards<span class=acl-fixed-case>B</span>ayesian Surprise and Silver Standards</a></strong><br><a href=/people/j/jordon-johnson/>Jordon Johnson</a>
|
<a href=/people/v/vaden-masrani/>Vaden Masrani</a>
|
<a href=/people/g/giuseppe-carenini/>Giuseppe Carenini</a>
|
<a href=/people/r/raymond-ng/>Raymond Ng</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5532><div class="card-body p-3 small">We define and motivate the problem of summarizing partial email threads. This problem introduces the challenge of generating reference summaries for partial threads when human annotation is only available for the threads as a whole, particularly when the human-selected sentences are not uniformly distributed within the threads. We propose an oracular algorithm for generating these reference summaries with arbitrary length, and we are making the resulting <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> publicly available. In addition, we apply a recent <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised method</a> based on Bayesian Surprise that incorporates background knowledge into partial thread summarization, extend it with conversational features, and modify the mechanism by which it handles redundancy. Experiments with our method indicate improved performance over the baseline for shorter partial threads ; and our results suggest that the potential benefits of background knowledge to partial thread summarization should be further investigated with larger datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5533.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5533 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5533 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5533/>Enabling robust and fluid spoken dialogue with cognitively impaired users</a></strong><br><a href=/people/r/ramin-yaghoubzadeh/>Ramin Yaghoubzadeh</a>
|
<a href=/people/s/stefan-kopp/>Stefan Kopp</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5533><div class="card-body p-3 small">We present the flexdiam dialogue management architecture, which was developed in a series of projects dedicated to tailoring spoken interaction to the needs of users with cognitive impairments in an everyday assistive domain, using a multimodal front-end. This hybrid DM architecture affords incremental processing of uncertain input, a flexible, mixed-initiative information grounding process that can be adapted to users&#8217; cognitive capacities and interactive idiosyncrasies, and generic mechanisms that foster transitions in the joint discourse state that are understandable and controllable by those users, in order to effect a robust interaction for users with varying capacities.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5534.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5534 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5534 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5534/>Adversarial evaluation for open-domain dialogue generation</a></strong><br><a href=/people/e/elia-bruni/>Elia Bruni</a>
|
<a href=/people/r/raquel-fernandez/>Raquel Fernández</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5534><div class="card-body p-3 small">We investigate the potential of adversarial evaluation methods for open-domain dialogue generation systems, comparing the performance of a discriminative agent to that of humans on the same task. Our results show that the task is hard, both for automated models and humans, but that a discriminative agent can learn patterns that lead to above-chance performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5535.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5535 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5535 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5535/>Exploring Joint Neural Model for Sentence Level Discourse Parsing and <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a></a></strong><br><a href=/people/b/bita-nejat/>Bita Nejat</a>
|
<a href=/people/g/giuseppe-carenini/>Giuseppe Carenini</a>
|
<a href=/people/r/raymond-ng/>Raymond Ng</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5535><div class="card-body p-3 small">Discourse Parsing and <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a> are two fundamental tasks in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a> that have been shown to be mutually beneficial. In this work, we design and compare two Neural Based models for jointly learning both <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. In the proposed approach, we first create a <a href=https://en.wikipedia.org/wiki/Vector_graphics>vector representation</a> for all the <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>text segments</a> in the input sentence. Next, we apply three different Recursive Neural Net models : one for discourse structure prediction, one for discourse relation prediction and one for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>. Finally, we combine these Neural Nets in two different joint models : <a href=https://en.wikipedia.org/wiki/Computer_multitasking>Multi-tasking</a> and Pre-training. Our results on two standard corpora indicate that both methods result in improvements in each task but <a href=https://en.wikipedia.org/wiki/Multi-tasking>Multi-tasking</a> has a bigger impact than Pre-training. Specifically for Discourse Parsing, we see improvements in the prediction of the set of contrastive relations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5538.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5538 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5538 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5538/>Finding Structure in <a href=https://en.wikipedia.org/wiki/Figurative_language>Figurative Language</a> : Metaphor Detection with Topic-based Frames</a></strong><br><a href=/people/h/hyeju-jang/>Hyeju Jang</a>
|
<a href=/people/k/keith-maki/>Keith Maki</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a>
|
<a href=/people/c/carolyn-rose/>Carolyn Rosé</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5538><div class="card-body p-3 small">In this paper, we present a novel and highly effective method for <a href=https://en.wikipedia.org/wiki/Inductive_reasoning>induction</a> and application of metaphor frame templates as a step toward detecting metaphor in extended discourse. We infer implicit facets of a given metaphor frame using a semi-supervised bootstrapping approach on an unlabeled corpus. Our model applies this frame facet information to metaphor detection, and achieves the state-of-the-art performance on a social media dataset when building upon other proven <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> in a nonlinear machine learning model. In addition, we illustrate the mechanism through which the frame and topic information enable the more accurate metaphor detection.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5539.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5539 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5539 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5539/>Using <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>Reinforcement Learning</a> to Model Incrementality in a Fast-Paced Dialogue Game</a></strong><br><a href=/people/r/ramesh-manuvinakurike/>Ramesh Manuvinakurike</a>
|
<a href=/people/d/david-devault/>David DeVault</a>
|
<a href=/people/k/kallirroi-georgila/>Kallirroi Georgila</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5539><div class="card-body p-3 small">We apply <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>Reinforcement Learning (RL)</a> to the problem of incremental dialogue policy learning in the context of a fast-paced dialogue game. We compare the <a href=https://en.wikipedia.org/wiki/Policy>policy</a> learned by RL with a high-performance baseline policy which has been shown to perform very efficiently (nearly as well as humans) in this dialogue game. The RL policy outperforms the baseline policy in offline simulations (based on real user data). We provide a detailed comparison of the RL policy and the baseline policy, including information about how much effort and time it took to develop each one of them. We also highlight the cases where the RL policy performs better, and show that understanding the RL policy can provide valuable insights which can inform the creation of an even better rule-based policy.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5540.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5540 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5540 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W17-5540.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W17-5540/>Inferring Narrative Causality between Event Pairs in Films</a></strong><br><a href=/people/z/zhichao-hu/>Zhichao Hu</a>
|
<a href=/people/m/marilyn-walker/>Marilyn Walker</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5540><div class="card-body p-3 small">To understand <a href=https://en.wikipedia.org/wiki/Narrative>narrative</a>, humans draw inferences about the underlying relations between <a href=https://en.wikipedia.org/wiki/Narrative>narrative events</a>. Cognitive theories of narrative understanding define these inferences as four different types of <a href=https://en.wikipedia.org/wiki/Causality>causality</a>, that include pairs of events A, B where A physically causes B (X drop, X break), to pairs of events where A causes emotional state B (Y saw X, Y felt fear). Previous work on learning narrative relations from <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>text</a> has either focused on strict physical causality, or has been vague about what relation is being learned. This paper learns pairs of causal events from a corpus of film scene descriptions which are action rich and tend to be told in chronological order. We show that event pairs induced using our methods are of high quality and are judged to have a stronger <a href=https://en.wikipedia.org/wiki/Causality>causal relation</a> than event pairs from Rel-Grams.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5542.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5542 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5542 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5542/>Information Navigation System with Discovering User Interests</a></strong><br><a href=/people/k/koichiro-yoshino/>Koichiro Yoshino</a>
|
<a href=/people/y/yu-suzuki/>Yu Suzuki</a>
|
<a href=/people/s/satoshi-nakamura/>Satoshi Nakamura</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5542><div class="card-body p-3 small">We demonstrate an information navigation system for sightseeing domains that has a <a href=https://en.wikipedia.org/wiki/User_interface>dialogue interface</a> for discovering user interests for <a href=https://en.wikipedia.org/wiki/Tourism>tourist activities</a>. The system discovers interests of a user with focus detection on user utterances, and proactively presents related information to the discovered user interest. A partially observable Markov decision process (POMDP)-based dialogue manager, which is extended with user focus states, controls the behavior of the system to provide information with several dialogue acts for providing information. We transferred the belief-update function and the policy of the manager from other <a href=https://en.wikipedia.org/wiki/System>system</a> trained on a different domain to show the generality of defined dialogue acts for our information navigation system.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5543.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5543 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5543 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W17-5543.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W17-5543/>Modelling Protagonist Goals and Desires in First-Person Narrative</a></strong><br><a href=/people/e/elahe-rahimtoroghi/>Elahe Rahimtoroghi</a>
|
<a href=/people/j/jiaqi-wu/>Jiaqi Wu</a>
|
<a href=/people/r/ruimin-wang/>Ruimin Wang</a>
|
<a href=/people/p/pranav-anand/>Pranav Anand</a>
|
<a href=/people/m/marilyn-walker/>Marilyn Walker</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5543><div class="card-body p-3 small">Many genres of natural language text are narratively structured, a testament to our predilection for organizing our experiences as narratives. There is broad consensus that understanding a narrative requires identifying and tracking the goals and desires of the characters and their narrative outcomes. However, to date, there has been limited work on <a href=https://en.wikipedia.org/wiki/Computational_model>computational models</a> for this <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a>. We introduce a new dataset, DesireDB, which includes gold-standard labels for identifying statements of desire, textual evidence for desire fulfillment, and annotations for whether the stated desire is fulfilled given the evidence in the narrative context. We report experiments on tracking desire fulfillment using different methods, and show that LSTM Skip-Thought model achieves <a href=https://en.wikipedia.org/wiki/F-measure>F-measure</a> of 0.7 on our <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5544.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5544 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5544 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5544/>SHIHbot : A Facebook chatbot for Sexual Health Information on HIV / AIDS<span class=acl-fixed-case>SHIH</span>bot: A <span class=acl-fixed-case>F</span>acebook chatbot for Sexual Health Information on <span class=acl-fixed-case>HIV</span>/<span class=acl-fixed-case>AIDS</span></a></strong><br><a href=/people/j/jacqueline-brixey/>Jacqueline Brixey</a>
|
<a href=/people/r/rens-hoegen/>Rens Hoegen</a>
|
<a href=/people/w/wei-lan/>Wei Lan</a>
|
<a href=/people/j/joshua-rusow/>Joshua Rusow</a>
|
<a href=/people/k/karan-singla/>Karan Singla</a>
|
<a href=/people/x/xusen-yin/>Xusen Yin</a>
|
<a href=/people/r/ron-artstein/>Ron Artstein</a>
|
<a href=/people/a/anton-leuski/>Anton Leuski</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5544><div class="card-body p-3 small">We present the implementation of an autonomous chatbot, SHIHbot, deployed on <a href=https://en.wikipedia.org/wiki/Facebook>Facebook</a>, which answers a wide variety of sexual health questions on HIV / AIDS. The chatbot&#8217;s response database is com-piled from professional medical and public health resources in order to provide reliable information to users. The system&#8217;s backend is NPCEditor, a response selection platform trained on linked questions and answers ; to our knowledge this is the first retrieval-based chatbot deployed on a large public social network.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5545.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5545 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5545 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5545/>How Would You Say It? Eliciting Lexically Diverse Dialogue for Supervised Semantic Parsing</a></strong><br><a href=/people/a/abhilasha-ravichander/>Abhilasha Ravichander</a>
|
<a href=/people/t/thomas-manzini/>Thomas Manzini</a>
|
<a href=/people/m/matthias-grabmair/>Matthias Grabmair</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/j/jonathan-francis/>Jonathan Francis</a>
|
<a href=/people/e/eric-nyberg/>Eric Nyberg</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5545><div class="card-body p-3 small">Building dialogue interfaces for real-world scenarios often entails training semantic parsers starting from zero examples. How can we build <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> that better capture the variety of ways users might phrase their queries, and what queries are actually realistic? Wang et al. (2015) proposed a method to build semantic parsing datasets by generating canonical utterances using a <a href=https://en.wikipedia.org/wiki/Grammar>grammar</a> and having crowdworkers paraphrase them into natural wording. A limitation of this approach is that it induces bias towards using similar language as the canonical utterances. In this work, we present a <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> that elicits meaningful and lexically diverse queries from users for semantic parsing tasks. Starting from a seed lexicon and a <a href=https://en.wikipedia.org/wiki/Generative_grammar>generative grammar</a>, we pair logical forms with mixed text-image representations and ask crowdworkers to paraphrase and confirm the plausibility of the queries that they generated. We use this method to build a semantic parsing dataset from scratch for a dialog agent in a smart-home simulation. We find evidence that this dataset, which we have named SmartHome, is demonstrably more lexically diverse and difficult to parse than existing domain-specific semantic parsing datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5547.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5547 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5547 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5547/>A data-driven model of explanations for a <a href=https://en.wikipedia.org/wiki/Chatbot>chatbot</a> that helps to practice conversation in a foreign language</a></strong><br><a href=/people/s/sviatlana-hohn/>Sviatlana Höhn</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5547><div class="card-body p-3 small">This article describes a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> of other-initiated self-repair for a <a href=https://en.wikipedia.org/wiki/Chatbot>chatbot</a> that helps to practice conversation in a foreign language. The <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> was developed using a <a href=https://en.wikipedia.org/wiki/Instant_messaging>corpus of instant messaging conversations</a> between <a href=https://en.wikipedia.org/wiki/German_language>German native and non-native speakers</a>. Conversation Analysis helped to create <a href=https://en.wikipedia.org/wiki/Computational_model>computational models</a> from a small number of examples. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> has been validated in an AIML-based chatbot. Unlike typical retrieval-based dialogue systems, the explanations are generated at run-time from a linguistic database.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>