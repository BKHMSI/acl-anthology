<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/P18-1.pdf>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></h2><p class=lead><a href=/people/i/iryna-gurevych/>Iryna Gurevych</a>,
<a href=/people/y/yusuke-miyao/>Yusuke Miyao</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>P18-1</dd><dt>Month:</dt><dd>July</dd><dt>Year:</dt><dd>2018</dd><dt>Address:</dt><dd>Melbourne, Australia</dd><dt>Venue:</dt><dd><a href=/venues/acl/>ACL</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/P18-1>https://aclanthology.org/P18-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/P18-1.pdf>https://aclanthology.org/P18-1.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/P18-1.pdf title="Open PDF of 'Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+56th+Annual+Meeting+of+the+Association+for+Computational+Linguistics+%28Volume+1%3A+Long+Papers%29" title="Search for 'Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-1000/>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></strong><br><a href=/people/i/iryna-gurevych/>Iryna Gurevych</a>
|
<a href=/people/y/yusuke-miyao/>Yusuke Miyao</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1002 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1002.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285807785 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1002" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1002/>A La Carte Embedding : Cheap but Effective Induction of Semantic Feature Vectors</a></strong><br><a href=/people/m/mikhail-khodak/>Mikhail Khodak</a>
|
<a href=/people/n/nikunj-saunshi/>Nikunj Saunshi</a>
|
<a href=/people/y/yingyu-liang/>Yingyu Liang</a>
|
<a href=/people/t/tengyu-ma/>Tengyu Ma</a>
|
<a href=/people/b/brandon-m-stewart/>Brandon Stewart</a>
|
<a href=/people/s/sanjeev-arora/>Sanjeev Arora</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1002><div class="card-body p-3 small">Motivations like <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a>, <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a>, and <a href=https://en.wikipedia.org/wiki/Feature_learning>feature learning</a> have fueled interest in inducing embeddings for rare or unseen words, n-grams, synsets, and other textual features. This paper introduces a la carte embedding, a simple and general alternative to the usual word2vec-based approaches for building such representations that is based upon recent theoretical results for GloVe-like embeddings. Our method relies mainly on a <a href=https://en.wikipedia.org/wiki/Linear_map>linear transformation</a> that is efficiently learnable using pretrained word vectors and <a href=https://en.wikipedia.org/wiki/Linear_regression>linear regression</a>. This transform is applicable on the fly in the future when a new text feature or rare word is encountered, even if only a single usage example is available. We introduce a new dataset showing how the a la carte method requires fewer examples of words in context to learn high-quality embeddings and we obtain state-of-the-art results on a nonce task and some unsupervised document classification tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1003 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285807793 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1003/>Unsupervised Learning of Distributional Relation Vectors</a></strong><br><a href=/people/s/shoaib-jameel/>Shoaib Jameel</a>
|
<a href=/people/z/zied-bouraoui/>Zied Bouraoui</a>
|
<a href=/people/s/steven-schockaert/>Steven Schockaert</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1003><div class="card-body p-3 small">Word embedding models such as <a href=https://en.wikipedia.org/wiki/GloVe_(machine_learning)>GloVe</a> rely on co-occurrence statistics to learn vector representations of word meaning. While we may similarly expect that co-occurrence statistics can be used to capture rich information about the relationships between different words, existing approaches for modeling such <a href=https://en.wikipedia.org/wiki/Correlation_and_dependence>relationships</a> are based on manipulating pre-trained word vectors. In this paper, we introduce a novel method which directly learns <a href=https://en.wikipedia.org/wiki/Relation_(database)>relation vectors</a> from co-occurrence statistics. To this end, we first introduce a variant of GloVe, in which there is an explicit connection between <a href=https://en.wikipedia.org/wiki/Word_(group_theory)>word vectors</a> and PMI weighted co-occurrence vectors. We then show how relation vectors can be naturally embedded into the resulting <a href=https://en.wikipedia.org/wiki/Vector_space>vector space</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1004.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1004 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1004.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1004.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285807800 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1004/>Explicit Retrofitting of Distributional Word Vectors</a></strong><br><a href=/people/g/goran-glavas/>Goran Glavaš</a>
|
<a href=/people/i/ivan-vulic/>Ivan Vulić</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1004><div class="card-body p-3 small">Semantic specialization of distributional word vectors, referred to as <a href=https://en.wikipedia.org/wiki/Retrofitting>retrofitting</a>, is a process of fine-tuning word vectors using external lexical knowledge in order to better embed some semantic relation. Existing retrofitting models integrate linguistic constraints directly into learning objectives and, consequently, specialize only the vectors of words from the constraints. In this work, in contrast, we transform external lexico-semantic relations into training examples which we use to learn an explicit retrofitting model (ER). The <a href=https://en.wikipedia.org/wiki/ER_model>ER model</a> allows us to learn a global specialization function and specialize the vectors of words unobserved in the training data as well. We report large gains over original distributional vector spaces in (1) intrinsic word similarity evaluation and on (2) two downstream tasks lexical simplification and dialog state tracking. Finally, we also successfully specialize vector spaces of new languages (i.e., unseen in the training data) by coupling ER with shared multilingual distributional vector spaces.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1006.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1006 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1006 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285807823 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1006/>Triangular Architecture for Rare Language Translation</a></strong><br><a href=/people/s/shuo-ren/>Shuo Ren</a>
|
<a href=/people/w/wenhu-chen/>Wenhu Chen</a>
|
<a href=/people/s/shujie-liu/>Shujie Liu</a>
|
<a href=/people/m/mu-li/>Mu Li</a>
|
<a href=/people/m/ming-zhou/>Ming Zhou</a>
|
<a href=/people/s/shuai-ma/>Shuai Ma</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1006><div class="card-body p-3 small">Neural Machine Translation (NMT) performs poor on the low-resource language pair (X, Z), especially when Z is a rare language. By introducing another rich language Y, we propose a novel triangular training architecture (TA-NMT) to leverage bilingual data (Y, Z) (may be small) and (X, Y) (can be rich) to improve the translation performance of low-resource pairs. In this triangular architecture, Z is taken as the intermediate latent variable, and translation models of Z are jointly optimized with an unified bidirectional EM algorithm under the goal of maximizing the translation likelihood of (X, Y). Empirical results demonstrate that our method significantly improves the translation quality of rare languages on MultiUN and IWSLT2012 datasets, and achieves even better performance combining back-translation methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1007.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1007 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1007 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285807834 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1007" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1007/>Subword Regularization : Improving Neural Network Translation Models with Multiple Subword Candidates</a></strong><br><a href=/people/t/taku-kudo/>Taku Kudo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1007><div class="card-body p-3 small">Subword units are an effective way to alleviate the open vocabulary problems in <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation (NMT)</a>. While sentences are usually converted into unique subword sequences, subword segmentation is potentially ambiguous and multiple segmentations are possible even with the same vocabulary. The question addressed in this paper is whether it is possible to harness the segmentation ambiguity as a <a href=https://en.wikipedia.org/wiki/Noise>noise</a> to improve the <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> of <a href=https://en.wikipedia.org/wiki/Normal_mode>NMT</a>. We present a simple <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularization method</a>, subword regularization, which trains the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> with multiple subword segmentations probabilistically sampled during training. In addition, for better subword sampling, we propose a new subword segmentation algorithm based on a unigram language model. We experiment with multiple corpora and report consistent improvements especially on low resource and out-of-domain settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1008.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1008 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1008 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1008.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1008.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285807844 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1008" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1008/>The Best of Both Worlds : Combining Recent Advances in <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a></a></strong><br><a href=/people/m/mia-xu-chen/>Mia Xu Chen</a>
|
<a href=/people/o/orhan-firat/>Orhan Firat</a>
|
<a href=/people/a/ankur-bapna/>Ankur Bapna</a>
|
<a href=/people/m/melvin-johnson/>Melvin Johnson</a>
|
<a href=/people/w/wolfgang-macherey/>Wolfgang Macherey</a>
|
<a href=/people/g/george-foster/>George Foster</a>
|
<a href=/people/l/llion-jones/>Llion Jones</a>
|
<a href=/people/m/mike-schuster/>Mike Schuster</a>
|
<a href=/people/n/noam-shazeer/>Noam Shazeer</a>
|
<a href=/people/n/niki-parmar/>Niki Parmar</a>
|
<a href=/people/a/ashish-vaswani/>Ashish Vaswani</a>
|
<a href=/people/j/jakob-uszkoreit/>Jakob Uszkoreit</a>
|
<a href=/people/l/lukasz-kaiser/>Lukasz Kaiser</a>
|
<a href=/people/z/zhifeng-chen/>Zhifeng Chen</a>
|
<a href=/people/y/yonghui-wu/>Yonghui Wu</a>
|
<a href=/people/m/macduff-hughes/>Macduff Hughes</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1008><div class="card-body p-3 small">The past year has witnessed rapid advances in sequence-to-sequence (seq2seq) modeling for Machine Translation (MT). The classic RNN-based approaches to MT were first out-performed by the convolutional seq2seq model, which was then out-performed by the more recent Transformer model. Each of these new approaches consists of a fundamental architecture accompanied by a set of modeling and training techniques that are in principle applicable to other seq2seq architectures. In this paper, we tease apart the new <a href=https://en.wikipedia.org/wiki/Computer_architecture>architectures</a> and their accompanying techniques in two ways. First, we identify several key modeling and training techniques, and apply them to the RNN architecture, yielding a new RNMT+ model that outperforms all of the three fundamental architectures on the benchmark WMT&#8217;14 English to French and English to German tasks. Second, we analyze the properties of each fundamental seq2seq architecture and devise new hybrid architectures intended to combine their strengths. Our hybrid models obtain further improvements, outperforming the RNMT+ model on both benchmark datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1009.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1009 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1009 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1009.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285807855 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1009/>Ultra-Fine Entity Typing</a></strong><br><a href=/people/e/eunsol-choi/>Eunsol Choi</a>
|
<a href=/people/o/omer-levy/>Omer Levy</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1009><div class="card-body p-3 small">We introduce a new entity typing task : given a sentence with an entity mention, the goal is to predict a set of free-form phrases (e.g. skyscraper, <a href=https://en.wikipedia.org/wiki/Songwriter>songwriter</a>, or criminal) that describe appropriate types for the target entity. This formulation allows us to use a new type of distant supervision at large scale : head words, which indicate the type of the noun phrases they appear in. We show that these ultra-fine types can be crowd-sourced, and introduce new evaluation sets that are much more diverse and fine-grained than existing <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmarks</a>. We present a model that can predict ultra-fine types, and is trained using a multitask objective that pools our new head-word supervision with prior supervision from <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity linking</a>. Experimental results demonstrate that our model is effective in predicting entity types at varying granularity ; it achieves state of the art performance on an existing fine-grained entity typing benchmark, and sets baselines for our newly-introduced datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1012 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1012.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1012.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1012.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285807892 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1012" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1012/>Towards Understanding the Geometry of Knowledge Graph Embeddings</a></strong><br><a href=/people/c/chandrahas/>Chandrahas</a>
|
<a href=/people/a/aditya-sharma/>Aditya Sharma</a>
|
<a href=/people/p/partha-talukdar/>Partha Talukdar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1012><div class="card-body p-3 small">Knowledge Graph (KG) embedding has emerged as a very active area of research over the last few years, resulting in the development of several embedding methods. These KG embedding methods represent KG entities and relations as vectors in a <a href=https://en.wikipedia.org/wiki/Dimension_(vector_space)>high-dimensional space</a>. Despite this popularity and effectiveness of KG embeddings in various <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> (e.g., link prediction), <a href=https://en.wikipedia.org/wiki/Geometry>geometric understanding</a> of such <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> (i.e., arrangement of entity and relation vectors in vector space) is unexplored we fill this gap in the paper. We initiate a study to analyze the geometry of KG embeddings and correlate it with task performance and other hyperparameters. To the best of our knowledge, this is the first study of its kind. Through extensive experiments on real-world datasets, we discover several insights. For example, we find that there are sharp differences between the geometry of embeddings learnt by different classes of KG embeddings methods. We hope that this initial study will inspire other follow-up research on this important but unexplored problem.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1013.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1013 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1013 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1013.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1013.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285800568 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1013/>A Unified Model for Extractive and Abstractive Summarization using Inconsistency Loss</a></strong><br><a href=/people/w/wan-ting-hsu/>Wan-Ting Hsu</a>
|
<a href=/people/c/chieh-kai-lin/>Chieh-Kai Lin</a>
|
<a href=/people/m/ming-ying-lee/>Ming-Ying Lee</a>
|
<a href=/people/k/kerui-min/>Kerui Min</a>
|
<a href=/people/j/jing-tang/>Jing Tang</a>
|
<a href=/people/m/min-sun/>Min Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1013><div class="card-body p-3 small">We propose a unified model combining the strength of extractive and abstractive summarization. On the one hand, a simple extractive model can obtain sentence-level attention with high ROUGE scores but less readable. On the other hand, a more complicated abstractive model can obtain word-level dynamic attention to generate a more readable paragraph. In our model, sentence-level attention is used to modulate the word-level attention such that words in less attended sentences are less likely to be generated. Moreover, a novel inconsistency loss function is introduced to penalize the inconsistency between two levels of attentions. By end-to-end training our model with the inconsistency loss and original losses of extractive and abstractive models, we achieve state-of-the-art ROUGE scores while being the most informative and readable summarization on the CNN / Daily Mail dataset in a solid human evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1014.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1014 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285800574 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1014/>Extractive Summarization with SWAP-NET : Sentences and Words from Alternating Pointer Networks<span class=acl-fixed-case>SWAP</span>-<span class=acl-fixed-case>NET</span>: Sentences and Words from Alternating Pointer Networks</a></strong><br><a href=/people/a/aishwarya-jadhav/>Aishwarya Jadhav</a>
|
<a href=/people/v/vaibhav-rajan/>Vaibhav Rajan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1014><div class="card-body p-3 small">We present a new neural sequence-to-sequence model for extractive summarization called SWAP-NET (Sentences and Words from Alternating Pointer Networks). Extractive summaries comprising a salient subset of input sentences, often also contain important key words. Guided by this principle, we design SWAP-NET that models the interaction of key words and salient sentences using a new two-level pointer network based architecture. SWAP-NET identifies both salient sentences and key words in an input document, and then combines them to form the extractive summary. Experiments on large scale benchmark corpora demonstrate the efficacy of SWAP-NET that outperforms state-of-the-art extractive summarizers.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1015.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1015 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1015 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1015.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285800584 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1015/>Retrieve, Rerank and Rewrite : Soft Template Based Neural Summarization</a></strong><br><a href=/people/z/ziqiang-cao/>Ziqiang Cao</a>
|
<a href=/people/w/wenjie-li/>Wenjie Li</a>
|
<a href=/people/s/sujian-li/>Sujian Li</a>
|
<a href=/people/f/furu-wei/>Furu Wei</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1015><div class="card-body p-3 small">Most previous seq2seq summarization systems purely depend on the source text to generate summaries, which tends to work unstably. Inspired by the traditional template-based summarization approaches, this paper proposes to use existing summaries as soft templates to guide the seq2seq model. To this end, we use a popular IR platform to Retrieve proper summaries as candidate templates. Then, we extend the seq2seq framework to jointly conduct template Reranking and template-aware summary generation (Rewriting). Experiments show that, in terms of informativeness, our model significantly outperforms the state-of-the-art methods, and even soft templates themselves demonstrate high competitiveness. In addition, the import of high-quality external summaries improves the <a href=https://en.wikipedia.org/wiki/BIBO_stability>stability</a> and readability of generated summaries.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1016.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1016 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1016 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1016.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285800596 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1016/>Simple and Effective Text Simplification Using Semantic and Neural Methods</a></strong><br><a href=/people/e/elior-sulem/>Elior Sulem</a>
|
<a href=/people/o/omri-abend/>Omri Abend</a>
|
<a href=/people/a/ari-rappoport/>Ari Rappoport</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1016><div class="card-body p-3 small">Sentence splitting is a major <a href=https://en.wikipedia.org/wiki/Operator_(mathematics)>simplification operator</a>. Here we present a simple and efficient splitting algorithm based on an automatic semantic parser. After splitting, the text is amenable for further fine-tuned simplification operations. In particular, we show that <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural Machine Translation</a> can be effectively used in this situation. Previous application of <a href=https://en.wikipedia.org/wiki/Machine_translation>Machine Translation</a> for simplification suffers from a considerable disadvantage in that they are over-conservative, often failing to modify the source in any way. Splitting based on <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a>, as proposed here, alleviates this issue. Extensive automatic and human evaluation shows that the proposed method compares favorably to the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> in combined lexical and structural simplification.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1019.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1019 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1019 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1019.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285800638 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1019" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1019/>A Corpus with Multi-Level Annotations of Patients, Interventions and Outcomes to Support <a href=https://en.wikipedia.org/wiki/Language_processing>Language Processing</a> for Medical Literature</a></strong><br><a href=/people/b/benjamin-nye/>Benjamin Nye</a>
|
<a href=/people/j/junyi-jessy-li/>Junyi Jessy Li</a>
|
<a href=/people/r/roma-patel/>Roma Patel</a>
|
<a href=/people/y/yinfei-yang/>Yinfei Yang</a>
|
<a href=/people/i/iain-marshall/>Iain Marshall</a>
|
<a href=/people/a/ani-nenkova/>Ani Nenkova</a>
|
<a href=/people/b/byron-c-wallace/>Byron Wallace</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1019><div class="card-body p-3 small">We present a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> of 5,000 richly annotated abstracts of medical articles describing clinical randomized controlled trials. Annotations include demarcations of text spans that describe the Patient population enrolled, the Interventions studied and to what they were Compared, and the Outcomes measured (the &#8216;PICO&#8217; elements). These spans are further annotated at a more granular level, e.g., individual interventions within them are marked and mapped onto a structured medical vocabulary. We acquired <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a> from a diverse set of workers with varying levels of expertise and cost. We describe our data collection process and the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> itself in detail. We then outline a set of challenging NLP tasks that would aid searching of the medical literature and the practice of evidence-based medicine.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1021.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1021 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1021 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1021.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1021.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285800652 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1021/>Neural Argument Generation Augmented with Externally Retrieved Evidence</a></strong><br><a href=/people/x/xinyu-hua/>Xinyu Hua</a>
|
<a href=/people/l/lu-wang/>Lu Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1021><div class="card-body p-3 small">High quality arguments are essential elements for <a href=https://en.wikipedia.org/wiki/Reason>human reasoning</a> and <a href=https://en.wikipedia.org/wiki/Decision-making>decision-making processes</a>. However, effective argument construction is a challenging <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> for both human and machines. In this work, we study a novel <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> on automatically generating arguments of a different stance for a given statement. We propose an encoder-decoder style neural network-based argument generation model enriched with externally retrieved evidence from <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>. Our model first generates a set of talking point phrases as intermediate representation, followed by a separate decoder producing the final argument based on both input and the keyphrases. Experiments on a large-scale dataset collected from <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a> show that our model constructs arguments with more topic-relevant content than popular sequence-to-sequence generation models according to automatic evaluation and human assessments.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1023.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1023 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1023 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1023.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285800671 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1023/>Retrieval of the Best Counterargument without Prior Topic Knowledge</a></strong><br><a href=/people/h/henning-wachsmuth/>Henning Wachsmuth</a>
|
<a href=/people/s/shahbaz-syed/>Shahbaz Syed</a>
|
<a href=/people/b/benno-stein/>Benno Stein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1023><div class="card-body p-3 small">Given any argument on any controversial topic, how to counter it? This question implies the challenging retrieval task of finding the best counterargument. Since prior knowledge of a topic can not be expected in general, we hypothesize the best counterargument to invoke the same aspects as the argument while having the opposite stance. To operationalize our hypothesis, we simultaneously model the similarity and dissimilarity of pairs of arguments, based on the words and embeddings of the arguments&#8217; premises and conclusions. A salient property of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is its independence from the topic at hand, i.e., it applies to arbitrary arguments. We evaluate different model variations on millions of argument pairs derived from the web portal idebate.org. Systematic ranking experiments suggest that our hypothesis is true for many arguments : For 7.6 candidates with opposing stance on average, we rank the best counterargument highest with 60 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. Even among all 2801 test set pairs as candidates, we still find the best one about every third time.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1024 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1024.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1024.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1024/>LinkNBed : Multi-Graph Representation Learning with Entity Linkage<span class=acl-fixed-case>L</span>ink<span class=acl-fixed-case>NB</span>ed: Multi-Graph Representation Learning with Entity Linkage</a></strong><br><a href=/people/r/rakshit-trivedi/>Rakshit Trivedi</a>
|
<a href=/people/b/bunyamin-sisman/>Bunyamin Sisman</a>
|
<a href=/people/x/xin-luna-dong/>Xin Luna Dong</a>
|
<a href=/people/c/christos-faloutsos/>Christos Faloutsos</a>
|
<a href=/people/j/jun-ma/>Jun Ma</a>
|
<a href=/people/h/hongyuan-zha/>Hongyuan Zha</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1024><div class="card-body p-3 small">Knowledge graphs have emerged as an important model for studying complex multi-relational data. This has given rise to the construction of numerous large scale but incomplete knowledge graphs encoding information extracted from various resources. An effective and scalable approach to jointly learn over multiple graphs and eventually construct a unified graph is a crucial next step for the success of knowledge-based inference for many downstream applications. To this end, we propose LinkNBed, a deep relational learning framework that learns entity and relationship representations across multiple graphs. We identify entity linkage across graphs as a vital component to achieve our goal. We design a novel objective that leverage <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity linkage</a> and build an efficient multi-task training procedure. Experiments on link prediction and <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity linkage</a> demonstrate substantial improvements over the state-of-the-art relational learning approaches.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1025.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1025 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1025 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1025.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1025/>Probabilistic Embedding of Knowledge Graphs with Box Lattice Measures</a></strong><br><a href=/people/l/luke-vilnis/>Luke Vilnis</a>
|
<a href=/people/x/xiang-li/>Xiang Li</a>
|
<a href=/people/s/shikhar-murty/>Shikhar Murty</a>
|
<a href=/people/a/andrew-mccallum/>Andrew McCallum</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1025><div class="card-body p-3 small">Embedding methods which enforce a partial order or lattice structure over the concept space, such as Order Embeddings (OE), are a natural way to model transitive relational data (e.g. entailment graphs). However, OE learns a deterministic knowledge base, limiting expressiveness of queries and the ability to use <a href=https://en.wikipedia.org/wiki/Uncertainty>uncertainty</a> for both <a href=https://en.wikipedia.org/wiki/Prediction>prediction</a> and <a href=https://en.wikipedia.org/wiki/Machine_learning>learning</a> (e.g. learning from expectations). Probabilistic extensions of OE have provided the ability to somewhat calibrate these denotational probabilities while retaining the consistency and inductive bias of ordered models, but lack the ability to model the negative correlations found in real-world knowledge. In this work we show that a broad class of models that assign probability measures to OE can never capture negative correlation, which motivates our construction of a novel box lattice and accompanying <a href=https://en.wikipedia.org/wiki/Probability_measure>probability measure</a> to capture anti-correlation and even disjoint concepts, while still providing the benefits of probabilistic modeling, such as the ability to perform rich joint and conditional queries over arbitrary sets of concepts, and both learning from and predicting calibrated uncertainty. We show improvements over previous approaches in modeling the Flickr and WordNet entailment graphs, and investigate the power of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1027.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1027 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1027 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1027.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1027.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1027" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1027/>Sharp Nearby, Fuzzy Far Away : How Neural Language Models Use Context</a></strong><br><a href=/people/u/urvashi-khandelwal/>Urvashi Khandelwal</a>
|
<a href=/people/h/he-he/>He He</a>
|
<a href=/people/p/peng-qi/>Peng Qi</a>
|
<a href=/people/d/dan-jurafsky/>Dan Jurafsky</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1027><div class="card-body p-3 small">We know very little about how neural language models (LM) use <a href=https://en.wikipedia.org/wiki/Context_(language_use)>prior linguistic context</a>. In this paper, we investigate the role of <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context</a> in an LSTM LM, through <a href=https://en.wikipedia.org/wiki/Ablation>ablation studies</a>. Specifically, we analyze the increase in <a href=https://en.wikipedia.org/wiki/Perplexity>perplexity</a> when prior context words are shuffled, replaced, or dropped. On two standard datasets, <a href=https://en.wikipedia.org/wiki/Penn_Treebank>Penn Treebank</a> and WikiText-2, we find that the model is capable of using about 200 tokens of context on average, but sharply distinguishes nearby context (recent 50 tokens) from the distant history. The model is highly sensitive to the order of words within the most recent sentence, but ignores word order in the long-range context (beyond 50 tokens), suggesting the distant past is modeled only as a rough semantic field or topic. We further find that the neural caching model (Grave et al., 2017b) especially helps the LSTM to copy words from within this distant context. Overall, our analysis not only provides a better understanding of how neural LMs use their context, but also sheds light on recent success from cache-based models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1028.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1028 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1028 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1028.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1028.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1028/>Bridging CNNs, <a href=https://en.wikipedia.org/wiki/Random-access_memory>RNNs</a>, and <a href=https://en.wikipedia.org/wiki/Finite-state_machine>Weighted Finite-State Machines</a><span class=acl-fixed-case>CNN</span>s, <span class=acl-fixed-case>RNN</span>s, and Weighted Finite-State Machines</a></strong><br><a href=/people/r/roy-schwartz/>Roy Schwartz</a>
|
<a href=/people/s/sam-thomson/>Sam Thomson</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1028><div class="card-body p-3 small">Recurrent and convolutional neural networks comprise two distinct families of <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that have proven to be useful for encoding natural language utterances. In this paper we present SoPa, a new <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> that aims to bridge these two approaches. SoPa combines neural representation learning with weighted finite-state automata (WFSAs) to learn a soft version of traditional surface patterns. We show that SoPa is an extension of a one-layer CNN, and that such CNNs are equivalent to a restricted version of SoPa, and accordingly, to a restricted form of WFSA. Empirically, on three text classification tasks, SoPa is comparable or better than both a BiLSTM (RNN) baseline and a CNN baseline, and is particularly useful in small data settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1029.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1029 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1029 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1029.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1029/>Zero-shot Learning of Classifiers from Natural Language Quantification</a></strong><br><a href=/people/s/shashank-srivastava/>Shashank Srivastava</a>
|
<a href=/people/i/igor-labutov/>Igor Labutov</a>
|
<a href=/people/t/tom-mitchell/>Tom Mitchell</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1029><div class="card-body p-3 small">Humans can efficiently learn new <a href=https://en.wikipedia.org/wiki/Concept>concepts</a> using <a href=https://en.wikipedia.org/wiki/Language>language</a>. We present a <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> through which a set of explanations of a concept can be used to learn a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> without access to any labeled examples. We use <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a> to map explanations to probabilistic assertions grounded in latent class labels and observed attributes of unlabeled data, and leverage the differential semantics of linguistic quantifiers (e.g., &#8216;usually&#8217; vs &#8216;always&#8217;) to drive <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>model training</a>. Experiments on three domains show that the learned <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> outperform previous approaches for learning with limited data, and are comparable with fully supervised classifiers trained from a small number of labeled examples.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1030.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1030 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1030 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1030.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1030/>Sentence-State LSTM for Text Representation<span class=acl-fixed-case>LSTM</span> for Text Representation</a></strong><br><a href=/people/y/yue-zhang/>Yue Zhang</a>
|
<a href=/people/q/qi-liu/>Qi Liu</a>
|
<a href=/people/l/linfeng-song/>Linfeng Song</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1030><div class="card-body p-3 small">Bi-directional LSTMs are a powerful tool for text representation. On the other hand, they have been shown to suffer various limitations due to their sequential nature. We investigate an alternative LSTM structure for encoding text, which consists of a parallel state for each word. Recurrent steps are used to perform local and global information exchange between words simultaneously, rather than incremental reading of a sequence of words. Results on various classification and sequence labelling benchmarks show that the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> has strong representation power, giving highly competitive performances compared to stacked BiLSTM models with similar parameter numbers.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1033.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1033 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1033 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1033.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1033" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1033/>Improving Text-to-SQL Evaluation Methodology<span class=acl-fixed-case>SQL</span> Evaluation Methodology</a></strong><br><a href=/people/c/catherine-finegan-dollak/>Catherine Finegan-Dollak</a>
|
<a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a>
|
<a href=/people/l/li-zhang/>Li Zhang</a>
|
<a href=/people/k/karthik-ramanathan/>Karthik Ramanathan</a>
|
<a href=/people/s/sesh-sadasivam/>Sesh Sadasivam</a>
|
<a href=/people/r/rui-zhang/>Rui Zhang</a>
|
<a href=/people/d/dragomir-radev/>Dragomir Radev</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1033><div class="card-body p-3 small">To be informative, an evaluation must measure how well systems generalize to realistic unseen data. We identify limitations of and propose improvements to current evaluations of text-to-SQL systems. First, we compare human-generated and automatically generated questions, characterizing properties of queries necessary for real-world applications. To facilitate evaluation on multiple datasets, we release standardized and improved versions of seven existing <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> and one new text-to-SQL dataset. Second, we show that the current division of data into training and test sets measures robustness to variations in the way questions are asked, but only partially tests how well systems generalize to new queries ; therefore, we propose a complementary dataset split for evaluation of future work. Finally, we demonstrate how the common practice of anonymizing variables during <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation</a> removes an important challenge of the task. Our observations highlight key difficulties, and our <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> enables effective measurement of future development.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1034.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1034 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1034 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-1034/>Semantic Parsing with Syntax- and Table-Aware SQL Generation<span class=acl-fixed-case>SQL</span> Generation</a></strong><br><a href=/people/y/yibo-sun/>Yibo Sun</a>
|
<a href=/people/d/duyu-tang/>Duyu Tang</a>
|
<a href=/people/n/nan-duan/>Nan Duan</a>
|
<a href=/people/j/jianshu-ji/>Jianshu Ji</a>
|
<a href=/people/g/guihong-cao/>Guihong Cao</a>
|
<a href=/people/x/xiaocheng-feng/>Xiaocheng Feng</a>
|
<a href=/people/b/bing-qin/>Bing Qin</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/m/ming-zhou/>Ming Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1034><div class="card-body p-3 small">We present a <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a> to map <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language questions</a> into <a href=https://en.wikipedia.org/wiki/SQL>SQL queries</a>. Existing neural network based approaches typically generate a SQL query word-by-word, however, a large portion of the generated results is incorrect or not executable due to the mismatch between question words and table contents. Our approach addresses this problem by considering the <a href=https://en.wikipedia.org/wiki/Table_(database)>structure of table</a> and the <a href=https://en.wikipedia.org/wiki/SQL>syntax of SQL language</a>. The quality of the generated SQL query is significantly improved through (1) learning to replicate content from column names, cells or SQL keywords ; and (2) improving the generation of WHERE clause by leveraging the column-cell relation. Experiments are conducted on WikiSQL, a recently released dataset with the largest question- SQL pairs. Our <a href=https://en.wikipedia.org/wiki/Scientific_method>approach</a> significantly improves the state-of-the-art <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>execution accuracy</a> from 69.0 % to 74.4 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1035.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1035 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1035 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1035.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1035.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1035.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1035" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1035/>Multitask Parsing Across Semantic Representations</a></strong><br><a href=/people/d/daniel-hershcovich/>Daniel Hershcovich</a>
|
<a href=/people/o/omri-abend/>Omri Abend</a>
|
<a href=/people/a/ari-rappoport/>Ari Rappoport</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1035><div class="card-body p-3 small">The ability to consolidate information of different types is at the core of intelligence, and has tremendous practical value in allowing <a href=https://en.wikipedia.org/wiki/Learning>learning</a> for one <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> to benefit from generalizations learned for others. In this paper we tackle the challenging task of improving semantic parsing performance, taking UCCA parsing as a test case, and AMR, SDP and Universal Dependencies (UD) parsing as auxiliary tasks. We experiment on three <a href=https://en.wikipedia.org/wiki/Programming_language>languages</a>, using a uniform transition-based system and learning architecture for all parsing tasks. Despite notable conceptual, formal and domain differences, we show that <a href=https://en.wikipedia.org/wiki/Multitask_learning>multitask learning</a> significantly improves UCCA parsing in both in-domain and out-of-domain settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1037.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1037 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1037 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1037.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1037.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1037" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1037/>AMR Parsing as Graph Prediction with Latent Alignment<span class=acl-fixed-case>AMR</span> Parsing as Graph Prediction with Latent Alignment</a></strong><br><a href=/people/c/chunchuan-lyu/>Chunchuan Lyu</a>
|
<a href=/people/i/ivan-titov/>Ivan Titov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1037><div class="card-body p-3 small">Abstract meaning representations (AMRs) are broad-coverage sentence-level semantic representations. AMRs represent sentences as rooted labeled directed acyclic graphs. AMR parsing is challenging partly due to the lack of annotated alignments between nodes in the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graphs</a> and words in the corresponding sentences. We introduce a neural parser which treats <a href=https://en.wikipedia.org/wiki/Sequence_alignment>alignments</a> as <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variables</a> within a joint probabilistic model of concepts, relations and <a href=https://en.wikipedia.org/wiki/Sequence_alignment>alignments</a>. As <a href=https://en.wikipedia.org/wiki/Exact_inference>exact inference</a> requires marginalizing over <a href=https://en.wikipedia.org/wiki/Sequence_alignment>alignments</a> and is infeasible, we use the variational autoencoding framework and a continuous relaxation of the discrete alignments. We show that joint modeling is preferable to using a pipeline of align and parse. The <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> achieves the best reported results on the standard <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark</a> (74.4 % on LDC2016E25).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1040.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1040 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1040 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1040.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1040.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1040" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1040/>Discourse Representation Structure Parsing</a></strong><br><a href=/people/j/jiangming-liu/>Jiangming Liu</a>
|
<a href=/people/s/shay-b-cohen/>Shay B. Cohen</a>
|
<a href=/people/m/mirella-lapata/>Mirella Lapata</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1040><div class="card-body p-3 small">We introduce an open-domain neural semantic parser which generates formal meaning representations in the style of Discourse Representation Theory (DRT ; Kamp and Reyle 1993). We propose a method which transforms Discourse Representation Structures (DRSs) to trees and develop a structure-aware model which decomposes the decoding process into three stages : basic DRS structure prediction, condition prediction (i.e., predicates and relations), and referent prediction (i.e., variables). Experimental results on the Groningen Meaning Bank (GMB) show that our model outperforms competitive baselines by a wide margin.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1041.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1041 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1041 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1041.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1041.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1041" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1041/>Baseline Needs More Love : On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms</a></strong><br><a href=/people/d/dinghan-shen/>Dinghan Shen</a>
|
<a href=/people/g/guoyin-wang/>Guoyin Wang</a>
|
<a href=/people/w/wenlin-wang/>Wenlin Wang</a>
|
<a href=/people/m/martin-renqiang-min/>Martin Renqiang Min</a>
|
<a href=/people/q/qinliang-su/>Qinliang Su</a>
|
<a href=/people/y/yizhe-zhang/>Yizhe Zhang</a>
|
<a href=/people/c/chunyuan-li/>Chunyuan Li</a>
|
<a href=/people/r/ricardo-henao/>Ricardo Henao</a>
|
<a href=/people/l/lawrence-carin/>Lawrence Carin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1041><div class="card-body p-3 small">Many deep learning architectures have been proposed to model the compositionality in text sequences, requiring substantial number of <a href=https://en.wikipedia.org/wiki/Parameter_(computer_programming)>parameters</a> and expensive computations. However, there has not been a rigorous evaluation regarding the added value of sophisticated <a href=https://en.wikipedia.org/wiki/Function_(mathematics)>compositional functions</a>. In this paper, we conduct a point-by-point comparative study between Simple Word-Embedding-based Models (SWEMs), consisting of parameter-free pooling operations, relative to word-embedding-based RNN / CNN models. Surprisingly, SWEMs exhibit comparable or even superior performance in the majority of cases considered. Based upon this understanding, we propose two additional pooling strategies over learned word embeddings : (i) a max-pooling operation for improved interpretability ; and (ii) a hierarchical pooling operation, which preserves spatial (n-gram) information within text sequences. We present experiments on 17 datasets encompassing three <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> : (i) (long) document classification ; (ii) text sequence matching ; and (iii) short text tasks, including classification and tagging.<i>compositionality</i> in text sequences, requiring substantial number of parameters and expensive computations. However, there has not been a rigorous evaluation regarding the added value of sophisticated compositional functions. In this paper, we conduct a point-by-point comparative study between Simple Word-Embedding-based Models (SWEMs), consisting of parameter-free pooling operations, relative to word-embedding-based RNN/CNN models. Surprisingly, SWEMs exhibit comparable or even superior performance in the majority of cases considered. Based upon this understanding, we propose two additional pooling strategies over learned word embeddings: (<i>i</i>) a max-pooling operation for improved interpretability; and (<i>ii</i>) a hierarchical pooling operation, which preserves spatial (<tex-math>n</tex-math>-gram) information within text sequences. We present experiments on 17 datasets encompassing three tasks: (<i>i</i>) (long) document classification; (<i>ii</i>) text sequence matching; and (<i>iii</i>) short text tasks, including classification and tagging.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1042.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1042 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1042 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1042.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1042/>ParaNMT-50 M : Pushing the Limits of Paraphrastic Sentence Embeddings with Millions of Machine Translations<span class=acl-fixed-case>P</span>ara<span class=acl-fixed-case>NMT</span>-50<span class=acl-fixed-case>M</span>: Pushing the Limits of Paraphrastic Sentence Embeddings with Millions of Machine Translations</a></strong><br><a href=/people/j/john-wieting/>John Wieting</a>
|
<a href=/people/k/kevin-gimpel/>Kevin Gimpel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1042><div class="card-body p-3 small">We describe ParaNMT-50 M, a dataset of more than 50 million English-English sentential paraphrase pairs. We generated the pairs automatically by using neural machine translation to translate the non-English side of a large parallel corpus, following Wieting et al. Our hope is that ParaNMT-50 M can be a valuable resource for <a href=https://en.wikipedia.org/wiki/Paraphrase_generation>paraphrase generation</a> and can provide a rich source of semantic knowledge to improve downstream natural language understanding tasks. To show its utility, we use ParaNMT-50 M to train paraphrastic sentence embeddings that outperform all supervised systems on every SemEval semantic textual similarity competition, in addition to showing how it can be used for <a href=https://en.wikipedia.org/wiki/Paraphrase_generation>paraphrase generation</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1044.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1044 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1044 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1044.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1044/>Neural Adversarial Training for Semi-supervised Japanese Predicate-argument Structure Analysis<span class=acl-fixed-case>J</span>apanese Predicate-argument Structure Analysis</a></strong><br><a href=/people/s/shuhei-kurita/>Shuhei Kurita</a>
|
<a href=/people/d/daisuke-kawahara/>Daisuke Kawahara</a>
|
<a href=/people/s/sadao-kurohashi/>Sadao Kurohashi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1044><div class="card-body p-3 small">Japanese predicate-argument structure (PAS) analysis involves zero anaphora resolution, which is notoriously difficult. To improve the performance of Japanese PAS analysis, it is straightforward to increase the size of corpora annotated with <a href=https://en.wikipedia.org/wiki/Partially_ordered_set>PAS</a>. However, since <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> is prohibitively expensive, it is promising to take advantage of a large amount of raw corpora. In this paper, we propose a novel Japanese PAS analysis model based on semi-supervised adversarial training with a <a href=https://en.wikipedia.org/wiki/Text_corpus>raw corpus</a>. In our experiments, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms existing state-of-the-art models for Japanese PAS analysis.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1048.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1048 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1048 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1048.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1048" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1048/>Self-regulation : Employing a Generative Adversarial Network to Improve Event Detection</a></strong><br><a href=/people/y/yu-hong/>Yu Hong</a>
|
<a href=/people/w/wenxuan-zhou/>Wenxuan Zhou</a>
|
<a href=/people/j/jingli-zhang/>Jingli Zhang</a>
|
<a href=/people/g/guodong-zhou/>Guodong Zhou</a>
|
<a href=/people/q/qiaoming-zhu/>Qiaoming Zhu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1048><div class="card-body p-3 small">Due to the ability of encoding and mapping semantic information into a high-dimensional latent feature space, <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> have been successfully used for detecting events to a certain extent. However, such a <a href=https://en.wikipedia.org/wiki/Feature_space>feature space</a> can be easily contaminated by spurious features inherent in event detection. In this paper, we propose a self-regulated learning approach by utilizing a <a href=https://en.wikipedia.org/wiki/Generative_adversarial_network>generative adversarial network</a> to generate spurious features. On the basis, we employ a recurrent network to eliminate the fakes. Detailed experiments on the ACE 2005 and TAC-KBP 2015 corpora show that our proposed method is highly effective and adaptable.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1050.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1050 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1050 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1050.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1050/>Temporal Event Knowledge Acquisition via Identifying Narratives</a></strong><br><a href=/people/w/wenlin-yao/>Wenlin Yao</a>
|
<a href=/people/r/ruihong-huang/>Ruihong Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1050><div class="card-body p-3 small">Inspired by the double temporality characteristic of narrative texts, we propose a novel approach for acquiring rich temporal before / after event knowledge across sentences in narrative stories. The double temporality states that a <a href=https://en.wikipedia.org/wiki/Narrative>narrative story</a> often describes a sequence of events following the <a href=https://en.wikipedia.org/wiki/Chronology>chronological order</a> and therefore, the temporal order of events matches with their textual order. We explored narratology principles and built a weakly supervised approach that identifies 287k narrative paragraphs from three large corpora. We then extracted rich temporal event knowledge from these narrative paragraphs. Such event knowledge is shown useful to improve temporal relation classification and outperforms several recent neural network models on the narrative cloze task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1051.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1051 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1051 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1051.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1051/>Textual Deconvolution Saliency (TDS) : a deep tool box for <a href=https://en.wikipedia.org/wiki/Linguistic_analysis>linguistic analysis</a><span class=acl-fixed-case>TDS</span>) : a deep tool box for linguistic analysis</a></strong><br><a href=/people/l/laurent-vanni/>Laurent Vanni</a>
|
<a href=/people/m/melanie-ducoffe/>Melanie Ducoffe</a>
|
<a href=/people/c/carlos-aguilar/>Carlos Aguilar</a>
|
<a href=/people/f/frederic-precioso/>Frederic Precioso</a>
|
<a href=/people/d/damon-mayaffre/>Damon Mayaffre</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1051><div class="card-body p-3 small">In this paper, we propose a new strategy, called Text Deconvolution Saliency (TDS), to visualize linguistic information detected by a CNN for <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a>. We extend Deconvolution Networks to <a href=https://en.wikipedia.org/wiki/Written_language>text</a> in order to present a new perspective on <a href=https://en.wikipedia.org/wiki/Written_language>text analysis</a> to the <a href=https://en.wikipedia.org/wiki/Linguistic_community>linguistic community</a>. We empirically demonstrated the efficiency of our Text Deconvolution Saliency on corpora from three different languages : <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/French_language>French</a>, and <a href=https://en.wikipedia.org/wiki/Latin>Latin</a>. For every tested dataset, our Text Deconvolution Saliency automatically encodes complex linguistic patterns based on co-occurrences and possibly on grammatical and syntax analysis.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1052.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1052 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1052 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1052.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1052.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1052/>Coherence Modeling of Asynchronous Conversations : A Neural Entity Grid Approach</a></strong><br><a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/m/muhammad-tasnim-mohiuddin/>Muhammad Tasnim Mohiuddin</a>
|
<a href=/people/d/dat-tien-nguyen/>Dat Tien Nguyen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1052><div class="card-body p-3 small">We propose a novel coherence model for <a href=https://en.wikipedia.org/wiki/Asynchronous_communication>written asynchronous conversations</a> (e.g., <a href=https://en.wikipedia.org/wiki/Internet_forum>forums</a>, emails), and show its applications in coherence assessment and thread reconstruction tasks. We conduct our research in two steps. First, we propose improvements to the recently proposed neural entity grid model by lexicalizing its entity transitions. Then, we extend the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to <a href=https://en.wikipedia.org/wiki/Asynchronous_communication>asynchronous conversations</a> by incorporating the underlying conversational structure in the <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity grid representation</a> and feature computation. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves state of the art results on standard coherence assessment tasks in monologue and conversations outperforming existing <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. We also demonstrate its effectiveness in reconstructing thread structures.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1053.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1053 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1053 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1053.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1053" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1053/>Deep Reinforcement Learning for Chinese Zero Pronoun Resolution<span class=acl-fixed-case>C</span>hinese Zero Pronoun Resolution</a></strong><br><a href=/people/q/qingyu-yin/>Qingyu Yin</a>
|
<a href=/people/y/yu-zhang/>Yu Zhang</a>
|
<a href=/people/w/weinan-zhang/>Wei-Nan Zhang</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1053><div class="card-body p-3 small">Recent neural network models for Chinese zero pronoun resolution gain great performance by capturing semantic information for zero pronouns and candidate antecedents, but tend to be short-sighted, operating solely by making local decisions. They typically predict coreference links between the <a href=https://en.wikipedia.org/wiki/Zero_pronoun>zero pronoun</a> and one single candidate antecedent at a time while ignoring their influence on future decisions. Ideally, modeling useful information of preceding potential antecedents is crucial for classifying later zero pronoun-candidate antecedent pairs, a need which leads traditional models of zero pronoun resolution to draw on <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a>. In this paper, we show how to integrate these goals, applying deep reinforcement learning to deal with the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. With the help of the reinforcement learning agent, our system learns the policy of selecting antecedents in a sequential manner, where useful information provided by earlier predicted antecedents could be utilized for making later coreference decisions. Experimental results on OntoNotes 5.0 show that our approach substantially outperforms the state-of-the-art methods under three experimental settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1054.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1054 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1054 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1054.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1054/>Entity-Centric Joint Modeling of Japanese Coreference Resolution and Predicate Argument Structure Analysis<span class=acl-fixed-case>J</span>apanese Coreference Resolution and Predicate Argument Structure Analysis</a></strong><br><a href=/people/t/tomohide-shibata/>Tomohide Shibata</a>
|
<a href=/people/s/sadao-kurohashi/>Sadao Kurohashi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1054><div class="card-body p-3 small">Predicate argument structure analysis is a task of identifying <a href=https://en.wikipedia.org/wiki/Event_(probability_theory)>structured events</a>. To improve this field, we need to identify a salient entity, which can not be identified without performing <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> and predicate argument structure analysis simultaneously. This paper presents an entity-centric joint model for Japanese coreference resolution and predicate argument structure analysis. Each entity is assigned an <a href=https://en.wikipedia.org/wiki/Embedding>embedding</a>, and when the result of both analyses refers to an entity, the entity embedding is updated. The <a href=https://en.wikipedia.org/wiki/Analysis>analyses</a> take the entity embedding into consideration to access the global information of entities. Our experimental results demonstrate the proposed method can improve the performance of the inter-sentential zero anaphora resolution drastically, which is a notoriously difficult task in predicate argument structure analysis.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1055.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1055 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1055 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1055.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1055/>Constraining MGbank : Agreement, L-Selection and Supertagging in Minimalist Grammars<span class=acl-fixed-case>MG</span>bank: Agreement, <span class=acl-fixed-case>L</span>-Selection and Supertagging in <span class=acl-fixed-case>M</span>inimalist <span class=acl-fixed-case>G</span>rammars</a></strong><br><a href=/people/j/john-torr/>John Torr</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1055><div class="card-body p-3 small">This paper reports on two strategies that have been implemented for improving the <a href=https://en.wikipedia.org/wiki/Efficiency>efficiency</a> and <a href=https://en.wikipedia.org/wiki/Precision_(computer_science)>precision</a> of wide-coverage Minimalist Grammar (MG) parsing. The first extends the <a href=https://en.wikipedia.org/wiki/Formalism_(philosophy_of_mathematics)>formalism</a> presented in Torr and Stabler (2016) with a mechanism for enforcing fine-grained selectional restrictions and agreements. The second is a method for factoring computationally costly null heads out from bottom-up MG parsing ; this has the additional benefit of rendering the formalism fully compatible for the first time with highly efficient Markovian supertaggers. These techniques aided in the task of generating MGbank, the first wide-coverage corpus of Minimalist Grammar derivation trees.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1058.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1058 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1058 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1058.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1058/>Give Me More Feedback : Annotating Argument Persuasiveness and Related Attributes in Student Essays</a></strong><br><a href=/people/w/winston-carlile/>Winston Carlile</a>
|
<a href=/people/n/nishant-gurrapadi/>Nishant Gurrapadi</a>
|
<a href=/people/z/zixuan-ke/>Zixuan Ke</a>
|
<a href=/people/v/vincent-ng/>Vincent Ng</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1058><div class="card-body p-3 small">While argument persuasiveness is one of the most important dimensions of argumentative essay quality, it is relatively little studied in automated essay scoring research. Progress on scoring argument persuasiveness is hindered in part by the scarcity of annotated corpora. We present the first <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus of essays</a> that are simultaneously annotated with argument components, argument persuasiveness scores, and attributes of argument components that impact an argument&#8217;s persuasiveness. This <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> could trigger the development of novel <a href=https://en.wikipedia.org/wiki/Computational_model>computational models</a> concerning argument persuasiveness that provide useful feedback to students on why their arguments are (un)persuasive in addition to how persuasive they are.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1059.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1059 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1059 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1059.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1059.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1059" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1059/>Inherent Biases in Reference-based Evaluation for Grammatical Error Correction</a></strong><br><a href=/people/l/leshem-choshen/>Leshem Choshen</a>
|
<a href=/people/o/omri-abend/>Omri Abend</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1059><div class="card-body p-3 small">The prevalent use of too few references for evaluating text-to-text generation is known to bias estimates of their quality (henceforth, low coverage bias or LCB). This paper shows that overcoming LCB in Grammatical Error Correction (GEC) evaluation can not be attained by re-scaling or by increasing the number of references in any feasible range, contrary to previous suggestions. This is due to the long-tailed distribution of valid corrections for a sentence. Concretely, we show that LCB incentivizes GEC systems to avoid correcting even when they can generate a valid correction. Consequently, existing <a href=https://en.wikipedia.org/wiki/System>systems</a> obtain comparable or superior performance compared to humans, by making few but targeted changes to the input. Similar effects on <a href=https://en.wikipedia.org/wiki/Text_Simplification>Text Simplification</a> further support our claims.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1062.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1062 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1062 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1062.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1062.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1062" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1062/>Unsupervised Abstractive Meeting Summarization with Multi-Sentence Compression and Budgeted Submodular Maximization</a></strong><br><a href=/people/g/guokan-shang/>Guokan Shang</a>
|
<a href=/people/w/wensi-ding/>Wensi Ding</a>
|
<a href=/people/z/zekun-zhang/>Zekun Zhang</a>
|
<a href=/people/a/antoine-tixier/>Antoine Tixier</a>
|
<a href=/people/p/polykarpos-meladianos/>Polykarpos Meladianos</a>
|
<a href=/people/m/michalis-vazirgiannis/>Michalis Vazirgiannis</a>
|
<a href=/people/j/jean-pierre-lorre/>Jean-Pierre Lorré</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1062><div class="card-body p-3 small">We introduce a novel graph-based framework for abstractive meeting speech summarization that is fully unsupervised and does not rely on any annotations. Our <a href=https://en.wikipedia.org/wiki/Work_(physics)>work</a> combines the strengths of multiple recent <a href=https://en.wikipedia.org/wiki/Scientific_method>approaches</a> while addressing their weaknesses. Moreover, we leverage recent advances in <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> and <a href=https://en.wikipedia.org/wiki/Graph_degeneracy>graph degeneracy</a> applied to <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> to take exterior semantic knowledge into account, and to design custom diversity and informativeness measures. Experiments on the AMI and ICSI corpus show that our system improves on the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a>. Code and data are publicly available, and our <a href=https://en.wikipedia.org/wiki/System>system</a> can be interactively tested.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1063.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1063 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1063 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1063.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1063" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1063/>Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting</a></strong><br><a href=/people/y/yen-chun-chen/>Yen-Chun Chen</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1063><div class="card-body p-3 small">Inspired by how humans summarize long documents, we propose an accurate and fast summarization model that first selects salient sentences and then rewrites them abstractively (i.e., compresses and paraphrases) to generate a concise overall summary. We use a novel sentence-level policy gradient method to bridge the non-differentiable computation between these two <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> in a hierarchical way, while maintaining <a href=https://en.wikipedia.org/wiki/Fluency>language fluency</a>. Empirically, we achieve the new state-of-the-art on all <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> (including human evaluation) on the CNN / Daily Mail dataset, as well as significantly higher abstractiveness scores. Moreover, by first operating at the sentence-level and then the word-level, we enable parallel decoding of our neural generative model that results in substantially faster (10-20x) inference speed as well as 4x faster training convergence than previous long-paragraph encoder-decoder models. We also demonstrate the generalization of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on the test-only DUC-2002 dataset, where we achieve higher scores than a state-of-the-art model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1064.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1064 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1064 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1064.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1064/>Soft Layer-Specific Multi-Task Summarization with Entailment and Question Generation</a></strong><br><a href=/people/h/han-guo/>Han Guo</a>
|
<a href=/people/r/ramakanth-pasunuru/>Ramakanth Pasunuru</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1064><div class="card-body p-3 small">An accurate abstractive summary of a document should contain all its salient information and should be logically entailed by the input document. We improve these important aspects of abstractive summarization via <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a> with the auxiliary tasks of question generation and entailment generation, where the former teaches the summarization model how to look for salient questioning-worthy details, and the latter teaches the model how to rewrite a summary which is a directed-logical subset of the input document. We also propose novel multi-task architectures with high-level (semantic) layer-specific sharing across multiple encoder and decoder layers of the three tasks, as well as soft-sharing mechanisms (and show performance ablations and analysis examples of each contribution). Overall, we achieve statistically significant improvements over the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> on both the CNN / DailyMail and Gigaword datasets, as well as on the DUC-2002 transfer setup. We also present several quantitative and qualitative analysis studies of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s learned saliency and entailment skills.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1068.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1068 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1068 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1068.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285800848 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1068" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1068/>Coarse-to-Fine Decoding for Neural Semantic Parsing</a></strong><br><a href=/people/l/li-dong/>Li Dong</a>
|
<a href=/people/m/mirella-lapata/>Mirella Lapata</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1068><div class="card-body p-3 small">Semantic parsing aims at mapping <a href=https://en.wikipedia.org/wiki/Utterance>natural language utterances</a> into structured meaning representations. In this work, we propose a structure-aware neural architecture which decomposes the semantic parsing process into two stages. Given an input utterance, we first generate a rough sketch of its meaning, where low-level information (such as <a href=https://en.wikipedia.org/wiki/Variable_(computer_science)>variable names</a> and arguments) is glossed over. Then, we fill in missing details by taking into account the <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language input</a> and the sketch itself. Experimental results on four <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> characteristic of different domains and meaning representations show that our approach consistently improves performance, achieving competitive results despite the use of relatively simple <a href=https://en.wikipedia.org/wiki/Code>decoders</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1069.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1069 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1069 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1069.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1069" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1069/>Confidence Modeling for Neural Semantic Parsing</a></strong><br><a href=/people/l/li-dong/>Li Dong</a>
|
<a href=/people/c/chris-quirk/>Chris Quirk</a>
|
<a href=/people/m/mirella-lapata/>Mirella Lapata</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1069><div class="card-body p-3 small">In this work we focus on confidence modeling for neural semantic parsers which are built upon sequence-to-sequence models. We outline three major causes of uncertainty, and design various <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> to quantify these factors. These <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> are then used to estimate <a href=https://en.wikipedia.org/wiki/Confidence_interval>confidence scores</a> that indicate whether model predictions are likely to be correct. Beyond confidence estimation, we identify which parts of the input contribute to uncertain predictions allowing users to interpret their <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>, and verify or refine its input. Experimental results show that our confidence model significantly outperforms a widely used method that relies on <a href=https://en.wikipedia.org/wiki/Posterior_probability>posterior probability</a>, and improves the quality of interpretation compared to simply relying on attention scores.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1072.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1072 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1072 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1072.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285800939 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1072/>On the Limitations of Unsupervised Bilingual Dictionary Induction</a></strong><br><a href=/people/a/anders-sogaard/>Anders Søgaard</a>
|
<a href=/people/s/sebastian-ruder/>Sebastian Ruder</a>
|
<a href=/people/i/ivan-vulic/>Ivan Vulić</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1072><div class="card-body p-3 small">Unsupervised machine translation-i.e., not assuming any cross-lingual supervision signal, whether a dictionary, translations, or comparable corpora-seems impossible, but nevertheless, Lample et al. (2017) recently proposed a fully unsupervised machine translation (MT) model. The model relies heavily on an adversarial, unsupervised cross-lingual word embedding technique for bilingual dictionary induction (Conneau et al., 2017), which we examine here. Our results identify the limitations of current unsupervised MT : unsupervised bilingual dictionary induction performs much worse on morphologically rich languages that are not dependent marking, when monolingual corpora from different domains or different embedding algorithms are used. We show that a simple trick, exploiting a weak supervision signal from identical words, enables more robust <a href=https://en.wikipedia.org/wiki/Mathematical_induction>induction</a> and establish a near-perfect correlation between unsupervised bilingual dictionary induction performance and a previously unexplored graph similarity metric.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1073.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1073 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1073 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1073.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285800964 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1073" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1073/>A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings</a></strong><br><a href=/people/m/mikel-artetxe/>Mikel Artetxe</a>
|
<a href=/people/g/gorka-labaka/>Gorka Labaka</a>
|
<a href=/people/e/eneko-agirre/>Eneko Agirre</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1073><div class="card-body p-3 small">Recent work has managed to learn cross-lingual word embeddings without parallel data by mapping monolingual embeddings to a shared space through adversarial training. However, their evaluation has focused on favorable conditions, using comparable corpora or closely-related languages, and we show that they often fail in more realistic scenarios. This work proposes an alternative approach based on a fully unsupervised initialization that explicitly exploits the structural similarity of the embeddings, and a robust self-learning algorithm that iteratively improves this solution. Our method succeeds in all tested scenarios and obtains the best published results in standard <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, even surpassing previous <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised systems</a>. Our <a href=https://en.wikipedia.org/wiki/Implementation>implementation</a> is released as an open source project at.<url>https://github.com/artetxem/vecmap</url>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1074.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1074 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1074 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1074.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285800977 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1074" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1074/>A Multi-lingual Multi-task Architecture for Low-resource Sequence Labeling</a></strong><br><a href=/people/y/ying-lin/>Ying Lin</a>
|
<a href=/people/s/shengqi-yang/>Shengqi Yang</a>
|
<a href=/people/v/veselin-stoyanov/>Veselin Stoyanov</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1074><div class="card-body p-3 small">We propose a multi-lingual multi-task architecture to develop <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised models</a> with a minimal amount of labeled data for <a href=https://en.wikipedia.org/wiki/Sequence_labeling>sequence labeling</a>. In this new <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a>, we combine various <a href=https://en.wikipedia.org/wiki/Transfer_function>transfer models</a> using two layers of parameter sharing. On the first layer, we construct the basis of the <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> to provide universal word representation and feature extraction capability for all <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a>. On the second level, we adopt different parameter sharing strategies for different transfer schemes. This <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> proves to be particularly effective for low-resource settings, when there are less than 200 training sentences for the target <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. Using Name Tagging as a target task, our <a href=https://en.wikipedia.org/wiki/Design_of_experiments>approach</a> achieved 4.3%-50.5 % absolute F-score gains compared to the mono-lingual single-task baseline model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1077.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1077 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1077 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285801036 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1077/>Multi-Relational Question Answering from Narratives : Machine Reading and Reasoning in Simulated Worlds</a></strong><br><a href=/people/i/igor-labutov/>Igor Labutov</a>
|
<a href=/people/b/bishan-yang/>Bishan Yang</a>
|
<a href=/people/a/anusha-prakash/>Anusha Prakash</a>
|
<a href=/people/a/amos-azaria/>Amos Azaria</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1077><div class="card-body p-3 small">Question Answering (QA), as a research field, has primarily focused on either knowledge bases (KBs) or free text as a source of knowledge. These two sources have historically shaped the kinds of questions that are asked over these sources, and the methods developed to answer them. In this work, we look towards a practical use-case of <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA</a> over user-instructed knowledge that uniquely combines elements of both structured QA over knowledge bases, and unstructured QA over narrative, introducing the task of multi-relational QA over personal narrative. As a first step towards this goal, we make three key contributions : (i) we generate and release TextWorldsQA, a set of five diverse datasets, where each dataset contains dynamic narrative that describes entities and relations in a simulated world, paired with variably compositional questions over that knowledge, (ii) we perform a thorough evaluation and analysis of several state-of-the-art QA models and their variants at this task, and (iii) we release a lightweight Python-based framework we call TextWorlds for easily generating arbitrary additional worlds and narrative, with the goal of allowing the community to create and share a growing collection of diverse worlds as a test-bed for this task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1078.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1078 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1078 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1078.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285801068 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1078" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1078/>Simple and Effective Multi-Paragraph Reading Comprehension</a></strong><br><a href=/people/c/christopher-clark/>Christopher Clark</a>
|
<a href=/people/m/matt-gardner/>Matt Gardner</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1078><div class="card-body p-3 small">We introduce a method of adapting neural paragraph-level question answering models to the case where entire documents are given as input. Most current question answering models can not scale to document or multi-document input, and naively applying these <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> to each paragraph independently often results in them being distracted by irrelevant text. We show that it is possible to significantly improve performance by using a modified <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training scheme</a> that teaches the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> to ignore non-answer containing paragraphs. Our method involves sampling multiple paragraphs from each document, and using an <a href=https://en.wikipedia.org/wiki/Loss_function>objective function</a> that requires the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to produce globally correct output. We additionally identify and improve upon a number of other <a href=https://en.wikipedia.org/wiki/Design_of_experiments>design decisions</a> that arise when working with document-level data. Experiments on TriviaQA and SQuAD shows our method advances the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state of the art</a>, including a 10 point gain on TriviaQA.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1079.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1079 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1079 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1079.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1079.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285801102 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1079" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1079/>Semantically Equivalent Adversarial Rules for Debugging NLP models<span class=acl-fixed-case>NLP</span> models</a></strong><br><a href=/people/m/marco-tulio-ribeiro/>Marco Tulio Ribeiro</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a>
|
<a href=/people/c/carlos-guestrin/>Carlos Guestrin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1079><div class="card-body p-3 small">Complex machine learning models for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> are often brittle, making different predictions for input instances that are extremely similar semantically. To automatically detect this behavior for individual instances, we present semantically equivalent adversaries (SEAs) semantic-preserving perturbations that induce changes in the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s predictions. We generalize these <a href=https://en.wikipedia.org/wiki/Adversarial_system>adversaries</a> into semantically equivalent adversarial rules (SEARs) simple, universal replacement rules that induce <a href=https://en.wikipedia.org/wiki/Adversarial_system>adversaries</a> on many instances. We demonstrate the usefulness and flexibility of SEAs and SEARs by detecting bugs in black-box state-of-the-art models for three domains : machine comprehension, visual question-answering, and <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>. Via user studies, we demonstrate that we generate high-quality local adversaries for more instances than humans, and that SEARs induce four times as many mistakes as the bugs discovered by human experts. SEARs are also actionable : retraining models using <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> significantly reduces bugs, while maintaining <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1080.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1080 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1080 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1080.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285801126 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1080" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1080/>Style Transfer Through Back-Translation</a></strong><br><a href=/people/s/shrimai-prabhumoye/>Shrimai Prabhumoye</a>
|
<a href=/people/y/yulia-tsvetkov/>Yulia Tsvetkov</a>
|
<a href=/people/r/ruslan-salakhutdinov/>Ruslan Salakhutdinov</a>
|
<a href=/people/a/alan-w-black/>Alan W Black</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1080><div class="card-body p-3 small">Style transfer is the task of rephrasing the text to contain specific stylistic properties without changing the intent or affect within the context. This paper introduces a new <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> for automatic style transfer. We first learn a latent representation of the input sentence which is grounded in a language translation model in order to better preserve the meaning of the sentence while reducing stylistic properties. Then adversarial generation techniques are used to make the output match the desired style. We evaluate this technique on three different style transformations : <a href=https://en.wikipedia.org/wiki/Sentimentality>sentiment</a>, <a href=https://en.wikipedia.org/wiki/Gender>gender</a> and political slant. Compared to two state-of-the-art style transfer modeling techniques we show improvements both in automatic evaluation of style transfer and in manual evaluation of meaning preservation and fluency.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1082.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1082 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1082 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1082.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285801163 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1082" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1082/>Hierarchical Neural Story Generation</a></strong><br><a href=/people/a/angela-fan/>Angela Fan</a>
|
<a href=/people/m/mike-lewis/>Mike Lewis</a>
|
<a href=/people/y/yann-dauphin/>Yann Dauphin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1082><div class="card-body p-3 small">We explore story generation : creative systems that can build coherent and fluent passages of text about a topic. We collect a large <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of 300 K human-written stories paired with writing prompts from an <a href=https://en.wikipedia.org/wiki/Internet_forum>online forum</a>. Our dataset enables hierarchical story generation, where the model first generates a premise, and then transforms it into a passage of text. We gain further improvements with a novel form of model fusion that improves the relevance of the story to the prompt, and adding a new gated multi-scale self-attention mechanism to model long-range context. Experiments show large improvements over strong <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> on both automated and human evaluations. Human judges prefer stories generated by our approach to those from a strong non-hierarchical model by a factor of two to one.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1083.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1083 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1083 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1083.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1083.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285801215 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1083" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1083/>No Metrics Are Perfect : Adversarial Reward Learning for Visual Storytelling</a></strong><br><a href=/people/x/xin-wang/>Xin Wang</a>
|
<a href=/people/w/wenhu-chen/>Wenhu Chen</a>
|
<a href=/people/y/yuan-fang-wang/>Yuan-Fang Wang</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1083><div class="card-body p-3 small">Though impressive results have been achieved in visual captioning, the task of generating abstract stories from photo streams is still a little-tapped problem. Different from captions, <a href=https://en.wikipedia.org/wiki/Narrative>stories</a> have more expressive language styles and contain many imaginary concepts that do not appear in the <a href=https://en.wikipedia.org/wiki/Image>images</a>. Thus <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> poses challenges to behavioral cloning algorithms. Furthermore, due to the limitations of <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>automatic metrics</a> on evaluating story quality, <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning methods</a> with <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>hand-crafted rewards</a> also face difficulties in gaining an overall performance boost. Therefore, we propose an Adversarial REward Learning (AREL) framework to learn an implicit reward function from human demonstrations, and then optimize policy search with the learned reward function. Though automatic evaluation indicates slight performance boost over state-of-the-art (SOTA) methods in cloning expert behaviors, human evaluation shows that our approach achieves significant improvement in generating more human-like stories than SOTA systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1087.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1087 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1087 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1087.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285801308 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1087" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1087/>Transformation Networks for Target-Oriented Sentiment Classification</a></strong><br><a href=/people/x/xin-li/>Xin Li</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/w/wai-lam/>Wai Lam</a>
|
<a href=/people/b/bei-shi/>Bei Shi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1087><div class="card-body p-3 small">Target-oriented sentiment classification aims at classifying sentiment polarities over individual opinion targets in a sentence. RNN with <a href=https://en.wikipedia.org/wiki/Attention>attention</a> seems a good fit for the characteristics of this <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>, and indeed it achieves the state-of-the-art performance. After re-examining the drawbacks of attention mechanism and the obstacles that block CNN to perform well in this classification task, we propose a new model that achieves new state-of-the-art results on a few benchmarks. Instead of <a href=https://en.wikipedia.org/wiki/Attention>attention</a>, our model employs a CNN layer to extract salient features from the transformed word representations originated from a bi-directional RNN layer. Between the two layers, we propose a component which first generates target-specific representations of words in the sentence, and then incorporates a mechanism for preserving the original contextual information from the RNN layer.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1088.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1088 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1088 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285801326 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1088/>Target-Sensitive Memory Networks for Aspect Sentiment Classification</a></strong><br><a href=/people/s/shuai-wang/>Shuai Wang</a>
|
<a href=/people/s/sahisnu-mazumder/>Sahisnu Mazumder</a>
|
<a href=/people/b/bing-liu/>Bing Liu</a>
|
<a href=/people/m/mianwei-zhou/>Mianwei Zhou</a>
|
<a href=/people/y/yi-chang/>Yi Chang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1088><div class="card-body p-3 small">Aspect sentiment classification (ASC) is a fundamental task in <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>. Given an aspect / target and a sentence, the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> classifies the sentiment polarity expressed on the target in the sentence. Memory networks (MNs) have been used for this task recently and have achieved state-of-the-art results. In MNs, attention mechanism plays a crucial role in detecting the <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment context</a> for the given target. However, we found an important problem with the current MNs in performing the ASC task. Simply improving the attention mechanism will not solve it. The problem is referred to as target-sensitive sentiment, which means that the sentiment polarity of the (detected) context is dependent on the given target and it can not be inferred from the context alone. To tackle this problem, we propose the target-sensitive memory networks (TMNs). Several alternative techniques are designed for the implementation of TMNs and their effectiveness is experimentally evaluated.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1089.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1089 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1089 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1089.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285801356 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1089/>Identifying Transferable Information Across Domains for Cross-domain Sentiment Classification</a></strong><br><a href=/people/r/raksha-sharma/>Raksha Sharma</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a>
|
<a href=/people/s/sandipan-dandapat/>Sandipan Dandapat</a>
|
<a href=/people/h/himanshu-sharad-bhatt/>Himanshu Sharad Bhatt</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1089><div class="card-body p-3 small">Getting manually labeled data in each domain is always an expensive and a time consuming task. Cross-domain sentiment analysis has emerged as a demanding concept where a labeled source domain facilitates a <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment classifier</a> for an unlabeled target domain. However, polarity orientation (positive or negative) and the significance of a word to express an opinion often differ from one domain to another domain. Owing to these differences, cross-domain sentiment classification is still a challenging task. In this paper, we propose that words that do not change their polarity and significance represent the transferable (usable) information across domains for cross-domain sentiment classification. We present a novel approach based on 2 test and cosine-similarity between context vector of words to identify polarity preserving significant words across domains. Furthermore, we show that a weighted ensemble of the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> enhances the cross-domain classification performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1090.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1090 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1090 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1090.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285801380 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1090" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1090/>Unpaired Sentiment-to-Sentiment Translation : A Cycled Reinforcement Learning Approach</a></strong><br><a href=/people/j/jingjing-xu/>Jingjing Xu</a>
|
<a href=/people/x/xu-sun/>Xu Sun</a>
|
<a href=/people/q/qi-zeng/>Qi Zeng</a>
|
<a href=/people/x/xiaodong-zhang/>Xiaodong Zhang</a>
|
<a href=/people/x/xuancheng-ren/>Xuancheng Ren</a>
|
<a href=/people/h/houfeng-wang/>Houfeng Wang</a>
|
<a href=/people/w/wenjie-li/>Wenjie Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1090><div class="card-body p-3 small">The goal of sentiment-to-sentiment translation is to change the underlying sentiment of a sentence while keeping its content. The main challenge is the lack of <a href=https://en.wikipedia.org/wiki/Parallel_computing>parallel data</a>. To solve this problem, we propose a cycled reinforcement learning method that enables training on unpaired data by collaboration between a neutralization module and an emotionalization module. We evaluate our approach on two review datasets, <a href=https://en.wikipedia.org/wiki/Yelp>Yelp</a> and <a href=https://en.wikipedia.org/wiki/Amazon_(company)>Amazon</a>. Experimental results show that our approach significantly outperforms the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art systems</a>. Especially, the proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a> substantially improves the <a href=https://en.wikipedia.org/wiki/Digital_preservation>content preservation</a> performance. The BLEU score is improved from 1.64 to 22.46 and from 0.56 to 14.06 on the two datasets, respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1092.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1092 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1092 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1092.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285802130 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1092/>Working Memory Networks : Augmenting Memory Networks with a Relational Reasoning Module</a></strong><br><a href=/people/j/juan-pavez/>Juan Pavez</a>
|
<a href=/people/h/hector-allende-cid/>Héctor Allende</a>
|
<a href=/people/h/hector-allende-cid/>Héctor Allende-Cid</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1092><div class="card-body p-3 small">During the last years, there has been a lot of interest in achieving some kind of complex reasoning using <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural networks</a>. To do that, models like Memory Networks (MemNNs) have combined external memory storages and <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanisms</a>. These <a href=https://en.wikipedia.org/wiki/Software_architecture>architectures</a>, however, lack of more complex reasoning mechanisms that could allow, for instance, <a href=https://en.wikipedia.org/wiki/Relational_model>relational reasoning</a>. Relation Networks (RNs), on the other hand, have shown outstanding results in relational reasoning tasks. Unfortunately, their <a href=https://en.wikipedia.org/wiki/Computational_cost>computational cost</a> grows quadratically with the number of <a href=https://en.wikipedia.org/wiki/Memory>memories</a>, something prohibitive for larger problems. To solve these issues, we introduce the Working Memory Network, a MemNN architecture with a novel working memory storage and reasoning module. Our model retains the relational reasoning abilities of the RN while reducing its <a href=https://en.wikipedia.org/wiki/Computational_complexity_theory>computational complexity</a> from quadratic to linear. We tested our model on the text QA dataset bAbI and the visual QA dataset NLVR. In the jointly trained bAbI-10k, we set a new <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a>, achieving a <a href=https://en.wikipedia.org/wiki/Mean>mean error</a> of less than 0.5 %. Moreover, a simple <a href=https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)>ensemble</a> of two of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> solves all 20 tasks in the joint version of the <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1094.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1094 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1094 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1094.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285802169 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1094/>Adversarial Contrastive Estimation</a></strong><br><a href=/people/a/avishek-joey-bose/>Avishek Joey Bose</a>
|
<a href=/people/h/huan-ling/>Huan Ling</a>
|
<a href=/people/y/yanshuai-cao/>Yanshuai Cao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1094><div class="card-body p-3 small">Learning by contrasting positive and negative samples is a general strategy adopted by many methods. Noise contrastive estimation (NCE) for <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> and translating embeddings for <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graphs</a> are examples in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> employing this approach. In this work, we view contrastive learning as an abstraction of all such methods and augment the negative sampler into a <a href=https://en.wikipedia.org/wiki/Mixture_distribution>mixture distribution</a> containing an adversarially learned sampler. The resulting adaptive sampler finds harder negative examples, which forces the main <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to learn a better representation of the data. We evaluate our proposal on learning <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a>, <a href=https://en.wikipedia.org/wiki/Order_embedding>order embeddings</a> and knowledge graph embeddings and observe both faster convergence and improved results on multiple metrics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1096.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1096 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1096 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1096.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285802189 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1096" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1096/>Strong Baselines for Neural Semi-Supervised Learning under Domain Shift</a></strong><br><a href=/people/s/sebastian-ruder/>Sebastian Ruder</a>
|
<a href=/people/b/barbara-plank/>Barbara Plank</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1096><div class="card-body p-3 small">Novel neural models have been proposed in recent years for learning under domain shift. Most <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>, however, only evaluate on a single task, on proprietary datasets, or compare to weak baselines, which makes comparison of <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> difficult. In this paper, we re-evaluate classic <a href=https://en.wikipedia.org/wiki/Bootstrapping_(statistics)>general-purpose bootstrapping approaches</a> in the context of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> under <a href=https://en.wikipedia.org/wiki/Bootstrapping_(statistics)>domain shifts</a> vs. recent neural approaches and propose a novel multi-task tri-training method that reduces the time and space complexity of classic tri-training. Extensive experiments on two benchmarks for <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a> and <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> are negative : while our novel method establishes a new state-of-the-art for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>, it does not fare consistently the best. More importantly, we arrive at the somewhat surprising conclusion that classic tri-training, with some additions, outperforms the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. Hence classic <a href=https://en.wikipedia.org/wiki/Methodology>approaches</a> constitute an important and strong baseline.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1098.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1098 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1098 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285802228 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1098/>A Neural Architecture for Automated ICD Coding<span class=acl-fixed-case>ICD</span> Coding</a></strong><br><a href=/people/p/pengtao-xie/>Pengtao Xie</a>
|
<a href=/people/e/eric-xing/>Eric Xing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1098><div class="card-body p-3 small">The International Classification of Diseases (ICD) provides a hierarchy of diagnostic codes for <a href=https://en.wikipedia.org/wiki/Medical_classification>classifying diseases</a>. Medical coding which assigns a subset of ICD codes to a patient visit is a mandatory process that is crucial for patient care and billing. Manual coding is time-consuming, expensive, and error prone. In this paper, we build a neural architecture for <a href=https://en.wikipedia.org/wiki/Computer_programming>automated coding</a>. It takes the diagnosis descriptions (DDs) of a patient as inputs and selects the most relevant <a href=https://en.wikipedia.org/wiki/ICD-10>ICD codes</a>. This architecture contains four major ingredients : (1) tree-of-sequences LSTM encoding of code descriptions (CDs), (2) <a href=https://en.wikipedia.org/wiki/Adversarial_learning>adversarial learning</a> for reconciling the different writing styles of DDs and CDs, (3) isotonic constraints for incorporating the importance order among the assigned codes, and (4) attentional matching for performing many-to-one and one-to-many mappings from DDs to CDs. We demonstrate the effectiveness of the proposed <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> on a <a href=https://en.wikipedia.org/wiki/Data_set>clinical datasets</a> with 59 K patient visits.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1099.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1099 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1099 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1099.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285802247 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1099" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1099/>Domain Adaptation with Adversarial Training and Graph Embeddings</a></strong><br><a href=/people/f/firoj-alam/>Firoj Alam</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/m/muhammad-imran/>Muhammad Imran</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1099><div class="card-body p-3 small">The success of deep neural networks (DNNs) is heavily dependent on the availability of labeled data. However, obtaining <a href=https://en.wikipedia.org/wiki/Labeled_data>labeled data</a> is a big challenge in many real-world problems. In such scenarios, a DNN model can leverage labeled and unlabeled data from a related domain, but it has to deal with the shift in data distributions between the source and the target domains. In this paper, we study the problem of classifying social media posts during a crisis event (e.g., Earthquake). For that, we use labeled and unlabeled data from past similar events (e.g., Flood) and unlabeled data for the current event. We propose a novel model that performs adversarial learning based domain adaptation to deal with distribution drifts and graph based semi-supervised learning to leverage unlabeled data within a single unified deep learning framework. Our experiments with two real-world crisis datasets collected from <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> demonstrate significant improvements over several <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1100.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1100 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1100 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1100.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285802257 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1100/>TDNN : A Two-stage Deep Neural Network for Prompt-independent Automated Essay Scoring<span class=acl-fixed-case>TDNN</span>: A Two-stage Deep Neural Network for Prompt-independent Automated Essay Scoring</a></strong><br><a href=/people/c/cancan-jin/>Cancan Jin</a>
|
<a href=/people/b/ben-he/>Ben He</a>
|
<a href=/people/k/kai-hui/>Kai Hui</a>
|
<a href=/people/l/le-sun/>Le Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1100><div class="card-body p-3 small">Existing automated essay scoring (AES) models rely on rated essays for the target prompt as training data. Despite their successes in prompt-dependent AES, how to effectively predict essay ratings under a prompt-independent setting remains a challenge, where the rated essays for the target prompt are not available. To close this gap, a two-stage deep neural network (TDNN) is proposed. In particular, in the first stage, using the rated essays for non-target prompts as the training data, a shallow model is learned to select essays with an extreme quality for the target prompt, serving as pseudo training data ; in the second stage, an end-to-end hybrid deep model is proposed to learn a prompt-dependent rating model consuming the pseudo training data from the first step. Evaluation of the proposed TDNN on the standard ASAP dataset demonstrates a promising improvement for the prompt-independent AES task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1101.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1101 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1101 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1101.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1101.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285802293 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1101" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1101/>Unsupervised Discrete Sentence Representation Learning for Interpretable Neural Dialog Generation</a></strong><br><a href=/people/t/tiancheng-zhao/>Tiancheng Zhao</a>
|
<a href=/people/k/kyusong-lee/>Kyusong Lee</a>
|
<a href=/people/m/maxine-eskenazi/>Maxine Eskenazi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1101><div class="card-body p-3 small">The encoder-decoder dialog model is one of the most prominent methods used to build <a href=https://en.wikipedia.org/wiki/Dialog_(software)>dialog systems</a> in <a href=https://en.wikipedia.org/wiki/Complex_system>complex domains</a>. Yet <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> is limited because <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> can not output interpretable actions as in traditional <a href=https://en.wikipedia.org/wiki/System>systems</a>, which hinders humans from understanding its generation process. We present an unsupervised discrete sentence representation learning method that can integrate with any existing encoder-decoder dialog models for interpretable response generation. Building upon variational autoencoders (VAEs), we present two novel models, DI-VAE and DI-VST that improve VAEs and can discover interpretable semantics via either auto encoding or context predicting. Our methods have been validated on real-world dialog datasets to discover semantic representations and enhance encoder-decoder models with interpretable generation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1104.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1104 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1104 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1104.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285802339 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1104" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1104/>MojiTalk : Generating Emotional Responses at Scale<span class=acl-fixed-case>M</span>oji<span class=acl-fixed-case>T</span>alk: Generating Emotional Responses at Scale</a></strong><br><a href=/people/x/xianda-zhou/>Xianda Zhou</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1104><div class="card-body p-3 small">Generating emotional language is a key step towards building empathetic natural language processing agents. However, a major challenge for this line of research is the lack of large-scale labeled training data, and previous studies are limited to only small sets of human annotated sentiment labels. Additionally, explicitly controlling the emotion and sentiment of generated text is also difficult. In this paper, we take a more radical approach : we exploit the idea of leveraging Twitter data that are naturally labeled with <a href=https://en.wikipedia.org/wiki/Emoji>emojis</a>. We collect a large corpus of Twitter conversations that include <a href=https://en.wikipedia.org/wiki/Emoji>emojis</a> in the response and assume the <a href=https://en.wikipedia.org/wiki/Emoji>emojis</a> convey the underlying emotions of the sentence. We investigate several conditional variational autoencoders training on these conversations, which allow us to use <a href=https://en.wikipedia.org/wiki/Emoji>emojis</a> to control the emotion of the generated text. Experimentally, we show in our quantitative and qualitative analyses that the proposed models can successfully generate high-quality abstractive conversation responses in accordance with designated emotions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1106.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1106 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1106 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1106.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1106.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285802370 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1106/>A Framework for Representing <a href=https://en.wikipedia.org/wiki/Language_acquisition>Language Acquisition</a> in a Population Setting</a></strong><br><a href=/people/j/jordan-kodner/>Jordan Kodner</a>
|
<a href=/people/c/christopher-cerezo-falco/>Christopher Cerezo Falco</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1106><div class="card-body p-3 small">Language variation and change are driven both by individuals&#8217; internal cognitive processes and by the <a href=https://en.wikipedia.org/wiki/Social_structure>social structures</a> through which language propagates. A wide range of <a href=https://en.wikipedia.org/wiki/Software_framework>computational frameworks</a> have been proposed to connect these drivers. We compare the strengths and weaknesses of existing approaches and propose a new analytic framework which combines previous network models&#8217; ability to capture realistic <a href=https://en.wikipedia.org/wiki/Social_structure>social structure</a> with practically and more elegant computational properties. The framework privileges the process of <a href=https://en.wikipedia.org/wiki/Language_acquisition>language acquisition</a> and embeds learners in a <a href=https://en.wikipedia.org/wiki/Social_network>social network</a> but is modular so that <a href=https://en.wikipedia.org/wiki/Population_structure>population structure</a> can be combined with different <a href=https://en.wikipedia.org/wiki/Language_acquisition>acquisition models</a>. We demonstrate two applications for the <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> : a test of practical concerns that arise when modeling <a href=https://en.wikipedia.org/wiki/Language_acquisition>acquisition</a> in a population setting and an application of the <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> to recent work on phonological mergers in progress.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1107.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1107 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1107 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1107.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285802428 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1107/>Prefix Lexicalization of Synchronous CFGs using Synchronous TAG<span class=acl-fixed-case>CFG</span>s using Synchronous <span class=acl-fixed-case>TAG</span></a></strong><br><a href=/people/l/logan-born/>Logan Born</a>
|
<a href=/people/a/anoop-sarkar/>Anoop Sarkar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1107><div class="card-body p-3 small">We show that an epsilon-free, chain-free synchronous context-free grammar (SCFG) can be converted into a weakly equivalent synchronous tree-adjoining grammar (STAG) which is prefix lexicalized. This transformation at most doubles the grammar&#8217;s rank and cubes its size, but we show that in practice the size increase is only quadratic. Our results extend <a href=https://en.wikipedia.org/wiki/Greibach_normal_form>Greibach normal form</a> from CFGs to SCFGs and prove new formal properties about SCFG, a formalism with many applications in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1108.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1108 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1108 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1108.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285802441 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1108" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1108/>Straight to the Tree : Constituency Parsing with Neural Syntactic Distance</a></strong><br><a href=/people/y/yikang-shen/>Yikang Shen</a>
|
<a href=/people/z/zhouhan-lin/>Zhouhan Lin</a>
|
<a href=/people/a/athul-paul-jacob/>Athul Paul Jacob</a>
|
<a href=/people/a/alessandro-sordoni/>Alessandro Sordoni</a>
|
<a href=/people/a/aaron-courville/>Aaron Courville</a>
|
<a href=/people/y/yoshua-bengio/>Yoshua Bengio</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1108><div class="card-body p-3 small">In this work, we propose a novel constituency parsing scheme. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> first predicts a real-valued scalar, named syntactic distance, for each split position in the sentence. The topology of grammar tree is then determined by the values of syntactic distances. Compared to traditional shift-reduce parsing schemes, our approach is free from the potentially disastrous compounding error. It is also easier to parallelize and much faster. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves the state-of-the-art single model F1 score of 92.1 on PTB and 86.4 on CTB dataset, which surpasses the previous single model results by a large margin.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1109.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1109 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1109 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1109.Notes.zip data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285802453 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1109" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1109/>Gaussian Mixture Latent Vector Grammars<span class=acl-fixed-case>G</span>aussian Mixture Latent Vector Grammars</a></strong><br><a href=/people/y/yanpeng-zhao/>Yanpeng Zhao</a>
|
<a href=/people/l/liwen-zhang/>Liwen Zhang</a>
|
<a href=/people/k/kewei-tu/>Kewei Tu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1109><div class="card-body p-3 small">We introduce Latent Vector Grammars (LVeGs), a new framework that extends latent variable grammars such that each nonterminal symbol is associated with a continuous vector space representing the set of (infinitely many) subtypes of the nonterminal. We show that previous models such as latent variable grammars and compositional vector grammars can be interpreted as special cases of LVeGs. We then present Gaussian Mixture LVeGs (GM-LVeGs), a new special case of LVeGs that uses Gaussian mixtures to formulate the weights of production rules over subtypes of nonterminals. A major advantage of using Gaussian mixtures is that the partition function and the expectations of subtype rules can be computed using an extension of the <a href=https://en.wikipedia.org/wiki/Inside-outside_algorithm>inside-outside algorithm</a>, which enables efficient <a href=https://en.wikipedia.org/wiki/Inference>inference</a> and <a href=https://en.wikipedia.org/wiki/Machine_learning>learning</a>. We apply GM-LVeGs to <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a> and constituency parsing and show that GM-LVeGs can achieve competitive accuracies.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1110.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1110 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1110 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1110.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285802475 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1110" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1110/>Extending a <a href=https://en.wikipedia.org/wiki/Parsing>Parser</a> to Distant Domains Using a Few Dozen Partially Annotated Examples</a></strong><br><a href=/people/v/vidur-joshi/>Vidur Joshi</a>
|
<a href=/people/m/matthew-e-peters/>Matthew Peters</a>
|
<a href=/people/m/mark-hopkins/>Mark Hopkins</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1110><div class="card-body p-3 small">We revisit <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> for <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a> in the neural era. First we show that recent advances in word representations greatly diminish the need for <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> when the target domain is syntactically similar to the source domain. As evidence, we train a <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> on the <a href=https://en.wikipedia.org/wiki/The_Wall_Street_Journal>Wall Street Journal</a> alone that achieves over 90 % <a href=https://en.wikipedia.org/wiki/F-number>F1</a> on the Brown corpus. For more syntactically distant domains, we provide a simple way to adapt a <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> using only dozens of partial annotations. For instance, we increase the percentage of error-free geometry-domain parses in a held-out set from 45 % to 73 % using approximately five dozen training examples. In the process, we demonstrate a new state-of-the-art single model result on the Wall Street Journal test set of 94.3 %. This is an absolute increase of 1.7 % over the previous <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> of 92.6 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1112.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1112 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1112 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1112.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285803381 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1112/>Searching for the X-Factor : Exploring Corpus Subjectivity for Word Embeddings<span class=acl-fixed-case>X</span>-Factor: Exploring Corpus Subjectivity for Word Embeddings</a></strong><br><a href=/people/m/maksim-tkachenko/>Maksim Tkachenko</a>
|
<a href=/people/c/chong-cher-chia/>Chong Cher Chia</a>
|
<a href=/people/h/hady-lauw/>Hady Lauw</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1112><div class="card-body p-3 small">We explore the notion of <a href=https://en.wikipedia.org/wiki/Subjectivity>subjectivity</a>, and hypothesize that word embeddings learnt from input corpora of varying levels of <a href=https://en.wikipedia.org/wiki/Subjectivity>subjectivity</a> behave differently on natural language processing tasks such as classifying a sentence by sentiment, <a href=https://en.wikipedia.org/wiki/Subjectivity>subjectivity</a>, or topic. Through systematic comparative analyses, we establish this to be the case indeed. Moreover, based on the discovery of the outsized role that sentiment words play on subjectivity-sensitive tasks such as sentiment classification, we develop a novel word embedding SentiVec which is infused with sentiment information from a lexical resource, and is shown to outperform baselines on such tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1113.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1113 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1113 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1113.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285803402 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1113/>Word Embedding and WordNet Based Metaphor Identification and Interpretation<span class=acl-fixed-case>W</span>ord<span class=acl-fixed-case>N</span>et Based Metaphor Identification and Interpretation</a></strong><br><a href=/people/r/rui-mao/>Rui Mao</a>
|
<a href=/people/c/chenghua-lin/>Chenghua Lin</a>
|
<a href=/people/f/frank-guerin/>Frank Guerin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1113><div class="card-body p-3 small">Metaphoric expressions are widespread in <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>, posing a significant challenge for various <a href=https://en.wikipedia.org/wiki/Natural_language>natural language processing tasks</a> such as <a href=https://en.wikipedia.org/wiki/Machine_translation>Machine Translation</a>. Current word embedding based metaphor identification models can not identify the exact metaphorical words within a sentence. In this paper, we propose an <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised learning method</a> that identifies and interprets <a href=https://en.wikipedia.org/wiki/Metaphor>metaphors</a> at word-level without any preprocessing, outperforming strong baselines in the metaphor identification task. Our model extends to interpret the identified <a href=https://en.wikipedia.org/wiki/Metaphor>metaphors</a>, paraphrasing them into their literal counterparts, so that they can be better translated by <a href=https://en.wikipedia.org/wiki/Machine>machines</a>. We evaluated this with two popular translation systems for <a href=https://en.wikipedia.org/wiki/English_language>English</a> to <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>, showing that our model improved the <a href=https://en.wikipedia.org/wiki/System>systems</a> significantly.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1117.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1117 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1117 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1117.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1117.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/288152860 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1117/>Context-Aware Neural Machine Translation Learns <a href=https://en.wikipedia.org/wiki/Anaphora_(linguistics)>Anaphora Resolution</a></a></strong><br><a href=/people/e/elena-voita/>Elena Voita</a>
|
<a href=/people/p/pavel-serdyukov/>Pavel Serdyukov</a>
|
<a href=/people/r/rico-sennrich/>Rico Sennrich</a>
|
<a href=/people/i/ivan-titov/>Ivan Titov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1117><div class="card-body p-3 small">Standard <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation systems</a> process sentences in isolation and hence ignore extra-sentential information, even though extended context can both prevent mistakes in ambiguous cases and improve translation coherence. We introduce a context-aware neural machine translation model designed in such way that the flow of information from the extended context to the <a href=https://en.wikipedia.org/wiki/Machine_translation>translation model</a> can be controlled and analyzed. We experiment with an English-Russian subtitles dataset, and observe that much of what is captured by our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> deals with improving pronoun translation. We measure correspondences between induced attention distributions and coreference relations and observe that the model implicitly captures <a href=https://en.wikipedia.org/wiki/Anaphora_(linguistics)>anaphora</a>. It is consistent with gains for sentences where <a href=https://en.wikipedia.org/wiki/Pronoun>pronouns</a> need to be gendered in <a href=https://en.wikipedia.org/wiki/Translation>translation</a>. Beside improvements in <a href=https://en.wikipedia.org/wiki/Anaphora_(linguistics)>anaphoric cases</a>, the model also improves in overall BLEU, both over its <a href=https://en.wikipedia.org/wiki/Context-free_grammar>context-agnostic version</a> (+0.7) and over simple concatenation of the context and source sentences (+0.6).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1118.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1118 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1118 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1118.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/288152852 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1118/>Document Context Neural Machine Translation with Memory Networks</a></strong><br><a href=/people/s/sameen-maruf/>Sameen Maruf</a>
|
<a href=/people/g/gholamreza-haffari/>Gholamreza Haffari</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1118><div class="card-body p-3 small">We present a document-level neural machine translation model which takes both source and target document context into account using memory networks. We model the <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> as a structured prediction problem with interdependencies among the <a href=https://en.wikipedia.org/wiki/Variable_(mathematics)>observed and hidden variables</a>, i.e., the source sentences and their unobserved target translations in the document. The resulting structured prediction problem is tackled with a neural translation model equipped with two memory components, one each for the source and target side, to capture the documental interdependencies. We train the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> end-to-end, and propose an iterative decoding algorithm based on block coordinate descent. Experimental results of English translations from French, German, and Estonian documents show that our model is effective in exploiting both source and target document context, and statistically significantly outperforms the previous work in terms of <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a> and <a href=https://en.wikipedia.org/wiki/METEOR>METEOR</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1120.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1120 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1120 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285803482 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1120/>Learning Prototypical Goal Activities for Locations</a></strong><br><a href=/people/t/tianyu-jiang/>Tianyu Jiang</a>
|
<a href=/people/e/ellen-riloff/>Ellen Riloff</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1120><div class="card-body p-3 small">People go to different places to engage in activities that reflect their goals. For example, people go to restaurants to eat, libraries to study, and churches to pray. We refer to an activity that represents a common reason why people typically go to a location as a prototypical goal activity (goal-act). Our research aims to learn goal-acts for specific locations using a <a href=https://en.wikipedia.org/wiki/Text_corpus>text corpus</a> and <a href=https://en.wikipedia.org/wiki/Semi-supervised_learning>semi-supervised learning</a>. First, we extract activities and locations that co-occur in goal-oriented syntactic patterns. Next, we create an activity profile matrix and apply a semi-supervised label propagation algorithm to iteratively revise the activity strengths for different locations using a small set of labeled data. We show that this approach outperforms several baseline methods when judged against goal-acts identified by human annotators.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1121.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1121 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1121 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285803502 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1121/>Guess Me if You Can : Acronym Disambiguation for Enterprises</a></strong><br><a href=/people/y/yang-li/>Yang Li</a>
|
<a href=/people/b/bo-zhao/>Bo Zhao</a>
|
<a href=/people/a/ariel-fuxman/>Ariel Fuxman</a>
|
<a href=/people/f/fangbo-tao/>Fangbo Tao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1121><div class="card-body p-3 small">Acronyms are abbreviations formed from the initial components of words or phrases. In <a href=https://en.wikipedia.org/wiki/Business>enterprises</a>, people often use <a href=https://en.wikipedia.org/wiki/Acronym>acronyms</a> to make communications more efficient. However, <a href=https://en.wikipedia.org/wiki/Acronym>acronyms</a> could be difficult to understand for people who are not familiar with the subject matter (new employees, etc.), thereby affecting productivity. To alleviate such troubles, we study how to automatically resolve the true meanings of <a href=https://en.wikipedia.org/wiki/Acronym>acronyms</a> in a given context. Acronym disambiguation for <a href=https://en.wikipedia.org/wiki/Business>enterprises</a> is challenging for several reasons. First, acronyms may be highly ambiguous since an <a href=https://en.wikipedia.org/wiki/Acronym>acronym</a> used in the <a href=https://en.wikipedia.org/wiki/Business>enterprise</a> could have multiple internal and external meanings. Second, there are usually no comprehensive <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge bases</a> such as <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a> available in enterprises. Finally, the <a href=https://en.wikipedia.org/wiki/System>system</a> should be generic to work for any enterprise. In this work we propose an end-to-end framework to tackle all these challenges. The <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> takes the enterprise corpus as input and produces a high-quality acronym disambiguation system as output. Our disambiguation models are trained via distant supervised learning, without requiring any manually labeled training examples. Therefore, our proposed <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> can be deployed to any enterprise to support high-quality <a href=https://en.wikipedia.org/wiki/Acronym>acronym disambiguation</a>. Experimental results on real world data justified the effectiveness of our <a href=https://en.wikipedia.org/wiki/System>system</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1122.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1122 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1122 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1122.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1122.Notes.pdf data-toggle=tooltip data-placement=top title=Notes><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285803517 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1122/>A Multi-Axis Annotation Scheme for Event Temporal Relations</a></strong><br><a href=/people/q/qiang-ning/>Qiang Ning</a>
|
<a href=/people/h/hao-wu/>Hao Wu</a>
|
<a href=/people/d/dan-roth/>Dan Roth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1122><div class="card-body p-3 small">Existing temporal relation (TempRel) annotation schemes often have low inter-annotator agreements (IAA) even between experts, suggesting that the current annotation task needs a better definition. This paper proposes a new multi-axis modeling to better capture the temporal structure of events. In addition, we identify that event end-points are a major source of confusion in <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a>, so we also propose to annotate TempRels based on start-points only. A pilot expert annotation effort using the proposed scheme shows significant improvement in IAA from the conventional 60&#8217;s to 80&#8217;s (Cohen&#8217;s Kappa). This better-defined annotation scheme further enables the use of <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing</a> to alleviate the labor intensity for each annotator. We hope that this work can foster more interesting studies towards <a href=https://en.wikipedia.org/wiki/Event_(probability_theory)>event understanding</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1124.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1124 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1124 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285803553 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1124/>DialSQL : Dialogue Based Structured Query Generation<span class=acl-fixed-case>D</span>ial<span class=acl-fixed-case>SQL</span>: Dialogue Based Structured Query Generation</a></strong><br><a href=/people/i/izzeddin-gur/>Izzeddin Gur</a>
|
<a href=/people/s/semih-yavuz/>Semih Yavuz</a>
|
<a href=/people/y/yu-su/>Yu Su</a>
|
<a href=/people/x/xifeng-yan/>Xifeng Yan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1124><div class="card-body p-3 small">The recent advance in <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> and <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a> has significantly improved the translation accuracy of <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language questions</a> to structured queries. However, further improvement of the existing <a href=https://en.wikipedia.org/wiki/Scientific_method>approaches</a> turns out to be quite challenging. Rather than solely relying on algorithmic innovations, in this work, we introduce DialSQL, a dialogue-based structured query generation framework that leverages <a href=https://en.wikipedia.org/wiki/Human_intelligence>human intelligence</a> to boost the performance of existing <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> via user interaction. DialSQL is capable of identifying potential errors in a generated <a href=https://en.wikipedia.org/wiki/SQL>SQL query</a> and asking users for validation via simple <a href=https://en.wikipedia.org/wiki/Multiple_choice>multi-choice questions</a>. User feedback is then leveraged to revise the query. We design a generic simulator to bootstrap synthetic training dialogues and evaluate the performance of DialSQL on the WikiSQL dataset. Using SQLNet as a black box query generation tool, DialSQL improves its performance from 61.3 % to 69.0 % using only 2.4 validation questions per dialogue.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1126.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1126 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1126 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1126.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1126.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285803604 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1126/>Are BLEU and Meaning Representation in Opposition?<span class=acl-fixed-case>BLEU</span> and Meaning Representation in Opposition?</a></strong><br><a href=/people/o/ondrej-cifka/>Ondřej Cífka</a>
|
<a href=/people/o/ondrej-bojar/>Ondřej Bojar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1126><div class="card-body p-3 small">One of possible ways of obtaining continuous-space sentence representations is by training neural machine translation (NMT) systems. The recent attention mechanism however removes the single point in the <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> from which the source sentence representation can be extracted. We propose several variations of the attentive NMT architecture bringing this meeting point back. Empirical evaluation suggests that the better the translation quality, the worse the learned sentence representations serve in a wide range of classification and similarity tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1128.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1128 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1128 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1128.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285803636 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1128" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1128/>The Hitchhiker’s Guide to Testing Statistical Significance in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a></a></strong><br><a href=/people/r/rotem-dror/>Rotem Dror</a>
|
<a href=/people/g/gili-baumer/>Gili Baumer</a>
|
<a href=/people/s/segev-shlomov/>Segev Shlomov</a>
|
<a href=/people/r/roi-reichart/>Roi Reichart</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1128><div class="card-body p-3 small">Statistical significance testing is a standard <a href=https://en.wikipedia.org/wiki/Statistics>statistical tool</a> designed to ensure that experimental results are not coincidental. In this opinion/ theoretical paper we discuss the role of <a href=https://en.wikipedia.org/wiki/Statistical_significance>statistical significance testing</a> in Natural Language Processing (NLP) research. We establish the fundamental concepts of <a href=https://en.wikipedia.org/wiki/Statistical_significance>significance testing</a> and discuss the specific aspects of NLP tasks, experimental setups and evaluation measures that affect the choice of <a href=https://en.wikipedia.org/wiki/Statistical_significance>significance tests</a> in NLP research. Based on this discussion we propose a simple practical <a href=https://en.wikipedia.org/wiki/Protocol_(science)>protocol</a> for statistical significance test selection in NLP setups and accompany this <a href=https://en.wikipedia.org/wiki/Protocol_(science)>protocol</a> with a brief survey of the most relevant tests. We then survey recent empirical papers published in ACL and TACL during 2017 and show that while our community assigns great value to experimental results, statistical significance testing is often ignored or misused. We conclude with a brief discussion of open issues that should be properly addressed so that this important <a href=https://en.wikipedia.org/wiki/Tool>tool</a> can be applied. in <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP research</a> in a statistically sound manner.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1130.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1130 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1130 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1130.Notes.zip data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1130.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285803695 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1130" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1130/>Stack-Pointer Networks for Dependency Parsing</a></strong><br><a href=/people/x/xuezhe-ma/>Xuezhe Ma</a>
|
<a href=/people/z/zecong-hu/>Zecong Hu</a>
|
<a href=/people/j/jingzhou-liu/>Jingzhou Liu</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1130><div class="card-body p-3 small">We introduce a novel <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> for dependency parsing : stack-pointer networks (StackPtr). Combining pointer networks (Vinyals et al., 2015) with an internal stack, the proposed model first reads and encodes the whole sentence, then builds the dependency tree top-down (from root-to-leaf) in a depth-first fashion. The <a href=https://en.wikipedia.org/wiki/Call_stack>stack</a> tracks the status of the <a href=https://en.wikipedia.org/wiki/Depth-first_search>depth-first search</a> and the pointer networks select one child for the word at the top of the stack at each step. The StackPtr parser benefits from the information of whole sentence and all previously derived subtree structures, and removes the left-to-right restriction in classical transition-based parsers. Yet the number of steps for building any (non-projective) parse tree is linear in the length of the sentence just as other transition-based parsers, yielding an efficient decoding algorithm with O(n^2) time complexity. We evaluate our model on 29 treebanks spanning 20 languages and different dependency annotation schemas, and achieve state-of-the-art performances on 21 of them<tex-math>O(n^2)</tex-math> time complexity. We evaluate our model on 29 treebanks spanning 20 languages and different dependency annotation schemas, and achieve state-of-the-art performances on 21 of them</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1131.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1131 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1131 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285803712 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1131/>Twitter Universal Dependency Parsing for African-American and Mainstream American English<span class=acl-fixed-case>T</span>witter <span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependency Parsing for <span class=acl-fixed-case>A</span>frican-<span class=acl-fixed-case>A</span>merican and Mainstream <span class=acl-fixed-case>A</span>merican <span class=acl-fixed-case>E</span>nglish</a></strong><br><a href=/people/s/su-lin-blodgett/>Su Lin Blodgett</a>
|
<a href=/people/j/johnny-wei/>Johnny Wei</a>
|
<a href=/people/b/brendan-oconnor/>Brendan O’Connor</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1131><div class="card-body p-3 small">Due to the presence of both Twitter-specific conventions and <a href=https://en.wikipedia.org/wiki/Non-standard_dialect>non-standard and dialectal language</a>, <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> presents a significant parsing challenge to current dependency parsing tools. We broaden English dependency parsing to handle social media English, particularly social media African-American English (AAE), by developing and annotating a new dataset of 500 tweets, 250 of which are in AAE, within the Universal Dependencies 2.0 framework. We describe our standards for handling Twitter- and AAE-specific features and evaluate a variety of cross-domain strategies for improving <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a> with no, or very little, in-domain labeled data, including a new data synthesis approach. We analyze these methods&#8217; impact on performance disparities between AAE and Mainstream American English tweets, and assess parsing accuracy for specific AAE lexical and syntactic features. Our annotated data and a parsing model are available at :.<url>http://slanglab.cs.umass.edu/TwitterAAE/</url>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1132.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1132 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1132 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1132.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285803729 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1132/>LSTMs Can Learn Syntax-Sensitive Dependencies Well, But <a href=https://en.wikipedia.org/wiki/Structure_(mathematical_logic)>Modeling Structure</a> Makes Them Better<span class=acl-fixed-case>LSTM</span>s Can Learn Syntax-Sensitive Dependencies Well, But Modeling Structure Makes Them Better</a></strong><br><a href=/people/a/adhiguna-kuncoro/>Adhiguna Kuncoro</a>
|
<a href=/people/c/chris-dyer/>Chris Dyer</a>
|
<a href=/people/j/john-hale/>John Hale</a>
|
<a href=/people/d/dani-yogatama/>Dani Yogatama</a>
|
<a href=/people/s/stephen-clark/>Stephen Clark</a>
|
<a href=/people/p/phil-blunsom/>Phil Blunsom</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1132><div class="card-body p-3 small">Language exhibits hierarchical structure, but recent work using a subject-verb agreement diagnostic argued that state-of-the-art language models, LSTMs, fail to learn long-range syntax sensitive dependencies. Using the same diagnostic, we show that, in fact, LSTMs do succeed in learning such dependenciesprovided they have enough capacity. We then explore whether <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> that have access to explicit syntactic information learn <a href=https://en.wikipedia.org/wiki/Agreement_(linguistics)>agreement</a> more effectively, and how the way in which this structural information is incorporated into the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> impacts performance. We find that the mere presence of syntactic information does not improve <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, but when model architecture is determined by <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a>, <a href=https://en.wikipedia.org/wiki/Agreement_(linguistics)>number agreement</a> is improved. Further, we find that the choice of how syntactic structure is built affects how well <a href=https://en.wikipedia.org/wiki/Agreement_(linguistics)>number agreement</a> is learned : <a href=https://en.wikipedia.org/wiki/Top-down_and_bottom-up_design>top-down construction</a> outperforms <a href=https://en.wikipedia.org/wiki/Top-down_and_bottom-up_design>left-corner and bottom-up variants</a> in capturing non-local structural dependencies.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1133.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1133 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1133 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1133.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1133" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1133/>Sequicity : Simplifying Task-oriented Dialogue Systems with Single Sequence-to-Sequence Architectures<span class=acl-fixed-case>S</span>equicity: Simplifying Task-oriented Dialogue Systems with Single Sequence-to-Sequence Architectures</a></strong><br><a href=/people/w/wenqiang-lei/>Wenqiang Lei</a>
|
<a href=/people/x/xisen-jin/>Xisen Jin</a>
|
<a href=/people/m/min-yen-kan/>Min-Yen Kan</a>
|
<a href=/people/z/zhaochun-ren/>Zhaochun Ren</a>
|
<a href=/people/x/xiangnan-he/>Xiangnan He</a>
|
<a href=/people/d/dawei-yin/>Dawei Yin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1133><div class="card-body p-3 small">Existing solutions to task-oriented dialogue systems follow <a href=https://en.wikipedia.org/wiki/Pipeline_(software)>pipeline designs</a> which introduces <a href=https://en.wikipedia.org/wiki/Architecture>architectural complexity</a> and <a href=https://en.wikipedia.org/wiki/Fragility>fragility</a>. We propose a novel, holistic, extendable framework based on a single sequence-to-sequence (seq2seq) model which can be optimized with supervised or reinforcement learning. A key contribution is that we design text spans named belief spans to track dialogue believes, allowing task-oriented dialogue systems to be modeled in a seq2seq way. Based on this, we propose a simplistic Two Stage CopyNet instantiation which emonstrates good scalability : significantly reducing model complexity in terms of number of parameters and <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training time</a> by a magnitude. It significantly outperforms state-of-the-art pipeline-based methods on large datasets and retains a satisfactory entity match rate on out-of-vocabulary (OOV) cases where pipeline-designed competitors totally fail.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1136.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1136 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1136 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1136.Notes.zip data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1136.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1136" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1136/>Mem2Seq : Effectively Incorporating Knowledge Bases into End-to-End Task-Oriented Dialog Systems<span class=acl-fixed-case>M</span>em2<span class=acl-fixed-case>S</span>eq: Effectively Incorporating Knowledge Bases into End-to-End Task-Oriented Dialog Systems</a></strong><br><a href=/people/a/andrea-madotto/>Andrea Madotto</a>
|
<a href=/people/c/chien-sheng-wu/>Chien-Sheng Wu</a>
|
<a href=/people/p/pascale-fung/>Pascale Fung</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1136><div class="card-body p-3 small">End-to-end task-oriented dialog systems usually suffer from the challenge of incorporating knowledge bases. In this paper, we propose a novel yet simple end-to-end differentiable model called memory-to-sequence (Mem2Seq) to address this issue. Mem2Seq is the first neural generative model that combines the <a href=https://en.wikipedia.org/wiki/Attentional_control>multi-hop attention</a> over memories with the idea of pointer network. We empirically show how Mem2Seq controls each generation step, and how its multi-hop attention mechanism helps in learning correlations between memories. In addition, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is quite general without complicated task-specific designs. As a result, we show that Mem2Seq can be trained faster and attain the state-of-the-art performance on three different task-oriented dialog datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1137.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1137 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1137 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1137.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1137/>Tailored Sequence to Sequence Models to Different Conversation Scenarios</a></strong><br><a href=/people/h/hainan-zhang/>Hainan Zhang</a>
|
<a href=/people/y/yanyan-lan/>Yanyan Lan</a>
|
<a href=/people/j/jiafeng-guo/>Jiafeng Guo</a>
|
<a href=/people/j/jun-xu/>Jun Xu</a>
|
<a href=/people/x/xueqi-cheng/>Xueqi Cheng</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1137><div class="card-body p-3 small">Sequence to sequence (Seq2Seq) models have been widely used for response generation in the area of <a href=https://en.wikipedia.org/wiki/Conversation>conversation</a>. However, the requirements for different conversation scenarios are distinct. For example, <a href=https://en.wikipedia.org/wiki/Customer_service>customer service</a> requires the generated responses to be specific and accurate, while <a href=https://en.wikipedia.org/wiki/Chatbot>chatbot</a> prefers diverse responses so as to attract different users. The current Seq2Seq model fails to meet these diverse requirements, by using a general average likelihood as the optimization criteria. As a result, it usually generates safe and commonplace responses, such as &#8216;I do n&#8217;t know&#8217;. In this paper, we propose two tailored optimization criteria for Seq2Seq to different <a href=https://en.wikipedia.org/wiki/Conversation_analysis>conversation scenarios</a>, i.e., the <a href=https://en.wikipedia.org/wiki/Maximum_likelihood_estimation>maximum generated likelihood</a> for specific-requirement scenario, and the <a href=https://en.wikipedia.org/wiki/Conditional_value_at_risk>conditional value-at-risk</a> for diverse-requirement scenario. Experimental results on the Ubuntu dialogue corpus (Ubuntu service scenario) and Chinese Weibo dataset (social chatbot scenario) show that our proposed models not only satisfies diverse requirements for different scenarios, but also yields better performances against traditional Seq2Seq models in terms of both metric-based and human evaluations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1140.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1140 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1140 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1140.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1140.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1140/>Sentiment Adaptive End-to-End Dialog Systems</a></strong><br><a href=/people/w/weiyan-shi/>Weiyan Shi</a>
|
<a href=/people/z/zhou-yu/>Zhou Yu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1140><div class="card-body p-3 small">End-to-end learning framework is useful for building <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialog systems</a> for its simplicity in training and efficiency in model updating. However, current <a href=https://en.wikipedia.org/wiki/End-to-end_principle>end-to-end approaches</a> only consider user semantic inputs in learning and under-utilize other <a href=https://en.wikipedia.org/wiki/User_information>user information</a>. Therefore, we propose to include user sentiment obtained through multimodal information (acoustic, dialogic and textual), in the end-to-end learning framework to make systems more user-adaptive and effective. We incorporated user sentiment information in both supervised and reinforcement learning settings. In both settings, adding <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment information</a> reduced the dialog length and improved the task success rate on a bus information search task. This work is the first attempt to incorporate multimodal user information in the adaptive end-to-end dialog system training framework and attained state-of-the-art performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1141.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1141 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1141 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1141.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1141/>Embedding Learning Through Multilingual Concept Induction</a></strong><br><a href=/people/p/philipp-dufter/>Philipp Dufter</a>
|
<a href=/people/m/mengjie-zhao/>Mengjie Zhao</a>
|
<a href=/people/m/martin-schmitt/>Martin Schmitt</a>
|
<a href=/people/a/alexander-fraser/>Alexander Fraser</a>
|
<a href=/people/h/hinrich-schutze/>Hinrich Schütze</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1141><div class="card-body p-3 small">We present a new method for estimating vector space representations of words : embedding learning by concept induction. We test this method on a highly parallel corpus and learn semantic representations of words in 1259 different languages in a single common space. An extensive experimental evaluation on crosslingual word similarity and <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> indicates that concept-based multilingual embedding learning performs better than previous approaches.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1143.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1143 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1143 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1143.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1143/>Language Modeling for <a href=https://en.wikipedia.org/wiki/Code_mixing>Code-Mixing</a> : The Role of <a href=https://en.wikipedia.org/wiki/Linguistic_theory>Linguistic Theory</a> based Synthetic Data</a></strong><br><a href=/people/a/adithya-pratapa/>Adithya Pratapa</a>
|
<a href=/people/g/gayatri-bhat/>Gayatri Bhat</a>
|
<a href=/people/m/monojit-choudhury/>Monojit Choudhury</a>
|
<a href=/people/s/sunayana-sitaram/>Sunayana Sitaram</a>
|
<a href=/people/s/sandipan-dandapat/>Sandipan Dandapat</a>
|
<a href=/people/k/kalika-bali/>Kalika Bali</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1143><div class="card-body p-3 small">Training language models for Code-mixed (CM) language is known to be a difficult problem because of lack of data compounded by the increased confusability due to the presence of more than one language. We present a computational technique for creation of grammatically valid artificial CM data based on the Equivalence Constraint Theory. We show that when training examples are sampled appropriately from this synthetic data and presented in certain order (aka training curriculum) along with monolingual and real CM data, it can significantly reduce the perplexity of an RNN-based language model. We also show that randomly generated CM data does not help in decreasing the perplexity of the LMs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1148.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1148 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1148 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1148.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1148" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1148/>Improving Entity Linking by Modeling Latent Relations between Mentions</a></strong><br><a href=/people/p/phong-le/>Phong Le</a>
|
<a href=/people/i/ivan-titov/>Ivan Titov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1148><div class="card-body p-3 small">Entity linking involves aligning textual mentions of named entities to their corresponding entries in a <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge base</a>. Entity linking systems often exploit relations between textual mentions in a document (e.g., coreference) to decide if the linking decisions are compatible. Unlike previous approaches, which relied on <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised systems</a> or <a href=https://en.wikipedia.org/wiki/Heuristic>heuristics</a> to predict these relations, we treat relations as <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variables</a> in our neural entity-linking model. We induce the relations without any <a href=https://en.wikipedia.org/wiki/Supervisor>supervision</a> while optimizing the entity-linking system in an end-to-end fashion. Our multi-relational model achieves the best reported scores on the standard benchmark (AIDA-CoNLL) and substantially outperforms its relation-agnostic version. Its training also converges much faster, suggesting that the injected structural bias helps to explain regularities in the training data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1149.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1149 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1149 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1149.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1149" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1149/>Dating Documents using Graph Convolution Networks</a></strong><br><a href=/people/s/shikhar-vashishth/>Shikhar Vashishth</a>
|
<a href=/people/s/shib-sankar-dasgupta/>Shib Sankar Dasgupta</a>
|
<a href=/people/s/swayambhu-nath-ray/>Swayambhu Nath Ray</a>
|
<a href=/people/p/partha-talukdar/>Partha Talukdar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1149><div class="card-body p-3 small">Document date is essential for many important tasks, such as <a href=https://en.wikipedia.org/wiki/Document_retrieval>document retrieval</a>, <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a>, event detection, etc. While existing approaches for these tasks assume accurate knowledge of the document date, this is not always available, especially for arbitrary documents from the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>Web</a>. Document Dating is a challenging <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> which requires inference over the temporal structure of the document. Prior document dating systems have largely relied on handcrafted features while ignoring such document-internal structures. In this paper, we propose NeuralDater, a Graph Convolutional Network (GCN) based document dating approach which jointly exploits syntactic and temporal graph structures of document in a principled way. To the best of our knowledge, this is the first application of <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> for the problem of document dating. Through extensive experiments on real-world datasets, we find that NeuralDater significantly outperforms state-of-the-art baseline by 19 % absolute (45 % relative) accuracy points.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1150.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1150 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1150 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1150.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1150" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1150/>A Graph-to-Sequence Model for AMR-to-Text Generation<span class=acl-fixed-case>AMR</span>-to-Text Generation</a></strong><br><a href=/people/l/linfeng-song/>Linfeng Song</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a>
|
<a href=/people/z/zhiguo-wang/>Zhiguo Wang</a>
|
<a href=/people/d/daniel-gildea/>Daniel Gildea</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1150><div class="card-body p-3 small">The problem of AMR-to-text generation is to recover a text representing the same meaning as an input AMR graph. The current state-of-the-art method uses a sequence-to-sequence model, leveraging LSTM for encoding a linearized AMR structure. Although being able to model non-local semantic information, a sequence LSTM can lose information from the AMR graph structure, and thus facing challenges with large-graphs, which result in long sequences. We introduce a neural graph-to-sequence model, using a novel LSTM structure for directly encoding graph-level semantics. On a standard <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmark</a>, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> shows superior results to existing methods in the literature.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1152.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1152 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1152 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1152.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1152.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1152" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1152/>Learning to Write with Cooperative Discriminators</a></strong><br><a href=/people/a/ari-holtzman/>Ari Holtzman</a>
|
<a href=/people/j/jan-buys/>Jan Buys</a>
|
<a href=/people/m/maxwell-forbes/>Maxwell Forbes</a>
|
<a href=/people/a/antoine-bosselut/>Antoine Bosselut</a>
|
<a href=/people/d/david-golub/>David Golub</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1152><div class="card-body p-3 small">Despite their local fluency, long-form text generated from RNNs is often generic, repetitive, and even self-contradictory. We propose a unified learning framework that collectively addresses all the above issues by composing a committee of discriminators that can guide a base RNN generator towards more globally coherent generations. More concretely, discriminators each specialize in a different principle of communication, such as <a href=https://en.wikipedia.org/wiki/Grice&#8217;s_maxims>Grice&#8217;s maxims</a>, and are collectively combined with the base RNN generator through a composite decoding objective. Human evaluation demonstrates that text generated by our model is preferred over that of baselines by a large margin, significantly enhancing the overall coherence, style, and information of the generations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1153.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1153 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1153 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1153.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1153/>A Neural Approach to Pun Generation</a></strong><br><a href=/people/z/zhiwei-yu/>Zhiwei Yu</a>
|
<a href=/people/j/jiwei-tan/>Jiwei Tan</a>
|
<a href=/people/x/xiaojun-wan/>Xiaojun Wan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1153><div class="card-body p-3 small">Automatic pun generation is an interesting and challenging text generation task. Previous efforts rely on <a href=https://en.wikipedia.org/wiki/Template_(word_processing)>templates</a> or laboriously manually annotated pun datasets, which heavily constrains the quality and diversity of generated puns. Since sequence-to-sequence models provide an effective technique for text generation, it is promising to investigate these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on the pun generation task. In this paper, we propose neural network models for homographic pun generation, and they can generate <a href=https://en.wikipedia.org/wiki/Pun>puns</a> without requiring any pun data for training. We first train a conditional neural language model from a general text corpus, and then generate puns from the <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> with an elaborately designed decoding algorithm. Automatic and human evaluations show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are able to generate homographic puns of good readability and quality.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1154.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1154 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1154 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1154.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1154" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1154/>Learning to Generate Move-by-Move Commentary for Chess Games from Large-Scale Social Forum Data</a></strong><br><a href=/people/h/harsh-jhamtani/>Harsh Jhamtani</a>
|
<a href=/people/v/varun-gangal/>Varun Gangal</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/t/taylor-berg-kirkpatrick/>Taylor Berg-Kirkpatrick</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1154><div class="card-body p-3 small">This paper examines the problem of generating natural language descriptions of chess games. We introduce a new large-scale chess commentary dataset and propose methods to generate commentary for individual moves in a <a href=https://en.wikipedia.org/wiki/Chess>chess game</a>. The introduced <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> consists of more than 298 K chess move-commentary pairs across 11 K chess games. We highlight how this task poses unique research challenges in <a href=https://en.wikipedia.org/wiki/Natural-language_generation>natural language generation</a> : the <a href=https://en.wikipedia.org/wiki/Data>data</a> contain a large variety of styles of commentary and frequently depend on pragmatic context. We benchmark various baselines and propose an end-to-end trainable neural model which takes into account multiple pragmatic aspects of the game state that may be commented upon to describe a given chess move. Through a human study on predictions for a subset of the <a href=https://en.wikipedia.org/wiki/Data>data</a> which deals with direct move descriptions, we observe that outputs from our models are rated similar to ground truth commentary texts in terms of <a href=https://en.wikipedia.org/wiki/Correctness_(computer_science)>correctness</a> and <a href=https://en.wikipedia.org/wiki/Fluency>fluency</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1155.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1155 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1155 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1155.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1155.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1155" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1155/>From Credit Assignment to Entropy Regularization : Two New <a href=https://en.wikipedia.org/wiki/Algorithm>Algorithms</a> for Neural Sequence Prediction</a></strong><br><a href=/people/z/zihang-dai/>Zihang Dai</a>
|
<a href=/people/q/qizhe-xie/>Qizhe Xie</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1155><div class="card-body p-3 small">In this work, we study the credit assignment problem in reward augmented maximum likelihood (RAML) learning, and establish a theoretical equivalence between the token-level counterpart of RAML and the entropy regularized reinforcement learning. Inspired by the connection, we propose two sequence prediction algorithms, one extending RAML with fine-grained credit assignment and the other improving Actor-Critic with a systematic entropy regularization. On two benchmark datasets, we show the proposed algorithms outperform RAML and Actor-Critic respectively, providing new alternatives to sequence prediction.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1156.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1156 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1156 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1156.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1156" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1156/>DuoRC : Towards Complex Language Understanding with Paraphrased Reading Comprehension<span class=acl-fixed-case>D</span>uo<span class=acl-fixed-case>RC</span>: Towards Complex Language Understanding with Paraphrased Reading Comprehension</a></strong><br><a href=/people/a/amrita-saha/>Amrita Saha</a>
|
<a href=/people/r/rahul-aralikatte/>Rahul Aralikatte</a>
|
<a href=/people/m/mitesh-m-khapra/>Mitesh M. Khapra</a>
|
<a href=/people/k/karthik-sankaranarayanan/>Karthik Sankaranarayanan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1156><div class="card-body p-3 small">We propose DuoRC, a novel dataset for Reading Comprehension (RC) that motivates several new challenges for neural approaches in <a href=https://en.wikipedia.org/wiki/Language_understanding>language understanding</a> beyond those offered by existing RC datasets. DuoRC contains 186,089 unique question-answer pairs created from a collection of 7680 pairs of movie plots where each pair in the <a href=https://en.wikipedia.org/wiki/Collection_(abstract_data_type)>collection</a> reflects two versions of the same movie-one from Wikipedia and the other from IMDb-written by two different authors. We asked crowdsourced workers to create questions from one version of the plot and a different set of workers to extract or synthesize answers from the other version. This unique characteristic of DuoRC where questions and answers are created from different versions of a document narrating the same underlying story, ensures by design, that there is very little lexical overlap between the questions created from one version and the segments containing the answer in the other version. Further, since the two versions have different levels of plot detail, narration style, <a href=https://en.wikipedia.org/wiki/Vocabulary>vocabulary</a>, etc., answering questions from the second version requires deeper <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>language understanding</a> and incorporating external background knowledge. Additionally, the narrative style of passages arising from movie plots (as opposed to typical descriptive passages in existing datasets) exhibits the need to perform complex reasoning over events across multiple sentences. Indeed, we observe that state-of-the-art neural RC models which have achieved near human performance on the SQuAD dataset, even when coupled with traditional NLP techniques to address the challenges presented in DuoRC exhibit very poor performance (F1 score of 37.42 % on DuoRC v / s 86 % on SQuAD dataset).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1157.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1157 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1157 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1157.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1157" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1157/>Stochastic Answer Networks for Machine Reading Comprehension</a></strong><br><a href=/people/x/xiaodong-liu/>Xiaodong Liu</a>
|
<a href=/people/y/yelong-shen/>Yelong Shen</a>
|
<a href=/people/k/kevin-duh/>Kevin Duh</a>
|
<a href=/people/j/jianfeng-gao/>Jianfeng Gao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1157><div class="card-body p-3 small">We propose a simple yet robust stochastic answer network (SAN) that simulates multi-step reasoning in machine reading comprehension. Compared to previous work such as ReasoNet which used <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a> to determine the number of steps, the unique feature is the use of a kind of stochastic prediction dropout on the answer module (final layer) of the <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> during the training. We show that this simple trick improves robustness and achieves results competitive to the state-of-the-art on the Stanford Question Answering Dataset (SQuAD), the Adversarial SQuAD, and the Microsoft MAchine Reading COmprehension Dataset (MS MARCO).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1159.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1159 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1159 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-1159/>Joint Training of Candidate Extraction and Answer Selection for Reading Comprehension</a></strong><br><a href=/people/z/zhen-wang/>Zhen Wang</a>
|
<a href=/people/j/jiachen-liu/>Jiachen Liu</a>
|
<a href=/people/x/xinyan-xiao/>Xinyan Xiao</a>
|
<a href=/people/y/yajuan-lyu/>Yajuan Lyu</a>
|
<a href=/people/t/tian-wu/>Tian Wu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1159><div class="card-body p-3 small">While sophisticated neural-based techniques have been developed in <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a>, most approaches model the answer in an independent manner, ignoring its relations with other answer candidates. This problem can be even worse in open-domain scenarios, where candidates from multiple passages should be combined to answer a single question. In this paper, we formulate <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a> as an extract-then-select two-stage procedure. We first extract answer candidates from passages, then select the final answer by combining information from all the candidates. Furthermore, we regard candidate extraction as a <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variable</a> and train the two-stage process jointly with <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a>. As a result, our approach has improved the state-of-the-art performance significantly on two challenging open-domain reading comprehension datasets. Further analysis demonstrates the effectiveness of our model components, especially the <a href=https://en.wikipedia.org/wiki/Information_fusion>information fusion</a> of all the candidates and the joint training of the extract-then-select procedure.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1160.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1160 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1160 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1160.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1160.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1160/>Efficient and Robust <a href=https://en.wikipedia.org/wiki/Question_answering>Question Answering</a> from Minimal Context over Documents</a></strong><br><a href=/people/s/sewon-min/>Sewon Min</a>
|
<a href=/people/v/victor-zhong/>Victor Zhong</a>
|
<a href=/people/r/richard-socher/>Richard Socher</a>
|
<a href=/people/c/caiming-xiong/>Caiming Xiong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1160><div class="card-body p-3 small">Neural models for <a href=https://en.wikipedia.org/wiki/Question_answering>question answering (QA)</a> over <a href=https://en.wikipedia.org/wiki/Document>documents</a> have achieved significant performance improvements. Although effective, these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> do not scale to large corpora due to their complex modeling of interactions between the document and the question. Moreover, recent work has shown that such <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are sensitive to adversarial inputs. In this paper, we study the minimal context required to answer the question, and find that most questions in existing <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> can be answered with a small set of sentences. Inspired by this observation, we propose a simple sentence selector to select the minimal set of sentences to feed into the QA model. Our overall system achieves significant reductions in training (up to 15 times) and inference times (up to 13 times), with accuracy comparable to or better than the state-of-the-art on SQuAD, NewsQA, TriviaQA and SQuAD-Open. Furthermore, our experimental results and analyses show that our approach is more robust to adversarial inputs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1163.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1163 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1163 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1163.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1163/>Towards Robust Neural Machine Translation</a></strong><br><a href=/people/y/yong-cheng/>Yong Cheng</a>
|
<a href=/people/z/zhaopeng-tu/>Zhaopeng Tu</a>
|
<a href=/people/f/fandong-meng/>Fandong Meng</a>
|
<a href=/people/j/junjie-zhai/>Junjie Zhai</a>
|
<a href=/people/y/yang-liu-ict/>Yang Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1163><div class="card-body p-3 small">Small perturbations in the input can severely distort intermediate representations and thus impact translation quality of neural machine translation (NMT) models. In this paper, we propose to improve the <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> of NMT models with adversarial stability training. The basic idea is to make both the encoder and decoder in NMT models robust against input perturbations by enabling them to behave similarly for the original input and its perturbed counterpart. Experimental results on Chinese-English, English-German and English-French translation tasks show that our approaches can not only achieve significant improvements over strong NMT systems but also improve the robustness of NMT models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1165.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1165 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1165 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1165.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1165.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1165/>Reliability and Learnability of Human Bandit Feedback for Sequence-to-Sequence Reinforcement Learning</a></strong><br><a href=/people/j/julia-kreutzer/>Julia Kreutzer</a>
|
<a href=/people/j/joshua-uyheng/>Joshua Uyheng</a>
|
<a href=/people/s/stefan-riezler/>Stefan Riezler</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1165><div class="card-body p-3 small">We present a study on <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning (RL)</a> from human bandit feedback for sequence-to-sequence learning, exemplified by the task of bandit neural machine translation (NMT). We investigate the <a href=https://en.wikipedia.org/wiki/Reliability_(statistics)>reliability</a> of human bandit feedback, and analyze the influence of <a href=https://en.wikipedia.org/wiki/Reliability_(statistics)>reliability</a> on the learnability of a reward estimator, and the effect of the quality of reward estimates on the overall RL task. Our analysis of cardinal (5-point ratings) and ordinal (pairwise preferences) feedback shows that their intra- and inter-annotator -agreement is comparable. Best <a href=https://en.wikipedia.org/wiki/Reliability_(statistics)>reliability</a> is obtained for standardized cardinal feedback, and cardinal feedback is also easiest to learn and generalize from. Finally, improvements of over 1 BLEU can be obtained by integrating a regression-based reward estimator trained on cardinal feedback for 800 translations into <a href=https://en.wikipedia.org/wiki/Linear_regression>RL</a> for NMT. This shows that RL is possible even from small amounts of fairly reliable human feedback, pointing to a great potential for applications at larger scale.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1166.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1166 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1166 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1166.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1166" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1166/>Accelerating Neural Transformer via an Average Attention Network</a></strong><br><a href=/people/b/biao-zhang/>Biao Zhang</a>
|
<a href=/people/d/deyi-xiong/>Deyi Xiong</a>
|
<a href=/people/j/jinsong-su/>Jinsong Su</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1166><div class="card-body p-3 small">With parallelizable attention networks, the neural Transformer is very fast to train. However, due to the auto-regressive architecture and self-attention in the <a href=https://en.wikipedia.org/wiki/Code>decoder</a>, the decoding procedure becomes slow. To alleviate this issue, we propose an average attention network as an alternative to the self-attention network in the decoder of the neural Transformer. The average attention network consists of two layers, with an average layer that models dependencies on previous positions and a gating layer that is stacked over the average layer to enhance the expressiveness of the proposed attention network. We apply this <a href=https://en.wikipedia.org/wiki/Neural_network>network</a> on the decoder part of the neural Transformer to replace the original target-side self-attention model. With masking tricks and <a href=https://en.wikipedia.org/wiki/Dynamic_programming>dynamic programming</a>, our model enables the neural Transformer to decode sentences over four times faster than its original version with almost no loss in training time and <a href=https://en.wikipedia.org/wiki/Translation>translation performance</a>. We conduct a series of experiments on WMT17 translation tasks, where on 6 different language pairs, we obtain robust and consistent speed-ups in decoding.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1167.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1167 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1167 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1167.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1167" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1167/>How Much Attention Do You Need? A Granular Analysis of Neural Machine Translation Architectures</a></strong><br><a href=/people/t/tobias-domhan/>Tobias Domhan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1167><div class="card-body p-3 small">With recent advances in network architectures for Neural Machine Translation (NMT) recurrent models have effectively been replaced by either convolutional or self-attentional approaches, such as in the Transformer. While the main innovation of the Transformer architecture is its use of self-attentional layers, there are several other aspects, such as attention with multiple heads and the use of many attention layers, that distinguish the model from previous baselines. In this work we take a fine-grained look at the different <a href=https://en.wikipedia.org/wiki/Computer_architecture>architectures</a> for <a href=https://en.wikipedia.org/wiki/Network_topology>NMT</a>. We introduce an Architecture Definition Language (ADL) allowing for a flexible combination of common building blocks. Making use of this language we show in experiments that one can bring recurrent and convolutional models very close to the Transformer performance by borrowing concepts from the Transformer architecture, but not using self-attention. Additionally, we find that self-attention is much more important on the encoder side than on the decoder side, where it can be replaced by a <a href=https://en.wikipedia.org/wiki/Radio-frequency_identification>RNN</a> or <a href=https://en.wikipedia.org/wiki/Computer-generated_imagery>CNN</a> without a loss in performance in most settings. Surprisingly, even a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> without any target side self-attention performs well.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1168.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1168 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1168 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1168.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1168.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285804766 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1168/>Weakly Supervised Semantic Parsing with Abstract Examples</a></strong><br><a href=/people/o/omer-goldman/>Omer Goldman</a>
|
<a href=/people/v/veronica-latcinnik/>Veronica Latcinnik</a>
|
<a href=/people/e/ehud-nave/>Ehud Nave</a>
|
<a href=/people/a/amir-globerson/>Amir Globerson</a>
|
<a href=/people/j/jonathan-berant/>Jonathan Berant</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1168><div class="card-body p-3 small">Training semantic parsers from weak supervision (denotations) rather than strong supervision (programs) complicates training in two ways. First, a large search space of potential <a href=https://en.wikipedia.org/wiki/Computer_program>programs</a> needs to be explored at training time to find a correct <a href=https://en.wikipedia.org/wiki/Computer_program>program</a>. Second, spurious programs that accidentally lead to a correct <a href=https://en.wikipedia.org/wiki/Denotation>denotation</a> add <a href=https://en.wikipedia.org/wiki/Noise>noise</a> to <a href=https://en.wikipedia.org/wiki/Training>training</a>. In this work we propose that in closed worlds with clear semantic types, one can substantially alleviate these problems by utilizing an abstract representation, where tokens in both the language utterance and <a href=https://en.wikipedia.org/wiki/Computer_program>program</a> are lifted to an abstract form. We show that these abstractions can be defined with a handful of lexical rules and that they result in sharing between different examples that alleviates the difficulties in training. To test our approach, we develop the first semantic parser for CNLVR, a challenging visual reasoning dataset, where the search space is large and overcoming spuriousness is critical, because denotations are either TRUE or FALSE, and thus random programs are likely to lead to a correct denotation. Our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> substantially improves performance, and reaches 82.5 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, a 14.7 % absolute accuracy improvement compared to the best reported <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> so far.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1169.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1169 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1169 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1169.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1169.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285804785 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1169" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1169/>Improving a Neural Semantic Parser by Counterfactual Learning from Human Bandit Feedback</a></strong><br><a href=/people/c/carolin-lawrence/>Carolin Lawrence</a>
|
<a href=/people/s/stefan-riezler/>Stefan Riezler</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1169><div class="card-body p-3 small">Counterfactual learning from human bandit feedback describes a scenario where user feedback on the quality of outputs of a historic system is logged and used to improve a target <a href=https://en.wikipedia.org/wiki/System>system</a>. We show how to apply this learning framework to neural semantic parsing. From a machine learning perspective, the key challenge lies in a proper reweighting of the <a href=https://en.wikipedia.org/wiki/Estimator>estimator</a> so as to avoid known degeneracies in counterfactual learning, while still being applicable to stochastic gradient optimization. To conduct experiments with <a href=https://en.wikipedia.org/wiki/User_(computing)>human users</a>, we devise an easy-to-use interface to collect <a href=https://en.wikipedia.org/wiki/Feedback>human feedback</a> on semantic parses. Our work is the first to show that semantic parsers can be improved significantly by counterfactual learning from logged human feedback data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1170.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1170 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1170 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1170.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1170.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285804795 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1170/>AMR dependency parsing with a typed semantic algebra<span class=acl-fixed-case>AMR</span> dependency parsing with a typed semantic algebra</a></strong><br><a href=/people/j/jonas-groschwitz/>Jonas Groschwitz</a>
|
<a href=/people/m/matthias-lindemann/>Matthias Lindemann</a>
|
<a href=/people/m/meaghan-fowlie/>Meaghan Fowlie</a>
|
<a href=/people/m/mark-johnson/>Mark Johnson</a>
|
<a href=/people/a/alexander-koller/>Alexander Koller</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1170><div class="card-body p-3 small">We present a <a href=https://en.wikipedia.org/wiki/Semantic_parser>semantic parser</a> for Abstract Meaning Representations which learns to parse strings into tree representations of the compositional structure of an AMR graph. This allows us to use standard neural techniques for supertagging and dependency tree parsing, constrained by a linguistically principled type system. We present two approximative decoding algorithms, which achieve state-of-the-art <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and outperform strong <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baselines</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1172.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1172 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1172 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285804833 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1172/>Batch IS NOT Heavy : Learning Word Representations From All Samples<span class=acl-fixed-case>IS</span> <span class=acl-fixed-case>NOT</span> Heavy: Learning Word Representations From All Samples</a></strong><br><a href=/people/x/xin-xin/>Xin Xin</a>
|
<a href=/people/f/fajie-yuan/>Fajie Yuan</a>
|
<a href=/people/x/xiangnan-he/>Xiangnan He</a>
|
<a href=/people/j/joemon-m-jose/>Joemon M. Jose</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1172><div class="card-body p-3 small">Stochastic Gradient Descent (SGD) with negative sampling is the most prevalent approach to learn word representations. However, it is known that <a href=https://en.wikipedia.org/wiki/Sampling_(statistics)>sampling methods</a> are biased especially when the <a href=https://en.wikipedia.org/wiki/Sampling_distribution>sampling distribution</a> deviates from the true data distribution. Besides, SGD suffers from dramatic fluctuation due to the one-sample learning scheme. In this work, we propose AllVec that uses batch gradient learning to generate word representations from all training samples. Remarkably, the <a href=https://en.wikipedia.org/wiki/Time_complexity>time complexity</a> of AllVec remains at the same level as SGD, being determined by the number of positive samples rather than all samples. We evaluate AllVec on several <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark tasks</a>. Experiments show that AllVec outperforms sampling-based SGD methods with comparable efficiency, especially for small training corpora.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1173.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1173 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1173 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1173.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1173.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285804853 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1173" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1173/>Backpropagating through Structured Argmax using a SPIGOT<span class=acl-fixed-case>SPIGOT</span></a></strong><br><a href=/people/h/hao-peng/>Hao Peng</a>
|
<a href=/people/s/sam-thomson/>Sam Thomson</a>
|
<a href=/people/n/noah-a-smith/>Noah A. Smith</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1173><div class="card-body p-3 small">We introduce structured projection of intermediate gradients (SPIGOT), a new method for <a href=https://en.wikipedia.org/wiki/Backpropagation>backpropagating through neural networks</a> that include hard-decision structured predictions (e.g., parsing) in intermediate layers. SPIGOT requires no marginal inference, unlike structured attention networks and reinforcement learning-inspired solutions. Like so-called straight-through estimators, SPIGOT defines gradient-like quantities associated with intermediate nondifferentiable operations, allowing <a href=https://en.wikipedia.org/wiki/Backpropagation>backpropagation</a> before and after them ; SPIGOT&#8217;s proxy aims to ensure that, after a parameter update, the intermediate structure will remain well-formed. We experiment on two structured NLP pipelines : syntactic-then-semantic dependency parsing, and <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a> followed by sentiment classification. We show that training with SPIGOT leads to a larger improvement on the downstream task than a modularly-trained pipeline, the straight-through estimator, and structured attention, reaching a new state of the art on semantic dependency parsing.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1174.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1174 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1174 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1174.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285804866 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1174" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1174/>Learning How to Actively Learn : A Deep Imitation Learning Approach</a></strong><br><a href=/people/m/ming-liu/>Ming Liu</a>
|
<a href=/people/w/wray-buntine/>Wray Buntine</a>
|
<a href=/people/g/gholamreza-haffari/>Gholamreza Haffari</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1174><div class="card-body p-3 small">Heuristic-based active learning (AL) methods are limited when the <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>data distribution</a> of the underlying learning problems vary. We introduce a <a href=https://en.wikipedia.org/wiki/Methodology>method</a> that learns an AL policy using imitation learning (IL). Our IL-based approach makes use of an efficient and effective algorithmic expert, which provides the policy learner with good actions in the encountered AL situations. The AL strategy is then learned with a feedforward network, mapping situations to most informative query datapoints. We evaluate our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> on two different <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> : <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a> and <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>. Experimental results show that our IL-based AL strategy is more effective than strong previous methods using <a href=https://en.wikipedia.org/wiki/Heuristic>heuristics</a> and <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1175.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1175 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1175 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1175.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285804886 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1175" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1175/>Training <a href=https://en.wikipedia.org/wiki/Classifier_(linguistics)>Classifiers</a> with Natural Language Explanations</a></strong><br><a href=/people/b/braden-hancock/>Braden Hancock</a>
|
<a href=/people/p/paroma-varma/>Paroma Varma</a>
|
<a href=/people/s/stephanie-wang/>Stephanie Wang</a>
|
<a href=/people/m/martin-bringmann/>Martin Bringmann</a>
|
<a href=/people/p/percy-liang/>Percy Liang</a>
|
<a href=/people/c/christopher-re/>Christopher Ré</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1175><div class="card-body p-3 small">Training accurate <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> requires many labels, but each label provides only limited information (one bit for binary classification). In this work, we propose BabbleLabble, a framework for training <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> in which an annotator provides a <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language explanation</a> for each labeling decision. A <a href=https://en.wikipedia.org/wiki/Semantic_parser>semantic parser</a> converts these explanations into programmatic labeling functions that generate noisy labels for an arbitrary amount of unlabeled data, which is used to train a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a>. On three relation extraction tasks, we find that users are able to train <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> with comparable F1 scores from 5-100 faster by providing explanations instead of just labels. Furthermore, given the inherent imperfection of labeling functions, we find that a simple rule-based semantic parser suffices.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1177.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1177 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1177 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1177.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285804906 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1177" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1177/>Harvesting Paragraph-level Question-Answer Pairs from Wikipedia<span class=acl-fixed-case>W</span>ikipedia</a></strong><br><a href=/people/x/xinya-du/>Xinya Du</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1177><div class="card-body p-3 small">We study the task of generating from Wikipedia articles question-answer pairs that cover content beyond a single sentence. We propose a neural network approach that incorporates coreference knowledge via a novel gating mechanism. As compared to <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> that only take into account sentence-level information (Heilman and Smith, 2010 ; Du et al., 2017 ; Zhou et al., 2017), we find that the linguistic knowledge introduced by the coreference representation aids question generation significantly, producing <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> that outperform the current state-of-the-art. We apply our system (composed of an answer span extraction system and the passage-level QG system) to the 10,000 top ranking Wikipedia articles and create a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> of over one million question-answer pairs. We provide qualitative analysis for the this large-scale generated corpus from <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1179.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1179 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1179 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1179.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1179.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/288152765 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1179/>Language Generation via DAG Transduction<span class=acl-fixed-case>DAG</span> Transduction</a></strong><br><a href=/people/y/yajie-ye/>Yajie Ye</a>
|
<a href=/people/w/weiwei-sun/>Weiwei Sun</a>
|
<a href=/people/x/xiaojun-wan/>Xiaojun Wan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1179><div class="card-body p-3 small">A DAG automaton is a formal device for manipulating <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graphs</a>. By augmenting a DAG automaton with transduction rules, a DAG transducer has potential applications in fundamental NLP tasks. In this paper, we propose a novel DAG transducer to perform graph-to-program transformation. The target structure of our <a href=https://en.wikipedia.org/wiki/Transducer>transducer</a> is a <a href=https://en.wikipedia.org/wiki/Computer_program>program</a> licensed by a <a href=https://en.wikipedia.org/wiki/Declarative_programming>declarative programming language</a> rather than linguistic structures. By executing such a <a href=https://en.wikipedia.org/wiki/Computer_program>program</a>, we can easily get a surface string. Our <a href=https://en.wikipedia.org/wiki/Transducer>transducer</a> is designed especially for natural language generation (NLG) from type-logical semantic graphs. Taking Elementary Dependency Structures, a format of English Resource Semantics, as input, our NLG system achieves a BLEU-4 score of 68.07. This remarkable result demonstrates the feasibility of applying a DAG transducer to resolve NLG, as well as the effectiveness of our design.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1180.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1180 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1180 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1180.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/288152732 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1180" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1180/>A Distributional and Orthographic Aggregation Model for English Derivational Morphology<span class=acl-fixed-case>E</span>nglish Derivational Morphology</a></strong><br><a href=/people/d/daniel-deutsch/>Daniel Deutsch</a>
|
<a href=/people/j/john-hewitt/>John Hewitt</a>
|
<a href=/people/d/dan-roth/>Dan Roth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1180><div class="card-body p-3 small">Modeling <a href=https://en.wikipedia.org/wiki/Morphological_derivation>derivational morphology</a> to generate words with particular <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> is useful in many text generation tasks, such as <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> or abstractive question answering. In this work, we tackle the task of derived word generation. That is, we attempt to generate the word runner for someone who runs. We identify two key problems in generating derived words from <a href=https://en.wikipedia.org/wiki/Root_(linguistics)>root words</a> and <a href=https://en.wikipedia.org/wiki/Transformation_(function)>transformations</a>. We contribute a novel aggregation model of derived word generation that learns derivational transformations both as orthographic functions using sequence-to-sequence models and as functions in distributional word embedding space. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> then learns to choose between the hypothesis of each system. We also present two ways of incorporating <a href=https://en.wikipedia.org/wiki/Corpus_linguistics>corpus information</a> into derived word generation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1182.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1182 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1182 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1182.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285804944 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1182" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1182/>NeuralREG : An end-to-end approach to referring expression generation<span class=acl-fixed-case>N</span>eural<span class=acl-fixed-case>REG</span>: An end-to-end approach to referring expression generation</a></strong><br><a href=/people/t/thiago-castro-ferreira/>Thiago Castro Ferreira</a>
|
<a href=/people/d/diego-moussallem/>Diego Moussallem</a>
|
<a href=/people/a/akos-kadar/>Ákos Kádár</a>
|
<a href=/people/s/sander-wubben/>Sander Wubben</a>
|
<a href=/people/e/emiel-krahmer/>Emiel Krahmer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1182><div class="card-body p-3 small">Traditionally, Referring Expression Generation (REG) models first decide on the form and then on the content of references to discourse entities in text, typically relying on features such as salience and <a href=https://en.wikipedia.org/wiki/Grammatical_relation>grammatical function</a>. In this paper, we present a new approach (NeuralREG), relying on <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural networks</a>, which makes decisions about form and content in one go without explicit <a href=https://en.wikipedia.org/wiki/Feature_extraction>feature extraction</a>. Using a delexicalized version of the WebNLG corpus, we show that the neural model substantially improves over two strong baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1183.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1183 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1183 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1183.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1183.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285804956 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1183" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1183/>Stock Movement Prediction from <a href=https://en.wikipedia.org/wiki/Twitter>Tweets</a> and Historical Prices</a></strong><br><a href=/people/y/yumo-xu/>Yumo Xu</a>
|
<a href=/people/s/shay-b-cohen/>Shay B. Cohen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1183><div class="card-body p-3 small">Stock movement prediction is a challenging problem : the market is highly stochastic, and we make temporally-dependent predictions from chaotic data. We treat these three complexities and present a novel deep generative model jointly exploiting text and price signals for this task. Unlike the case with discriminative or topic modeling, our model introduces recurrent, continuous latent variables for a better treatment of <a href=https://en.wikipedia.org/wiki/Stochastic>stochasticity</a>, and uses neural variational inference to address the intractable posterior inference. We also provide a hybrid objective with temporal auxiliary to flexibly capture predictive dependencies. We demonstrate the state-of-the-art performance of our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on a new stock movement prediction dataset which we collected.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1186.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1186 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1186 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285804998 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1186/>Multimodal Named Entity Disambiguation for Noisy Social Media Posts</a></strong><br><a href=/people/s/seungwhan-moon/>Seungwhan Moon</a>
|
<a href=/people/l/leonardo-neves/>Leonardo Neves</a>
|
<a href=/people/v/vitor-carvalho/>Vitor Carvalho</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1186><div class="card-body p-3 small">We introduce the new Multimodal Named Entity Disambiguation (MNED) task for multimodal social media posts such as Snapchat or Instagram captions, which are composed of short captions with accompanying images. Social media posts bring significant challenges for disambiguation tasks because 1) ambiguity not only comes from polysemous entities, but also from inconsistent or incomplete notations, 2) very limited context is provided with surrounding words, and 3) there are many emerging entities often unseen during training. To this end, we build a new dataset called SnapCaptionsKB, a collection of Snapchat image captions submitted to public and crowd-sourced stories, with named entity mentions fully annotated and linked to entities in an external knowledge base. We then build a deep zeroshot multimodal network for MNED that 1) extracts contexts from both text and image, and 2) predicts correct entity in the knowledge graph embeddings space, allowing for zeroshot disambiguation of entities unseen in training set as well. The proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> significantly outperforms the state-of-the-art text-only NED models, showing efficacy and potentials of the MNED task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1187.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1187 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1187 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1187.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1187.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285805016 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1187/>Semi-supervised User Geolocation via Graph Convolutional Networks</a></strong><br><a href=/people/a/afshin-rahimi/>Afshin Rahimi</a>
|
<a href=/people/t/trevor-cohn/>Trevor Cohn</a>
|
<a href=/people/t/timothy-baldwin/>Timothy Baldwin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1187><div class="card-body p-3 small">Social media user geolocation is vital to many <a href=https://en.wikipedia.org/wiki/Application_software>applications</a> such as <a href=https://en.wikipedia.org/wiki/Geolocation>event detection</a>. In this paper, we propose GCN, a multiview geolocation model based on Graph Convolutional Networks, that uses both text and network context. We compare GCN to the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a>, and to two baselines we propose, and show that our model achieves or is competitive with the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> over three benchmark geolocation datasets when sufficient supervision is available. We also evaluate GCN under a minimal supervision scenario, and show it outperforms <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a>. We find that highway network gates are essential for controlling the amount of useful neighbourhood expansion in GCN.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1192.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1192 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1192 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1192.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285805245 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1192" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1192/>Syntax for Semantic Role Labeling, To Be, Or Not To Be</a></strong><br><a href=/people/s/shexia-he/>Shexia He</a>
|
<a href=/people/z/zuchao-li/>Zuchao Li</a>
|
<a href=/people/h/hai-zhao/>Hai Zhao</a>
|
<a href=/people/h/hongxiao-bai/>Hongxiao Bai</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1192><div class="card-body p-3 small">Semantic role labeling (SRL) is dedicated to recognizing the predicate-argument structure of a sentence. Previous studies have shown <a href=https://en.wikipedia.org/wiki/Syntax>syntactic information</a> has a remarkable contribution to <a href=https://en.wikipedia.org/wiki/Speech_recognition>SRL</a> performance. However, such perception was challenged by a few recent neural SRL models which give impressive performance without a syntactic backbone. This paper intends to quantify the importance of <a href=https://en.wikipedia.org/wiki/Syntax>syntactic information</a> to dependency SRL in deep learning framework. We propose an enhanced argument labeling model companying with an extended korder argument pruning algorithm for effectively exploiting syntactic information. Our model achieves state-of-the-art results on the CoNLL-2008, 2009 benchmarks for both <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>, showing the quantitative significance of <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a> to neural SRL together with a thorough empirical survey over existing models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1193.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1193 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1193 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1193.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1193.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285805263 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1193" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1193/>Situated Mapping of Sequential Instructions to Actions with Single-step Reward Observation</a></strong><br><a href=/people/a/alane-suhr/>Alane Suhr</a>
|
<a href=/people/y/yoav-artzi/>Yoav Artzi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1193><div class="card-body p-3 small">We propose a learning approach for mapping context-dependent sequential instructions to actions. We address the problem of discourse and state dependencies with an attention-based model that considers both the history of the interaction and the state of the world. To train from start and goal states without access to demonstrations, we propose SESTRA, a <a href=https://en.wikipedia.org/wiki/Machine_learning>learning algorithm</a> that takes advantage of single-step reward observations and immediate expected reward maximization. We evaluate on the SCONE domains, and show absolute accuracy improvements of 9.8%-25.3 % across the domains over approaches that use <a href=https://en.wikipedia.org/wiki/High-level_programming_language>high-level logical representations</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1194.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1194 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1194 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1194.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285805276 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1194/>Marrying Up <a href=https://en.wikipedia.org/wiki/Regular_expression>Regular Expressions</a> with <a href=https://en.wikipedia.org/wiki/Neural_network>Neural Networks</a> : A Case Study for Spoken Language Understanding</a></strong><br><a href=/people/b/bingfeng-luo/>Bingfeng Luo</a>
|
<a href=/people/y/yansong-feng/>Yansong Feng</a>
|
<a href=/people/z/zheng-wang/>Zheng Wang</a>
|
<a href=/people/s/songfang-huang/>Songfang Huang</a>
|
<a href=/people/r/rui-yan/>Rui Yan</a>
|
<a href=/people/d/dongyan-zhao/>Dongyan Zhao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1194><div class="card-body p-3 small">The success of many natural language processing (NLP) tasks is bound by the number and quality of annotated data, but there is often a shortage of such training data. In this paper, we ask the question : Can we combine a neural network (NN) with regular expressions (RE) to improve <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised learning</a> for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>?. In answer, we develop novel methods to exploit the rich expressiveness of REs at different levels within a NN, showing that the combination significantly enhances the learning effectiveness when a small number of training examples are available. We evaluate our approach by applying it to spoken language understanding for intent detection and slot filling. Experimental results show that our approach is highly effective in exploiting the available <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training data</a>, giving a clear boost to the RE-unaware NN.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1197.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1197 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1197 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1197.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285805320 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1197/>To Attend or not to Attend : A Case Study on Syntactic Structures for Semantic Relatedness</a></strong><br><a href=/people/a/amulya-gupta/>Amulya Gupta</a>
|
<a href=/people/z/zhu-zhang/>Zhu Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1197><div class="card-body p-3 small">With the recent success of <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>Recurrent Neural Networks (RNNs)</a> in <a href=https://en.wikipedia.org/wiki/Machine_translation>Machine Translation (MT)</a>, attention mechanisms have become increasingly popular. The purpose of this paper is two-fold ; firstly, we propose a novel attention model on Tree Long Short-Term Memory Networks (Tree-LSTMs), a tree-structured generalization of standard <a href=https://en.wikipedia.org/wiki/Long_short-term_memory>LSTM</a>. Secondly, we study the interaction between <a href=https://en.wikipedia.org/wiki/Attention>attention</a> and syntactic structures, by experimenting with three LSTM variants : bidirectional-LSTMs, Constituency Tree-LSTMs, and Dependency Tree-LSTMs. Our models are evaluated on two semantic relatedness tasks : semantic relatedness scoring for sentence pairs (SemEval 2012, Task 6 and SemEval 2014, Task 1) and paraphrase detection for question pairs (Quora, 2017).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1198.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1198 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1198 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1198.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1198.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285805339 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1198/>What you can cram into a single $ & ! # * vector : Probing sentence embeddings for linguistic properties</a></strong><br><a href=/people/a/alexis-conneau/>Alexis Conneau</a>
|
<a href=/people/g/german-kruszewski/>German Kruszewski</a>
|
<a href=/people/g/guillaume-lample/>Guillaume Lample</a>
|
<a href=/people/l/loic-barrault/>Loïc Barrault</a>
|
<a href=/people/m/marco-baroni/>Marco Baroni</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1198><div class="card-body p-3 small">Although much effort has recently been devoted to training high-quality <a href=https://en.wikipedia.org/wiki/Sentence_embedding>sentence embeddings</a>, we still have a poor understanding of what they are capturing. Downstream tasks, often based on sentence classification, are commonly used to evaluate the quality of sentence representations. The <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a> of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> makes it however difficult to infer what kind of information is present in the <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a>. We introduce here 10 probing tasks designed to capture simple linguistic features of sentences, and we use them to study embeddings generated by three different <a href=https://en.wikipedia.org/wiki/Encoder>encoders</a> trained in eight distinct ways, uncovering intriguing properties of both <a href=https://en.wikipedia.org/wiki/Encoder>encoders</a> and training methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1199.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1199 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1199 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1199.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285805358 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1199" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1199/>Robust Distant Supervision Relation Extraction via <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Reinforcement Learning</a></a></strong><br><a href=/people/p/pengda-qin/>Pengda Qin</a>
|
<a href=/people/w/weiran-xu/>Weiran Xu</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1199><div class="card-body p-3 small">Distant supervision has become the standard method for <a href=https://en.wikipedia.org/wiki/Relation_extraction>relation extraction</a>. However, even though <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> is an efficient method, it does not come at no costThe resulted distantly-supervised training samples are often very noisy. To combat the noise, most of the recent state-of-the-art approaches focus on selecting one-best sentence or calculating soft attention weights over the set of the sentences of one specific entity pair. However, these <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>methods</a> are suboptimal, and the false positive problem is still a key stumbling bottleneck for the performance. We argue that those incorrectly-labeled candidate sentences must be treated with a hard decision, rather than being dealt with soft attention weights. To do this, our paper describes a radical solutionWe explore a deep reinforcement learning strategy to generate the <a href=https://en.wikipedia.org/wiki/False_positives_and_false_negatives>false-positive indicator</a>, where we automatically recognize <a href=https://en.wikipedia.org/wiki/False_positives_and_false_negatives>false positives</a> for each relation type without any <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised information</a>. Unlike the removal operation in the previous studies, we redistribute them into the negative examples. The experimental results show that the proposed <a href=https://en.wikipedia.org/wiki/Strategy>strategy</a> significantly improves the performance of distant supervision comparing to <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art systems</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1200.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1200 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1200 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1200.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285805371 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1200" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1200/>Interpretable and Compositional Relation Learning by Joint Training with an <a href=https://en.wikipedia.org/wiki/Autoencoder>Autoencoder</a></a></strong><br><a href=/people/r/ryo-takahashi/>Ryo Takahashi</a>
|
<a href=/people/r/ran-tian/>Ran Tian</a>
|
<a href=/people/k/kentaro-inui/>Kentaro Inui</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1200><div class="card-body p-3 small">Embedding models for entities and relations are extremely useful for recovering missing facts in a <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge base</a>. Intuitively, a <a href=https://en.wikipedia.org/wiki/Binary_relation>relation</a> can be modeled by a matrix mapping entity vectors. However, <a href=https://en.wikipedia.org/wiki/Matrix_(mathematics)>relations</a> reside on low dimension sub-manifolds in the parameter space of arbitrary matrices for one reason, composition of two relations M1, M2 may match a third M3 (e.g. composition of relations currency_of_country and country_of_film usually matches currency_of_film_budget), which imposes compositional constraints to be satisfied by the parameters (i.e. M1*M2 = M3). In this paper we investigate a dimension reduction technique by training <a href=https://en.wikipedia.org/wiki/Binary_relation>relations</a> jointly with an <a href=https://en.wikipedia.org/wiki/Autoencoder>autoencoder</a>, which is expected to better capture compositional constraints. We achieve state-of-the-art on Knowledge Base Completion tasks with strongly improved Mean Rank, and show that joint training with an <a href=https://en.wikipedia.org/wiki/Autoencoder>autoencoder</a> leads to interpretable sparse codings of relations, helps discovering compositional constraints and benefits from compositional training. Our source code is released at.<url>github.com/tianran/glimvec</url>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1201.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1201 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1201 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1201.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285805384 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1201" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1201/>Zero-Shot Transfer Learning for Event Extraction</a></strong><br><a href=/people/l/lifu-huang/>Lifu Huang</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/k/kyunghyun-cho/>Kyunghyun Cho</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a>
|
<a href=/people/s/sebastian-riedel/>Sebastian Riedel</a>
|
<a href=/people/c/clare-voss/>Clare Voss</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1201><div class="card-body p-3 small">Most previous supervised event extraction methods have relied on features derived from manual annotations, and thus can not be applied to new event types without extra annotation effort. We take a fresh look at <a href=https://en.wikipedia.org/wiki/Event_extraction>event extraction</a> and model it as a generic grounding problem : mapping each event mention to a specific type in a target event ontology. We design a transferable architecture of structural and compositional neural networks to jointly represent and map event mentions and types into a shared semantic space. Based on this new framework, we can select, for each event mention, the event type which is semantically closest in this space as its type. By leveraging manual annotations available for a small set of existing <a href=https://en.wikipedia.org/wiki/Event_(computing)>event types</a>, our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> can be applied to new unseen event types without additional manual annotations. When tested on 23 unseen event types, our zero-shot framework, without manual annotations, achieved performance comparable to a <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised model</a> trained from 3,000 sentences annotated with 500 event mentions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1205.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1205 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1205 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1205.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285805443 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1205" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1205/>Personalizing Dialogue Agents : I have a dog, do you have pets too?<span class=acl-fixed-case>I</span> have a dog, do you have pets too?</a></strong><br><a href=/people/s/saizheng-zhang/>Saizheng Zhang</a>
|
<a href=/people/e/emily-dinan/>Emily Dinan</a>
|
<a href=/people/j/jack-urbanek/>Jack Urbanek</a>
|
<a href=/people/a/arthur-szlam/>Arthur Szlam</a>
|
<a href=/people/d/douwe-kiela/>Douwe Kiela</a>
|
<a href=/people/j/jason-weston/>Jason Weston</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1205><div class="card-body p-3 small">Chit-chat models are known to have several problems : they lack <a href=https://en.wikipedia.org/wiki/Sensitivity_and_specificity>specificity</a>, do not display a consistent personality and are often not very captivating. In this work we present the task of making <a href=https://en.wikipedia.org/wiki/Chit-chat>chit-chat</a> more engaging by conditioning on profile information. We collect data and train models to (i)condition on their given profile information ; and (ii) information about the person they are talking to, resulting in improved dialogues, as measured by next utterance prediction. Since (ii) is initially unknown our model is trained to engage its partner with personal topics, and we show the resulting dialogue can be used to predict profile information about the interlocutors.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1206.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1206 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1206 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285805460 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1206/>Efficient Large-Scale Neural Domain Classification with Personalized Attention</a></strong><br><a href=/people/y/young-bum-kim/>Young-Bum Kim</a>
|
<a href=/people/d/dongchan-kim/>Dongchan Kim</a>
|
<a href=/people/a/anjishnu-kumar/>Anjishnu Kumar</a>
|
<a href=/people/r/ruhi-sarikaya/>Ruhi Sarikaya</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1206><div class="card-body p-3 small">In this paper, we explore the task of mapping spoken language utterances to one of thousands of natural language understanding domains in intelligent personal digital assistants (IPDAs). This scenario is observed in mainstream IPDAs in industry that allow third parties to develop thousands of new domains to augment built-in first party domains to rapidly increase domain coverage and overall IPDA capabilities. We propose a scalable neural model architecture with a shared encoder, a novel <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanism</a> that incorporates <a href=https://en.wikipedia.org/wiki/Personalization>personalization information</a> and domain-specific classifiers that solves the problem efficiently. Our <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> is designed to efficiently accommodate incremental domain additions achieving two orders of magnitude speed up compared to full model retraining. We consider the practical constraints of <a href=https://en.wikipedia.org/wiki/Real-time_computing>real-time production systems</a>, and design to minimize <a href=https://en.wikipedia.org/wiki/Memory_footprint>memory footprint</a> and <a href=https://en.wikipedia.org/wiki/Latency_(engineering)>runtime latency</a>. We demonstrate that incorporating <a href=https://en.wikipedia.org/wiki/Personalization>personalization</a> significantly improves domain classification accuracy in a setting with thousands of overlapping domains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1208.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1208 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1208 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285805491 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1208/>Multimodal Language Analysis in the Wild : CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph<span class=acl-fixed-case>CMU</span>-<span class=acl-fixed-case>MOSEI</span> Dataset and Interpretable Dynamic Fusion Graph</a></strong><br><a href=/people/a/amirali-bagher-zadeh/>AmirAli Bagher Zadeh</a>
|
<a href=/people/p/paul-pu-liang/>Paul Pu Liang</a>
|
<a href=/people/s/soujanya-poria/>Soujanya Poria</a>
|
<a href=/people/e/erik-cambria/>Erik Cambria</a>
|
<a href=/people/l/louis-philippe-morency/>Louis-Philippe Morency</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1208><div class="card-body p-3 small">Analyzing human multimodal language is an emerging area of research in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. Intrinsically this <a href=https://en.wikipedia.org/wiki/Language>language</a> is multimodal (heterogeneous), sequential and asynchronous ; it consists of the language (words), visual (expressions) and acoustic (paralinguistic) modalities all in the form of asynchronous coordinated sequences. From a resource perspective, there is a genuine need for large scale datasets that allow for in-depth studies of this form of language. In this paper we introduce CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI), the largest dataset of <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> and <a href=https://en.wikipedia.org/wiki/Emotion_recognition>emotion recognition</a> to date. Using data from CMU-MOSEI and a novel multimodal fusion technique called the Dynamic Fusion Graph (DFG), we conduct experimentation to exploit how modalities interact with each other in human multimodal language. Unlike previously proposed fusion techniques, DFG is highly interpretable and achieves competative performance when compared to the previous state of the art.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1212.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1212 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1212 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1212.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1212.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285805571 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1212/>Joint Reasoning for Temporal and Causal Relations</a></strong><br><a href=/people/q/qiang-ning/>Qiang Ning</a>
|
<a href=/people/z/zhili-feng/>Zhili Feng</a>
|
<a href=/people/h/hao-wu/>Hao Wu</a>
|
<a href=/people/d/dan-roth/>Dan Roth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1212><div class="card-body p-3 small">Understanding temporal and causal relations between events is a fundamental <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding task</a>. Because a cause must occur earlier than its effect, temporal and causal relations are closely related and one relation often dictates the value of the other. However, limited attention has been paid to studying these two relations jointly. This paper presents a joint inference framework for <a href=https://en.wikipedia.org/wiki/Logical_disjunction>them</a> using constrained conditional models (CCMs). Specifically, we formulate the joint problem as an integer linear programming (ILP) problem, enforcing <a href=https://en.wikipedia.org/wiki/Constraint_(mathematics)>constraints</a> that are inherent in the nature of time and <a href=https://en.wikipedia.org/wiki/Causality>causality</a>. We show that the joint inference framework results in statistically significant improvement in the extraction of both temporal and causal relations from text.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1214.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1214 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1214 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1214.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1214" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1214/>A Deep Relevance Model for Zero-Shot Document Filtering</a></strong><br><a href=/people/c/chenliang-li/>Chenliang Li</a>
|
<a href=/people/w/wei-zhou/>Wei Zhou</a>
|
<a href=/people/f/feng-ji/>Feng Ji</a>
|
<a href=/people/y/yuguang-duan/>Yu Duan</a>
|
<a href=/people/h/haiqing-chen/>Haiqing Chen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1214><div class="card-body p-3 small">In the era of <a href=https://en.wikipedia.org/wiki/Big_data>big data</a>, focused analysis for diverse topics with a short response time becomes an urgent demand. As a fundamental task, <a href=https://en.wikipedia.org/wiki/Information_filtering>information filtering</a> therefore becomes a critical necessity. In this paper, we propose a novel deep relevance model for zero-shot document filtering, named DAZER. DAZER estimates the <a href=https://en.wikipedia.org/wiki/Relevance>relevance</a> between a document and a category by taking a small set of seed words relevant to the category. With pre-trained word embeddings from a large external corpus, DAZER is devised to extract the relevance signals by modeling the hidden feature interactions in the word embedding space. The relevance signals are extracted through a gated convolutional process. The gate mechanism controls which convolution filters output the relevance signals in a category dependent manner. Experiments on two document collections of two different <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> (i.e., topic categorization and sentiment analysis) demonstrate that DAZER significantly outperforms the existing alternative solutions, including the state-of-the-art deep relevance ranking models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1216.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1216 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1216 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1216.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1216" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1216/>Joint Embedding of Words and Labels for Text Classification</a></strong><br><a href=/people/g/guoyin-wang/>Guoyin Wang</a>
|
<a href=/people/c/chunyuan-li/>Chunyuan Li</a>
|
<a href=/people/w/wenlin-wang/>Wenlin Wang</a>
|
<a href=/people/y/yizhe-zhang/>Yizhe Zhang</a>
|
<a href=/people/d/dinghan-shen/>Dinghan Shen</a>
|
<a href=/people/x/xinyuan-zhang/>Xinyuan Zhang</a>
|
<a href=/people/r/ricardo-henao/>Ricardo Henao</a>
|
<a href=/people/l/lawrence-carin/>Lawrence Carin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1216><div class="card-body p-3 small">Word embeddings are effective intermediate representations for capturing semantic regularities between words, when learning the representations of text sequences. We propose to view <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a> as a label-word joint embedding problem : each label is embedded in the same space with the word vectors. We introduce an attention framework that measures the compatibility of embeddings between <a href=https://en.wikipedia.org/wiki/String_(computer_science)>text sequences</a> and labels. The <a href=https://en.wikipedia.org/wiki/Attention>attention</a> is learned on a training set of labeled samples to ensure that, given a text sequence, the relevant words are weighted higher than the irrelevant ones. Our method maintains the interpretability of word embeddings, and enjoys a built-in ability to leverage alternative sources of information, in addition to input text sequences. Extensive results on the several large text datasets show that the proposed framework outperforms the state-of-the-art methods by a large margin, in terms of both <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and <a href=https://en.wikipedia.org/wiki/Speed>speed</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1218.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1218 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1218 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1218.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1218.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1218" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1218/>Document Similarity for Texts of Varying Lengths via Hidden Topics</a></strong><br><a href=/people/h/hongyu-gong/>Hongyu Gong</a>
|
<a href=/people/t/tarek-sakakini/>Tarek Sakakini</a>
|
<a href=/people/s/suma-bhat/>Suma Bhat</a>
|
<a href=/people/j/jinjun-xiong/>JinJun Xiong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1218><div class="card-body p-3 small">Measuring similarity between texts is an important task for several applications. Available approaches to measure document similarity are inadequate for document pairs that have non-comparable lengths, such as a long document and its summary. This is because of the lexical, contextual and the abstraction gaps between a long document of rich details and its concise summary of abstract information. In this paper, we present a document matching approach to bridge this gap, by comparing the texts in a common space of hidden topics. We evaluate the matching algorithm on two <a href=https://en.wikipedia.org/wiki/Matching_(graph_theory)>matching tasks</a> and find that it consistently and widely outperforms strong baselines. We also highlight the benefits of the incorporation of <a href=https://en.wikipedia.org/wiki/Domain_knowledge>domain knowledge</a> to text matching.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1220.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1220 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1220 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1220.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1220/>Multi-Input Attention for Unsupervised OCR Correction<span class=acl-fixed-case>OCR</span> Correction</a></strong><br><a href=/people/r/rui-dong/>Rui Dong</a>
|
<a href=/people/d/david-a-smith/>David Smith</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1220><div class="card-body p-3 small">We propose a novel approach to OCR post-correction that exploits repeated texts in large corpora both as a source of noisy target outputs for <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised training</a> and as a source of evidence when decoding. A sequence-to-sequence model with <a href=https://en.wikipedia.org/wiki/Attention>attention</a> is applied for single-input correction, and a new decoder with multi-input attention averaging is developed to search for <a href=https://en.wikipedia.org/wiki/Consensus_decision-making>consensus</a> among multiple sequences. We design two ways of training the correction model without human annotation, either training to match noisily observed textual variants or <a href=https://en.wikipedia.org/wiki/Bootstrapping_(statistics)>bootstrapping</a> from a uniform error model. On two corpora of historical newspapers and books, we show that these unsupervised techniques cut the character and word error rates nearly in half on single inputs and, with the addition of multi-input decoding, can rival supervised methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1221.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1221 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1221 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1221.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1221" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1221/>Building <a href=https://en.wikipedia.org/wiki/Language_model>Language Models</a> for Text with Named Entities</a></strong><br><a href=/people/m/md-rizwan-parvez/>Md Rizwan Parvez</a>
|
<a href=/people/s/saikat-chakraborty/>Saikat Chakraborty</a>
|
<a href=/people/b/baishakhi-ray/>Baishakhi Ray</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1221><div class="card-body p-3 small">Text in many domains involves a significant amount of <a href=https://en.wikipedia.org/wiki/Named_entity>named entities</a>. Predicting the entity names is often challenging for a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> as they appear less frequent on the training corpus. In this paper, we propose a novel and effective approach to building a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> which can learn the entity names by leveraging their entity type information. We also introduce two <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark datasets</a> based on recipes and <a href=https://en.wikipedia.org/wiki/Java_(programming_language)>Java programming codes</a>, on which we evaluate the proposed <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>. Experimental results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves 52.2 % better perplexity in recipe generation and 22.06 % on <a href=https://en.wikipedia.org/wiki/Code_generation_(compiler)>code generation</a> than state-of-the-art language models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1222.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1222 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1222 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1222.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1222/>hyperdoc2vec : Distributed Representations of Hypertext Documents</a></strong><br><a href=/people/j/jialong-han/>Jialong Han</a>
|
<a href=/people/y/yan-song/>Yan Song</a>
|
<a href=/people/w/wayne-xin-zhao/>Wayne Xin Zhao</a>
|
<a href=/people/s/shuming-shi/>Shuming Shi</a>
|
<a href=/people/h/haisong-zhang/>Haisong Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1222><div class="card-body p-3 small">Hypertext documents, such as <a href=https://en.wikipedia.org/wiki/Web_page>web pages</a> and <a href=https://en.wikipedia.org/wiki/Academic_publishing>academic papers</a>, are of great importance in delivering information in our daily life. Although being effective on <a href=https://en.wikipedia.org/wiki/Plain_text>plain documents</a>, conventional text embedding methods suffer from <a href=https://en.wikipedia.org/wiki/Information_loss>information loss</a> if directly adapted to <a href=https://en.wikipedia.org/wiki/Hypertext>hyper-documents</a>. In this paper, we propose a general embedding approach for hyper-documents, namely, hyperdoc2vec, along with four criteria characterizing necessary information that hyper-document embedding models should preserve. Systematic comparisons are conducted between hyperdoc2vec and several <a href=https://en.wikipedia.org/wiki/Competition_(biology)>competitors</a> on two <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>, i.e., paper classification and <a href=https://en.wikipedia.org/wiki/Citation>citation recommendation</a>, in the academic paper domain. Analyses and experiments both validate the superiority of hyperdoc2vec to other <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> w.r.t. the four criteria.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1223.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1223 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1223 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1223.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1223" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1223/>Entity-Duet Neural Ranking : Understanding the Role of Knowledge Graph Semantics in Neural Information Retrieval</a></strong><br><a href=/people/z/zhenghao-liu/>Zhenghao Liu</a>
|
<a href=/people/c/chenyan-xiong/>Chenyan Xiong</a>
|
<a href=/people/m/maosong-sun/>Maosong Sun</a>
|
<a href=/people/z/zhiyuan-liu/>Zhiyuan Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1223><div class="card-body p-3 small">This paper presents the Entity-Duet Neural Ranking Model (EDRM), which introduces <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graphs</a> to neural search systems. EDRM represents queries and documents by their words and entity annotations. The <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> from <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graphs</a> are integrated in the distributed representations of their entities, while the <a href=https://en.wikipedia.org/wiki/Ranking>ranking</a> is conducted by interaction-based neural ranking networks. The two <a href=https://en.wikipedia.org/wiki/Component-based_software_engineering>components</a> are learned end-to-end, making EDRM a natural combination of entity-oriented search and neural information retrieval. Our experiments on a commercial search log demonstrate the effectiveness of <a href=https://en.wikipedia.org/wiki/EDRM>EDRM</a>. Our analyses reveal that knowledge graph semantics significantly improve the <a href=https://en.wikipedia.org/wiki/Generalization>generalization ability</a> of neural ranking models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1224.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1224 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1224 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1224.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1224" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1224/>Neural Natural Language Inference Models Enhanced with External Knowledge</a></strong><br><a href=/people/q/qian-chen/>Qian Chen</a>
|
<a href=/people/x/xiaodan-zhu/>Xiaodan Zhu</a>
|
<a href=/people/z/zhen-hua-ling/>Zhen-Hua Ling</a>
|
<a href=/people/d/diana-inkpen/>Diana Inkpen</a>
|
<a href=/people/s/si-wei/>Si Wei</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1224><div class="card-body p-3 small">Modeling natural language inference is a very challenging task. With the availability of large annotated data, it has recently become feasible to train complex <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> such as neural-network-based inference models, which have shown to achieve the state-of-the-art performance. Although there exist relatively large annotated data, can machines learn all knowledge needed to perform natural language inference (NLI) from these <a href=https://en.wikipedia.org/wiki/Data>data</a>? If not, how can neural-network-based NLI models benefit from external knowledge and how to build NLI models to leverage it? In this paper, we enrich the state-of-the-art neural natural language inference models with external knowledge. We demonstrate that the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> improve neural NLI models to achieve the state-of-the-art performance on the SNLI and MultiNLI datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1225.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1225 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1225 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1225.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1225.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1225" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1225/>AdvEntuRe : Adversarial Training for Textual Entailment with Knowledge-Guided Examples<span class=acl-fixed-case>A</span>dv<span class=acl-fixed-case>E</span>ntu<span class=acl-fixed-case>R</span>e: Adversarial Training for Textual Entailment with Knowledge-Guided Examples</a></strong><br><a href=/people/d/dongyeop-kang/>Dongyeop Kang</a>
|
<a href=/people/t/tushar-khot/>Tushar Khot</a>
|
<a href=/people/a/ashish-sabharwal/>Ashish Sabharwal</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1225><div class="card-body p-3 small">We consider the problem of learning textual entailment models with limited supervision (5K-10 K training examples), and present two complementary approaches for it. First, we propose knowledge-guided adversarial example generators for incorporating large lexical resources in entailment models via only a handful of rule templates. Second, to make the entailment modela discriminatormore robust, we propose the first GAN-style approach for training it using a natural language example generator that iteratively adjusts to the discriminator&#8217;s weaknesses. We demonstrate effectiveness using two entailment datasets, where the proposed <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> increase <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> by 4.7 % on SciTail and by 2.8 % on a 1 % sub-sample of <a href=https://en.wikipedia.org/wiki/Single-nucleotide_polymorphism>SNLI</a>. Notably, even a single hand-written rule, negate, improves the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of negation examples in SNLI by 6.1 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1226.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1226 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1226 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1226.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1226" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1226/>Subword-level Word Vector Representations for Korean<span class=acl-fixed-case>K</span>orean</a></strong><br><a href=/people/s/sungjoon-park/>Sungjoon Park</a>
|
<a href=/people/j/jeongmin-byun/>Jeongmin Byun</a>
|
<a href=/people/s/sion-baek/>Sion Baek</a>
|
<a href=/people/y/yongseok-cho/>Yongseok Cho</a>
|
<a href=/people/a/alice-oh/>Alice Oh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1226><div class="card-body p-3 small">Research on distributed word representations is focused on widely-used languages such as <a href=https://en.wikipedia.org/wiki/English_language>English</a>. Although the same <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>methods</a> can be used for other languages, language-specific knowledge can enhance the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and richness of <a href=https://en.wikipedia.org/wiki/Vector_space>word vector representations</a>. In this paper, we look at improving distributed word representations for <a href=https://en.wikipedia.org/wiki/Korean_language>Korean</a> using knowledge about the unique linguistic structure of <a href=https://en.wikipedia.org/wiki/Korean_language>Korean</a>. Specifically, we decompose Korean words into the jamo-level, beyond the character-level, allowing a systematic use of subword information. To evaluate the <a href=https://en.wikipedia.org/wiki/Vector_(mathematics_and_physics)>vectors</a>, we develop Korean test sets for word similarity and analogy and make them publicly available. The results show that our simple method outperforms <a href=https://en.wikipedia.org/wiki/Word2vec>word2vec</a> and character-level Skip-Grams on semantic and syntactic similarity and analogy tasks and contributes positively toward downstream NLP tasks such as <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1229.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1229 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1229 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1229.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1229" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1229/>End-to-End Reinforcement Learning for Automatic Taxonomy Induction</a></strong><br><a href=/people/y/yuning-mao/>Yuning Mao</a>
|
<a href=/people/x/xiang-ren/>Xiang Ren</a>
|
<a href=/people/j/jiaming-shen/>Jiaming Shen</a>
|
<a href=/people/x/xiaotao-gu/>Xiaotao Gu</a>
|
<a href=/people/j/jiawei-han/>Jiawei Han</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1229><div class="card-body p-3 small">We present a novel end-to-end reinforcement learning approach to <a href=https://en.wikipedia.org/wiki/Automatic_taxonomy_induction>automatic taxonomy induction</a> from a set of terms. While prior methods treat the <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> as a two-phase task (i.e.,, detecting hypernymy pairs followed by organizing these pairs into a tree-structured hierarchy), we argue that such two-phase methods may suffer from <a href=https://en.wikipedia.org/wiki/Error_propagation>error propagation</a>, and can not effectively optimize <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> that capture the holistic structure of a taxonomy. In our approach, the representations of term pairs are learned using multiple sources of information and used to determine which term to select and where to place it on the <a href=https://en.wikipedia.org/wiki/Taxonomy_(biology)>taxonomy</a> via a policy network. All components are trained in an end-to-end manner with cumulative rewards, measured by a holistic tree metric over the training <a href=https://en.wikipedia.org/wiki/Taxonomy_(biology)>taxonomies</a>. Experiments on two public datasets of different domains show that our approach outperforms prior state-of-the-art taxonomy induction methods up to 19.6 % on ancestor F1.<i>i.e.</i>,, detecting hypernymy pairs followed by organizing these pairs into a tree-structured hierarchy), we argue that such two-phase methods may suffer from error propagation, and cannot effectively optimize metrics that capture the holistic structure of a taxonomy. In our approach, the representations of term pairs are learned using multiple sources of information and used to determine <i>which</i> term to select and <i>where</i> to place it on the taxonomy via a policy network. All components are trained in an end-to-end manner with cumulative rewards, measured by a holistic tree metric over the training taxonomies. Experiments on two public datasets of different domains show that our approach outperforms prior state-of-the-art taxonomy induction methods up to 19.6% on ancestor F1.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1230.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1230 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1230 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1230.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1230" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1230/>Incorporating Glosses into Neural Word Sense Disambiguation</a></strong><br><a href=/people/f/fuli-luo/>Fuli Luo</a>
|
<a href=/people/t/tianyu-liu/>Tianyu Liu</a>
|
<a href=/people/q/qiaolin-xia/>Qiaolin Xia</a>
|
<a href=/people/b/baobao-chang/>Baobao Chang</a>
|
<a href=/people/z/zhifang-sui/>Zhifang Sui</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1230><div class="card-body p-3 small">Word Sense Disambiguation (WSD) aims to identify the correct meaning of <a href=https://en.wikipedia.org/wiki/Polysemy>polysemous words</a> in the particular context. Lexical resources like <a href=https://en.wikipedia.org/wiki/WordNet>WordNet</a> which are proved to be of great help for WSD in the knowledge-based methods. However, previous <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> for WSD always rely on massive labeled data (context), ignoring lexical resources like <a href=https://en.wikipedia.org/wiki/Gloss_(annotation)>glosses</a> (sense definitions). In this paper, we integrate the context and glosses of the target word into a unified framework in order to make full use of both <a href=https://en.wikipedia.org/wiki/Labeled_data>labeled data</a> and <a href=https://en.wikipedia.org/wiki/Lexical_analysis>lexical knowledge</a>. Therefore, we propose GAS : a gloss-augmented WSD neural network which jointly encodes the context and glosses of the target word. GAS models the semantic relationship between the context and the gloss in an improved memory network framework, which breaks the barriers of the previous <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised methods</a> and knowledge-based methods. We further extend the original gloss of word sense via its semantic relations in <a href=https://en.wikipedia.org/wiki/WordNet>WordNet</a> to enrich the <a href=https://en.wikipedia.org/wiki/Gloss_(annotation)>gloss information</a>. The experimental results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms the state-of-the-art systems on several English all-words WSD datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1231.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1231 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1231 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1231.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1231" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1231/>Bilingual Sentiment Embeddings : Joint Projection of Sentiment Across Languages</a></strong><br><a href=/people/j/jeremy-barnes/>Jeremy Barnes</a>
|
<a href=/people/r/roman-klinger/>Roman Klinger</a>
|
<a href=/people/s/sabine-schulte-im-walde/>Sabine Schulte im Walde</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1231><div class="card-body p-3 small">Sentiment analysis in low-resource languages suffers from a lack of annotated corpora to estimate high-performing models. Machine translation and bilingual word embeddings provide some relief through cross-lingual sentiment approaches. However, they either require large amounts of parallel data or do not sufficiently capture <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment information</a>. We introduce Bilingual Sentiment Embeddings (BLSE), which jointly represent <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment information</a> in a source and target language. This model only requires a small <a href=https://en.wikipedia.org/wiki/Bilingual_lexicon>bilingual lexicon</a>, a source-language corpus annotated for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment</a>, and monolingual word embeddings for each language. We perform experiments on three language combinations (Spanish, Catalan, Basque) for sentence-level cross-lingual sentiment classification and find that our model significantly outperforms state-of-the-art methods on four out of six experimental setups, as well as capturing complementary information to <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. Our analysis of the resulting <a href=https://en.wikipedia.org/wiki/Embedding>embedding space</a> provides evidence that it represents <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment information</a> in the resource-poor target language without any annotated data in that language.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1232.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1232 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1232 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1232.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1232/>Learning Domain-Sensitive and Sentiment-Aware Word Embeddings</a></strong><br><a href=/people/b/bei-shi/>Bei Shi</a>
|
<a href=/people/z/zihao-fu/>Zihao Fu</a>
|
<a href=/people/l/lidong-bing/>Lidong Bing</a>
|
<a href=/people/w/wai-lam/>Wai Lam</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1232><div class="card-body p-3 small">Word embeddings have been widely used in sentiment classification because of their efficacy for semantic representations of words. Given reviews from different domains, some existing methods for <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> exploit <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment information</a>, but they can not produce domain-sensitive embeddings. On the other hand, some other existing methods can generate domain-sensitive word embeddings, but they can not distinguish words with similar contexts but opposite sentiment polarity. We propose a new method for learning domain-sensitive and sentiment-aware embeddings that simultaneously capture the information of sentiment semantics and domain sensitivity of individual words. Our method can automatically determine and produce domain-common embeddings and domain-specific embeddings. The differentiation of domain-common and domain-specific words enables the advantage of data augmentation of common semantics from multiple domains and capture the varied semantics of specific words from different domains at the same time. Experimental results show that our model provides an effective way to learn domain-sensitive and sentiment-aware word embeddings which benefit sentiment classification at both sentence level and lexicon term level.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1233.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1233 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1233 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1233.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1233/>Cross-Domain Sentiment Classification with Target Domain Specific Information</a></strong><br><a href=/people/m/minlong-peng/>Minlong Peng</a>
|
<a href=/people/q/qi-zhang/>Qi Zhang</a>
|
<a href=/people/y/yu-gang-jiang/>Yu-gang Jiang</a>
|
<a href=/people/x/xuan-jing-huang/>Xuanjing Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1233><div class="card-body p-3 small">The task of adopting a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> with good performance to a target domain that is different from the source domain used for training has received considerable attention in <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>. Most existing approaches mainly focus on learning <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a> that are domain-invariant in both the source and target domains. Few of them pay attention to domain-specific information, which should also be informative. In this work, we propose a method to simultaneously extract domain specific and invariant representations and train a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> on each of the <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representation</a>, respectively. And we introduce a few target domain labeled data for learning domain-specific information. To effectively utilize the target domain labeled data, we train the domain invariant representation based classifier with both the source and target domain labeled data and train the domain-specific representation based classifier with only the target domain labeled data. These two classifiers then boost each other in a co-training style. Extensive <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> experiments demonstrated that the proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a> could achieve better performance than state-of-the-art methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1234.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1234 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1234 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1234.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1234/>Aspect Based Sentiment Analysis with Gated Convolutional Networks</a></strong><br><a href=/people/w/wei-xue/>Wei Xue</a>
|
<a href=/people/t/tao-li/>Tao Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1234><div class="card-body p-3 small">Aspect based sentiment analysis (ABSA) can provide more detailed information than general sentiment analysis, because it aims to predict the sentiment polarities of the given aspects or entities in text. We summarize previous approaches into two subtasks : aspect-category sentiment analysis (ACSA) and aspect-term sentiment analysis (ATSA). Most previous approaches employ long short-term memory and attention mechanisms to predict the sentiment polarity of the concerned targets, which are often complicated and need more training time. We propose a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> based on <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>convolutional neural networks</a> and gating mechanisms, which is more accurate and efficient. First, the novel Gated Tanh-ReLU Units can selectively output the sentiment features according to the given aspect or entity. The <a href=https://en.wikipedia.org/wiki/Architecture>architecture</a> is much simpler than attention layer used in the existing <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a>. Second, the computations of our model could be easily parallelized during training, because convolutional layers do not have time dependency as in LSTM layers, and gating units also work independently. The experiments on SemEval datasets demonstrate the efficiency and effectiveness of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1235.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1235 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1235 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P18-1235/>A Helping Hand : <a href=https://en.wikipedia.org/wiki/Transfer_learning>Transfer Learning</a> for Deep Sentiment Analysis</a></strong><br><a href=/people/x/xin-luna-dong/>Xin Dong</a>
|
<a href=/people/g/gerard-de-melo/>Gerard de Melo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1235><div class="card-body p-3 small">Deep convolutional neural networks excel at sentiment polarity classification, but tend to require substantial amounts of training data, which moreover differs quite significantly between domains. In this work, we present an approach to feed generic cues into the training process of such <a href=https://en.wikipedia.org/wiki/Neural_network>networks</a>, leading to better generalization abilities given limited training data. We propose to induce sentiment embeddings via supervision on extrinsic data, which are then fed into the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> via a dedicated memory-based component. We observe significant gains in effectiveness on a range of different <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> in seven different languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1236.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1236 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1236 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1236.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1236" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1236/>Cold-Start Aware User and Product Attention for Sentiment Classification</a></strong><br><a href=/people/r/reinald-kim-amplayo/>Reinald Kim Amplayo</a>
|
<a href=/people/j/jihyeok-kim/>Jihyeok Kim</a>
|
<a href=/people/s/sua-sung/>Sua Sung</a>
|
<a href=/people/s/seung-won-hwang/>Seung-won Hwang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1236><div class="card-body p-3 small">The use of user / product information in <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> is important, especially for cold-start users / products, whose number of reviews are very limited. However, current <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> do not deal with the cold-start problem which is typical in <a href=https://en.wikipedia.org/wiki/Review_site>review websites</a>. In this paper, we present Hybrid Contextualized Sentiment Classifier (HCSC), which contains two modules : (1) a fast word encoder that returns word vectors embedded with short and long range dependency features ; and (2) Cold-Start Aware Attention (CSAA), an attention mechanism that considers the existence of cold-start problem when attentively pooling the encoded word vectors. HCSC introduces shared vectors that are constructed from similar users / products, and are used when the original distinct vectors do not have sufficient information (i.e. cold-start). This is decided by a frequency-guided selective gate vector. Our experiments show that in terms of RMSE, HCSC performs significantly better when compared with on famous datasets, despite having less <a href=https://en.wikipedia.org/wiki/Computational_complexity_theory>complexity</a>, and thus can be trained much faster. More importantly, our <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> performs significantly better than previous <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> when the training data is sparse and has cold-start problems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1237.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1237 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1237 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1237.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1237/>Modeling Deliberative Argumentation Strategies on Wikipedia<span class=acl-fixed-case>W</span>ikipedia</a></strong><br><a href=/people/k/khalid-al-khatib/>Khalid Al-Khatib</a>
|
<a href=/people/h/henning-wachsmuth/>Henning Wachsmuth</a>
|
<a href=/people/k/kevin-lang/>Kevin Lang</a>
|
<a href=/people/j/jakob-herpel/>Jakob Herpel</a>
|
<a href=/people/m/matthias-hagen/>Matthias Hagen</a>
|
<a href=/people/b/benno-stein/>Benno Stein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1237><div class="card-body p-3 small">This paper studies how the <a href=https://en.wikipedia.org/wiki/Argumentation_theory>argumentation strategies</a> of participants in <a href=https://en.wikipedia.org/wiki/Deliberation>deliberative discussions</a> can be supported computationally. Our ultimate goal is to predict the best next deliberative move of each participant. In this paper, we present a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> for <a href=https://en.wikipedia.org/wiki/Deliberative_assembly>deliberative discussions</a> and we illustrate its operationalization. Previous <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> have been built manually based on a small set of discussions, resulting in a level of abstraction that is not suitable for move recommendation. In contrast, we derive our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> statistically from several types of <a href=https://en.wikipedia.org/wiki/Metadata>metadata</a> that can be used for move description. Applied to six million discussions from Wikipedia talk pages, our approach results in a model with 13 categories along three dimensions : discourse acts, argumentative relations, and frames. On this basis, we automatically generate a corpus with about 200,000 turns, labeled for the 13 categories. We then operationalize the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> with three supervised classifiers and provide evidence that the proposed categories can be predicted.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1241.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1241 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1241 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1241.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1241.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1241" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1241/>Attacking Visual Language Grounding with Adversarial Examples : A Case Study on Neural Image Captioning</a></strong><br><a href=/people/h/hongge-chen/>Hongge Chen</a>
|
<a href=/people/h/huan-zhang/>Huan Zhang</a>
|
<a href=/people/p/pin-yu-chen/>Pin-Yu Chen</a>
|
<a href=/people/j/jinfeng-yi/>Jinfeng Yi</a>
|
<a href=/people/c/cho-jui-hsieh/>Cho-Jui Hsieh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1241><div class="card-body p-3 small">Visual language grounding is widely studied in modern neural image captioning systems, which typically adopts an encoder-decoder framework consisting of two principal components : a convolutional neural network (CNN) for image feature extraction and a recurrent neural network (RNN) for language caption generation. To study the robustness of language grounding to adversarial perturbations in <a href=https://en.wikipedia.org/wiki/Machine_vision>machine vision</a> and perception, we propose Show-and-Fool, a novel <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> for crafting adversarial examples in neural image captioning. The proposed <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> provides two evaluation approaches, which check if we can mislead neural image captioning systems to output some randomly chosen captions or keywords. Our extensive experiments show that our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> can successfully craft visually-similar adversarial examples with randomly targeted captions or keywords, and the adversarial examples can be made highly transferable to other image captioning systems. Consequently, our approach leads to new robustness implications of neural image captioning and novel insights in visual language grounding.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1243.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1243 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1243 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1243.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1243.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1243" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1243/>Interactive Language Acquisition with One-shot Visual Concept Learning through a Conversational Game</a></strong><br><a href=/people/h/haichao-zhang/>Haichao Zhang</a>
|
<a href=/people/h/haonan-yu/>Haonan Yu</a>
|
<a href=/people/w/wei-xu/>Wei Xu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1243><div class="card-body p-3 small">Building <a href=https://en.wikipedia.org/wiki/Intelligent_agent>intelligent agents</a> that can communicate with and learn from humans in <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a> is of great value. Supervised language learning is limited by the ability of capturing mainly the statistics of training data, and is hardly adaptive to new scenarios or flexible for acquiring new knowledge without inefficient retraining or catastrophic forgetting. We highlight the perspective that conversational interaction serves as a natural interface both for <a href=https://en.wikipedia.org/wiki/Language_acquisition>language learning</a> and for novel <a href=https://en.wikipedia.org/wiki/Knowledge_acquisition>knowledge acquisition</a> and propose a joint imitation and reinforcement approach for grounded language learning through an interactive conversational game. The <a href=https://en.wikipedia.org/wiki/Intelligent_agent>agent</a> trained with this approach is able to actively acquire information by asking questions about novel objects and use the just-learned knowledge in subsequent conversations in a one-shot fashion. Results compared with other methods verified the effectiveness of the proposed approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1245.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1245 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1245 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1245.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1245.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1245" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1245/>A Structured Variational Autoencoder for Contextual Morphological Inflection</a></strong><br><a href=/people/l/lawrence-wolf-sonkin/>Lawrence Wolf-Sonkin</a>
|
<a href=/people/j/jason-naradowsky/>Jason Naradowsky</a>
|
<a href=/people/s/sabrina-j-mielke/>Sabrina J. Mielke</a>
|
<a href=/people/r/ryan-cotterell/>Ryan Cotterell</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1245><div class="card-body p-3 small">Statistical morphological inflectors are typically trained on fully supervised, type-level data. One remaining open research question is the following : How can we effectively exploit raw, token-level data to improve their performance? To this end, we introduce a novel generative latent-variable model for the semi-supervised learning of inflection generation. To enable <a href=https://en.wikipedia.org/wiki/Posterior_probability>posterior inference</a> over the <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variables</a>, we derive an efficient variational inference procedure based on the <a href=https://en.wikipedia.org/wiki/Wake-sleep_algorithm>wake-sleep algorithm</a>. We experiment on 23 languages, using the Universal Dependencies corpora in a simulated low-resource setting, and find improvements of over 10 % absolute accuracy in some cases.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1248.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1248 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1248 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1248.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P18-1248" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P18-1248/>Global Transition-based Non-projective Dependency Parsing</a></strong><br><a href=/people/c/carlos-gomez-rodriguez/>Carlos Gómez-Rodríguez</a>
|
<a href=/people/t/tianze-shi/>Tianze Shi</a>
|
<a href=/people/l/lillian-lee/>Lillian Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1248><div class="card-body p-3 small">Shi, Huang, and Lee (2017a) obtained state-of-the-art results for English and Chinese dependency parsing by combining dynamic-programming implementations of transition-based dependency parsers with a minimal set of bidirectional LSTM features. However, their results were limited to projective parsing. In this paper, we extend their approach to support non-projectivity by providing the first practical implementation of the MH algorithm, an O(n^4) mildly nonprojective dynamic-programming parser with very high coverage on non-projective treebanks. To make MH compatible with minimal transition-based feature sets, we introduce a transition-based interpretation of it in which parser items are mapped to sequences of transitions. We thus obtain the first implementation of global decoding for non-projective transition-based parsing, and demonstrate empirically that it is effective than its projective counterpart in parsing a number of highly non-projective languages.<tex-math>O(n^4)</tex-math> mildly nonprojective dynamic-programming parser with very high coverage on non-projective treebanks. To make MH&#8324; compatible with minimal transition-based feature sets, we introduce a transition-based interpretation of it in which parser items are mapped to sequences of transitions. We thus obtain the first implementation of global decoding for non-projective transition-based parsing, and demonstrate empirically that it is effective than its projective counterpart in parsing a number of highly non-projective languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1251.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1251 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1251 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1251.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1251/>Composing <a href=https://en.wikipedia.org/wiki/Finite-state_transducer>Finite State Transducers</a> on GPUs<span class=acl-fixed-case>GPU</span>s</a></strong><br><a href=/people/a/arturo-argueta/>Arturo Argueta</a>
|
<a href=/people/d/david-chiang/>David Chiang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1251><div class="card-body p-3 small">Weighted finite state transducers (FSTs) are frequently used in <a href=https://en.wikipedia.org/wiki/Language_processing>language processing</a> to handle tasks such as <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a> and <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech recognition</a>. There has been previous work using multiple <a href=https://en.wikipedia.org/wiki/Central_processing_unit>CPU cores</a> to accelerate <a href=https://en.wikipedia.org/wiki/Finite-state_machine>finite state algorithms</a>, but limited attention has been given to parallel graphics processing unit (GPU) implementations. In this paper, we introduce the first (to our knowledge) GPU implementation of the FST composition operation, and we also discuss the optimizations used to achieve the best performance on this <a href=https://en.wikipedia.org/wiki/Computer_architecture>architecture</a>. We show that our approach obtains speedups of up to 6 times over our serial implementation and 4.5 times over OpenFST.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1254.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1254 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1254 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/288152828 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1254/>Finding syntax in human encephalography with <a href=https://en.wikipedia.org/wiki/Beam_search>beam search</a></a></strong><br><a href=/people/j/john-hale/>John Hale</a>
|
<a href=/people/c/chris-dyer/>Chris Dyer</a>
|
<a href=/people/a/adhiguna-kuncoro/>Adhiguna Kuncoro</a>
|
<a href=/people/j/jonathan-brennan/>Jonathan Brennan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1254><div class="card-body p-3 small">Recurrent neural network grammars (RNNGs) are generative models of (tree, string) pairs that rely on neural networks to evaluate derivational choices. Parsing with them using <a href=https://en.wikipedia.org/wiki/Beam_search>beam search</a> yields a variety of incremental complexity metrics such as word surprisal and parser action count. When used as regressors against human electrophysiological responses to naturalistic text, they derive two amplitude effects : an early peak and a P600-like later peak. By contrast, a non-syntactic neural language model yields no reliable effects. Model comparisons attribute the early peak to <a href=https://en.wikipedia.org/wiki/Syntax>syntactic composition</a> within the RNNG. This pattern of results recommends the RNNG+beam search combination as a mechanistic model of the <a href=https://en.wikipedia.org/wiki/Syntax>syntactic processing</a> that occurs during normal human language comprehension.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P18-1256.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P18-1256 data-toggle=collapse aria-expanded=false aria-controls=abstract-P18-1256 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P18-1256.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/288152712 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P18-1256/>Let’s do it again : A First Computational Approach to Detecting Adverbial Presupposition Triggers</a></strong><br><a href=/people/a/andre-cianflone/>Andre Cianflone</a>
|
<a href=/people/y/yulan-feng/>Yulan Feng</a>
|
<a href=/people/j/jad-kabbara/>Jad Kabbara</a>
|
<a href=/people/j/jackie-chi-kit-cheung/>Jackie Chi Kit Cheung</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P18-1256><div class="card-body p-3 small">We introduce the novel task of predicting adverbial presupposition triggers, which is useful for natural language generation tasks such as <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> and dialogue systems. We introduce two new corpora, derived from the Penn Treebank and the Annotated English Gigaword dataset and investigate the use of a novel attention mechanism tailored to this task. Our attention mechanism augments a baseline recurrent neural network without the need for additional trainable parameters, minimizing the added computational cost of our <a href=https://en.wikipedia.org/wiki/Mechanism_design>mechanism</a>. We demonstrate that this <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> statistically outperforms our <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a>.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>