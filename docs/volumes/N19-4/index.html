<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/N19-4.pdf>Proceedings of the 2019 Conference of the North <span class=acl-fixed-case>A</span>merican Chapter of the Association for Computational Linguistics (Demonstrations)</a></h2><p class=lead><a href=/people/w/waleed-ammar/>Waleed Ammar</a>,
<a href=/people/a/annie-louis/>Annie Louis</a>,
<a href=/people/n/nasrin-mostafazadeh/>Nasrin Mostafazadeh</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>N19-4</dd><dt>Month:</dt><dd>June</dd><dt>Year:</dt><dd>2019</dd><dt>Address:</dt><dd>Minneapolis, Minnesota</dd><dt>Venue:</dt><dd><a href=/venues/naacl/>NAACL</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/N19-4>https://aclanthology.org/N19-4</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/N19-4.pdf>https://aclanthology.org/N19-4.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/N19-4.pdf title="Open PDF of 'Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+2019+Conference+of+the+North+American+Chapter+of+the+Association+for+Computational+Linguistics+%28Demonstrations%29" title="Search for 'Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-4000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N19-4000/>Proceedings of the 2019 Conference of the North <span class=acl-fixed-case>A</span>merican Chapter of the Association for Computational Linguistics (Demonstrations)</a></strong><br><a href=/people/w/waleed-ammar/>Waleed Ammar</a>
|
<a href=/people/a/annie-louis/>Annie Louis</a>
|
<a href=/people/n/nasrin-mostafazadeh/>Nasrin Mostafazadeh</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-4002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-4002 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-4002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N19-4002/>ADIDA : Automatic Dialect Identification for <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a><span class=acl-fixed-case>ADIDA</span>: Automatic Dialect Identification for <span class=acl-fixed-case>A</span>rabic</a></strong><br><a href=/people/o/ossama-obeid/>Ossama Obeid</a>
|
<a href=/people/m/mohammad-salameh/>Mohammad Salameh</a>
|
<a href=/people/h/houda-bouamor/>Houda Bouamor</a>
|
<a href=/people/n/nizar-habash/>Nizar Habash</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-4002><div class="card-body p-3 small">This demo paper describes ADIDA, a web-based system for automatic dialect identification for <a href=https://en.wikipedia.org/wiki/Arabic_alphabet>Arabic text</a>. The system distinguishes among the dialects of 25 Arab cities (from Rabat to Muscat) in addition to Modern Standard <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a>. The results are presented with either a point map or a <a href=https://en.wikipedia.org/wiki/Heat_map>heat map</a> visualizing the automatic identification probabilities over a geographical map of the Arab World.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-4004.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-4004 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-4004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N19-4004/>INS : An Interactive Chinese News Synthesis System<span class=acl-fixed-case>INS</span>: An Interactive <span class=acl-fixed-case>C</span>hinese News Synthesis System</a></strong><br><a href=/people/h/hui-liu/>Hui Liu</a>
|
<a href=/people/w/wentao-qin/>Wentao Qin</a>
|
<a href=/people/x/xiaojun-wan/>Xiaojun Wan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-4004><div class="card-body p-3 small">Nowadays, we are surrounded by more and more <a href=https://en.wikipedia.org/wiki/Online_newspaper>online news articles</a>. Tens or hundreds of <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a> need to be read if we wish to explore a hot news event or topic. So it is of vital importance to automatically synthesize a batch of <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a> related to the event or topic into a new synthesis article (or overview article) for reader&#8217;s convenience. It is so challenging to make news synthesis fully automatic that there is no successful solution by now. In this paper, we put forward a novel Interactive News Synthesis system (i.e. INS), which can help generate news overview articles automatically or by interacting with users. More importantly, <a href=https://en.wikipedia.org/wiki/Immigration_and_Naturalization_Service>INS</a> can serve as a tool for editors to help them finish their jobs. In our experiments, INS performs well on both <a href=https://en.wikipedia.org/wiki/Topic_and_comment>topic representation</a> and synthesis article generation. A <a href=https://en.wikipedia.org/wiki/User_study>user study</a> also demonstrates the usefulness and users&#8217; satisfaction with the INS tool. A demo video is available at.<url>https://youtu.be/7ItteKW3GEk</url>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-4006.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-4006 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-4006 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-4006" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N19-4006/>Train, Sort, Explain : Learning to Diagnose Translation Models</a></strong><br><a href=/people/r/robert-schwarzenberg/>Robert Schwarzenberg</a>
|
<a href=/people/d/david-harbecke/>David Harbecke</a>
|
<a href=/people/v/vivien-macketanz/>Vivien Macketanz</a>
|
<a href=/people/e/eleftherios-avramidis/>Eleftherios Avramidis</a>
|
<a href=/people/s/sebastian-moller/>Sebastian Möller</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-4006><div class="card-body p-3 small">Evaluating translation models is a trade-off between effort and detail. On the one end of the spectrum there are automatic count-based methods such as <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>, on the other end linguistic evaluations by humans, which arguably are more informative but also require a disproportionately high effort. To narrow the spectrum, we propose a general approach on how to automatically expose systematic differences between human and machine translations to human experts. Inspired by <a href=https://en.wikipedia.org/wiki/Adversarial_system>adversarial settings</a>, we train a neural text classifier to distinguish human from machine translations. A <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> that performs and generalizes well after training should recognize systematic differences between the two classes, which we uncover with neural explainability methods. Our proof-of-concept implementation, DiaMaT, is open source. Applied to a dataset translated by a state-of-the-art neural Transformer model, DiaMaT achieves a classification accuracy of 75 % and exposes meaningful differences between humans and the Transformer, amidst the current discussion about human parity.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-4012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-4012 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-4012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-4012" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N19-4012/>LeafNATS : An Open-Source Toolkit and Live Demo System for Neural Abstractive Text Summarization<span class=acl-fixed-case>L</span>eaf<span class=acl-fixed-case>NATS</span>: An Open-Source Toolkit and Live Demo System for Neural Abstractive Text Summarization</a></strong><br><a href=/people/t/tian-shi/>Tian Shi</a>
|
<a href=/people/p/ping-wang/>Ping Wang</a>
|
<a href=/people/c/chandan-k-reddy/>Chandan K. Reddy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-4012><div class="card-body p-3 small">Neural abstractive text summarization (NATS) has received a lot of attention in the past few years from both industry and academia. In this paper, we introduce an open-source toolkit, namely LeafNATS, for training and evaluation of different sequence-to-sequence based models for the NATS task, and for deploying the pre-trained models to real-world applications. The <a href=https://en.wikipedia.org/wiki/List_of_toolkits>toolkit</a> is modularized and extensible in addition to maintaining competitive performance in the NATS task. A live news blogging system has also been implemented to demonstrate how these models can aid blog / news editors by providing them suggestions of headlines and summaries of their articles.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-4014.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-4014 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-4014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N19-4014/>FAKTA : An Automatic End-to-End Fact Checking System<span class=acl-fixed-case>FAKTA</span>: An Automatic End-to-End Fact Checking System</a></strong><br><a href=/people/m/moin-nadeem/>Moin Nadeem</a>
|
<a href=/people/w/wei-fang/>Wei Fang</a>
|
<a href=/people/b/brian-xu/>Brian Xu</a>
|
<a href=/people/m/mitra-mohtarami/>Mitra Mohtarami</a>
|
<a href=/people/j/james-glass/>James Glass</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-4014><div class="card-body p-3 small">We present FAKTA which is a unified framework that integrates various components of a fact-checking process : document retrieval from media sources with various types of reliability, stance detection of documents with respect to given claims, evidence extraction, and linguistic analysis. FAKTA predicts the factuality of given claims and provides evidence at the document and sentence level to explain its predictions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-4016.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-4016 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-4016 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-4016" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N19-4016/>Plan, Write, and Revise : an Interactive System for Open-Domain Story Generation</a></strong><br><a href=/people/s/seraphina-goldfarb-tarrant/>Seraphina Goldfarb-Tarrant</a>
|
<a href=/people/h/haining-feng/>Haining Feng</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-4016><div class="card-body p-3 small">Story composition is a challenging problem for machines and even for humans. We present a neural narrative generation system that interacts with humans to generate stories. Our system has different levels of human interaction, which enables us to understand at what stage of story-writing human collaboration is most productive, both to improving story quality and human engagement in the writing process. We compare different varieties of interaction in story-writing, story-planning, and diversity controls under time constraints, and show that increased types of human collaboration at both planning and writing stages results in a 10-50 % improvement in story quality as compared to less interactive baselines. We also show an accompanying increase in user engagement and satisfaction with stories as compared to our own less interactive systems and to previous turn-taking approaches to <a href=https://en.wikipedia.org/wiki/Interaction>interaction</a>. Finally, we find that humans tasked with collaboratively improving a particular characteristic of a story are in fact able to do so, which has implications for future uses of human-in-the-loop systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-4017.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-4017 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-4017 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=N19-4017" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/N19-4017/>LT Expertfinder : An Evaluation Framework for Expert Finding Methods<span class=acl-fixed-case>LT</span> Expertfinder: An Evaluation Framework for Expert Finding Methods</a></strong><br><a href=/people/t/tim-fischer/>Tim Fischer</a>
|
<a href=/people/s/steffen-remus/>Steffen Remus</a>
|
<a href=/people/c/chris-biemann/>Chris Biemann</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-4017><div class="card-body p-3 small">Expert finding is the task of ranking persons for a predefined topic or search query. Finding experts for a specified area is an important task and has attracted much attention in the <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval community</a>. Most approaches for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> are evaluated in a supervised fashion, which depend on predefined topics of interest as well as gold standard expert rankings. Famous representatives of such datasets are enriched versions of <a href=https://en.wikipedia.org/wiki/DBLP>DBLP</a> provided by the ArnetMiner projet or the W3C Corpus of TREC. However, manually ranking experts can be considered highly subjective and detailed rankings are hardly distinguishable. Evaluating these <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> does not necessarily guarantee a good or bad performance of the <a href=https://en.wikipedia.org/wiki/System>system</a>. Particularly for <a href=https://en.wikipedia.org/wiki/Dynamical_system>dynamic systems</a>, where topics are not predefined but formulated as a <a href=https://en.wikipedia.org/wiki/Web_search_query>search query</a>, we believe a more informative approach is to perform <a href=https://en.wikipedia.org/wiki/User_study>user studies</a> for directly comparing different methods in the same view. In order to accomplish this in a user-friendly way, we present the LT Expert Finder web-application, which is equipped with various query-based expert finding methods that can be easily extended, a detailed expert profile view, detailed evidence in form of relevant documents and statistics, and an evaluation component that allows the qualitative comparison between different rankings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-4020.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-4020 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-4020 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N19-4020/>Litigation Analytics : Extracting and querying motions and orders from US federal courts<span class=acl-fixed-case>US</span> federal courts</a></strong><br><a href=/people/t/thomas-vacek/>Thomas Vacek</a>
|
<a href=/people/d/dezhao-song/>Dezhao Song</a>
|
<a href=/people/h/hugo-molina-salgado/>Hugo Molina-Salgado</a>
|
<a href=/people/r/ronald-teo/>Ronald Teo</a>
|
<a href=/people/c/conner-cowling/>Conner Cowling</a>
|
<a href=/people/f/frank-schilder/>Frank Schilder</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-4020><div class="card-body p-3 small">Legal litigation planning can benefit from statistics collected from past decisions made by judges. Information on the typical duration for a submitted motion, for example, can give valuable clues for developing a successful <a href=https://en.wikipedia.org/wiki/Strategy>strategy</a>. Such information is encoded in semi-structured documents called dockets. In order to extract and aggregate this information, we deployed various <a href=https://en.wikipedia.org/wiki/Information_extraction>information extraction</a> and machine learning techniques. The aggregated data can be queried in real time within the Westlaw Edge search engine. In addition to a <a href=https://en.wikipedia.org/wiki/Keyword_search>keyword search</a> for <a href=https://en.wikipedia.org/wiki/Judge>judges</a>, <a href=https://en.wikipedia.org/wiki/Lawyer>lawyers</a>, <a href=https://en.wikipedia.org/wiki/Law_firm>law firms</a>, parties and courts, we also implemented a question answering interface that offers targeted questions in order to get to the respective answers quicker.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-4023.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-4023 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-4023 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N19-4023/>A Research Platform for Multi-Robot Dialogue with Humans<span class=acl-fixed-case>R</span>esearch <span class=acl-fixed-case>P</span>latform for <span class=acl-fixed-case>M</span>ulti-<span class=acl-fixed-case>R</span>obot <span class=acl-fixed-case>D</span>ialogue with <span class=acl-fixed-case>H</span>umans</a></strong><br><a href=/people/m/matthew-marge/>Matthew Marge</a>
|
<a href=/people/s/stephen-nogar/>Stephen Nogar</a>
|
<a href=/people/c/cory-hayes/>Cory J. Hayes</a>
|
<a href=/people/s/stephanie-lukin/>Stephanie M. Lukin</a>
|
<a href=/people/j/jesse-bloecker/>Jesse Bloecker</a>
|
<a href=/people/e/eric-holder/>Eric Holder</a>
|
<a href=/people/c/clare-voss/>Clare Voss</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-4023><div class="card-body p-3 small">This paper presents a <a href=https://en.wikipedia.org/wiki/Computing_platform>research platform</a> that supports spoken dialogue interaction with multiple robots. The demonstration showcases our crafted MultiBot testing scenario in which users can verbally issue search, navigate, and follow instructions to two robotic teammates : a simulated ground robot and an <a href=https://en.wikipedia.org/wiki/Autonomous_robot>aerial robot</a>. This flexible language and robotic platform takes advantage of existing tools for <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech recognition</a> and dialogue management that are compatible with new domains, and implements an inter-agent communication protocol (tactical behavior specification), where verbal instructions are encoded for tasks assigned to the appropriate robot.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/N19-4024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-N19-4024 data-toggle=collapse aria-expanded=false aria-controls=abstract-N19-4024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/N19-4024/>Chat-crowd : A Dialog-based Platform for Visual Layout Composition</a></strong><br><a href=/people/p/paola-cascante-bonilla/>Paola Cascante-Bonilla</a>
|
<a href=/people/x/xuwang-yin/>Xuwang Yin</a>
|
<a href=/people/v/vicente-ordonez/>Vicente Ordonez</a>
|
<a href=/people/s/song-feng/>Song Feng</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-N19-4024><div class="card-body p-3 small">In this paper we introduce Chat-crowd, an interactive environment for visual layout composition via conversational interactions. Chat-crowd supports multiple agents with two conversational roles : agents who play the role of a designer are in charge of placing objects in an editable canvas according to instructions or commands issued by agents with a director role. The system can be integrated with <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing platforms</a> for both synchronous and asynchronous data collection and is equipped with comprehensive <a href=https://en.wikipedia.org/wiki/Quality_control>quality controls</a> on the performance of both types of <a href=https://en.wikipedia.org/wiki/Intelligent_agent>agents</a>. We expect that this system will be useful to build multimodal goal-oriented dialog tasks that require spatial and geometric reasoning.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>