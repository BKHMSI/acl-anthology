<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)</h2><p class=lead><a href=/people/d/dorothee-beermann/>Dorothee Beermann</a>,
<a href=/people/l/laurent-besacier/>Laurent Besacier</a>,
<a href=/people/s/sakriani-sakti/>Sakriani Sakti</a>,
<a href=/people/c/claudia-soria/>Claudia Soria</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2020.sltu-1</dd><dt>Month:</dt><dd>May</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Marseille, France</dd><dt>Venues:</dt><dd><a href=/venues/lrec/>LREC</a>
| <a href=/venues/sltu/>SLTU</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>European Language Resources association</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.sltu-1>https://aclanthology.org/2020.sltu-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+1st+Joint+Workshop+on+Spoken+Language+Technologies+for+Under-resourced+languages+%28SLTU%29+and+Collaboration+and+Computing+for+Under-Resourced+Languages+%28CCURL%29" title="Search for 'Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.0/>Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)</a></strong><br><a href=/people/d/dorothee-beermann/>Dorothee Beermann</a>
|
<a href=/people/l/laurent-besacier/>Laurent Besacier</a>
|
<a href=/people/s/sakriani-sakti/>Sakriani Sakti</a>
|
<a href=/people/c/claudia-soria/>Claudia Soria</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.3/>Open-Source High Quality Speech Datasets for Basque, Catalan and Galician<span class=acl-fixed-case>B</span>asque, <span class=acl-fixed-case>C</span>atalan and <span class=acl-fixed-case>G</span>alician</a></strong><br><a href=/people/o/oddur-kjartansson/>Oddur Kjartansson</a>
|
<a href=/people/a/alexander-gutkin/>Alexander Gutkin</a>
|
<a href=/people/a/alena-butryna/>Alena Butryna</a>
|
<a href=/people/i/isin-demirsahin/>Isin Demirsahin</a>
|
<a href=/people/c/clara-rivera/>Clara Rivera</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--3><div class="card-body p-3 small">This paper introduces new open speech datasets for three of the languages of Spain : <a href=https://en.wikipedia.org/wiki/Basque_language>Basque</a>, <a href=https://en.wikipedia.org/wiki/Catalan_language>Catalan</a> and <a href=https://en.wikipedia.org/wiki/Galician_language>Galician</a>. Catalan is furthermore the official language of the Principality of Andorra. The <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> consist of high-quality multi-speaker recordings of the three languages along with the associated transcriptions. The resulting <a href=https://en.wikipedia.org/wiki/Text_corpus>corpora</a> include over 33 hours of crowd-sourced recordings of 132 male and female native speakers. The recording scripts also include material for elicitation of global and local place names, personal and business names. The <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> are released under a permissive license and are available for free download for commercial, academic and personal use. The high-quality annotated speech datasets described in this paper can be used to, among other things, build <a href=https://en.wikipedia.org/wiki/Speech_synthesis>text-to-speech systems</a>, serve as adaptation data in <a href=https://en.wikipedia.org/wiki/Speech_recognition>automatic speech recognition</a> and provide useful phonetic and phonological insights in <a href=https://en.wikipedia.org/wiki/Corpus_linguistics>corpus linguistics</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.5/>Morphological Disambiguation of South Smi with FSTs and <a href=https://en.wikipedia.org/wiki/Neural_network>Neural Networks</a><span class=acl-fixed-case>S</span>outh <span class=acl-fixed-case>S</span>ámi with <span class=acl-fixed-case>FST</span>s and Neural Networks</a></strong><br><a href=/people/m/mika-hamalainen/>Mika Hämäläinen</a>
|
<a href=/people/l/linda-wiechetek/>Linda Wiechetek</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--5><div class="card-body p-3 small">We present a method for conducting morphological disambiguation for South Smi, which is an <a href=https://en.wikipedia.org/wiki/Endangered_language>endangered language</a>. Our method uses an FST-based morphological analyzer to produce an ambiguous set of morphological readings for each word in a sentence. These readings are disambiguated with a Bi-RNN model trained on the related North Smi UD Treebank and some synthetically generated South Smi data. The disambiguation is done on the level of morphological tags ignoring word forms and <a href=https://en.wikipedia.org/wiki/Lemma_(morphology)>lemmas</a> ; this makes it possible to use North Smi training data for South Smi without the need for a <a href=https://en.wikipedia.org/wiki/Bilingual_dictionary>bilingual dictionary</a> or aligned word embeddings. Our approach requires only minimal resources for South Smi, which makes it usable and applicable in the contexts of any other <a href=https://en.wikipedia.org/wiki/Endangered_language>endangered language</a> as well.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.8.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--8 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.8 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.8/>Neural Text-to-Speech Synthesis for an Under-Resourced Language in a Diglossic Environment : the Case of Gascon Occitan<span class=acl-fixed-case>G</span>ascon <span class=acl-fixed-case>O</span>ccitan</a></strong><br><a href=/people/a/ander-corral/>Ander Corral</a>
|
<a href=/people/i/igor-leturia/>Igor Leturia</a>
|
<a href=/people/a/aure-seguier/>Aure Séguier</a>
|
<a href=/people/m/michael-barret/>Michäel Barret</a>
|
<a href=/people/b/benaset-dazeas/>Benaset Dazéas</a>
|
<a href=/people/p/philippe-boula-de-mareuil/>Philippe Boula de Mareüil</a>
|
<a href=/people/n/nicolas-quint/>Nicolas Quint</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--8><div class="card-body p-3 small">Occitan is a <a href=https://en.wikipedia.org/wiki/Minority_language>minority language</a> spoken in Southern France, some Alpine Valleys of Italy, and the Val d&#8217;Aran in Spain, which only very recently started developing language and speech technologies. This paper describes the first project for designing a Text-to-Speech synthesis system for one of its main <a href=https://en.wikipedia.org/wiki/Gascon_language>regional varieties</a>, namely <a href=https://en.wikipedia.org/wiki/Gascon_language>Gascon</a>. We used a state-of-the-art deep neural network approach, the Tacotron2-WaveGlow system. However, we faced two additional difficulties or challenges : on the one hand, we wanted to test if it was possible to obtain good quality results with fewer recording hours than is usually reported for such systems ; on the other hand, we needed to achieve a standard, non-Occitan pronunciation of French proper names, therefore we needed to record French words and test phoneme-based approaches. The evaluation carried out over the various developed <a href=https://en.wikipedia.org/wiki/System>systems</a> and <a href=https://en.wikipedia.org/wiki/Software_development_process>approaches</a> shows promising results with near production-ready quality. It has also allowed us to detect the phenomena for which some flaws or fall of quality occur, pointing at the direction of future work to improve the quality of the actual system and for new systems for other <a href=https://en.wikipedia.org/wiki/Variety_(linguistics)>language varieties</a> and voices.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.14/>Poio Text Prediction : Lessons on the Development and Sustainability of LTs for Endangered Languages<span class=acl-fixed-case>LT</span>s for Endangered Languages</a></strong><br><a href=/people/g/gema-zamora-fernandez/>Gema Zamora Fernández</a>
|
<a href=/people/v/vera-ferreira/>Vera Ferreira</a>
|
<a href=/people/p/pedro-manha/>Pedro Manha</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--14><div class="card-body p-3 small">2019, the International Year of Indigenous Languages (IYIL), marked a crucial milestone for a diverse community united by a strong sense of urgency. In this presentation, we evaluate the impact of IYIL&#8217;s outcomes in the development of LTs for <a href=https://en.wikipedia.org/wiki/Endangered_language>endangered languages</a>. We give a brief description of the field of <a href=https://en.wikipedia.org/wiki/Language_documentation>Language Documentation</a>, whose experts have led the research and data collection efforts surrounding <a href=https://en.wikipedia.org/wiki/Endangered_language>endangered languages</a> for the past 30 years. We introduce the work of the Interdisciplinary Centre for Social and Language Documentation and we look at Poio as an example of an LT developed specifically with speakers of endangered languages in mind. This example illustrates how the deeper systemic causes of <a href=https://en.wikipedia.org/wiki/Endangered_language>language endangerment</a> are reflected in the development of <a href=https://en.wikipedia.org/wiki/Language_proficiency>LTs</a>. Additionally, we share some of the strategic decisions that have led the development of this project. Finally, we advocate the importance of bridging the divide between research and activism, pushing for the inclusion of threatened languages in the world of LTs, and doing so in close collaboration with the speaker community.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.16/>Scaling Language Data Import / Export with a Data Transformer Interface</a></strong><br><a href=/people/n/nicholas-buckeridge/>Nicholas Buckeridge</a>
|
<a href=/people/b/ben-foley/>Ben Foley</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--16><div class="card-body p-3 small">This paper focuses on the technical improvement of <a href=https://en.wikipedia.org/wiki/Elpis>Elpis</a>, a <a href=https://en.wikipedia.org/wiki/Language_technology>language technology</a> which assists people in the process of transcription, particularly for low-resource language documentation situations. To provide better support for the diversity of file formats encountered by people working to document the world&#8217;s languages, a Data Transformer interface has been developed to abstract the complexities of designing individual data import scripts. This work took place as part of a larger project of <a href=https://en.wikipedia.org/wiki/Code_quality>code quality improvement</a> and the publication of <a href=https://en.wikipedia.org/wiki/Template_processor>template code</a> that can be used for development of other <a href=https://en.wikipedia.org/wiki/Programming_language>language technologies</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.21/>Natural Language Processing Chains Inside a Cross-lingual Event-Centric Knowledge Pipeline for European Union Under-resourced Languages<span class=acl-fixed-case>E</span>uropean <span class=acl-fixed-case>U</span>nion Under-resourced Languages</a></strong><br><a href=/people/d/diego-alves/>Diego Alves</a>
|
<a href=/people/g/gaurish-thakkar/>Gaurish Thakkar</a>
|
<a href=/people/m/marko-tadic/>Marko Tadić</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--21><div class="card-body p-3 small">This article presents the strategy for developing a platform containing Language Processing Chains for European Union languages, consisting of Tokenization to <a href=https://en.wikipedia.org/wiki/Parsing>Parsing</a>, also including Named Entity recognition and with addition of <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a>. These chains are part of the first step of an event-centric knowledge processing pipeline whose aim is to process multilingual media information about major events that can cause an impact in Europe and the rest of the world. Due to the differences in terms of availability of language resources for each language, we have built this strategy in three steps, starting with processing chains for the well-resourced languages and finishing with the development of new modules for the under-resourced ones. In order to classify all <a href=https://en.wikipedia.org/wiki/Languages_of_the_European_Union>European Union official languages</a> in terms of resources, we have analysed the size of annotated corpora as well as the existence of pre-trained models in mainstream Language Processing tools, and we have combined this information with the proposed classification published at META-NET whitepaper series.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.23.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--23 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.23 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.23/>Acoustic-Phonetic Approach for ASR of Less Resourced Languages Using Monolingual and Cross-Lingual Information<span class=acl-fixed-case>ASR</span> of Less Resourced Languages Using Monolingual and Cross-Lingual Information</a></strong><br><a href=/people/s/shweta-bansal/>Shweta Bansal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--23><div class="card-body p-3 small">The exploration of <a href=https://en.wikipedia.org/wiki/Speech_processing>speech processing</a> for <a href=https://en.wikipedia.org/wiki/Endangered_language>endangered languages</a> has substantially increased in the past epoch of time. In this paper, we present the acoustic-phonetic approach for automatic speech recognition (ASR) using monolingual and cross-lingual information with application to under-resourced Indian languages, <a href=https://en.wikipedia.org/wiki/Punjabi_language>Punjabi</a>, <a href=https://en.wikipedia.org/wiki/Nepali_language>Nepali</a> and <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a>. The challenging task while developing the ASR was the collection of the acoustic corpus for under-resourced languages. We have described here, in brief, the strategies used for designing the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> and also highlighted the issues pertaining while collecting data for these <a href=https://en.wikipedia.org/wiki/Language>languages</a>. The bootstrap GMM-UBM based approach is used, which integrates pronunciation lexicon, <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> and <a href=https://en.wikipedia.org/wiki/Acoustic_phonetics>acoustic-phonetic model</a>. Mel Frequency Cepstral Coefficients were used for extracting the acoustic signal features for training in monolingual and cross-lingual settings. The experimental result shows the overall performance of ASR for cross-lingual and monolingual. The phone substitution plays a key role in the cross-lingual as well as monolingual recognition. The result obtained by cross-lingual recognition compared with other <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline system</a> and it has been found that the performance of the <a href=https://en.wikipedia.org/wiki/Speech_recognition>recognition system</a> is based on <a href=https://en.wikipedia.org/wiki/Phoneme>phonemic units</a>. The recognition rate of cross-lingual generally declines as compared with the monolingual.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.25.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--25 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.25 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.sltu-1.25" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.25/>A Sentiment Analysis Dataset for Code-Mixed Malayalam-English<span class=acl-fixed-case>M</span>alayalam-<span class=acl-fixed-case>E</span>nglish</a></strong><br><a href=/people/b/bharathi-raja-chakravarthi/>Bharathi Raja Chakravarthi</a>
|
<a href=/people/n/navya-jose/>Navya Jose</a>
|
<a href=/people/s/shardul-suryawanshi/>Shardul Suryawanshi</a>
|
<a href=/people/e/elizabeth-sherly/>Elizabeth Sherly</a>
|
<a href=/people/j/john-philip-mccrae/>John Philip McCrae</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--25><div class="card-body p-3 small">There is an increasing demand for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> of text from <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> which are mostly code-mixed. Systems trained on monolingual data fail for code-mixed data due to the complexity of mixing at different levels of the text. However, very few resources are available for code-mixed data to create <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> specific for this <a href=https://en.wikipedia.org/wiki/Data>data</a>. Although much research in multilingual and cross-lingual sentiment analysis has used <a href=https://en.wikipedia.org/wiki/Semi-supervised_learning>semi-supervised or unsupervised methods</a>, <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised methods</a> still performs better. Only a few datasets for popular languages such as English-Spanish, <a href=https://en.wikipedia.org/wiki/English_language_in_India>English-Hindi</a>, and <a href=https://en.wikipedia.org/wiki/Standard_Chinese>English-Chinese</a> are available. There are no resources available for Malayalam-English code-mixed data. This paper presents a new gold standard corpus for sentiment analysis of code-mixed text in <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam-English</a> annotated by voluntary annotators. This gold standard <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> obtained a <a href=https://en.wikipedia.org/wiki/Krippendorff&#8217;s_alpha>Krippendorff&#8217;s alpha</a> above 0.8 for the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. We use this new <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> to provide the benchmark for sentiment analysis in Malayalam-English code-mixed texts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.27.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--27 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.27 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.sltu-1.27" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.27/>Macsen : A Voice Assistant for Speakers of a Lesser Resourced Language<span class=acl-fixed-case>M</span>acsen: A Voice Assistant for Speakers of a Lesser Resourced Language</a></strong><br><a href=/people/d/dewi-jones/>Dewi Jones</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--27><div class="card-body p-3 small">This paper reports on the development of a voice assistant mobile app for speakers of a lesser resourced language Welsh. An assistant with a smaller set of effective but useful skills is both desirable and urgent for the wider Welsh speaking community. Descriptions of the <a href=https://en.wikipedia.org/wiki/Mobile_app>app</a>&#8217;s skills, architecture, design decisions and <a href=https://en.wikipedia.org/wiki/User_interface>user interface</a> is provided before elaborating on the most recent research and activities in open source speech technology for <a href=https://en.wikipedia.org/wiki/Welsh_language>Welsh</a>. The paper reports on the progress to date on crowdsourcing Welsh speech data in Mozilla Common Voice and of its suitability for training Mozilla&#8217;s DeepSpeech speech recognition for a voice assistant application according to conventional and transfer learning methods. We demonstrate that with smaller datasets of speech data, <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> and a domain specific language model, acceptable <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech recognition</a> is achievable that facilitates, as confirmed by beta users, a practical and useful voice assistant for Welsh speakers. We hope that this work informs and serves as a model to researchers and developers in other lesser-resourced linguistic communities and helps bring into being voice assistant apps for their languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.29.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--29 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.29 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.29/>Gender Detection from <a href=https://en.wikipedia.org/wiki/Human_voice>Human Voice</a> Using Tensor Analysis</a></strong><br><a href=/people/p/prasanta-roy/>Prasanta Roy</a>
|
<a href=/people/p/parabattina-bhagath/>Parabattina Bhagath</a>
|
<a href=/people/p/pradip-das/>Pradip Das</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--29><div class="card-body p-3 small">Speech-based communication is one of the most preferred modes of communication for humans. The <a href=https://en.wikipedia.org/wiki/Human_voice>human voice</a> contains several important information and clues that help in interpreting the voice message. The gender of the speaker can be accurately guessed by a person based on the received voice of a speaker. The knowledge of the speaker&#8217;s gender can be a great aid to design accurate <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech recognition systems</a>. GMM based classifier is a popular choice used for gender detection. In this paper, we propose a Tensor-based approach for detecting the gender of a speaker and discuss its implementation details for low resourceful languages. Experiments were conducted using the TIMIT and SHRUTI dataset. An average gender detection accuracy of 91 % is recorded. Analysis of the results with the proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a> is presented in this paper.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.30.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--30 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.30 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.30/>Data-Driven Parametric Text Normalization : Rapidly Scaling Finite-State Transduction Verbalizers to New Languages</a></strong><br><a href=/people/s/sandy-ritchie/>Sandy Ritchie</a>
|
<a href=/people/e/eoin-mahon/>Eoin Mahon</a>
|
<a href=/people/k/kim-heiligenstein/>Kim Heiligenstein</a>
|
<a href=/people/n/nikos-bampounis/>Nikos Bampounis</a>
|
<a href=/people/d/daan-van-esch/>Daan van Esch</a>
|
<a href=/people/c/christian-schallhart/>Christian Schallhart</a>
|
<a href=/people/j/jonas-mortensen/>Jonas Mortensen</a>
|
<a href=/people/b/benoit-brard/>Benoit Brard</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--30><div class="card-body p-3 small">This paper presents a methodology for rapidly generating FST-based verbalizers for ASR and TTS systems by efficiently sourcing language-specific data. We describe a questionnaire which collects the necessary data to bootstrap the number grammar induction system and parameterize the verbalizer templates described in Ritchie et al. (2019), and a machine-readable data store which allows the data collected through the questionnaire to be supplemented by additional data from other sources. This system allows us to rapidly scale technologies such as <a href=https://en.wikipedia.org/wiki/Autonomous_system_(Internet)>ASR</a> and <a href=https://en.wikipedia.org/wiki/Text-based_user_interface>TTS</a> to more languages, including low-resource languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.32.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--32 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.32 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.32/>Adapting a Welsh Terminology Tool to Develop a Cornish Dictionary<span class=acl-fixed-case>W</span>elsh Terminology Tool to Develop a <span class=acl-fixed-case>C</span>ornish Dictionary</a></strong><br><a href=/people/d/delyth-prys/>Delyth Prys</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--32><div class="card-body p-3 small">Cornish and <a href=https://en.wikipedia.org/wiki/Welsh_language>Welsh</a> are closely related <a href=https://en.wikipedia.org/wiki/Celtic_languages>Celtic languages</a> and this paper provides a brief description of a recent project to publish an online bilingual English / Cornish dictionary, the Gerlyver Kernewek, based on similar work previously undertaken for <a href=https://en.wikipedia.org/wiki/Welsh_language>Welsh</a>. Both languages are endangered, Cornish critically so, but both can benefit from the use of <a href=https://en.wikipedia.org/wiki/Language_technology>language technology</a>. Welsh has previous experience of using language technologies for <a href=https://en.wikipedia.org/wiki/Language_revitalization>language revitalization</a>, and this is now being used to help the <a href=https://en.wikipedia.org/wiki/Cornish_language>Cornish language</a> create new tools and resources, including lexicographical ones, helping a dispersed team of language specialists and editors, many of them in a voluntary capacity, to work collaboratively online. Details are given of the Maes T dictionary writing and publication platform, originally developed for <a href=https://en.wikipedia.org/wiki/Welsh_language>Welsh</a>, and of some of the adaptations that had to be made to accommodate the specific needs of Cornish, including their use of Middle and Late varieties due to its development as a revived language.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.40.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--40 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.40 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.40/>On the Exploration of English to Urdu Machine Translation<span class=acl-fixed-case>E</span>nglish to <span class=acl-fixed-case>U</span>rdu Machine Translation</a></strong><br><a href=/people/s/sadaf-abdul-rauf/>Sadaf Abdul Rauf</a>
|
<a href=/people/s/syeda-abida/>Syeda Abida</a>
|
<a href=/people/n/noor-e-hira/>Noor-e- Hira</a>
|
<a href=/people/s/syeda-zahra/>Syeda Zahra</a>
|
<a href=/people/d/dania-parvez/>Dania Parvez</a>
|
<a href=/people/j/javeria-bashir/>Javeria Bashir</a>
|
<a href=/people/q/qurat-ul-ain-majid/>Qurat-ul-ain Majid</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--40><div class="card-body p-3 small">Machine Translation is the inevitable technology to reduce communication barriers in today&#8217;s world. It has made substantial progress in recent years and is being widely used in commercial as well as non-profit sectors. Such is only the case for European and other high resource languages. For English-Urdu language pair, the <a href=https://en.wikipedia.org/wiki/Technology>technology</a> is in its infancy stage due to scarcity of resources. Present research is an important milestone in English-Urdu machine translation, as we present results for four major domains including Biomedical, Religious, Technological and General using Statistical and Neural Machine Translation. We performed series of experiments in attempts to optimize the performance of each <a href=https://en.wikipedia.org/wiki/System>system</a> and also to study the impact of data sources on the <a href=https://en.wikipedia.org/wiki/System>systems</a>. Finally, we established a comparison of the data sources and the effect of language model size on <a href=https://en.wikipedia.org/wiki/Statistical_machine_translation>statistical machine translation</a> performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.42.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--42 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.42 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.42/>Adapting Language Specific Components of Cross-Media Analysis Frameworks to Less-Resourced Languages : the Case of Amharic<span class=acl-fixed-case>A</span>mharic</a></strong><br><a href=/people/y/yonas-woldemariam/>Yonas Woldemariam</a>
|
<a href=/people/a/adam-dahlgren/>Adam Dahlgren</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--42><div class="card-body p-3 small">We present an ASR based pipeline for <a href=https://en.wikipedia.org/wiki/Amharic>Amharic</a> that orchestrates NLP components within a cross media analysis framework (CMAF). One of the major challenges that are inherently associated with CMAFs is effectively addressing multi-lingual issues. As a result, many languages remain under-resourced and fail to leverage out of available media analysis solutions. Although spoken natively by over 22 million people and there is an ever-increasing amount of Amharic multimedia content on the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>Web</a>, querying them with simple text search is difficult. Searching for, especially audio / video content with simple key words, is even hard as they exist in their raw form. In this study, we introduce a spoken and textual content processing workflow into a CMAF for <a href=https://en.wikipedia.org/wiki/Amharic>Amharic</a>. We design an ASR-named entity recognition (NER) pipeline that includes three main components : ASR, a transliterator and NER. We explore various acoustic modeling techniques and develop an OpenNLP-based NER extractor along with a transliterator that interfaces between ASR and <a href=https://en.wikipedia.org/wiki/Near-infrared_spectroscopy>NER</a>. The designed ASR-NER pipeline for <a href=https://en.wikipedia.org/wiki/Amharic>Amharic</a> promotes the multi-lingual support of CMAFs. Also, the state-of-the art design principles and techniques employed in this study shed light for other less-resourced languages, particularly the <a href=https://en.wikipedia.org/wiki/Semitic_languages>Semitic ones</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.45.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--45 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.45 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.45/>Owksape-An Online Language Learning Platform for Lakota<span class=acl-fixed-case>L</span>akota</a></strong><br><a href=/people/j/jan-ullrich/>Jan Ullrich</a>
|
<a href=/people/e/elliot-thornton/>Elliot Thornton</a>
|
<a href=/people/p/peter-vieira/>Peter Vieira</a>
|
<a href=/people/l/logan-swango/>Logan Swango</a>
|
<a href=/people/m/marek-kupiec/>Marek Kupiec</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--45><div class="card-body p-3 small">This paper presents Owksape, an online language learning platform for the under-resourced language Lakota. The Lakota language (Laktiyapi) is a Siouan language native to the United States with fewer than 2000 fluent speakers. Owksape was developed by The Language Conservancy to support revitalization efforts, including reaching younger generations and providing a tool to complement traditional teaching methods. This project grew out of various multimedia resources in order to combine their most effective aspects into a single, self-paced learning tool. The first section of this paper discusses the motivation for and background of Owksape. Section two details the <a href=https://en.wikipedia.org/wiki/Linguistic_description>linguistic features</a> and language documentation principles that form the backbone of the <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a>. Section three lays out the unique integration of cultural aspects of the Lakota people into the <a href=https://en.wikipedia.org/wiki/Graphic_design>visual design</a> of the <a href=https://en.wikipedia.org/wiki/Application_software>application</a>. Section four explains the pedagogical principles of Owksape. Application features and exercise types are then discussed in detail with visual examples, followed by an overview of the <a href=https://en.wikipedia.org/wiki/Software_design>software design</a>, as well as the effort required to develop the <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a>. Finally, a description of future features and considerations is presented.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.51.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--51 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.51 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.51/>Speech Transcription Challenges for Resource Constrained Indigenous Language Cree<span class=acl-fixed-case>C</span>ree</a></strong><br><a href=/people/v/vishwa-gupta/>Vishwa Gupta</a>
|
<a href=/people/g/gilles-boulianne/>Gilles Boulianne</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--51><div class="card-body p-3 small">Cree is one of the most spoken Indigenous languages in Canada. From a speech recognition perspective, it is a low-resource language, since very little data is available for either acoustic or language modeling. This has prevented development of <a href=https://en.wikipedia.org/wiki/Speech_technology>speech technology</a> that could help revitalize the <a href=https://en.wikipedia.org/wiki/Language>language</a>. We describe our experiments with available Cree data to improve <a href=https://en.wikipedia.org/wiki/Transcription_(biology)>automatic transcription</a> both in speaker- independent and dependent scenarios. While it was difficult to get low speaker-independent word error rates with only six speakers, we were able to get low word and phoneme error rates in the speaker-dependent scenario. We compare our phoneme recognition with two state-of-the-art open-source phoneme recognition toolkits, which use end-to-end training and sequence-to-sequence modeling. Our phoneme error rate (8.7 %) is significantly lower than that achieved by the best of these systems (15.1 %). With these systems and varying amounts of transcribed and text data, we show that pre-training on other languages is important for speaker-independent recognition, and even small amounts of additional text-only documents are useful. These results can guide practical language documentation work, when deciding how much transcribed and text data is needed to achieve useful phoneme accuracies.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>