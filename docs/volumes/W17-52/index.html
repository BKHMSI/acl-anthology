<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/W17-52.pdf>Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</a></h2><p class=lead><a href=/people/a/alexandra-balahur/>Alexandra Balahur</a>,
<a href=/people/s/saif-mohammad/>Saif M. Mohammad</a>,
<a href=/people/e/erik-van-der-goot/>Erik van der Goot</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>W17-52</dd><dt>Month:</dt><dd>September</dd><dt>Year:</dt><dd>2017</dd><dt>Address:</dt><dd>Copenhagen, Denmark</dd><dt>Venues:</dt><dd><a href=/venues/wassa/>WASSA</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/W17-52>https://aclanthology.org/W17-52</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/W17-52 title="To the current version of the paper by DOI">10.18653/v1/W17-52</a></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/W17-52.pdf>https://aclanthology.org/W17-52.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/W17-52.pdf title="Open PDF of 'Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+8th+Workshop+on+Computational+Approaches+to+Subjectivity%2C+Sentiment+and+Social+Media+Analysis" title="Search for 'Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5200.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5200/>Proceedings of the 8th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</a></strong><br><a href=/people/a/alexandra-balahur/>Alexandra Balahur</a>
|
<a href=/people/s/saif-mohammad/>Saif M. Mohammad</a>
|
<a href=/people/e/erik-van-der-goot/>Erik van der Goot</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5201.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5201 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5201 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5201/>Detecting Sarcasm Using Different Forms Of Incongruity</a></strong><br><a href=/people/a/aditya-joshi/>Aditya Joshi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5201><div class="card-body p-3 small">Sarcasm is a form of <a href=https://en.wikipedia.org/wiki/Irony>verbal irony</a> that is intended to express contempt or ridicule. Often quoted as a challenge to <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>, <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> involves use of words of positive or no polarity to convey negative sentiment. Incongruity has been observed to be at the heart of sarcasm understanding in humans. Our work in sarcasm detection identifies different forms of incongruity and employs different machine learning techniques to capture them. This talk will describe the approach, datasets and challenges in sarcasm detection using different forms of incongruity. We identify two forms of <a href=https://en.wikipedia.org/wiki/Incongruity>incongruity</a> : <a href=https://en.wikipedia.org/wiki/Incongruity>incongruity</a> which can be understood based on the target text and common background knowledge, and <a href=https://en.wikipedia.org/wiki/Incongruity>incongruity</a> which can be understood based on the target text and additional, specific context. The former involves use of <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment-based features</a>, <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a>, and <a href=https://en.wikipedia.org/wiki/Topic_model>topic models</a>. The latter involves creation of author&#8217;s historical context based on their historical data, and creation of conversational context for sarcasm detection of dialogue.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5203.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5203 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5203 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W17-5203.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/W17-5203/>Annotation, Modelling and Analysis of Fine-Grained Emotions on a Stance and Sentiment Detection Corpus</a></strong><br><a href=/people/h/hendrik-schuff/>Hendrik Schuff</a>
|
<a href=/people/j/jeremy-barnes/>Jeremy Barnes</a>
|
<a href=/people/j/julian-mohme/>Julian Mohme</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Pad√≥</a>
|
<a href=/people/r/roman-klinger/>Roman Klinger</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5203><div class="card-body p-3 small">There is a rich variety of data sets for sentiment analysis (viz., polarity and subjectivity classification). For the more challenging task of detecting discrete emotions following the definitions of Ekman and Plutchik, however, there are much fewer data sets, and notably no resources for the social media domain. This paper contributes to closing this gap by extending the SemEval 2016 stance and sentiment datasetwith emotion annotation. We (a) analyse annotation reliability and annotation merging ; (b) investigate the relation between emotion annotation and the other annotation layers (stance, sentiment) ; (c) report modelling results as a baseline for future work.<i>SemEval 2016 stance and sentiment dataset</i>\n\nwith emotion annotation. We (a) analyse annotation reliability and annotation merging; (b) investigate the relation between emotion annotation and the other annotation layers (stance, sentiment); (c) report modelling results as a baseline for future work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5204.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5204 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5204 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5204/>Ranking Right-Wing Extremist Social Media Profiles by Similarity to Democratic and Extremist Groups</a></strong><br><a href=/people/m/matthias-hartung/>Matthias Hartung</a>
|
<a href=/people/r/roman-klinger/>Roman Klinger</a>
|
<a href=/people/f/franziska-schmidtke/>Franziska Schmidtke</a>
|
<a href=/people/l/lars-vogel/>Lars Vogel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5204><div class="card-body p-3 small">Social media are used by an increasing number of political actors. A small subset of these is interested in pursuing extremist motives such as <a href=https://en.wikipedia.org/wiki/Mobilization>mobilization</a>, recruiting or radicalization activities. In order to counteract these trends, online providers and state institutions reinforce their monitoring efforts, mostly relying on manual workflows. We propose a machine learning approach to support manual attempts towards identifying right-wing extremist content in <a href=https://en.wikipedia.org/wiki/Twitter>German Twitter profiles</a>. Based on a fine-grained conceptualization of <a href=https://en.wikipedia.org/wiki/Far-right_politics>right-wing extremism</a>, we frame the task as ranking each individual profile on a continuum spanning different degrees of <a href=https://en.wikipedia.org/wiki/Far-right_politics>right-wing extremism</a>, based on a <a href=https://en.wikipedia.org/wiki/Nearest_neighbour_search>nearest neighbour approach</a>. A quantitative evaluation reveals that our <a href=https://en.wikipedia.org/wiki/Ranking_(statistics)>ranking model</a> yields robust performance (up to 0.81 F_1 score) when being used for predicting discrete class labels. At the same time, the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> provides plausible continuous ranking scores for a small sample of borderline cases at the division of right-wing extremism and New Right political movements.<tex-math>_1</tex-math> score) when being used for predicting discrete class labels. At the same time, the model provides plausible continuous ranking scores for a small sample of borderline cases at the division of right-wing extremism and New Right political movements.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5205.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5205 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5205 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5205/>WASSA-2017 Shared Task on Emotion Intensity<span class=acl-fixed-case>WASSA</span>-2017 Shared Task on Emotion Intensity</a></strong><br><a href=/people/s/saif-mohammad/>Saif Mohammad</a>
|
<a href=/people/f/felipe-bravo-marquez/>Felipe Bravo-Marquez</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5205><div class="card-body p-3 small">We present the first shared task on detecting the intensity of emotion felt by the speaker of a tweet. We create the first datasets of <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a> annotated for <a href=https://en.wikipedia.org/wiki/Anger>anger</a>, <a href=https://en.wikipedia.org/wiki/Fear>fear</a>, <a href=https://en.wikipedia.org/wiki/Joy>joy</a>, and sadness intensities using a technique called bestworst scaling (BWS). We show that the annotations lead to reliable fine-grained intensity scores (rankings of tweets by intensity). The <a href=https://en.wikipedia.org/wiki/Data>data</a> was partitioned into training, development, and test sets for the competition. Twenty-two teams participated in the shared task, with the best system obtaining a Pearson correlation of 0.747 with the gold intensity scores. We summarize the machine learning setups, resources, and tools used by the participating teams, with a focus on the techniques and resources that are particularly useful for the task. The emotion intensity dataset and the shared task are helping improve our understanding of how we convey more or less intense emotions through language.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5206.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5206 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5206 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5206/>IMS at EmoInt-2017 : Emotion Intensity Prediction with Affective Norms, Automatically Extended Resources and <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Learning</a><span class=acl-fixed-case>IMS</span> at <span class=acl-fixed-case>E</span>mo<span class=acl-fixed-case>I</span>nt-2017: Emotion Intensity Prediction with Affective Norms, Automatically Extended Resources and Deep Learning</a></strong><br><a href=/people/m/maximilian-koper/>Maximilian K√∂per</a>
|
<a href=/people/e/evgeny-kim/>Evgeny Kim</a>
|
<a href=/people/r/roman-klinger/>Roman Klinger</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5206><div class="card-body p-3 small">Our submission to the WASSA-2017 shared task on the prediction of emotion intensity in tweets is a supervised learning method with extended lexicons of affective norms. We combine three main information sources in a random forrest regressor, namely (1), manually created resources, (2) automatically extended lexicons, and (3) the output of a neural network (CNN-LSTM) for sentence regression. All three <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature sets</a> perform similarly well in isolation (.67 macro average Pearson correlation). The <a href=https://en.wikipedia.org/wiki/Combination>combination</a> achieves.72 on the official test set (ranked 2nd out of 22 participants). Our analysis reveals that performance is increased by providing cross-emotional intensity predictions. The automatic extension of lexicon features benefit from domain specific embeddings. Complementary ratings for affective norms increase the impact of <a href=https://en.wikipedia.org/wiki/Lexicon>lexicon features</a>. Our resources (ratings for 1.6 million twitter specific words) and our <a href=https://en.wikipedia.org/wiki/Implementation>implementation</a> is publicly available at.<url>http://www.ims.uni-stuttgart.de/data/ims_emoint</url>.\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5207.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5207 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5207 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5207/>Prayas at EmoInt 2017 : An Ensemble of Deep Neural Architectures for Emotion Intensity Prediction in Tweets<span class=acl-fixed-case>E</span>mo<span class=acl-fixed-case>I</span>nt 2017: An Ensemble of Deep Neural Architectures for Emotion Intensity Prediction in Tweets</a></strong><br><a href=/people/p/pranav-goel/>Pranav Goel</a>
|
<a href=/people/d/devang-kulshreshtha/>Devang Kulshreshtha</a>
|
<a href=/people/p/prayas-jain/>Prayas Jain</a>
|
<a href=/people/k/kaushal-kumar-shukla/>Kaushal Kumar Shukla</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5207><div class="card-body p-3 small">The paper describes the best performing system for EmoInt-a shared task to predict the intensity of emotions in tweets. Intensity is a real valued score, between 0 and 1. The <a href=https://en.wikipedia.org/wiki/Emotion>emotions</a> are classified as-anger, <a href=https://en.wikipedia.org/wiki/Fear>fear</a>, <a href=https://en.wikipedia.org/wiki/Joy>joy</a> and sadness. We apply three different deep neural network based models, which approach the problem from essentially different directions. Our final performance quantified by an average pearson correlation score of 74.7 and an average spearman correlation score of 73.5 is obtained using an <a href=https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)>ensemble</a> of the three <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. We outperform the <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baseline model</a> of the shared task by 9.9 % and 9.4 % pearson and spearman correlation scores respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5209.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5209 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5209 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-5209" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-5209/>Towards Syntactic Iberian Polarity Classification<span class=acl-fixed-case>I</span>berian Polarity Classification</a></strong><br><a href=/people/d/david-vilares/>David Vilares</a>
|
<a href=/people/m/marcos-garcia/>Marcos Garcia</a>
|
<a href=/people/m/miguel-a-alonso/>Miguel A. Alonso</a>
|
<a href=/people/c/carlos-gomez-rodriguez/>Carlos G√≥mez-Rodr√≠guez</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5209><div class="card-body p-3 small">Lexicon-based methods using syntactic rules for polarity classification rely on <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a> that are dependent on the language and on <a href=https://en.wikipedia.org/wiki/Treebank>treebank guidelines</a>. Thus, <a href=https://en.wikipedia.org/wiki/Rule_of_inference>rules</a> are also dependent and require adaptation, especially in multilingual scenarios. We tackle this challenge in the context of the <a href=https://en.wikipedia.org/wiki/Iberian_Peninsula>Iberian Peninsula</a>, releasing the first symbolic syntax-based Iberian system with rules shared across five official languages : <a href=https://en.wikipedia.org/wiki/Basque_language>Basque</a>, <a href=https://en.wikipedia.org/wiki/Catalan_language>Catalan</a>, <a href=https://en.wikipedia.org/wiki/Galician_language>Galician</a>, <a href=https://en.wikipedia.org/wiki/Portuguese_language>Portuguese</a> and <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>. The model is made available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5212.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5212 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5212 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5212/>Forecasting Consumer Spending from Purchase Intentions Expressed on <a href=https://en.wikipedia.org/wiki/Social_media>Social Media</a></a></strong><br><a href=/people/v/viktor-pekar/>Viktor Pekar</a>
|
<a href=/people/j/jane-binner/>Jane Binner</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5212><div class="card-body p-3 small">Consumer spending is an important macroeconomic indicator that is used by policy-makers to judge the health of an economy. In this paper we present a novel method for predicting future consumer spending from <a href=https://en.wikipedia.org/wiki/Social_media>social media data</a>. In contrast to previous work that largely relied on <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>, the proposed method models <a href=https://en.wikipedia.org/wiki/Consumer_spending>consumer spending</a> from purchase intentions found on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. Our experiments with time series analysis models and machine-learning regression models reveal utility of this data for making short-term forecasts of consumer spending : for three- and seven-day horizons, prediction variables derived from social media help to improve forecast accuracy by 11 % to 18 % for all the three models, in comparison to models that used only autoregressive predictors.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5213.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5213 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5213 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-5213" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-5213/>Mining fine-grained opinions on closed captions of YouTube videos with an attention-RNN<span class=acl-fixed-case>Y</span>ou<span class=acl-fixed-case>T</span>ube videos with an attention-<span class=acl-fixed-case>RNN</span></a></strong><br><a href=/people/e/edison-marrese-taylor/>Edison Marrese-Taylor</a>
|
<a href=/people/j/jorge-balazs/>Jorge Balazs</a>
|
<a href=/people/y/yutaka-matsuo/>Yutaka Matsuo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5213><div class="card-body p-3 small">Video reviews are the natural evolution of written product reviews. In this paper we target this phenomenon and introduce the first dataset created from closed captions of YouTube product review videos as well as a new attention-RNN model for <a href=https://en.wikipedia.org/wiki/Aspect_extraction>aspect extraction</a> and joint aspect extraction and sentiment classification. Our model provides state-of-the-art performance on <a href=https://en.wikipedia.org/wiki/Aspect_extraction>aspect extraction</a> without requiring the usage of hand-crafted features on the SemEval ABSA corpus, while it outperforms the baseline on the joint task. In our dataset, the attention-RNN model outperforms the baseline for both tasks, but we observe important performance drops for all models in comparison to <a href=https://en.wikipedia.org/wiki/SemEval>SemEval</a>. These results, as well as further experiments on <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> for <a href=https://en.wikipedia.org/wiki/Aspect_extraction>aspect extraction</a>, suggest that differences between speech and written text, which have been discussed extensively in the literature, also extend to the domain of product reviews, where they are relevant for fine-grained opinion mining.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5216.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5216 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5216 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5216/>Investigating Redundancy in Emoji Use : Study on a Twitter Based Corpus<span class=acl-fixed-case>T</span>witter Based Corpus</a></strong><br><a href=/people/g/giulia-donato/>Giulia Donato</a>
|
<a href=/people/p/patrizia-paggio/>Patrizia Paggio</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5216><div class="card-body p-3 small">In this paper we present an annotated corpus created with the aim of analyzing the informative behaviour of <a href=https://en.wikipedia.org/wiki/Emoji>emoji</a> an issue of importance for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> and <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. The corpus consists of 2475 tweets all containing at least one <a href=https://en.wikipedia.org/wiki/Emoji>emoji</a>, which has been annotated using one of the three possible classes : <a href=https://en.wikipedia.org/wiki/Redundancy_(information_theory)>Redundant</a>, Non Redundant, and Non Redundant + POS. We explain how the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> was collected, describe the annotation procedure and the <a href=https://en.wikipedia.org/wiki/Interface_(computing)>interface</a> developed for the task. We provide an analysis of the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>, considering also possible predictive features, discuss the problematic aspects of the <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a>, and suggest future improvements.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5217.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5217 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5217 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5217/>Modeling Temporal Progression of Emotional Status in Mental Health Forum : A Recurrent Neural Net Approach</a></strong><br><a href=/people/k/kishaloy-halder/>Kishaloy Halder</a>
|
<a href=/people/l/lahari-poddar/>Lahari Poddar</a>
|
<a href=/people/m/min-yen-kan/>Min-Yen Kan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5217><div class="card-body p-3 small">Patients turn to <a href=https://en.wikipedia.org/wiki/Online_health_communities>Online Health Communities</a> not only for information on specific conditions but also for <a href=https://en.wikipedia.org/wiki/Emotional_support>emotional support</a>. Previous research has indicated that the progression of emotional status can be studied through the linguistic patterns of an individual&#8217;s posts. We analyze a real-world dataset from the Mental Health section of HealthBoards.com. Estimated from the word usages in their posts, we find that the emotional progress across patients vary widely. We study the problem of predicting a patient&#8217;s emotional status in the future from her past posts and we propose a Recurrent Neural Network (RNN) based architecture to address it. We find that the future emotional status can be predicted with reasonable accuracy given her historical posts and participation features. Our evaluation results demonstrate the efficacy of our proposed <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a>, by outperforming <a href=https://en.wikipedia.org/wiki/Software_architecture>state-of-the-art approaches</a> with over 0.13 reduction in <a href=https://en.wikipedia.org/wiki/Mean_absolute_error>Mean Absolute Error</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5218.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5218 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5218 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5218/>Towards an integrated pipeline for aspect-based sentiment analysis in various domains</a></strong><br><a href=/people/o/orphee-de-clercq/>Orph√©e De Clercq</a>
|
<a href=/people/e/els-lefever/>Els Lefever</a>
|
<a href=/people/g/gilles-jacobs/>Gilles Jacobs</a>
|
<a href=/people/t/tijl-carpels/>Tijl Carpels</a>
|
<a href=/people/v/veronique-hoste/>V√©ronique Hoste</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5218><div class="card-body p-3 small">This paper presents an integrated ABSA pipeline for <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch</a> that has been developed and tested on qualitative user feedback coming from three domains : <a href=https://en.wikipedia.org/wiki/Retail>retail</a>, <a href=https://en.wikipedia.org/wiki/Bank>banking</a> and <a href=https://en.wikipedia.org/wiki/Human_resources>human resources</a>. The two latter <a href=https://en.wikipedia.org/wiki/Domain_(software_engineering)>domains</a> provide <a href=https://en.wikipedia.org/wiki/Service-oriented_architecture>service-oriented data</a>, which has not been investigated before in ABSA. By performing in-domain and cross-domain experiments the validity of our approach was investigated. We show promising results for the three ABSA subtasks, aspect term extraction, aspect category classification and aspect polarity classification.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5219.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5219 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5219 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5219/>Building a SentiWordNet for Odia<span class=acl-fixed-case>S</span>enti<span class=acl-fixed-case>W</span>ord<span class=acl-fixed-case>N</span>et for <span class=acl-fixed-case>O</span>dia</a></strong><br><a href=/people/g/gaurav-mohanty/>Gaurav Mohanty</a>
|
<a href=/people/a/abishek-kannan/>Abishek Kannan</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5219><div class="card-body p-3 small">As a discipline of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a>, <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a> is used to extract and analyze <a href=https://en.wikipedia.org/wiki/Subjectivity>subjective information</a> present in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language data</a>. The task of <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a> has acquired wide commercial uses including social media monitoring tasks, survey responses, review systems, etc. Languages like <a href=https://en.wikipedia.org/wiki/English_language>English</a> have several resources which aid in the task of <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a>. SentiWordNet and Subjectivity WordList are examples of such tools and resources. With more data being available in native vernacular, language-specific SentiWordNet(s) have become essential. For resource poor languages, creating such SentiWordNet(s) is a difficult task to achieve. One solution is to use available resources in <a href=https://en.wikipedia.org/wiki/English_language>English</a> and translate the final source lexicon to target lexicon via <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. Machine translation systems for the English-Odia language pair have not yet been developed. In this paper, we discuss a method to create a SentiWordNet for <a href=https://en.wikipedia.org/wiki/Odia_language>Odia</a>, which is resource-poor, by only using resources which are currently available for <a href=https://en.wikipedia.org/wiki/Languages_of_India>Indian languages</a>. The lexicon created, would serve as a tool for Sentiment Analysis related task specific to Odia data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5220.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5220 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5220 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5220/>Lexicon Integrated CNN Models with Attention for Sentiment Analysis<span class=acl-fixed-case>CNN</span> Models with Attention for Sentiment Analysis</a></strong><br><a href=/people/b/bonggun-shin/>Bonggun Shin</a>
|
<a href=/people/t/timothy-lee/>Timothy Lee</a>
|
<a href=/people/j/jinho-d-choi/>Jinho D. Choi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5220><div class="card-body p-3 small">With the advent of <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a>, <a href=https://en.wikipedia.org/wiki/Lexicon>lexicons</a> are no longer fully utilized for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> although they still provide important features in the traditional setting. This paper introduces a novel approach to <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> that integrates lexicon embeddings and an <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanism</a> into <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>Convolutional Neural Networks</a>. Our approach performs separate convolutions for word and lexicon embeddings and provides a global view of the document using <a href=https://en.wikipedia.org/wiki/Attention>attention</a>. Our models are experimented on both the SemEval&#8217;16 Task 4 dataset and the Stanford Sentiment Treebank and show comparative or better results against the existing state-of-the-art systems. Our analysis shows that lexicon embeddings allow building high-performing models with much smaller word embeddings, and the attention mechanism effectively dims out noisy words for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5221.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5221 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5221 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-5221" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-5221/>Explaining Recurrent Neural Network Predictions in Sentiment Analysis</a></strong><br><a href=/people/l/leila-arras/>Leila Arras</a>
|
<a href=/people/g/gregoire-montavon/>Gr√©goire Montavon</a>
|
<a href=/people/k/klaus-robert-muller/>Klaus-Robert M√ºller</a>
|
<a href=/people/w/wojciech-samek/>Wojciech Samek</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5221><div class="card-body p-3 small">Recently, a technique called Layer-wise Relevance Propagation (LRP) was shown to deliver insightful explanations in the form of input space relevances for understanding feed-forward neural network classification decisions. In the present work, we extend the usage of LRP to <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural networks</a>. We propose a specific propagation rule applicable to multiplicative connections as they arise in recurrent network architectures such as LSTMs and GRUs. We apply our technique to a word-based bi-directional LSTM model on a five-class sentiment prediction task, and evaluate the resulting LRP relevances both qualitatively and quantitatively, obtaining better results than a gradient-based related method which was used in previous work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5222.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5222 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5222 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5222/>GradAscent at EmoInt-2017 : Character and Word Level Recurrent Neural Network Models for Tweet Emotion Intensity Detection<span class=acl-fixed-case>G</span>rad<span class=acl-fixed-case>A</span>scent at <span class=acl-fixed-case>E</span>mo<span class=acl-fixed-case>I</span>nt-2017: Character and Word Level Recurrent Neural Network Models for Tweet Emotion Intensity Detection</a></strong><br><a href=/people/e/egor-lakomkin/>Egor Lakomkin</a>
|
<a href=/people/c/chandrakant-bothe/>Chandrakant Bothe</a>
|
<a href=/people/s/stefan-wermter/>Stefan Wermter</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5222><div class="card-body p-3 small">The WASSA 2017 EmoInt shared task has the goal to predict emotion intensity values of <a href=https://en.wikipedia.org/wiki/Twitter>tweet messages</a>. Given the text of a tweet and its emotion category (anger, joy, fear, and sadness), the participants were asked to build a system that assigns emotion intensity values. Emotion intensity estimation is a challenging problem given the short length of the tweets, the noisy structure of the text and the lack of annotated data. To solve this problem, we developed an ensemble of two neural models, processing input on the character. and word-level with a lexicon-driven system. The correlation scores across all four emotions are averaged to determine the bottom-line competition metric, and our system ranks place forth in full intensity range and third in 0.5-1 range of intensity among 23 systems at the time of writing (June 2017).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5223.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5223 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5223 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5223/>NUIG at EmoInt-2017 : BiLSTM and SVR Ensemble to Detect Emotion Intensity<span class=acl-fixed-case>NUIG</span> at <span class=acl-fixed-case>E</span>mo<span class=acl-fixed-case>I</span>nt-2017: <span class=acl-fixed-case>B</span>i<span class=acl-fixed-case>LSTM</span> and <span class=acl-fixed-case>SVR</span> Ensemble to Detect Emotion Intensity</a></strong><br><a href=/people/v/vladimir-andryushechkin/>Vladimir Andryushechkin</a>
|
<a href=/people/i/ian-wood/>Ian Wood</a>
|
<a href=/people/j/james-o-neill/>James O‚Äô Neill</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5223><div class="card-body p-3 small">This paper describes the entry NUIG in the WASSA 2017 (8th Workshop on Computational Approaches to Subjectivity, Sentiment & Social Media Analysis) shared task on <a href=https://en.wikipedia.org/wiki/Emotion_recognition>emotion recognition</a>. The NUIG system used an SVR (SVM regression) and BLSTM ensemble, utilizing primarily n-grams (for SVR features) and tweet word embeddings (for BLSTM features). Experiments were carried out on several other candidate features, some of which were added to the SVR model. Parameter selection for the SVR model was run as a <a href=https://en.wikipedia.org/wiki/Grid_search>grid search</a> whilst parameters for the BLSTM model were selected through a non-exhaustive ad-hoc search.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5224.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5224 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5224 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5224/>Unsupervised Aspect Term Extraction with B-LSTM & CRF using Automatically Labelled Datasets<span class=acl-fixed-case>B</span>-<span class=acl-fixed-case>LSTM</span> & <span class=acl-fixed-case>CRF</span> using Automatically Labelled Datasets</a></strong><br><a href=/people/a/athanasios-giannakopoulos/>Athanasios Giannakopoulos</a>
|
<a href=/people/c/claudiu-musat/>Claudiu Musat</a>
|
<a href=/people/a/andreea-hossmann/>Andreea Hossmann</a>
|
<a href=/people/m/michael-baeriswyl/>Michael Baeriswyl</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5224><div class="card-body p-3 small">Aspect Term Extraction (ATE) identifies opinionated aspect terms in texts and is one of the tasks in the SemEval Aspect Based Sentiment Analysis (ABSA) contest. The small amount of available datasets for supervised ATE and the costly human annotation for aspect term labelling give rise to the need for unsupervised ATE. In this paper, we introduce an <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> that achieves top-ranking performance for supervised ATE. Moreover, it can be used efficiently as feature extractor and <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> for <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised ATE</a>. Our second contribution is a method to automatically construct <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> for ATE. We train a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> on our automatically labelled datasets and evaluate it on the human annotated SemEval ABSA test sets. Compared to a strong rule-based baseline, we obtain a dramatically higher <a href=https://en.wikipedia.org/wiki/F-score>F-score</a> and attain <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a> values above 80 %. Our <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised method</a> beats the supervised ABSA baseline from <a href=https://en.wikipedia.org/wiki/SemEval>SemEval</a>, while preserving high precision scores.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5227.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5227 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5227 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5227/>YNU-HPCC at EmoInt-2017 : Using a CNN-LSTM Model for Sentiment Intensity Prediction<span class=acl-fixed-case>YNU</span>-<span class=acl-fixed-case>HPCC</span> at <span class=acl-fixed-case>E</span>mo<span class=acl-fixed-case>I</span>nt-2017: Using a <span class=acl-fixed-case>CNN</span>-<span class=acl-fixed-case>LSTM</span> Model for Sentiment Intensity Prediction</a></strong><br><a href=/people/y/you-zhang/>You Zhang</a>
|
<a href=/people/h/hang-yuan/>Hang Yuan</a>
|
<a href=/people/j/jin-wang/>Jin Wang</a>
|
<a href=/people/x/xuejie-zhang/>Xuejie Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5227><div class="card-body p-3 small">In this paper, we present a system that uses a convolutional neural network with long short-term memory (CNN-LSTM) model to complete the task. The CNN-LSTM model has two combined parts : CNN extracts local n-gram features within tweets and LSTM composes the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> to capture long-distance dependency across tweets. Additionally, we used other three models (CNN, LSTM, BiLSTM) as baseline algorithms. Our introduced <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> showed good performance in the experimental results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5228.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5228 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5228 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/W17-5228.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-5228" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-5228/>Seernet at EmoInt-2017 : Tweet Emotion Intensity Estimator<span class=acl-fixed-case>E</span>mo<span class=acl-fixed-case>I</span>nt-2017: Tweet Emotion Intensity Estimator</a></strong><br><a href=/people/v/venkatesh-duppada/>Venkatesh Duppada</a>
|
<a href=/people/s/sushant-hiray/>Sushant Hiray</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5228><div class="card-body p-3 small">The paper describes experiments on estimating emotion intensity in <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a> using a generalized regressor system. The system combines various independent feature extractors, trains them on general regressors and finally combines the best performing models to create an <a href=https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)>ensemble</a>. The proposed <a href=https://en.wikipedia.org/wiki/System>system</a> stood 3rd out of 22 systems in leaderboard of WASSA-2017 Shared Task on Emotion Intensity.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5230.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5230 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5230 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5230/>NSEmo at EmoInt-2017 : An Ensemble to Predict Emotion Intensity in Tweets<span class=acl-fixed-case>NSE</span>mo at <span class=acl-fixed-case>E</span>mo<span class=acl-fixed-case>I</span>nt-2017: An Ensemble to Predict Emotion Intensity in Tweets</a></strong><br><a href=/people/s/sreekanth-madisetty/>Sreekanth Madisetty</a>
|
<a href=/people/m/maunendra-sankar-desarkar/>Maunendra Sankar Desarkar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5230><div class="card-body p-3 small">In this paper, we describe a <a href=https://en.wikipedia.org/wiki/Methodology>method</a> to predict emotion intensity in <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a>. Our approach is an ensemble of three <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression methods</a>. The first method uses content-based features (hashtags, <a href=https://en.wikipedia.org/wiki/Emoticon>emoticons</a>, elongated words, etc.). The second method considers <a href=https://en.wikipedia.org/wiki/N-gram>word n-grams</a> and character n-grams for training. The final method uses <a href=https://en.wikipedia.org/wiki/Lexicon>lexicons</a>, <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a>, <a href=https://en.wikipedia.org/wiki/N-gram>word n-grams</a>, character n-grams for training the model. An <a href=https://en.wikipedia.org/wiki/Ensemble_cast>ensemble</a> of these three <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> gives better performance than individual methods. We applied our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> on WASSA emotion dataset. Achieved results are as follows : <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>average Pearson correlation</a> is 0.706, <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>average Spearman correlation</a> is 0.696, <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>average Pearson correlation</a> for gold scores in range 0.5 to 1 is 0.539, and <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>average Spearman correlation</a> for gold scores in range 0.5 to 1 is 0.514.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5231.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5231 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5231 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5231/>Tecnolengua Lingmotif at EmoInt-2017 : A lexicon-based approach<span class=acl-fixed-case>T</span>ecnolengua <span class=acl-fixed-case>L</span>ingmotif at <span class=acl-fixed-case>E</span>mo<span class=acl-fixed-case>I</span>nt-2017: A lexicon-based approach</a></strong><br><a href=/people/a/antonio-moreno-ortiz/>Antonio Moreno-Ortiz</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5231><div class="card-body p-3 small">In this paper we describe Tecnolengua Group&#8217;s participation in the shared task on emotion intensity at WASSA 2017. We used the Lingmotif tool and a new, complementary tool, Lingmotif Learn, which we developed for this occasion. We based our intensity predictions for the four test datasets entirely on Lingmotif&#8217;s TSS (text sentiment score) feature. We also developed <a href=https://en.wikipedia.org/wiki/Mechanism_design>mechanisms</a> for dealing with the <a href=https://en.wikipedia.org/wiki/Idiosyncrasy>idiosyncrasies</a> of <a href=https://en.wikipedia.org/wiki/Twitter>Twitter text</a>. Results were comparatively poor, but the experience meant a good opportunity for us to identify issues in our score calculation for short texts, a genre for which the Lingmotif tool was not originally designed.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5232.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5232 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5232 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-5232" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-5232/>EmoAtt at EmoInt-2017 : Inner attention sentence embedding for Emotion Intensity<span class=acl-fixed-case>E</span>mo<span class=acl-fixed-case>A</span>tt at <span class=acl-fixed-case>E</span>mo<span class=acl-fixed-case>I</span>nt-2017: Inner attention sentence embedding for Emotion Intensity</a></strong><br><a href=/people/e/edison-marrese-taylor/>Edison Marrese-Taylor</a>
|
<a href=/people/y/yutaka-matsuo/>Yutaka Matsuo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5232><div class="card-body p-3 small">In this paper we describe a deep learning system that has been designed and built for the WASSA 2017 Emotion Intensity Shared Task. We introduce a representation learning approach based on inner attention on top of an <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>RNN</a>. Results show that our model offers good capabilities and is able to successfully identify emotion-bearing words to predict intensity without leveraging on lexicons, obtaining the 13 t place among 22 shared task competitors.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5234.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5234 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5234 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5234/>DMGroup at EmoInt-2017 : Emotion Intensity Using Ensemble Method<span class=acl-fixed-case>DMG</span>roup at <span class=acl-fixed-case>E</span>mo<span class=acl-fixed-case>I</span>nt-2017: Emotion Intensity Using Ensemble Method</a></strong><br><a href=/people/s/song-jiang/>Song Jiang</a>
|
<a href=/people/x/xiaotian-han/>Xiaotian Han</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5234><div class="card-body p-3 small">In this paper, we present a novel ensemble learning architecture for emotion intensity analysis, particularly a novel framework of ensemble method. The ensemble method has two stages and each stage includes several single machine learning models. In stage1, we employ both linear and nonlinear regression models to obtain a more diverse emotion intensity representation. In stage2, we use two <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression models</a> including <a href=https://en.wikipedia.org/wiki/Linear_regression>linear regression</a> and <a href=https://en.wikipedia.org/wiki/XGBoost>XGBoost</a>. The result of stage1 serves as the input of stage2, so the two different type models (linear and non-linear) in stage2 can describe the input in two opposite aspects. We also added a method for analyzing and splitting multi-words hashtags and appending them to the emotion intensity corpus before feeding it to our model. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves 0.571 <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>Pearson-measure</a> for the average of four emotions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5235.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5235 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5235 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5235/>UWat-Emote at EmoInt-2017 : Emotion Intensity Detection using Affect Clues, Sentiment Polarity and Word Embeddings<span class=acl-fixed-case>UW</span>at-Emote at <span class=acl-fixed-case>E</span>mo<span class=acl-fixed-case>I</span>nt-2017: Emotion Intensity Detection using Affect Clues, Sentiment Polarity and Word Embeddings</a></strong><br><a href=/people/v/vineet-john/>Vineet John</a>
|
<a href=/people/o/olga-vechtomova/>Olga Vechtomova</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5235><div class="card-body p-3 small">This paper describes the UWaterloo affect prediction system developed for EmoInt-2017. We delve into our feature selection approach for affect intensity, affect presence, sentiment intensity and sentiment presence lexica alongside pre-trained word embeddings, which are utilized to extract emotion intensity signals from tweets in an ensemble learning approach. The system employs emotion specific model training, and utilizes distinct <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> for each of the emotion corpora in isolation. Our system utilizes gradient boosted regression as the primary learning technique to predict the final emotion intensities.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5236.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5236 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5236 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5236/>LIPN-UAM at EmoInt-2017 : Combination of Lexicon-based features and Sentence-level Vector Representations for Emotion Intensity Determination<span class=acl-fixed-case>LIPN</span>-<span class=acl-fixed-case>UAM</span> at <span class=acl-fixed-case>E</span>mo<span class=acl-fixed-case>I</span>nt-2017:Combination of Lexicon-based features and Sentence-level Vector Representations for Emotion Intensity Determination</a></strong><br><a href=/people/d/davide-buscaldi/>Davide Buscaldi</a>
|
<a href=/people/b/belem-priego-sanchez/>Belem Priego</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5236><div class="card-body p-3 small">This paper presents the combined LIPN-UAM participation in the WASSA 2017 Shared Task on Emotion Intensity. In particular, the paper provides some highlights on the Tweetaneuse system that was presented to the shared task. We combined lexicon-based features with sentence-level vector representations to implement a random forest regressor.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5237.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5237 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5237 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5237/>deepCybErNet at EmoInt-2017 : Deep Emotion Intensities in Tweets<span class=acl-fixed-case>C</span>yb<span class=acl-fixed-case>E</span>r<span class=acl-fixed-case>N</span>et at <span class=acl-fixed-case>E</span>mo<span class=acl-fixed-case>I</span>nt-2017: Deep Emotion Intensities in Tweets</a></strong><br><a href=/people/v/vinayakumar-r/>Vinayakumar R</a>
|
<a href=/people/p/premjith-b/>Premjith B</a>
|
<a href=/people/s/sachin-kumar-s/>Sachin Kumar S</a>
|
<a href=/people/s/soman-kp/>Soman KP</a>
|
<a href=/people/p/prabaharan-poornachandran/>Prabaharan Poornachandran</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5237><div class="card-body p-3 small">This working note presents the methodology used in deepCybErNet submission to the shared task on Emotion Intensities in Tweets (EmoInt) WASSA-2017. The goal of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is to predict a real valued score in the range [ 0-1 ] for a particular tweet with an <a href=https://en.wikipedia.org/wiki/Emotion>emotion type</a>. To do this, we used Bag-of-Words and embedding based on recurrent network architecture. We have developed two systems and experiments are conducted on the Emotion Intensity shared Task 1 data base at WASSA-2017. A system which uses <a href=https://en.wikipedia.org/wiki/Word_embedding>word embedding</a> based on recurrent network architecture has achieved highest 5 fold cross-validation accuracy. This has used <a href=https://en.wikipedia.org/wiki/Embedding>embedding</a> with <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent network</a> to extract optimal features at tweet level and <a href=https://en.wikipedia.org/wiki/Logistic_regression>logistic regression</a> for <a href=https://en.wikipedia.org/wiki/Prediction>prediction</a>. These methods are highly language independent and experimental results shows that the proposed methods are apt for predicting a real valued score in than range [ 0-1 ] for a given tweet with its emotion type.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ¬©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>