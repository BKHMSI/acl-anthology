<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 13th Workshop on Building and Using Comparable Corpora - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Proceedings of the 13th Workshop on Building and Using Comparable Corpora</h2><p class=lead><a href=/people/r/reinhard-rapp/>Reinhard Rapp</a>,
<a href=/people/p/pierre-zweigenbaum/>Pierre Zweigenbaum</a>,
<a href=/people/s/serge-sharoff/>Serge Sharoff</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2020.bucc-1</dd><dt>Month:</dt><dd>May</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Marseille, France</dd><dt>Venues:</dt><dd><a href=/venues/bucc/>BUCC</a>
| <a href=/venues/lrec/>LREC</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>European Language Resources Association</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.bucc-1>https://aclanthology.org/2020.bucc-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+13th+Workshop+on+Building+and+Using+Comparable+Corpora" title="Search for 'Proceedings of the 13th Workshop on Building and Using Comparable Corpora' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bucc-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bucc-1.0/>Proceedings of the 13th Workshop on Building and Using Comparable Corpora</a></strong><br><a href=/people/r/reinhard-rapp/>Reinhard Rapp</a>
|
<a href=/people/p/pierre-zweigenbaum/>Pierre Zweigenbaum</a>
|
<a href=/people/s/serge-sharoff/>Serge Sharoff</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bucc-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bucc-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bucc-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bucc-1.3/>Constructing a Bilingual Corpus of Parallel Tweets</a></strong><br><a href=/people/h/hamdy-mubarak/>Hamdy Mubarak</a>
|
<a href=/people/s/sabit-hassan/>Sabit Hassan</a>
|
<a href=/people/a/ahmed-abdelali/>Ahmed Abdelali</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bucc-1--3><div class="card-body p-3 small">In a bid to reach a larger and more diverse audience, Twitter users often post parallel tweetstweets that contain the same content but are written in different languages. Parallel tweets can be an important resource for developing <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation (MT) systems</a> among other <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP) tasks</a>. In this paper, we introduce a generic <a href=https://en.wikipedia.org/wiki/Methodology>method</a> for collecting parallel tweets. Using this method, we collect a bilingual corpus of English-Arabic parallel tweets and a list of Twitter accounts who post English-Arabictweets regularly. Since our method is generic, it can also be used for collecting parallel tweets that cover less-resourced languages such as <a href=https://en.wikipedia.org/wiki/Serbian_language>Serbian</a> and <a href=https://en.wikipedia.org/wiki/Urdu>Urdu</a>. Additionally, we annotate a subset of Twitter accounts with their countries of origin and topic of interest, which provides insights about the population who post parallel tweets. This latter information can also be useful for author profiling tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bucc-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bucc-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bucc-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bucc-1.4/>Automatic Creation of Correspondence Table of Meaning Tags from Two Dictionaries in One Language Using Bilingual Word Embedding</a></strong><br><a href=/people/t/teruo-hirabayashi/>Teruo Hirabayashi</a>
|
<a href=/people/k/kanako-komiya/>Kanako Komiya</a>
|
<a href=/people/m/masayuki-asahara/>Masayuki Asahara</a>
|
<a href=/people/h/hiroyuki-shinnou/>Hiroyuki Shinnou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bucc-1--4><div class="card-body p-3 small">In this paper, we show how to use bilingual word embeddings (BWE) to automatically create a corresponding table of meaning tags from two dictionaries in one language and examine the effectiveness of the method. To do this, we had a problem : the meaning tags do not always correspond one-to-one because the granularities of the <a href=https://en.wikipedia.org/wiki/Word_sense>word senses</a> and the <a href=https://en.wikipedia.org/wiki/Concept>concepts</a> are different from each other. Therefore, we regarded the concept tag that corresponds to a <a href=https://en.wikipedia.org/wiki/Word_sense>word sense</a> the most as the correct concept tag corresponding the <a href=https://en.wikipedia.org/wiki/Word_sense>word sense</a>. We used two BWE methods, a <a href=https://en.wikipedia.org/wiki/Linear_map>linear transformation matrix</a> and VecMap. We evaluated the most frequent sense (MFS) method and the corpus concatenation method for comparison. The accuracies of the proposed methods were higher than the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of the random baseline but lower than those of the MFS and corpus concatenation methods. However, because our method utilized the embedding vectors of the word senses, the relations of the sense tags corresponding to concept tags could be examined by mapping the sense embeddings to the vector space of the concept tags. Also, our methods could be performed when we have only concept or word sense embeddings whereas the MFS method requires a <a href=https://en.wikipedia.org/wiki/Parallel_corpus>parallel corpus</a> and the corpus concatenation method needs two tagged corpora.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bucc-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bucc-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bucc-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.bucc-1.6" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.bucc-1.6/>Benchmarking Multidomain English-Indonesian Machine Translation<span class=acl-fixed-case>E</span>nglish-<span class=acl-fixed-case>I</span>ndonesian Machine Translation</a></strong><br><a href=/people/t/tri-wahyu-guntara/>Tri Wahyu Guntara</a>
|
<a href=/people/a/alham-fikri-aji/>Alham Fikri Aji</a>
|
<a href=/people/r/radityo-eko-prasojo/>Radityo Eko Prasojo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bucc-1--6><div class="card-body p-3 small">In the context of Machine Translation (MT) from-and-to English, <a href=https://en.wikipedia.org/wiki/Indonesian_language>Bahasa Indonesia</a> has been considered a low-resource language, and therefore applying Neural Machine Translation (NMT) which typically requires large training dataset proves to be problematic. In this paper, we show otherwise by collecting large, publicly-available datasets from the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>Web</a>, which we split into several domains : <a href=https://en.wikipedia.org/wiki/News>news</a>, <a href=https://en.wikipedia.org/wiki/Religion>religion</a>, general, and <a href=https://en.wikipedia.org/wiki/Conversation>conversation</a>, to train and benchmark some variants of transformer-based NMT models across the domains. We show using BLEU that our models perform well across them, outperform the baseline Statistical Machine Translation (SMT) models, and perform comparably with <a href=https://en.wikipedia.org/wiki/Google_Translate>Google Translate</a>. Our datasets (with the standard split for training, validation, and testing), code, and models are available on<url>https://github.com/gunnxx/indonesian-mt-data</url>\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bucc-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bucc-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bucc-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bucc-1.7/>Reducing the Search Space for Parallel Sentences in Comparable Corpora</a></strong><br><a href=/people/r/remi-cardon/>Rémi Cardon</a>
|
<a href=/people/n/natalia-grabar/>Natalia Grabar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bucc-1--7><div class="card-body p-3 small">This paper describes and evaluates simple techniques for reducing the research space for parallel sentences in monolingual comparable corpora. Initially, when searching for parallel sentences between two comparable documents, all the possible sentence pairs between the documents have to be considered, which introduces a great degree of imbalance between parallel pairs and non-parallel pairs. This is a problem because even with a high performing <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a>, a lot of <a href=https://en.wikipedia.org/wiki/Noise>noise</a> will be present in the extracted results, thus introducing a need for an extensive and costly manual check phase. We work on a manually annotated subset obtained from a French comparable corpus and show how we can drastically reduce the number of sentence pairs that have to be fed to a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> so that the results can be manually handled.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bucc-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bucc-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bucc-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bucc-1.9/>TALN / LS2N Participation at the BUCC Shared Task : Bilingual Dictionary Induction from Comparable Corpora<span class=acl-fixed-case>TALN</span>/<span class=acl-fixed-case>LS</span>2<span class=acl-fixed-case>N</span> Participation at the <span class=acl-fixed-case>BUCC</span> Shared Task: Bilingual Dictionary Induction from Comparable Corpora</a></strong><br><a href=/people/m/martin-laville/>Martin Laville</a>
|
<a href=/people/a/amir-hazem/>Amir Hazem</a>
|
<a href=/people/e/emmanuel-morin/>Emmanuel Morin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bucc-1--9><div class="card-body p-3 small">This paper describes the TALN / LS2N system participation at the Building and Using Comparable Corpora (BUCC) shared task. We first introduce three strategies : (i) a word embedding approach based on fastText embeddings ; (ii) a concatenation approach using both character Skip-Gram and character CBOW models, and finally (iii) a cognates matching approach based on an exact match string similarity. Then, we present the applied <a href=https://en.wikipedia.org/wiki/Strategy_(game_theory)>strategy</a> for the shared task which consists in the combination of the embeddings concatenation and the cognates matching approaches. The covered languages are <a href=https://en.wikipedia.org/wiki/French_language>French</a>, <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/German_language>German</a>, <a href=https://en.wikipedia.org/wiki/Russian_language>Russian</a> and <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>. Overall, our system mixing embeddings concatenation and perfect cognates matching obtained the best results while compared to individual strategies, except for English-Russian and Russian-English language pairs for which the concatenation approach was preferred.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bucc-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bucc-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bucc-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bucc-1.11/>BUCC2020 : Bilingual Dictionary Induction using Cross-lingual Embedding<span class=acl-fixed-case>BUCC</span>2020: Bilingual Dictionary Induction using Cross-lingual Embedding</a></strong><br><a href=/people/s/sanjanasri-jp/>Sanjanasri JP</a>
|
<a href=/people/v/vijay-krishna-menon/>Vijay Krishna Menon</a>
|
<a href=/people/s/soman-kp/>Soman KP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bucc-1--11><div class="card-body p-3 small">This paper presents a <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning system</a> for the BUCC 2020 shared task : Bilingual dictionary induction from comparable corpora. We have submitted two runs for this shared Task, German (de) and English (en) language pair for closed track and Tamil (ta) and English (en) for the open track. Our core approach focuses on quantifying the <a href=https://en.wikipedia.org/wiki/Semantics>semantics of the language pairs</a>, so that <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> of two different language pairs can be compared or transfer learned. With the advent of <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a>, it is possible to quantify this. In this paper, we propose a deep learning approach which makes use of the supplied training data, to generate cross-lingual embedding. This is later used for inducting <a href=https://en.wikipedia.org/wiki/Bilingual_dictionary>bilingual dictionary</a> from comparable corpora.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>