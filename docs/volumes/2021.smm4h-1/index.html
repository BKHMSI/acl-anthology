<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the Sixth Social Media Mining for Health (#SMM4H) Workshop and Shared Task - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/2021.smm4h-1.pdf>Proceedings of the Sixth Social Media Mining for Health (#SMM4H) Workshop and Shared Task</a></h2><p class=lead><a href=/people/a/arjun-magge/>Arjun Magge</a>,
<a href=/people/a/ari-klein/>Ari Klein</a>,
<a href=/people/a/antonio-miranda-escalada/>Antonio Miranda-Escalada</a>,
<a href=/people/m/mohammed-ali-al-garadi/>Mohammed Ali Al-garadi</a>,
<a href=/people/i/ilseyar-alimova/>Ilseyar Alimova</a>,
<a href=/people/z/zulfat-miftahutdinov/>Zulfat Miftahutdinov</a>,
<a href=/people/e/eulalia-farre-maduell/>Eulalia Farre-Maduell</a>,
<a href=/people/s/salvador-lima-lopez/>Salvador Lima Lopez</a>,
<a href=/people/i/ivan-flores/>Ivan Flores</a>,
<a href=/people/k/karen-o-connor/>Karen O'Connor</a>,
<a href=/people/d/davy-weissenbacher/>Davy Weissenbacher</a>,
<a href=/people/e/elena-tutubalina/>Elena Tutubalina</a>,
<a href=/people/a/abeed-sarker/>Abeed Sarker</a>,
<a href=/people/j/juan-m-banda/>Juan M Banda</a>,
<a href=/people/m/martin-krallinger/>Martin Krallinger</a>,
<a href=/people/g/graciela-gonzalez/>Graciela Gonzalez-Hernandez</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2021.smm4h-1</dd><dt>Month:</dt><dd>June</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Mexico City, Mexico</dd><dt>Venues:</dt><dd><a href=/venues/naacl/>NAACL</a>
| <a href=/venues/smm4h/>SMM4H</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.smm4h-1>https://aclanthology.org/2021.smm4h-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2021.smm4h-1.pdf>https://aclanthology.org/2021.smm4h-1.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2021.smm4h-1.pdf title="Open PDF of 'Proceedings of the Sixth Social Media Mining for Health (#SMM4H) Workshop and Shared Task'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+Sixth+Social+Media+Mining+for+Health+%28%23SMM4H%29+Workshop+and+Shared+Task" title="Search for 'Proceedings of the Sixth Social Media Mining for Health (#SMM4H) Workshop and Shared Task' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.smm4h-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.smm4h-1.0/>Proceedings of the Sixth Social Media Mining for Health (#SMM4H) Workshop and Shared Task</a></strong><br><a href=/people/a/arjun-magge/>Arjun Magge</a>
|
<a href=/people/a/ari-klein/>Ari Klein</a>
|
<a href=/people/a/antonio-miranda-escalada/>Antonio Miranda-Escalada</a>
|
<a href=/people/m/mohammed-ali-al-garadi/>Mohammed Ali Al-garadi</a>
|
<a href=/people/i/ilseyar-alimova/>Ilseyar Alimova</a>
|
<a href=/people/z/zulfat-miftahutdinov/>Zulfat Miftahutdinov</a>
|
<a href=/people/e/eulalia-farre-maduell/>Eulalia Farre-Maduell</a>
|
<a href=/people/s/salvador-lima-lopez/>Salvador Lima Lopez</a>
|
<a href=/people/i/ivan-flores/>Ivan Flores</a>
|
<a href=/people/k/karen-o-connor/>Karen O'Connor</a>
|
<a href=/people/d/davy-weissenbacher/>Davy Weissenbacher</a>
|
<a href=/people/e/elena-tutubalina/>Elena Tutubalina</a>
|
<a href=/people/a/abeed-sarker/>Abeed Sarker</a>
|
<a href=/people/j/juan-m-banda/>Juan M Banda</a>
|
<a href=/people/m/martin-krallinger/>Martin Krallinger</a>
|
<a href=/people/g/graciela-gonzalez/>Graciela Gonzalez-Hernandez</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.smm4h-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--smm4h-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.smm4h-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.smm4h-1.2/>View Distillation with Unlabeled Data for Extracting Adverse Drug Effects from User-Generated Data</a></strong><br><a href=/people/p/payam-karisani/>Payam Karisani</a>
|
<a href=/people/j/jinho-d-choi/>Jinho D. Choi</a>
|
<a href=/people/l/li-xiong/>Li Xiong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--smm4h-1--2><div class="card-body p-3 small">We present an <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> based on multi-layer transformers for identifying Adverse Drug Reactions (ADR) in social media data. Our model relies on the properties of the problem and the characteristics of contextual word embeddings to extract two views from documents. Then a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> is trained on each view to label a set of unlabeled documents to be used as an initializer for a new <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> in the other view. Finally, the initialized classifier in each view is further trained using the initial training examples. We evaluated our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> in the largest publicly available ADR dataset. The experiments testify that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> significantly outperforms the transformer-based models pretrained on domain-specific data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.smm4h-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--smm4h-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.smm4h-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.smm4h-1.3/>The ProfNER shared task on automatic recognition of occupation mentions in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> : systems, evaluation, guidelines, embeddings and corpora<span class=acl-fixed-case>P</span>rof<span class=acl-fixed-case>NER</span> shared task on automatic recognition of occupation mentions in social media: systems, evaluation, guidelines, embeddings and corpora</a></strong><br><a href=/people/a/antonio-miranda-escalada/>Antonio Miranda-Escalada</a>
|
<a href=/people/e/eulalia-farre-maduell/>Eulàlia Farré-Maduell</a>
|
<a href=/people/s/salvador-lima-lopez/>Salvador Lima-López</a>
|
<a href=/people/l/luis-gasco/>Luis Gascó</a>
|
<a href=/people/v/vicent-briva-iglesias/>Vicent Briva-Iglesias</a>
|
<a href=/people/m/marvin-aguero-torales/>Marvin Agüero-Torales</a>
|
<a href=/people/m/martin-krallinger/>Martin Krallinger</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--smm4h-1--3><div class="card-body p-3 small">Detection of occupations in texts is relevant for a range of important application scenarios, like <a href=https://en.wikipedia.org/wiki/Competitive_intelligence>competitive intelligence</a>, sociodemographic analysis, legal NLP or health-related occupational data mining. Despite the importance and heterogeneous data types that mention <a href=https://en.wikipedia.org/wiki/Job>occupations</a>, <a href=https://en.wikipedia.org/wiki/Text_mining>text mining</a> efforts to recognize them have been limited. This is due to the lack of clear annotation guidelines and high-quality Gold Standard corpora. Social media data can be regarded as a relevant source of information for real-time monitoring of at-risk occupational groups in the context of <a href=https://en.wikipedia.org/wiki/Pandemic>pandemics</a> like the COVID-19 one, facilitating intervention strategies for occupations in direct contact with infectious agents or affected by mental health issues. To evaluate current NLP methods and to generate resources, we have organized the ProfNER track at SMM4H 2021, providing ProfNER participants with a Gold Standard corpus of manually annotated tweets (human IAA of 0.919) following annotation guidelines available in <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a> and <a href=https://en.wikipedia.org/wiki/English_language>English</a>, an occupation gazetteer, a machine-translated version of <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a>, and FastText embeddings. Out of 35 registered teams, 11 submitted a total of 27 runs. Best-performing participants built <a href=https://en.wikipedia.org/wiki/System>systems</a> based on recent <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP technologies</a> (e.g. transformers) and achieved 0.93 <a href=https://en.wikipedia.org/wiki/F-score>F-score</a> in Text Classification and 0.839 in <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>Named Entity Recognition</a>. Corpus : https://doi.org/10.5281/zenodo.4309356</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.smm4h-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--smm4h-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.smm4h-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.smm4h-1.7/>Transformer-based Multi-Task Learning for Adverse Effect Mention Analysis in Tweets</a></strong><br><a href=/people/g/george-andrei-dima/>George-Andrei Dima</a>
|
<a href=/people/d/dumitru-clementin-cercel/>Dumitru-Clementin Cercel</a>
|
<a href=/people/m/mihai-dascalu/>Mihai Dascalu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--smm4h-1--7><div class="card-body p-3 small">This paper presents our contribution to the <a href=https://en.wikipedia.org/wiki/Social_media_mining>Social Media Mining</a> for Health Applications Shared Task 2021. We addressed all the three subtasks of Task 1 : Subtask A (classification of tweets containing adverse effects), Subtask B (extraction of text spans containing adverse effects) and Subtask C (adverse effects resolution). We explored various pre-trained transformer-based language models and we focused on a multi-task training architecture. For the first subtask, we also applied adversarial augmentation techniques and we formed model ensembles in order to improve the <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> of the prediction. Our system ranked first at Subtask B with 0.51 F1 score, 0.514 <a href=https://en.wikipedia.org/wiki/Precision_(computer_science)>precision</a> and 0.514 recall. For Subtask A we obtained 0.44 <a href=https://en.wikipedia.org/wiki/Precision_(computer_science)>F1 score</a>, 0.49 <a href=https://en.wikipedia.org/wiki/Precision_(computer_science)>precision</a> and 0.39 recall and for Subtask C we obtained 0.16 <a href=https://en.wikipedia.org/wiki/Precision_(computer_science)>F1 score</a> with 0.16 <a href=https://en.wikipedia.org/wiki/Precision_(computer_science)>precision</a> and 0.17 recall.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.smm4h-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--smm4h-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.smm4h-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.smm4h-1.10/>UACH-INAOE at SMM4H : a BERT based approach for classification of COVID-19 Twitter posts<span class=acl-fixed-case>UACH</span>-<span class=acl-fixed-case>INAOE</span> at <span class=acl-fixed-case>SMM</span>4<span class=acl-fixed-case>H</span>: a <span class=acl-fixed-case>BERT</span> based approach for classification of <span class=acl-fixed-case>COVID</span>-19 <span class=acl-fixed-case>T</span>witter posts</a></strong><br><a href=/people/a/alberto-valdes/>Alberto Valdes</a>
|
<a href=/people/j/jesus-lopez/>Jesus Lopez</a>
|
<a href=/people/m/manuel-montes/>Manuel Montes</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--smm4h-1--10><div class="card-body p-3 small">This work describes the participation of the Universidad Autnoma de Chihuahua-Instituto Nacional de Astrofsica, ptica y Electrnica team at the Social Media Mining for Health Applications (SMM4H) 2021 shared task. Our team participated in task 5 and 6, both focused on the automatic classification of Twitter posts related to COVID-19. Task 5 was oriented on solving a binary classification problem, trying to identify self-reporting tweets of potential cases of COVID-19. Task 6 objective was to classify tweets containing COVID-19 symptoms. For both tasks we used <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> based on bidirectional encoder representations from transformers (BERT). Our objective was to determine if a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> pretrained on a corpus in the domain of interest can outperform one trained on a much larger general domain corpus. Our F1 results were encouraging, 0.77 and 0.95 for task 5 and 6 respectively, having achieved the highest score among all the participants in the latter.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.smm4h-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--smm4h-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.smm4h-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.smm4h-1.12/>Word Embeddings, <a href=https://en.wikipedia.org/wiki/Cosine_similarity>Cosine Similarity</a> and <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Learning</a> for Identification of Professions & Occupations in Health-related Social Media</a></strong><br><a href=/people/s/sergio-santamaria-carrasco/>Sergio Santamaría Carrasco</a>
|
<a href=/people/r/roberto-cuervo-rosillo/>Roberto Cuervo Rosillo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--smm4h-1--12><div class="card-body p-3 small">ProfNER-ST focuses on the recognition of professions and occupations from <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> using Spanish data. Our participation is based on a combination of word-level embeddings, including pre-trained Spanish BERT, as well as cosine similarity computed over a subset of entities that serve as input for an encoder-decoder architecture with attention mechanism. Finally, our best score achieved an F1-measure of 0.823 in the official test set.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.smm4h-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--smm4h-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.smm4h-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.smm4h-1.16/>A Joint Training Approach to Tweet Classification and Adverse Effect Extraction and Normalization for SMM4H 2021<span class=acl-fixed-case>SMM</span>4<span class=acl-fixed-case>H</span> 2021</a></strong><br><a href=/people/m/mohab-el-karef/>Mohab Elkaref</a>
|
<a href=/people/l/lamiece-hassan/>Lamiece Hassan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--smm4h-1--16><div class="card-body p-3 small">In this work we describe our submissions to the Social Media Mining for Health (SMM4H) 2021 Shared Task. We investigated the effectiveness of a joint training approach to Task 1, specifically classification, extraction and normalization of Adverse Drug Effect (ADE) mentions in English tweets. Our approach performed well on the normalization task, achieving an above average f1 score of 24 %, but less so on <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> and extraction, with f1 scores of 22 % and 37 % respectively. Our experiments also showed that a larger dataset with more negative results led to stronger results than a smaller more balanced dataset, even when both datasets have the same positive examples. Finally we also submitted a tuned BERT model for Task 6 : Classification of Covid-19 tweets containing symptoms, which achieved an above average f1 score of 96 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.smm4h-1.20.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--smm4h-1--20 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.smm4h-1.20 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.smm4h-1.20/>Identification of profession & occupation in Health-related Social Media using tweets in Spanish<span class=acl-fixed-case>S</span>panish</a></strong><br><a href=/people/v/victoria-pachon/>Victoria Pachón</a>
|
<a href=/people/j/jacinto-mata-vazquez/>Jacinto Mata Vázquez</a>
|
<a href=/people/j/juan-luis-dominguez-olmedo/>Juan Luís Domínguez Olmedo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--smm4h-1--20><div class="card-body p-3 small">In this paper we present our approach and system description on Task 7a in ProfNer-ST : Identification of profession & occupation in Health related Social Media. Our main contribution is to show the effectiveness of using BETO-Spanish BERT as a model based on transformers pretrained with a Spanish Corpus for classification tasks. In our experiments we compared several <a href=https://en.wikipedia.org/wiki/Computer_architecture>architectures</a> based on <a href=https://en.wikipedia.org/wiki/Transformer>transformers</a> with others based on classical <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning algorithms</a>. With this <a href=https://en.wikipedia.org/wiki/Software_development_process>approach</a>, we achieved an F1-score of 0.92 in the evaluation process.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.smm4h-1.23.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--smm4h-1--23 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.smm4h-1.23 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.smm4h-1.23/>UoB at ProfNER 2021 : Data Augmentation for Classification Using <a href=https://en.wikipedia.org/wiki/Machine_translation>Machine Translation</a><span class=acl-fixed-case>U</span>o<span class=acl-fixed-case>B</span> at <span class=acl-fixed-case>P</span>rof<span class=acl-fixed-case>NER</span> 2021: Data Augmentation for Classification Using Machine Translation</a></strong><br><a href=/people/f/frances-adriana-laureano-de-leon/>Frances Adriana Laureano De Leon</a>
|
<a href=/people/h/harish-tayyar-madabushi/>Harish Tayyar Madabushi</a>
|
<a href=/people/m/mark-lee/>Mark Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--smm4h-1--23><div class="card-body p-3 small">This paper describes the participation of the UoB-NLP team in the ProfNER-ST shared subtask 7a. The <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> was aimed at detecting the mention of professions in social media text. Our team experimented with two methods of improving the performance of pre-trained models : Specifically, we experimented with <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> through <a href=https://en.wikipedia.org/wiki/Translation>translation</a> and the merging of multiple language inputs to meet the objective of the task. While the best performing model on the test data consisted of mBERT fine-tuned on augmented data using <a href=https://en.wikipedia.org/wiki/Back-translation>back-translation</a>, the improvement is minor possibly because multi-lingual pre-trained models such as mBERT already have access to the kind of information provided through <a href=https://en.wikipedia.org/wiki/Back-translation>back-translation and bilingual data</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.smm4h-1.26.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--smm4h-1--26 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.smm4h-1.26 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.smm4h-1.26/>PAII-NLP at SMM4H 2021 : Joint Extraction and Normalization of Adverse Drug Effect Mentions in Tweets<span class=acl-fixed-case>PAII</span>-<span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>SMM</span>4<span class=acl-fixed-case>H</span> 2021: Joint Extraction and Normalization of Adverse Drug Effect Mentions in Tweets</a></strong><br><a href=/people/z/zongcheng-ji/>Zongcheng Ji</a>
|
<a href=/people/t/tian-xia/>Tian Xia</a>
|
<a href=/people/m/mei-han/>Mei Han</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--smm4h-1--26><div class="card-body p-3 small">This paper describes our system developed for the subtask 1c of the sixth Social Media Mining for Health Applications (SMM4H) shared task in 2021. The aim of the subtask is to recognize the adverse drug effect (ADE) mentions from tweets and normalize the identified mentions to their mapping MedDRA preferred term IDs. Our system is based on a neural transition-based joint model, which is to perform <a href=https://en.wikipedia.org/wiki/Computer_vision>recognition</a> and <a href=https://en.wikipedia.org/wiki/Normalization_(statistics)>normalization</a> simultaneously. Our final two submissions outperform the average F1 score by 1-2 %.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>