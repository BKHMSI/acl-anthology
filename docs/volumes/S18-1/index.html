<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of The 12th International Workshop on Semantic Evaluation - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/S18-1.pdf>Proceedings of The 12th International Workshop on Semantic Evaluation</a></h2><p class=lead><a href=/people/m/marianna-apidianaki/>Marianna Apidianaki</a>,
<a href=/people/s/saif-mohammad/>Saif M. Mohammad</a>,
<a href=/people/j/jonathan-may/>Jonathan May</a>,
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a>,
<a href=/people/s/steven-bethard/>Steven Bethard</a>,
<a href=/people/m/marine-carpuat/>Marine Carpuat</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>S18-1</dd><dt>Month:</dt><dd>June</dd><dt>Year:</dt><dd>2018</dd><dt>Address:</dt><dd>New Orleans, Louisiana</dd><dt>Venue:</dt><dd><a href=/venues/semeval/>SemEval</a></dd><dt>SIGs:</dt><dd><a href=/sigs/siglex/>SIGLEX</a>
|
<a href=/sigs/sigsem/>SIGSEM</a></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/S18-1>https://aclanthology.org/S18-1</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/S18-1 title="To the current version of the paper by DOI">10.18653/v1/S18-1</a></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/S18-1.pdf>https://aclanthology.org/S18-1.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/S18-1.pdf title="Open PDF of 'Proceedings of The 12th International Workshop on Semantic Evaluation'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+The+12th+International+Workshop+on+Semantic+Evaluation" title="Search for 'Proceedings of The 12th International Workshop on Semantic Evaluation' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1000/>Proceedings of The 12th International Workshop on Semantic Evaluation</a></strong><br><a href=/people/m/marianna-apidianaki/>Marianna Apidianaki</a>
|
<a href=/people/s/saif-mohammad/>Saif M. Mohammad</a>
|
<a href=/people/j/jonathan-may/>Jonathan May</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a>
|
<a href=/people/s/steven-bethard/>Steven Bethard</a>
|
<a href=/people/m/marine-carpuat/>Marine Carpuat</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1001 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/S18-1001.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/S18-1001/>SemEval-2018 Task 1 : Affect in Tweets<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Affect in Tweets</a></strong><br><a href=/people/s/saif-mohammad/>Saif Mohammad</a>
|
<a href=/people/f/felipe-bravo-marquez/>Felipe Bravo-Marquez</a>
|
<a href=/people/m/mohammad-salameh/>Mohammad Salameh</a>
|
<a href=/people/s/svetlana-kiritchenko/>Svetlana Kiritchenko</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1001><div class="card-body p-3 small">We present the SemEval-2018 Task 1 : Affect in Tweets, which includes an array of subtasks on inferring the affectual state of a person from their tweet. For each <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, we created labeled data from <a href=https://en.wikipedia.org/wiki/English_language>English</a>, Arabic, and Spanish tweets. The individual tasks are : 1. emotion intensity regression, 2. emotion intensity ordinal classification, 3. valence (sentiment) regression, 4. valence ordinal classification, and 5. <a href=https://en.wikipedia.org/wiki/Emotion_classification>emotion classification</a>. Seventy-five teams (about 200 team members) participated in the shared task. We summarize the <a href=https://en.wikipedia.org/wiki/Methodology>methods</a>, resources, and tools used by the participating teams, with a focus on the techniques and resources that are particularly useful. We also analyze <a href=https://en.wikipedia.org/wiki/System>systems</a> for consistent bias towards a particular race or gender. The data is made freely available to further improve our understanding of how people convey emotions through language.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1002 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1002/>SeerNet at SemEval-2018 Task 1 : Domain Adaptation for Affect in Tweets<span class=acl-fixed-case>S</span>eer<span class=acl-fixed-case>N</span>et at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Domain Adaptation for Affect in Tweets</a></strong><br><a href=/people/v/venkatesh-duppada/>Venkatesh Duppada</a>
|
<a href=/people/r/royal-jain/>Royal Jain</a>
|
<a href=/people/s/sushant-hiray/>Sushant Hiray</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1002><div class="card-body p-3 small">The paper describes the best performing <a href=https://en.wikipedia.org/wiki/System>system</a> for the SemEval-2018 Affect in Tweets(English) sub-tasks. The system focuses on the <a href=https://en.wikipedia.org/wiki/Ordinal_data>ordinal classification</a> and regression sub-tasks for <a href=https://en.wikipedia.org/wiki/Valence_(psychology)>valence</a> and <a href=https://en.wikipedia.org/wiki/Emotion>emotion</a>. For ordinal classification valence is classified into 7 different classes ranging from -3 to 3 whereas <a href=https://en.wikipedia.org/wiki/Emotion>emotion</a> is classified into 4 different classes 0 to 3 separately for each <a href=https://en.wikipedia.org/wiki/Emotion>emotion</a> namely <a href=https://en.wikipedia.org/wiki/Anger>anger</a>, <a href=https://en.wikipedia.org/wiki/Fear>fear</a>, joy and sadness. The <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression sub-tasks</a> estimate the <a href=https://en.wikipedia.org/wiki/Valence_(psychology)>intensity of valence</a> and each <a href=https://en.wikipedia.org/wiki/Emotion>emotion</a>. The <a href=https://en.wikipedia.org/wiki/System>system</a> performs <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> of 4 different models and creates an <a href=https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)>ensemble</a> to give the final prediction. The proposed <a href=https://en.wikipedia.org/wiki/System>system</a> achieved 1stposition out of 75 teams which participated in the fore-mentioned sub-tasks. We outperform the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline model</a> by margins ranging from 49.2 % to 76.4 %, thus, pushing the state-of-the-art significantly.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1003 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1003/>SemEval 2018 Task 2 : Multilingual Emoji Prediction<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val 2018 Task 2: Multilingual Emoji Prediction</a></strong><br><a href=/people/f/francesco-barbieri/>Francesco Barbieri</a>
|
<a href=/people/j/jose-camacho-collados/>Jose Camacho-Collados</a>
|
<a href=/people/f/francesco-ronzano/>Francesco Ronzano</a>
|
<a href=/people/l/luis-espinosa-anke/>Luis Espinosa-Anke</a>
|
<a href=/people/m/miguel-ballesteros/>Miguel Ballesteros</a>
|
<a href=/people/v/valerio-basile/>Valerio Basile</a>
|
<a href=/people/v/viviana-patti/>Viviana Patti</a>
|
<a href=/people/h/horacio-saggion/>Horacio Saggion</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1003><div class="card-body p-3 small">This paper describes the results of the first Shared Task on Multilingual Emoji Prediction, organized as part of SemEval 2018. Given the text of a tweet, the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> consists of predicting the most likely <a href=https://en.wikipedia.org/wiki/Emoji>emoji</a> to be used along such tweet. Two <a href=https://en.wikipedia.org/wiki/Task_(project_management)>subtasks</a> were proposed, one for <a href=https://en.wikipedia.org/wiki/English_language>English</a> and one for <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>, and participants were allowed to submit a <a href=https://en.wikipedia.org/wiki/System>system</a> run to one or both <a href=https://en.wikipedia.org/wiki/Task_(project_management)>subtasks</a>. In total, 49 teams participated to the <a href=https://en.wikipedia.org/wiki/English_language>English subtask</a> and 22 teams submitted a <a href=https://en.wikipedia.org/wiki/System>system</a> run to the <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish subtask</a>. Evaluation was carried out emoji-wise, and the final <a href=https://en.wikipedia.org/wiki/Ranking>ranking</a> was based on macro F-Score. Data and further information about this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> can be found at.<url>https://competitions.codalab.org/competitions/17344</url>.\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1004.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1004 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1004/>Tbingen-Oslo at SemEval-2018 Task 2 : SVMs perform better than RNNs in Emoji Prediction<span class=acl-fixed-case>T</span>übingen-<span class=acl-fixed-case>O</span>slo at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 2: <span class=acl-fixed-case>SVM</span>s perform better than <span class=acl-fixed-case>RNN</span>s in Emoji Prediction</a></strong><br><a href=/people/c/cagri-coltekin/>Çağrı Çöltekin</a>
|
<a href=/people/t/taraka-rama/>Taraka Rama</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1004><div class="card-body p-3 small">This paper describes our participation in the SemEval-2018 task Multilingual Emoji Prediction. We participated in both English and Spanish subtasks, experimenting with support vector machines (SVMs) and <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural networks</a>. Our SVM classifier obtained the top rank in both subtasks with macro-averaged F1-measures of 35.99 % for <a href=https://en.wikipedia.org/wiki/English_language>English</a> and 22.36 % for Spanish data sets. Similar to a few earlier attempts, the results with <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> were not on par with linear SVMs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1005.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1005 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1005 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1005/>SemEval-2018 Task 3 : Irony Detection in English Tweets<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 3: Irony Detection in <span class=acl-fixed-case>E</span>nglish Tweets</a></strong><br><a href=/people/c/cynthia-van-hee/>Cynthia Van Hee</a>
|
<a href=/people/e/els-lefever/>Els Lefever</a>
|
<a href=/people/v/veronique-hoste/>Véronique Hoste</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1005><div class="card-body p-3 small">This paper presents the first shared task on <a href=https://en.wikipedia.org/wiki/Irony>irony detection</a> : given a tweet, automatic natural language processing systems should determine whether the tweet is ironic (Task A) and which type of <a href=https://en.wikipedia.org/wiki/Irony>irony</a> (if any) is expressed (Task B). The ironic tweets were collected using irony-related hashtags (i.e. # irony, # sarcasm, # not) and were subsequently manually annotated to minimise the amount of noise in the corpus. Prior to distributing the data, <a href=https://en.wikipedia.org/wiki/Hashtag>hashtags</a> that were used to collect the tweets were removed from the corpus. For both tasks, a <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training corpus</a> of 3,834 tweets was provided, as well as a <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>test set</a> containing 784 tweets. Our shared tasks received submissions from 43 teams for the binary classification Task A and from 31 teams for the multiclass Task B. The highest classification scores obtained for both subtasks are respectively F1= 0.71 and F1= 0.51 and demonstrate that fine-grained irony classification is much more challenging than binary irony detection.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1006.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1006 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1006 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1006/>THU_NGN at SemEval-2018 Task 3 : Tweet Irony Detection with Densely connected LSTM and Multi-task Learning<span class=acl-fixed-case>THU</span>_<span class=acl-fixed-case>NGN</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 3: Tweet Irony Detection with Densely connected <span class=acl-fixed-case>LSTM</span> and Multi-task Learning</a></strong><br><a href=/people/c/chuhan-wu/>Chuhan Wu</a>
|
<a href=/people/f/fangzhao-wu/>Fangzhao Wu</a>
|
<a href=/people/s/sixing-wu/>Sixing Wu</a>
|
<a href=/people/j/junxin-liu/>Junxin Liu</a>
|
<a href=/people/z/zhigang-yuan/>Zhigang Yuan</a>
|
<a href=/people/y/yongfeng-huang/>Yongfeng Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1006><div class="card-body p-3 small">Detecting irony is an important task to mine fine-grained information from social web messages. Therefore, the Semeval-2018 task 3 is aimed to detect the ironic tweets (subtask A) and their ironic types (subtask B). In order to address this task, we propose a <a href=https://en.wikipedia.org/wiki/System>system</a> based on a densely connected LSTM network with multi-task learning strategy. In our dense LSTM model, each layer will take all outputs from previous layers as input. The last LSTM layer will output the hidden representations of texts, and they will be used in three classification task. In addition, we incorporate several types of features to improve the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performance. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieved an <a href=https://en.wikipedia.org/wiki/F-score>F-score</a> of 70.54 (ranked 2/43) in the subtask A and 49.47 (ranked 3/29) in the subtask B. The experimental results validate the effectiveness of our <a href=https://en.wikipedia.org/wiki/System>system</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1007.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1007 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1007 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1007/>SemEval 2018 Task 4 : Character Identification on Multiparty Dialogues<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val 2018 Task 4: Character Identification on Multiparty Dialogues</a></strong><br><a href=/people/j/jinho-d-choi/>Jinho D. Choi</a>
|
<a href=/people/h/henry-y-chen/>Henry Y. Chen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1007><div class="card-body p-3 small">Character identification is a task of <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity linking</a> that finds the global entity of each personal mention in multiparty dialogue. For this task, the first two seasons of the popular TV show Friends are annotated, comprising a total of 448 dialogues, 15,709 mentions, and 401 entities. The personal mentions are detected from <a href=https://en.wikipedia.org/wiki/Character_(arts)>nominals</a> referring to certain characters in the show, and the <a href=https://en.wikipedia.org/wiki/Non-physical_entity>entities</a> are collected from the list of all characters in those two seasons of the show. This <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is challenging because it requires the identification of characters that are mentioned but may not be active during the conversation. Among 90 + participants, four of them submitted their system outputs and showed strengths in different aspects about the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. Thorough analyses of the <a href=https://en.wikipedia.org/wiki/Distributed_database>distributed datasets</a>, <a href=https://en.wikipedia.org/wiki/System>system outputs</a>, and comparative studies are also provided. To facilitate the momentum, we create an open-source project for this task and publicly release a larger and cleaner dataset, hoping to support researchers for more enhanced modeling.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1008.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1008 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1008 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=S18-1008" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/S18-1008/>AMORE-UPF at SemEval-2018 Task 4 : BiLSTM with Entity Library<span class=acl-fixed-case>AMORE</span>-<span class=acl-fixed-case>UPF</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 4: <span class=acl-fixed-case>B</span>i<span class=acl-fixed-case>LSTM</span> with Entity Library</a></strong><br><a href=/people/l/laura-aina/>Laura Aina</a>
|
<a href=/people/c/carina-silberer/>Carina Silberer</a>
|
<a href=/people/i/ionut-sorodoc/>Ionut-Teodor Sorodoc</a>
|
<a href=/people/m/matthijs-westera/>Matthijs Westera</a>
|
<a href=/people/g/gemma-boleda/>Gemma Boleda</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1008><div class="card-body p-3 small">This paper describes our winning contribution to SemEval 2018 Task 4 : Character Identification on Multiparty Dialogues. It is a simple, standard <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> with one key innovation, an <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity library</a>. Our results show that this <a href=https://en.wikipedia.org/wiki/Innovation>innovation</a> greatly facilitates the identification of infrequent characters. Because of the generic nature of our model, this finding is potentially relevant to any task that requires the effective learning from sparse or imbalanced data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1010.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1010 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1010 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1010/>KOI at SemEval-2018 Task 5 : Building Knowledge Graph of Incidents<span class=acl-fixed-case>KOI</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 5: Building Knowledge Graph of Incidents</a></strong><br><a href=/people/p/paramita-mirza/>Paramita Mirza</a>
|
<a href=/people/f/fariz-darari/>Fariz Darari</a>
|
<a href=/people/r/rahmad-mahendra/>Rahmad Mahendra</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1010><div class="card-body p-3 small">We present KOI (Knowledge of Incidents), a system that given <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a> as input, builds a knowledge graph (KOI-KG) of incidental events. KOI-KG can then be used to efficiently answer questions such How many killing incidents happened in 2017 that involve Sean? The required steps in building the KG include : (i) document preprocessing involving <a href=https://en.wikipedia.org/wiki/Word-sense_disambiguation>word sense disambiguation</a>, <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named-entity recognition</a>, temporal expression recognition and normalization, and <a href=https://en.wikipedia.org/wiki/Semantic_role_labeling>semantic role labeling</a> ; (ii) incidental event extraction and coreference resolution via document clustering ; and (iii) KG construction and population.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1013.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1013 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1013 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1013/>NEUROSENT-PDI at SemEval-2018 Task 1 : Leveraging a Multi-Domain Sentiment Model for Inferring Polarity in Micro-blog Text<span class=acl-fixed-case>NEUROSENT</span>-<span class=acl-fixed-case>PDI</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Leveraging a Multi-Domain Sentiment Model for Inferring Polarity in Micro-blog Text</a></strong><br><a href=/people/m/mauro-dragoni/>Mauro Dragoni</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1013><div class="card-body p-3 small">This paper describes the NeuroSent system that participated in SemEval 2018 Task 1. Our <a href=https://en.wikipedia.org/wiki/System>system</a> takes a supervised approach that builds on <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> and <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a>. Word embeddings were built by starting from a repository of user generated reviews. Thus, they are specific for sentiment analysis tasks. Then, <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a> are converted in the corresponding <a href=https://en.wikipedia.org/wiki/Vector_graphics>vector representation</a> and given as input to the <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> with the aim of learning the different <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> contained in each emotion taken into account by the SemEval task. The output layer has been adapted based on the characteristics of each subtask. Preliminary results obtained on the provided <a href=https://en.wikipedia.org/wiki/Training_set>training set</a> are encouraging for pursuing the investigation into this direction.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1014.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1014 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1014/>FOI DSS at SemEval-2018 Task 1 : Combining LSTM States, Embeddings, and Lexical Features for Affect Analysis<span class=acl-fixed-case>FOI</span> <span class=acl-fixed-case>DSS</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Combining <span class=acl-fixed-case>LSTM</span> States, Embeddings, and Lexical Features for Affect Analysis</a></strong><br><a href=/people/m/maja-karasalo/>Maja Karasalo</a>
|
<a href=/people/m/mattias-nilsson/>Mattias Nilsson</a>
|
<a href=/people/m/magnus-rosell/>Magnus Rosell</a>
|
<a href=/people/u/ulrika-wickenberg-bolin/>Ulrika Wickenberg Bolin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1014><div class="card-body p-3 small">This paper describes the system used and results obtained for team FOI DSS at SemEval-2018 Task 1 : Affect In Tweets. The team participated in all English language subtasks, with a method utilizing transfer learning from LSTM nets trained on large sentiment datasets combined with embeddings and lexical features. For four out of five subtasks, the <a href=https://en.wikipedia.org/wiki/System>system</a> performed in the range of 92-95 % of the winning systems, in terms of the <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>competition metrics</a>. Analysis of the results suggests that improved <a href=https://en.wikipedia.org/wiki/Data_pre-processing>pre-processing</a> and addition of more <a href=https://en.wikipedia.org/wiki/Lexical_item>lexical features</a> may further elevate performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1015.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1015 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1015 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1015/>NLPZZX at SemEval-2018 Task 1 : Using Ensemble Method for Emotion and Sentiment Intensity Determination<span class=acl-fixed-case>NLPZZX</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Using Ensemble Method for Emotion and Sentiment Intensity Determination</a></strong><br><a href=/people/z/zhengxin-zhang/>Zhengxin Zhang</a>
|
<a href=/people/q/qimin-zhou/>Qimin Zhou</a>
|
<a href=/people/h/hao-wu/>Hao Wu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1015><div class="card-body p-3 small">In this paper, we put forward a <a href=https://en.wikipedia.org/wiki/System>system</a> that competed at SemEval-2018 Task 1 : Affect in Tweets. Our <a href=https://en.wikipedia.org/wiki/System>system</a> uses a simple yet effective <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensemble method</a> which combines several <a href=https://en.wikipedia.org/wiki/Neural_circuit>neural network components</a>. We participate in two subtasks for English tweets : EI-reg and V-reg. For two subtasks, different combinations of <a href=https://en.wikipedia.org/wiki/Neural_circuit>neural components</a> are examined. For EI-reg, our system achieves an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 0.727 in <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>Pearson Correlation Coefficient</a> (all instances) and an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 0.555 in <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>Pearson Correlation Coefficient</a> (0.5-1). For V-reg, the achieved accuracy scores are respectively 0.835 and 0.670</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1016.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1016 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1016 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1016/>LT3 at SemEval-2018 Task 1 : A classifier chain to detect emotions in tweets<span class=acl-fixed-case>LT</span>3 at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: A classifier chain to detect emotions in tweets</a></strong><br><a href=/people/l/luna-de-bruyne/>Luna De Bruyne</a>
|
<a href=/people/o/orphee-de-clercq/>Orphée De Clercq</a>
|
<a href=/people/v/veronique-hoste/>Véronique Hoste</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1016><div class="card-body p-3 small">This paper presents an emotion classification system for English tweets, submitted for the SemEval shared task on Affect in Tweets, subtask 5 : Detecting Emotions. The system combines <a href=https://en.wikipedia.org/wiki/Lexicon>lexicon</a>, <a href=https://en.wikipedia.org/wiki/N-gram>n-gram</a>, style, syntactic and semantic features. For this multi-class multi-label problem, we created a classifier chain. This is an ensemble of eleven <a href=https://en.wikipedia.org/wiki/Binary_classification>binary classifiers</a>, one for each possible <a href=https://en.wikipedia.org/wiki/Emotion_classification>emotion category</a>, where each model gets the predictions of the preceding models as additional <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a>. The predicted labels are combined to get a multi-label representation of the predictions. Our <a href=https://en.wikipedia.org/wiki/System>system</a> was ranked eleventh among thirty five participating teams, with a <a href=https://en.wikipedia.org/wiki/Jaccard>Jaccard accuracy</a> of 52.0 % and macro- and micro-average F1-scores of 49.3 % and 64.0 %, respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1017.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1017 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1017 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1017/>SINAI at SemEval-2018 Task 1 : Emotion Recognition in Tweets<span class=acl-fixed-case>SINAI</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Emotion Recognition in Tweets</a></strong><br><a href=/people/f/flor-miriam-plaza-del-arco/>Flor Miriam Plaza-del-Arco</a>
|
<a href=/people/s/salud-maria-jimenez-zafra/>Salud María Jiménez-Zafra</a>
|
<a href=/people/m/m-teresa-martin-valdivia/>Maite Martin</a>
|
<a href=/people/l/l-alfonso-urena-lopez/>L. Alfonso Ureña-López</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1017><div class="card-body p-3 small">Emotion classification is a new task that combines several disciplines including <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>Artificial Intelligence</a> and <a href=https://en.wikipedia.org/wiki/Psychology>Psychology</a>, although <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a> is perhaps the most challenging area. In this paper, we describe our participation in SemEval-2018 Task1 : Affect in Tweets. In particular, we have participated in EI-oc, EI-reg and E-c subtasks for English and Spanish languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1020.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1020 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1020 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1020/>INGEOTEC at SemEval-2018 Task 1 : EvoMSA and TC for Sentiment Analysis<span class=acl-fixed-case>INGEOTEC</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: <span class=acl-fixed-case>E</span>vo<span class=acl-fixed-case>MSA</span> and μ<span class=acl-fixed-case>TC</span> for Sentiment Analysis</a></strong><br><a href=/people/m/mario-graff/>Mario Graff</a>
|
<a href=/people/s/sabino-miranda-jimenez/>Sabino Miranda-Jiménez</a>
|
<a href=/people/e/eric-sadit-tellez/>Eric S. Tellez</a>
|
<a href=/people/d/daniela-moctezuma/>Daniela Moctezuma</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1020><div class="card-body p-3 small">This paper describes our participation in Affective Tweets task for emotional intensity and sentiment intensity subtasks for English, Spanish, and Arabic languages. We used two approaches, TC and EvoMSA. The first one is a generic text categorization and regression system ; and the second one, a two-stage architecture for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a>. Both approaches are multilingual and domain independent.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1024 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1024/>Tw-StAR at SemEval-2018 Task 1 : Preprocessing Impact on Multi-label Emotion Classification<span class=acl-fixed-case>S</span>t<span class=acl-fixed-case>AR</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Preprocessing Impact on Multi-label Emotion Classification</a></strong><br><a href=/people/h/hala-mulki/>Hala Mulki</a>
|
<a href=/people/c/chedi-bechikh-ali/>Chedi Bechikh Ali</a>
|
<a href=/people/h/hatem-haddad/>Hatem Haddad</a>
|
<a href=/people/i/ismail-babaoglu/>Ismail Babaoğlu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1024><div class="card-body p-3 small">In this paper, we describe our contribution in SemEval-2018 contest. We tackled task 1 Affect in <a href=https://en.wikipedia.org/wiki/Twitter>Tweets</a>, subtask E-c Detecting Emotions (multi-label classification). A multilabel classification system Tw-StAR was developed to recognize the emotions embedded in Arabic, English and Spanish tweets. To handle the multi-label classification problem via traditional classifiers, we employed the binary relevance transformation strategy while a TF-IDF scheme was used to generate the tweets&#8217; features. We investigated using single and combinations of several preprocessing tasks to further improve the performance. The results showed that specific combinations of preprocessing tasks could significantly improve the evaluation measures. This has been later emphasized by the official results as our system ranked 3rd for both Arabic and Spanish datasets and 14th for the English dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1026.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1026 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1026 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1026/>EmoIntens Tracker at SemEval-2018 Task 1 : Emotional Intensity Levels in # Tweets<span class=acl-fixed-case>E</span>mo<span class=acl-fixed-case>I</span>ntens Tracker at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Emotional Intensity Levels in #Tweets</a></strong><br><a href=/people/r/ramona-andreea-turcu/>Ramona-Andreea Turcu</a>
|
<a href=/people/s/sandra-maria-amarandei/>Sandra Maria Amarandei</a>
|
<a href=/people/i/iuliana-alexandra-flescan-lovin-arseni/>Iuliana-Alexandra Flescan-Lovin-Arseni</a>
|
<a href=/people/d/daniela-gifu/>Daniela Gifu</a>
|
<a href=/people/d/diana-trandabat/>Diana Trandabat</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1026><div class="card-body p-3 small">The Affect in Tweets task is centered on emotions categorization and evaluation matrix using multi-language tweets (English and Spanish). In this research, SemEval Affect dataset was preprocessed, categorized, and evaluated accordingly (precision, <a href=https://en.wikipedia.org/wiki/Recall_(memory)>recall</a>, and accuracy). The system described in this paper is based on the implementation of supervised machine learning (Naive Bayes, KNN and SVM), deep learning (NN Tensor Flow model), and decision trees algorithms.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1028.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1028 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1028 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1028/>THU_NGN at SemEval-2018 Task 1 : Fine-grained Tweet Sentiment Intensity Analysis with Attention CNN-LSTM<span class=acl-fixed-case>THU</span>_<span class=acl-fixed-case>NGN</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Fine-grained Tweet Sentiment Intensity Analysis with Attention <span class=acl-fixed-case>CNN</span>-<span class=acl-fixed-case>LSTM</span></a></strong><br><a href=/people/c/chuhan-wu/>Chuhan Wu</a>
|
<a href=/people/f/fangzhao-wu/>Fangzhao Wu</a>
|
<a href=/people/j/junxin-liu/>Junxin Liu</a>
|
<a href=/people/z/zhigang-yuan/>Zhigang Yuan</a>
|
<a href=/people/s/sixing-wu/>Sixing Wu</a>
|
<a href=/people/y/yongfeng-huang/>Yongfeng Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1028><div class="card-body p-3 small">Traditional sentiment analysis approaches mainly focus on classifying the sentiment polarities or emotion categories of texts. However, <a href=https://en.wikipedia.org/wiki/Information_technology>they</a> ca n&#8217;t exploit the <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment intensity information</a>. Therefore, the SemEval-2018 Task 1 is aimed to automatically determine the intensity of emotions or sentiment of tweets to mine fine-grained sentiment information. In order to address this task, we propose a <a href=https://en.wikipedia.org/wiki/System>system</a> based on an attention CNN-LSTM model. In our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>, LSTM is used to extract the long-term contextual information from texts. We apply <a href=https://en.wikipedia.org/wiki/Attentional_control>attention techniques</a> to selecting this <a href=https://en.wikipedia.org/wiki/Information>information</a>. A CNN layer with different size of kernels is used to extract local features. The dense layers take the pooled CNN feature maps and predict the intensity scores. Our system reaches average Pearson correlation score of 0.722 (ranked 12/48) in emotion intensity regression task, and 0.810 in valence regression task (ranked 15/38). It indicates that our <a href=https://en.wikipedia.org/wiki/System>system</a> can be further extended.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1029.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1029 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1029 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1029/>EiTAKA at SemEval-2018 Task 1 : An Ensemble of N-Channels ConvNet and XGboost Regressors for Emotion Analysis of Tweets<span class=acl-fixed-case>E</span>i<span class=acl-fixed-case>TAKA</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: An Ensemble of N-Channels <span class=acl-fixed-case>C</span>onv<span class=acl-fixed-case>N</span>et and <span class=acl-fixed-case>XG</span>boost Regressors for Emotion Analysis of Tweets</a></strong><br><a href=/people/m/mohammed-jabreel/>Mohammed Jabreel</a>
|
<a href=/people/a/antonio-moreno-ribas/>Antonio Moreno</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1029><div class="card-body p-3 small">This paper describes our <a href=https://en.wikipedia.org/wiki/System>system</a> that has been used in Task1 Affect in Tweets. We combine two different approaches. The first one called N-Stream ConvNets, which is a deep learning approach where the second one is XGboost regressor based on a set of embedding and lexicons based features. Our system was evaluated on the testing sets of the tasks outperforming all other approaches for the Arabic version of valence intensity regression task and valence ordinal classification task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1030.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1030 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1030 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1030/>CENTEMENT at SemEval-2018 Task 1 : Classification of Tweets using Multiple Thresholds with Self-correction and Weighted Conditional Probabilities<span class=acl-fixed-case>CENTEMENT</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Classification of Tweets using Multiple Thresholds with Self-correction and Weighted Conditional Probabilities</a></strong><br><a href=/people/t/tariq-ahmad/>Tariq Ahmad</a>
|
<a href=/people/a/allan-ramsay/>Allan Ramsay</a>
|
<a href=/people/h/hanady-ahmed/>Hanady Ahmed</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1030><div class="card-body p-3 small">In this paper we present our contribution to SemEval-2018, a classifier for classifying multi-label emotions of Arabic and English tweets. We attempted Affect in <a href=https://en.wikipedia.org/wiki/Twitter>Tweets</a>, specifically Task E-c : Detecting Emotions (multi-label classification). Our method is based on preprocessing the <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a> and creating <a href=https://en.wikipedia.org/wiki/Vector_space>word vectors</a> combined with a self correction step to remove <a href=https://en.wikipedia.org/wiki/Image_noise>noise</a>. We also make use of emotion specific thresholds. The final submission was selected upon the best performance achieved, selected when using a range of thresholds. Our system was evaluated on the Arabic and English datasets provided for the task by the competition organisers, where it ranked 2nd for the Arabic dataset (out of 14 entries) and 12th for the English dataset (out of 35 entries).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1031.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1031 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1031 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1031/>Yuan at SemEval-2018 Task 1 : Tweets Emotion Intensity Prediction using Ensemble Recurrent Neural Network<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Tweets Emotion Intensity Prediction using Ensemble Recurrent Neural Network</a></strong><br><a href=/people/m/min-wang/>Min Wang</a>
|
<a href=/people/x/xiaobing-zhou/>Xiaobing Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1031><div class="card-body p-3 small">We perform the LSTM and BiLSTM model for the emotion intensity prediction. We only join the third subtask in Task 1 : Affect in Tweets. Our system rank 6th among all the teams.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1033.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1033 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1033 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1033/>Amobee at SemEval-2018 Task 1 : GRU Neural Network with a CNN Attention Mechanism for Sentiment Classification<span class=acl-fixed-case>A</span>mobee at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: <span class=acl-fixed-case>GRU</span> Neural Network with a <span class=acl-fixed-case>CNN</span> Attention Mechanism for Sentiment Classification</a></strong><br><a href=/people/a/alon-rozental/>Alon Rozental</a>
|
<a href=/people/d/daniel-fleischer/>Daniel Fleischer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1033><div class="card-body p-3 small">This paper describes the participation of Amobee in the shared sentiment analysis task at SemEval 2018. We participated in all the English sub-tasks and the Spanish valence tasks. Our system consists of three parts : training task-specific word embeddings, training a model consisting of gated-recurrent-units (GRU) with a convolution neural network (CNN) attention mechanism and training stacking-based ensembles for each of the sub-tasks. Our <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> reached the 3rd and 1st places in the valence ordinal classification sub-tasks in <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>, respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1035.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1035 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1035 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1035/>ECNU at SemEval-2018 Task 1 : Emotion Intensity Prediction Using Effective Features and Machine Learning Models<span class=acl-fixed-case>ECNU</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Emotion Intensity Prediction Using Effective Features and Machine Learning Models</a></strong><br><a href=/people/h/huimin-xu/>Huimin Xu</a>
|
<a href=/people/m/man-lan/>Man Lan</a>
|
<a href=/people/y/yuanbin-wu/>Yuanbin Wu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1035><div class="card-body p-3 small">This paper describes our submissions to SemEval 2018 task 1. The <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is affect intensity prediction in <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a>, including five <a href=https://en.wikipedia.org/wiki/Task_(project_management)>subtasks</a>. We participated in all subtasks of <a href=https://en.wikipedia.org/wiki/Twitter>English tweets</a>. We extracted several traditional <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, sentiment lexicon, emotion lexicon and domain specific features from tweets, adopted supervised machine learning algorithms to perform emotion intensity prediction.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1037.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1037 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1037 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=S18-1037" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/S18-1037/>NTUA-SLP at SemEval-2018 Task 1 : Predicting Affective Content in Tweets with Deep Attentive RNNs and Transfer Learning<span class=acl-fixed-case>NTUA</span>-<span class=acl-fixed-case>SLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Predicting Affective Content in Tweets with Deep Attentive <span class=acl-fixed-case>RNN</span>s and Transfer Learning</a></strong><br><a href=/people/c/christos-baziotis/>Christos Baziotis</a>
|
<a href=/people/a/athanasiou-nikolaos/>Athanasiou Nikolaos</a>
|
<a href=/people/a/alexandra-chronopoulou/>Alexandra Chronopoulou</a>
|
<a href=/people/a/athanasia-kolovou/>Athanasia Kolovou</a>
|
<a href=/people/g/georgios-paraskevopoulos/>Georgios Paraskevopoulos</a>
|
<a href=/people/n/nikolaos-ellinas/>Nikolaos Ellinas</a>
|
<a href=/people/s/shrikanth-narayanan/>Shrikanth Narayanan</a>
|
<a href=/people/a/alexandros-potamianos/>Alexandros Potamianos</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1037><div class="card-body p-3 small">In this paper we present deep-learning models that submitted to the SemEval-2018 Task 1 competition : Affect in Tweets. We participated in all subtasks for <a href=https://en.wikipedia.org/wiki/Twitter>English tweets</a>. We propose a Bi-LSTM architecture equipped with a multi-layer self attention mechanism. The attention mechanism improves the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> performance and allows us to identify salient words in <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a>, as well as gain insight into the <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> making them more interpretable. Our model utilizes a set of word2vec word embeddings trained on a large collection of 550 million Twitter messages, augmented by a set of word affective features. Due to the limited amount of task-specific training data, we opted for a transfer learning approach by pretraining the Bi-LSTMs on the dataset of Semeval 2017, Task 4A. The proposed approach ranked 1st in Subtask E Multi-Label Emotion Classification, 2nd in Subtask A Emotion Intensity Regression and achieved competitive results in other subtasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1038.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1038 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1038 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1038/>CrystalFeel at SemEval-2018 Task 1 : Understanding and Detecting Emotion Intensity using Affective Lexicons<span class=acl-fixed-case>C</span>rystal<span class=acl-fixed-case>F</span>eel at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Understanding and Detecting Emotion Intensity using Affective Lexicons</a></strong><br><a href=/people/r/raj-kumar-gupta/>Raj Kumar Gupta</a>
|
<a href=/people/y/yinping-yang/>Yinping Yang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1038><div class="card-body p-3 small">While sentiment and emotion analysis has received a considerable amount of research attention, the notion of understanding and detecting the intensity of emotions is relatively less explored. This paper describes a <a href=https://en.wikipedia.org/wiki/System>system</a> developed for predicting emotion intensity in <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a>. Given a Twitter message, CrystalFeel uses features derived from parts-of-speech, n-grams, word embedding, and multiple affective lexicons including Opinion Lexicon, SentiStrength, AFFIN, NRC Emotion & Hash Emotion, and our in-house developed EI Lexicons to predict the degree of the intensity associated with fear, anger, sadness, and joy in the tweet. We found that including the affective lexicons-based features allowed the system to obtain strong prediction performance, while revealing interesting emotion word-level and message-level associations. On gold test data, CrystalFeel obtained <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>Pearson correlations</a> of 0.717 on average emotion intensity and of 0.816 on <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment intensity</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1039.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1039 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1039 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1039/>PlusEmo2Vec at SemEval-2018 Task 1 : Exploiting emotion knowledge from <a href=https://en.wikipedia.org/wiki/Emoji>emoji</a> and # hashtags<span class=acl-fixed-case>P</span>lus<span class=acl-fixed-case>E</span>mo2<span class=acl-fixed-case>V</span>ec at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Exploiting emotion knowledge from emoji and #hashtags</a></strong><br><a href=/people/j/ji-ho-park/>Ji Ho Park</a>
|
<a href=/people/p/peng-xu/>Peng Xu</a>
|
<a href=/people/p/pascale-fung/>Pascale Fung</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1039><div class="card-body p-3 small">This paper describes our <a href=https://en.wikipedia.org/wiki/System>system</a> that has been submitted to SemEval-2018 Task 1 : Affect in Tweets (AIT) to solve five subtasks. We focus on modeling both sentence and word level representations of emotion inside texts through large distantly labeled corpora with <a href=https://en.wikipedia.org/wiki/Emoji>emojis</a> and <a href=https://en.wikipedia.org/wiki/Hashtag>hashtags</a>. We transfer the emotional knowledge by exploiting neural network models as <a href=https://en.wikipedia.org/wiki/Feature_extraction>feature extractors</a> and use these representations for traditional machine learning models such as support vector regression (SVR) and <a href=https://en.wikipedia.org/wiki/Logistic_regression>logistic regression</a> to solve the competition tasks. Our <a href=https://en.wikipedia.org/wiki/System>system</a> is placed among the Top3 for all subtasks we participated.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1040.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1040 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1040 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1040/>YNU-HPCC at SemEval-2018 Task 1 : BiLSTM with Attention based Sentiment Analysis for Affect in Tweets<span class=acl-fixed-case>YNU</span>-<span class=acl-fixed-case>HPCC</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: <span class=acl-fixed-case>B</span>i<span class=acl-fixed-case>LSTM</span> with Attention based Sentiment Analysis for Affect in Tweets</a></strong><br><a href=/people/y/you-zhang/>You Zhang</a>
|
<a href=/people/j/jin-wang/>Jin Wang</a>
|
<a href=/people/x/xuejie-zhang/>Xuejie Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1040><div class="card-body p-3 small">We implemented the <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment system</a> in all five subtasks for <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>. All subtasks involve emotion or sentiment intensity prediction (regression and ordinal classification) and emotions determining (multi-labels classification). The useful BiLSTM (Bidirectional Long-Short Term Memory) model with attention mechanism was mainly applied for our <a href=https://en.wikipedia.org/wiki/System>system</a>. We use BiLSTM in order to get word information extracted from both directions. The attention mechanism was used to find the contribution of each word for improving the scores. Furthermore, based on BiLSTMATT (BiLSTM with attention mechanism) a few deep-learning algorithms were employed for different subtasks. For regression and ordinal classification tasks we used <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> and ensemble learning methods to leverage base model. While a single base model was used for <a href=https://en.wikipedia.org/wiki/Task_(computing)>multi-labels task</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1041.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1041 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1041 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1041/>UG18 at SemEval-2018 Task 1 : Generating Additional Training Data for Predicting Emotion Intensity in <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a><span class=acl-fixed-case>UG</span>18 at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Generating Additional Training Data for Predicting Emotion Intensity in <span class=acl-fixed-case>S</span>panish</a></strong><br><a href=/people/m/marloes-kuijper/>Marloes Kuijper</a>
|
<a href=/people/m/mike-van-lenthe/>Mike van Lenthe</a>
|
<a href=/people/r/rik-van-noord/>Rik van Noord</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1041><div class="card-body p-3 small">The present study describes our submission to SemEval 2018 Task 1 : Affect in <a href=https://en.wikipedia.org/wiki/Twitter>Tweets</a>. Our Spanish-only approach aimed to demonstrate that it is beneficial to automatically generate additional training data by (i) translating training data from other languages and (ii) applying a semi-supervised learning method. We find strong support for both approaches, with those <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> outperforming our regular models in all subtasks. However, creating a stepwise ensemble of different <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> as opposed to simply averaging did not result in an increase in performance. We placed second (EI-Reg), second (EI-Oc), fourth (V-Reg) and fifth (V-Oc) in the four Spanish subtasks we participated in.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1042.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1042 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1042 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1042/>ISCLAB at SemEval-2018 Task 1 : UIR-Miner for Affect in Tweets<span class=acl-fixed-case>ISCLAB</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: <span class=acl-fixed-case>UIR</span>-Miner for Affect in Tweets</a></strong><br><a href=/people/m/meng-li/>Meng Li</a>
|
<a href=/people/z/zhenyuan-dong/>Zhenyuan Dong</a>
|
<a href=/people/z/zhihao-fan/>Zhihao Fan</a>
|
<a href=/people/k/kongming-meng/>Kongming Meng</a>
|
<a href=/people/j/jinghua-cao/>Jinghua Cao</a>
|
<a href=/people/g/guanqi-ding/>Guanqi Ding</a>
|
<a href=/people/y/yuhan-liu/>Yuhan Liu</a>
|
<a href=/people/j/jiawei-shan/>Jiawei Shan</a>
|
<a href=/people/b/binyang-li/>Binyang Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1042><div class="card-body p-3 small">This paper presents a UIR-Miner system for emotion and sentiment analysis evaluation in <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> in SemEval 2018. Our system consists of three main modules : preprocessing module, stacking module to solve the intensity prediction of emotion and sentiment, LSTM network module to solve multi-label classification, and the hierarchical attention network module for solving emotion and sentiment classification problem. According to the <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> of SemEval 2018, our system gets the final scores of 0.636, 0.531, 0.731, 0.708, and 0.408 on 5 subtasks, respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1043.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1043 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1043 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1043/>TCS Research at SemEval-2018 Task 1 : Learning Robust Representations using Multi-Attention Architecture<span class=acl-fixed-case>TCS</span> Research at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Learning Robust Representations using Multi-Attention Architecture</a></strong><br><a href=/people/h/hardik-meisheri/>Hardik Meisheri</a>
|
<a href=/people/l/lipika-dey/>Lipika Dey</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1043><div class="card-body p-3 small">This paper presents system description of our submission to the SemEval-2018 task-1 : Affect in tweets for the <a href=https://en.wikipedia.org/wiki/English_language>English language</a>. We combine three different <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> generated using <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning models</a> and traditional methods in support vector machines to create a unified ensemble system. A robust representation of a tweet is learned using a multi-attention based architecture which uses a mixture of different pre-trained embeddings. In addition to this analysis of different <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> is also presented. Our <a href=https://en.wikipedia.org/wiki/System>system</a> ranked 2nd, 5th, and 7th in different subtasks among 75 teams.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1044.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1044 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1044 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1044/>DMCB at SemEval-2018 Task 1 : Transfer Learning of Sentiment Classification Using Group LSTM for Emotion Intensity prediction<span class=acl-fixed-case>DMCB</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Transfer Learning of Sentiment Classification Using Group <span class=acl-fixed-case>LSTM</span> for Emotion Intensity prediction</a></strong><br><a href=/people/y/youngmin-kim/>Youngmin Kim</a>
|
<a href=/people/h/hyunju-lee/>Hyunju Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1044><div class="card-body p-3 small">This paper describes a system attended in the SemEval-2018 Task 1 Affect in <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a> that predicts emotional intensities. We use Group LSTM with an attention model and <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> with sentiment classification data as a source data (SemEval 2017 Task 4a). A transfer model structure consists of a source domain and a target domain. Additionally, we try a new dropout that is applied to LSTMs in the Group LSTM. Our <a href=https://en.wikipedia.org/wiki/System>system</a> ranked 8th at the subtask 1a (emotion intensity regression). We also show various results with different <a href=https://en.wikipedia.org/wiki/Computer_architecture>architectures</a> in the source, target and transfer models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1045.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1045 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1045 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1045/>DeepMiner at SemEval-2018 Task 1 : Emotion Intensity Recognition Using <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Representation Learning</a><span class=acl-fixed-case>D</span>eep<span class=acl-fixed-case>M</span>iner at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Emotion Intensity Recognition Using Deep Representation Learning</a></strong><br><a href=/people/h/habibeh-naderi/>Habibeh Naderi</a>
|
<a href=/people/b/behrouz-haji-soleimani/>Behrouz Haji Soleimani</a>
|
<a href=/people/s/saif-mohammad/>Saif Mohammad</a>
|
<a href=/people/s/svetlana-kiritchenko/>Svetlana Kiritchenko</a>
|
<a href=/people/s/stan-matwin/>Stan Matwin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1045><div class="card-body p-3 small">In this paper, we propose a <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression system</a> to infer the emotion intensity of a tweet. We develop a multi-aspect feature learning mechanism to capture the most discriminative semantic features of a tweet as well as the emotion information conveyed by each word in it. We combine six types of feature groups : (1) a tweet representation learned by an LSTM deep neural network on the training data, (2) a tweet representation learned by an LSTM network on a large corpus of tweets that contain emotion words (a distant supervision corpus), (3) word embeddings trained on the distant supervision corpus and averaged over all words in a tweet, (4) word and character n-grams, (5) features derived from various sentiment and emotion lexicons, and (6) other hand-crafted features. As part of the word embedding training, we also learn the distributed representations of multi-word expressions (MWEs) and negated forms of words. An SVR regressor is then trained over the full set of <a href=https://en.wikipedia.org/wiki/Feature_(computer_vision)>features</a>. We evaluate the effectiveness of our ensemble feature sets on the SemEval-2018 Task 1 datasets and achieve a <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>Pearson correlation</a> of 72 % on the task of tweet emotion intensity prediction.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1046.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1046 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1046 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1046/>Zewen at SemEval-2018 Task 1 : An Ensemble Model for Affect Prediction in Tweets<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: An Ensemble Model for Affect Prediction in Tweets</a></strong><br><a href=/people/z/zewen-chi/>Zewen Chi</a>
|
<a href=/people/h/he-yan-huang/>Heyan Huang</a>
|
<a href=/people/j/jiangui-chen/>Jiangui Chen</a>
|
<a href=/people/h/hao-wu/>Hao Wu</a>
|
<a href=/people/r/ran-wei/>Ran Wei</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1046><div class="card-body p-3 small">This paper presents a method for Affect in Tweets, which is the task to automatically determine the intensity of emotions and intensity of sentiment of tweets. The term <a href=https://en.wikipedia.org/wiki/Affect_(psychology)>affect</a> refers to emotion-related categories such as <a href=https://en.wikipedia.org/wiki/Anger>anger</a>, <a href=https://en.wikipedia.org/wiki/Fear>fear</a>, etc. Intensity of emo-tions need to be quantified into a real valued score in [ 0, 1 ]. We propose an en-semble system including four different deep learning methods which are CNN, Bidirectional LSTM (BLSTM), LSTM-CNN and a CNN-based Attention model (CA). Our system gets an <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>average Pearson correlation score</a> of 0.682 in the subtask EI-reg and an <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>average Pearson correlation score</a> of 0.784 in subtask V-reg, which ranks 17th among 48 systems in EI-reg and 19th among 38 systems in V-reg.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1055.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1055 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1055 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1055/>ARB-SEN at SemEval-2018 Task1 : A New Set of Features for Enhancing the Sentiment Intensity Prediction in Arabic Tweets<span class=acl-fixed-case>ARB</span>-<span class=acl-fixed-case>SEN</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task1: A New Set of Features for Enhancing the Sentiment Intensity Prediction in <span class=acl-fixed-case>A</span>rabic Tweets</a></strong><br><a href=/people/e/el-moatez-billah-nagoudi/>El Moatez Billah Nagoudi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1055><div class="card-body p-3 small">This article describes our proposed Arabic Sentiment Analysis system named ARB-SEN. This system is designed for the International Workshop on Semantic Evaluation 2018 (SemEval-2018), Task1 : Affect in Tweets. ARB-SEN proposes two <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised models</a> to estimate the <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment intensity</a> in <a href=https://en.wikipedia.org/wiki/Twitter>Arabic tweets</a>. Both models use a set of features including sentiment lexicon, <a href=https://en.wikipedia.org/wiki/Affirmation_and_negation>negation</a>, <a href=https://en.wikipedia.org/wiki/Word_embedding>word embedding</a> and emotion symbols features. Our <a href=https://en.wikipedia.org/wiki/System>system</a> combines these <a href=https://en.wikipedia.org/wiki/Software_feature>features</a> to assist the <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis task</a>. ARB-SEN system achieves a <a href=https://en.wikipedia.org/wiki/Correlation_and_dependence>correlation score</a> of 0.720, ranking 6th among all participants in the valence intensity regression (V-reg) for the Arabic sub-task organized within the SemEval 2018 evaluation campaign.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1056.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1056 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1056 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1056/>psyML at SemEval-2018 Task 1 : Transfer Learning for Sentiment and Emotion Analysis<span class=acl-fixed-case>ML</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Transfer Learning for Sentiment and Emotion Analysis</a></strong><br><a href=/people/g/grace-gee/>Grace Gee</a>
|
<a href=/people/e/eugene-wang/>Eugene Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1056><div class="card-body p-3 small">In this paper, we describe the first attempt to perform <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> from <a href=https://en.wikipedia.org/wiki/Sentimentality>sentiment</a> to <a href=https://en.wikipedia.org/wiki/Emotion>emotions</a>. Our system employs Long Short-Term Memory (LSTM) networks, including bidirectional LSTM (biLSTM) and LSTM with attention mechanism. We perform <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> by first pre-training the LSTM networks on <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment data</a> before concatenating the penultimate layers of these <a href=https://en.wikipedia.org/wiki/Computer_network>networks</a> into a single vector as input to new dense layers. For the E-c subtask, we utilize a novel approach to train <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> for correlated emotion classes. Our system performs 4/48, 3/39, 8/38, 4/37, 4/35 on all English subtasks EI-reg, EI-oc, V-reg, V-oc, E-c of SemEval 2018 Task 1 : Affect in Tweets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1057.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1057 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1057 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1057/>UIUC at SemEval-2018 Task 1 : Recognizing Affect with Ensemble Models<span class=acl-fixed-case>UIUC</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Recognizing Affect with Ensemble Models</a></strong><br><a href=/people/a/abhishek-avinash-narwekar/>Abhishek Avinash Narwekar</a>
|
<a href=/people/r/roxana-girju/>Roxana Girju</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1057><div class="card-body p-3 small">Our submission to the SemEval-2018 Task1 : Affect in Tweets shared task competition is a supervised learning model relying on standard lexicon features coupled with word embedding features. We used an ensemble of diverse models, including <a href=https://en.wikipedia.org/wiki/Random_forest>random forests</a>, gradient boosted trees, and <a href=https://en.wikipedia.org/wiki/Linear_model>linear models</a>, corrected for training-development set mismatch. We submitted the system&#8217;s output for subtasks 1 (emotion intensity prediction), 2 (emotion ordinal classification), 3 (valence intensity regression) and 4 (valence ordinal classification), for English tweets. We placed 25th, 19th, 24th and 15th in the four subtasks respectively. The baseline considered was an SVM (Support Vector Machines) model with linear kernel on the lexicon and embedding based features. Our <a href=https://en.wikipedia.org/wiki/System>system</a>&#8217;s final performance measured in <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>Pearson correlation scores</a> outperformed the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> by a margin of 2.2 % to 14.6 % across all tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1058.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1058 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1058 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1058/>KU-MTL at SemEval-2018 Task 1 : Multi-task Identification of Affect in Tweets<span class=acl-fixed-case>KU</span>-<span class=acl-fixed-case>MTL</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 1: Multi-task Identification of Affect in Tweets</a></strong><br><a href=/people/t/thomas-nyegaard-signori/>Thomas Nyegaard-Signori</a>
|
<a href=/people/c/casper-veistrup-helms/>Casper Veistrup Helms</a>
|
<a href=/people/j/johannes-bjerva/>Johannes Bjerva</a>
|
<a href=/people/i/isabelle-augenstein/>Isabelle Augenstein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1058><div class="card-body p-3 small">We take a multi-task learning approach to the shared Task 1 at SemEval-2018. The general idea concerning the model structure is to use as little external data as possible in order to preserve the task relatedness and reduce <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a>. We employ <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a> with hard parameter sharing to exploit the relatedness between sub-tasks. As a base model, we use a standard <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network</a> for both the classification and regression subtasks. Our system ranks 32nd out of 48 participants with a <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>Pearson score</a> of 0.557 in the first subtask, and 20th out of 35 in the fifth subtask with an accuracy score of 0.464.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1059.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1059 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1059 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1059/>EmoNLP at SemEval-2018 Task 2 : English Emoji Prediction with Gradient Boosting Regression Tree Method and Bidirectional LSTM<span class=acl-fixed-case>E</span>mo<span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 2: <span class=acl-fixed-case>E</span>nglish Emoji Prediction with Gradient Boosting Regression Tree Method and Bidirectional <span class=acl-fixed-case>LSTM</span></a></strong><br><a href=/people/m/man-liu/>Man Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1059><div class="card-body p-3 small">This paper describes our <a href=https://en.wikipedia.org/wiki/System>system</a> used in the English Emoji Prediction Task 2 at the SemEval-2018. Our system is based on two supervised machine learning algorithms : Gradient Boosting Regression Tree Method (GBM) and Bidirectional Long Short-term Memory Network (BLSTM). Besides the common features, we extract various lexicon and syntactic features from external resources. After comparing the results of two <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a>, GBM is chosen for the final evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1060.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1060 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1060 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1060/>UMDSub at SemEval-2018 Task 2 : Multilingual Emoji Prediction Multi-channel Convolutional Neural Network on Subword Embedding<span class=acl-fixed-case>UMDS</span>ub at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 2: Multilingual Emoji Prediction Multi-channel Convolutional Neural Network on Subword Embedding</a></strong><br><a href=/people/z/zhenduo-wang/>Zhenduo Wang</a>
|
<a href=/people/t/ted-pedersen/>Ted Pedersen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1060><div class="card-body p-3 small">This paper describes the UMDSub system that participated in Task 2 of SemEval-2018. We developed a system that predicts an <a href=https://en.wikipedia.org/wiki/Emoji>emoji</a> given the raw text in a English tweet. The system is a Multi-channel Convolutional Neural Network based on subword embeddings for the representation of tweets. This <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> improves on character or word based methods by about 2 %. Our <a href=https://en.wikipedia.org/wiki/System>system</a> placed 21st of 48 participating systems in the official evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1061.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1061 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1061 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1061/>UMDuluth-CS8761 at SemEval-2018 Task 2 : Emojis : Too many Choices?<span class=acl-fixed-case>UMD</span>uluth-<span class=acl-fixed-case>CS</span>8761 at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 2: Emojis: Too many Choices?</a></strong><br><a href=/people/j/jonathan-beaulieu/>Jonathan Beaulieu</a>
|
<a href=/people/d/dennis-asamoah-owusu/>Dennis Asamoah Owusu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1061><div class="card-body p-3 small">In this paper, we present our system for assigning an <a href=https://en.wikipedia.org/wiki/Emoji>emoji</a> to a tweet based on the text. Each tweet was originally posted with an <a href=https://en.wikipedia.org/wiki/Emoji>emoji</a> which the task providers removed. Our task was to decide out of 20 <a href=https://en.wikipedia.org/wiki/Emoji>emojis</a>, which originally came with the tweet. Two <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> were provided-one in <a href=https://en.wikipedia.org/wiki/English_language>English</a> and the other in <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>. We treated the <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a> as a standard classification task with the emojis as our classes and the tweets as our documents. Our best performing system used a <a href=https://en.wikipedia.org/wiki/Bag_of_words_model>Bag of Words model</a> with a Linear Support Vector Machine as its&#8217; classifier. We achieved a macro F1 score of 32.73 % for the English data and 17.98 % for the Spanish data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1063.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1063 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1063 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1063/>THU_NGN at SemEval-2018 Task 2 : Residual CNN-LSTM Network with Attention for English Emoji Prediction<span class=acl-fixed-case>THU</span>_<span class=acl-fixed-case>NGN</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 2: Residual <span class=acl-fixed-case>CNN</span>-<span class=acl-fixed-case>LSTM</span> Network with Attention for <span class=acl-fixed-case>E</span>nglish Emoji Prediction</a></strong><br><a href=/people/c/chuhan-wu/>Chuhan Wu</a>
|
<a href=/people/f/fangzhao-wu/>Fangzhao Wu</a>
|
<a href=/people/s/sixing-wu/>Sixing Wu</a>
|
<a href=/people/z/zhigang-yuan/>Zhigang Yuan</a>
|
<a href=/people/j/junxin-liu/>Junxin Liu</a>
|
<a href=/people/y/yongfeng-huang/>Yongfeng Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1063><div class="card-body p-3 small">Emojis are widely used by <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> and social network users when posting their messages. It is important to study the relationships between messages and <a href=https://en.wikipedia.org/wiki/Emoji>emojis</a>. Thus, in SemEval-2018 Task 2 an interesting and challenging <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is proposed, i.e., predicting which <a href=https://en.wikipedia.org/wiki/Emoji>emojis</a> are evoked by <a href=https://en.wikipedia.org/wiki/Twitter>text-based tweets</a>. We propose a residual CNN-LSTM with attention (RCLA) model for this task. Our model combines CNN and LSTM layers to capture both local and long-range contextual information for tweet representation. In addition, attention mechanism is used to select important components. Besides, residual connection is applied to CNN layers to facilitate the training of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>. We also incorporated additional <a href=https://en.wikipedia.org/wiki/Software_feature>features</a> such as POS tags and sentiment features extracted from <a href=https://en.wikipedia.org/wiki/Lexicon>lexicons</a>. Our model achieved 30.25 % macro-averaged F-score in the first subtask (i.e., emoji prediction in English), ranking 7th out of 48 participants.<b>RCLA</b>) model\n for this task. Our model combines CNN and LSTM layers to capture\n both local and long-range contextual information for tweet\n representation. In addition, attention mechanism is used to\n select important components. Besides, residual connection is\n applied to CNN layers to facilitate the training of neural\n networks. We also incorporated additional features such as POS\n tags and sentiment features extracted from lexicons. Our model\n achieved 30.25% macro-averaged F-score in the first subtask\n (i.e., emoji prediction in English), ranking 7th out of 48\n participants.\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1064.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1064 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1064 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1064/># TeamINF at SemEval-2018 Task 2 : Emoji Prediction in Tweets<span class=acl-fixed-case>T</span>eam<span class=acl-fixed-case>INF</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 2: Emoji Prediction in Tweets</a></strong><br><a href=/people/a/alison-ribeiro/>Alison Ribeiro</a>
|
<a href=/people/n/nadia-silva/>Nádia Silva</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1064><div class="card-body p-3 small">In this paper, we describe a <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> to predict <a href=https://en.wikipedia.org/wiki/Emoji>emoji</a> in <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a>. Our approach is based on the classic <a href=https://en.wikipedia.org/wiki/Bag-of-words_model>bag-of-words model</a> in conjunction with <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a>. The used <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification algorithm</a> was <a href=https://en.wikipedia.org/wiki/Logistic_regression>Logistic Regression</a>. This <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> was used and evaluated in the context of the SemEval 2018 challenge (task 2, subtask 1).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1065.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1065 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1065 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1065/>EICA Team at SemEval-2018 Task 2 : Semantic and Metadata-based Features for Multilingual Emoji Prediction<span class=acl-fixed-case>EICA</span> Team at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 2: Semantic and Metadata-based Features for Multilingual Emoji Prediction</a></strong><br><a href=/people/y/yufei-xie/>Yufei Xie</a>
|
<a href=/people/q/qingqing-song/>Qingqing Song</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1065><div class="card-body p-3 small">The advent of <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> has brought along a novel way of communication where <a href=https://en.wikipedia.org/wiki/Meaning_(linguistics)>meaning</a> is composed by combining short text messages and visual enhancements, the so-called <a href=https://en.wikipedia.org/wiki/Emoji>emojis</a>. We describe our <a href=https://en.wikipedia.org/wiki/System>system</a> for participating in SemEval-2018 Task 2 on Multilingual Emoji Prediction. Our approach relies on combining a rich set of various types of <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> : <a href=https://en.wikipedia.org/wiki/Semantic_Web>semantic</a> and <a href=https://en.wikipedia.org/wiki/Metadata>metadata</a>. The most important types turned out to be the <a href=https://en.wikipedia.org/wiki/Metadata>metadata feature</a>. In subtask 1 : Emoji Prediction in <a href=https://en.wikipedia.org/wiki/English_language>English</a>, our primary submission obtain a <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>MAP</a> of 16.45, <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>Precision</a> of 31.557, <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>Recall</a> of 16.771 and <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>Accuracy</a> of 30.992.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1066.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1066 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1066 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/S18-1066.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/S18-1066/>EmojiIt at SemEval-2018 Task 2 : An Effective Attention-Based Recurrent Neural Network Model for Emoji Prediction with Characters Gated Words<span class=acl-fixed-case>E</span>moji<span class=acl-fixed-case>I</span>t at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 2: An Effective Attention-Based Recurrent Neural Network Model for Emoji Prediction with Characters Gated Words</a></strong><br><a href=/people/s/shiyun-chen/>Shiyun Chen</a>
|
<a href=/people/m/maoquan-wang/>Maoquan Wang</a>
|
<a href=/people/l/liang-he/>Liang He</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1066><div class="card-body p-3 small">This paper presents our single model to Subtask 1 of SemEval 2018 Task 2 : Emoji Prediction in <a href=https://en.wikipedia.org/wiki/English_language>English</a>. In order to predict the <a href=https://en.wikipedia.org/wiki/Emoji>emoji</a> that may be contained in a tweet, the basic model we use is an attention-based recurrent neural network which has achieved satisfactory performs in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language processing</a>. Considering the text comes from <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>, it contains many discrepant abbreviations and online terms, we also combine word-level and character-level word vector embedding to better handling the words not appear in the vocabulary. Our single model1 achieved 29.50 % Macro F-score in test data and ranks 9th among 48 teams.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1067.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1067 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1067 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1067/>Peperomia at SemEval-2018 Task 2 : Vector Similarity Based Approach for Emoji Prediction<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 2: Vector Similarity Based Approach for Emoji Prediction</a></strong><br><a href=/people/j/jing-chen/>Jing Chen</a>
|
<a href=/people/d/dechuan-yang/>Dechuan Yang</a>
|
<a href=/people/x/xilian-li/>Xilian Li</a>
|
<a href=/people/w/wei-chen/>Wei Chen</a>
|
<a href=/people/t/tengjiao-wang/>Tengjiao Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1067><div class="card-body p-3 small">This paper describes our participation in SemEval 2018 Task 2 : Multilingual Emoji Prediction, in which participants are asked to predict a tweet&#8217;s most associated <a href=https://en.wikipedia.org/wiki/Emoji>emoji</a> from 20 emojis. Instead of regarding <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> as a 20-class classification problem we regard <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> as a text similarity problem. We propose a vector similarity based approach for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. First the distributed representation (tweet vector) for each tweet is generated, then the similarity between this tweet vector and each emoji&#8217;s embedding is evaluated. The most similar <a href=https://en.wikipedia.org/wiki/Emoji>emoji</a> is chosen as the predicted label. Experimental results show that our approach performs comparably with the classification approach and shows its advantage in classifying <a href=https://en.wikipedia.org/wiki/Emoji>emojis</a> with similar semantic meaning.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1069.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1069 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1069 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=S18-1069" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/S18-1069/>NTUA-SLP at SemEval-2018 Task 2 : Predicting Emojis using RNNs with Context-aware Attention<span class=acl-fixed-case>NTUA</span>-<span class=acl-fixed-case>SLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 2: Predicting Emojis using <span class=acl-fixed-case>RNN</span>s with Context-aware Attention</a></strong><br><a href=/people/c/christos-baziotis/>Christos Baziotis</a>
|
<a href=/people/a/athanasiou-nikolaos/>Athanasiou Nikolaos</a>
|
<a href=/people/a/athanasia-kolovou/>Athanasia Kolovou</a>
|
<a href=/people/g/georgios-paraskevopoulos/>Georgios Paraskevopoulos</a>
|
<a href=/people/n/nikolaos-ellinas/>Nikolaos Ellinas</a>
|
<a href=/people/a/alexandros-potamianos/>Alexandros Potamianos</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1069><div class="card-body p-3 small">In this paper we present a <a href=https://en.wikipedia.org/wiki/Deep_learning>deep-learning model</a> that competed at SemEval-2018 Task 2 Multilingual Emoji Prediction. We participated in subtask A, in which we are called to predict the most likely associated emoji in English tweets. The proposed architecture relies on a Long Short-Term Memory network, augmented with an attention mechanism, that conditions the weight of each word, on a context vector which is taken as the aggregation of a tweet&#8217;s meaning. Moreover, we initialize the embedding layer of our model, with word2vec word embeddings, pretrained on a dataset of 550 million English tweets. Finally, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> does not rely on hand-crafted features or <a href=https://en.wikipedia.org/wiki/Lexicon>lexicons</a> and is trained end-to-end with <a href=https://en.wikipedia.org/wiki/Backpropagation>back-propagation</a>. We ranked 2nd out of 48 teams.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1070.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1070 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1070 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1070/>Hatching Chick at SemEval-2018 Task 2 : Multilingual Emoji Prediction<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 2: Multilingual Emoji Prediction</a></strong><br><a href=/people/j/joel-coster/>Joël Coster</a>
|
<a href=/people/r/reinder-gerard-van-dalen/>Reinder Gerard van Dalen</a>
|
<a href=/people/n/nathalie-adrienne-jacqueline-stierman/>Nathalie Adriënne Jacqueline Stierman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1070><div class="card-body p-3 small">As part of a SemEval 2018 shared task an attempt was made to build a system capable of predicting the occurence of a language&#8217;s most frequently used <a href=https://en.wikipedia.org/wiki/Emoji>emoji</a> in Tweets. Specifically, <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> for English and Spanish data were created and trained on 500.000 and 100.000 tweets respectively. In order to create these models, first a <a href=https://en.wikipedia.org/wiki/Logistic_regression>logistic regressor</a>, a sequential LSTM, a random forest regressor and a SVM were tested. The <a href=https://en.wikipedia.org/wiki/Second-generation_programming_language>latter</a> was found to perform best and therefore optimized individually for both languages. During developmet <a href=https://en.wikipedia.org/wiki/F-number>f1-scores</a> of 61 and 82 were obtained for English and Spanish data respectively, in comparison, <a href=https://en.wikipedia.org/wiki/F-number>f1-scores</a> on the official evaluation data were 21 and 18. The significant decrease in performance during <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation</a> might be explained by <a href=https://en.wikipedia.org/wiki/Overfitting>overfitting</a> during development and might therefore have partially be prevented by using <a href=https://en.wikipedia.org/wiki/Cross-validation_(statistics)>cross-validation</a>. Over all, <a href=https://en.wikipedia.org/wiki/Emoji>emoji</a> which occur in a very specific context such as a <a href=https://en.wikipedia.org/wiki/Christmas_tree>Christmas tree</a> were found to be most predictable.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1071.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1071 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1071 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/S18-1071.Notes.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/S18-1071/>EPUTION at SemEval-2018 Task 2 : Emoji Prediction with User Adaption<span class=acl-fixed-case>EPUTION</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 2: Emoji Prediction with User Adaption</a></strong><br><a href=/people/l/liyuan-zhou/>Liyuan Zhou</a>
|
<a href=/people/q/qiongkai-xu/>Qiongkai Xu</a>
|
<a href=/people/h/hanna-suominen/>Hanna Suominen</a>
|
<a href=/people/t/tom-gedeon/>Tom Gedeon</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1071><div class="card-body p-3 small">This paper describes our approach, called EPUTION, for the open trial of the SemEval- 2018 Task 2, Multilingual Emoji Prediction. The task relates to using <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> more precisely, <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> with its aim to predict the most likely associated <a href=https://en.wikipedia.org/wiki/Emoji>emoji</a> of a tweet. Our solution for this text classification problem explores the idea of <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> for adapting the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> based on users&#8217; tweeting history. Our experiments show that our user-adaption method improves <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> results by more than 6 per cent on the macro-averaged F1. Thus, our paper provides evidence for the rationality of enriching the original <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> longitudinally with user behaviors and transferring the lessons learned from corresponding users to specific instances.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1072.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1072 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1072 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1072/>PickleTeam ! at SemEval-2018 Task 2 : English and Spanish Emoji Prediction from Tweets<span class=acl-fixed-case>P</span>ickle<span class=acl-fixed-case>T</span>eam! at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 2: <span class=acl-fixed-case>E</span>nglish and <span class=acl-fixed-case>S</span>panish Emoji Prediction from Tweets</a></strong><br><a href=/people/d/daphne-groot/>Daphne Groot</a>
|
<a href=/people/r/remon-kruizinga/>Rémon Kruizinga</a>
|
<a href=/people/h/hennie-veldthuis/>Hennie Veldthuis</a>
|
<a href=/people/s/simon-de-wit/>Simon de Wit</a>
|
<a href=/people/h/hessel-haagsma/>Hessel Haagsma</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1072><div class="card-body p-3 small">We present a system for emoji prediction on English and Spanish tweets, prepared for the SemEval-2018 task on Multilingual Emoji Prediction. We compared the performance of an SVM, LSTM and an <a href=https://en.wikipedia.org/wiki/Musical_ensemble>ensemble</a> of these two. We found the <a href=https://en.wikipedia.org/wiki/Speech_recognition>SVM</a> performed best on our development set with an accuracy of 61.3 % for <a href=https://en.wikipedia.org/wiki/English_language>English</a> and 83 % for <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>. The features used for the SVM are lowercased word n-grams in the range of 1 to 20, tokenised by a TweetTokenizer and stripped of stop words. On the test set, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieved an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 34 % on <a href=https://en.wikipedia.org/wiki/English_language>English</a>, with a slightly lower score of 29.7 % accuracy on <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1073.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1073 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1073 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1073/>YNU-HPCC at SemEval-2018 Task 2 : Multi-ensemble Bi-GRU Model with Attention Mechanism for Multilingual Emoji Prediction<span class=acl-fixed-case>YNU</span>-<span class=acl-fixed-case>HPCC</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 2: Multi-ensemble <span class=acl-fixed-case>B</span>i-<span class=acl-fixed-case>GRU</span> Model with Attention Mechanism for Multilingual Emoji Prediction</a></strong><br><a href=/people/n/nan-wang/>Nan Wang</a>
|
<a href=/people/j/jin-wang/>Jin Wang</a>
|
<a href=/people/x/xuejie-zhang/>Xuejie Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1073><div class="card-body p-3 small">This paper describes our approach to SemEval-2018 Task 2, which aims to predict the most likely associated <a href=https://en.wikipedia.org/wiki/Emoji>emoji</a>, given a tweet in <a href=https://en.wikipedia.org/wiki/English_language>English</a> or <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>. We normalized text-based tweets during pre-processing, following which we utilized a bi-directional gated recurrent unit with an attention mechanism to build our base model. Multi-models with or without class weights were trained for the <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensemble methods</a>. We boosted models without <a href=https://en.wikipedia.org/wiki/Weight_function>class weights</a>, and only strong boost classifiers were identified. In our <a href=https://en.wikipedia.org/wiki/System>system</a>, not only was a boosting method used, but we also took advantage of the voting ensemble method to enhance our final <a href=https://en.wikipedia.org/wiki/System>system</a> result. Our method demonstrated an obvious improvement of approximately 3 % of the macro F1 score in <a href=https://en.wikipedia.org/wiki/English_language>English</a> and 2 % in <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1074.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1074 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1074 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1074/>DUTH at SemEval-2018 Task 2 : Emoji Prediction in Tweets<span class=acl-fixed-case>DUTH</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 2: Emoji Prediction in Tweets</a></strong><br><a href=/people/d/dimitrios-effrosynidis/>Dimitrios Effrosynidis</a>
|
<a href=/people/g/georgios-peikos/>Georgios Peikos</a>
|
<a href=/people/s/symeon-symeonidis/>Symeon Symeonidis</a>
|
<a href=/people/a/avi-arampatzis/>Avi Arampatzis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1074><div class="card-body p-3 small">This paper describes the approach that was developed for SemEval 2018 Task 2 (Multilingual Emoji Prediction) by the DUTH Team. First, we employed a combination of pre-processing techniques to reduce the noise of tweets and produce a number of features. Then, we built several <a href=https://en.wikipedia.org/wiki/N-gram>N-grams</a>, to represent the combination of word and emojis. Finally, we trained our <a href=https://en.wikipedia.org/wiki/System>system</a> with a tuned LinearSVC classifier. Our approach in the <a href=https://en.wikipedia.org/wiki/2010_FIFA_World_Cup>leaderboard</a> ranked 18th amongst 48 teams.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1077.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1077 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1077 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=S18-1077" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/S18-1077/>Duluth UROP at SemEval-2018 Task 2 : Multilingual Emoji Prediction with Ensemble Learning and Oversampling<span class=acl-fixed-case>D</span>uluth <span class=acl-fixed-case>UROP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 2: Multilingual Emoji Prediction with Ensemble Learning and Oversampling</a></strong><br><a href=/people/s/shuning-jin/>Shuning Jin</a>
|
<a href=/people/t/ted-pedersen/>Ted Pedersen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1077><div class="card-body p-3 small">This paper describes the Duluth UROP systems that participated in SemEval2018 Task 2, Multilingual Emoji Prediction. We relied on a variety of ensembles made up of classifiers using <a href=https://en.wikipedia.org/wiki/Naive_Bayes_classifier>Naive Bayes</a>, <a href=https://en.wikipedia.org/wiki/Logistic_regression>Logistic Regression</a>, and Random Forests. We used unigram and bigram features and tried to offset the <a href=https://en.wikipedia.org/wiki/Skewness>skewness</a> of the data through the use of oversampling. Our task evaluation results place us 19th of 48 systems in the <a href=https://en.wikipedia.org/wiki/English_language>English evaluation</a>, and 5th of 21 in the <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>. After the evaluation we realized that some simple changes to our pre-processing could significantly improve our results. After making these changes we attained results that would have placed us sixth in the <a href=https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language>English evaluation</a>, and second in the <a href=https://en.wikipedia.org/wiki/Spanish_as_a_second_or_foreign_language>Spanish</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1078.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1078 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1078 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1078/>CENNLP at SemEval-2018 Task 2 : Enhanced Distributed Representation of Text using Target Classes for Emoji Prediction Representation<span class=acl-fixed-case>CENNLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 2: Enhanced Distributed Representation of Text using Target Classes for Emoji Prediction Representation</a></strong><br><a href=/people/n/naveen-j-r/>Naveen J R</a>
|
<a href=/people/h/hariharan-v/>Hariharan V</a>
|
<a href=/people/b/barathi-ganesh-h-b/>Barathi Ganesh H. B.</a>
|
<a href=/people/a/anand-kumar-m/>Anand Kumar M</a>
|
<a href=/people/s/soman-k-p/>Soman K P</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1078><div class="card-body p-3 small">Emoji is one of the fastest growing language in <a href=https://en.wikipedia.org/wiki/Popular_culture>pop-culture</a>, especially in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> and it is very unlikely for its usage to decrease. These are generally used to bring an extra level of meaning to the texts, posted on <a href=https://en.wikipedia.org/wiki/Social_media>social media platforms</a>. Providing such an added info, gives more insights to the <a href=https://en.wikipedia.org/wiki/Plain_text>plain text</a>, arising to hidden interpretation within the text. This paper explains our analysis on Task 2, Multilingual Emoji Prediction sharedtask conducted by Semeval-2018. In the task, a predicted <a href=https://en.wikipedia.org/wiki/Emoji>emoji</a> based on a piece of Twitter text are labelled under 20 different classes (most commonly used emojis) where these <a href=https://en.wikipedia.org/wiki/Class_(computer_programming)>classes</a> are learnt and further predicted are made for unseen Twitter text. In this work, we have experimented and analysed emojis predicted based on Twitter text, as a classification problem where the entailing <a href=https://en.wikipedia.org/wiki/Emoji>emoji</a> is considered as a label for every individual text data. We have implemented this using distributed representation of text through <a href=https://en.wikipedia.org/wiki/FastText>fastText</a>. Also, we have made an effort to demonstrate how fastText framework can be useful in case of emoji prediction. This <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is divide into two subtask, they are based on dataset presented in two different languages English and <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1081.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1081 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1081 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1081/>LIS at SemEval-2018 Task 2 : Mixing Word Embeddings and Bag of Features for Multilingual Emoji Prediction<span class=acl-fixed-case>LIS</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 2: Mixing Word Embeddings and Bag of Features for Multilingual Emoji Prediction</a></strong><br><a href=/people/g/gael-guibon/>Gaël Guibon</a>
|
<a href=/people/m/magalie-ochs/>Magalie Ochs</a>
|
<a href=/people/p/patrice-bellot/>Patrice Bellot</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1081><div class="card-body p-3 small">In this paper we present the <a href=https://en.wikipedia.org/wiki/System>system</a> submitted to the SemEval2018 task2 : Multilingual Emoji Prediction. Our system approaches both languages as being equal by first ; considering word embeddings associated to automatically computed features of different types, then by applying bagging algorithm RandomForest to predict the <a href=https://en.wikipedia.org/wiki/Emoji>emoji</a> of a tweet.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1082.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1082 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1082 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1082/>ALANIS at SemEval-2018 Task 3 : A Feature Engineering Approach to Irony Detection in English Tweets<span class=acl-fixed-case>ALANIS</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 3: A Feature Engineering Approach to Irony Detection in <span class=acl-fixed-case>E</span>nglish Tweets</a></strong><br><a href=/people/k/kevin-swanberg/>Kevin Swanberg</a>
|
<a href=/people/m/madiha-mirza/>Madiha Mirza</a>
|
<a href=/people/t/ted-pedersen/>Ted Pedersen</a>
|
<a href=/people/z/zhenduo-wang/>Zhenduo Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1082><div class="card-body p-3 small">This paper describes the ALANIS system that participated in Task 3 of SemEval-2018. We develop a system for detection of irony, as well as the detection of three types of <a href=https://en.wikipedia.org/wiki/Irony>irony</a> : verbal polar irony, other verbal irony, and situational irony. The system uses a <a href=https://en.wikipedia.org/wiki/Logistic_regression>logistic regression model</a> in subtask A and a voted classifier system with manually developed <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> to identify ironic tweets. This <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> improves on a naive bayes baseline by about 8 percent on training set.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1084.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1084 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1084 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1084/>UWB at SemEval-2018 Task 3 : Irony detection in English tweets<span class=acl-fixed-case>UWB</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 3: Irony detection in <span class=acl-fixed-case>E</span>nglish tweets</a></strong><br><a href=/people/t/tomas-hercig/>Tomáš Hercig</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1084><div class="card-body p-3 small">This paper describes our system created for the SemEval-2018 Task 3 : Irony detection in English tweets. Our strongly constrained <a href=https://en.wikipedia.org/wiki/System>system</a> uses only the provided training data without any additional external resources. Our system is based on <a href=https://en.wikipedia.org/wiki/Maximum_entropy_classifier>Maximum Entropy classifier</a> and various features using <a href=https://en.wikipedia.org/wiki/Parse_tree>parse tree</a>, POS tags, and morphological features. Even without additional <a href=https://en.wikipedia.org/wiki/Lexicon>lexicons</a> and <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> we achieved fourth place in Subtask A and seventh in Subtask B in terms of accuracy.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1085.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1085 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1085 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=S18-1085" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/S18-1085/>NIHRIO at SemEval-2018 Task 3 : A Simple and Accurate Neural Network Model for Irony Detection in Twitter<span class=acl-fixed-case>NIHRIO</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 3: A Simple and Accurate Neural Network Model for Irony Detection in <span class=acl-fixed-case>T</span>witter</a></strong><br><a href=/people/t/thanh-vu/>Thanh Vu</a>
|
<a href=/people/d/dat-quoc-nguyen/>Dat Quoc Nguyen</a>
|
<a href=/people/x/xuan-son-vu/>Xuan-Son Vu</a>
|
<a href=/people/d/dai-quoc-nguyen/>Dai Quoc Nguyen</a>
|
<a href=/people/m/michael-catt/>Michael Catt</a>
|
<a href=/people/m/michael-trenell/>Michael Trenell</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1085><div class="card-body p-3 small">This paper describes our NIHRIO system for SemEval-2018 Task 3 Irony detection in English tweets. We propose to use a simple neural network architecture of Multilayer Perceptron with various types of input features including : lexical, syntactic, semantic and polarity features. Our system achieves very high performance in both subtasks of binary and multi-class irony detection in <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a>. In particular, we rank at least fourth using the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy metric</a> and sixth using the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>F1 metric</a>. Our code is available at :<url>https://github.com/NIHRIO/IronyDetectionInTwitter</url>\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1086.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1086 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1086 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1086/>LDR at SemEval-2018 Task 3 : A Low Dimensional Text Representation for Irony Detection<span class=acl-fixed-case>LDR</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 3: A Low Dimensional Text Representation for Irony Detection</a></strong><br><a href=/people/b/bilal-ghanem/>Bilal Ghanem</a>
|
<a href=/people/f/francisco-rangel/>Francisco Rangel</a>
|
<a href=/people/p/paolo-rosso/>Paolo Rosso</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1086><div class="card-body p-3 small">In this paper we describe our participation in the SemEval-2018 task 3 Shared Task on Irony Detection. We have approached the task with our low dimensionality representation method (LDR), which exploits low dimensional features extracted from text on the basis of the occurrence probability of the words depending on each class. Our intuition is that words in ironic texts have different probability of occurrence than in non-ironic ones. Our <a href=https://en.wikipedia.org/wiki/Design_of_experiments>approach</a> obtained acceptable results in both subtasks A and B. We have performed an error analysis that shows the difference on correct and incorrect classified tweets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1088.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1088 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1088 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1088/>PunFields at SemEval-2018 Task 3 : Detecting Irony by Tools of Humor Analysis<span class=acl-fixed-case>P</span>un<span class=acl-fixed-case>F</span>ields at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 3: Detecting Irony by Tools of Humor Analysis</a></strong><br><a href=/people/e/elena-mikhalkova/>Elena Mikhalkova</a>
|
<a href=/people/y/yuri-karyakin/>Yuri Karyakin</a>
|
<a href=/people/a/alexander-voronov/>Alexander Voronov</a>
|
<a href=/people/d/dmitry-grigoriev/>Dmitry Grigoriev</a>
|
<a href=/people/a/artem-leoznov/>Artem Leoznov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1088><div class="card-body p-3 small">The paper describes our search for a universal algorithm of detecting intentional lexical ambiguity in different forms of creative language. At SemEval-2018 Task 3, we used PunFields, the system of automatic analysis of English puns that we introduced at SemEval-2017, to detect irony in tweets. Preliminary tests showed that <a href=https://en.wikipedia.org/wiki/It_(2017_film)>it</a> can reach the score of F1=0.596. However, at the competition, its result was F1=0.549.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1089.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1089 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1089 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1089/>HashCount at SemEval-2018 Task 3 : Concatenative Featurization of Tweet and Hashtags for Irony Detection<span class=acl-fixed-case>H</span>ash<span class=acl-fixed-case>C</span>ount at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 3: Concatenative Featurization of Tweet and Hashtags for Irony Detection</a></strong><br><a href=/people/w/won-ik-cho/>Won Ik Cho</a>
|
<a href=/people/w/woo-hyun-kang/>Woo Hyun Kang</a>
|
<a href=/people/n/nam-soo-kim/>Nam Soo Kim</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1089><div class="card-body p-3 small">This paper proposes a novel feature extraction process for SemEval task 3 : Irony detection in English tweets. The proposed system incorporates a concatenative featurization of tweet and <a href=https://en.wikipedia.org/wiki/Hashtag>hashtags</a>, which helps distinguishing between the irony-related and the other components. The system embeds tweets into a <a href=https://en.wikipedia.org/wiki/Vector_space>vector sequence</a> with widely used pretrained word vectors, partially using a character embedding for the words that are out of vocabulary. Identification was performed with BiLSTM and CNN classifiers, achieving F1 score of 0.5939 (23/42) and 0.3925 (10/28) each for the binary and the multi-class case, respectively. The <a href=https://en.wikipedia.org/wiki/Reliability_(statistics)>reliability</a> of the proposed scheme was verified by analyzing the Gold test data, which demonstrates how <a href=https://en.wikipedia.org/wiki/Hashtag>hashtags</a> can be taken into account when identifying various types of <a href=https://en.wikipedia.org/wiki/Irony>irony</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1090.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1090 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1090 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1090/>WLV at SemEval-2018 Task 3 : Dissecting Tweets in Search of Irony<span class=acl-fixed-case>WLV</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 3: Dissecting Tweets in Search of Irony</a></strong><br><a href=/people/o/omid-rohanian/>Omid Rohanian</a>
|
<a href=/people/s/shiva-taslimipoor/>Shiva Taslimipoor</a>
|
<a href=/people/r/richard-evans/>Richard Evans</a>
|
<a href=/people/r/ruslan-mitkov/>Ruslan Mitkov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1090><div class="card-body p-3 small">This paper describes the systems submitted to SemEval 2018 Task 3 Irony detection in English tweets for both subtasks A and B. The first system leveraging a combination of <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment</a>, distributional semantic, and text surface features is ranked third among 44 teams according to the official leaderboard of the subtask A. The second <a href=https://en.wikipedia.org/wiki/Formal_system>system</a> with slightly different representation of the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> ranked ninth in subtask B. We present a <a href=https://en.wikipedia.org/wiki/Methodology>method</a> that entails decomposing tweets into separate parts. Searching for <a href=https://en.wikipedia.org/wiki/Contrast_(vision)>contrast</a> within the constituents of a tweet is an integral part of our <a href=https://en.wikipedia.org/wiki/System>system</a>. We embrace an extensive definition of <a href=https://en.wikipedia.org/wiki/Contrast_(linguistics)>contrast</a> which leads to a vast coverage in detecting ironic content.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1095.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1095 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1095 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1095/>Irony Detector at SemEval-2018 Task 3 : Irony Detection in English Tweets using Word Graph<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 3: Irony Detection in <span class=acl-fixed-case>E</span>nglish Tweets using Word Graph</a></strong><br><a href=/people/u/usman-ahmed/>Usman Ahmed</a>
|
<a href=/people/l/lubna-zafar/>Lubna Zafar</a>
|
<a href=/people/f/faiza-qayyum/>Faiza Qayyum</a>
|
<a href=/people/m/muhammad-arshad-islam/>Muhammad Arshad Islam</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1095><div class="card-body p-3 small">This paper describes the Irony detection system that participates in SemEval-2018 Task 3 : Irony detection in English tweets. The <a href=https://en.wikipedia.org/wiki/System>system</a> participated in the subtasks A and B. This paper discusses the results of our <a href=https://en.wikipedia.org/wiki/System>system</a> in the development, evaluation and post evaluation. Each class in the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> is represented as <a href=https://en.wikipedia.org/wiki/Directed_graph>directed unweighted graphs</a>. Then, the comparison is carried out with each <a href=https://en.wikipedia.org/wiki/Class_graph>class graph</a> which results in a <a href=https://en.wikipedia.org/wiki/Vector_(mathematics_and_physics)>vector</a>. This <a href=https://en.wikipedia.org/wiki/Vector_(mathematics_and_physics)>vector</a> is used as <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> by <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning algorithm</a>. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is evaluated on a hold on strategy. The organizers randomly split 80 % (3,833 instances) training set (provided to the participant in training their system) and testing set 20%(958 instances). The test set is reserved to evaluate the performance of participants systems. During the evaluation, our <a href=https://en.wikipedia.org/wiki/System>system</a> ranked 23 in the Coda Lab result of the subtask A (binary class problem). The binary class system achieves <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> 0.6135, <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a> 0.5091, <a href=https://en.wikipedia.org/wiki/Precision_and_recall>recall</a> 0.7170 and F measure 0.5955. The subtask B (multi-class problem) system is ranked 22 in Coda Lab results. The multiclass model achieves the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> 0.4158, <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a> 0.4055, <a href=https://en.wikipedia.org/wiki/Precision_and_recall>recall</a> 0.3526 and <a href=https://en.wikipedia.org/wiki/F-number>f measure</a> 0.3101.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1096.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1096 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1096 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1096/>Lancaster at SemEval-2018 Task 3 : Investigating Ironic Features in English Tweets<span class=acl-fixed-case>L</span>ancaster at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 3: Investigating Ironic Features in <span class=acl-fixed-case>E</span>nglish Tweets</a></strong><br><a href=/people/e/edward-dearden/>Edward Dearden</a>
|
<a href=/people/a/alistair-baron/>Alistair Baron</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1096><div class="card-body p-3 small">This paper describes the <a href=https://en.wikipedia.org/wiki/System>system</a> we submitted to SemEval-2018 Task 3. The aim of the system is to distinguish between irony and non-irony in English tweets. We create a targeted feature set and analyse how different <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> are useful in the task of irony detection, achieving an F1-score of 0.5914. The analysis of individual features provides insight that may be useful in future attempts at detecting <a href=https://en.wikipedia.org/wiki/Irony>irony</a> in <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1097.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1097 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1097 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1097/>INAOE-UPV at SemEval-2018 Task 3 : An Ensemble Approach for Irony Detection in Twitter<span class=acl-fixed-case>INAOE</span>-<span class=acl-fixed-case>UPV</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 3: An Ensemble Approach for Irony Detection in <span class=acl-fixed-case>T</span>witter</a></strong><br><a href=/people/d/delia-irazu-hernandez-farias/>Delia Irazú Hernández Farías</a>
|
<a href=/people/f/fernando-sanchez-vega/>Fernando Sánchez-Vega</a>
|
<a href=/people/m/manuel-montes/>Manuel Montes-y-Gómez</a>
|
<a href=/people/p/paolo-rosso/>Paolo Rosso</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1097><div class="card-body p-3 small">This paper describes an <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensemble approach</a> to the SemEval-2018 Task 3. The proposed method is composed of two renowned methods in <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a> together with a novel approach for capturing ironic content by exploiting a tailored lexicon for irony detection. We experimented with different <a href=https://en.wikipedia.org/wiki/Ensemble_cast>ensemble settings</a>. The obtained results show that our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> has a good performance for detecting the presence of ironic content in <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1099.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1099 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1099 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1099/>KLUEnicorn at SemEval-2018 Task 3 : A Naive Approach to Irony Detection<span class=acl-fixed-case>KLUE</span>nicorn at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 3: A Naive Approach to Irony Detection</a></strong><br><a href=/people/l/luise-durlich/>Luise Dürlich</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1099><div class="card-body p-3 small">This paper describes the KLUEnicorn system submitted to the SemEval-2018 task on Irony detection in English tweets. The proposed system uses a <a href=https://en.wikipedia.org/wiki/Naive_Bayes_classifier>naive Bayes classifier</a> to exploit rather simple lexical, pragmatical and semantical features as well as sentiment. It further takes a closer look at different adverb categories and <a href=https://en.wikipedia.org/wiki/Named_entity>named entities</a> and factors in word-embedding information.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1101.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1101 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1101 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1101/>YNU-HPCC at SemEval-2018 Task 3 : Ensemble Neural Network Models for Irony Detection on Twitter<span class=acl-fixed-case>YNU</span>-<span class=acl-fixed-case>HPCC</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 3: Ensemble Neural Network Models for Irony Detection on <span class=acl-fixed-case>T</span>witter</a></strong><br><a href=/people/b/bo-peng/>Bo Peng</a>
|
<a href=/people/j/jin-wang/>Jin Wang</a>
|
<a href=/people/x/xuejie-zhang/>Xuejie Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1101><div class="card-body p-3 small">This paper describe the <a href=https://en.wikipedia.org/wiki/System>system</a> we proposed to participate the first year of Irony detection in English tweets competition. Previous works demonstrate that LSTMs models have achieved remarkable performance in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> ; besides, combining multiple classification from various individual classifiers in general is more powerful than a single classification. In order to obtain more precision classification of irony detection, our system trained several individual neural network classifiers and combined their results according to the ensemble-learning algorithm.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1102.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1102 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1102 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1102/>Binarizer at SemEval-2018 Task 3 : Parsing dependency and <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> for irony detection<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 3: Parsing dependency and deep learning for irony detection</a></strong><br><a href=/people/n/nishant-nikhil/>Nishant Nikhil</a>
|
<a href=/people/m/muktabh-mayank-srivastava/>Muktabh Mayank Srivastava</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1102><div class="card-body p-3 small">In this paper, we describe the system submitted for the SemEval 2018 Task 3 (Irony detection in English tweets) Subtask A by the team Binarizer. Irony detection is a key task for many natural language processing works. Our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> treats ironical tweets to consist of smaller parts containing different <a href=https://en.wikipedia.org/wiki/Emotion>emotions</a>. We break down tweets into separate phrases using a <a href=https://en.wikipedia.org/wiki/Dependency_grammar>dependency parser</a>. We then embed those phrases using an LSTM-based neural network model which is pre-trained to predict <a href=https://en.wikipedia.org/wiki/Emoticon>emoticons</a> for tweets. Finally, we train a <a href=https://en.wikipedia.org/wiki/Connectivity_(graph_theory)>fully-connected network</a> to achieve <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1105.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1105 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1105 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1105/>ValenTO at SemEval-2018 Task 3 : Exploring the Role of Affective Content for Detecting Irony in English Tweets<span class=acl-fixed-case>V</span>alen<span class=acl-fixed-case>TO</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 3: Exploring the Role of Affective Content for Detecting Irony in <span class=acl-fixed-case>E</span>nglish Tweets</a></strong><br><a href=/people/d/delia-irazu-hernandez-farias/>Delia Irazú Hernández Farías</a>
|
<a href=/people/v/viviana-patti/>Viviana Patti</a>
|
<a href=/people/p/paolo-rosso/>Paolo Rosso</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1105><div class="card-body p-3 small">In this paper we describe the system used by the ValenTO team in the shared task on Irony Detection in English Tweets at SemEval 2018. The system takes as starting point emotIDM, an irony detection model that explores the use of affective features based on a wide range of lexical resources available for <a href=https://en.wikipedia.org/wiki/English_language>English</a>, reflecting different facets of affect. We experimented with different settings, by exploiting different <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> and <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a>, and participated both to the binary irony detection task and to the task devoted to distinguish among different types of <a href=https://en.wikipedia.org/wiki/Irony>irony</a>. We report on the results obtained by our system both in a constrained setting and unconstrained setting, where we explored the impact of using additional data in the training phase, such as corpora annotated for the presence of <a href=https://en.wikipedia.org/wiki/Irony>irony</a> or <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> from the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state of the art</a>. Overall, the performance of our <a href=https://en.wikipedia.org/wiki/System>system</a> seems to validate the important role that affective information has for identifying ironic content in <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1108.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1108 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1108 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1108/>NewsReader at SemEval-2018 Task 5 : Counting events by reasoning over event-centric-knowledge-graphs<span class=acl-fixed-case>N</span>ews<span class=acl-fixed-case>R</span>eader at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 5: Counting events by reasoning over event-centric-knowledge-graphs</a></strong><br><a href=/people/p/piek-vossen/>Piek Vossen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1108><div class="card-body p-3 small">In this paper, we describe the participation of the NewsReader system in the SemEval-2018 Task 5 on Counting Events and Participants in the Long Tail. NewsReader is a generic <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised text processing system</a> that detects events with participants, time and place to generate Event Centric Knowledge Graphs (ECKGs). We minimally adapted these ECKGs to establish a baseline performance for the <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>. We first use the ECKGs to establish which documents report on the same incident and what event mentions are coreferential. Next, we aggregate ECKGs across coreferential mentions and use the aggregated knowledge to answer the questions of the task. Our participation tests the quality of NewsReader to create ECKGs, as well as the potential of ECKGs to establish event identity and reason over the result to answer the task queries.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1113.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1113 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1113 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1113/>SemEval-2018 Task 8 : Semantic Extraction from CybersecUrity REports using Natural Language Processing (SecureNLP)<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 8: Semantic Extraction from <span class=acl-fixed-case>C</span>ybersec<span class=acl-fixed-case>U</span>rity <span class=acl-fixed-case>RE</span>ports using Natural Language Processing (<span class=acl-fixed-case>S</span>ecure<span class=acl-fixed-case>NLP</span>)</a></strong><br><a href=/people/p/peter-phandi/>Peter Phandi</a>
|
<a href=/people/a/amila-silva/>Amila Silva</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1113><div class="card-body p-3 small">This paper describes the <a href=https://en.wikipedia.org/wiki/SemEval>SemEval 2018 shared task</a> on semantic extraction from cybersecurity reports, which is introduced for the first time as a shared task on <a href=https://en.wikipedia.org/wiki/SemEval>SemEval</a>. This task comprises four SubTasks done incrementally to predict the characteristics of a specific malware using cybersecurity reports. To the best of our knowledge, we introduce the world&#8217;s largest publicly available dataset of annotated malware reports in this task. This <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> received in total 18 submissions from 9 participating teams.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1114.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1114 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1114 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1114/>DM_NLP at SemEval-2018 Task 8 : neural sequence labeling with linguistic features<span class=acl-fixed-case>DM</span>_<span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 8: neural sequence labeling with linguistic features</a></strong><br><a href=/people/c/chunping-ma/>Chunping Ma</a>
|
<a href=/people/h/huafei-zheng/>Huafei Zheng</a>
|
<a href=/people/p/pengjun-xie/>Pengjun Xie</a>
|
<a href=/people/c/chen-li/>Chen Li</a>
|
<a href=/people/l/linlin-li/>Linlin Li</a>
|
<a href=/people/l/luo-si/>Luo Si</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1114><div class="card-body p-3 small">This paper describes our submissions for SemEval-2018 Task 8 : Semantic Extraction from CybersecUrity REports using <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. The DM_NLP participated in two subtasks : SubTask 1 classifies if a sentence is useful for inferring malware actions and capabilities, and SubTask 2 predicts token labels (Action, Entity, Modifier and Others) for a given malware-related sentence. Since we leverage results of Subtask 2 directly to infer the result of Subtask 1, the paper focus on the system solving Subtask 2. By taking Subtask 2 as a sequence labeling task, our system relies on a <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network</a> named BiLSTM-CNN-CRF with rich linguistic features, such as POS tags, dependency parsing labels, chunking labels, NER labels, Brown clustering. Our <a href=https://en.wikipedia.org/wiki/System>system</a> achieved the highest F1 score in both token level and phrase level.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1115.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1115 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1115 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1115/>SemEval-2018 Task 9 : Hypernym Discovery<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 9: Hypernym Discovery</a></strong><br><a href=/people/j/jose-camacho-collados/>Jose Camacho-Collados</a>
|
<a href=/people/c/claudio-delli-bovi/>Claudio Delli Bovi</a>
|
<a href=/people/l/luis-espinosa-anke/>Luis Espinosa-Anke</a>
|
<a href=/people/s/sergio-oramas/>Sergio Oramas</a>
|
<a href=/people/t/tommaso-pasini/>Tommaso Pasini</a>
|
<a href=/people/e/enrico-santus/>Enrico Santus</a>
|
<a href=/people/v/vered-shwartz/>Vered Shwartz</a>
|
<a href=/people/r/roberto-navigli/>Roberto Navigli</a>
|
<a href=/people/h/horacio-saggion/>Horacio Saggion</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1115><div class="card-body p-3 small">This paper describes the SemEval 2018 Shared Task on Hypernym Discovery. We put forward this task as a complementary benchmark for modeling <a href=https://en.wikipedia.org/wiki/Hypernymy>hypernymy</a>, a problem which has traditionally been cast as a binary classification task, taking a pair of candidate words as input. Instead, our reformulated task is defined as follows : given an input term, retrieve (or discover) its suitable <a href=https://en.wikipedia.org/wiki/Hypernym>hypernyms</a> from a target corpus. We proposed five different subtasks covering three languages (English, Spanish, and Italian), and two specific domains of knowledge in English (Medical and Music). Participants were allowed to compete in any or all of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>subtasks</a>. Overall, a total of 11 teams participated, with a total of 39 different systems submitted through all subtasks. Data, results and further information about the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> can be found at.<url>https://competitions.codalab.org/competitions/17119</url>.\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1117.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1117 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1117 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1117/>SemEval-2018 Task 10 : Capturing Discriminative Attributes<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 10: Capturing Discriminative Attributes</a></strong><br><a href=/people/a/alicia-krebs/>Alicia Krebs</a>
|
<a href=/people/a/alessandro-lenci/>Alessandro Lenci</a>
|
<a href=/people/d/denis-paperno/>Denis Paperno</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1117><div class="card-body p-3 small">This paper describes the SemEval 2018 Task 10 on Capturing Discriminative Attributes. Participants were asked to identify whether an attribute could help discriminate between two concepts. For example, a successful <a href=https://en.wikipedia.org/wiki/System>system</a> should determine that &#8216;urine&#8217; is a discriminating feature in the word pair &#8216;kidney&#8217;, &#8216;bone&#8217;. The aim of the task is to better evaluate the capabilities of state of the art semantic models, beyond pure semantic similarity. The <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> attracted submissions from 21 teams, and the best <a href=https://en.wikipedia.org/wiki/System>system</a> achieved a 0.75 F1 score.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1119.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1119 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1119 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1119/>SemEval-2018 Task 11 : <a href=https://en.wikipedia.org/wiki/Machine_learning>Machine Comprehension</a> Using Commonsense Knowledge<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 11: Machine Comprehension Using Commonsense Knowledge</a></strong><br><a href=/people/s/simon-ostermann/>Simon Ostermann</a>
|
<a href=/people/m/michael-roth/>Michael Roth</a>
|
<a href=/people/a/ashutosh-modi/>Ashutosh Modi</a>
|
<a href=/people/s/stefan-thater/>Stefan Thater</a>
|
<a href=/people/m/manfred-pinkal/>Manfred Pinkal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1119><div class="card-body p-3 small">This report summarizes the results of the SemEval 2018 task on <a href=https://en.wikipedia.org/wiki/Machine_learning>machine comprehension</a> using <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a>. For this machine comprehension task, we created a new <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>, MCScript. It contains a high number of questions that require <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a> for finding the correct answer. 11 teams from 4 different countries participated in this shared <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, most of them used neural approaches. The best performing <a href=https://en.wikipedia.org/wiki/System>system</a> achieves an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 83.95 %, outperforming the <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baselines</a> by a large margin, but still far from the <a href=https://en.wikipedia.org/wiki/Upper_and_lower_bounds>human upper bound</a>, which was found to be at 98 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1120.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1120 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1120 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=S18-1120" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/S18-1120/>Yuanfudao at SemEval-2018 Task 11 : Three-way Attention and Relational Knowledge for Commonsense Machine Comprehension<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 11: Three-way Attention and Relational Knowledge for Commonsense Machine Comprehension</a></strong><br><a href=/people/l/liang-wang/>Liang Wang</a>
|
<a href=/people/m/meng-sun/>Meng Sun</a>
|
<a href=/people/w/wei-zhao/>Wei Zhao</a>
|
<a href=/people/k/kewei-shen/>Kewei Shen</a>
|
<a href=/people/j/jingming-liu/>Jingming Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1120><div class="card-body p-3 small">This paper describes our <a href=https://en.wikipedia.org/wiki/System>system</a> for SemEval-2018 Task 11 : <a href=https://en.wikipedia.org/wiki/Machine_learning>Machine Comprehension</a> using Commonsense Knowledge. We use Three-way Attentive Networks (TriAN) to model interactions between the passage, question and answers. To incorporate <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a>, we augment the input with relation embedding from the graph of general knowledge ConceptNet. As a result, our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves state-of-the-art performance with 83.95 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on the official test data. Code is publicly available at.<url>https://github.com/intfloat/commonsense-rc</url>.\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1121.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1121 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1121 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1121/>SemEval-2018 Task 12 : The Argument Reasoning Comprehension Task<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 12: The Argument Reasoning Comprehension Task</a></strong><br><a href=/people/i/ivan-habernal/>Ivan Habernal</a>
|
<a href=/people/h/henning-wachsmuth/>Henning Wachsmuth</a>
|
<a href=/people/i/iryna-gurevych/>Iryna Gurevych</a>
|
<a href=/people/b/benno-stein/>Benno Stein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1121><div class="card-body p-3 small">A natural language argument is composed of a claim as well as reasons given as premises for the claim. The warrant explaining the reasoning is usually left implicit, as it is clear from the context and common sense. This makes a <a href=https://en.wikipedia.org/wiki/Comprehension_(logic)>comprehension of arguments</a> easy for humans but hard for machines. This paper summarizes the first shared <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> on argument reasoning comprehension. Given a premise and a claim along with some topic information, the goal was to automatically identify the correct warrant among two candidates that are plausible and lexically close, but in fact imply opposite claims. We describe the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> with 1970 instances that we built for the task, and we outline the 21 computational approaches that participated, most of which used <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>. The results reveal the <a href=https://en.wikipedia.org/wiki/Computational_complexity_theory>complexity</a> of the <a href=https://en.wikipedia.org/wiki/Computational_complexity_theory>task</a>, with many approaches hardly improving over the <a href=https://en.wikipedia.org/wiki/Random_variable>random accuracy</a> of about 0.5. Still, the best observed accuracy (0.712) underlines the principle feasibility of <a href=https://en.wikipedia.org/wiki/Warrant_(law)>identifying warrants</a>. Our analysis indicates that an inclusion of <a href=https://en.wikipedia.org/wiki/Knowledge>external knowledge</a> is key to <a href=https://en.wikipedia.org/wiki/Understanding>reasoning comprehension</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1122.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1122 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1122 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=S18-1122" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/S18-1122/>GIST at SemEval-2018 Task 12 : A network transferring inference knowledge to Argument Reasoning Comprehension task<span class=acl-fixed-case>GIST</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 12: A network transferring inference knowledge to Argument Reasoning Comprehension task</a></strong><br><a href=/people/h/hongseok-choi/>HongSeok Choi</a>
|
<a href=/people/h/hyunju-lee/>Hyunju Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1122><div class="card-body p-3 small">This paper describes our GIST team system that participated in SemEval-2018 Argument Reasoning Comprehension task (Task 12). Here, we address two challenging factors : unstated common senses and two lexically close warrants that lead to contradicting claims. A key idea for our <a href=https://en.wikipedia.org/wiki/System>system</a> is full use of <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> from the Natural Language Inference (NLI) task to this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. We used Enhanced Sequential Inference Model (ESIM) to learn the NLI dataset. We describe how to use ESIM for <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> to choose correct warrant through a proposed <a href=https://en.wikipedia.org/wiki/System>system</a>. We show comparable results through ablation experiments. Our <a href=https://en.wikipedia.org/wiki/System>system</a> ranked 1st among 22 systems, outperforming all the <a href=https://en.wikipedia.org/wiki/System>systems</a> more than 10 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1123.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1123 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1123 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1123/>LightRel at SemEval-2018 Task 7 : Lightweight and Fast Relation Classification<span class=acl-fixed-case>L</span>ight<span class=acl-fixed-case>R</span>el at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 7: Lightweight and Fast Relation Classification</a></strong><br><a href=/people/t/tyler-renslow/>Tyler Renslow</a>
|
<a href=/people/g/gunter-neumann/>Günter Neumann</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1123><div class="card-body p-3 small">We present LightRel, a lightweight and fast relation classifier. Our goal is to develop a high baseline for different relation extraction tasks. By defining only very few data-internal, word-level features and external knowledge sources in the form of word clusters and <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a>, we train a fast and simple <a href=https://en.wikipedia.org/wiki/Linear_classifier>linear classifier</a></div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1124.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1124 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1124 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1124/>OhioState at SemEval-2018 Task 7 : Exploiting Data Augmentation for Relation Classification in Scientific Papers Using Piecewise Convolutional Neural Networks<span class=acl-fixed-case>O</span>hio<span class=acl-fixed-case>S</span>tate at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 7: Exploiting Data Augmentation for Relation Classification in Scientific Papers Using Piecewise Convolutional Neural Networks</a></strong><br><a href=/people/d/dushyanta-dhyani/>Dushyanta Dhyani</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1124><div class="card-body p-3 small">We describe our system for SemEval-2018 Shared Task on Semantic Relation Extraction and Classification in Scientific Papers where we focus on the Classification task. Our simple piecewise convolution neural encoder performs decently in an end to end manner. A simple inter-task data augmentation significantly boosts the performance of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. Our best-performing systems stood 8th out of 20 teams on the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification task</a> on <a href=https://en.wikipedia.org/wiki/Noisy_data>noisy data</a> and 12th out of 28 teams on the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification task</a> on clean data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1126.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1126 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1126 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1126/>UC3M-NII Team at SemEval-2018 Task 7 : Semantic Relation Classification in Scientific Papers via Convolutional Neural Network<span class=acl-fixed-case>UC</span>3<span class=acl-fixed-case>M</span>-<span class=acl-fixed-case>NII</span> Team at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 7: Semantic Relation Classification in Scientific Papers via Convolutional Neural Network</a></strong><br><a href=/people/v/victor-suarez-paniagua/>Víctor Suárez-Paniagua</a>
|
<a href=/people/i/isabel-segura-bedmar/>Isabel Segura-Bedmar</a>
|
<a href=/people/a/akiko-aizawa/>Akiko Aizawa</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1126><div class="card-body p-3 small">This paper reports our participation for SemEval-2018 Task 7 on extraction and classification of relationships between entities in <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific papers</a>. Our approach is based on the use of a Convolutional Neural Network (CNN) trained on350 abstract with manually annotated entities and relations. Our hypothesis is that this deep learning model can be applied to extract and classify relations between entities for <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific papers</a> at the same time. We use the Part-of-Speech and the distances to the target entities as part of the embedding for each word and we blind all the entities by marker names. In addition, we use <a href=https://en.wikipedia.org/wiki/Sampling_(statistics)>sampling techniques</a> to overcome the imbalance issues of this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. Our <a href=https://en.wikipedia.org/wiki/Computer_architecture>architecture</a> obtained an F1-score of 35.4 % for the relation extraction task and 18.5 % for the relation classification task with a basic configuration of the one step CNN.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1127.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1127 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1127 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1127/>MIT-MEDG at SemEval-2018 Task 7 : Semantic Relation Classification via Convolution Neural Network<span class=acl-fixed-case>MIT</span>-<span class=acl-fixed-case>MEDG</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 7: Semantic Relation Classification via Convolution Neural Network</a></strong><br><a href=/people/d/di-jin/>Di Jin</a>
|
<a href=/people/f/franck-dernoncourt/>Franck Dernoncourt</a>
|
<a href=/people/e/elena-sergeeva/>Elena Sergeeva</a>
|
<a href=/people/m/matthew-mcdermott/>Matthew McDermott</a>
|
<a href=/people/g/geeticka-chauhan/>Geeticka Chauhan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1127><div class="card-body p-3 small">SemEval 2018 Task 7 tasked participants to build a <a href=https://en.wikipedia.org/wiki/System>system</a> to classify two entities within a sentence into one of the 6 possible relation types. We tested 3 classes of <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> : Linear classifiers, Long Short-Term Memory (LSTM) models, and Convolutional Neural Network (CNN) models. Ultimately, the CNN model class proved most performant, so we specialized to this <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> for our final submissions. We improved performance beyond a vanilla CNN by including a variant of negative sampling, using custom <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> learned over a corpus of ACL articles, training over corpora of both <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> 1.1 and 1.2, using reversed feature, using part of context words beyond the entity pairs and using <a href=https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)>ensemble methods</a> to improve our final predictions. We also tested attention based pooling, up-sampling, and <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a>, but none improved performance. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieved rank 6 out of 28 (macro-averaged F1-score : 72.7) in subtask 1.1, and rank 4 out of 20 (macro F1 : 80.6) in subtask 1.2.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1128.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1128 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1128 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1128/>SIRIUS-LTG-UiO at SemEval-2018 Task 7 : Convolutional Neural Networks with Shortest Dependency Paths for Semantic Relation Extraction and Classification in Scientific Papers<span class=acl-fixed-case>SIRIUS</span>-<span class=acl-fixed-case>LTG</span>-<span class=acl-fixed-case>U</span>i<span class=acl-fixed-case>O</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 7: Convolutional Neural Networks with Shortest Dependency Paths for Semantic Relation Extraction and Classification in Scientific Papers</a></strong><br><a href=/people/f/farhad-nooralahzadeh/>Farhad Nooralahzadeh</a>
|
<a href=/people/l/lilja-ovrelid/>Lilja Øvrelid</a>
|
<a href=/people/j/jan-tore-lonning/>Jan Tore Lønning</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1128><div class="card-body p-3 small">This article presents the SIRIUS-LTG-UiO system for the SemEval 2018 Task 7 on Semantic Relation Extraction and Classification in Scientific Papers. First we extract the shortest dependency path (sdp) between two entities, then we introduce a convolutional neural network (CNN) which takes the shortest dependency path embeddings as input and performs relation classification with differing objectives for each subtask of the shared task. This approach achieved overall F1 scores of 76.7 and 83.2 for <a href=https://en.wikipedia.org/wiki/Relation_(database)>relation classification</a> on clean and noisy data, respectively. Furthermore, for combined relation extraction and classification on <a href=https://en.wikipedia.org/wiki/Data_integrity>clean data</a>, it obtained <a href=https://en.wikipedia.org/wiki/F-number>F1 scores</a> of 37.4 and 33.6 for each phase. Our <a href=https://en.wikipedia.org/wiki/System>system</a> ranks 3rd in all three sub-tasks of the shared task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1131.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1131 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1131 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1131/>Texterra at SemEval-2018 Task 7 : Exploiting Syntactic Information for Relation Extraction and Classification in Scientific Papers<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 7: Exploiting Syntactic Information for Relation Extraction and Classification in Scientific Papers</a></strong><br><a href=/people/a/andrey-sysoev/>Andrey Sysoev</a>
|
<a href=/people/v/vladimir-mayorov/>Vladimir Mayorov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1131><div class="card-body p-3 small">In this work we evaluate applicability of <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity pair models</a> and neural network architectures for relation extraction and classification in scientific papers at SemEval-2018. We carry out experiments with representing entity pairs through sentence tokens and through shortest path in dependency tree, comparing approaches based on convolutional and recurrent neural networks. With convolutional network applied to shortest path in dependency tree we managed to be ranked eighth in subtask 1.1 (clean data), ninth in 1.2 (noisy data). Similar model applied to separate parts of the <a href=https://en.wikipedia.org/wiki/Shortest_path_problem>shortest path</a> was mounted to ninth (extraction track) and seventh (classification track) positions in subtask 2 ranking.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1132.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1132 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1132 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1132/>UniMa at SemEval-2018 Task 7 : Semantic Relation Extraction and Classification from Scientific Publications<span class=acl-fixed-case>U</span>ni<span class=acl-fixed-case>M</span>a at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 7: Semantic Relation Extraction and Classification from Scientific Publications</a></strong><br><a href=/people/t/thorsten-keiper/>Thorsten Keiper</a>
|
<a href=/people/z/zhonghao-lyu/>Zhonghao Lyu</a>
|
<a href=/people/s/sara-pooladzadeh/>Sara Pooladzadeh</a>
|
<a href=/people/y/yuan-xu/>Yuan Xu</a>
|
<a href=/people/j/jingyi-zhang/>Jingyi Zhang</a>
|
<a href=/people/a/anne-lauscher/>Anne Lauscher</a>
|
<a href=/people/s/simone-paolo-ponzetto/>Simone Paolo Ponzetto</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1132><div class="card-body p-3 small">Large repositories of scientific literature call for the development of robust methods to extract information from <a href=https://en.wikipedia.org/wiki/Academic_publishing>scholarly papers</a>. This <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> is addressed by the SemEval 2018 Task 7 on extracting and classifying relations found within <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific publications</a>. In this paper, we present a feature-based and a deep learning-based approach to the task and discuss the results of the system runs that we submitted for evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1134.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1134 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1134 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1134/>ClaiRE at SemEval-2018 Task 7 : Classification of Relations using Embeddings<span class=acl-fixed-case>C</span>lai<span class=acl-fixed-case>RE</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 7: Classification of Relations using Embeddings</a></strong><br><a href=/people/l/lena-hettinger/>Lena Hettinger</a>
|
<a href=/people/a/alexander-dallmann/>Alexander Dallmann</a>
|
<a href=/people/a/albin-zehe/>Albin Zehe</a>
|
<a href=/people/t/thomas-niebler/>Thomas Niebler</a>
|
<a href=/people/a/andreas-hotho/>Andreas Hotho</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1134><div class="card-body p-3 small">In this paper we describe our <a href=https://en.wikipedia.org/wiki/System>system</a> for SemEval-2018 Task 7 on classification of semantic relations in <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific literature</a> for clean (subtask 1.1) and noisy data (subtask 1.2). We compare two models for classification, a C-LSTM which utilizes only <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> and an SVM that also takes handcrafted features into account. To adapt to the domain of science we train <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> on <a href=https://en.wikipedia.org/wiki/Scientific_literature>scientific papers</a> collected from arXiv.org. The hand-crafted features consist of lexical features to model the semantic relations as well as the entities between which the relation holds. Classification of Relations using Embeddings (ClaiRE) achieved an F1 score of 74.89 % for the first subtask and 78.39 % for the second.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1138.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1138 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1138 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1138/>NTNU at SemEval-2018 Task 7 : Classifier Ensembling for Semantic Relation Identification and Classification in Scientific Papers<span class=acl-fixed-case>NTNU</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 7: Classifier Ensembling for Semantic Relation Identification and Classification in Scientific Papers</a></strong><br><a href=/people/b/biswanath-barik/>Biswanath Barik</a>
|
<a href=/people/u/utpal-kumar-sikdar/>Utpal Kumar Sikdar</a>
|
<a href=/people/b/bjorn-gamback/>Björn Gambäck</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1138><div class="card-body p-3 small">The paper presents NTNU&#8217;s contribution to SemEval-2018 Task 7 on relation identification and classification. The class weights and parameters of five alternative supervised classifiers were optimized through <a href=https://en.wikipedia.org/wiki/Grid_search>grid search</a> and <a href=https://en.wikipedia.org/wiki/Cross-validation_(statistics)>cross-validation</a>. The outputs of the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> were combined through <a href=https://en.wikipedia.org/wiki/Voting>voting</a> for the final prediction. A wide variety of <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> were explored, with the most informative identified by <a href=https://en.wikipedia.org/wiki/Feature_selection>feature selection</a>. The best setting achieved F1 scores of 47.4 % and 66.0 % in the relation classification subtasks 1.1 and 1.2. For relation identification and classification in subtask 2, it achieved F1 scores of 33.9 % and 17.0 %,</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1139.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1139 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1139 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1139/>Talla at SemEval-2018 Task 7 : Hybrid Loss Optimization for Relation Classification using Convolutional Neural Networks<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 7: Hybrid Loss Optimization for Relation Classification using Convolutional Neural Networks</a></strong><br><a href=/people/b/bhanu-pratap/>Bhanu Pratap</a>
|
<a href=/people/d/daniel-shank/>Daniel Shank</a>
|
<a href=/people/o/oladipo-ositelu/>Oladipo Ositelu</a>
|
<a href=/people/b/byron-galbraith/>Byron Galbraith</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1139><div class="card-body p-3 small">This paper describes our approach to SemEval-2018 Task 7 given an entity-tagged text from the ACL Anthology corpus, identify and classify pairs of entities that have one of six possible semantic relationships. Our model consists of a <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>convolutional neural network</a> leveraging pre-trained word embeddings, unlabeled ACL-abstracts, and multiple window sizes to automatically learn useful features from entity-tagged sentences. We also experiment with a hybrid loss function, a combination of cross-entropy loss and ranking loss, to boost the separation in classification scores. Lastly, we include WordNet-based features to further improve the performance of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. Our best <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves an F1(macro) score of 74.2 and 84.8 on subtasks 1.1 and 1.2, respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1140.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1140 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1140 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1140/>TeamDL at SemEval-2018 Task 8 : Cybersecurity Text Analysis using <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>Convolutional Neural Network</a> and Conditional Random Fields<span class=acl-fixed-case>T</span>eam<span class=acl-fixed-case>DL</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 8: Cybersecurity Text Analysis using Convolutional Neural Network and Conditional Random Fields</a></strong><br><a href=/people/m/manikandan-r/>Manikandan R</a>
|
<a href=/people/k/krishna-madgula/>Krishna Madgula</a>
|
<a href=/people/s/snehanshu-saha/>Snehanshu Saha</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1140><div class="card-body p-3 small">In this work we present our participation to SemEval-2018 Task 8 subtasks 1 & 2 respectively. We developed Convolution Neural Network system for malware sentence classification (subtask 1) and Conditional Random Fields system for malware token label prediction (subtask 2). We experimented with couple of word embedding strategies, feature sets and achieved competitive performance across the two subtasks. For subtask 1 We experimented with two category of word embeddings namely native embeddings and task specific embedding using Word2vec and Glove algorithms. Native Embeddings : All words including the unknown ones that are randomly initialized use embeddings from original Word2vec / Glove models. Task specific : The embeddings are generated by training Word2vec / Glove algorithms on sentences from MalwareTextDB We found that glove outperforms rest of embeddings for subtask 1. For subtask 2, we used N-grams of size 6, previous, next tokens and labels, <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>features</a> giving disjunctions of words anywhere in the left or right, word shape features, word lemma of current, previous and next words, word-tag pair features, POS tags, prefix and suffixes.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1141.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1141 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1141 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1141/>HCCL at SemEval-2018 Task 8 : An End-to-End System for Sequence Labeling from Cybersecurity Reports<span class=acl-fixed-case>HCCL</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 8: An End-to-End System for Sequence Labeling from Cybersecurity Reports</a></strong><br><a href=/people/m/mingming-fu/>Mingming Fu</a>
|
<a href=/people/x/xuemin-zhao/>Xuemin Zhao</a>
|
<a href=/people/y/yonghong-yan/>Yonghong Yan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1141><div class="card-body p-3 small">This paper describes HCCL team systems that participated in SemEval 2018 Task 8 : SecureNLP (Semantic Extraction from cybersecurity reports using NLP). To solve the problem, our team applied a neural network architecture that benefits from both word and character level representaions automatically, by using combination of Bi-directional LSTM, CNN and CRF (Ma and Hovy, 2016). Our system is truly end-to-end, requiring no <a href=https://en.wikipedia.org/wiki/Feature_engineering>feature engineering</a> or <a href=https://en.wikipedia.org/wiki/Data_preprocessing>data preprocessing</a>, and we ranked 4th in the subtask 1, 7th in the subtask2 and 3rd in the SubTask2-relaxed.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1142.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1142 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1142 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1142/>UMBC at SemEval-2018 Task 8 : Understanding Text about Malware<span class=acl-fixed-case>UMBC</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 8: Understanding Text about Malware</a></strong><br><a href=/people/a/ankur-padia/>Ankur Padia</a>
|
<a href=/people/a/arpita-roy/>Arpita Roy</a>
|
<a href=/people/t/taneeya-satyapanich/>Taneeya Satyapanich</a>
|
<a href=/people/f/francis-ferraro/>Francis Ferraro</a>
|
<a href=/people/s/shimei-pan/>Shimei Pan</a>
|
<a href=/people/y/youngja-park/>Youngja Park</a>
|
<a href=/people/a/anupam-joshi/>Anupam Joshi</a>
|
<a href=/people/t/tim-finin/>Tim Finin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1142><div class="card-body p-3 small">We describe the systems developed by the UMBC team for 2018 SemEval Task 8, SecureNLP (Semantic Extraction from CybersecUrity REports using Natural Language Processing). We participated in three of the sub-tasks : (1) classifying sentences as being relevant or irrelevant to malware, (2) predicting token labels for sentences, and (4) predicting attribute labels from the Malware Attribute Enumeration and Characterization vocabulary for defining malware characteristics. We achieve <a href=https://en.wikipedia.org/wiki/F-number>F1 score</a> of 50.34/18.0 (dev / test), 22.23 (test-data), and 31.98 (test-data) for Task1, Task2 and Task2 respectively. We also make our cybersecurity embeddings publicly available at.<url>http://bit.ly/cyber2vec</url>.\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1143.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1143 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1143 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1143/>Villani at SemEval-2018 Task 8 : Semantic Extraction from Cybersecurity Reports using <a href=https://en.wikipedia.org/wiki/Representation_learning>Representation Learning</a><span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 8: Semantic Extraction from Cybersecurity Reports using Representation Learning</a></strong><br><a href=/people/p/pablo-loyola/>Pablo Loyola</a>
|
<a href=/people/k/kugamoorthy-gajananan/>Kugamoorthy Gajananan</a>
|
<a href=/people/y/yuji-watanabe/>Yuji Watanabe</a>
|
<a href=/people/f/fumiko-satoh/>Fumiko Satoh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1143><div class="card-body p-3 small">In this paper, we describe our proposal for the task of Semantic Extraction from Cybersecurity Reports. The goal is to explore if <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing methods</a> can provide relevant and actionable knowledge to contribute to better understand <a href=https://en.wikipedia.org/wiki/Malice_(law)>malicious behavior</a>. Our method consists of an attention-based Bi-LSTM which achieved competitive performance of 0.57 for the Subtask 1. In the due process we also present ablation studies across multiple embeddings and their level of representation and also report the strategies we used to mitigate the extreme imbalance between classes.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1145.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1145 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1145 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1145/>Digital Operatives at SemEval-2018 Task 8 : Using dependency features for malware NLP<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 8: Using dependency features for malware <span class=acl-fixed-case>NLP</span></a></strong><br><a href=/people/c/chris-brew/>Chris Brew</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1145><div class="card-body p-3 small">The four sub-tasks of SecureNLP build towards a capability for quickly highlighting critical information from malware reports, such as the specific actions taken by a malware sample. Digital Operatives (DO) submitted to sub-tasks 1 and 2, using standard text analysis technology (text classification for sub-task 1, and a CRF for sub-task 2). Performance is broadly competitive with other submitted <a href=https://en.wikipedia.org/wiki/System>systems</a> on sub-task 1 and weak on sub-task 2. The annotation guidelines for the intermediate sub-tasks create a linkage to the final <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, which is both an annotation challenge and a potentially useful feature of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. The methods that DO chose do not attempt to make use of this <a href=https://en.wikipedia.org/wiki/Linkage_(mechanical)>linkage</a>, which may be a missed opportunity. This motivates a post-hoc error analysis. It appears that the annotation task is very hard, and that in some cases both deep conceptual knowledge and substantial surrounding context are needed in order to correctly classify sentences.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1147.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1147 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1147 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1147/>SJTU-NLP at SemEval-2018 Task 9 : Neural Hypernym Discovery with Term Embeddings<span class=acl-fixed-case>SJTU</span>-<span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 9: Neural Hypernym Discovery with Term Embeddings</a></strong><br><a href=/people/z/zhuosheng-zhang/>Zhuosheng Zhang</a>
|
<a href=/people/j/jiangtong-li/>Jiangtong Li</a>
|
<a href=/people/h/hai-zhao/>Hai Zhao</a>
|
<a href=/people/b/bingjie-tang/>Bingjie Tang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1147><div class="card-body p-3 small">This paper describes a hypernym discovery system for our participation in the SemEval-2018 Task 9, which aims to discover the best (set of) candidate hypernyms for input concepts or entities, given the search space of a pre-defined vocabulary. We introduce a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network architecture</a> for the concerned task and empirically study various neural network models to build the representations in latent space for words and phrases. The evaluated models include <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>convolutional neural network</a>, long-short term memory network, <a href=https://en.wikipedia.org/wiki/Gated_recurrent_unit>gated recurrent unit</a> and recurrent convolutional neural network. We also explore different embedding methods, including <a href=https://en.wikipedia.org/wiki/Word_embedding>word embedding</a> and sense embedding for better performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1148.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1148 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1148 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1148/>NLP_HZ at SemEval-2018 Task 9 : a Nearest Neighbor Approach<span class=acl-fixed-case>NLP</span>_<span class=acl-fixed-case>HZ</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 9: a Nearest Neighbor Approach</a></strong><br><a href=/people/w/wei-qiu/>Wei Qiu</a>
|
<a href=/people/m/mosha-chen/>Mosha Chen</a>
|
<a href=/people/l/linlin-li/>Linlin Li</a>
|
<a href=/people/l/luo-si/>Luo Si</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1148><div class="card-body p-3 small">Hypernym discovery aims to discover the hypernym word sets given a <a href=https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy>hyponym word</a> and proper corpus. This paper proposes a simple but effective method for the discovery of hypernym sets based on <a href=https://en.wikipedia.org/wiki/Word_embedding>word embedding</a>, which can be used to measure the contextual similarities between words. Given a test <a href=https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy>hyponym word</a>, we get its hypernym lists by computing the similarities between the <a href=https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy>hyponym word</a> and words in the training data, and fill the test word&#8217;s hypernym lists with the hypernym list in the training set of the nearest similarity distance to the test word. In SemEval 2018 task9, our results, achieve 1st on <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>, 2nd on <a href=https://en.wikipedia.org/wiki/Italian_language>Italian</a>, 6th on <a href=https://en.wikipedia.org/wiki/English_language>English</a> in the metric of MAP.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1149.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1149 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1149 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1149/>UMDuluth-CS8761 at SemEval-2018 Task9 : Hypernym Discovery using Hearst Patterns, Co-occurrence frequencies and Word Embeddings<span class=acl-fixed-case>UMD</span>uluth-<span class=acl-fixed-case>CS</span>8761 at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task9: Hypernym Discovery using Hearst Patterns, Co-occurrence frequencies and Word Embeddings</a></strong><br><a href=/people/a/arshia-zernab-hassan/>Arshia Zernab Hassan</a>
|
<a href=/people/m/manikya-swathi-vallabhajosyula/>Manikya Swathi Vallabhajosyula</a>
|
<a href=/people/t/ted-pedersen/>Ted Pedersen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1149><div class="card-body p-3 small">Hypernym Discovery is the task of identifying potential <a href=https://en.wikipedia.org/wiki/Hypernym>hypernyms</a> for a given term. A <a href=https://en.wikipedia.org/wiki/Hypernym>hypernym</a> is a more generalized word that is super-ordinate to more specific words. This paper explores several approaches that rely on co-occurrence frequencies of word pairs, Hearst Patterns based on regular expressions, and word embeddings created from the UMBC corpus. Our system <a href=https://en.wikipedia.org/wiki/Charles_Babbage>Babbage</a> participated in Subtask 1A for <a href=https://en.wikipedia.org/wiki/English_language>English</a> and placed 6th of 19 systems when identifying concept hypernyms, and 12th of 18 systems for entity hypernyms.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1150.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1150 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1150 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1150/>EXPR at SemEval-2018 Task 9 : A Combined Approach for Hypernym Discovery<span class=acl-fixed-case>EXPR</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 9: A Combined Approach for Hypernym Discovery</a></strong><br><a href=/people/a/ahmad-issa-alaa-aldine/>Ahmad Issa Alaa Aldine</a>
|
<a href=/people/m/mounira-harzallah/>Mounira Harzallah</a>
|
<a href=/people/g/giuseppe-berio/>Giuseppe Berio</a>
|
<a href=/people/n/nicolas-bechet/>Nicolas Béchet</a>
|
<a href=/people/a/ahmad-faour/>Ahmad Faour</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1150><div class="card-body p-3 small">In this paper, we present our proposed <a href=https://en.wikipedia.org/wiki/System>system</a> (EXPR) to participate in the hypernym discovery task of SemEval 2018. The <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> addresses the challenge of discovering hypernym relations from a <a href=https://en.wikipedia.org/wiki/Text_corpus>text corpus</a>. Our proposal is a combined approach of path-based technique and distributional technique. We use dependency parser on a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> to extract candidate hypernyms and represent their dependency paths as a <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature vector</a>. The <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature vector</a> is concatenated with a <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature vector</a> obtained using Wikipedia pre-trained term embedding model. The concatenated feature vector fits a supervised machine learning method to learn a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier model</a>. This <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is able to classify new candidate hypernyms as <a href=https://en.wikipedia.org/wiki/Hypernym>hypernym</a> or not. Our <a href=https://en.wikipedia.org/wiki/System>system</a> performs well to discover new <a href=https://en.wikipedia.org/wiki/Hypernym>hypernyms</a> not defined in gold hypernyms.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1154.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1154 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1154 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1154/>Meaning_space at SemEval-2018 Task 10 : Combining explicitly encoded knowledge with information extracted from word embeddings<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 10: Combining explicitly encoded knowledge with information extracted from word embeddings</a></strong><br><a href=/people/p/pia-sommerauer/>Pia Sommerauer</a>
|
<a href=/people/a/antske-fokkens/>Antske Fokkens</a>
|
<a href=/people/p/piek-vossen/>Piek Vossen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1154><div class="card-body p-3 small">This paper presents the two systems submitted by the meaning space team in Task 10 of the SemEval competition 2018 entitled Capturing discriminative attributes. The systems consist of combinations of approaches exploiting explicitly encoded knowledge about concepts in <a href=https://en.wikipedia.org/wiki/WordNet>WordNet</a> and information encoded in distributional semantic vectors. Rather than aiming for high performance, we explore which kind of <a href=https://en.wikipedia.org/wiki/Semantic_property>semantic knowledge</a> is best captured by different methods. The results indicate that WordNet glosses on different levels of the <a href=https://en.wikipedia.org/wiki/Hierarchy>hierarchy</a> capture many attributes relevant for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. In combination with exploiting word embedding similarities, this source of information yielded our best results. Our best performing <a href=https://en.wikipedia.org/wiki/System>system</a> ranked 5th out of 13 final ranks. Our analysis yields insights into the different kinds of attributes represented by different sources of knowledge.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1156.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1156 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1156 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1156/>CitiusNLP at SemEval-2018 Task 10 : The Use of Transparent Distributional Models and Salient Contexts to Discriminate Word Attributes<span class=acl-fixed-case>C</span>itius<span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 10: The Use of Transparent Distributional Models and Salient Contexts to Discriminate Word Attributes</a></strong><br><a href=/people/p/pablo-gamallo/>Pablo Gamallo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1156><div class="card-body p-3 small">This article describes the <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised strategy</a> submitted by the CitiusNLP team to the SemEval 2018 Task 10, a task which consists of predict whether a word is a discriminative attribute between two other words. Our strategy relies on the correspondence between discriminative attributes and relevant contexts of a word. More precisely, the method uses transparent distributional models to extract salient contexts of words which are identified as discriminative attributes. The <a href=https://en.wikipedia.org/wiki/System>system</a> performance reaches about 70 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> when it is applied on the development dataset, but its <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> goes down (63 %) on the official test dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1157.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1157 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1157 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1157/>THU_NGN at SemEval-2018 Task 10 : Capturing Discriminative Attributes with MLP-CNN model<span class=acl-fixed-case>THU</span>_<span class=acl-fixed-case>NGN</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 10: Capturing Discriminative Attributes with <span class=acl-fixed-case>MLP</span>-<span class=acl-fixed-case>CNN</span> model</a></strong><br><a href=/people/c/chuhan-wu/>Chuhan Wu</a>
|
<a href=/people/f/fangzhao-wu/>Fangzhao Wu</a>
|
<a href=/people/s/sixing-wu/>Sixing Wu</a>
|
<a href=/people/z/zhigang-yuan/>Zhigang Yuan</a>
|
<a href=/people/y/yongfeng-huang/>Yongfeng Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1157><div class="card-body p-3 small">Existing semantic models are capable of identifying the semantic similarity of words. However, it&#8217;s hard for these <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> to discriminate between a word and another similar word. Thus, the aim of SemEval-2018 Task 10 is to predict whether a word is a discriminative attribute between two concepts. In this task, we apply a multilayer perceptron (MLP)-convolutional neural network (CNN) model to identify whether an attribute is discriminative. The CNNs are used to extract low-level features from the inputs. The MLP takes both the flatten CNN maps and inputs to predict the labels. The evaluation F-score of our <a href=https://en.wikipedia.org/wiki/System>system</a> on the test set is 0.629 (ranked 15th), which indicates that our <a href=https://en.wikipedia.org/wiki/System>system</a> still needs to be improved. However, the behaviours of our <a href=https://en.wikipedia.org/wiki/System>system</a> in our experiments provide useful information, which can help to improve the collective understanding of this novel <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1158.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1158 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1158 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1158/>ALB at SemEval-2018 Task 10 : A System for Capturing Discriminative Attributes<span class=acl-fixed-case>ALB</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 10: A System for Capturing Discriminative Attributes</a></strong><br><a href=/people/b/bogdan-dumitru/>Bogdan Dumitru</a>
|
<a href=/people/a/alina-maria-ciobanu/>Alina Maria Ciobanu</a>
|
<a href=/people/l/liviu-p-dinu/>Liviu P. Dinu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1158><div class="card-body p-3 small">Semantic difference detection attempts to capture whether a word is a discriminative attribute between two other words. For example, the discriminative feature red characterizes the first word from the (apple, banana) pair, but not the second. Modeling semantic difference is essential for <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>language understanding systems</a>, as it provides useful information for identifying particular aspects of <a href=https://en.wikipedia.org/wiki/Word_sense>word senses</a>. This paper describes our <a href=https://en.wikipedia.org/wiki/System>system</a> implementation (the ALB system of the NLP@Unibuc team) for the 10th task of the SemEval 2018 workshop, Capturing Discriminative Attributes. We propose a method for semantic difference detection that uses an SVM classifier with <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> based on co-occurrence counts and shallow semantic parsing, achieving 0.63 F1 score in the competition.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1159.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1159 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1159 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1159/>ELiRF-UPV at SemEval-2018 Task 10 : Capturing Discriminative Attributes with Knowledge Graphs and Wikipedia<span class=acl-fixed-case>EL</span>i<span class=acl-fixed-case>RF</span>-<span class=acl-fixed-case>UPV</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 10: Capturing Discriminative Attributes with Knowledge Graphs and <span class=acl-fixed-case>W</span>ikipedia</a></strong><br><a href=/people/j/jose-angel-gonzalez/>José-Ángel González</a>
|
<a href=/people/l/lluis-f-hurtado/>Lluís-F. Hurtado</a>
|
<a href=/people/e/encarna-segarra/>Encarna Segarra</a>
|
<a href=/people/f/ferran-pla/>Ferran Pla</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1159><div class="card-body p-3 small">This paper describes the participation of ELiRF-UPV team at task 10, Capturing Discriminative Attributes, of SemEval-2018. Our best approach consists of using <a href=https://en.wikipedia.org/wiki/ConceptNet>ConceptNet</a>, <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a> and NumberBatch embeddings in order to stablish relationships between concepts and attributes. Furthermore, this <a href=https://en.wikipedia.org/wiki/System>system</a> achieves competitive results in the official evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1160.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1160 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1160 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1160/>Wolves at SemEval-2018 Task 10 : Semantic Discrimination based on Knowledge and Association<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 10: Semantic Discrimination based on Knowledge and Association</a></strong><br><a href=/people/s/shiva-taslimipoor/>Shiva Taslimipoor</a>
|
<a href=/people/o/omid-rohanian/>Omid Rohanian</a>
|
<a href=/people/l/le-an-ha/>Le An Ha</a>
|
<a href=/people/g/gloria-corpas-pastor/>Gloria Corpas Pastor</a>
|
<a href=/people/r/ruslan-mitkov/>Ruslan Mitkov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1160><div class="card-body p-3 small">This paper describes the <a href=https://en.wikipedia.org/wiki/System>system</a> submitted to SemEval 2018 shared task 10 &#8216;Capturing Dicriminative Attributes&#8217;. We use a combination of knowledge-based and co-occurrence features to capture the semantic difference between two words in relation to an attribute. We define scores based on association measures, <a href=https://en.wikipedia.org/wiki/Grammatical_number>ngram counts</a>, word similarity, and ConceptNet relations. The <a href=https://en.wikipedia.org/wiki/System>system</a> is ranked 4th (joint) on the official leaderboard of the task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1162.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1162 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1162 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=S18-1162" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/S18-1162/>Luminoso at SemEval-2018 Task 10 : Distinguishing Attributes Using Text Corpora and Relational Knowledge<span class=acl-fixed-case>L</span>uminoso at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 10: Distinguishing Attributes Using Text Corpora and Relational Knowledge</a></strong><br><a href=/people/r/robyn-speer/>Robyn Speer</a>
|
<a href=/people/j/joanna-lowry-duda/>Joanna Lowry-Duda</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1162><div class="card-body p-3 small">Luminoso participated in the SemEval 2018 task on Capturing Discriminative Attributes with a system based on <a href=https://en.wikipedia.org/wiki/ConceptNet>ConceptNet</a>, an open knowledge graph focused on <a href=https://en.wikipedia.org/wiki/General_knowledge>general knowledge</a>. In this paper, we describe how we trained a <a href=https://en.wikipedia.org/wiki/Linear_classifier>linear classifier</a> on a small number of semantically-informed features to achieve an F1 score of 0.7368 on the task, close to the task&#8217;s high score of 0.75.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1163.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1163 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1163 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1163/>BomJi at SemEval-2018 Task 10 : Combining Vector-, Pattern- and Graph-based Information to Identify Discriminative Attributes<span class=acl-fixed-case>B</span>om<span class=acl-fixed-case>J</span>i at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 10: Combining Vector-, Pattern- and Graph-based Information to Identify Discriminative Attributes</a></strong><br><a href=/people/e/enrico-santus/>Enrico Santus</a>
|
<a href=/people/c/chris-biemann/>Chris Biemann</a>
|
<a href=/people/e/emmanuele-chersoni/>Emmanuele Chersoni</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1163><div class="card-body p-3 small">This paper describes BomJi, a <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised system</a> for capturing discriminative attributes in word pairs (e.g. yellow as discriminative for banana over watermelon). The system relies on an XGB classifier trained on carefully engineered graph-, pattern- and word embedding-based features. It participated in the SemEval-2018 Task 10 on Capturing Discriminative Attributes, achieving an F1 score of 0.73 and ranking 2nd out of 26 participant systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1164.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1164 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1164 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1164/>Igevorse at SemEval-2018 Task 10 : Exploring an Impact of Word Embeddings Concatenation for Capturing Discriminative Attributes<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 10: Exploring an Impact of Word Embeddings Concatenation for Capturing Discriminative Attributes</a></strong><br><a href=/people/m/maxim-grishin/>Maxim Grishin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1164><div class="card-body p-3 small">This paper presents a comparison of several approaches for capturing discriminative attributes and considers an impact of <a href=https://en.wikipedia.org/wiki/Concatenation>concatenation</a> of several <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> of different nature on the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> performance. A similarity-based method is proposed and compared with classical machine learning approaches. It is shown that this method outperforms others on all the considered word vector models and there is a performance increase when concatenated datasets are used.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1166.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1166 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1166 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1166/>AmritaNLP at SemEval-2018 Task 10 : Capturing discriminative attributes using convolution neural network over global vector representation.<span class=acl-fixed-case>A</span>mrita<span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 10: Capturing discriminative attributes using convolution neural network over global vector representation.</a></strong><br><a href=/people/v/vivek-vinayan/>Vivek Vinayan</a>
|
<a href=/people/a/anand-kumar-m/>Anand Kumar M</a>
|
<a href=/people/s/soman-k-p/>Soman K P</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1166><div class="card-body p-3 small">The Capturing Discriminative Attributes sharedtask is the tenth <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>, conjoint with SemEval2018. The task is to predict if a word can capture distinguishing attributes of one word from another. We use GloVe word embedding, pre-trained on openly sourced corpus for this task. A base <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representation</a> is initially established over varied dimensions. These representations are evaluated based on validation scores over two <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>, first on an SVM based classifier and second on a one dimension CNN model. The scores are used to further develop the <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representation</a> with vector combinations, by considering various distance measures. These measures correspond to offset vectors which are concatenated as <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a>, mainly to improve upon the F1score, with the best <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. The <a href=https://en.wikipedia.org/wiki/Software_feature>features</a> are then further tuned on the validation scores, to achieve highest F1score. Our evaluation narrowed down to two <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representations</a>, classified on CNN models, having a total dimension length of 1204 & 1203 for the final submissions. Of the two, the latter feature representation delivered our best F1score of 0.658024 (as per result).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1167.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1167 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1167 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1167/>Discriminator at SemEval-2018 Task 10 : Minimally Supervised Discrimination<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 10: Minimally Supervised Discrimination</a></strong><br><a href=/people/a/artur-kulmizev/>Artur Kulmizev</a>
|
<a href=/people/m/mostafa-abdou/>Mostafa Abdou</a>
|
<a href=/people/v/vinit-ravishankar/>Vinit Ravishankar</a>
|
<a href=/people/m/malvina-nissim/>Malvina Nissim</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1167><div class="card-body p-3 small">We participated to the SemEval-2018 shared task on capturing discriminative attributes (Task 10) with a simple system that ranked 8th amongst the 26 teams that took part in the evaluation. Our final score was 0.67, which is competitive with the winning score of 0.75, particularly given that our <a href=https://en.wikipedia.org/wiki/System>system</a> is a zero-shot system that requires no training and minimal parameter optimisation. In addition to describing the submitted <a href=https://en.wikipedia.org/wiki/System>system</a>, and discussing the implications of the relative success of such a <a href=https://en.wikipedia.org/wiki/System>system</a> on this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, we also report on other, more complex models we experimented with.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1170.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1170 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1170 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1170/>UMD at SemEval-2018 Task 10 : Can Word Embeddings Capture Discriminative Attributes?<span class=acl-fixed-case>UMD</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 10: Can Word Embeddings Capture Discriminative Attributes?</a></strong><br><a href=/people/a/alexander-zhang/>Alexander Zhang</a>
|
<a href=/people/m/marine-carpuat/>Marine Carpuat</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1170><div class="card-body p-3 small">We describe the University of Maryland&#8217;s submission to SemEval-018 Task 10, Capturing Discriminative Attributes : given word triples (w1, w2, d), the goal is to determine whether d is a discriminating attribute belonging to w1 but not w2. Our study aims to determine whether <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> can address this challenging task. Our submission casts this <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> as supervised binary classification using only word embedding features. Using a gaussian SVM model trained only on <a href=https://en.wikipedia.org/wiki/Data_validation>validation data</a> results in an <a href=https://en.wikipedia.org/wiki/F-score>F-score</a> of 60 %. We also show that cosine similarity features are more effective, both in <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised systems</a> (F-score of 65 %) and <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised systems</a> (F-score of 67 %).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1171.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1171 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1171 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1171/>NTU NLP Lab System at SemEval-2018 Task 10 : Verifying Semantic Differences by Integrating Distributional Information and Expert Knowledge<span class=acl-fixed-case>NTU</span> <span class=acl-fixed-case>NLP</span> Lab System at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 10: Verifying Semantic Differences by Integrating Distributional Information and Expert Knowledge</a></strong><br><a href=/people/y/yow-ting-shiue/>Yow-Ting Shiue</a>
|
<a href=/people/h/hen-hsen-huang/>Hen-Hsen Huang</a>
|
<a href=/people/h/hsin-hsi-chen/>Hsin-Hsi Chen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1171><div class="card-body p-3 small">This paper presents the NTU NLP Lab system for the SemEval-2018 Capturing Discriminative Attributes task. Word embeddings, pointwise mutual information (PMI), ConceptNet edges and shortest path lengths are utilized as input features to build binary classifiers to tell whether an attribute is discriminative for a pair of concepts. Our <a href=https://en.wikipedia.org/wiki/Neural_network>neural network model</a> reaches about 73 % F1 score on the test set and ranks the 3rd in the task. Though the <a href=https://en.wikipedia.org/wiki/Attribute_(computing)>attributes</a> to deal with in this task are all visual, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are not provided with any <a href=https://en.wikipedia.org/wiki/Image>image data</a>. The results indicate that <a href=https://en.wikipedia.org/wiki/Visual_system>visual information</a> can be derived from <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>textual data</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1172.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1172 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1172 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1172/>ELiRF-UPV at SemEval-2018 Task 11 : Machine Comprehension using Commonsense Knowledge<span class=acl-fixed-case>EL</span>i<span class=acl-fixed-case>RF</span>-<span class=acl-fixed-case>UPV</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 11: Machine Comprehension using Commonsense Knowledge</a></strong><br><a href=/people/j/jose-angel-gonzalez/>José-Ángel González</a>
|
<a href=/people/l/lluis-f-hurtado/>Lluís-F. Hurtado</a>
|
<a href=/people/e/encarna-segarra/>Encarna Segarra</a>
|
<a href=/people/f/ferran-pla/>Ferran Pla</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1172><div class="card-body p-3 small">This paper describes the participation of ELiRF-UPV team at task 11, <a href=https://en.wikipedia.org/wiki/Machine_learning>Machine Comprehension</a> using Commonsense Knowledge, of SemEval-2018. Our approach is based on the use of word embeddings, NumberBatch Embeddings, and a Deep Learning architecture to find the best answer for the multiple-choice questions based on the narrative text. The results obtained are in line with those obtained by the other participants and they encourage us to continue working on this problem.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1174.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1174 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1174 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1174/>YNU_Deep at SemEval-2018 Task 11 : An Ensemble of Attention-based BiLSTM Models for Machine Comprehension<span class=acl-fixed-case>YNU</span>_<span class=acl-fixed-case>D</span>eep at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 11: An Ensemble of Attention-based <span class=acl-fixed-case>B</span>i<span class=acl-fixed-case>LSTM</span> Models for Machine Comprehension</a></strong><br><a href=/people/p/peng-ding/>Peng Ding</a>
|
<a href=/people/x/xiaobing-zhou/>Xiaobing Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1174><div class="card-body p-3 small">We firstly use GloVe to learn the distributed representations automatically from the instance, question and answer triples. Then an attentionbased Bidirectional LSTM (BiLSTM) model is used to encode the triples. We also perform a simple <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensemble method</a> to improve the effectiveness of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. The <a href=https://en.wikipedia.org/wiki/System>system</a> we developed obtains an encouraging result on this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. It achieves the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> 0.7472 on the test set. We rank 5th according to the official ranking.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1176.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1176 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1176 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1176/>CSReader at SemEval-2018 Task 11 : Multiple Choice Question Answering as Textual Entailment<span class=acl-fixed-case>CSR</span>eader at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 11: Multiple Choice Question Answering as Textual Entailment</a></strong><br><a href=/people/z/zheng-ping-jiang/>Zhengping Jiang</a>
|
<a href=/people/q/qi-sun/>Qi Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1176><div class="card-body p-3 small">In this document we present an end-to-end machine reading comprehension system that solves multiple choice questions with a textual entailment perspective. Since some of the knowledge required is not explicitly mentioned in the text, we try to exploit commonsense knowledge by using pretrained word embeddings during contextual embeddings and by dynamically generating a weighted representation of related script knowledge. In the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> two kinds of prediction structure are ensembled, and the final <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of our <a href=https://en.wikipedia.org/wiki/System>system</a> is 10 percent higher than the naiive baseline.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1177.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1177 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1177 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1177/>YNU-HPCC at Semeval-2018 Task 11 : Using an Attention-based CNN-LSTM for Machine Comprehension using Commonsense Knowledge<span class=acl-fixed-case>YNU</span>-<span class=acl-fixed-case>HPCC</span> at <span class=acl-fixed-case>S</span>emeval-2018 Task 11: Using an Attention-based <span class=acl-fixed-case>CNN</span>-<span class=acl-fixed-case>LSTM</span> for Machine Comprehension using Commonsense Knowledge</a></strong><br><a href=/people/h/hang-yuan/>Hang Yuan</a>
|
<a href=/people/j/jin-wang/>Jin Wang</a>
|
<a href=/people/x/xuejie-zhang/>Xuejie Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1177><div class="card-body p-3 small">This shared task is a typical <a href=https://en.wikipedia.org/wiki/Question_answering>question answering task</a>. Compared with the normal question and answer system, it needs to give the answer to the question based on the text provided. The essence of the problem is actually <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a>. Typically, there are several questions for each text that correspond to it. And for each question, there are two candidate answers (and only one of them is correct). To solve this problem, the usual approach is to use <a href=https://en.wikipedia.org/wiki/Convolutional_neural_network>convolutional neural networks (CNN)</a> and <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural network (RNN)</a> or their improved models (such as long short-term memory (LSTM)). In this paper, an attention-based CNN-LSTM model is proposed for this task. By adding an <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanism</a> and combining the two <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>, this experimental result has been significantly improved.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1178.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1178 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1178 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1178/>Jiangnan at SemEval-2018 Task 11 : Deep Neural Network with Attention Method for Machine Comprehension Task<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 11: Deep Neural Network with Attention Method for Machine Comprehension Task</a></strong><br><a href=/people/j/jiangnan-xia/>Jiangnan Xia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1178><div class="card-body p-3 small">This paper describes our submission for the International Workshop on Semantic Evaluation (SemEval-2018) shared task 11 Machine Comprehension using Commonsense Knowledge (Ostermann et al., 2018b). We use a deep neural network model to choose the correct answer from the candidate answers pair when the document and question are given. The interactions between document, question and answers are modeled by attention mechanism and a variety of manual features are used to improve <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performance. We also use CoVe (McCann et al., 2017) as an external source of knowledge which is not mentioned in the document. As a result, our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves 80.91 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on the test data, which is on the third place of the leaderboard.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1180.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1180 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1180 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1180/>Lyb3b at SemEval-2018 Task 11 : Machine Comprehension Task using Deep Learning Models<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 11: Machine Comprehension Task using Deep Learning Models</a></strong><br><a href=/people/y/yongbin-li/>Yongbin Li</a>
|
<a href=/people/x/xiaobing-zhou/>Xiaobing Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1180><div class="card-body p-3 small">Machine Comprehension of text is a typical Natural Language Processing task which remains an elusive challenge. This paper is to solve the task 11 of SemEval-2018, <a href=https://en.wikipedia.org/wiki/Machine_learning>Machine Comprehension</a> using Commonsense Knowledge task. We use deep learning model to solve the problem. We build distributed word embedding of text, question and answering respectively instead of manually extracting features by linguistic tools. Meanwhile, we use a series of frameworks such as CNN model, LSTM model, LSTM with attention model and biLSTM with attention model for processing word vector. Experiments demonstrate the superior performance of biLSTM with attention framework compared to other <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. We also delete high frequency words and combine <a href=https://en.wikipedia.org/wiki/Word_vector>word vector and data augmentation methods</a>, achieved a certain effect. The approach we proposed rank 6th in official results, with <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy rate</a> of 0.7437 in test dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1181.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1181 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1181 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1181/>MITRE at SemEval-2018 Task 11 : Commonsense Reasoning without Commonsense Knowledge<span class=acl-fixed-case>MITRE</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 11: Commonsense Reasoning without Commonsense Knowledge</a></strong><br><a href=/people/e/elizabeth-merkhofer/>Elizabeth Merkhofer</a>
|
<a href=/people/j/john-henderson/>John Henderson</a>
|
<a href=/people/d/david-bloom/>David Bloom</a>
|
<a href=/people/l/laura-strickhart/>Laura Strickhart</a>
|
<a href=/people/g/guido-zarrella/>Guido Zarrella</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1181><div class="card-body p-3 small">This paper describes MITRE&#8217;s participation in SemEval-2018 Task 11 : Machine Comprehension using Commonsense Knowledge. The techniques explored range from simple bag-of-ngrams classifiers to neural architectures with varied attention and alignment mechanisms. Logistic regression ties the <a href=https://en.wikipedia.org/wiki/System>systems</a> together into an <a href=https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)>ensemble</a> submitted for evaluation. The resulting <a href=https://en.wikipedia.org/wiki/System>system</a> answers <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension questions</a> with 82.27 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1182.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1182 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1182 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=S18-1182" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/S18-1182/>SNU_IDS at SemEval-2018 Task 12 : Sentence Encoder with Contextualized Vectors for Argument Reasoning Comprehension<span class=acl-fixed-case>SNU</span>_<span class=acl-fixed-case>IDS</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 12: Sentence Encoder with Contextualized Vectors for Argument Reasoning Comprehension</a></strong><br><a href=/people/t/taeuk-kim/>Taeuk Kim</a>
|
<a href=/people/j/jihun-choi/>Jihun Choi</a>
|
<a href=/people/s/sang-goo-lee/>Sang-goo Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1182><div class="card-body p-3 small">We present a novel neural architecture for the Argument Reasoning Comprehension task of SemEval 2018. It is a simple <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> consisting of three parts, collectively judging whether the logic built on a set of given sentences (a claim, reason, and warrant) is plausible or not. The model utilizes contextualized word vectors pre-trained on large machine translation (MT) datasets as a form of <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a>, which can help to mitigate the lack of training data. Quantitative analysis shows that simply leveraging LSTMs trained on MT datasets outperforms several baselines and non-transferred models, achieving accuracies of about 70 % on the development set and about 60 % on the test set.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1183.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1183 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1183 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1183/>ITNLP-ARC at SemEval-2018 Task 12 : Argument Reasoning Comprehension with Attention<span class=acl-fixed-case>ITNLP</span>-<span class=acl-fixed-case>ARC</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 12: Argument Reasoning Comprehension with Attention</a></strong><br><a href=/people/w/wenjie-liu/>Wenjie Liu</a>
|
<a href=/people/c/cheng-jie-sun/>Chengjie Sun</a>
|
<a href=/people/l/lei-lin/>Lei Lin</a>
|
<a href=/people/b/bingquan-liu/>Bingquan Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1183><div class="card-body p-3 small">Reasoning is a very important topic and has many important applications in the field of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. Semantic Evaluation (SemEval) 2018 Task 12 The Argument Reasoning Comprehension committed to research <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language reasoning</a>. In this task, we proposed a novel argument reasoning comprehension system, ITNLP-ARC, which use Neural Networks technology to solve this problem. In our system, the LSTM model is involved to encode both the premise sentences and the warrant sentences. The attention model is used to merge the two premise sentence vectors. Through comparing the similarity between the <a href=https://en.wikipedia.org/wiki/Attention>attention vector</a> and each of the two warrant vectors, we choose the one with higher similarity as our system&#8217;s final answer.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1184.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1184 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1184 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1184/>ECNU at SemEval-2018 Task 12 : An End-to-End Attention-based Neural Network for the Argument Reasoning Comprehension Task<span class=acl-fixed-case>ECNU</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 12: An End-to-End Attention-based Neural Network for the Argument Reasoning Comprehension Task</a></strong><br><a href=/people/j/junfeng-tian/>Junfeng Tian</a>
|
<a href=/people/m/man-lan/>Man Lan</a>
|
<a href=/people/y/yuanbin-wu/>Yuanbin Wu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1184><div class="card-body p-3 small">This paper presents our submissions to SemEval 2018 Task 12 : the Argument Reasoning Comprehension Task. We investigate an end-to-end attention-based neural network to represent the two lexically close candidate warrants. On the one hand, we extract their different parts as attention vectors to obtain distinguishable representations. On the other hand, we use their surrounds (i.e., claim, reason, debate context) as another <a href=https://en.wikipedia.org/wiki/Attention>attention vectors</a> to get contextual representations, which work as final clues to select the correct warrant. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves 60.4 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and ranks 3rd among 22 participating systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1185.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1185 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1185 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=S18-1185" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/S18-1185/>NLITrans at SemEval-2018 Task 12 : Transfer of Semantic Knowledge for Argument Comprehension<span class=acl-fixed-case>NLIT</span>rans at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 12: Transfer of Semantic Knowledge for Argument Comprehension</a></strong><br><a href=/people/t/timothy-niven/>Timothy Niven</a>
|
<a href=/people/h/hung-yu-kao/>Hung-Yu Kao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1185><div class="card-body p-3 small">The Argument Reasoning Comprehension Task is a difficult challenge requiring significant <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>language understanding</a> and complex reasoning over <a href=https://en.wikipedia.org/wiki/Epistemology>world knowledge</a>. We focus on transfer of a sentence encoder to bootstrap more complicated architectures given the small size of the dataset. Our best model uses a pre-trained BiLSTM to encode input sentences, learns task-specific features for the argument and warrants, then performs independent argument-warrant matching. This <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves mean test set accuracy of 61.31 %. Encoder transfer yields a significant gain to our best <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> over random initialization. Sharing parameters for independent warrant evaluation provides regularization and effectively doubles the size of the dataset. We demonstrate that <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularization</a> comes from ignoring statistical correlations between warrant positions. We also report an experiment with our best <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> that only matches warrants to reasons, ignoring claims. Performance is still competitive, suggesting that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is not necessarily learning the intended task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1186.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1186 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1186 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1186/>BLCU_NLP at SemEval-2018 Task 12 : An Ensemble Model for Argument Reasoning Based on Hierarchical Attention<span class=acl-fixed-case>BLCU</span>_<span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 12: An Ensemble Model for Argument Reasoning Based on Hierarchical Attention</a></strong><br><a href=/people/m/meiqian-zhao/>Meiqian Zhao</a>
|
<a href=/people/c/chunhua-liu/>Chunhua Liu</a>
|
<a href=/people/l/lu-liu/>Lu Liu</a>
|
<a href=/people/y/yan-zhao/>Yan Zhao</a>
|
<a href=/people/d/dong-yu/>Dong Yu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1186><div class="card-body p-3 small">To comprehend an argument and fill the gap between claims and reasons, it is vital to find the implicit supporting warrants behind. In this paper, we propose a hierarchical attention model to identify the right warrant which explains why the reason stands for the claim. Our model focuses not only on the similar part between warrants and other information but also on the contradictory part between two opposing warrants. In addition, we use the ensemble method for different <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 61 %, ranking second in this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. Experimental results demonstrate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is effective to make correct choices.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1189.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1189 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1189 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1189/>YNU Deep at SemEval-2018 Task 12 : A BiLSTM Model with Neural Attention for Argument Reasoning Comprehension<span class=acl-fixed-case>YNU</span> Deep at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 12: A <span class=acl-fixed-case>B</span>i<span class=acl-fixed-case>LSTM</span> Model with Neural Attention for Argument Reasoning Comprehension</a></strong><br><a href=/people/p/peng-ding/>Peng Ding</a>
|
<a href=/people/x/xiaobing-zhou/>Xiaobing Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1189><div class="card-body p-3 small">This paper describes the system submitted to SemEval-2018 Task 12 (The Argument Reasoning Comprehension Task). Enabling a computer to understand a text so that it can answer comprehension questions is still a challenging goal of <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP</a>. We propose a Bidirectional LSTM (BiLSTM) model that reads two sentences separated by a delimiter to determine which warrant is correct. We extend this <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> with a neural attention mechanism that encourages the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to make reasoning over the given claims and reasons. Officially released results show that our <a href=https://en.wikipedia.org/wiki/System>system</a> ranks 6th among 22 submissions to this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1190.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1190 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1190 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1190/>UniMelb at SemEval-2018 Task 12 : Generative Implication using LSTMs, Siamese Networks and Semantic Representations with Synonym Fuzzing<span class=acl-fixed-case>U</span>ni<span class=acl-fixed-case>M</span>elb at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 12: Generative Implication using <span class=acl-fixed-case>LSTM</span>s, <span class=acl-fixed-case>S</span>iamese Networks and Semantic Representations with Synonym Fuzzing</a></strong><br><a href=/people/a/anirudh-joshi/>Anirudh Joshi</a>
|
<a href=/people/t/timothy-baldwin/>Tim Baldwin</a>
|
<a href=/people/r/richard-o-sinnott/>Richard O. Sinnott</a>
|
<a href=/people/c/cecile-paris/>Cecile Paris</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1190><div class="card-body p-3 small">This paper describes a warrant classification system for SemEval 2018 Task 12, that attempts to learn semantic representations of reasons, claims and warrants. The system consists of 3 stacked LSTMs : one for the reason, one for the claim, and one shared Siamese Network for the 2 candidate warrants. Our main contribution is to force the embeddings into a shared feature space using vector operations, semantic similarity classification, Siamese networks, and <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a>. In doing so, we learn a form of generative implication, in encoding implication interrelationships between reasons, claims, and the associated correct and incorrect warrants. We augment the limited data in the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> further by utilizing WordNet synonym fuzzing. When applied to SemEval 2018 Task 12, our <a href=https://en.wikipedia.org/wiki/System>system</a> performs well on the development data, and officially ranked 8th among 21 teams.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1191.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1191 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1191 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1191/>Joker at SemEval-2018 Task 12 : The Argument Reasoning Comprehension with Neural Attention<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 12: The Argument Reasoning Comprehension with Neural Attention</a></strong><br><a href=/people/g/guobin-sui/>Guobin Sui</a>
|
<a href=/people/w/wenhan-chao/>Wenhan Chao</a>
|
<a href=/people/z/zhunchen-luo/>Zhunchen Luo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1191><div class="card-body p-3 small">This paper describes a classification system that participated in the SemEval-2018 Task 12 : The Argument Reasoning Comprehension Task. Briefly the task can be described as that a natural language argument is what we have, with reason, claim, and correct and incorrect warrants, and we need to choose the correct warrant. In order to make fully understand of the <a href=https://en.wikipedia.org/wiki/Semantics>semantic information</a> of the sentences, we proposed a neural network architecture with <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanism</a> to achieve this goal. Besides we try to introduce <a href=https://en.wikipedia.org/wiki/Index_term>keywords</a> into the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to improve <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. Finally the proposed <a href=https://en.wikipedia.org/wiki/System>system</a> achieved 5th place among 22 participating systems</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/S18-1194.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-S18-1194 data-toggle=collapse aria-expanded=false aria-controls=abstract-S18-1194 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/S18-1194/>TRANSRW at SemEval-2018 Task 12 : Transforming Semantic Representations for Argument Reasoning Comprehension<span class=acl-fixed-case>TRANSRW</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2018 Task 12: Transforming Semantic Representations for Argument Reasoning Comprehension</a></strong><br><a href=/people/z/zhimin-chen/>Zhimin Chen</a>
|
<a href=/people/w/wei-song/>Wei Song</a>
|
<a href=/people/l/lizhen-liu/>Lizhen Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-S18-1194><div class="card-body p-3 small">This paper describes our <a href=https://en.wikipedia.org/wiki/System>system</a> in SemEval-2018 task 12 : Argument Reasoning Comprehension. The task is to select the correct warrant that explains reasoning of a particular argument consisting of a claim and a reason. The main idea of our methods is based on the assumption that the semantic composition of the reason and the warrant should be close to the semantic representation of the corresponding claim. We propose two neural network models. The first <a href=https://en.wikipedia.org/wiki/Monotonic_function>one</a> considers two warrant candidates simultaneously, while the second <a href=https://en.wikipedia.org/wiki/Monotonic_function>one</a> processes each candidate separately and then chooses the best one. We also incorporate sentiment polarity by assuming that there are kinds of sentiment associations between the reason, the warrant and the claim. The experiments show that the first <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> is more effective and sentiment polarity is useful.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>