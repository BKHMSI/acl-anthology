<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/P19-1.pdf>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></h2><p class=lead><a href=/people/a/anna-korhonen/>Anna Korhonen</a>,
<a href=/people/d/david-traum/>David Traum</a>,
<a href=/people/l/lluis-marquez/>Lluís Màrquez</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>P19-1</dd><dt>Month:</dt><dd>July</dd><dt>Year:</dt><dd>2019</dd><dt>Address:</dt><dd>Florence, Italy</dd><dt>Venue:</dt><dd><a href=/venues/acl/>ACL</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/P19-1>https://aclanthology.org/P19-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/P19-1.pdf>https://aclanthology.org/P19-1.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/P19-1.pdf title="Open PDF of 'Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+57th+Annual+Meeting+of+the+Association+for+Computational+Linguistics" title="Search for 'Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1000/>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></strong><br><a href=/people/a/anna-korhonen/>Anna Korhonen</a>
|
<a href=/people/d/david-traum/>David Traum</a>
|
<a href=/people/l/lluis-marquez/>Lluís Màrquez</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1001 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1001/>One Time of Interaction May Not Be Enough : Go Deep with an Interaction-over-Interaction Network for Response Selection in Dialogues</a></strong><br><a href=/people/c/chongyang-tao/>Chongyang Tao</a>
|
<a href=/people/w/wei-wu/>Wei Wu</a>
|
<a href=/people/c/can-xu/>Can Xu</a>
|
<a href=/people/w/wenpeng-hu/>Wenpeng Hu</a>
|
<a href=/people/d/dongyan-zhao/>Dongyan Zhao</a>
|
<a href=/people/r/rui-yan/>Rui Yan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1001><div class="card-body p-3 small">Currently, researchers have paid great attention to retrieval-based dialogues in <a href=https://en.wikipedia.org/wiki/Open_domain>open-domain</a>. In particular, people study the problem by investigating context-response matching for multi-turn response selection based on publicly recognized benchmark data sets. State-of-the-art methods require a response to interact with each utterance in a context from the beginning, but the interaction is performed in a shallow way. In this work, we let utterance-response interaction go deep by proposing an interaction-over-interaction network (IoI). The model performs <a href=https://en.wikipedia.org/wiki/Matching_(statistics)>matching</a> by stacking multiple interaction blocks in which <a href=https://en.wikipedia.org/wiki/Errors_and_residuals>residual information</a> from one time of interaction initiates the interaction process again. Thus, matching information within an utterance-response pair is extracted from the <a href=https://en.wikipedia.org/wiki/Interaction>interaction</a> of the pair in an iterative fashion, and the information flows along the chain of the blocks via <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a>. Evaluation results on three benchmark data sets indicate that IoI can significantly outperform state-of-the-art methods in terms of various matching metrics. Through further analysis, we also unveil how the depth of interaction affects the performance of IoI.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1002.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1002 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1002 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/383950369 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1002" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1002/>Incremental Transformer with Deliberation Decoder for Document Grounded Conversations</a></strong><br><a href=/people/z/zekang-li/>Zekang Li</a>
|
<a href=/people/c/cheng-niu/>Cheng Niu</a>
|
<a href=/people/f/fandong-meng/>Fandong Meng</a>
|
<a href=/people/y/yang-feng/>Yang Feng</a>
|
<a href=/people/q/qian-li/>Qian Li</a>
|
<a href=/people/j/jie-zhou/>Jie Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1002><div class="card-body p-3 small">Document Grounded Conversations is a task to generate dialogue responses when chatting about the content of a given document. Obviously, document knowledge plays a critical role in Document Grounded Conversations, while existing dialogue models do not exploit this kind of knowledge effectively enough. In this paper, we propose a novel Transformer-based architecture for multi-turn document grounded conversations. In particular, we devise an Incremental Transformer to encode multi-turn utterances along with knowledge in related documents. Motivated by the human cognitive process, we design a two-pass decoder (Deliberation Decoder) to improve context coherence and knowledge correctness. Our empirical study on a real-world Document Grounded Dataset proves that responses generated by our model significantly outperform competitive baselines on both context coherence and knowledge relevance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1003 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/383951307 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1003/>Improving Multi-turn Dialogue Modelling with Utterance ReWriter<span class=acl-fixed-case>R</span>e<span class=acl-fixed-case>W</span>riter</a></strong><br><a href=/people/h/hui-su/>Hui Su</a>
|
<a href=/people/x/xiaoyu-shen/>Xiaoyu Shen</a>
|
<a href=/people/r/rongzhi-zhang/>Rongzhi Zhang</a>
|
<a href=/people/f/fei-sun/>Fei Sun</a>
|
<a href=/people/p/pengwei-hu/>Pengwei Hu</a>
|
<a href=/people/c/cheng-niu/>Cheng Niu</a>
|
<a href=/people/j/jie-zhou/>Jie Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1003><div class="card-body p-3 small">Recent research has achieved impressive results in single-turn dialogue modelling. In the multi-turn setting, however, current <a href=https://en.wikipedia.org/wiki/Computer_simulation>models</a> are still far from satisfactory. One major challenge is the frequently occurred coreference and information omission in our daily conversation, making it hard for machines to understand the real intention. In this paper, we propose rewriting the human utterance as a <a href=https://en.wikipedia.org/wiki/Pre-process>pre-process</a> to help multi-turn dialgoue modelling. Each utterance is first rewritten to recover all coreferred and omitted information. The next processing steps are then performed based on the rewritten utterance. To properly train the utterance rewriter, we collect a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> with human annotations and introduce a Transformer-based utterance rewriting architecture using the pointer network. We show the proposed <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> achieves remarkably good performance on the utterance rewriting task. The trained utterance rewriter can be easily integrated into <a href=https://en.wikipedia.org/wiki/Chatbot>online chatbots</a> and brings general improvement over different domains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1004.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1004 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/383952222 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1004" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1004/>Do Neural Dialog Systems Use the Conversation History Effectively? An Empirical Study</a></strong><br><a href=/people/c/chinnadhurai-sankar/>Chinnadhurai Sankar</a>
|
<a href=/people/s/sandeep-subramanian/>Sandeep Subramanian</a>
|
<a href=/people/c/christopher-pal/>Chris Pal</a>
|
<a href=/people/s/sarath-chandar/>Sarath Chandar</a>
|
<a href=/people/y/yoshua-bengio/>Yoshua Bengio</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1004><div class="card-body p-3 small">Neural generative models have been become increasingly popular when building <a href=https://en.wikipedia.org/wiki/Intelligent_agent>conversational agents</a>. They offer flexibility, can be easily adapted to <a href=https://en.wikipedia.org/wiki/Domain_of_unknown_function>new domains</a>, and require minimal domain engineering. A common criticism of these <a href=https://en.wikipedia.org/wiki/System>systems</a> is that they seldom understand or use the available dialog history effectively. In this paper, we take an empirical approach to understanding how these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> use the available dialog history by studying the sensitivity of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> to artificially introduced unnatural changes or perturbations to their context at test time. We experiment with 10 different types of perturbations on 4 multi-turn dialog datasets and find that commonly used neural dialog architectures like recurrent and transformer-based seq2seq models are rarely sensitive to most perturbations such as missing or reordering utterances, shuffling words, etc. Also, by open-sourcing our <a href=https://en.wikipedia.org/wiki/Source_code>code</a>, we believe that it will serve as a useful diagnostic tool for evaluating <a href=https://en.wikipedia.org/wiki/Dialog_(software)>dialog systems</a> in the future.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1005.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1005 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1005 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/383953490 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1005/>Boosting Dialog Response Generation</a></strong><br><a href=/people/w/wenchao-du/>Wenchao Du</a>
|
<a href=/people/a/alan-w-black/>Alan W Black</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1005><div class="card-body p-3 small">Neural models have become one of the most important approaches to dialog response generation. However, they still tend to generate the most common and generic responses in the corpus all the time. To address this problem, we designed an iterative training process and <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensemble method</a> based on <a href=https://en.wikipedia.org/wiki/Boosting_(machine_learning)>boosting</a>. We combined our method with different training and decoding paradigms as the base model, including mutual-information-based decoding and reward-augmented maximum likelihood learning. Empirical results show that our approach can significantly improve the diversity and relevance of the responses generated by all base models, backed by objective measurements and human evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1007.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1007 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1007 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/383955994 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1007" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1007/>Semantic Parsing with Dual Learning</a></strong><br><a href=/people/r/ruisheng-cao/>Ruisheng Cao</a>
|
<a href=/people/s/su-zhu/>Su Zhu</a>
|
<a href=/people/c/chen-liu/>Chen Liu</a>
|
<a href=/people/j/jieyu-li/>Jieyu Li</a>
|
<a href=/people/k/kai-yu/>Kai Yu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1007><div class="card-body p-3 small">Semantic parsing converts <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language queries</a> into structured logical forms. The lack of training data is still one of the most serious problems in this area. In this work, we develop a semantic parsing framework with the dual learning algorithm, which enables a <a href=https://en.wikipedia.org/wiki/Semantic_parser>semantic parser</a> to make full use of data (labeled and even unlabeled) through a dual-learning game. This game between a primal model (semantic parsing) and a dual model (logical form to query) forces them to regularize each other, and can achieve feedback signals from some prior-knowledge. By utilizing the prior-knowledge of logical form structures, we propose a novel reward signal at the surface and semantic levels which tends to generate complete and reasonable logical forms. Experimental results show that our approach achieves new state-of-the-art performance on ATIS dataset and gets competitive performance on OVERNIGHT dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1009.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1009 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1009 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/383957151 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1009" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1009/>AMR Parsing as Sequence-to-Graph Transduction<span class=acl-fixed-case>AMR</span> Parsing as Sequence-to-Graph Transduction</a></strong><br><a href=/people/s/sheng-zhang/>Sheng Zhang</a>
|
<a href=/people/x/xutai-ma/>Xutai Ma</a>
|
<a href=/people/k/kevin-duh/>Kevin Duh</a>
|
<a href=/people/b/benjamin-van-durme/>Benjamin Van Durme</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1009><div class="card-body p-3 small">We propose an attention-based model that treats AMR parsing as sequence-to-graph transduction. Unlike most AMR parsers that rely on pre-trained aligners, external semantic resources, or data augmentation, our proposed <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> is aligner-free, and it can be effectively trained with limited amounts of labeled AMR data. Our experimental results outperform all previously reported SMATCH scores, on both AMR 2.0 (76.3 % on LDC2017T10) and AMR 1.0 (70.2 % on LDC2014T12).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1010.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1010 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1010 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/383957851 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1010/>Generating Logical Forms from Graph Representations of Text and Entities</a></strong><br><a href=/people/p/peter-shaw/>Peter Shaw</a>
|
<a href=/people/p/philip-massey/>Philip Massey</a>
|
<a href=/people/a/angelica-chen/>Angelica Chen</a>
|
<a href=/people/f/francesco-piccinno/>Francesco Piccinno</a>
|
<a href=/people/y/yasemin-altun/>Yasemin Altun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1010><div class="card-body p-3 small">Structured information about entities is critical for many semantic parsing tasks. We present an approach that uses a Graph Neural Network (GNN) architecture to incorporate information about relevant entities and their relations during <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a>. Combined with a decoder copy mechanism, this approach provides a conceptually simple mechanism to generate <a href=https://en.wikipedia.org/wiki/Logical_form>logical forms</a> with <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entities</a>. We demonstrate that this approach is competitive with the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> across several tasks without pre-training, and outperforms existing approaches when combined with BERT pre-training.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1011.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1011 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1011 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/383958512 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1011/>Learning Compressed Sentence Representations for On-Device Text Processing</a></strong><br><a href=/people/d/dinghan-shen/>Dinghan Shen</a>
|
<a href=/people/p/pengyu-cheng/>Pengyu Cheng</a>
|
<a href=/people/d/dhanasekar-sundararaman/>Dhanasekar Sundararaman</a>
|
<a href=/people/x/xinyuan-zhang/>Xinyuan Zhang</a>
|
<a href=/people/q/qian-yang/>Qian Yang</a>
|
<a href=/people/m/meng-tang/>Meng Tang</a>
|
<a href=/people/a/asli-celikyilmaz/>Asli Celikyilmaz</a>
|
<a href=/people/l/lawrence-carin/>Lawrence Carin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1011><div class="card-body p-3 small">Vector representations of sentences, trained on massive text corpora, are widely used as generic sentence embeddings across a variety of NLP problems. The learned representations are generally assumed to be continuous and real-valued, giving rise to a large <a href=https://en.wikipedia.org/wiki/Memory_footprint>memory footprint</a> and slow retrieval speed, which hinders their applicability to low-resource (memory and computation) platforms, such as <a href=https://en.wikipedia.org/wiki/Mobile_device>mobile devices</a>. In this paper, we propose four different strategies to transform continuous and generic sentence embeddings into a binarized form, while preserving their rich semantic information. The introduced methods are evaluated across a wide range of downstream tasks, where the binarized sentence embeddings are demonstrated to degrade performance by only about 2 % relative to their continuous counterparts, while reducing the storage requirement by over 98 %. Moreover, with the learned binary representations, the semantic relatedness of two sentences can be evaluated by simply calculating their <a href=https://en.wikipedia.org/wiki/Hamming_distance>Hamming distance</a>, which is more computational efficient compared with the <a href=https://en.wikipedia.org/wiki/Inner_product_space>inner product operation</a> between continuous embeddings. Detailed analysis and case study further validate the effectiveness of proposed methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1012 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/383962400 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1012/>The (Non-)Utility of Structural Features in BiLSTM-based Dependency Parsers<span class=acl-fixed-case>B</span>i<span class=acl-fixed-case>LSTM</span>-based Dependency Parsers</a></strong><br><a href=/people/a/agnieszka-falenska/>Agnieszka Falenska</a>
|
<a href=/people/j/jonas-kuhn/>Jonas Kuhn</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1012><div class="card-body p-3 small">Classical non-neural dependency parsers put considerable effort on the design of feature functions. Especially, they benefit from information coming from structural features, such as features drawn from neighboring tokens in the dependency tree. In contrast, their BiLSTM-based successors achieve state-of-the-art performance without explicit information about the structural context. In this paper we aim to answer the question : How much structural context are the BiLSTM representations able to capture implicitly? We show that <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> drawn from partial subtrees become redundant when the BiLSTMs are used. We provide a deep insight into <a href=https://en.wikipedia.org/wiki/Information_flow>information flow</a> in transition- and graph-based neural architectures to demonstrate where the implicit information comes from when the <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a> make their decisions. Finally, with model ablations we demonstrate that the structural context is not only present in the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>, but it significantly influences their performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1019.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1019 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1019 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/383966926 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1019" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1019/>An Effective Approach to Unsupervised Machine Translation</a></strong><br><a href=/people/m/mikel-artetxe/>Mikel Artetxe</a>
|
<a href=/people/g/gorka-labaka/>Gorka Labaka</a>
|
<a href=/people/e/eneko-agirre/>Eneko Agirre</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1019><div class="card-body p-3 small">While <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> has traditionally relied on large amounts of parallel corpora, a recent research line has managed to train both Neural Machine Translation (NMT) and Statistical Machine Translation (SMT) systems using monolingual corpora only. In this paper, we identify and address several deficiencies of existing unsupervised SMT approaches by exploiting subword information, developing a theoretically well founded unsupervised tuning method, and incorporating a joint refinement procedure. Moreover, we use our improved SMT system to initialize a dual NMT model, which is further fine-tuned through on-the-fly back-translation. Together, we obtain large improvements over the previous <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> in unsupervised machine translation. For instance, we get 22.5 BLEU points in English-to-German WMT 2014, 5.5 points more than the previous best unsupervised system, and 0.5 points more than the (supervised) shared task winner back in 2014.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1020.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1020 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1020 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1020.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/383968561 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1020/>Effective Adversarial Regularization for Neural Machine Translation</a></strong><br><a href=/people/m/motoki-sato/>Motoki Sato</a>
|
<a href=/people/j/jun-suzuki/>Jun Suzuki</a>
|
<a href=/people/s/shun-kiyono/>Shun Kiyono</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1020><div class="card-body p-3 small">A <a href=https://en.wikipedia.org/wiki/Regularization_(mathematics)>regularization technique</a> based on adversarial perturbation, which was initially developed in the field of <a href=https://en.wikipedia.org/wiki/Digital_image_processing>image processing</a>, has been successfully applied to text classification tasks and has yielded attractive improvements. We aim to further leverage this promising <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> into more sophisticated and critical neural models in the natural language processing field, i.e., <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation (NMT) models</a>. However, it is not trivial to apply this <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> to such <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. Thus, this paper investigates the effectiveness of several possible configurations of applying the adversarial perturbation and reveals that the adversarial regularization technique can significantly and consistently improve the performance of widely used NMT models, such as LSTM-based and Transformer-based models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1024 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/383992004 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1024" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1024/>Attention Guided Graph Convolutional Networks for Relation Extraction</a></strong><br><a href=/people/z/zhijiang-guo/>Zhijiang Guo</a>
|
<a href=/people/y/yan-zhang/>Yan Zhang</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1024><div class="card-body p-3 small">Dependency trees convey rich structural information that is proven useful for extracting relations among entities in text. However, how to effectively make use of relevant information while ignoring irrelevant information from the dependency trees remains a challenging research question. Existing approaches employing rule based hard-pruning strategies for selecting relevant partial dependency structures may not always yield optimal results. In this work, we propose Attention Guided Graph Convolutional Networks (AGGCNs), a novel model which directly takes full dependency trees as inputs. Our model can be understood as a soft-pruning approach that automatically learns how to selectively attend to the relevant sub-structures useful for the relation extraction task. Extensive results on various tasks including cross-sentence n-ary relation extraction and large-scale sentence-level relation extraction show that our model is able to better leverage the structural information of the full dependency trees, giving significantly better results than previous approaches.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1026.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1026 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1026 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/383993749 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1026/>Relation Embedding with <a href=https://en.wikipedia.org/wiki/Dihedral_group>Dihedral Group</a> in Knowledge Graph</a></strong><br><a href=/people/c/canran-xu/>Canran Xu</a>
|
<a href=/people/r/ruijiang-li/>Ruijiang Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1026><div class="card-body p-3 small">Link prediction is critical for the application of incomplete knowledge graph (KG) in the downstream tasks. As a family of effective approaches for link predictions, embedding methods try to learn low-rank representations for both entities and relations such that the <a href=https://en.wikipedia.org/wiki/Bilinear_form>bilinear form</a> defined therein is a well-behaved scoring function. Despite of their successful performances, existing <a href=https://en.wikipedia.org/wiki/Bilinear_form>bilinear forms</a> overlook the modeling of relation compositions, resulting in lacks of interpretability for reasoning on <a href=https://en.wikipedia.org/wiki/Key_(music)>KG</a>. To fulfill this gap, we propose a new <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> called DihEdral, named after <a href=https://en.wikipedia.org/wiki/Dihedral_group>dihedral symmetry group</a>. This new <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> learns knowledge graph embeddings that can capture <a href=https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms>relation compositions</a> by nature. Furthermore, our approach models the relation embeddings parametrized by discrete values, thereby decrease the <a href=https://en.wikipedia.org/wiki/Solution_space>solution space</a> drastically. Our experiments show that DihEdral is able to capture all desired properties such as (skew-) symmetry, inversion and (non-) Abelian composition, and outperforms existing bilinear form based approach and is comparable to or better than deep learning models such as ConvE.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1028.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1028 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1028 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/383997156 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1028" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1028/>Augmenting Neural Networks with <a href=https://en.wikipedia.org/wiki/First-order_logic>First-order Logic</a></a></strong><br><a href=/people/t/tao-li/>Tao Li</a>
|
<a href=/people/v/vivek-srikumar/>Vivek Srikumar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1028><div class="card-body p-3 small">Today, the dominant paradigm for training <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> involves minimizing task loss on a large dataset. Using <a href=https://en.wikipedia.org/wiki/World_knowledge>world knowledge</a> to inform a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>, and yet retain the ability to perform end-to-end training remains an open question. In this paper, we present a novel framework for introducing declarative knowledge to neural network architectures in order to guide <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training</a> and <a href=https://en.wikipedia.org/wiki/Prediction>prediction</a>. Our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> systematically compiles logical statements into computation graphs that augment a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> without extra learnable parameters or manual redesign. We evaluate our modeling strategy on three tasks : machine comprehension, natural language inference, and text chunking. Our experiments show that knowledge-augmented networks can strongly improve over <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a>, especially in low-data regimes.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1029.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1029 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1029 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/383997816 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1029" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1029/>Self-Regulated Interactive Sequence-to-Sequence Learning</a></strong><br><a href=/people/j/julia-kreutzer/>Julia Kreutzer</a>
|
<a href=/people/s/stefan-riezler/>Stefan Riezler</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1029><div class="card-body p-3 small">Not all types of supervision signals are created equal : Different types of <a href=https://en.wikipedia.org/wiki/Feedback>feedback</a> have different costs and effects on <a href=https://en.wikipedia.org/wiki/Learning>learning</a>. We show how self-regulation strategies that decide when to ask for which kind of <a href=https://en.wikipedia.org/wiki/Feedback>feedback</a> from a teacher (or from oneself) can be cast as a learning-to-learn problem leading to improved cost-aware sequence-to-sequence learning. In experiments on interactive neural machine translation, we find that the self-regulator discovers an -greedy strategy for the optimal cost-quality trade-off by mixing different feedback types including corrections, error markups, and self-supervision. Furthermore, we demonstrate its <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> under domain shift and identify it as a promising alternative to <a href=https://en.wikipedia.org/wiki/Active_learning>active learning</a>.<tex-math>\\epsilon</tex-math>-greedy strategy for the optimal cost-quality trade-off by mixing different feedback types including corrections, error markups, and self-supervision. Furthermore, we demonstrate its robustness under domain shift and identify it as a promising alternative to active learning.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1030.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1030 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1030 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384000960 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1030/>You Only Need Attention to Traverse Trees</a></strong><br><a href=/people/m/mahtab-ahmed/>Mahtab Ahmed</a>
|
<a href=/people/m/muhammad-rifayat-samee/>Muhammad Rifayat Samee</a>
|
<a href=/people/r/robert-e-mercer/>Robert E. Mercer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1030><div class="card-body p-3 small">In recent NLP research, a topic of interest is universal sentence encoding, sentence representations that can be used in any <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised task</a>. At the word sequence level, fully attention-based models suffer from two problems : a quadratic increase in memory consumption with respect to the <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence length</a> and an inability to capture and use <a href=https://en.wikipedia.org/wiki/Syntax>syntactic information</a>. Recursive neural nets can extract very good <a href=https://en.wikipedia.org/wiki/Syntax>syntactic information</a> by traversing a <a href=https://en.wikipedia.org/wiki/Tree_(graph_theory)>tree structure</a>. To this end, we propose Tree Transformer, a model that captures phrase level syntax for constituency trees as well as word-level dependencies for dependency trees by doing recursive traversal only with <a href=https://en.wikipedia.org/wiki/Attention>attention</a>. Evaluation of this model on four tasks gets noteworthy results compared to the standard transformer and LSTM-based models as well as tree-structured LSTMs. Ablation studies to find whether positional information is inherently encoded in the <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>trees</a> and which type of <a href=https://en.wikipedia.org/wiki/Attention>attention</a> is suitable for doing the recursive traversal are provided.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1031.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1031 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1031 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385244938 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1031" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1031/>Cross-Domain Generalization of Neural Constituency Parsers</a></strong><br><a href=/people/d/daniel-fried/>Daniel Fried</a>
|
<a href=/people/n/nikita-kitaev/>Nikita Kitaev</a>
|
<a href=/people/d/dan-klein/>Dan Klein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1031><div class="card-body p-3 small">Neural parsers obtain state-of-the-art results on benchmark treebanks for constituency parsingbut to what degree do they generalize to other domains? We present three results about the generalization of neural parsers in a zero-shot setting : training on trees from one corpus and evaluating on out-of-domain corpora. First, neural and non-neural parsers generalize comparably to new domains. Second, incorporating pre-trained encoder representations into neural parsers substantially improves their performance across all domains, but does not give a larger relative improvement for out-of-domain treebanks. Finally, despite the rich input representations they learn, neural parsers still benefit from structured output prediction of output trees, yielding higher exact match accuracy and stronger generalization both to larger text spans and to out-of-domain corpora. We analyze generalization on English and Chinese corpora, and in the process obtain state-of-the-art parsing results for the Brown, Genia, and English Web treebanks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1032.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1032 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1032 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384007585 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1032" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1032/>Adaptive Attention Span in Transformers</a></strong><br><a href=/people/s/sainbayar-sukhbaatar/>Sainbayar Sukhbaatar</a>
|
<a href=/people/e/edouard-grave/>Edouard Grave</a>
|
<a href=/people/p/piotr-bojanowski/>Piotr Bojanowski</a>
|
<a href=/people/a/armand-joulin/>Armand Joulin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1032><div class="card-body p-3 small">We propose a novel self-attention mechanism that can learn its optimal attention span. This allows us to extend significantly the maximum context size used in Transformer, while maintaining control over their <a href=https://en.wikipedia.org/wiki/Memory_footprint>memory footprint</a> and <a href=https://en.wikipedia.org/wiki/Time_complexity>computational time</a>. We show the effectiveness of our approach on the task of character level language modeling, where we achieve state-of-the-art performances on text8 and enwiki8 by using a maximum context of 8k characters.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1033.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1033 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1033 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1033/>Neural News Recommendation with Long- and Short-term User Representations</a></strong><br><a href=/people/m/mingxiao-an/>Mingxiao An</a>
|
<a href=/people/f/fangzhao-wu/>Fangzhao Wu</a>
|
<a href=/people/c/chuhan-wu/>Chuhan Wu</a>
|
<a href=/people/k/kun-zhang/>Kun Zhang</a>
|
<a href=/people/z/zheng-liu/>Zheng Liu</a>
|
<a href=/people/x/xing-xie/>Xing Xie</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1033><div class="card-body p-3 small">Personalized news recommendation is important to help users find their interested news and improve reading experience. A key problem in news recommendation is learning accurate user representations to capture their interests. Users usually have both long-term preferences and short-term interests. However, existing news recommendation methods usually learn single representations of users, which may be insufficient. In this paper, we propose a neural news recommendation approach which can learn both long- and short-term user representations. The core of our approach is a news encoder and a <a href=https://en.wikipedia.org/wiki/User-generated_content>user encoder</a>. In the news encoder, we learn representations of news from their titles and topic categories, and use attention network to select important words. In the user encoder, we propose to learn long-term user representations from the embeddings of their IDs. In addition, we propose to learn short-term user representations from their recently browsed news via GRU network. Besides, we propose two <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> to combine long-term and short-term user representations. The first one is using the long-term user representation to initialize the hidden state of the GRU network in short-term user representation. The second one is concatenating both long- and short-term user representations as a unified user vector. Extensive experiments on a real-world dataset show our approach can effectively improve the performance of neural news recommendation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1035.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1035 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1035 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1035.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1035.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1035" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1035/>Manipulating the Difficulty of C-Tests<span class=acl-fixed-case>C</span>-Tests</a></strong><br><a href=/people/j/ji-ung-lee/>Ji-Ung Lee</a>
|
<a href=/people/e/erik-schwan/>Erik Schwan</a>
|
<a href=/people/c/christian-m-meyer/>Christian M. Meyer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1035><div class="card-body p-3 small">We propose two novel manipulation strategies for increasing and decreasing the difficulty of C-tests automatically. This is a crucial step towards generating learner-adaptive exercises for self-directed language learning and preparing <a href=https://en.wikipedia.org/wiki/Language_assessment>language assessment tests</a>. To reach the desired difficulty level, we manipulate the size and the distribution of gaps based on absolute and relative gap difficulty predictions. We evaluate our approach in corpus-based experiments and in a <a href=https://en.wikipedia.org/wiki/User_study>user study</a> with 60 participants. We find that both <a href=https://en.wikipedia.org/wiki/Strategy>strategies</a> are able to generate C-tests with the desired <a href=https://en.wikipedia.org/wiki/Degree_of_difficulty>difficulty level</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1041.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1041 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1041 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1041" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1041/>Disentangled Representation Learning for Non-Parallel Text Style Transfer</a></strong><br><a href=/people/v/vineet-john/>Vineet John</a>
|
<a href=/people/l/lili-mou/>Lili Mou</a>
|
<a href=/people/h/hareesh-bahuleyan/>Hareesh Bahuleyan</a>
|
<a href=/people/o/olga-vechtomova/>Olga Vechtomova</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1041><div class="card-body p-3 small">This paper tackles the problem of disentangling the latent representations of style and content in <a href=https://en.wikipedia.org/wiki/Language_model>language models</a>. We propose a simple yet effective approach, which incorporates auxiliary multi-task and adversarial objectives, for style prediction and bag-of-words prediction, respectively. We show, both qualitatively and quantitatively, that the style and content are indeed disentangled in the latent space. This disentangled latent representation learning can be applied to style transfer on non-parallel corpora. We achieve high performance in terms of transfer accuracy, <a href=https://en.wikipedia.org/wiki/Preservation_(library_and_archival_science)>content preservation</a>, and <a href=https://en.wikipedia.org/wiki/Fluency>language fluency</a>, in comparison to various previous approaches.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1043.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1043 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1043 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1043.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1043" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1043/>This Email Could Save Your Life : Introducing the Task of Email Subject Line Generation</a></strong><br><a href=/people/r/rui-zhang/>Rui Zhang</a>
|
<a href=/people/j/joel-tetreault/>Joel Tetreault</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1043><div class="card-body p-3 small">Given the overwhelming number of emails, an effective subject line becomes essential to better inform the recipient of the email&#8217;s content. In this paper, we propose and study the task of email subject line generation : automatically generating an email subject line from the <a href=https://en.wikipedia.org/wiki/Email>email body</a>. We create the first dataset for this task and find that email subject line generation favor extremely abstractive summary which differentiates it from news headline generation or news single document summarization. We then develop a novel deep learning method and compare it to several baselines as well as recent state-of-the-art text summarization systems. We also investigate the efficacy of several automatic metrics based on correlations with human judgments and propose a new automatic evaluation metric. Our <a href=https://en.wikipedia.org/wiki/System>system</a> outperforms competitive <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> given both automatic and human evaluations. To our knowledge, this is the first work to tackle the problem of effective email subject line generation.<i>email subject line generation</i>: automatically generating an email subject line from the email body. We create the first dataset for this task and find that email subject line generation favor extremely abstractive summary which differentiates it from news headline generation or news single document summarization. We then develop a novel deep learning method and compare it to several baselines as well as recent state-of-the-art text summarization systems. We also investigate the efficacy of several automatic metrics based on correlations with human judgments and propose a new automatic evaluation metric. Our system outperforms competitive baselines given both automatic and human evaluations. To our knowledge, this is the first work to tackle the problem of effective email subject line generation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1044.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1044 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1044 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1044" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1044/>Time-Out : Temporal Referencing for Robust Modeling of Lexical Semantic Change</a></strong><br><a href=/people/h/haim-dubossarsky/>Haim Dubossarsky</a>
|
<a href=/people/s/simon-hengchen/>Simon Hengchen</a>
|
<a href=/people/n/nina-tahmasebi/>Nina Tahmasebi</a>
|
<a href=/people/d/dominik-schlechtweg/>Dominik Schlechtweg</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1044><div class="card-body p-3 small">State-of-the-art models of lexical semantic change detection suffer from <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noise</a> stemming from vector space alignment. We have empirically tested the Temporal Referencing method for lexical semantic change and show that, by avoiding alignment, it is less affected by this <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noise</a>. We show that, trained on a diachronic corpus, the skip-gram with negative sampling architecture with temporal referencing outperforms alignment models on a synthetic task as well as a manual testset. We introduce a principled way to simulate lexical semantic change and systematically control for possible biases.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1046.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1046 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1046 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1046/>Divide, Conquer and Combine : Hierarchical Feature Fusion Network with Local and Global Perspectives for Multimodal Affective Computing</a></strong><br><a href=/people/s/sijie-mai/>Sijie Mai</a>
|
<a href=/people/h/haifeng-hu/>Haifeng Hu</a>
|
<a href=/people/s/songlong-xing/>Songlong Xing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1046><div class="card-body p-3 small">We propose a general <a href=https://en.wikipedia.org/wiki/Strategy>strategy</a> named &#8216;divide, conquer and combine&#8217; for multimodal fusion. Instead of directly fusing features at holistic level, we conduct fusion hierarchically so that both local and global interactions are considered for a comprehensive interpretation of multimodal embeddings. In the &#8216;divide&#8217; and &#8216;conquer&#8217; stages, we conduct local fusion by exploring the interaction of a portion of the aligned feature vectors across various modalities lying within a sliding window, which ensures that each part of multimodal embeddings are explored sufficiently. On its basis, global fusion is conducted in the &#8216;combine&#8217; stage to explore the interconnection across local interactions, via an Attentive Bi-directional Skip-connected LSTM that directly connects distant local interactions and integrates two levels of attention mechanism. In this way, local interactions can exchange information sufficiently and thus obtain an overall view of multimodal information. Our <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> achieves state-of-the-art performance on multimodal affective computing with higher efficiency.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1050.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1050 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1050 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1050" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1050/>MELD : A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations<span class=acl-fixed-case>MELD</span>: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations</a></strong><br><a href=/people/s/soujanya-poria/>Soujanya Poria</a>
|
<a href=/people/d/devamanyu-hazarika/>Devamanyu Hazarika</a>
|
<a href=/people/n/navonil-majumder/>Navonil Majumder</a>
|
<a href=/people/g/gautam-naik/>Gautam Naik</a>
|
<a href=/people/e/erik-cambria/>Erik Cambria</a>
|
<a href=/people/r/rada-mihalcea/>Rada Mihalcea</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1050><div class="card-body p-3 small">Emotion recognition in conversations is a challenging <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> that has recently gained popularity due to its potential applications. Until now, however, a large-scale multimodal multi-party emotional conversational database containing more than two speakers per dialogue was missing. Thus, we propose the Multimodal EmotionLines Dataset (MELD), an extension and enhancement of EmotionLines. MELD contains about 13,000 utterances from 1,433 dialogues from the TV-series Friends. Each utterance is annotated with emotion and sentiment labels, and encompasses audio, visual and textual modalities. We propose several strong multimodal baselines and show the importance of contextual and multimodal information for emotion recognition in conversations. The full dataset is available for use at http://affective-meld.github.io.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1051.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1051 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1051 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1051" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1051/>Open-Domain Targeted Sentiment Analysis via Span-Based Extraction and Classification</a></strong><br><a href=/people/m/minghao-hu/>Minghao Hu</a>
|
<a href=/people/y/yuxing-peng/>Yuxing Peng</a>
|
<a href=/people/z/zhen-huang/>Zhen Huang</a>
|
<a href=/people/d/dongsheng-li/>Dongsheng Li</a>
|
<a href=/people/y/yiwei-lv/>Yiwei Lv</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1051><div class="card-body p-3 small">Open-domain targeted sentiment analysis aims to detect <a href=https://en.wikipedia.org/wiki/Opinion_poll>opinion targets</a> along with their <a href=https://en.wikipedia.org/wiki/Sentimentality>sentiment polarities</a> from a sentence. Prior work typically formulates this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> as a sequence tagging problem. However, such <a href=https://en.wikipedia.org/wiki/Formulation>formulation</a> suffers from problems such as <a href=https://en.wikipedia.org/wiki/Big_data>huge search space</a> and <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment inconsistency</a>. To address these problems, we propose a span-based extract-then-classify framework, where multiple opinion targets are directly extracted from the sentence under the supervision of target span boundaries, and corresponding polarities are then classified using their span representations. We further investigate three approaches under this framework, namely the pipeline, joint, and collapsed models. Experiments on three benchmark datasets show that our approach consistently outperforms the sequence tagging baseline. Moreover, we find that the <a href=https://en.wikipedia.org/wiki/Pipeline_(software)>pipeline model</a> achieves the best performance compared with the other two <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1053.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1053 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1053 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1053" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1053/>Progressive Self-Supervised Attention Learning for Aspect-Level Sentiment Analysis</a></strong><br><a href=/people/j/jialong-tang/>Jialong Tang</a>
|
<a href=/people/z/ziyao-lu/>Ziyao Lu</a>
|
<a href=/people/j/jinsong-su/>Jinsong Su</a>
|
<a href=/people/y/yubin-ge/>Yubin Ge</a>
|
<a href=/people/l/linfeng-song/>Linfeng Song</a>
|
<a href=/people/l/le-sun/>Le Sun</a>
|
<a href=/people/j/jiebo-luo/>Jiebo Luo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1053><div class="card-body p-3 small">In aspect-level sentiment classification (ASC), it is prevalent to equip dominant neural models with attention mechanisms, for the sake of acquiring the importance of each context word on the given aspect. However, such a <a href=https://en.wikipedia.org/wiki/Mechanism_(sociology)>mechanism</a> tends to excessively focus on a few frequent words with sentiment polarities, while ignoring infrequent ones. In this paper, we propose a progressive self-supervised attention learning approach for neural ASC models, which automatically mines useful attention supervision information from a training corpus to refine attention mechanisms. Specifically, we iteratively conduct <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment predictions</a> on all training instances. Particularly, at each iteration, the context word with the maximum attention weight is extracted as the one with active / misleading influence on the correct / incorrect prediction of every instance, and then the word itself is masked for subsequent iterations. Finally, we augment the conventional training objective with a regularization term, which enables ASC models to continue equally focusing on the extracted active context words while decreasing weights of those misleading ones. Experimental results on multiple datasets show that our proposed approach yields better attention mechanisms, leading to substantial improvements over the two state-of-the-art neural ASC models. Source code and trained models are available at https://github.com/DeepLearnXMU/PSSAttention.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1055.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1055 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1055 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1055.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1055" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1055/>Sentiment Tagging with Partial Labels using Modular Architectures</a></strong><br><a href=/people/x/xiao-zhang/>Xiao Zhang</a>
|
<a href=/people/d/dan-goldwasser/>Dan Goldwasser</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1055><div class="card-body p-3 small">Many NLP learning tasks can be decomposed into several distinct sub-tasks, each associated with a partial label. In this paper we focus on a popular class of learning problems, sequence prediction applied to several sentiment analysis tasks, and suggest a modular learning approach in which different sub-tasks are learned using separate functional modules, combined to perform the final task while sharing information. Our experiments show this approach helps constrain the <a href=https://en.wikipedia.org/wiki/Learning>learning process</a> and can alleviate some of the supervision efforts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1057.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1057 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1057 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1057/>A Corpus for Modeling User and Language Effects in <a href=https://en.wikipedia.org/wiki/Argumentation_theory>Argumentation</a> on Online Debating</a></strong><br><a href=/people/e/esin-durmus/>Esin Durmus</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1057><div class="card-body p-3 small">Existing argumentation datasets have succeeded in allowing researchers to develop <a href=https://en.wikipedia.org/wiki/Computational_linguistics>computational methods</a> for analyzing the content, structure and linguistic features of argumentative text. They have been much less successful in fostering studies of the effect of user traits characteristics and beliefs of the participants on the debate / argument outcome as this type of user information is generally not available. This paper presents a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of 78,376 <a href=https://en.wikipedia.org/wiki/Debate>debates</a> generated over a 10-year period along with surprisingly comprehensive participant profiles. We also complete an example study using the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> to analyze the effect of selected user traits on the debate outcome in comparison to the <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>linguistic features</a> typically employed in studies of this kind.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1061.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1061 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1061 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1061/>Data Programming for Learning Discourse Structure</a></strong><br><a href=/people/s/sonia-badene/>Sonia Badene</a>
|
<a href=/people/k/kate-thompson/>Kate Thompson</a>
|
<a href=/people/j/jean-pierre-lorre/>Jean-Pierre Lorré</a>
|
<a href=/people/n/nicholas-asher/>Nicholas Asher</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1061><div class="card-body p-3 small">This paper investigates the advantages and limits of data programming for the task of learning discourse structure. The data programming paradigm implemented in the Snorkel framework allows a user to label training data using expert-composed heuristics, which are then transformed via the generative step into probability distributions of the class labels given the training candidates. These results are later generalized using a <a href=https://en.wikipedia.org/wiki/Discriminative_model>discriminative model</a>. Snorkel&#8217;s attractive promise to create a large amount of annotated data from a smaller set of training data by unifying the output of a set of <a href=https://en.wikipedia.org/wiki/Heuristic>heuristics</a> has yet to be used for computationally difficult tasks, such as that of discourse attachment, in which one must decide where a given discourse unit attaches to other units in a text in order to form a coherent discourse structure. Although approaching this problem using <a href=https://en.wikipedia.org/wiki/Snorkeling>Snorkel</a> requires significant modifications to the structure of the <a href=https://en.wikipedia.org/wiki/Heuristic>heuristics</a>, we show that weak supervision methods can be more than competitive with classical supervised learning approaches to the attachment problem.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1062.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1062 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1062 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1062.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1062" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1062/>Evaluating Discourse in Structured Text Representations</a></strong><br><a href=/people/e/elisa-ferracane/>Elisa Ferracane</a>
|
<a href=/people/g/greg-durrett/>Greg Durrett</a>
|
<a href=/people/j/junyi-jessy-li/>Junyi Jessy Li</a>
|
<a href=/people/k/katrin-erk/>Katrin Erk</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1062><div class="card-body p-3 small">Discourse structure is integral to understanding a text and is helpful in many NLP tasks. Learning latent representations of discourse is an attractive alternative to acquiring expensive labeled discourse data. Liu and Lapata (2018) propose a structured attention mechanism for text classification that derives a <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>tree</a> over a text, akin to an RST discourse tree. We examine this model in detail, and evaluate on additional discourse-relevant tasks and datasets, in order to assess whether the structured attention improves performance on the end task and whether it captures a text&#8217;s discourse structure. We find the learned latent trees have little to no structure and instead focus on lexical cues ; even after obtaining more structured trees with proposed model modifications, the <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>trees</a> are still far from capturing discourse structure when compared to discourse dependency trees from an existing discourse parser. Finally, ablation studies show the structured attention provides little benefit, sometimes even hurting performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1068.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1068 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1068 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1068" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1068/>MOROCO : The Moldavian and Romanian Dialectal Corpus<span class=acl-fixed-case>MOROCO</span>: The <span class=acl-fixed-case>M</span>oldavian and <span class=acl-fixed-case>R</span>omanian Dialectal Corpus</a></strong><br><a href=/people/a/andrei-butnaru/>Andrei Butnaru</a>
|
<a href=/people/r/radu-tudor-ionescu/>Radu Tudor Ionescu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1068><div class="card-body p-3 small">In this work, we introduce the MOldavian and ROmanian Dialectal COrpus (MOROCO), which is freely available for download at https://github.com/butnaruandrei/MOROCO. The <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> contains 33564 samples of text (with over 10 million tokens) collected from the <a href=https://en.wikipedia.org/wiki/News_media>news domain</a>. The samples belong to one of the following six topics : <a href=https://en.wikipedia.org/wiki/Culture>culture</a>, <a href=https://en.wikipedia.org/wiki/Finance>finance</a>, <a href=https://en.wikipedia.org/wiki/Politics>politics</a>, <a href=https://en.wikipedia.org/wiki/Science>science</a>, sports and tech. The <a href=https://en.wikipedia.org/wiki/Data_set>data set</a> is divided into 21719 samples for training, 5921 samples for validation and another 5924 samples for testing. For each sample, we provide corresponding dialectal and category labels. This allows us to perform empirical studies on several classification tasks such as (i) binary discrimination of Moldavian versus Romanian text samples, (ii) intra-dialect multi-class categorization by topic and (iii) cross-dialect multi-class categorization by topic. We perform experiments using a shallow approach based on <a href=https://en.wikipedia.org/wiki/String_kernel>string kernels</a>, as well as a novel deep approach based on character-level convolutional neural networks containing Squeeze-and-Excitation blocks. We also present and analyze the most discriminative features of our best performing <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>, before and after named entity removal.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1069.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1069 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1069 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1069/>Just OneSeC for Producing Multilingual Sense-Annotated Data<span class=acl-fixed-case>O</span>ne<span class=acl-fixed-case>S</span>e<span class=acl-fixed-case>C</span>” for Producing Multilingual Sense-Annotated Data</a></strong><br><a href=/people/b/bianca-scarlini/>Bianca Scarlini</a>
|
<a href=/people/t/tommaso-pasini/>Tommaso Pasini</a>
|
<a href=/people/r/roberto-navigli/>Roberto Navigli</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1069><div class="card-body p-3 small">The well-known problem of <a href=https://en.wikipedia.org/wiki/Knowledge_acquisition>knowledge acquisition</a> is one of the biggest issues in Word Sense Disambiguation (WSD), where annotated data are still scarce in <a href=https://en.wikipedia.org/wiki/English_language>English</a> and almost absent in other languages. In this paper we formulate the assumption of One Sense per Wikipedia Category and present OneSeC, a language-independent method for the automatic extraction of hundreds of thousands of sentences in which a target word is tagged with its meaning. Our automatically-generated data consistently lead a supervised WSD model to state-of-the-art performance when compared with other automatic and semi-automatic methods. Moreover, our approach outperforms its competitors on multilingual and domain-specific settings, where it beats the existing state of the art on all languages and most domains. All the training data are available for research purposes at http://trainomatic.org/onesec.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1070.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1070 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1070 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1070.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1070" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1070/>How to (Properly) Evaluate Cross-Lingual Word Embeddings : On Strong Baselines, Comparative Analyses, and Some Misconceptions</a></strong><br><a href=/people/g/goran-glavas/>Goran Glavaš</a>
|
<a href=/people/r/robert-litschko/>Robert Litschko</a>
|
<a href=/people/s/sebastian-ruder/>Sebastian Ruder</a>
|
<a href=/people/i/ivan-vulic/>Ivan Vulić</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1070><div class="card-body p-3 small">Cross-lingual word embeddings (CLEs) facilitate cross-lingual transfer of NLP models. Despite their ubiquitous downstream usage, increasingly popular projection-based CLE models are almost exclusively evaluated on bilingual lexicon induction (BLI). Even the BLI evaluations vary greatly, hindering our ability to correctly interpret performance and properties of different CLE models. In this work, we take the first step towards a comprehensive evaluation of CLE models : we thoroughly evaluate both supervised and unsupervised CLE models, for a large number of language pairs, on BLI and three downstream tasks, providing new insights concerning the ability of cutting-edge CLE models to support cross-lingual NLP. We empirically demonstrate that the performance of CLE models largely depends on the task at hand and that optimizing CLE models for BLI may hurt downstream performance. We indicate the most robust supervised and unsupervised CLE models and emphasize the need to reassess simple baselines, which still display competitive performance across the board. We hope our work catalyzes further research on CLE evaluation and model analysis.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1076.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1076 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1076 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1076/>Automatic Evaluation of Local Topic Quality</a></strong><br><a href=/people/j/jeffrey-lund/>Jeffrey Lund</a>
|
<a href=/people/p/piper-armstrong/>Piper Armstrong</a>
|
<a href=/people/w/wilson-fearn/>Wilson Fearn</a>
|
<a href=/people/s/stephen-cowley/>Stephen Cowley</a>
|
<a href=/people/c/courtni-byun/>Courtni Byun</a>
|
<a href=/people/j/jordan-boyd-graber/>Jordan Boyd-Graber</a>
|
<a href=/people/k/kevin-seppi/>Kevin Seppi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1076><div class="card-body p-3 small">Topic models are typically evaluated with respect to the global topic distributions that they generate, using <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> such as <a href=https://en.wikipedia.org/wiki/Coherence_(statistics)>coherence</a>, but without regard to local (token-level) topic assignments. Token-level assignments are important for downstream tasks such as <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a>. Even recent <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>, which aim to improve the quality of these token-level topic assignments, have been evaluated only with respect to <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>global metrics</a>. We propose a <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> designed to elicit human judgments of token-level topic assignments. We use a variety of <a href=https://en.wikipedia.org/wiki/Topic_model>topic model</a> types and parameters and discover that global metrics agree poorly with human assignments. Since <a href=https://en.wikipedia.org/wiki/Evaluation>human evaluation</a> is expensive we propose a variety of <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>automated metrics</a> to evaluate <a href=https://en.wikipedia.org/wiki/Topic_model>topic models</a> at a local level. Finally, we correlate our proposed <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> with <a href=https://en.wikipedia.org/wiki/Judgement>human judgments</a> from the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> on several datasets. We show that an <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation</a> based on the percent of topic switches correlates most strongly with human judgment of local topic quality. We suggest that this new <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a>, which we call <a href=https://en.wikipedia.org/wiki/Consistency>consistency</a>, be adopted alongside global metrics such as topic coherence when evaluating new topic models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1078.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1078 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1078 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><span class="align-middle mr-1" data-toggle=tooltip data-placement=bottom title="Outstanding Paper"><i class="fas fa-award"></i></span><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384011409 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1078" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1078/>Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems</a></strong><br><a href=/people/c/chien-sheng-wu/>Chien-Sheng Wu</a>
|
<a href=/people/a/andrea-madotto/>Andrea Madotto</a>
|
<a href=/people/e/ehsan-hosseini-asl/>Ehsan Hosseini-Asl</a>
|
<a href=/people/c/caiming-xiong/>Caiming Xiong</a>
|
<a href=/people/r/richard-socher/>Richard Socher</a>
|
<a href=/people/p/pascale-fung/>Pascale Fung</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1078><div class="card-body p-3 small">Over-dependence on <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>domain ontology</a> and lack of sharing knowledge across domains are two practical and yet less studied problems of dialogue state tracking. Existing approaches generally fall short when tracking unknown slot values during <a href=https://en.wikipedia.org/wiki/Inference>inference</a> and often have difficulties in adapting to new domains. In this paper, we propose a Transferable Dialogue State Generator (TRADE) that generates dialogue states from utterances using copy mechanism, facilitating transfer when predicting (domain, slot, value) triplets not encountered during training. Our model is composed of an utterance encoder, a slot gate, and a state generator, which are shared across domains. Empirical results demonstrate that TRADE achieves state-of-the-art 48.62 % joint goal accuracy for the five domains of MultiWOZ, a human-human dialogue dataset. In addition, we show the transferring ability by simulating zero-shot and few-shot dialogue state tracking for unseen domains. TRADE achieves 60.58 % joint goal accuracy in one of the zero-shot domains, and is able to adapt to few-shot cases without forgetting already trained domains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1079.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1079 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1079 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384538335 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1079/>Multi-Task Networks with Universe, Group, and Task Feature Learning</a></strong><br><a href=/people/s/shiva-pentyala/>Shiva Pentyala</a>
|
<a href=/people/m/mengwen-liu/>Mengwen Liu</a>
|
<a href=/people/m/markus-dreyer/>Markus Dreyer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1079><div class="card-body p-3 small">We present methods for <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a> that take advantage of natural groupings of related tasks. Task groups may be defined along known properties of the <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a>, such as task domain or language. Such task groups represent <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised information</a> at the inter-task level and can be encoded into the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>. We investigate two variants of neural network architectures that accomplish this, learning different feature spaces at the levels of individual tasks, task groups, as well as the universe of all tasks : (1) parallel architectures encode each input simultaneously into feature spaces at different levels ; (2) serial architectures encode each input successively into feature spaces at different levels in the task hierarchy. We demonstrate the methods on natural language understanding (NLU) tasks, where a grouping of tasks into different task domains leads to improved performance on <a href=https://en.wikipedia.org/wiki/Automatic_terminal_information_service>ATIS</a>, Snips, and a large in-house dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1084.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1084 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1084 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1084.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384034160 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1084" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1084/>Do n’t Take the Premise for Granted : Mitigating Artifacts in Natural Language Inference</a></strong><br><a href=/people/y/yonatan-belinkov/>Yonatan Belinkov</a>
|
<a href=/people/a/adam-poliak/>Adam Poliak</a>
|
<a href=/people/s/stuart-m-shieber/>Stuart Shieber</a>
|
<a href=/people/b/benjamin-van-durme/>Benjamin Van Durme</a>
|
<a href=/people/a/alexander-m-rush/>Alexander Rush</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1084><div class="card-body p-3 small">Natural Language Inference (NLI) datasets often contain hypothesis-only biasesartifacts that allow models to achieve non-trivial performance without learning whether a premise entails a hypothesis. We propose two probabilistic methods to build <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that are more robust to such <a href=https://en.wikipedia.org/wiki/Bias>biases</a> and better transfer across datasets. In contrast to standard approaches to NLI, our methods predict the probability of a premise given a hypothesis and NLI label, discouraging models from ignoring the premise. We evaluate our methods on synthetic and existing NLI datasets by training on <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> containing biases and testing on <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> containing no (or different) hypothesis-only biases. Our results indicate that these methods can make NLI models more robust to dataset-specific artifacts, transferring better than a baseline architecture in 9 out of 12 NLI datasets. Additionally, we provide an extensive analysis of the interplay of our methods with known biases in NLI datasets, as well as the effects of encouraging models to ignore <a href=https://en.wikipedia.org/wiki/Bias>biases</a> and fine-tuning on target datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1088.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1088 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1088 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384465038 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1088/>What Makes a Good Counselor? Learning to Distinguish between High-quality and Low-quality Counseling Conversations</a></strong><br><a href=/people/v/veronica-perez-rosas/>Verónica Pérez-Rosas</a>
|
<a href=/people/x/xinyi-wu/>Xinyi Wu</a>
|
<a href=/people/k/kenneth-resnicow/>Kenneth Resnicow</a>
|
<a href=/people/r/rada-mihalcea/>Rada Mihalcea</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1088><div class="card-body p-3 small">The quality of a <a href=https://en.wikipedia.org/wiki/Intervention_(counseling)>counseling intervention</a> relies highly on the active collaboration between clients and counselors. In this paper, we explore several <a href=https://en.wikipedia.org/wiki/Linguistics>linguistic aspects</a> of the <a href=https://en.wikipedia.org/wiki/Collaboration>collaboration process</a> occurring during <a href=https://en.wikipedia.org/wiki/List_of_counseling_topics>counseling conversations</a>. Specifically, we address the differences between high-quality and low-quality counseling. Our approach examines participants&#8217; turn-by-turn interaction, their linguistic alignment, the sentiment expressed by speakers during the conversation, as well as the different topics being discussed. Our results suggest important language differences in low- and high-quality counseling, which we further use to derive linguistic features able to capture the differences between the two groups. These <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> are then used to build <a href=https://en.wikipedia.org/wiki/Statistical_classification>automatic classifiers</a> that can predict <a href=https://en.wikipedia.org/wiki/Counseling_psychology>counseling quality</a> with <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracies</a> of up to 88 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1089.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1089 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1089 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384467269 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1089/>Finding Your Voice : The Linguistic Development of Mental Health Counselors</a></strong><br><a href=/people/j/justine-zhang/>Justine Zhang</a>
|
<a href=/people/r/robert-filbin/>Robert Filbin</a>
|
<a href=/people/c/christine-morrison/>Christine Morrison</a>
|
<a href=/people/j/jaclyn-weiser/>Jaclyn Weiser</a>
|
<a href=/people/c/cristian-danescu-niculescu-mizil/>Cristian Danescu-Niculescu-Mizil</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1089><div class="card-body p-3 small">Mental health counseling is an enterprise with profound societal importance where <a href=https://en.wikipedia.org/wiki/Conversation>conversations</a> play a primary role. In order to acquire the conversational skills needed to face a challenging range of situations, mental health counselors must rely on training and on continued experience with actual clients. However, in the absence of large scale longitudinal studies, the nature and significance of this developmental process remain unclear. For example, prior literature suggests that experience might not translate into consequential changes in counselor behavior. This has led some to even argue that <a href=https://en.wikipedia.org/wiki/List_of_counseling_topics>counseling</a> is a profession without expertise. In this work, we develop a computational framework to quantify the extent to which individuals change their linguistic behavior with experience and to study the nature of this evolution. We use our <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> to conduct a large longitudinal study of mental health counseling conversations, tracking over 3,400 counselors across their tenure. We reveal that overall, counselors do indeed change their conversational behavior to become more diverse across interactions, developing an individual voice that distinguishes them from other counselors. Furthermore, a finer-grained investigation shows that the rate and nature of this diversification vary across functionally different conversational components.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1093.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1093 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1093 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384469154 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1093/>Are You Convinced? Choosing the More Convincing Evidence with a Siamese Network<span class=acl-fixed-case>S</span>iamese Network</a></strong><br><a href=/people/m/martin-gleize/>Martin Gleize</a>
|
<a href=/people/e/eyal-shnarch/>Eyal Shnarch</a>
|
<a href=/people/l/leshem-choshen/>Leshem Choshen</a>
|
<a href=/people/l/lena-dankin/>Lena Dankin</a>
|
<a href=/people/g/guy-moshkowich/>Guy Moshkowich</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1093><div class="card-body p-3 small">With the advancement in argument detection, we suggest to pay more attention to the challenging task of identifying the more convincing arguments. Machines capable of responding and interacting with humans in helpful ways have become ubiquitous. We now expect them to discuss with us the more delicate questions in our world, and they should do so armed with effective arguments. But what makes an argument more persuasive? What will convince you? In this paper, we present a new <a href=https://en.wikipedia.org/wiki/Data_set>data set</a>, IBM-EviConv, of pairs of evidence labeled for convincingness, designed to be more challenging than existing alternatives. We also propose a Siamese neural network architecture shown to outperform several baselines on both a prior convincingness data set and our own. Finally, we provide insights into our experimental results and the various kinds of argumentative value our method is capable of detecting.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1094.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1094 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1094 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384469239 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1094/>From Surrogacy to Adoption ; From <a href=https://en.wikipedia.org/wiki/Bitcoin>Bitcoin</a> to <a href=https://en.wikipedia.org/wiki/Cryptocurrency>Cryptocurrency</a> : Debate Topic Expansion</a></strong><br><a href=/people/r/roy-bar-haim/>Roy Bar-Haim</a>
|
<a href=/people/d/dalia-krieger/>Dalia Krieger</a>
|
<a href=/people/o/orith-toledo-ronen/>Orith Toledo-Ronen</a>
|
<a href=/people/l/lilach-edelstein/>Lilach Edelstein</a>
|
<a href=/people/y/yonatan-bilu/>Yonatan Bilu</a>
|
<a href=/people/a/alon-halfon/>Alon Halfon</a>
|
<a href=/people/y/yoav-katz/>Yoav Katz</a>
|
<a href=/people/a/amir-menczel/>Amir Menczel</a>
|
<a href=/people/r/ranit-aharonov/>Ranit Aharonov</a>
|
<a href=/people/n/noam-slonim/>Noam Slonim</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1094><div class="card-body p-3 small">When debating a controversial topic, it is often desirable to expand the boundaries of discussion. For example, we may consider the pros and cons of possible alternatives to the debate topic, make generalizations, or give specific examples. We introduce the task of Debate Topic Expansion-finding such related topics for a given debate topic, along with a novel annotated dataset for the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. We focus on relations between Wikipedia concepts, and show that they differ from well-studied lexical-semantic relations such as <a href=https://en.wikipedia.org/wiki/Hypernymy>hypernyms</a>, <a href=https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy>hyponyms</a> and <a href=https://en.wikipedia.org/wiki/Opposite_(semantics)>antonyms</a>. We present <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> for finding both consistent and contrastive expansions and demonstrate their effectiveness empirically. We suggest that debate topic expansion may have various use cases in argumentation mining.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1096.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1096 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1096 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><span class="align-middle mr-1" data-toggle=tooltip data-placement=bottom title="Outstanding Paper"><i class="fas fa-award"></i></span><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1096" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1096/>Emotion-Cause Pair Extraction : A New Task to Emotion Analysis in Texts</a></strong><br><a href=/people/r/rui-xia/>Rui Xia</a>
|
<a href=/people/z/zixiang-ding/>Zixiang Ding</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1096><div class="card-body p-3 small">Emotion cause extraction (ECE), the task aimed at extracting the potential causes behind certain emotions in text, has gained much attention in recent years due to its wide applications. However, it suffers from two shortcomings : 1) the emotion must be annotated before cause extraction in ECE, which greatly limits its applications in real-world scenarios ; 2) the way to first annotate emotion and then extract the cause ignores the fact that they are mutually indicative. In this work, we propose a new task : emotion-cause pair extraction (ECPE), which aims to extract the potential pairs of <a href=https://en.wikipedia.org/wiki/Emotion>emotions</a> and corresponding causes in a document. We propose a 2-step approach to address this new ECPE task, which first performs individual emotion extraction and cause extraction via <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a>, and then conduct emotion-cause pairing and filtering. The experimental results on a benchmark emotion cause corpus prove the feasibility of the ECPE task as well as the effectiveness of our approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1099.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1099 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1099 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384475549 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1099/>Global Optimization under Length Constraint for Neural Text Summarization</a></strong><br><a href=/people/t/takuya-makino/>Takuya Makino</a>
|
<a href=/people/t/tomoya-iwakura/>Tomoya Iwakura</a>
|
<a href=/people/h/hiroya-takamura/>Hiroya Takamura</a>
|
<a href=/people/m/manabu-okumura/>Manabu Okumura</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1099><div class="card-body p-3 small">We propose a global optimization method under length constraint (GOLC) for neural text summarization models. GOLC increases the probabilities of generating summaries that have high evaluation scores, ROUGE in this paper, within a desired length. We compared GOLC with two optimization methods, a maximum log-likelihood and a minimum risk training, on CNN / Daily Mail and a Japanese single document summarization data set of The Mainichi Shimbun Newspapers. The experimental results show that a state-of-the-art neural summarization model optimized with GOLC generates fewer overlength summaries while maintaining the fastest <a href=https://en.wikipedia.org/wiki/Time_complexity>processing speed</a> ; only 6.70 % overlength summaries on CNN / Daily and 7.8 % on long summary of Mainichi, compared to the approximately 20 % to 50 % on CNN / Daily Mail and 10 % to 30 % on Mainichi with the other optimization methods. We also demonstrate the importance of the generation of in-length summaries for <a href=https://en.wikipedia.org/wiki/Post-editing>post-editing</a> with the dataset Mainich that is created with strict length constraints. The ex- perimental results show approximately 30 % to 40 % improved post-editing time by use of in-length summaries.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1102.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1102 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1102 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1102.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384478403 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1102" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1102/>Multi-News : A Large-Scale Multi-Document Summarization Dataset and Abstractive Hierarchical Model</a></strong><br><a href=/people/a/alexander-richard-fabbri/>Alexander Fabbri</a>
|
<a href=/people/i/irene-li/>Irene Li</a>
|
<a href=/people/t/tianwei-she/>Tianwei She</a>
|
<a href=/people/s/suyi-li/>Suyi Li</a>
|
<a href=/people/d/dragomir-radev/>Dragomir Radev</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1102><div class="card-body p-3 small">Automatic generation of summaries from multiple <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a> is a valuable tool as the number of <a href=https://en.wikipedia.org/wiki/Online_newspaper>online publications</a> grows rapidly. Single document summarization (SDS) systems have benefited from advances in neural encoder-decoder model thanks to the availability of large datasets. However, multi-document summarization (MDS) of <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a> has been limited to <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> of a couple of hundred examples. In this paper, we introduce Multi-News, the first large-scale MDS news dataset. Additionally, we propose an end-to-end model which incorporates a traditional extractive summarization model with a standard SDS model and achieves competitive results on MDS datasets. We benchmark several methods on Multi-News and hope that this work will promote advances in summarization in the multi-document setting.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1103.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1103 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1103 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384478489 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1103" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1103/>Generating Natural Language Adversarial Examples through Probability Weighted Word Saliency</a></strong><br><a href=/people/s/shuhuai-ren/>Shuhuai Ren</a>
|
<a href=/people/y/yihe-deng/>Yihe Deng</a>
|
<a href=/people/k/kun-he/>Kun He</a>
|
<a href=/people/w/wanxiang-che/>Wanxiang Che</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1103><div class="card-body p-3 small">We address the problem of adversarial attacks on <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a>, which is rarely studied comparing to attacks on <a href=https://en.wikipedia.org/wiki/Image_classification>image classification</a>. The challenge of this task is to generate adversarial examples that maintain <a href=https://en.wikipedia.org/wiki/Lexical_analysis>lexical correctness</a>, <a href=https://en.wikipedia.org/wiki/Grammaticality>grammatical correctness</a> and <a href=https://en.wikipedia.org/wiki/Semantic_similarity>semantic similarity</a>. Based on the synonyms substitution strategy, we introduce a new word replacement order determined by both the word saliency and the classification probability, and propose a <a href=https://en.wikipedia.org/wiki/Greedy_algorithm>greedy algorithm</a> called probability weighted word saliency (PWWS) for text adversarial attack. Experiments on three popular datasets using <a href=https://en.wikipedia.org/wiki/Convolution>convolutional</a> as well as LSTM models show that PWWS reduces the classification accuracy to the most extent, and keeps a very low word substitution rate. A human evaluation study shows that our generated adversarial examples maintain the <a href=https://en.wikipedia.org/wiki/Semantic_similarity>semantic similarity</a> well and are hard for humans to perceive. Performing adversarial training using our perturbed datasets improves the robustness of the <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a>. At last, our <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> also exhibits a good transferability on the generated adversarial examples.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1104.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1104 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1104 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384478577 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1104" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1104/>Heuristic Authorship Obfuscation</a></strong><br><a href=/people/j/janek-bevendorff/>Janek Bevendorff</a>
|
<a href=/people/m/martin-potthast/>Martin Potthast</a>
|
<a href=/people/m/matthias-hagen/>Matthias Hagen</a>
|
<a href=/people/b/benno-stein/>Benno Stein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1104><div class="card-body p-3 small">Authorship verification is the task of determining whether two texts were written by the same author. We deal with the adversary task, called authorship obfuscation : preventing verification by altering a to-be-obfuscated text. Our new obfuscation approach (1) models writing style difference as the Jensen-Shannon distance between the character n-gram distributions of texts, and (2) manipulates an author&#8217;s subconsciously encoded writing style in a sophisticated manner using heuristic search. To obfuscate, we analyze the huge space of textual variants for a paraphrased version of the to-be-obfuscated text that has a sufficient Jensen-Shannon distance at minimal costs in terms of text quality. We analyze, quantify, and illustrate the rationale of this approach, define paraphrasing operators, derive obfuscation thresholds, and develop an effective obfuscation framework. Our authorship obfuscation approach defeats state-of-the-art verification approaches, including unmasking and compression models, while keeping text changes at a minimum.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1108.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1108 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1108 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1108/>Figurative Usage Detection of Symptom Words to Improve Personal Health Mention Detection</a></strong><br><a href=/people/a/adith-iyer/>Adith Iyer</a>
|
<a href=/people/a/aditya-joshi/>Aditya Joshi</a>
|
<a href=/people/s/sarvnaz-karimi/>Sarvnaz Karimi</a>
|
<a href=/people/r/ross-sparks/>Ross Sparks</a>
|
<a href=/people/c/cecile-paris/>Cecile Paris</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1108><div class="card-body p-3 small">Personal health mention detection deals with predicting whether or not a given sentence is a report of a health condition. Past work mentions errors in this prediction when symptom words, i.e., names of symptoms of interest, are used in a <a href=https://en.wikipedia.org/wiki/Literal_and_figurative_language>figurative sense</a>. Therefore, we combine a state-of-the-art figurative usage detection with CNN-based personal health mention detection. To do so, we present two <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> : a <a href=https://en.wikipedia.org/wiki/Pipeline_(software)>pipeline-based approach</a> and a feature augmentation-based approach. The introduction of figurative usage detection results in an average improvement of 2.21 % F-score of personal health mention detection, in the case of the feature augmentation-based approach. This paper demonstrates the promise of using figurative usage detection to improve personal health mention detection.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1110.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1110 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1110 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1110/>Neural News Recommendation with Topic-Aware News Representation</a></strong><br><a href=/people/c/chuhan-wu/>Chuhan Wu</a>
|
<a href=/people/f/fangzhao-wu/>Fangzhao Wu</a>
|
<a href=/people/m/mingxiao-an/>Mingxiao An</a>
|
<a href=/people/y/yongfeng-huang/>Yongfeng Huang</a>
|
<a href=/people/x/xing-xie/>Xing Xie</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1110><div class="card-body p-3 small">News recommendation can help users find interested news and alleviate <a href=https://en.wikipedia.org/wiki/Information_overload>information overload</a>. The topic information of news is critical for learning accurate news and user representations for <a href=https://en.wikipedia.org/wiki/News_aggregator>news recommendation</a>. However, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> is not considered in many existing news recommendation methods. In this paper, we propose a neural news recommendation approach with topic-aware news representations. The core of our approach is a topic-aware news encoder and a user encoder. In the news encoder we learn representations of news from their titles via CNN networks and apply attention networks to select important words. In addition, we propose to learn topic-aware news representations by jointly training the news encoder with an auxiliary topic classification task. In the user encoder we learn the representations of users from their browsed news and use attention networks to select informative news for user representation learning. Extensive experiments on a real-world dataset validate the effectiveness of our approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1115.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1115 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1115 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1115/>Self-Attentional Models for <a href=https://en.wikipedia.org/wiki/Lattice_model_(physics)>Lattice Inputs</a></a></strong><br><a href=/people/m/matthias-sperber/>Matthias Sperber</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/n/ngoc-quan-pham/>Ngoc-Quan Pham</a>
|
<a href=/people/a/alex-waibel/>Alex Waibel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1115><div class="card-body p-3 small">Lattices are an efficient and effective method to encode ambiguity of upstream systems in natural language processing tasks, for example to compactly capture multiple speech recognition hypotheses, or to represent multiple linguistic analyses. Previous work has extended <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural networks</a> to model lattice inputs and achieved improvements in various tasks, but these models suffer from very slow computation speeds. This paper extends the recently proposed paradigm of self-attention to handle lattice inputs. Self-attention is a sequence modeling technique that relates inputs to one another by computing pairwise similarities and has gained popularity for both its strong results and its computational efficiency. To extend such models to handle <a href=https://en.wikipedia.org/wiki/Lattice_(group)>lattices</a>, we introduce probabilistic reachability masks that incorporate lattice structure into the model and support lattice scores if available. We also propose a method for adapting positional embeddings to <a href=https://en.wikipedia.org/wiki/Lattice_model_(physics)>lattice structures</a>. We apply the proposed model to a speech translation task and find that it outperforms all examined baselines while being much faster to compute than previous neural lattice models during both <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training</a> and <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1117.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1117 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1117 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1117/>A Compact and Language-Sensitive Multilingual Translation Method</a></strong><br><a href=/people/y/yining-wang/>Yining Wang</a>
|
<a href=/people/l/long-zhou/>Long Zhou</a>
|
<a href=/people/j/jiajun-zhang/>Jiajun Zhang</a>
|
<a href=/people/f/feifei-zhai/>Feifei Zhai</a>
|
<a href=/people/j/jingfang-xu/>Jingfang Xu</a>
|
<a href=/people/c/chengqing-zong/>Chengqing Zong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1117><div class="card-body p-3 small">Multilingual neural machine translation (Multi-NMT) with one encoder-decoder model has made remarkable progress due to its simple deployment. However, this multilingual translation paradigm does not make full use of <a href=https://en.wikipedia.org/wiki/Language_family>language commonality</a> and parameter sharing between encoder and decoder. Furthermore, this kind of <a href=https://en.wikipedia.org/wiki/Paradigm>paradigm</a> can not outperform the individual <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained on bilingual corpus in most cases. In this paper, we propose a compact and language-sensitive method for multilingual translation. To maximize parameter sharing, we first present a universal representor to replace both encoder and decoder models. To make the representor sensitive for specific languages, we further introduce language-sensitive embedding, <a href=https://en.wikipedia.org/wiki/Attention>attention</a>, and <a href=https://en.wikipedia.org/wiki/Discriminator>discriminator</a> with the ability to enhance model performance. We verify our methods on various translation scenarios, including one-to-many, many-to-many and zero-shot. Extensive experiments demonstrate that our proposed methods remarkably outperform strong standard multilingual translation systems on WMT and IWSLT datasets. Moreover, we find that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is especially helpful in low-resource and zero-shot translation scenarios.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1119.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1119 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1119 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1119/>Unsupervised Bilingual Word Embedding Agreement for Unsupervised Neural Machine Translation</a></strong><br><a href=/people/h/haipeng-sun/>Haipeng Sun</a>
|
<a href=/people/r/rui-wang/>Rui Wang</a>
|
<a href=/people/k/kehai-chen/>Kehai Chen</a>
|
<a href=/people/m/masao-utiyama/>Masao Utiyama</a>
|
<a href=/people/e/eiichiro-sumita/>Eiichiro Sumita</a>
|
<a href=/people/t/tiejun-zhao/>Tiejun Zhao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1119><div class="card-body p-3 small">Unsupervised bilingual word embedding (UBWE), together with other technologies such as <a href=https://en.wikipedia.org/wiki/Back-translation>back-translation</a> and <a href=https://en.wikipedia.org/wiki/Noise_reduction>denoising</a>, has helped unsupervised neural machine translation (UNMT) achieve remarkable results in several language pairs. In previous methods, UBWE is first trained using non-parallel monolingual corpora and then this pre-trained UBWE is used to initialize the <a href=https://en.wikipedia.org/wiki/Word_embedding>word embedding</a> in the encoder and decoder of UNMT. That is, the training of UBWE and UNMT are separate. In this paper, we first empirically investigate the relationship between UBWE and <a href=https://en.wikipedia.org/wiki/UNMT>UNMT</a>. The empirical findings show that the performance of <a href=https://en.wikipedia.org/wiki/Unmanned_combat_aerial_vehicle>UNMT</a> is significantly affected by the performance of <a href=https://en.wikipedia.org/wiki/Unmanned_combat_aerial_vehicle>UBWE</a>. Thus, we propose two methods that train UNMT with UBWE agreement. Empirical results on several language pairs show that the proposed methods significantly outperform conventional UNMT.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1120.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1120 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1120 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1120" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1120/>Effective Cross-lingual Transfer of Neural Machine Translation Models without Shared Vocabularies</a></strong><br><a href=/people/y/yunsu-kim/>Yunsu Kim</a>
|
<a href=/people/y/yingbo-gao/>Yingbo Gao</a>
|
<a href=/people/h/hermann-ney/>Hermann Ney</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1120><div class="card-body p-3 small">Transfer learning or multilingual model is essential for low-resource neural machine translation (NMT), but the applicability is limited to cognate languages by sharing their vocabularies. This paper shows effective techniques to transfer a pretrained NMT model to a new, unrelated language without shared vocabularies. We relieve the vocabulary mismatch by using cross-lingual word embedding, train a more language-agnostic encoder by injecting artificial noises, and generate synthetic data easily from the pretraining data without back-translation. Our <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> do not require restructuring the vocabulary or retraining the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>. We improve plain NMT transfer by up to +5.1 % BLEU in five low-resource translation tasks, outperforming multilingual joint training by a large margin. We also provide extensive ablation studies on pretrained embedding, synthetic data, vocabulary size, and parameter freezing for a better understanding of NMT transfer.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1121.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1121 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1121 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1121/>Improved Zero-shot Neural Machine Translation via Ignoring Spurious Correlations</a></strong><br><a href=/people/j/jiatao-gu/>Jiatao Gu</a>
|
<a href=/people/y/yong-wang/>Yong Wang</a>
|
<a href=/people/k/kyunghyun-cho/>Kyunghyun Cho</a>
|
<a href=/people/v/victor-o-k-li/>Victor O.K. Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1121><div class="card-body p-3 small">Zero-shot translation, translating between language pairs on which a Neural Machine Translation (NMT) system has never been trained, is an emergent property when training the <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>system</a> in multilingual settings. However, naive training for zero-shot NMT easily fails, and is sensitive to hyper-parameter setting. The performance typically lags far behind the more conventional pivot-based approach which translates twice using a third language as a pivot. In this work, we address the degeneracy problem due to capturing spurious correlations by quantitatively analyzing the <a href=https://en.wikipedia.org/wiki/Mutual_information>mutual information</a> between language IDs of the source and decoded sentences. Inspired by this analysis, we propose to use two simple but effective approaches : (1) decoder pre-training ; (2) back-translation. These methods show significant improvement (4 22 BLEU points) over the vanilla zero-shot translation on three challenging multilingual datasets, and achieve similar or better results than the pivot-based approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1122.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1122 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1122 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1122.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1122" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1122/>Syntactically Supervised Transformers for Faster Neural Machine Translation</a></strong><br><a href=/people/n/nader-akoury/>Nader Akoury</a>
|
<a href=/people/k/kalpesh-krishna/>Kalpesh Krishna</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1122><div class="card-body p-3 small">Standard decoders for <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation autoregressively</a> generate a single target token per timestep, which slows <a href=https://en.wikipedia.org/wiki/Inference>inference</a> especially for long outputs. While architectural advances such as the Transformer fully parallelize the decoder computations at training time, <a href=https://en.wikipedia.org/wiki/Inference>inference</a> still proceeds sequentially. Recent developments in non- and semi-autoregressive decoding produce multiple tokens per timestep independently of the others, which improves inference speed but deteriorates translation quality. In this work, we propose the syntactically supervised Transformer (SynST), which first autoregressively predicts a chunked parse tree before generating all of the target tokens in one shot conditioned on the predicted parse. A series of controlled experiments demonstrates that SynST decodes sentences ~5x faster than the baseline autoregressive Transformer while achieving higher BLEU scores than most competing methods on En-De and En-Fr datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1123.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1123 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1123 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1123/>Dynamically Composing Domain-Data Selection with Clean-Data Selection by Co-Curricular Learning for Neural Machine Translation</a></strong><br><a href=/people/w/wei-wang/>Wei Wang</a>
|
<a href=/people/i/isaac-caswell/>Isaac Caswell</a>
|
<a href=/people/c/ciprian-chelba/>Ciprian Chelba</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1123><div class="card-body p-3 small">Noise and domain are important aspects of <a href=https://en.wikipedia.org/wiki/Data_quality>data quality</a> for <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a>. Existing research focus separately on domain-data selection, clean-data selection, or their static combination, leaving the dynamic interaction across them not explicitly examined. This paper introduces a co-curricular learning method to compose dynamic domain-data selection with dynamic clean-data selection, for <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> across both capabilities. We apply an EM-style optimization procedure to further refine the co-curriculum. Experiment results and analysis with two domains demonstrate the effectiveness of the method and the properties of data scheduled by the co-curriculum.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1125.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1125 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1125 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1125/>Imitation Learning for Non-Autoregressive Neural Machine Translation</a></strong><br><a href=/people/b/bingzhen-wei/>Bingzhen Wei</a>
|
<a href=/people/m/mingxuan-wang/>Mingxuan Wang</a>
|
<a href=/people/h/hao-zhou/>Hao Zhou</a>
|
<a href=/people/j/junyang-lin/>Junyang Lin</a>
|
<a href=/people/x/xu-sun/>Xu Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1125><div class="card-body p-3 small">Non-autoregressive translation models (NAT) have achieved impressive inference speedup. A potential issue of the existing NAT algorithms, however, is that the decoding is conducted in parallel, without directly considering previous context. In this paper, we propose an imitation learning framework for non-autoregressive machine translation, which still enjoys the fast translation speed but gives comparable translation performance compared to its auto-regressive counterpart. We conduct experiments on the IWSLT16, WMT14 and WMT16 datasets. Our proposed model achieves a significant speedup over the <a href=https://en.wikipedia.org/wiki/Autoregressive_model>autoregressive models</a>, while keeping the translation quality comparable to the <a href=https://en.wikipedia.org/wiki/Autoregressive_model>autoregressive models</a>. By sampling <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence length</a> in parallel at <a href=https://en.wikipedia.org/wiki/Time_complexity>inference time</a>, we achieve the performance of 31.85 BLEU on WMT16 RoEn and 30.68 BLEU on IWSLT16 EnDe.<tex-math>\\rightarrow</tex-math>En and 30.68 BLEU on IWSLT16 En<tex-math>\\rightarrow</tex-math>De.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1126.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1126 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1126 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1126.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1126/>Monotonic Infinite Lookback Attention for Simultaneous Machine Translation</a></strong><br><a href=/people/n/naveen-arivazhagan/>Naveen Arivazhagan</a>
|
<a href=/people/c/colin-cherry/>Colin Cherry</a>
|
<a href=/people/w/wolfgang-macherey/>Wolfgang Macherey</a>
|
<a href=/people/c/chung-cheng-chiu/>Chung-Cheng Chiu</a>
|
<a href=/people/s/semih-yavuz/>Semih Yavuz</a>
|
<a href=/people/r/ruoming-pang/>Ruoming Pang</a>
|
<a href=/people/w/wei-li/>Wei Li</a>
|
<a href=/people/c/colin-raffel/>Colin Raffel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1126><div class="card-body p-3 small">Simultaneous machine translation begins to translate each source sentence before the source speaker is finished speaking, with applications to live and streaming scenarios. Simultaneous systems must carefully schedule their reading of the source sentence to balance <a href=https://en.wikipedia.org/wiki/Quality_(business)>quality</a> against <a href=https://en.wikipedia.org/wiki/Latency_(engineering)>latency</a>. We present the first simultaneous translation system to learn an adaptive schedule jointly with a neural machine translation (NMT) model that attends over all source tokens read thus far. We do so by introducing Monotonic Infinite Lookback (MILk) attention, which maintains both a hard, monotonic attention head to schedule the reading of the source sentence, and a soft attention head that extends from the monotonic head back to the beginning of the source. We show that MILk&#8217;s adaptive schedule allows it to arrive at latency-quality trade-offs that are favorable to those of a recently proposed wait-k strategy for many latency values.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1130.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1130 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1130 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1130/>Exploiting Entity BIO Tag Embeddings and Multi-task Learning for Relation Extraction with Imbalanced Data<span class=acl-fixed-case>BIO</span> Tag Embeddings and Multi-task Learning for Relation Extraction with Imbalanced Data</a></strong><br><a href=/people/w/wei-ye/>Wei Ye</a>
|
<a href=/people/b/bo-li/>Bo Li</a>
|
<a href=/people/r/rui-xie/>Rui Xie</a>
|
<a href=/people/z/zhonghao-sheng/>Zhonghao Sheng</a>
|
<a href=/people/l/long-chen/>Long Chen</a>
|
<a href=/people/s/shikun-zhang/>Shikun Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1130><div class="card-body p-3 small">In practical scenario, <a href=https://en.wikipedia.org/wiki/Relation_extraction>relation extraction</a> needs to first identify entity pairs that have relation and then assign a correct <a href=https://en.wikipedia.org/wiki/Relation_(database)>relation class</a>. However, the number of non-relation entity pairs in context (negative instances) usually far exceeds the others (positive instances), which negatively affects a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s performance. To mitigate this problem, we propose a multi-task architecture which jointly trains a model to perform relation identification with cross-entropy loss and relation classification with ranking loss. Meanwhile, we observe that a sentence may have multiple entities and relation mentions, and the patterns in which the entities appear in a sentence may contain useful semantic information that can be utilized to distinguish between positive and negative instances. Thus we further incorporate the embeddings of character-wise / word-wise BIO tag from the named entity recognition task into character / word embeddings to enrich the input representation. Experiment results show that our proposed approach can significantly improve the performance of a baseline model with more than 10 % absolute increase in F1-score, and outperform the state-of-the-art models on ACE 2005 Chinese and English corpus. Moreover, BIO tag embeddings are particularly effective and can be used to improve other <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> as well.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1132.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1132 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1132 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1132" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1132/>Extracting Multiple-Relations in One-Pass with Pre-Trained Transformers</a></strong><br><a href=/people/h/haoyu-wang/>Haoyu Wang</a>
|
<a href=/people/m/ming-tan/>Ming Tan</a>
|
<a href=/people/m/mo-yu/>Mo Yu</a>
|
<a href=/people/s/shiyu-chang/>Shiyu Chang</a>
|
<a href=/people/d/dakuo-wang/>Dakuo Wang</a>
|
<a href=/people/k/kun-xu/>Kun Xu</a>
|
<a href=/people/x/xiaoxiao-guo/>Xiaoxiao Guo</a>
|
<a href=/people/s/saloni-potdar/>Saloni Potdar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1132><div class="card-body p-3 small">Many approaches to extract multiple relations from a paragraph require multiple passes over the paragraph. In practice, multiple passes are computationally expensive and this makes difficult to scale to longer paragraphs and larger <a href=https://en.wikipedia.org/wiki/Text_corpus>text corpora</a>. In this work, we focus on the task of multiple relation extractions by encoding the paragraph only once. We build our solution upon the pre-trained self-attentive models (Transformer), where we first add a structured prediction layer to handle extraction between multiple entity pairs, then enhance the paragraph embedding to capture multiple relational information associated with each entity with entity-aware attention. We show that our approach is not only scalable but can also perform <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> on the standard benchmark ACE 2005.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1134.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1134 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1134 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1134" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1134/>Fine-tuning Pre-Trained Transformer Language Models to Distantly Supervised Relation Extraction</a></strong><br><a href=/people/c/christoph-alt/>Christoph Alt</a>
|
<a href=/people/m/marc-hubner/>Marc Hübner</a>
|
<a href=/people/l/leonhard-hennig/>Leonhard Hennig</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1134><div class="card-body p-3 small">Distantly supervised relation extraction is widely used to extract relational facts from text, but suffers from noisy labels. Current relation extraction methods try to alleviate the noise by multi-instance learning and by providing supporting linguistic and contextual information to more efficiently guide the relation classification. While achieving state-of-the-art results, we observed these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> to be biased towards recognizing a limited set of relations with high <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a>, while ignoring those in the long tail. To address this gap, we utilize a pre-trained language model, the OpenAI Generative Pre-trained Transformer (GPT) (Radford et al., 2018). The GPT and similar models have been shown to capture semantic and syntactic features, and also a notable amount of common-sense knowledge, which we hypothesize are important features for recognizing a more diverse set of relations. By extending the GPT to the distantly supervised setting, and fine-tuning it on the NYT10 dataset, we show that it predicts a larger set of distinct relation types with high confidence. Manual and automated evaluation of our <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> shows that it achieves a state-of-the-art <a href=https://en.wikipedia.org/wiki/Receiver_operating_characteristic>AUC score</a> of 0.422 on the NYT10 dataset, and performs especially well at higher recall levels.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1135.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1135 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1135 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1135/>ARNOR : Attention Regularization based Noise Reduction for Distant Supervision Relation Classification<span class=acl-fixed-case>ARNOR</span>: Attention Regularization based Noise Reduction for Distant Supervision Relation Classification</a></strong><br><a href=/people/w/wei-jia/>Wei Jia</a>
|
<a href=/people/d/dai-dai/>Dai Dai</a>
|
<a href=/people/x/xinyan-xiao/>Xinyan Xiao</a>
|
<a href=/people/h/hua-wu/>Hua Wu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1135><div class="card-body p-3 small">Distant supervision is widely used in relation classification in order to create large-scale training data by aligning a <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge base</a> with an unlabeled corpus. However, it also introduces amounts of noisy labels where a contextual sentence actually does not express the labeled relation. In this paper, we propose ARNOR, a novel Attention Regularization based NOise Reduction framework for distant supervision relation classification. ARNOR assumes that a trustable relation label should be explained by the neural attention model. Specifically, our ARNOR framework iteratively learns an interpretable model and utilizes it to select trustable instances. We first introduce attention regularization to force the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to pay attention to the patterns which explain the relation labels, so as to make the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> more interpretable. Then, if the learned model can clearly locate the relation patterns of a candidate instance in the training set, we will select it as a trustable instance for further training step. According to the experiments on NYT data, our ARNOR framework achieves significant improvements over state-of-the-art methods in both relation classification performance and noise reduction effect.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1136.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1136 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1136 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1136/>GraphRel : Modeling Text as Relational Graphs for Joint Entity and Relation Extraction<span class=acl-fixed-case>G</span>raph<span class=acl-fixed-case>R</span>el: Modeling Text as Relational Graphs for Joint Entity and Relation Extraction</a></strong><br><a href=/people/t/tsu-jui-fu/>Tsu-Jui Fu</a>
|
<a href=/people/p/peng-hsuan-li/>Peng-Hsuan Li</a>
|
<a href=/people/w/wei-yun-ma/>Wei-Yun Ma</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1136><div class="card-body p-3 small">In this paper, we present GraphRel, an end-to-end relation extraction model which uses graph convolutional networks (GCNs) to jointly learn named entities and relations. In contrast to previous baselines, we consider the interaction between named entities and relations via a 2nd-phase relation-weighted GCN to better extract <a href=https://en.wikipedia.org/wiki/Binary_relation>relations</a>. Linear and dependency structures are both used to extract both sequential and regional features of the text, and a complete word graph is further utilized to extract implicit features among all word pairs of the text. With the graph-based approach, the prediction for overlapping relations is substantially improved over previous sequential approaches. We evaluate GraphRel on two public datasets : <a href=https://en.wikipedia.org/wiki/The_New_York_Times>NYT</a> and WebNLG. Results show that GraphRel maintains high <a href=https://en.wikipedia.org/wiki/Precision_(computer_science)>precision</a> while increasing <a href=https://en.wikipedia.org/wiki/Precision_(computer_science)>recall</a> substantially. Also, GraphRel outperforms previous <a href=https://en.wikipedia.org/wiki/Work_(thermodynamics)>work</a> by 3.2 % and 5.8 % (F1 score), achieving a new state-of-the-art for <a href=https://en.wikipedia.org/wiki/Relation_extraction>relation extraction</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1137.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1137 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1137 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1137" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1137/>DIAG-NRE : A Neural Pattern Diagnosis Framework for Distantly Supervised Neural Relation Extraction<span class=acl-fixed-case>DIAG</span>-<span class=acl-fixed-case>NRE</span>: A Neural Pattern Diagnosis Framework for Distantly Supervised Neural Relation Extraction</a></strong><br><a href=/people/s/shun-zheng/>Shun Zheng</a>
|
<a href=/people/x/xu-han/>Xu Han</a>
|
<a href=/people/y/yankai-lin/>Yankai Lin</a>
|
<a href=/people/p/peilin-yu/>Peilin Yu</a>
|
<a href=/people/l/lu-chen/>Lu Chen</a>
|
<a href=/people/l/ling-huang/>Ling Huang</a>
|
<a href=/people/z/zhiyuan-liu/>Zhiyuan Liu</a>
|
<a href=/people/w/wei-xu/>Wei Xu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1137><div class="card-body p-3 small">Pattern-based labeling methods have achieved promising results in alleviating the inevitable labeling noises of distantly supervised neural relation extraction. However, these methods require significant expert labor to write relation-specific patterns, which makes them too sophisticated to generalize quickly. To ease the labor-intensive workload of pattern writing and enable the quick generalization to new relation types, we propose a neural pattern diagnosis framework, DIAG-NRE, that can automatically summarize and refine high-quality relational patterns from noise data with human experts in the loop. To demonstrate the effectiveness of DIAG-NRE, we apply it to two real-world datasets and present both significant and interpretable improvements over state-of-the-art methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1139.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1139 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1139 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1139" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1139/>ERNIE : Enhanced Language Representation with Informative Entities<span class=acl-fixed-case>ERNIE</span>: Enhanced Language Representation with Informative Entities</a></strong><br><a href=/people/z/zhengyan-zhang/>Zhengyan Zhang</a>
|
<a href=/people/x/xu-han/>Xu Han</a>
|
<a href=/people/z/zhiyuan-liu/>Zhiyuan Liu</a>
|
<a href=/people/x/xin-jiang/>Xin Jiang</a>
|
<a href=/people/m/maosong-sun/>Maosong Sun</a>
|
<a href=/people/q/qun-liu/>Qun Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1139><div class="card-body p-3 small">Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>language understanding</a>. We argue that informative entities in KGs can enhance <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>language representation</a> with <a href=https://en.wikipedia.org/wiki/Knowledge>external knowledge</a>. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The code and datasets will be available in the future.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1140.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1140 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1140 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1140" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1140/>Multi-Channel Graph Neural Network for Entity Alignment</a></strong><br><a href=/people/y/yixin-cao/>Yixin Cao</a>
|
<a href=/people/z/zhiyuan-liu/>Zhiyuan Liu</a>
|
<a href=/people/c/chengjiang-li/>Chengjiang Li</a>
|
<a href=/people/z/zhiyuan-liu/>Zhiyuan Liu</a>
|
<a href=/people/j/juanzi-li/>Juanzi Li</a>
|
<a href=/people/t/tat-seng-chua/>Tat-Seng Chua</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1140><div class="card-body p-3 small">Entity alignment typically suffers from the issues of structural heterogeneity and limited seed alignments. In this paper, we propose a novel Multi-channel Graph Neural Network model (MuGNN) to learn alignment-oriented knowledge graph (KG) embeddings by robustly encoding two KGs via multiple channels. Each channel encodes KGs via different relation weighting schemes with respect to self-attention towards KG completion and cross-KG attention for pruning exclusive entities respectively, which are further combined via pooling techniques. Moreover, we also infer and transfer rule knowledge for completing two KGs consistently. MuGNN is expected to reconcile the structural differences of two KGs, and thus make better use of seed alignments. Extensive experiments on five publicly available datasets demonstrate our superior performance (5 % Hits@1 up on average). Source code and data used in the experiments can be accessed at https://github.com/thunlp/MuGNN.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1141.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1141 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1141 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1141.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1141.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1141" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1141/>A Neural Multi-digraph Model for Chinese NER with Gazetteers<span class=acl-fixed-case>C</span>hinese <span class=acl-fixed-case>NER</span> with Gazetteers</a></strong><br><a href=/people/r/ruixue-ding/>Ruixue Ding</a>
|
<a href=/people/p/pengjun-xie/>Pengjun Xie</a>
|
<a href=/people/x/xiaoyan-zhang/>Xiaoyan Zhang</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a>
|
<a href=/people/l/linlin-li/>Linlin Li</a>
|
<a href=/people/l/luo-si/>Luo Si</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1141><div class="card-body p-3 small">Gazetteers were shown to be useful resources for named entity recognition (NER). Many existing approaches to incorporating <a href=https://en.wikipedia.org/wiki/Gazetteer>gazetteers</a> into machine learning based NER systems rely on manually defined selection strategies or handcrafted templates, which may not always lead to optimal effectiveness, especially when multiple gazetteers are involved. This is especially the case for the task of Chinese NER, where the words are not naturally tokenized, leading to additional <a href=https://en.wikipedia.org/wiki/Ambiguity>ambiguities</a>. To automatically learn how to incorporate multiple <a href=https://en.wikipedia.org/wiki/Gazetteer>gazetteers</a> into an NER system, we propose a novel approach based on graph neural networks with a multi-digraph structure that captures the information that the <a href=https://en.wikipedia.org/wiki/Gazetteer>gazetteers</a> offer. Experiments on various datasets show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is effective in incorporating rich gazetteer information while resolving <a href=https://en.wikipedia.org/wiki/Ambiguity>ambiguities</a>, outperforming previous approaches.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1153.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1153 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1153 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1153" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1153/>Towards Lossless Encoding of Sentences</a></strong><br><a href=/people/g/gabriele-prato/>Gabriele Prato</a>
|
<a href=/people/m/mathieu-duchesneau/>Mathieu Duchesneau</a>
|
<a href=/people/s/sarath-chandar/>Sarath Chandar</a>
|
<a href=/people/a/alain-tapp/>Alain Tapp</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1153><div class="card-body p-3 small">A lot of work has been done in the field of <a href=https://en.wikipedia.org/wiki/Image_compression>image compression</a> via <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning</a>, but not much attention has been given to the compression of natural language. Compressing text into lossless representations while making <a href=https://en.wikipedia.org/wiki/Feature_(computer_vision)>features</a> easily retrievable is not a trivial task, yet has huge benefits. Most methods designed to produce feature rich sentence embeddings focus solely on performing well on downstream tasks and are unable to properly reconstruct the original sequence from the learned embedding. In this work, we propose a near lossless method for encoding long sequences of texts as well as all of their sub-sequences into feature rich representations. We test our method on <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> and show good performance across all sub-sentence and sentence embeddings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1157.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1157 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1157 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1157/>Historical Text Normalization with Delayed Rewards</a></strong><br><a href=/people/s/simon-flachs/>Simon Flachs</a>
|
<a href=/people/m/marcel-bollmann/>Marcel Bollmann</a>
|
<a href=/people/a/anders-sogaard/>Anders Søgaard</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1157><div class="card-body p-3 small">Training neural sequence-to-sequence models with simple token-level log-likelihood is now a standard approach to historical text normalization, albeit often outperformed by phrase-based models. Policy gradient training enables direct optimization for exact matches, and while the small datasets in historical text normalization are prohibitive of <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>from-scratch reinforcement learning</a>, we show that policy gradient fine-tuning leads to significant improvements across the board. Policy gradient training, in particular, leads to more accurate <a href=https://en.wikipedia.org/wiki/Normalization_(statistics)>normalizations</a> for long or unseen words.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1160.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1160 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1160 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384482232 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1160" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1160/>Gender-preserving Debiasing for Pre-trained Word Embeddings</a></strong><br><a href=/people/m/masahiro-kaneko/>Masahiro Kaneko</a>
|
<a href=/people/d/danushka-bollegala/>Danushka Bollegala</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1160><div class="card-body p-3 small">Word embeddings learnt from massive text collections have demonstrated significant levels of discriminative biases such as gender, racial or ethnic biases, which in turn bias the down-stream NLP applications that use those word embeddings. Taking gender-bias as a working example, we propose a debiasing method that preserves non-discriminative gender-related information, while removing stereotypical discriminative gender biases from pre-trained word embeddings. Specifically, we consider four types of information : feminine, masculine, gender-neutral and stereotypical, which represent the relationship between gender vs. bias, and propose a debiasing method that (a) preserves the gender-related information in feminine and masculine words, (b) preserves the neutrality in gender-neutral words, and (c) removes the biases from stereotypical words. Experimental results on several previously proposed benchmark datasets show that our proposed method can debias pre-trained word embeddings better than existing SoTA methods proposed for debiasing word embeddings while preserving gender-related but non-discriminative information.<i>feminine</i>, <i>masculine</i>, <i>gender-neutral</i> and <i>stereotypical</i>, which represent the relationship between gender vs. bias, and propose a debiasing method that (a) preserves the gender-related information in feminine and masculine words, (b) preserves the neutrality in gender-neutral words, and (c) removes the biases from stereotypical words. Experimental results on several previously proposed benchmark datasets show that our proposed method can debias pre-trained word embeddings better than existing SoTA methods proposed for debiasing word embeddings while preserving gender-related but non-discriminative information.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1165.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1165 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1165 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384489801 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1165/>LSTMEmbed : Learning Word and Sense Representations from a Large Semantically Annotated Corpus with Long Short-Term Memories<span class=acl-fixed-case>LSTME</span>mbed: Learning Word and Sense Representations from a Large Semantically Annotated Corpus with Long Short-Term Memories</a></strong><br><a href=/people/i/ignacio-iacobacci/>Ignacio Iacobacci</a>
|
<a href=/people/r/roberto-navigli/>Roberto Navigli</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1165><div class="card-body p-3 small">While <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> are now a de facto standard representation of words in most NLP tasks, recently the attention has been shifting towards <a href=https://en.wikipedia.org/wiki/Vector_graphics>vector representations</a> which capture the different meanings, i.e., senses, of words. In this paper we explore the capabilities of a bidirectional LSTM model to learn representations of word senses from semantically annotated corpora. We show that the utilization of an <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> that is aware of <a href=https://en.wikipedia.org/wiki/Word_order>word order</a>, like an LSTM, enables us to create better <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a>. We assess our proposed model on various standard benchmarks for evaluating semantic representations, reaching state-of-the-art performance on the SemEval-2014 word-to-sense similarity task. We release the <a href=https://en.wikipedia.org/wiki/Source_code>code</a> and the resulting <a href=https://en.wikipedia.org/wiki/Word_embedding>word and sense embeddings</a> at http://lcl.uniroma1.it/LSTMEmbed.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1166.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1166 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1166 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384490216 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1166/>Understanding Undesirable Word Embedding Associations</a></strong><br><a href=/people/k/kawin-ethayarajh/>Kawin Ethayarajh</a>
|
<a href=/people/d/david-duvenaud/>David Duvenaud</a>
|
<a href=/people/g/graeme-hirst/>Graeme Hirst</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1166><div class="card-body p-3 small">Word embeddings are often criticized for capturing undesirable word associations such as <a href=https://en.wikipedia.org/wiki/Stereotypes_of_East_Asians_in_the_United_States>gender stereotypes</a>. However, <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> for measuring and removing such <a href=https://en.wikipedia.org/wiki/Bias>biases</a> remain poorly understood. We show that for any embedding model that implicitly does matrix factorization, debiasing vectors post hoc using subspace projection (Bolukbasi et al., 2016) is, under certain conditions, equivalent to training on an unbiased corpus. We also prove that WEAT, the most common <a href=https://en.wikipedia.org/wiki/Association_test>association test</a> for word embeddings, systematically overestimates bias. Given that the subspace projection method is provably effective, we use it to derive a new measure of association called the relational inner product association (RIPA). Experiments with RIPA reveal that, on average, skipgram with negative sampling (SGNS) does not make most words any more gendered than they are in the training corpus. However, for gender-stereotyped words, SGNS actually amplifies the gender association in the corpus.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1167.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1167 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1167 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1167.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1167/>Unsupervised Discovery of Gendered Language through <a href=https://en.wikipedia.org/wiki/Latent-variable_model>Latent-Variable Modeling</a></a></strong><br><a href=/people/a/alexander-miserlis-hoyle/>Alexander Miserlis Hoyle</a>
|
<a href=/people/l/lawrence-wolf-sonkin/>Lawrence Wolf-Sonkin</a>
|
<a href=/people/h/hanna-wallach/>Hanna Wallach</a>
|
<a href=/people/i/isabelle-augenstein/>Isabelle Augenstein</a>
|
<a href=/people/r/ryan-cotterell/>Ryan Cotterell</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1167><div class="card-body p-3 small">Studying the ways in which language is gendered has long been an area of interest in <a href=https://en.wikipedia.org/wiki/Sociolinguistics>sociolinguistics</a>. Studies have explored, for example, the speech of male and female characters in film and the language used to describe male and female politicians. In this paper, we aim not to merely study this phenomenon qualitatively, but instead to quantify the degree to which the language used to describe men and women is different and, moreover, different in a positive or negative way. To that end, we introduce a generative latent-variable model that jointly represents adjective (or verb) choice, with its sentiment, given the natural gender of a head (or dependent) noun. We find that there are significant differences between descriptions of male and female nouns and that these differences align with common gender stereotypes : Positive adjectives used to describe women are more often related to their bodies than <a href=https://en.wikipedia.org/wiki/Adjective>adjectives</a> used to describe men.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1169.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1169 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1169 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384491244 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1169/>SphereRE : Distinguishing <a href=https://en.wikipedia.org/wiki/Lexical_analysis>Lexical Relations</a> with Hyperspherical Relation Embeddings<span class=acl-fixed-case>S</span>phere<span class=acl-fixed-case>RE</span>: Distinguishing Lexical Relations with Hyperspherical Relation Embeddings</a></strong><br><a href=/people/c/chengyu-wang/>Chengyu Wang</a>
|
<a href=/people/x/xiaofeng-he/>Xiaofeng He</a>
|
<a href=/people/a/aoying-zhou/>Aoying Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1169><div class="card-body p-3 small">Lexical relations describe how meanings of terms relate to each other. Typical examples include <a href=https://en.wikipedia.org/wiki/Hypernymy>hypernymy</a>, <a href=https://en.wikipedia.org/wiki/Synonym>synonymy</a>, <a href=https://en.wikipedia.org/wiki/Meronymy>meronymy</a>, etc. Automatic distinction of lexical relations is vital for NLP applications, and also challenging due to the lack of contextual signals to discriminate between such <a href=https://en.wikipedia.org/wiki/Binary_relation>relations</a>. In this work, we present a neural representation learning model to distinguish lexical relations among term pairs based on Hyperspherical Relation Embeddings (SphereRE). Rather than learning embeddings for individual terms, the model learns representations of relation triples by mapping them to the hyperspherical embedding space, where relation triples of different lexical relations are well separated. Experiments over several benchmarks confirm SphereRE outperforms <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-arts</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1170.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1170 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1170 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1170.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384494210 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1170" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1170/>Multilingual Factor Analysis</a></strong><br><a href=/people/f/francisco-vargas/>Francisco Vargas</a>
|
<a href=/people/k/kamen-brestnichki/>Kamen Brestnichki</a>
|
<a href=/people/a/alex-papadopoulos-korfiatis/>Alex Papadopoulos Korfiatis</a>
|
<a href=/people/n/nils-hammerla/>Nils Hammerla</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1170><div class="card-body p-3 small">In this work we approach the task of learning multilingual word representations in an offline manner by fitting a <a href=https://en.wikipedia.org/wiki/Generative_model>generative latent variable model</a> to a <a href=https://en.wikipedia.org/wiki/Multilingual_dictionary>multilingual dictionary</a>. We model equivalent words in different languages as different views of the same word generated by a common <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variable</a> representing their latent lexical meaning. We explore the task of alignment by querying the fitted <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> for multilingual embeddings achieving competitive results across a variety of tasks. The proposed model is robust to <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noise</a> in the embedding space making it a suitable method for <a href=https://en.wikipedia.org/wiki/Distributed_representation>distributed representations</a> learned from noisy corpora.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1173.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1173 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1173 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384512599 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1173/>Adversarial Multitask Learning for Joint Multi-Feature and Multi-Dialect Morphological Modeling</a></strong><br><a href=/people/n/nasser-zalmout/>Nasser Zalmout</a>
|
<a href=/people/n/nizar-habash/>Nizar Habash</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1173><div class="card-body p-3 small">Morphological tagging is challenging for morphologically rich languages due to the large target space and the need for more <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training data</a> to minimize model sparsity. Dialectal variants of morphologically rich languages suffer more as they tend to be more noisy and have less resources. In this paper we explore the use of <a href=https://en.wikipedia.org/wiki/Multitask_learning>multitask learning</a> and adversarial training to address morphological richness and dialectal variations in the context of full morphological tagging. We use <a href=https://en.wikipedia.org/wiki/Multitask_learning>multitask learning</a> for joint morphological modeling for the <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>features</a> within two dialects, and as a <a href=https://en.wikipedia.org/wiki/Knowledge_transfer>knowledge-transfer scheme</a> for cross-dialectal modeling. We use adversarial training to learn dialect invariant features that can help the knowledge-transfer scheme from the high to low-resource variants. We work with two dialectal variants : Modern Standard Arabic (high-resource dialect&#8217;) and Egyptian Arabic (low-resource dialect) as a case study. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> achieve state-of-the-art results for both. Furthermore, adversarial training provides more significant improvement when using smaller training datasets in particular.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1174.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1174 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1174 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384527233 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1174/>Neural Machine Translation with Reordering Embeddings</a></strong><br><a href=/people/k/kehai-chen/>Kehai Chen</a>
|
<a href=/people/r/rui-wang/>Rui Wang</a>
|
<a href=/people/m/masao-utiyama/>Masao Utiyama</a>
|
<a href=/people/e/eiichiro-sumita/>Eiichiro Sumita</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1174><div class="card-body p-3 small">The reordering model plays an important role in phrase-based statistical machine translation. However, there are few works that exploit the reordering information in <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a>. In this paper, we propose a reordering mechanism to learn the reordering embedding of a word based on its <a href=https://en.wikipedia.org/wiki/Context_(language_use)>contextual information</a>. These learned reordering embeddings are stacked together with self-attention networks to learn sentence representation for <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. The reordering mechanism can be easily integrated into both the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> and the <a href=https://en.wikipedia.org/wiki/Code>decoder</a> in the Transformer translation system. Experimental results on WMT&#8217;14 English-to-German, NIST Chinese-to-English, and WAT Japanese-to-English translation tasks demonstrate that the proposed methods can significantly improve the performance of the Transformer.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1175.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1175 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1175 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384527378 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1175/>Neural Fuzzy Repair : Integrating Fuzzy Matches into Neural Machine Translation</a></strong><br><a href=/people/b/bram-bulte/>Bram Bulte</a>
|
<a href=/people/a/arda-tezcan/>Arda Tezcan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1175><div class="card-body p-3 small">We present a simple yet powerful data augmentation method for boosting Neural Machine Translation (NMT) performance by leveraging information retrieved from a Translation Memory (TM). We propose and test two <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> for augmenting <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>NMT training data</a> with fuzzy TM matches. Tests on the DGT-TM data set for two language pairs show consistent and substantial improvements over a range of baseline systems. The results suggest that this method is promising for any translation environment in which a sizeable TM is available and a certain amount of <a href=https://en.wikipedia.org/wiki/Repetition_(rhetorical_device)>repetition</a> across translations is to be expected, especially considering its ease of implementation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1178.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1178 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1178 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384515284 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1178" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1178/>Self-Supervised Neural Machine Translation</a></strong><br><a href=/people/d/dana-ruiter/>Dana Ruiter</a>
|
<a href=/people/c/cristina-espana-bonet/>Cristina España-Bonet</a>
|
<a href=/people/j/josef-van-genabith/>Josef van Genabith</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1178><div class="card-body p-3 small">We present a simple new method where an emergent NMT system is used for simultaneously selecting training data and learning internal NMT representations. This is done in a self-supervised way without parallel data, in such a way that both tasks enhance each other during training. The method is language independent, introduces no additional hyper-parameters, and achieves BLEU scores of 29.21 (en2fr) and 27.36 (fr2en) on newstest2014 using English and French Wikipedia data for training.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1179.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1179 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1179 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384515395 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1179/>Exploring Phoneme-Level Speech Representations for End-to-End Speech Translation</a></strong><br><a href=/people/e/elizabeth-salesky/>Elizabeth Salesky</a>
|
<a href=/people/m/matthias-sperber/>Matthias Sperber</a>
|
<a href=/people/a/alan-w-black/>Alan W Black</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1179><div class="card-body p-3 small">Previous work on end-to-end translation from <a href=https://en.wikipedia.org/wiki/Speech>speech</a> has primarily used frame-level features as <a href=https://en.wikipedia.org/wiki/Speech>speech representations</a>, which creates longer, sparser sequences than <a href=https://en.wikipedia.org/wiki/Written_language>text</a>. We show that a naive method to create compressed phoneme-like speech representations is far more effective and efficient for <a href=https://en.wikipedia.org/wiki/Translation>translation</a> than traditional frame-level speech features. Specifically, we generate phoneme labels for speech frames and average consecutive frames with the same label to create shorter, higher-level source sequences for <a href=https://en.wikipedia.org/wiki/Translation>translation</a>. We see improvements of up to 5 <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a> on both our high and low resource language pairs, with a reduction in training time of 60 %. Our improvements hold across multiple data sizes and two language pairs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1181.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1181 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1181 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384518803 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1181/>Stay on the Path : Instruction Fidelity in Vision-and-Language Navigation</a></strong><br><a href=/people/v/vihan-jain/>Vihan Jain</a>
|
<a href=/people/g/gabriel-magalhaes/>Gabriel Magalhaes</a>
|
<a href=/people/a/alexander-ku/>Alexander Ku</a>
|
<a href=/people/a/ashish-vaswani/>Ashish Vaswani</a>
|
<a href=/people/e/eugene-ie/>Eugene Ie</a>
|
<a href=/people/j/jason-baldridge/>Jason Baldridge</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1181><div class="card-body p-3 small">Advances in learning and representations have reinvigorated work that connects <a href=https://en.wikipedia.org/wiki/Language>language</a> to other modalities. A particularly exciting direction is Vision-and-Language Navigation(VLN), in which agents interpret natural language instructions and visual scenes to move through environments and reach goals. Despite recent progress, current research leaves unclear how much of a role language under-standing plays in this task, especially because dominant evaluation metrics have focused on goal completion rather than the sequence of actions corresponding to the instructions. Here, we highlight shortcomings of current <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> for the Room-to-Room dataset (Anderson et al.,2018b) and propose a new <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a>, Coverage weighted by Length Score (CLS). We also show that the existing <a href=https://en.wikipedia.org/wiki/Path_(graph_theory)>paths</a> in the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> are not ideal for evaluating instruction following because they are direct-to-goal shortest paths. We join existing short paths to form more challenging extended paths to create a new <a href=https://en.wikipedia.org/wiki/Data_set>data set</a>, Room-for-Room (R4R). Using R4R and CLS, we show that <a href=https://en.wikipedia.org/wiki/Intelligent_agent>agents</a> that receive rewards for instruction fidelity outperform <a href=https://en.wikipedia.org/wiki/Intelligent_agent>agents</a> that focus on goal completion.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1182.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1182 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1182 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384520109 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1182" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1182/>Expressing Visual Relationships via Language</a></strong><br><a href=/people/h/hao-tan/>Hao Tan</a>
|
<a href=/people/f/franck-dernoncourt/>Franck Dernoncourt</a>
|
<a href=/people/z/zhe-lin/>Zhe Lin</a>
|
<a href=/people/t/trung-bui/>Trung Bui</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1182><div class="card-body p-3 small">Describing images with text is a fundamental problem in vision-language research. Current studies in this domain mostly focus on single image captioning. However, in various real applications (e.g., <a href=https://en.wikipedia.org/wiki/Image_editing>image editing</a>, difference interpretation, and retrieval), generating relational captions for two images, can also be very useful. This important <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> has not been explored mostly due to lack of datasets and effective <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. To push forward the research in this direction, we first introduce a new language-guided image editing dataset that contains a large number of real image pairs with corresponding editing instructions. We then propose a new relational speaker model based on an encoder-decoder architecture with static relational attention and sequential multi-head attention. We also extend the model with dynamic relational attention, which calculates visual alignment while decoding. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are evaluated on our newly collected and two public datasets consisting of image pairs annotated with relationship sentences. Experimental results, based on both automatic and human evaluation, demonstrate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms all baselines and existing methods on all the <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1189.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1189 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1189 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1189" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1189/>Reinforced Training Data Selection for Domain Adaptation</a></strong><br><a href=/people/m/miaofeng-liu/>Miaofeng Liu</a>
|
<a href=/people/y/yan-song/>Yan Song</a>
|
<a href=/people/h/hongbin-zou/>Hongbin Zou</a>
|
<a href=/people/t/tong-zhang/>Tong Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1189><div class="card-body p-3 small">Supervised models suffer from the problem of domain shifting where distribution mismatch in the data across domains greatly affect <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performance. To solve the problem, training data selection (TDS) has been proven to be a prospective solution for <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> in leveraging appropriate data. However, conventional TDS methods normally requires a predefined threshold which is neither easy to set nor can be applied across tasks, and models are trained separately with the TDS process. To make <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>TDS</a> self-adapted to data and task, and to combine it with model training, in this paper, we propose a reinforcement learning (RL) framework that synchronously searches for training instances relevant to the target domain and learns better representations for them. A selection distribution generator (SDG) is designed to perform the selection and is updated according to the rewards computed from the selected data, where a predictor is included in the framework to ensure a task-specific model can be trained on the selected data and provides feedback to rewards. Experimental results from <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a>, dependency parsing, and <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>, as well as <a href=https://en.wikipedia.org/wiki/Ablation>ablation studies</a>, illustrate that the proposed framework is not only effective in data selection and representation, but also generalized to accommodate different NLP tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1192.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1192 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1192 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1192" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1192/>Rhetorically Controlled Encoder-Decoder for Modern Chinese Poetry Generation<span class=acl-fixed-case>M</span>odern <span class=acl-fixed-case>C</span>hinese Poetry Generation</a></strong><br><a href=/people/z/zhiqiang-liu/>Zhiqiang Liu</a>
|
<a href=/people/z/zuohui-fu/>Zuohui Fu</a>
|
<a href=/people/j/jie-cao/>Jie Cao</a>
|
<a href=/people/g/gerard-de-melo/>Gerard de Melo</a>
|
<a href=/people/y/yik-cheung-tam/>Yik-Cheung Tam</a>
|
<a href=/people/c/cheng-niu/>Cheng Niu</a>
|
<a href=/people/j/jie-zhou/>Jie Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1192><div class="card-body p-3 small">Rhetoric is a vital element in modern <a href=https://en.wikipedia.org/wiki/Poetry>poetry</a>, and plays an essential role in improving its <a href=https://en.wikipedia.org/wiki/Aesthetics>aesthetics</a>. However, to date, it has not been considered in research on automatic poetry generation. In this paper, we propose a rhetorically controlled encoder-decoder for modern Chinese poetry generation. Our model relies on a <a href=https://en.wikipedia.org/wiki/Latent_variable_model>continuous latent variable</a> as a rhetoric controller to capture various rhetorical patterns in an <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a>, and then incorporates rhetoric-based mixtures while generating <a href=https://en.wikipedia.org/wiki/Modern_Chinese_poetry>modern Chinese poetry</a>. For metaphor and personification, an automated evaluation shows that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms state-of-the-art baselines by a substantial margin, while human evaluation shows that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> generates better poems than baseline methods in terms of fluency, coherence, meaningfulness, and rhetorical aesthetics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1196.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1196 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1196 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1196/>Ensuring Readability and Data-fidelity using Head-modifier Templates in Deep Type Description Generation</a></strong><br><a href=/people/j/jiangjie-chen/>Jiangjie Chen</a>
|
<a href=/people/a/ao-wang/>Ao Wang</a>
|
<a href=/people/h/haiyun-jiang/>Haiyun Jiang</a>
|
<a href=/people/s/suo-feng/>Suo Feng</a>
|
<a href=/people/c/chenguang-li/>Chenguang Li</a>
|
<a href=/people/y/yanghua-xiao/>Yanghua Xiao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1196><div class="card-body p-3 small">A <a href=https://en.wikipedia.org/wiki/Type_description>type description</a> is a succinct noun compound which helps human and machines to quickly grasp the informative and distinctive information of an entity. Entities in most knowledge graphs (KGs) still lack such descriptions, thus calling for automatic methods to supplement such information. However, existing <a href=https://en.wikipedia.org/wiki/Generative_grammar>generative methods</a> either overlook the <a href=https://en.wikipedia.org/wiki/Grammar>grammatical structure</a> or make factual mistakes in generated texts. To solve these problems, we propose a head-modifier template based method to ensure the readability and data fidelity of generated type descriptions. We also propose a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> and two <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. Experiments show that our method improves substantially compared with <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baselines</a> and achieves state-of-the-art performance on both <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1197.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1197 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1197 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1197" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1197/>Key Fact as Pivot : A Two-Stage Model for Low Resource Table-to-Text Generation</a></strong><br><a href=/people/s/shuming-ma/>Shuming Ma</a>
|
<a href=/people/p/pengcheng-yang/>Pengcheng Yang</a>
|
<a href=/people/t/tianyu-liu/>Tianyu Liu</a>
|
<a href=/people/p/peng-li/>Peng Li</a>
|
<a href=/people/j/jie-zhou/>Jie Zhou</a>
|
<a href=/people/x/xu-sun/>Xu Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1197><div class="card-body p-3 small">Table-to-text generation aims to translate the <a href=https://en.wikipedia.org/wiki/Data_structure>structured data</a> into the <a href=https://en.wikipedia.org/wiki/Unstructured_data>unstructured text</a>. Most existing methods adopt the encoder-decoder framework to learn the <a href=https://en.wikipedia.org/wiki/Transformation_(function)>transformation</a>, which requires large-scale training samples. However, the lack of large parallel data is a major practical problem for many domains. In this work, we consider the scenario of low resource table-to-text generation, where only limited parallel data is available. We propose a novel <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to separate the generation into two stages : key fact prediction and surface realization. It first predicts the key facts from the tables, and then generates the text with the key facts. The training of key fact prediction needs much fewer annotated data, while surface realization can be trained with pseudo parallel corpus. We evaluate our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on a biography generation dataset. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can achieve 27.34 BLEU score with only 1,000 <a href=https://en.wikipedia.org/wiki/Parallel_computing>parallel data</a>, while the baseline model only obtain the performance of 9.71 BLEU score.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1200.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1200 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1200 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1200.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1200/>Towards Generating Long and Coherent Text with Multi-Level Latent Variable Models</a></strong><br><a href=/people/d/dinghan-shen/>Dinghan Shen</a>
|
<a href=/people/a/asli-celikyilmaz/>Asli Celikyilmaz</a>
|
<a href=/people/y/yizhe-zhang/>Yizhe Zhang</a>
|
<a href=/people/l/liqun-chen/>Liqun Chen</a>
|
<a href=/people/x/xin-wang/>Xin Wang</a>
|
<a href=/people/j/jianfeng-gao/>Jianfeng Gao</a>
|
<a href=/people/l/lawrence-carin/>Lawrence Carin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1200><div class="card-body p-3 small">Variational autoencoders (VAEs) have received much attention recently as an end-to-end architecture for <a href=https://en.wikipedia.org/wiki/Text_generator>text generation</a> with <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variables</a>. However, previous works typically focus on synthesizing relatively short sentences (up to 20 words), and the posterior collapse issue has been widely identified in <a href=https://en.wikipedia.org/wiki/Text-based_user_interface>text-VAEs</a>. In this paper, we propose to leverage several multi-level structures to learn a VAE model for generating long, and coherent text. In particular, a hierarchy of stochastic layers between the encoder and decoder networks is employed to abstract more informative and semantic-rich latent codes. Besides, we utilize a multi-level decoder structure to capture the coherent long-term structure inherent in long-form texts, by generating intermediate sentence representations as high-level plan vectors. Extensive experimental results demonstrate that the proposed multi-level VAE model produces more coherent and less repetitive long text compared to baselines as well as can mitigate the posterior-collapse issue.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1205.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1205 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1205 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1205/>Improving Abstractive Document Summarization with Salient Information Modeling</a></strong><br><a href=/people/y/yongjian-you/>Yongjian You</a>
|
<a href=/people/w/weijia-jia/>Weijia Jia</a>
|
<a href=/people/t/tianyi-liu/>Tianyi Liu</a>
|
<a href=/people/w/wenmian-yang/>Wenmian Yang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1205><div class="card-body p-3 small">Comprehensive document encoding and salient information selection are two major difficulties for generating summaries with adequate salient information. To tackle the above difficulties, we propose a Transformer-based encoder-decoder framework with two novel extensions for abstractive document summarization. Specifically, (1) to encode the documents comprehensively, we design a focus-attention mechanism and incorporate it into the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a>. This mechanism models a Gaussian focal bias on attention scores to enhance the perception of local context, which contributes to producing salient and informative summaries. (2) To distinguish <a href=https://en.wikipedia.org/wiki/Salience_(neuroscience)>salient information</a> precisely, we design an independent saliency-selection network which manages the <a href=https://en.wikipedia.org/wiki/Information_flow>information flow</a> from <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> to <a href=https://en.wikipedia.org/wiki/Code>decoder</a>. This <a href=https://en.wikipedia.org/wiki/Social_network>network</a> effectively reduces the influences of secondary information on the generated summaries. Experimental results on the popular CNN / Daily Mail benchmark demonstrate that our model outperforms other state-of-the-art baselines on the ROUGE metrics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1206.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1206 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1206 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1206.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1206" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1206/>Unsupervised Neural Single-Document Summarization of Reviews via Learning Latent Discourse Structure and its Ranking</a></strong><br><a href=/people/m/masaru-isonuma/>Masaru Isonuma</a>
|
<a href=/people/j/junichiro-mori/>Junichiro Mori</a>
|
<a href=/people/i/ichiro-sakata/>Ichiro Sakata</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1206><div class="card-body p-3 small">This paper focuses on the end-to-end abstractive summarization of a single product review without supervision. We assume that a review can be described as a discourse tree, in which the summary is the root, and the child sentences explain their parent in detail. By recursively estimating a parent from its children, our model learns the latent discourse tree without an external parser and generates a concise summary. We also introduce an <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> that ranks the importance of each sentence on the <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>tree</a> to support summary generation focusing on the main review point. The experimental results demonstrate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is competitive with or outperforms other unsupervised approaches. In particular, for relatively long reviews, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> achieves a competitive or better performance than <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised models</a>. The induced tree shows that the child sentences provide additional information about their parent, and the generated summary abstracts the entire review.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1211.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1211 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1211 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1211/>Adversarial Domain Adaptation Using Artificial Titles for Abstractive Title Generation</a></strong><br><a href=/people/f/francine-chen/>Francine Chen</a>
|
<a href=/people/y/yan-ying-chen/>Yan-Ying Chen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1211><div class="card-body p-3 small">A common issue in training a deep learning, abstractive summarization model is lack of a large set of training summaries. This paper examines techniques for adapting from a labeled source domain to an unlabeled target domain in the context of an encoder-decoder model for text generation. In addition to adversarial domain adaptation (ADA), we introduce the use of artificial titles and sequential training to capture the grammatical style of the unlabeled target domain. Evaluation on adapting to / from news articles and Stack Exchange posts indicates that the use of these techniques can boost performance for both unsupervised adaptation as well as <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> with limited target data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1212.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1212 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1212 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1212/>BIGPATENT : A Large-Scale Dataset for Abstractive and Coherent Summarization<span class=acl-fixed-case>BIGPATENT</span>: A Large-Scale Dataset for Abstractive and Coherent Summarization</a></strong><br><a href=/people/e/eva-sharma/>Eva Sharma</a>
|
<a href=/people/c/chen-li/>Chen Li</a>
|
<a href=/people/l/lu-wang/>Lu Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1212><div class="card-body p-3 small">Most existing text summarization datasets are compiled from the <a href=https://en.wikipedia.org/wiki/News_media>news domain</a>, where summaries have a flattened discourse structure. In such <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, summary-worthy content often appears in the beginning of input articles. Moreover, large segments from input articles are present verbatim in their respective summaries. These issues impede the learning and evaluation of systems that can understand an article&#8217;s global content structure as well as produce abstractive summaries with high <a href=https://en.wikipedia.org/wiki/Compression_ratio>compression ratio</a>. In this work, we present a novel <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, BIGPATENT, consisting of 1.3 million records of <a href=https://en.wikipedia.org/wiki/United_States_patent_law>U.S. patent documents</a> along with <a href=https://en.wikipedia.org/wiki/Abstract_(summary)>human written abstractive summaries</a>. Compared to existing summarization datasets, BIGPATENT has the following properties : i) summaries contain a richer discourse structure with more recurring entities, ii) salient content is evenly distributed in the input, and iii) lesser and shorter extractive fragments are present in the summaries. Finally, we train and evaluate baselines and popular learning models on BIGPATENT to shed light on new challenges and motivate future directions for summarization research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1213.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1213 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1213 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1213/>Ranking Generated Summaries by Correctness : An Interesting but Challenging Application for Natural Language Inference</a></strong><br><a href=/people/t/tobias-falke/>Tobias Falke</a>
|
<a href=/people/l/leonardo-f-r-ribeiro/>Leonardo F. R. Ribeiro</a>
|
<a href=/people/p/prasetya-ajie-utama/>Prasetya Ajie Utama</a>
|
<a href=/people/i/ido-dagan/>Ido Dagan</a>
|
<a href=/people/i/iryna-gurevych/>Iryna Gurevych</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1213><div class="card-body p-3 small">While recent progress on abstractive summarization has led to remarkably fluent summaries, factual errors in generated summaries still severely limit their use in practice. In this paper, we evaluate summaries produced by state-of-the-art <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> via <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing</a> and show that such <a href=https://en.wikipedia.org/wiki/Errors-in-variables_models>errors</a> occur frequently, in particular with more abstractive models. We study whether textual entailment predictions can be used to detect such errors and if they can be reduced by reranking alternative predicted summaries. That leads to an interesting downstream application for <a href=https://en.wikipedia.org/wiki/Logical_consequence>entailment models</a>. In our experiments, we find that out-of-the-box entailment models trained on NLI datasets do not yet offer the desired performance for the downstream task and we therefore release our annotations as additional test data for future extrinsic evaluations of NLI.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1214.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1214 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1214 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1214" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1214/>Self-Supervised Learning for Contextualized Extractive Summarization</a></strong><br><a href=/people/h/hong-wang/>Hong Wang</a>
|
<a href=/people/x/xin-wang/>Xin Wang</a>
|
<a href=/people/w/wenhan-xiong/>Wenhan Xiong</a>
|
<a href=/people/m/mo-yu/>Mo Yu</a>
|
<a href=/people/x/xiaoxiao-guo/>Xiaoxiao Guo</a>
|
<a href=/people/s/shiyu-chang/>Shiyu Chang</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1214><div class="card-body p-3 small">Existing models for extractive summarization are usually trained from scratch with a cross-entropy loss, which does not explicitly capture the global context at the document level. In this paper, we aim to improve this task by introducing three auxiliary pre-training tasks that learn to capture the document-level context in a self-supervised fashion. Experiments on the widely-used CNN / DM dataset validate the effectiveness of the proposed auxiliary tasks. Furthermore, we show that after pre-training, a clean model with simple building blocks is able to outperform previous <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> that are carefully designed.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1215.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1215 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1215 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1215" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1215/>On the Summarization of Consumer Health Questions</a></strong><br><a href=/people/a/asma-ben-abacha/>Asma Ben Abacha</a>
|
<a href=/people/d/dina-demner-fushman/>Dina Demner-Fushman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1215><div class="card-body p-3 small">Question understanding is one of the main challenges in <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>. In real world applications, users often submit <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language questions</a> that are longer than needed and include peripheral information that increases the <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a> of the question, leading to substantially more false positives in answer retrieval. In this paper, we study neural abstractive models for medical question summarization. We introduce the MeQSum corpus of 1,000 summarized consumer health questions. We explore data augmentation methods and evaluate state-of-the-art neural abstractive models on this new task. In particular, we show that semantic augmentation from question datasets improves the overall performance, and that pointer-generator networks outperform sequence-to-sequence attentional models on this task, with a ROUGE-1 score of 44.16 %. We also present a detailed error analysis and discuss directions for improvement that are specific to question summarization.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1216.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1216 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1216 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1216.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1216/>Unsupervised Rewriter for Multi-Sentence Compression</a></strong><br><a href=/people/y/yang-zhao/>Yang Zhao</a>
|
<a href=/people/x/xiaoyu-shen/>Xiaoyu Shen</a>
|
<a href=/people/w/wei-bi/>Wei Bi</a>
|
<a href=/people/a/akiko-aizawa/>Akiko Aizawa</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1216><div class="card-body p-3 small">Multi-sentence compression (MSC) aims to generate a grammatical but reduced compression from multiple input sentences while retaining their key information. Previous dominating approach for <a href=https://en.wikipedia.org/wiki/Microsoft_SQL_Server>MSC</a> is the extraction-based word graph approach. A few variants further leveraged <a href=https://en.wikipedia.org/wiki/Lexical_substitution>lexical substitution</a> to yield more abstractive compression. However, two limitations exist. First, the word graph approach that simply concatenates fragments from multiple sentences may yield non-fluent or ungrammatical compression. Second, <a href=https://en.wikipedia.org/wiki/Lexical_substitution>lexical substitution</a> is often inappropriate without the consideration of <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context information</a>. To tackle the above-mentioned issues, we present a neural rewriter for multi-sentence compression that does not need any <a href=https://en.wikipedia.org/wiki/Parallel_text>parallel corpus</a>. Empirical studies have shown that our approach achieves comparable results upon automatic evaluation and improves the <a href=https://en.wikipedia.org/wiki/Grammaticality>grammaticality</a> of compression based on human evaluation. A <a href=https://en.wikipedia.org/wiki/Parallel_corpus>parallel corpus</a> with more than 140,000 (sentence group, compression) pairs is also constructed as a by-product for future research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1219.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1219 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1219 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1219/>Explicit Utilization of General Knowledge in Machine Reading Comprehension</a></strong><br><a href=/people/c/chao-wang/>Chao Wang</a>
|
<a href=/people/h/hui-jiang/>Hui Jiang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1219><div class="card-body p-3 small">To bridge the gap between Machine Reading Comprehension (MRC) models and human beings, which is mainly reflected in the hunger for data and the robustness to noise, in this paper, we explore how to integrate the neural networks of MRC models with the general knowledge of human beings. On the one hand, we propose a data enrichment method, which uses <a href=https://en.wikipedia.org/wiki/WordNet>WordNet</a> to extract inter-word semantic connections as <a href=https://en.wikipedia.org/wiki/General_knowledge>general knowledge</a> from each given passage-question pair. On the other hand, we propose an end-to-end MRC model named as Knowledge Aided Reader (KAR), which explicitly uses the above extracted <a href=https://en.wikipedia.org/wiki/General_knowledge>general knowledge</a> to assist its attention mechanisms. Based on the data enrichment method, KAR is comparable in performance with the state-of-the-art MRC models, and significantly more robust to <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noise</a> than them. When only a subset (20%-80 %) of the training examples are available, KAR outperforms the state-of-the-art MRC models by a large margin, and is still reasonably robust to <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noise</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1220.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1220 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1220 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1220.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1220/>Multi-style Generative Reading Comprehension</a></strong><br><a href=/people/k/kyosuke-nishida/>Kyosuke Nishida</a>
|
<a href=/people/i/itsumi-saito/>Itsumi Saito</a>
|
<a href=/people/k/kosuke-nishida/>Kosuke Nishida</a>
|
<a href=/people/k/kazutoshi-shinoda/>Kazutoshi Shinoda</a>
|
<a href=/people/a/atsushi-otsuka/>Atsushi Otsuka</a>
|
<a href=/people/h/hisako-asano/>Hisako Asano</a>
|
<a href=/people/j/junji-tomita/>Junji Tomita</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1220><div class="card-body p-3 small">This study tackles generative reading comprehension (RC), which consists of answering questions based on textual evidence and natural language generation (NLG). We propose a multi-style abstractive summarization model for <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>, called <a href=https://en.wikipedia.org/wiki/Masque>Masque</a>. The proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> has two key characteristics. First, unlike most studies on RC that have focused on extracting an answer span from the provided passages, our model instead focuses on generating a summary from the question and multiple passages. This serves to cover various answer styles required for real-world applications. Second, whereas previous studies built a specific <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> for each answer style because of the difficulty of acquiring one general model, our approach learns multi-style answers within a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to improve the NLG capability for all styles involved. This also enables our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> to give an answer in the target style. Experiments show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves state-of-the-art performance on the Q&A task and the Q&A + NLG task of MS MARCO 2.1 and the summary task of NarrativeQA. We observe that the transfer of the style-independent NLG capability to the target style is the key to its success.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1223.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1223 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1223 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1223.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1223" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1223/>E3 : Entailment-driven Extracting and Editing for Conversational Machine Reading<span class=acl-fixed-case>E</span>3: Entailment-driven Extracting and Editing for Conversational Machine Reading</a></strong><br><a href=/people/v/victor-zhong/>Victor Zhong</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1223><div class="card-body p-3 small">Conversational machine reading systems help users answer high-level questions (e.g. determine if they qualify for particular government benefits) when they do not know the exact <a href=https://en.wikipedia.org/wiki/Rule_of_inference>rules</a> by which the determination is made (e.g. whether they need certain <a href=https://en.wikipedia.org/wiki/Income_inequality_in_the_United_States>income levels</a> or veteran status). The key challenge is that these <a href=https://en.wikipedia.org/wiki/Rule_of_inference>rules</a> are only provided in the form of a procedural text (e.g. guidelines from government website) which the system must read to figure out what to ask the user. We present a new conversational machine reading model that jointly extracts a set of decision rules from the procedural text while reasoning about which are entailed by the conversational history and which still need to be edited to create questions for the user. On the recently introduced ShARC conversational machine reading dataset, our Entailment-driven Extract and Edit network (E3) achieves a new state-of-the-art, outperforming existing systems as well as a new BERT-based baseline. In addition, by explicitly highlighting which information still needs to be gathered, E3 provides a more explainable alternative to prior work. We release source code for our models and experiments at https://github.com/vzhong/e3.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1224.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1224 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1224 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1224.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1224.Note.pdf data-toggle=tooltip data-placement=top title=Note><i class="fas fa-file-alt"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1224" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1224/>Generating Question-Answer Hierarchies</a></strong><br><a href=/people/k/kalpesh-krishna/>Kalpesh Krishna</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1224><div class="card-body p-3 small">The process of <a href=https://en.wikipedia.org/wiki/Knowledge_acquisition>knowledge acquisition</a> can be viewed as a question-answer game between a student and a teacher in which the student typically starts by asking broad, open-ended questions before drilling down into specifics (Hintikka, 1981 ; Hakkarainen and Sintonen, 2002). This pedagogical perspective motivates a new way of representing documents. In this paper, we present SQUASH (Specificity-controlled Question-Answer Hierarchies), a novel and challenging text generation task that converts an input document into a hierarchy of question-answer pairs. Users can click on high-level questions (e.g., Why did Frodo leave the Fellowship?) to reveal related but more specific questions (e.g., Who did Frodo leave with?). Using a question taxonomy loosely based on Lehnert (1978), we classify questions in existing reading comprehension datasets as either GENERAL or SPECIFIC. We then use these labels as input to a <a href=https://en.wikipedia.org/wiki/Pipeline_(software)>pipelined system</a> centered around a conditional neural language model. We extensively evaluate the quality of the generated QA hierarchies through crowdsourced experiments and report strong empirical results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1226.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1226 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1226 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1226/>Enhancing Pre-Trained Language Representations with Rich Knowledge for Machine Reading Comprehension</a></strong><br><a href=/people/a/an-yang/>An Yang</a>
|
<a href=/people/q/quan-wang/>Quan Wang</a>
|
<a href=/people/j/jing-liu/>Jing Liu</a>
|
<a href=/people/k/kai-liu/>Kai Liu</a>
|
<a href=/people/y/yajuan-lyu/>Yajuan Lyu</a>
|
<a href=/people/h/hua-wu/>Hua Wu</a>
|
<a href=/people/q/qiaoqiao-she/>Qiaoqiao She</a>
|
<a href=/people/s/sujian-li/>Sujian Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1226><div class="card-body p-3 small">Machine reading comprehension (MRC) is a crucial and challenging task in <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP</a>. Recently, pre-trained language models (LMs), especially BERT, have achieved remarkable success, presenting new state-of-the-art results in <a href=https://en.wikipedia.org/wiki/Machine_learning>MRC</a>. In this work, we investigate the potential of leveraging external knowledge bases (KBs) to further improve BERT for <a href=https://en.wikipedia.org/wiki/Medical_record>MRC</a>. We introduce KT-NET, which employs an attention mechanism to adaptively select desired knowledge from KBs, and then fuses selected knowledge with BERT to enable context- and knowledge-aware predictions. We believe this would combine the merits of both deep LMs and curated KBs towards better MRC. Experimental results indicate that KT-NET offers significant and consistent improvements over BERT, outperforming competitive <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>baselines</a> on ReCoRD and SQuAD1.1 benchmarks. Notably, it ranks the 1st place on the ReCoRD leaderboard, and is also the best single <a href=https://en.wikipedia.org/wiki/Computer_model>model</a> on the SQuAD1.1 leaderboard at the time of submission (March 4th, 2019).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1229.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1229 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1229 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1229" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1229/>Semi-supervised Domain Adaptation for Dependency Parsing</a></strong><br><a href=/people/z/zhenghua-li/>Zhenghua Li</a>
|
<a href=/people/x/xue-peng/>Xue Peng</a>
|
<a href=/people/m/min-zhang/>Min Zhang</a>
|
<a href=/people/r/rui-wang/>Rui Wang</a>
|
<a href=/people/l/luo-si/>Luo Si</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1229><div class="card-body p-3 small">During the past decades, due to the lack of sufficient labeled data, most studies on cross-domain parsing focus on unsupervised domain adaptation, assuming there is no target-domain training data. However, <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised approaches</a> make limited progress so far due to the intrinsic difficulty of both <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> and <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a>. This paper tackles the semi-supervised domain adaptation problem for Chinese dependency parsing, based on two newly-annotated large-scale domain-aware datasets. We propose a simple domain embedding approach to merge the source- and target-domain training data, which is shown to be more effective than both direct corpus concatenation and <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a>. In order to utilize unlabeled target-domain data, we employ the recent contextualized word representations and show that a simple fine-tuning procedure can further boost cross-domain parsing accuracy by large margin.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1230.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1230 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1230 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1230.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1230" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1230/>Head-Driven Phrase Structure Grammar Parsing on <a href=https://en.wikipedia.org/wiki/Penn_Treebank>Penn Treebank</a><span class=acl-fixed-case>H</span>ead-<span class=acl-fixed-case>D</span>riven <span class=acl-fixed-case>P</span>hrase <span class=acl-fixed-case>S</span>tructure <span class=acl-fixed-case>G</span>rammar Parsing on <span class=acl-fixed-case>P</span>enn <span class=acl-fixed-case>T</span>reebank</a></strong><br><a href=/people/j/junru-zhou/>Junru Zhou</a>
|
<a href=/people/h/hai-zhao/>Hai Zhao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1230><div class="card-body p-3 small">Head-driven phrase structure grammar (HPSG) enjoys a uniform formalism representing rich contextual syntactic and even semantic meanings. This paper makes the first attempt to formulate a simplified <a href=https://en.wikipedia.org/wiki/Head-driven_phrase_structure_grammar>HPSG</a> by integrating constituent and dependency formal representations into <a href=https://en.wikipedia.org/wiki/Head-driven_phrase_structure_grammar>head-driven phrase structure</a>. Then two parsing algorithms are respectively proposed for two converted tree representations, division span and joint span. As HPSG encodes both constituent and dependency structure information, the proposed HPSG parsers may be regarded as a sort of joint decoder for both types of structures and thus are evaluated in terms of extracted or converted constituent and dependency parsing trees. Our <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> achieves new state-of-the-art performance for both parsing tasks on Penn Treebank (PTB) and Chinese Penn Treebank, verifying the effectiveness of joint learning constituent and dependency structures. In details, we report 95.84 F1 of <a href=https://en.wikipedia.org/wiki/Constituent_(linguistics)>constituent parsing</a> and 97.00 % UAS of dependency parsing on <a href=https://en.wikipedia.org/wiki/Partially_ordered_set>PTB</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1237.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1237 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1237 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1237" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1237/>Graph-based Dependency Parsing with Graph Neural Networks</a></strong><br><a href=/people/t/tao-ji/>Tao Ji</a>
|
<a href=/people/y/yuanbin-wu/>Yuanbin Wu</a>
|
<a href=/people/m/man-lan/>Man Lan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1237><div class="card-body p-3 small">We investigate the problem of efficiently incorporating <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>high-order features</a> into neural graph-based dependency parsing. Instead of explicitly extracting high-order features from intermediate parse trees, we develop a more powerful dependency tree node representation which captures high-order information concisely and efficiently. We use graph neural networks (GNNs) to learn the representations and discuss several new configurations of GNN&#8217;s updating and aggregation functions. Experiments on <a href=https://en.wikipedia.org/wiki/Parsing>PTB</a> show that our <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> achieves the best UAS and LAS on <a href=https://en.wikipedia.org/wiki/Parsing>PTB</a> (96.0 %, 94.3 %) among systems without using any external resources.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1240.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1240 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1240 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1240" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1240/>Topic-Aware Neural Keyphrase Generation for Social Media Language</a></strong><br><a href=/people/y/yue-wang/>Yue Wang</a>
|
<a href=/people/j/jing-li/>Jing Li</a>
|
<a href=/people/h/hou-pong-chan/>Hou Pong Chan</a>
|
<a href=/people/i/irwin-king/>Irwin King</a>
|
<a href=/people/m/michael-r-lyu/>Michael R. Lyu</a>
|
<a href=/people/s/shuming-shi/>Shuming Shi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1240><div class="card-body p-3 small">A huge volume of <a href=https://en.wikipedia.org/wiki/User-generated_content>user-generated content</a> is daily produced on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. To facilitate automatic language understanding, we study keyphrase prediction, distilling salient information from massive posts. While most existing methods extract words from source posts to form keyphrases, we propose a sequence-to-sequence (seq2seq) based neural keyphrase generation framework, enabling absent keyphrases to be created. Moreover, our model, being topic-aware, allows joint modeling of corpus-level latent topic representations, which helps alleviate data sparsity widely exhibited in social media language. Experiments on three datasets collected from English and Chinese social media platforms show that our model significantly outperforms both extraction and generation models without exploiting latent topics. Further discussions show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> learns meaningful topics, which interprets its superiority in social media keyphrase generation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1241.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1241 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1241 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1241" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1241/># YouToo? Detection of Personal Recollections of Sexual Harassment on <a href=https://en.wikipedia.org/wiki/Social_media>Social Media</a><span class=acl-fixed-case>Y</span>ou<span class=acl-fixed-case>T</span>oo? Detection of Personal Recollections of Sexual Harassment on Social Media</a></strong><br><a href=/people/a/arijit-ghosh-chowdhury/>Arijit Ghosh Chowdhury</a>
|
<a href=/people/r/ramit-sawhney/>Ramit Sawhney</a>
|
<a href=/people/r/rajiv-shah/>Rajiv Ratn Shah</a>
|
<a href=/people/d/debanjan-mahata/>Debanjan Mahata</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1241><div class="card-body p-3 small">The availability of large-scale online social data, coupled with computational methods can help us answer fundamental questions relat- ing to our social lives, particularly our health and well-being. The # MeToo trend has led to people talking about personal experiences of harassment more openly. This work at- tempts to aggregate such experiences of <a href=https://en.wikipedia.org/wiki/Sexual_abuse>sex- ual abuse</a> to facilitate a better understanding of <a href=https://en.wikipedia.org/wiki/Social_constructionism>social media constructs</a> and to bring about <a href=https://en.wikipedia.org/wiki/Social_change>social change</a>. It has been found that disclo- sure of abuse has positive psychological im- pacts. Hence, we contend that such informa- tion can leveraged to create better campaigns for <a href=https://en.wikipedia.org/wiki/Social_change>social change</a> by analyzing how users react to these stories and to obtain a better insight into the consequences of <a href=https://en.wikipedia.org/wiki/Sexual_abuse>sexual abuse</a>. We use a three part Twitter-Specific Social Media Lan- guage Model to segregate personal recollec- tions of sexual harassment from <a href=https://en.wikipedia.org/wiki/Twitter>Twitter posts</a>. An extensive comparison with state-of-the-art generic and specific models along with a de- tailed error analysis explores the merit of our proposed model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1244.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1244 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1244 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1244/>Sentence-Level Evidence Embedding for Claim Verification with Hierarchical Attention Networks</a></strong><br><a href=/people/j/jing-ma/>Jing Ma</a>
|
<a href=/people/w/wei-gao/>Wei Gao</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/k/kam-fai-wong/>Kam-Fai Wong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1244><div class="card-body p-3 small">Claim verification is generally a task of verifying the veracity of a given claim, which is critical to many downstream applications. It is cumbersome and inefficient for human fact-checkers to find consistent pieces of evidence, from which solid verdict could be inferred against the claim. In this paper, we propose a novel end-to-end hierarchical attention network focusing on learning to represent coherent evidence as well as their semantic relatedness with the claim. Our model consists of three main components : 1) A coherence-based attention layer embeds coherent evidence considering the claim and sentences from relevant articles ; 2) An entailment-based attention layer attends on sentences that can semantically infer the claim on top of the first attention ; and 3) An output layer predicts the verdict based on the embedded evidence. Experimental results on three public benchmark datasets show that our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms a set of state-of-the-art baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1246.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1246 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1246 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1246/>You Write like You Eat : Stylistic Variation as a Predictor of <a href=https://en.wikipedia.org/wiki/Social_stratification>Social Stratification</a></a></strong><br><a href=/people/a/angelo-basile/>Angelo Basile</a>
|
<a href=/people/a/albert-gatt/>Albert Gatt</a>
|
<a href=/people/m/malvina-nissim/>Malvina Nissim</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1246><div class="card-body p-3 small">Inspired by Labov&#8217;s seminal work on stylisticvariation as a function of <a href=https://en.wikipedia.org/wiki/Social_stratification>social stratification</a>, we develop and compare neural models thatpredict a person&#8217;s presumed socio-economicstatus, obtained through distant supervision, from their writing style on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. Thefocus of our work is on identifying the mostimportant stylistic parameters to predict <a href=https://en.wikipedia.org/wiki/Socioeconomic_status>socio-economic group</a>. In particular, we show theeffectiveness of morpho-syntactic features aspredictors of style, in contrast to lexical fea-tures, which are good predictors of topic</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1249.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1249 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1249 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1249" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1249/>Celebrity Profiling</a></strong><br><a href=/people/m/matti-wiegmann/>Matti Wiegmann</a>
|
<a href=/people/b/benno-stein/>Benno Stein</a>
|
<a href=/people/m/martin-potthast/>Martin Potthast</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1249><div class="card-body p-3 small">Celebrities are among the most prolific users of <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>, promoting their personas and rallying followers. This activity is closely tied to genuine writing samples, which makes them worthy research subjects in many respects, not least <a href=https://en.wikipedia.org/wiki/Profiling_(information_science)>profiling</a>. With this paper we introduce the Webis Celebrity Corpus 2019. For its construction the Twitter feeds of 71,706 verified accounts have been carefully linked with their respective Wikidata items, crawling both. After cleansing, the resulting profiles contain an average of 29,968 words per <a href=https://en.wikipedia.org/wiki/User_profile>profile</a> and up to 239 pieces of <a href=https://en.wikipedia.org/wiki/Personal_data>personal information</a>. A <a href=https://en.wikipedia.org/wiki/Cross-validation_(statistics)>cross-evaluation</a> that checked the correct association of Twitter account and Wikidata item revealed an <a href=https://en.wikipedia.org/wiki/Error_rate>error rate</a> of only 0.6 %, rendering the <a href=https://en.wikipedia.org/wiki/User_profile>profiles</a> highly reliable. Our <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> comprises a wide cross-section of local and global celebrities, forming a unique combination of <a href=https://en.wikipedia.org/wiki/Scale_(social_sciences)>scale</a>, profile comprehensiveness, and label reliability. We further establish the state of the art&#8217;s profiling performance by evaluating the winning approaches submitted to the PAN gender prediction tasks in a transfer learning experiment. They are only outperformed by our own deep learning approach, which we also use to exemplify celebrity occupation prediction for the first time.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1252.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1252 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1252 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1252.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1252" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1252/>Twitter Homophily : Network Based Prediction of User’s Occupation<span class=acl-fixed-case>T</span>witter Homophily: Network Based Prediction of User’s Occupation</a></strong><br><a href=/people/j/jiaqi-pan/>Jiaqi Pan</a>
|
<a href=/people/r/rishabh-bhardwaj/>Rishabh Bhardwaj</a>
|
<a href=/people/w/wei-lu/>Wei Lu</a>
|
<a href=/people/h/hai-leong-chieu/>Hai Leong Chieu</a>
|
<a href=/people/x/xinghao-pan/>Xinghao Pan</a>
|
<a href=/people/n/ni-yi-puay/>Ni Yi Puay</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1252><div class="card-body p-3 small">In this paper, we investigate the importance of <a href=https://en.wikipedia.org/wiki/Social_network>social network information</a> compared to <a href=https://en.wikipedia.org/wiki/Content_(media)>content information</a> in the prediction of a Twitter user&#8217;s occupational class. We show that the content information of a user&#8217;s tweets, the profile descriptions of a user&#8217;s follower / following community, and the user&#8217;s social network provide useful information for classifying a user&#8217;s occupational group. In our study, we extend an existing <a href=https://en.wikipedia.org/wiki/Data_set>data set</a> for this <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a>, and we achieve significantly better performance by using social network homophily that has not been fully exploited in previous work. In our analysis, we found that by using the graph convolutional network to exploit social homophily, we can achieve competitive performance on this <a href=https://en.wikipedia.org/wiki/Data_set>data set</a> with just a small fraction of the training data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1254.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1254 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1254 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384728593 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1254/>Strategies for Structuring Story Generation</a></strong><br><a href=/people/a/angela-fan/>Angela Fan</a>
|
<a href=/people/m/mike-lewis/>Mike Lewis</a>
|
<a href=/people/y/yann-dauphin/>Yann Dauphin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1254><div class="card-body p-3 small">Writers often rely on plans or sketches to write long stories, but most current <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> generate word by word from left to right. We explore coarse-to-fine models for creating <a href=https://en.wikipedia.org/wiki/Narrative>narrative texts</a> of several hundred words, and introduce new <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> which decompose stories by abstracting over actions and entities. The <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> first generates the predicate-argument structure of the text, where different mentions of the same entity are marked with placeholder tokens. It then generates a surface realization of the predicate-argument structure, and finally replaces the entity placeholders with context-sensitive names and references. Human judges prefer the stories from our models to a wide range of previous approaches to hierarchical text generation. Extensive analysis shows that our methods can help improve the diversity and coherence of events and entities in generated stories.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1255.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1255 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1255 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384728654 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1255/>Argument Generation with Retrieval, <a href=https://en.wikipedia.org/wiki/Planning>Planning</a>, and Realization</a></strong><br><a href=/people/x/xinyu-hua/>Xinyu Hua</a>
|
<a href=/people/z/zhe-hu/>Zhe Hu</a>
|
<a href=/people/l/lu-wang/>Lu Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1255><div class="card-body p-3 small">Automatic argument generation is an appealing but challenging <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. In this paper, we study the specific problem of counter-argument generation, and present a novel framework, CANDELA. It consists of a powerful retrieval system and a novel two-step generation model, where a text planning decoder first decides on the main talking points and a proper language style for each sentence, then a content realization decoder reflects the decisions and constructs an informative paragraph-level argument. Furthermore, our generation model is empowered by a retrieval system indexed with 12 million articles collected from <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a> and popular English news media, which provides access to high-quality content with diversity. Automatic evaluation on a large-scale dataset collected from <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a> shows that our model yields significantly higher BLEU, ROUGE, and METEOR scores than the state-of-the-art and non-trivial comparisons. Human evaluation further indicates that our system arguments are more appropriate for refutation and richer in content.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1256.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1256 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1256 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384728744 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1256/>A Simple Recipe towards Reducing Hallucination in Neural Surface Realisation</a></strong><br><a href=/people/f/feng-nie/>Feng Nie</a>
|
<a href=/people/j/jin-ge-yao/>Jin-Ge Yao</a>
|
<a href=/people/j/jinpeng-wang/>Jinpeng Wang</a>
|
<a href=/people/r/rong-pan/>Rong Pan</a>
|
<a href=/people/c/chin-yew-lin/>Chin-Yew Lin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1256><div class="card-body p-3 small">Recent neural language generation systems often hallucinate contents (i.e., producing irrelevant or contradicted facts), especially when trained on loosely corresponding pairs of the input structure and text. To mitigate this issue, we propose to integrate a language understanding module for data refinement with self-training iterations to effectively induce strong equivalence between the input data and the paired text. Experiments on the E2E challenge dataset show that our proposed framework can reduce more than 50 % relative unaligned noise from the original data-text pairs. A vanilla sequence-to-sequence neural NLG model trained on the refined data has improved on content correctness compared with the current state-of-the-art ensemble generator.<i>hallucinate</i> contents (i.e., producing irrelevant or contradicted facts), especially when trained on loosely corresponding pairs of the input structure and text. To mitigate this issue, we propose to integrate a language understanding module for data refinement with self-training iterations to effectively induce strong equivalence between the input data and the paired text. Experiments on the E2E challenge dataset show that our proposed framework can reduce more than 50% relative unaligned noise from the original data-text pairs. A vanilla sequence-to-sequence neural NLG model trained on the refined data has improved on content correctness compared with the current state-of-the-art ensemble generator.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1257.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1257 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1257 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384731731 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1257" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1257/>Cross-Modal Commentator : Automatic Machine Commenting Based on Cross-Modal Information</a></strong><br><a href=/people/p/pengcheng-yang/>Pengcheng Yang</a>
|
<a href=/people/z/zhihan-zhang/>Zhihan Zhang</a>
|
<a href=/people/f/fuli-luo/>Fuli Luo</a>
|
<a href=/people/l/lei-li/>Lei Li</a>
|
<a href=/people/c/chengyang-huang/>Chengyang Huang</a>
|
<a href=/people/x/xu-sun/>Xu Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1257><div class="card-body p-3 small">Automatic commenting of online articles can provide additional opinions and facts to the reader, which improves user experience and engagement on social media platforms. Previous work focuses on automatic commenting based solely on <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>textual content</a>. However, in real-scenarios, online articles usually contain multiple modal contents. For instance, graphic news contains plenty of images in addition to text. Contents other than text are also vital because they are not only more attractive to the reader but also may provide critical information. To remedy this, we propose a new task : cross-model automatic commenting (CMAC), which aims to make comments by integrating multiple modal contents. We construct a <a href=https://en.wikipedia.org/wiki/Data_set>large-scale dataset</a> for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> and explore several representative methods. Going a step further, an effective co-attention model is presented to capture the dependency between textual and visual information. Evaluation results show that our proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can achieve better performance than competitive <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1259.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1259 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1259 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384732092 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1259" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1259/>Cognitive Graph for Multi-Hop Reading Comprehension at Scale</a></strong><br><a href=/people/m/ming-ding/>Ming Ding</a>
|
<a href=/people/c/chang-zhou/>Chang Zhou</a>
|
<a href=/people/q/qibin-chen/>Qibin Chen</a>
|
<a href=/people/h/hongxia-yang/>Hongxia Yang</a>
|
<a href=/people/j/jie-tang/>Jie Tang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1259><div class="card-body p-3 small">We propose a new CogQA framework for multi-hop reading comprehension question answering in web-scale documents. Founded on the <a href=https://en.wikipedia.org/wiki/Dual_process_theory>dual process theory</a> in <a href=https://en.wikipedia.org/wiki/Cognitive_science>cognitive science</a>, the framework gradually builds a cognitive graph in an iterative process by coordinating an implicit extraction module (System 1) and an explicit reasoning module (System 2). While giving accurate answers, our <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> further provides explainable reasoning paths. Specifically, our implementation based on BERT and graph neural network efficiently handles millions of documents for multi-hop reasoning questions in the HotpotQA fullwiki dataset, achieving a winning joint F_1 score of 34.9 on the leaderboard, compared to 23.1 of the best competitor.<i>cognitive graph</i> in an iterative process by coordinating an implicit extraction module (System 1) and an explicit reasoning module (System 2). While giving accurate answers, our framework further provides explainable reasoning paths. Specifically, our implementation based on BERT and graph neural network efficiently handles millions of documents for multi-hop reasoning questions in the HotpotQA fullwiki dataset, achieving a winning joint <tex-math>F_1</tex-math> score of 34.9 on the leaderboard, compared to 23.1 of the best competitor.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1262.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1262 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1262 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384736016 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1262" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1262/>Avoiding Reasoning Shortcuts : Adversarial Evaluation, Training, and Model Development for Multi-Hop QA<span class=acl-fixed-case>QA</span></a></strong><br><a href=/people/y/yichen-jiang/>Yichen Jiang</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1262><div class="card-body p-3 small">Multi-hop question answering requires a <a href=https://en.wikipedia.org/wiki/Scientific_modelling>model</a> to connect multiple pieces of evidence scattered in a long context to answer the question. In this paper, we show that in the multi-hop HotpotQA (Yang et al., 2018) dataset, the examples often contain reasoning shortcuts through which models can directly locate the answer by word-matching the question with a sentence in the context. We demonstrate this issue by constructing adversarial documents that create contradicting answers to the shortcut but do not affect the validity of the original answer. The performance of strong baseline models drops significantly on our adversarial test, indicating that they are indeed exploiting the <a href=https://en.wikipedia.org/wiki/Shortcut_(computing)>shortcuts</a> rather than performing multi-hop reasoning. After adversarial training, the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a>&#8217;s performance improves but is still limited on the adversarial test. Hence, we use a <a href=https://en.wikipedia.org/wiki/Control_unit>control unit</a> that dynamically attends to the question at different reasoning hops to guide the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s multi-hop reasoning. We show that our 2-hop model trained on the regular data is more robust to the adversaries than the baseline. After adversarial training, it not only achieves significant improvements over its counterpart trained on regular data, but also outperforms the adversarially-trained baseline significantly. Finally, we sanity-check that these improvements are not obtained by exploiting potential new shortcuts in the adversarial data, but indeed due to robust multi-hop reasoning skills of the models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1263.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1263 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1263 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384736068 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1263" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1263/>Exploiting Explicit Paths for Multi-hop Reading Comprehension</a></strong><br><a href=/people/s/souvik-kundu/>Souvik Kundu</a>
|
<a href=/people/t/tushar-khot/>Tushar Khot</a>
|
<a href=/people/a/ashish-sabharwal/>Ashish Sabharwal</a>
|
<a href=/people/p/peter-clark/>Peter Clark</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1263><div class="card-body p-3 small">We propose a novel, path-based reasoning approach for the multi-hop reading comprehension task where a system needs to combine facts from multiple passages to answer a question. Although inspired by multi-hop reasoning over <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graphs</a>, our proposed approach operates directly over <a href=https://en.wikipedia.org/wiki/Unstructured_data>unstructured text</a>. It generates potential paths through passages and scores them without any direct path supervision. The proposed model, named PathNet, attempts to extract implicit relations from text through <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity pair representations</a>, and compose them to encode each path. To capture additional context, PathNet also composes the passage representations along each path to compute a passage-based representation. Unlike previous approaches, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is then able to explain its reasoning via these explicit paths through the passages. We show that our approach outperforms prior models on the multi-hop Wikihop dataset, and also can be generalized to apply to the OpenBookQA dataset, matching state-of-the-art performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1267.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1267 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1267 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><span class="align-middle mr-1" data-toggle=tooltip data-placement=bottom title="Outstanding Paper"><i class="fas fa-award"></i></span><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384738334 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1267" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1267/>We Need to Talk about Standard Splits</a></strong><br><a href=/people/k/kyle-gorman/>Kyle Gorman</a>
|
<a href=/people/s/steven-bedrick/>Steven Bedrick</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1267><div class="card-body p-3 small">It is standard practice in speech & language technology to rank systems according to their performance on a test set held out for evaluation. However, few researchers apply <a href=https://en.wikipedia.org/wiki/Statistical_hypothesis_testing>statistical tests</a> to determine whether differences in performance are likely to arise by chance, and few examine the stability of <a href=https://en.wikipedia.org/wiki/Ranking>system ranking</a> across multiple <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training-testing splits</a>. We conduct replication and reproduction experiments with nine <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech taggers</a> published between 2000 and 2018, each of which claimed state-of-the-art performance on a widely-used standard split. While we replicate results on the standard split, we fail to reliably reproduce some rankings when we repeat this analysis with randomly generated training-testing splits. We argue that randomly generated splits should be used in system evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1270.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1270 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1270 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384738763 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1270" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1270/>Joint Effects of Context and User History for Predicting Online Conversation Re-entries</a></strong><br><a href=/people/x/xingshan-zeng/>Xingshan Zeng</a>
|
<a href=/people/j/jing-li/>Jing Li</a>
|
<a href=/people/l/lu-wang/>Lu Wang</a>
|
<a href=/people/k/kam-fai-wong/>Kam-Fai Wong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1270><div class="card-body p-3 small">As the <a href=https://en.wikipedia.org/wiki/Online_and_offline>online world</a> continues its exponential growth, <a href=https://en.wikipedia.org/wiki/Interpersonal_communication>interpersonal communication</a> has come to play an increasingly central role in opinion formation and <a href=https://en.wikipedia.org/wiki/Social_change>change</a>. In order to help users better engage with each other online, we study a challenging problem of re-entry prediction foreseeing whether a user will come back to a conversation they once participated in. We hypothesize that both the context of the ongoing conversations and the users&#8217; previous chatting history will affect their continued interests in future engagement. Specifically, we propose a neural framework with three main layers, each modeling context, user history, and interactions between them, to explore how the conversation context and user chatting history jointly result in their re-entry behavior. We experiment with two <a href=https://en.wikipedia.org/wiki/Data_set>large-scale datasets</a> collected from <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> and <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a>. Results show that our proposed <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> with bi-attention achieves an F1 score of 61.1 on <a href=https://en.wikipedia.org/wiki/Twitter>Twitter conversations</a>, outperforming the state-of-the-art methods from previous work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1271.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1271 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1271 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384740828 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1271" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1271/>CONAN-COunter NArratives through Nichesourcing : a Multilingual Dataset of Responses to Fight Online Hate Speech<span class=acl-fixed-case>CONAN</span> - <span class=acl-fixed-case>CO</span>unter <span class=acl-fixed-case>NA</span>rratives through Nichesourcing: a Multilingual Dataset of Responses to Fight Online Hate Speech</a></strong><br><a href=/people/y/yi-ling-chung/>Yi-Ling Chung</a>
|
<a href=/people/e/elizaveta-kuzmenko/>Elizaveta Kuzmenko</a>
|
<a href=/people/s/serra-sinem-tekiroglu/>Serra Sinem Tekiroglu</a>
|
<a href=/people/m/marco-guerini/>Marco Guerini</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1271><div class="card-body p-3 small">Although there is an unprecedented effort to provide adequate responses in terms of laws and policies to hate content on <a href=https://en.wikipedia.org/wiki/Social_media>social media platforms</a>, dealing with hatred online is still a tough problem. Tackling <a href=https://en.wikipedia.org/wiki/Hate_speech>hate speech</a> in the standard way of content deletion or <a href=https://en.wikipedia.org/wiki/Suspension_(punishment)>user suspension</a> may be charged with <a href=https://en.wikipedia.org/wiki/Censorship>censorship</a> and overblocking. One alternate strategy, that has received little attention so far by the research community, is to actually oppose hate content with counter-narratives (i.e. informed textual responses). In this paper, we describe the creation of the first large-scale, multilingual, expert-based dataset of hate-speech / counter-narrative pairs. This dataset has been built with the effort of more than 100 operators from three different NGOs that applied their training and expertise to the task. Together with the collected data we also provide additional annotations about expert demographics, hate and response type, and data augmentation through <a href=https://en.wikipedia.org/wiki/Translation>translation</a> and <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrasing</a>. Finally, we provide initial experiments to assess the quality of our <a href=https://en.wikipedia.org/wiki/Data>data</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1275.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1275 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1275 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384744638 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1275/>Exploring Author Context for Detecting Intended vs Perceived Sarcasm</a></strong><br><a href=/people/s/silviu-oprea/>Silviu Oprea</a>
|
<a href=/people/w/walid-magdy/>Walid Magdy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1275><div class="card-body p-3 small">We investigate the impact of using author context on textual sarcasm detection. We define author context as the embedded representation of their historical posts on <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> and suggest neural models that extract these representations. We experiment with two tweet datasets, one labelled manually for <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a>, and the other via tag-based distant supervision. We achieve state-of-the-art performance on the second <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, but not on the one labelled manually, indicating a difference between <a href=https://en.wikipedia.org/wiki/Sarcasm>intended sarcasm</a>, captured by distant supervision, and <a href=https://en.wikipedia.org/wiki/Sarcasm>perceived sarcasm</a>, captured by manual labelling.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1276.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1276 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1276 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384744763 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1276" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1276/>Open Domain Event Extraction Using Neural Latent Variable Models</a></strong><br><a href=/people/x/xiao-liu/>Xiao Liu</a>
|
<a href=/people/h/he-yan-huang/>Heyan Huang</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1276><div class="card-body p-3 small">We consider open domain event extraction, the task of extracting unconstraint types of events from news clusters. A novel latent variable neural model is constructed, which is scalable to very large corpus. A <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> is collected and manually annotated, with task-specific evaluation metrics being designed. Results show that the proposed <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised model</a> gives better performance compared to the state-of-the-art method for event schema induction.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1277.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1277 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1277 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384744882 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1277" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1277/>Multi-Level Matching and Aggregation Network for Few-Shot Relation Classification</a></strong><br><a href=/people/z/zhi-xiu-ye/>Zhi-Xiu Ye</a>
|
<a href=/people/z/zhen-hua-ling/>Zhen-Hua Ling</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1277><div class="card-body p-3 small">This paper presents a multi-level matching and aggregation network (MLMAN) for few-shot relation classification. Previous studies on this topic adopt prototypical networks, which calculate the embedding vector of a query instance and the prototype vector of the support set for each relation candidate independently. On the contrary, our proposed MLMAN model encodes the query instance and each support set in an interactive way by considering their matching information at both local and instance levels. The final class prototype for each support set is obtained by attentive aggregation over the representations of support instances, where the weights are calculated using the query instance. Experimental results demonstrate the effectiveness of our proposed methods, which achieve a new state-of-the-art performance on the FewRel dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1281.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1281 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1281 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384794970 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1281" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1281/>FIESTA : Fast IdEntification of State-of-The-Art models using adaptive bandit algorithms<span class=acl-fixed-case>FIESTA</span>: Fast <span class=acl-fixed-case>I</span>d<span class=acl-fixed-case>E</span>ntification of State-of-The-Art models using adaptive bandit algorithms</a></strong><br><a href=/people/h/henry-moss/>Henry Moss</a>
|
<a href=/people/a/andrew-moore/>Andrew Moore</a>
|
<a href=/people/d/david-leslie/>David Leslie</a>
|
<a href=/people/p/paul-rayson/>Paul Rayson</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1281><div class="card-body p-3 small">We present FIESTA, a model selection approach that significantly reduces the computational resources required to reliably identify state-of-the-art performance from large collections of candidate models. Despite being known to produce unreliable comparisons, it is still common practice to compare model evaluations based on single choices of <a href=https://en.wikipedia.org/wiki/Random_seed>random seeds</a>. We show that reliable <a href=https://en.wikipedia.org/wiki/Model_selection>model selection</a> also requires evaluations based on multiple train-test splits (contrary to common practice in many shared tasks). Using bandit theory from the statistics literature, we are able to adaptively determine appropriate numbers of data splits and random seeds used to evaluate each <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>, focusing computational resources on the evaluation of promising <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> whilst avoiding wasting evaluations on models with lower performance. Furthermore, our user-friendly Python implementation produces <a href=https://en.wikipedia.org/wiki/Confidence_interval>confidence guarantees</a> of correctly selecting the optimal model. We evaluate our algorithms by selecting between 8 target-dependent sentiment analysis methods using dramatically fewer model evaluations than current model selection approaches.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1286.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1286 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1286 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1286.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1286/>Domain Adaptation of Neural Machine Translation by Lexicon Induction</a></strong><br><a href=/people/j/junjie-hu/>Junjie Hu</a>
|
<a href=/people/m/mengzhou-xia/>Mengzhou Xia</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/j/jaime-g-carbonell/>Jaime Carbonell</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1286><div class="card-body p-3 small">It has been previously noted that neural machine translation (NMT) is very sensitive to domain shift. In this paper, we argue that this is a dual effect of the highly lexicalized nature of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NMT</a>, resulting in failure for sentences with large numbers of unknown words, and lack of supervision for domain-specific words. To remedy this problem, we propose an unsupervised adaptation method which fine-tunes a pre-trained out-of-domain NMT model using a pseudo-in-domain corpus. Specifically, we perform lexicon induction to extract an in-domain lexicon, and construct a pseudo-parallel in-domain corpus by performing word-for-word back-translation of monolingual in-domain target sentences. In five domains over twenty pairwise adaptation settings and two model architectures, our method achieves consistent improvements without using any in-domain parallel sentences, improving up to 14 BLEU over unadapted models, and up to 2 BLEU over strong back-translation baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1287.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1287 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1287 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1287/>Reference Network for Neural Machine Translation</a></strong><br><a href=/people/h/han-fu/>Han Fu</a>
|
<a href=/people/c/chenghao-liu/>Chenghao Liu</a>
|
<a href=/people/j/jianling-sun/>Jianling Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1287><div class="card-body p-3 small">Neural Machine Translation (NMT) has achieved notable success in recent years. Such a <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> usually generates <a href=https://en.wikipedia.org/wiki/Translation>translations</a> in isolation. In contrast, <a href=https://en.wikipedia.org/wiki/Translation>human translators</a> often refer to <a href=https://en.wikipedia.org/wiki/Reference_data>reference data</a>, either rephrasing the intricate sentence fragments with common terms in source language, or just accessing to the golden translation directly. In this paper, we propose a Reference Network to incorporate referring process into translation decoding of NMT. To construct a <a href=https://en.wikipedia.org/wiki/Reference_work>reference book</a>, an intuitive way is to store the detailed translation history with extra <a href=https://en.wikipedia.org/wiki/Computer_memory>memory</a>, which is computationally expensive. Instead, we employ Local Coordinates Coding (LCC) to obtain global context vectors containing monolingual and bilingual contextual information for NMT decoding. Experimental results on Chinese-English and English-German tasks demonstrate that our proposed model is effective in improving the translation quality with lightweight computation cost.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1290.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1290 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1290 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1290/>Look Harder : A Neural Machine Translation Model with Hard Attention</a></strong><br><a href=/people/s/sathish-reddy-indurthi/>Sathish Reddy Indurthi</a>
|
<a href=/people/i/insoo-chung/>Insoo Chung</a>
|
<a href=/people/s/sangha-kim/>Sangha Kim</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1290><div class="card-body p-3 small">Soft-attention based Neural Machine Translation (NMT) models have achieved promising results on several translation tasks. These models attend all the words in the source sequence for each target token, which makes them ineffective for long sequence translation. In this work, we propose a hard-attention based NMT model which selects a subset of source tokens for each target token to effectively handle long sequence translation. Due to the discrete nature of the hard-attention mechanism, we design a <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning algorithm</a> coupled with reward shaping strategy to efficiently train it. Experimental results show that the proposed model performs better on long sequences and thereby achieves significant BLEU score improvement on English-German (EN-DE) and English-French (ENFR) translation tasks compared to the soft attention based NMT.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1292.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1292 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1292 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1292" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1292/>A Simple and Effective Approach to Automatic Post-Editing with <a href=https://en.wikipedia.org/wiki/Transfer_learning>Transfer Learning</a></a></strong><br><a href=/people/g/goncalo-m-correia/>Gonçalo M. Correia</a>
|
<a href=/people/a/andre-f-t-martins/>André F. T. Martins</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1292><div class="card-body p-3 small">Automatic post-editing (APE) seeks to automatically refine the output of a black-box machine translation (MT) system through human post-edits. APE systems are usually trained by complementing human post-edited data with large, artificial data generated through back-translations, a time-consuming process often no easier than training a MT system from scratch. in this paper, we propose an alternative where we fine-tune pre-trained BERT models on both the encoder and decoder of an APE system, exploring several parameter sharing strategies. By only training on a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of 23 K sentences for 3 hours on a single GPU we obtain results that are competitive with <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>systems</a> that were trained on 5 M artificial sentences. When we add this <a href=https://en.wikipedia.org/wiki/Data_(computing)>artificial data</a> our <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> obtains state-of-the-art results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1294.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1294 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1294 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1294" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1294/>Training Neural Machine Translation to Apply Terminology Constraints</a></strong><br><a href=/people/g/georgiana-dinu/>Georgiana Dinu</a>
|
<a href=/people/p/prashant-mathur/>Prashant Mathur</a>
|
<a href=/people/m/marcello-federico/>Marcello Federico</a>
|
<a href=/people/y/yaser-al-onaizan/>Yaser Al-Onaizan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1294><div class="card-body p-3 small">This paper proposes a novel method to inject custom terminology into <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a> at run time. Previous works have mainly proposed modifications to the decoding algorithm in order to constrain the output to include run-time-provided target terms. While being effective, these constrained decoding methods add, however, significant <a href=https://en.wikipedia.org/wiki/Overhead_(computing)>computational overhead</a> to the inference step, and, as we show in this paper, can be brittle when tested in realistic conditions. In this paper we approach the problem by training a neural MT system to learn how to use custom terminology when provided with the input. Comparative experiments show that our method is not only more effective than a state-of-the-art implementation of constrained decoding, but is also as fast as constraint-free decoding.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1295.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1295 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1295 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1295" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1295/>Leveraging Local and Global Patterns for Self-Attention Networks</a></strong><br><a href=/people/m/mingzhou-xu/>Mingzhou Xu</a>
|
<a href=/people/d/derek-f-wong/>Derek F. Wong</a>
|
<a href=/people/b/baosong-yang/>Baosong Yang</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a>
|
<a href=/people/l/lidia-s-chao/>Lidia S. Chao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1295><div class="card-body p-3 small">Self-attention networks have received increasing research attention. By default, the hidden states of each word are hierarchically calculated by attending to all words in the sentence, which assembles global information. However, several studies pointed out that taking all signals into account may lead to overlooking <a href=https://en.wikipedia.org/wiki/Entropy_(information_theory)>neighboring information</a> (e.g. phrase pattern). To address this argument, we propose a hybrid attention mechanism to dynamically leverage both of the local and global information. Specifically, our approach uses a gating scalar for integrating both sources of the information, which is also convenient for quantifying their contributions. Experiments on various neural machine translation tasks demonstrate the effectiveness of the proposed method. The extensive analyses verify that the two types of contexts are complementary to each other, and our method gives highly effective improvements in their integration.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1296.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1296 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1296 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1296/>Sentence-Level Agreement for Neural Machine Translation</a></strong><br><a href=/people/m/mingming-yang/>Mingming Yang</a>
|
<a href=/people/r/rui-wang/>Rui Wang</a>
|
<a href=/people/k/kehai-chen/>Kehai Chen</a>
|
<a href=/people/m/masao-utiyama/>Masao Utiyama</a>
|
<a href=/people/e/eiichiro-sumita/>Eiichiro Sumita</a>
|
<a href=/people/m/min-zhang/>Min Zhang</a>
|
<a href=/people/t/tiejun-zhao/>Tiejun Zhao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1296><div class="card-body p-3 small">The training objective of neural machine translation (NMT) is to minimize the loss between the words in the translated sentences and those in the references. In NMT, there is a natural correspondence between the source sentence and the target sentence. However, this relationship has only been represented using the entire <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> and the <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training objective</a> is computed in word-level. In this paper, we propose a sentence-level agreement module to directly minimize the difference between the representation of source and target sentence. The proposed agreement module can be integrated into NMT as an additional training objective function and can also be used to enhance the representation of the source sentences. Empirical results on the NIST Chinese-to-English and WMT English-to-German tasks show the proposed agreement module can significantly improve the NMT performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1297.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1297 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1297 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1297/>Multilingual Unsupervised NMT using Shared Encoder and Language-Specific Decoders<span class=acl-fixed-case>NMT</span> using Shared Encoder and Language-Specific Decoders</a></strong><br><a href=/people/s/sukanta-sen/>Sukanta Sen</a>
|
<a href=/people/k/kamal-kumar-gupta/>Kamal Kumar Gupta</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1297><div class="card-body p-3 small">In this paper, we propose a multilingual unsupervised NMT scheme which jointly trains multiple languages with a shared encoder and multiple decoders. Our approach is based on denoising autoencoding of each language and back-translating between English and multiple non-English languages. This results in a universal encoder which can encode any language participating in training into an inter-lingual representation, and language-specific decoders. Our experiments using only monolingual corpora show that multilingual unsupervised model performs better than the separately trained bilingual models achieving improvement of up to 1.48 BLEU points on WMT test sets. We also observe that even if we do not train the <a href=https://en.wikipedia.org/wiki/Computer_network>network</a> for all possible translation directions, the <a href=https://en.wikipedia.org/wiki/Computer_network>network</a> is still able to translate in a many-to-many fashion leveraging encoder&#8217;s ability to generate interlingual representation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1301.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1301 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1301 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1301" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1301/>Choosing <a href=https://en.wikipedia.org/wiki/Language_transfer>Transfer Languages</a> for Cross-Lingual Learning</a></strong><br><a href=/people/y/yu-hsiang-lin/>Yu-Hsiang Lin</a>
|
<a href=/people/c/chian-yu-chen/>Chian-Yu Chen</a>
|
<a href=/people/j/jean-lee/>Jean Lee</a>
|
<a href=/people/z/zirui-li/>Zirui Li</a>
|
<a href=/people/y/yuyan-zhang/>Yuyan Zhang</a>
|
<a href=/people/m/mengzhou-xia/>Mengzhou Xia</a>
|
<a href=/people/s/shruti-rijhwani/>Shruti Rijhwani</a>
|
<a href=/people/j/junxian-he/>Junxian He</a>
|
<a href=/people/z/zhisong-zhang/>Zhisong Zhang</a>
|
<a href=/people/x/xuezhe-ma/>Xuezhe Ma</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a>
|
<a href=/people/p/patrick-littell/>Patrick Littell</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1301><div class="card-body p-3 small">Cross-lingual transfer, where a high-resource transfer language is used to improve the accuracy of a low-resource task language, is now an invaluable tool for improving performance of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP)</a> on low-resource languages. However, given a particular task language, it is not clear which language to transfer from, and the standard strategy is to select languages based on ad hoc criteria, usually the intuition of the experimenter. Since a large number of features contribute to the success of cross-lingual transfer (including <a href=https://en.wikipedia.org/wiki/Phylogenetic_tree>phylogenetic similarity</a>, <a href=https://en.wikipedia.org/wiki/Linguistic_typology>typological properties</a>, lexical overlap, or size of available data), even the most enlightened experimenter rarely considers all these factors for the particular task at hand. In this paper, we consider this task of automatically selecting optimal transfer languages as a ranking problem, and build <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that consider the aforementioned <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> to perform this prediction. In experiments on representative NLP tasks, we demonstrate that our model predicts good transfer languages much better than ad hoc baselines considering single features in isolation, and glean insights on what <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> are most informative for each different NLP tasks, which may inform future ad hoc selection even without use of our method.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1302.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1302 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1302 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1302.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1302" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1302/>CogNet : A Large-Scale Cognate Database<span class=acl-fixed-case>C</span>og<span class=acl-fixed-case>N</span>et: A Large-Scale Cognate Database</a></strong><br><a href=/people/k/khuyagbaatar-batsuren/>Khuyagbaatar Batsuren</a>
|
<a href=/people/g/gabor-bella/>Gabor Bella</a>
|
<a href=/people/f/fausto-giunchiglia/>Fausto Giunchiglia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1302><div class="card-body p-3 small">This paper introduces CogNet, a new, large-scale lexical database that provides cognates -words of common origin and meaning- across languages. The <a href=https://en.wikipedia.org/wiki/Database>database</a> currently contains 3.1 million <a href=https://en.wikipedia.org/wiki/Cognate>cognate pairs</a> across 338 languages using 35 <a href=https://en.wikipedia.org/wiki/Writing_system>writing systems</a>. The paper also describes the automated method by which <a href=https://en.wikipedia.org/wiki/Cognate>cognates</a> were computed from publicly available <a href=https://en.wikipedia.org/wiki/Wordnet>wordnets</a>, with an <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> evaluated to 94 %. Finally, it presents statistics about the cognate data and some initial insights into it, hinting at a possible future exploitation of the <a href=https://en.wikipedia.org/wiki/Resource>resource</a> by various fields of <a href=https://en.wikipedia.org/wiki/Lingustics>lingustics</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1303.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1303 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1303 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1303" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1303/>Neural Decipherment via Minimum-Cost Flow : From Ugaritic to Linear B<span class=acl-fixed-case>U</span>garitic to <span class=acl-fixed-case>L</span>inear <span class=acl-fixed-case>B</span></a></strong><br><a href=/people/j/jiaming-luo/>Jiaming Luo</a>
|
<a href=/people/y/yuan-cao/>Yuan Cao</a>
|
<a href=/people/r/regina-barzilay/>Regina Barzilay</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1303><div class="card-body p-3 small">In this paper we propose a novel neural approach for automatic decipherment of lost languages. To compensate for the lack of strong supervision signal, our model design is informed by patterns in language change documented in <a href=https://en.wikipedia.org/wiki/Historical_linguistics>historical linguistics</a>. The <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> utilizes an expressive sequence-to-sequence model to capture character-level correspondences between cognates. To effectively train the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> in unsupervised manner, we innovate the <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training procedure</a> by formalizing it as a minimum-cost flow problem. When applied to decipherment of Ugaritic, we achieve 5 % absolute improvement over state-of-the-art results. We also report first automatic results in deciphering Linear B, a <a href=https://en.wikipedia.org/wiki/Syllabary>syllabic language</a> related to <a href=https://en.wikipedia.org/wiki/Ancient_Greek>ancient Greek</a>, where our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> correctly translates 67.3 % of <a href=https://en.wikipedia.org/wiki/Cognate>cognates</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1306.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1306 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1306 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1306/>Improving Low-Resource Cross-lingual Document Retrieval by Reranking with Deep Bilingual Representations</a></strong><br><a href=/people/r/rui-zhang/>Rui Zhang</a>
|
<a href=/people/c/caitlin-westerfield/>Caitlin Westerfield</a>
|
<a href=/people/s/sungrok-shim/>Sungrok Shim</a>
|
<a href=/people/g/garrett-bingham/>Garrett Bingham</a>
|
<a href=/people/a/alexander-richard-fabbri/>Alexander Fabbri</a>
|
<a href=/people/w/william-hu/>William Hu</a>
|
<a href=/people/n/neha-verma/>Neha Verma</a>
|
<a href=/people/d/dragomir-radev/>Dragomir Radev</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1306><div class="card-body p-3 small">In this paper, we propose to boost low-resource cross-lingual document retrieval performance with deep bilingual query-document representations. We match queries and documents in both source and target languages with four components, each of which is implemented as a term interaction-based deep neural network with cross-lingual word embeddings as input. By including query likelihood scores as extra <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a>, our model effectively learns to rerank the retrieved documents by using a small number of relevance labels for low-resource language pairs. Due to the shared cross-lingual word embedding space, the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> can also be directly applied to another language pair without any <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training label</a>. Experimental results on the Material dataset show that our model outperforms the competitive translation-based baselines on English-Swahili, English-Tagalog, and English-Somali cross-lingual information retrieval tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1307.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1307 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1307 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1307/>Are Girls Neko or Shjo? Cross-Lingual Alignment of Non-Isomorphic Embeddings with Iterative Normalization</a></strong><br><a href=/people/m/mozhi-zhang/>Mozhi Zhang</a>
|
<a href=/people/k/keyulu-xu/>Keyulu Xu</a>
|
<a href=/people/k/ken-ichi-kawarabayashi/>Ken-ichi Kawarabayashi</a>
|
<a href=/people/s/stefanie-jegelka/>Stefanie Jegelka</a>
|
<a href=/people/j/jordan-boyd-graber/>Jordan Boyd-Graber</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1307><div class="card-body p-3 small">Cross-lingual word embeddings (CLWE) underlie many multilingual natural language processing systems, often through orthogonal transformations of pre-trained monolingual embeddings. However, orthogonal mapping only works on language pairs whose embeddings are naturally isomorphic. For non-isomorphic pairs, our method (Iterative Normalization) transforms monolingual embeddings to make orthogonal alignment easier by simultaneously enforcing that (1) individual word vectors are unit length, and (2) each language&#8217;s average vector is zero. Iterative Normalization consistently improves word translation accuracy of three CLWE methods, with the largest improvement observed on English-Japanese (from 2 % to 44 % test accuracy).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1311.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1311 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1311 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1311" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1311/>Cross-Lingual Syntactic Transfer through Unsupervised Adaptation of Invertible Projections</a></strong><br><a href=/people/j/junxian-he/>Junxian He</a>
|
<a href=/people/z/zhisong-zhang/>Zhisong Zhang</a>
|
<a href=/people/t/taylor-berg-kirkpatrick/>Taylor Berg-Kirkpatrick</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1311><div class="card-body p-3 small">Cross-lingual transfer is an effective way to build syntactic analysis tools in low-resource languages. However, transfer is difficult when transferring to typologically distant languages, especially when neither annotated target data nor <a href=https://en.wikipedia.org/wiki/Parallel_text>parallel corpora</a> are available. In this paper, we focus on methods for cross-lingual transfer to distant languages and propose to learn a <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a> with a structured prior that utilizes labeled source data and unlabeled target data jointly. The parameters of <a href=https://en.wikipedia.org/wiki/Statistical_model>source model</a> and <a href=https://en.wikipedia.org/wiki/Statistical_model>target model</a> are softly shared through a regularized log likelihood objective. An invertible projection is employed to learn a new interlingual latent embedding space that compensates for imperfect cross-lingual word embedding input. We evaluate our method on two syntactic tasks : part-of-speech (POS) tagging and dependency parsing. On the Universal Dependency Treebanks, we use <a href=https://en.wikipedia.org/wiki/English_language>English</a> as the only source corpus and transfer to a wide range of target languages. On the 10 languages in this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> that are distant from <a href=https://en.wikipedia.org/wiki/English_language>English</a>, our <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> yields an average of 5.2 % absolute improvement on <a href=https://en.wikipedia.org/wiki/Tag_(metadata)>POS tagging</a> and 8.3 % absolute improvement on dependency parsing over a direct transfer method using state-of-the-art <a href=https://en.wikipedia.org/wiki/Discriminative_model>discriminative models</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1312.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1312 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1312 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1312/>Unsupervised Joint Training of Bilingual Word Embeddings</a></strong><br><a href=/people/b/benjamin-marie/>Benjamin Marie</a>
|
<a href=/people/a/atsushi-fujita/>Atsushi Fujita</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1312><div class="card-body p-3 small">State-of-the-art methods for unsupervised bilingual word embeddings (BWE) train a <a href=https://en.wikipedia.org/wiki/Function_(mathematics)>mapping function</a> that maps pre-trained monolingual word embeddings into a bilingual space. Despite its remarkable results, unsupervised mapping is also well-known to be limited by the original dissimilarity between the word embedding spaces to be mapped. In this work, we propose a new approach that trains unsupervised BWE jointly on synthetic parallel data generated through unsupervised machine translation. We demonstrate that existing algorithms that jointly train BWE are very robust to noisy training data and show that unsupervised BWE jointly trained significantly outperform unsupervised mapped BWE in several cross-lingual NLP tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1314.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1314 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1314 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1314/>Is <a href=https://en.wikipedia.org/wiki/Word_segmentation>Word Segmentation</a> Necessary for Deep Learning of Chinese Representations?<span class=acl-fixed-case>C</span>hinese Representations?</a></strong><br><a href=/people/x/xiaoya-li/>Xiaoya Li</a>
|
<a href=/people/y/yuxian-meng/>Yuxian Meng</a>
|
<a href=/people/x/xiaofei-sun/>Xiaofei Sun</a>
|
<a href=/people/q/qinghong-han/>Qinghong Han</a>
|
<a href=/people/a/arianna-yuan/>Arianna Yuan</a>
|
<a href=/people/j/jiwei-li/>Jiwei Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1314><div class="card-body p-3 small">Segmenting a chunk of text into words is usually the first step of processing <a href=https://en.wikipedia.org/wiki/Written_Chinese>Chinese text</a>, but its necessity has rarely been explored. In this paper, we ask the fundamental question of whether Chinese word segmentation (CWS) is necessary for deep learning-based Chinese Natural Language Processing. We benchmark neural word-based models which rely on <a href=https://en.wikipedia.org/wiki/Word_segmentation>word segmentation</a> against neural char-based models which do not involve <a href=https://en.wikipedia.org/wiki/Word_segmentation>word segmentation</a> in four end-to-end NLP benchmark tasks : language modeling, <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, sentence matching / paraphrase and text classification. Through direct comparisons between these two types of <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>, we find that char-based models consistently outperform word-based models. Based on these observations, we conduct comprehensive experiments to study why word-based models underperform char-based models in these deep learning-based NLP tasks. We show that it is because word-based models are more vulnerable to data sparsity and the presence of out-of-vocabulary (OOV) words, and thus more prone to <a href=https://en.wikipedia.org/wiki/Overfitting>overfitting</a>. We hope this paper could encourage researchers in the community to rethink the necessity of <a href=https://en.wikipedia.org/wiki/Word_segmentation>word segmentation</a> in deep learning-based Chinese Natural Language Processing.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1316.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1316 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1316 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1316/>On the Compositionality Prediction of Noun Phrases using Poincar Embeddings</a></strong><br><a href=/people/a/abhik-jana/>Abhik Jana</a>
|
<a href=/people/d/dima-puzyrev/>Dima Puzyrev</a>
|
<a href=/people/a/alexander-panchenko/>Alexander Panchenko</a>
|
<a href=/people/p/pawan-goyal/>Pawan Goyal</a>
|
<a href=/people/c/chris-biemann/>Chris Biemann</a>
|
<a href=/people/a/animesh-mukherjee/>Animesh Mukherjee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1316><div class="card-body p-3 small">The compositionality degree of multiword expressions indicates to what extent the meaning of a phrase can be derived from the meaning of its constituents and their <a href=https://en.wikipedia.org/wiki/Grammatical_relation>grammatical relations</a>. Prediction of (non)-compositionality is a task that has been frequently addressed with distributional semantic models. We introduce a novel technique to blend hierarchical information with <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>distributional information</a> for predicting compositionality. In particular, we use hypernymy information of the multiword and its constituents encoded in the form of the recently introduced Poincar embeddings in addition to the distributional information to detect compositionality for <a href=https://en.wikipedia.org/wiki/Noun_phrase>noun phrases</a>. Using a <a href=https://en.wikipedia.org/wiki/Weighted_arithmetic_mean>weighted average</a> of the distributional similarity and a Poincar similarity function, we obtain consistent and substantial, statistically significant improvement across three gold standard datasets over state-of-the-art models based on distributional information only. Unlike traditional approaches that solely use an <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised setting</a>, we have also framed the <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> as a <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised task</a>, obtaining comparable improvements. Further, we publicly release our Poincar embeddings, which are trained on the output of handcrafted lexical-syntactic patterns on a large corpus.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1317.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1317 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1317 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1317/>Robust Representation Learning of Biomedical Names</a></strong><br><a href=/people/m/minh-c-phan/>Minh C. Phan</a>
|
<a href=/people/a/aixin-sun/>Aixin Sun</a>
|
<a href=/people/y/yi-tay/>Yi Tay</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1317><div class="card-body p-3 small">Biomedical concepts are often mentioned in <a href=https://en.wikipedia.org/wiki/Medical_record>medical documents</a> under different name variations (synonyms). This mismatch between surface forms is problematic, resulting in difficulties pertaining to learning effective <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a>. Consequently, this has tremendous implications such as rendering downstream applications inefficacious and/or potentially unreliable. This paper proposes a new <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> for learning robust representations of biomedical names and terms. The idea behind our approach is to consider and encode <a href=https://en.wikipedia.org/wiki/Context_(language_use)>contextual meaning</a>, conceptual meaning, and the <a href=https://en.wikipedia.org/wiki/Synonym>similarity between synonyms</a> during the representation learning process. Via extensive experiments, we show that our proposed method outperforms other baselines on a battery of retrieval, similarity and relatedness benchmarks. Moreover, our proposed method is also able to compute meaningful representations for unseen names, resulting in high practical utility in real-world applications.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1320.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1320 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1320 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1320.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1320" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1320/>Incorporating Syntactic and Semantic Information in Word Embeddings using Graph Convolutional Networks</a></strong><br><a href=/people/s/shikhar-vashishth/>Shikhar Vashishth</a>
|
<a href=/people/m/manik-bhandari/>Manik Bhandari</a>
|
<a href=/people/p/prateek-yadav/>Prateek Yadav</a>
|
<a href=/people/p/piyush-rai/>Piyush Rai</a>
|
<a href=/people/c/chiranjib-bhattacharyya/>Chiranjib Bhattacharyya</a>
|
<a href=/people/p/partha-talukdar/>Partha Talukdar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1320><div class="card-body p-3 small">Word embeddings have been widely adopted across several NLP applications. Most existing word embedding methods utilize sequential context of a word to learn its embedding. While there have been some attempts at utilizing <a href=https://en.wikipedia.org/wiki/Context_(language_use)>syntactic context</a> of a word, such methods result in an explosion of the <a href=https://en.wikipedia.org/wiki/Vocabulary_size>vocabulary size</a>. In this paper, we overcome this problem by proposing SynGCN, a flexible Graph Convolution based method for learning <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a>. SynGCN utilizes the <a href=https://en.wikipedia.org/wiki/Dependency_grammar>dependency context</a> of a word without increasing the <a href=https://en.wikipedia.org/wiki/Linguistic_prescription>vocabulary size</a>. Word embeddings learned by SynGCN outperform existing methods on various intrinsic and extrinsic tasks and provide an advantage when used with ELMo. We also propose SemGCN, an effective framework for incorporating diverse semantic knowledge for further enhancing learned word representations. We make the source code of both <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> available to encourage reproducible research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1325.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1325 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1325 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1325" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1325/>Making Fast Graph-based Algorithms with Graph Metric Embeddings</a></strong><br><a href=/people/a/andrey-kutuzov/>Andrey Kutuzov</a>
|
<a href=/people/m/mohammad-dorgham/>Mohammad Dorgham</a>
|
<a href=/people/o/oleksiy-oliynyk/>Oleksiy Oliynyk</a>
|
<a href=/people/c/chris-biemann/>Chris Biemann</a>
|
<a href=/people/a/alexander-panchenko/>Alexander Panchenko</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1325><div class="card-body p-3 small">Graph measures, such as node distances, are inefficient to compute. We explore dense vector representations as an effective way to approximate the same information. We introduce a simple yet efficient and effective approach for learning <a href=https://en.wikipedia.org/wiki/Graph_embedding>graph embeddings</a>. Instead of directly operating on the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a>, our method takes structural measures of pairwise node similarities into account and learns dense node representations reflecting user-defined graph distance measures, such as e.g. the shortest path distance or distance measures that take information beyond the <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph structure</a> into account. We demonstrate a speed-up of several orders of magnitude when predicting word similarity by vector operations on our embeddings as opposed to directly computing the respective path-based measures, while outperforming various other graph embeddings on semantic similarity and word sense disambiguation tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1328.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1328 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1328 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1328.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1328/>BERT-based Lexical Substitution<span class=acl-fixed-case>BERT</span>-based Lexical Substitution</a></strong><br><a href=/people/w/wangchunshu-zhou/>Wangchunshu Zhou</a>
|
<a href=/people/t/tao-ge/>Tao Ge</a>
|
<a href=/people/k/ke-xu/>Ke Xu</a>
|
<a href=/people/f/furu-wei/>Furu Wei</a>
|
<a href=/people/m/ming-zhou/>Ming Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1328><div class="card-body p-3 small">Previous studies on <a href=https://en.wikipedia.org/wiki/Lexical_substitution>lexical substitution</a> tend to obtain substitute candidates by finding the target word&#8217;s synonyms from lexical resources (e.g., WordNet) and then rank the candidates based on its contexts. These approaches have two limitations : (1) They are likely to overlook good substitute candidates that are not the synonyms of the target words in the lexical resources ; (2) They fail to take into account the substitution&#8217;s influence on the global context of the sentence. To address these issues, we propose an end-to-end BERT-based lexical substitution approach which can propose and validate substitute candidates without using any annotated data or manually curated resources. Our approach first applies dropout to the target word&#8217;s embedding for partially masking the word, allowing BERT to take balanced consideration of the target word&#8217;s semantics and contexts for proposing substitute candidates, and then validates the candidates based on their substitution&#8217;s influence on the global contextualized representation of the sentence. Experiments show our approach performs well in both proposing and ranking substitute candidates, achieving the state-of-the-art results in both LS07 and LS14 benchmarks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1330.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1330 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1330 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1330.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384768559 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1330" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1330/>HighRES : Highlight-based Reference-less Evaluation of Summarization<span class=acl-fixed-case>H</span>igh<span class=acl-fixed-case>RES</span>: Highlight-based Reference-less Evaluation of Summarization</a></strong><br><a href=/people/h/hardy-hardy/>Hardy Hardy</a>
|
<a href=/people/s/shashi-narayan/>Shashi Narayan</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1330><div class="card-body p-3 small">There has been substantial progress in <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> research enabled by the availability of novel, often large-scale, datasets and recent advances on neural network-based approaches. However, manual evaluation of the system generated summaries is inconsistent due to the difficulty the task poses to human non-expert readers. To address this issue, we propose a novel approach for manual evaluation, Highlight-based Reference-less Evaluation of Summarization (HighRES), in which summaries are assessed by multiple annotators against the source document via manually highlighted salient content in the latter. Thus summary assessment on the source document by human judges is facilitated, while the highlights can be used for evaluating multiple systems. To validate our approach we employ crowd-workers to augment with highlights a recently proposed dataset and compare two state-of-the-art systems. We demonstrate that HighRES improves inter-annotator agreement in comparison to using the source document directly, while they help emphasize differences among systems that would be ignored under other evaluation approaches.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1331.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1331 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1331 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384771870 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1331" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1331/>EditNTS : An Neural Programmer-Interpreter Model for Sentence Simplification through Explicit Editing<span class=acl-fixed-case>E</span>dit<span class=acl-fixed-case>NTS</span>: An Neural Programmer-Interpreter Model for Sentence Simplification through Explicit Editing</a></strong><br><a href=/people/y/yue-dong/>Yue Dong</a>
|
<a href=/people/z/zichao-li/>Zichao Li</a>
|
<a href=/people/m/mehdi-rezagholizadeh/>Mehdi Rezagholizadeh</a>
|
<a href=/people/j/jackie-chi-kit-cheung/>Jackie Chi Kit Cheung</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1331><div class="card-body p-3 small">We present the first sentence simplification model that learns explicit edit operations (ADD, DELETE, and KEEP) via a neural programmer-interpreter approach. Most current neural sentence simplification systems are variants of sequence-to-sequence models adopted from <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. These methods learn to simplify sentences as a byproduct of the fact that they are trained on complex-simple sentence pairs. By contrast, our neural programmer-interpreter is directly trained to predict explicit edit operations on targeted parts of the input sentence, resembling the way that humans perform <a href=https://en.wikipedia.org/wiki/Simplification>simplification</a> and revision. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms previous state-of-the-art neural sentence simplification models (without external knowledge) by large margins on three benchmark text simplification corpora in terms of SARI (+0.95 WikiLarge, +1.89 WikiSmall, +1.41 Newsela), and is judged by humans to produce overall better and simpler output sentences.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1332.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1332 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1332 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384795570 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1332/>Decomposable Neural Paraphrase Generation</a></strong><br><a href=/people/z/zichao-li/>Zichao Li</a>
|
<a href=/people/x/xin-jiang/>Xin Jiang</a>
|
<a href=/people/l/lifeng-shang/>Lifeng Shang</a>
|
<a href=/people/q/qun-liu/>Qun Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1332><div class="card-body p-3 small">Paraphrasing exists at different granularity levels, such as <a href=https://en.wikipedia.org/wiki/Lexicon>lexical level</a>, <a href=https://en.wikipedia.org/wiki/Phrase_structure>phrasal level</a> and <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentential level</a>. This paper presents Decomposable Neural Paraphrase Generator (DNPG), a Transformer-based model that can learn and generate paraphrases of a sentence at different levels of granularity in a disentangled way. Specifically, the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is composed of multiple encoders and decoders with different structures, each of which corresponds to a specific granularity. The empirical study shows that the decomposition mechanism of DNPG makes <a href=https://en.wikipedia.org/wiki/Paraphrase_generation>paraphrase generation</a> more interpretable and controllable. Based on DNPG, we further develop an unsupervised domain adaptation method for <a href=https://en.wikipedia.org/wiki/Paraphrase_generation>paraphrase generation</a>. Experimental results show that the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves competitive in-domain performance compared to state-of-the-art neural models, and significantly better performance when adapting to a new domain.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1334.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1334 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1334 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384776891 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1334" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1334/>Right for the Wrong Reasons : Diagnosing Syntactic Heuristics in Natural Language Inference</a></strong><br><a href=/people/t/tom-mccoy/>Tom McCoy</a>
|
<a href=/people/e/ellie-pavlick/>Ellie Pavlick</a>
|
<a href=/people/t/tal-linzen/>Tal Linzen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1334><div class="card-body p-3 small">A <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning system</a> can score well on a given test set by relying on <a href=https://en.wikipedia.org/wiki/Heuristic>heuristics</a> that are effective for frequent example types but break down in more challenging cases. We study this issue within natural language inference (NLI), the task of determining whether one sentence entails another. We hypothesize that statistical NLI models may adopt three fallible syntactic heuristics : the lexical overlap heuristic, the subsequence heuristic, and the constituent heuristic. To determine whether models have adopted these <a href=https://en.wikipedia.org/wiki/Heuristic>heuristics</a>, we introduce a controlled evaluation set called HANS (Heuristic Analysis for NLI Systems), which contains many examples where the <a href=https://en.wikipedia.org/wiki/Heuristic>heuristics</a> fail. We find that models trained on MNLI, including BERT, a state-of-the-art model, perform very poorly on <a href=https://en.wikipedia.org/wiki/HANS>HANS</a>, suggesting that they have indeed adopted these <a href=https://en.wikipedia.org/wiki/Heuristic>heuristics</a>. We conclude that there is substantial room for improvement in NLI systems, and that the HANS dataset can motivate and measure progress in this area.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1336.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1336 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1336 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384782139 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1336/>Dual Adversarial Neural Transfer for Low-Resource Named Entity Recognition</a></strong><br><a href=/people/j/joey-tianyi-zhou/>Joey Tianyi Zhou</a>
|
<a href=/people/h/hao-zhang/>Hao Zhang</a>
|
<a href=/people/d/di-jin/>Di Jin</a>
|
<a href=/people/h/hongyuan-zhu/>Hongyuan Zhu</a>
|
<a href=/people/m/meng-fang/>Meng Fang</a>
|
<a href=/people/r/rick-siow-mong-goh/>Rick Siow Mong Goh</a>
|
<a href=/people/k/kenneth-kwok/>Kenneth Kwok</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1336><div class="card-body p-3 small">We propose a new neural transfer method termed Dual Adversarial Transfer Network (DATNet) for addressing low-resource Named Entity Recognition (NER). Specifically, two variants of DATNet, i.e., DATNet-F and DATNet-P, are investigated to explore effective feature fusion between high and low resource. To address the noisy and imbalanced training data, we propose a novel Generalized Resource-Adversarial Discriminator (GRAD). Additionally, adversarial training is adopted to boost model generalization. In experiments, we examine the effects of different components in DATNet across domains and languages and show that significant improvement can be obtained especially for low-resource data, without augmenting any additional hand-crafted features and pre-trained language model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1338.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1338 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1338 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384800134 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1338" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1338/>An Imitation Learning Approach to Unsupervised Parsing</a></strong><br><a href=/people/b/bowen-li/>Bowen Li</a>
|
<a href=/people/l/lili-mou/>Lili Mou</a>
|
<a href=/people/f/frank-keller/>Frank Keller</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1338><div class="card-body p-3 small">Recently, there has been an increasing interest in <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised parsers</a> that optimize semantically oriented objectives, typically using <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a>. Unfortunately, the learned trees often do not match actual <a href=https://en.wikipedia.org/wiki/Tree_(data_structure)>syntax trees</a> well. Shen et al. (2018) propose a structured attention mechanism for language modeling (PRPN), which induces better syntactic structures but relies on ad hoc heuristics. Also, their <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> lacks interpretability as <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> is not grounded in parsing actions. In our work, we propose an imitation learning approach to unsupervised parsing, where we transfer the syntactic knowledge induced by PRPN to a Tree-LSTM model with discrete parsing actions. Its <a href=https://en.wikipedia.org/wiki/Policy>policy</a> is then refined by Gumbel-Softmax training towards a semantically oriented objective. We evaluate our approach on the All Natural Language Inference dataset and show that it achieves a new state of the art in terms of parsing F-score, outperforming our base models, including PRPN.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1339.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1339 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1339 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384801759 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1339/>Women’s Syntactic Resilience and Men’s Grammatical Luck : Gender-Bias in Part-of-Speech Tagging and Dependency Parsing</a></strong><br><a href=/people/a/aparna-garimella/>Aparna Garimella</a>
|
<a href=/people/c/carmen-banea/>Carmen Banea</a>
|
<a href=/people/d/dirk-hovy/>Dirk Hovy</a>
|
<a href=/people/r/rada-mihalcea/>Rada Mihalcea</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1339><div class="card-body p-3 small">Several linguistic studies have shown the prevalence of various lexical and grammatical patterns in texts authored by a person of a particular gender, but models for <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a> and <a href=https://en.wikipedia.org/wiki/Dependency_grammar>dependency parsing</a> have still not adapted to account for these differences. To address this, we annotate the <a href=https://en.wikipedia.org/wiki/The_Wall_Street_Journal>Wall Street Journal</a> part of the Penn Treebank with the gender information of the articles&#8217; authors, and build taggers and parsers trained on this data that show performance differences in text written by men and women. Further analyses reveal numerous <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tags</a> and <a href=https://en.wikipedia.org/wiki/Syntax>syntactic relations</a> whose prediction performances benefit from the prevalence of a specific gender in the training data. The results underscore the importance of accounting for gendered differences in syntactic tasks, and outline future venues for developing more accurate taggers and parsers. We release our data to the research community.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1340.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1340 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1340 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384782901 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1340" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1340/>Multilingual Constituency Parsing with Self-Attention and Pre-Training</a></strong><br><a href=/people/n/nikita-kitaev/>Nikita Kitaev</a>
|
<a href=/people/s/steven-cao/>Steven Cao</a>
|
<a href=/people/d/dan-klein/>Dan Klein</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1340><div class="card-body p-3 small">We show that constituency parsing benefits from unsupervised pre-training across a variety of languages and a range of pre-training conditions. We first compare the benefits of no pre-training, <a href=https://en.wikipedia.org/wiki/FastText>fastText</a>, ELMo, and BERT for English and find that BERT outperforms ELMo, in large part due to increased model capacity, whereas ELMo in turn outperforms the non-contextual fastText embeddings. We also find that pre-training is beneficial across all 11 languages tested ; however, large model sizes (more than 100 million parameters) make it computationally expensive to train separate models for each language. To address this shortcoming, we show that joint multilingual pre-training and fine-tuning allows sharing all but a small number of parameters between ten languages in the final <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>. The 10x reduction in model size compared to fine-tuning one model per language causes only a 3.2 % relative error increase in aggregate. We further explore the idea of joint fine-tuning and show that it gives low-resource languages a way to benefit from the larger datasets of other languages. Finally, we demonstrate new state-of-the-art results for 11 <a href=https://en.wikipedia.org/wiki/Language>languages</a>, including <a href=https://en.wikipedia.org/wiki/English_language>English</a> (95.8 F1) and <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a> (91.8 F1).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1341.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1341 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1341 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384801834 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1341/>A Multilingual BPE Embedding Space for Universal Sentiment Lexicon Induction<span class=acl-fixed-case>BPE</span> Embedding Space for Universal Sentiment Lexicon Induction</a></strong><br><a href=/people/m/mengjie-zhao/>Mengjie Zhao</a>
|
<a href=/people/h/hinrich-schutze/>Hinrich Schütze</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1341><div class="card-body p-3 small">We present a new method for sentiment lexicon induction that is designed to be applicable to the entire range of typological diversity of the world&#8217;s languages. We evaluate our method on Parallel Bible Corpus+ (PBC+), a parallel corpus of 1593 languages. The key idea is to use Byte Pair Encodings (BPEs) as basic units for multilingual embeddings. Through zero-shot transfer from English sentiment, we learn a seed lexicon for each language in the domain of PBC+. Through <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a>, we then generalize the domain-specific lexicon to a general one. We show across typologically diverse languages in PBC+ good quality of seed and general-domain sentiment lexicons by intrinsic and extrinsic and by automatic and human evaluation. We make freely available our code, seed sentiment lexicons for all 1593 languages and induced general-domain sentiment lexicons for 200 languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1343.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1343 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1343 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384803075 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1343" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1343/>Improved Sentiment Detection via Label Transfer from <a href=https://en.wikipedia.org/wiki/Monolingualism>Monolingual</a> to Synthetic Code-Switched Text</a></strong><br><a href=/people/b/bidisha-samanta/>Bidisha Samanta</a>
|
<a href=/people/n/niloy-ganguly/>Niloy Ganguly</a>
|
<a href=/people/s/soumen-chakrabarti/>Soumen Chakrabarti</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1343><div class="card-body p-3 small">Multilingual writers and speakers often alternate between two languages in a single discourse. This practice is called <a href=https://en.wikipedia.org/wiki/Code-switching>code-switching</a>. Existing sentiment detection methods are usually trained on sentiment-labeled monolingual text. Manually labeled code-switched text, especially involving <a href=https://en.wikipedia.org/wiki/Minority_language>minority languages</a>, is extremely rare. Consequently, the best monolingual methods perform relatively poorly on code-switched text. We present an effective technique for synthesizing labeled code-switched text from labeled monolingual text, which is relatively readily available. The idea is to replace carefully selected subtrees of constituency parses of sentences in the resource-rich language with suitable token spans selected from automatic translations to the resource-poor language. By augmenting the scarce labeled code-switched text with plentiful synthetic labeled code-switched text, we achieve significant improvements in sentiment labeling accuracy (1.5 %, 5.11 % 7.20 %) for three different language pairs (English-Hindi, English-Spanish and English-Bengali). The improvement is even significant in hatespeech detection whereby we achieve a 4 % improvement using only synthetic code-switched data (6 % with data augmentation).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1346.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1346 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1346 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1346.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384783066 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1346" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1346/>ELI5 : Long Form Question Answering<span class=acl-fixed-case>ELI</span>5: Long Form Question Answering</a></strong><br><a href=/people/a/angela-fan/>Angela Fan</a>
|
<a href=/people/y/yacine-jernite/>Yacine Jernite</a>
|
<a href=/people/e/ethan-perez/>Ethan Perez</a>
|
<a href=/people/d/david-grangier/>David Grangier</a>
|
<a href=/people/j/jason-weston/>Jason Weston</a>
|
<a href=/people/m/michael-auli/>Michael Auli</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1346><div class="card-body p-3 small">We introduce the first <a href=https://en.wikipedia.org/wiki/Text_corpus>large-scale corpus</a> for long form question answering, a task requiring elaborate and in-depth answers to <a href=https://en.wikipedia.org/wiki/Open-ended_question>open-ended questions</a>. The dataset comprises 270 K threads from the Reddit forum Explain Like I&#8217;m Five (ELI5) where an <a href=https://en.wikipedia.org/wiki/Online_community>online community</a> provides answers to questions which are comprehensible by five year olds. Compared to existing <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, ELI5 comprises diverse questions requiring multi-sentence answers. We provide a large set of <a href=https://en.wikipedia.org/wiki/Web_page>web documents</a> to help answer the question. Automatic and human evaluations show that an abstractive model trained with a multi-task objective outperforms conventional Seq2Seq, <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a>, as well as a strong extractive baseline. However, our best model is still far from human performance since raters prefer gold responses in over 86 % of cases, leaving ample opportunity for future improvement.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1347.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1347 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1347 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1347/>Textbook Question Answering with Multi-modal Context Graph Understanding and Self-supervised Open-set Comprehension</a></strong><br><a href=/people/d/daesik-kim/>Daesik Kim</a>
|
<a href=/people/s/seonhoon-kim/>Seonhoon Kim</a>
|
<a href=/people/n/nojun-kwak/>Nojun Kwak</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1347><div class="card-body p-3 small">In this work, we introduce a novel <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> for solving the textbook question answering (TQA) task which describes more realistic QA problems compared to other recent tasks. We mainly focus on two related issues with analysis of the TQA dataset. First, solving the TQA problems requires to comprehend multi-modal contexts in complicated input data. To tackle this issue of extracting knowledge features from long text lessons and merging them with visual features, we establish a context graph from texts and images, and propose a new module f-GCN based on graph convolutional networks (GCN). Second, scientific terms are not spread over the chapters and subjects are split in the TQA dataset. To overcome this so called &#8216;out-of-domain&#8217; issue, before learning QA problems, we introduce a novel self-supervised open-set learning process without any annotations. The experimental results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> significantly outperforms prior state-of-the-art methods. Moreover, ablation studies validate that both methods of incorporating f-GCN for extracting knowledge from multi-modal contexts and our newly proposed self-supervised learning process are effective for TQA problems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1350.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1350 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1350 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1350.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384787273 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1350/>Psycholinguistics Meets Continual Learning : Measuring Catastrophic Forgetting in Visual Question Answering</a></strong><br><a href=/people/c/claudio-greco/>Claudio Greco</a>
|
<a href=/people/b/barbara-plank/>Barbara Plank</a>
|
<a href=/people/r/raquel-fernandez/>Raquel Fernández</a>
|
<a href=/people/r/raffaella-bernardi/>Raffaella Bernardi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1350><div class="card-body p-3 small">We study the issue of catastrophic forgetting in the context of neural multimodal approaches to Visual Question Answering (VQA). Motivated by evidence from psycholinguistics, we devise a set of linguistically-informed VQA tasks, which differ by the types of questions involved (Wh-questions and polar questions). We test what impact task difficulty has on continual learning, and whether the order in which a child acquires question types facilitates <a href=https://en.wikipedia.org/wiki/Computational_model>computational models</a>. Our results show that dramatic forgetting is at play and that task difficulty and <a href=https://en.wikipedia.org/wiki/Order_and_disorder>order</a> matter. Two well-known current continual learning methods mitigate the problem only to a limiting degree.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1354.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1354 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1354 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384961600 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1354" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1354/>Assessing the Ability of Self-Attention Networks to Learn Word Order</a></strong><br><a href=/people/b/baosong-yang/>Baosong Yang</a>
|
<a href=/people/l/longyue-wang/>Longyue Wang</a>
|
<a href=/people/d/derek-f-wong/>Derek F. Wong</a>
|
<a href=/people/l/lidia-s-chao/>Lidia S. Chao</a>
|
<a href=/people/z/zhaopeng-tu/>Zhaopeng Tu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1354><div class="card-body p-3 small">Self-attention networks (SAN) have attracted a lot of interests due to their high <a href=https://en.wikipedia.org/wiki/Parallel_computing>parallelization</a> and strong performance on a variety of NLP tasks, e.g. machine translation. Due to the lack of <a href=https://en.wikipedia.org/wiki/Recurrence_relation>recurrence structure</a> such as <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural networks (RNN)</a>, SAN is ascribed to be weak at learning positional information of words for sequence modeling. However, neither this speculation has been empirically confirmed, nor explanations for their strong performances on machine translation tasks when lacking positional information have been explored. To this end, we propose a novel word reordering detection task to quantify how well the word order information learned by <a href=https://en.wikipedia.org/wiki/Signal-to-noise_ratio>SAN</a> and <a href=https://en.wikipedia.org/wiki/Signal-to-noise_ratio>RNN</a>. Specifically, we randomly move one word to another position, and examine whether a trained <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> can detect both the original and inserted positions. Experimental results reveal that : 1) SAN trained on word reordering detection indeed has difficulty learning the positional information even with the position embedding ; and 2) SAN trained on <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> learns better positional information than its RNN counterpart, in which position embedding plays a critical role. Although <a href=https://en.wikipedia.org/wiki/Recurrence_relation>recurrence structure</a> make the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> more universally-effective on learning <a href=https://en.wikipedia.org/wiki/Word_order>word order</a>, learning objectives matter more in the downstream tasks such as <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1355.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1355 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1355 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/384787604 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1355" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1355/>Energy and Policy Considerations for <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Learning</a> in NLP<span class=acl-fixed-case>NLP</span></a></strong><br><a href=/people/e/emma-strubell/>Emma Strubell</a>
|
<a href=/people/a/ananya-ganesh/>Ananya Ganesh</a>
|
<a href=/people/a/andrew-mccallum/>Andrew McCallum</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1355><div class="card-body p-3 small">Recent progress in hardware and methodology for training <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> has ushered in a new generation of large networks trained on abundant data. These <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> have obtained notable gains in <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> across many <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP tasks</a>. However, these <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> improvements depend on the availability of exceptionally large computational resources that necessitate similarly substantial <a href=https://en.wikipedia.org/wiki/Energy_consumption>energy consumption</a>. As a result these models are costly to train and develop, both financially, due to the cost of <a href=https://en.wikipedia.org/wiki/Computer_hardware>hardware</a> and electricity or cloud compute time, and environmentally, due to the <a href=https://en.wikipedia.org/wiki/Carbon_footprint>carbon footprint</a> required to fuel modern tensor processing hardware. In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>. Based on these findings, we propose actionable recommendations to reduce costs and improve equity in NLP research and practice.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1359.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1359 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1359 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1359/>Generating Responses with a Specific Emotion in Dialog</a></strong><br><a href=/people/z/zhenqiao-song/>Zhenqiao Song</a>
|
<a href=/people/x/xiaoqing-zheng/>Xiaoqing Zheng</a>
|
<a href=/people/l/lu-liu/>Lu Liu</a>
|
<a href=/people/m/mu-xu/>Mu Xu</a>
|
<a href=/people/x/xuan-jing-huang/>Xuanjing Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1359><div class="card-body p-3 small">It is desirable for dialog systems to have capability to express specific emotions during a conversation, which has a direct, quantifiable impact on improvement of their <a href=https://en.wikipedia.org/wiki/Usability>usability</a> and user satisfaction. After a careful investigation of real-life conversation data, we found that there are at least two ways to express emotions with language. One is to describe emotional states by explicitly using strong emotional words ; another is to increase the intensity of the emotional experiences by implicitly combining neutral words in distinct ways. We propose an emotional dialogue system (EmoDS) that can generate the meaningful responses with a coherent structure for a post, and meanwhile express the desired emotion explicitly or implicitly within a unified framework. Experimental results showed EmoDS performed better than the baselines in <a href=https://en.wikipedia.org/wiki/BLEU>BLEU</a>, diversity and the quality of emotional expression.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1360.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1360 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1360 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1360" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1360/>Semantically Conditioned Dialog Response Generation via Hierarchical Disentangled Self-Attention</a></strong><br><a href=/people/w/wenhu-chen/>Wenhu Chen</a>
|
<a href=/people/j/jianshu-chen/>Jianshu Chen</a>
|
<a href=/people/p/pengda-qin/>Pengda Qin</a>
|
<a href=/people/x/xifeng-yan/>Xifeng Yan</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1360><div class="card-body p-3 small">Semantically controlled neural response generation on <a href=https://en.wikipedia.org/wiki/Domain-specific_language>limited-domain</a> has achieved great performance. However, moving towards multi-domain large-scale scenarios are shown to be difficult because the possible combinations of semantic inputs grow exponentially with the number of domains. To alleviate such scalability issue, we exploit the structure of dialog acts to build a multi-layer hierarchical graph, where each act is represented as a root-to-leaf route on the <a href=https://en.wikipedia.org/wiki/Graph_(abstract_data_type)>graph</a>. Then, we incorporate such graph structure prior as an inductive bias to build a hierarchical disentangled self-attention network, where we disentangle attention heads to model designated nodes on the dialog act graph. By activating different (disentangled) heads at each layer, combinatorially many dialog act semantics can be modeled to control the neural response generation. On the large-scale Multi-Domain-WOZ dataset, our model can yield a significant improvement over the baselines on various automatic and human evaluation metrics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1365.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1365 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1365 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1365" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1365/>Comparison of Diverse Decoding Methods from <a href=https://en.wikipedia.org/wiki/Conditional_(computer_programming)>Conditional Language Models</a></a></strong><br><a href=/people/d/daphne-ippolito/>Daphne Ippolito</a>
|
<a href=/people/r/reno-kriz/>Reno Kriz</a>
|
<a href=/people/j/joao-sedoc/>João Sedoc</a>
|
<a href=/people/m/maria-kustikova/>Maria Kustikova</a>
|
<a href=/people/c/chris-callison-burch/>Chris Callison-Burch</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1365><div class="card-body p-3 small">While conditional language models have greatly improved in their ability to output high quality natural language, many NLP applications benefit from being able to generate a diverse set of candidate sequences. Diverse decoding strategies aim to, within a given-sized candidate list, cover as much of the space of high-quality outputs as possible, leading to improvements for tasks that rerank and combine candidate outputs. Standard decoding methods, such as <a href=https://en.wikipedia.org/wiki/Beam_search>beam search</a>, optimize for generating high likelihood sequences rather than diverse ones, though recent work has focused on increasing diversity in these methods. In this work, we perform an extensive survey of decoding-time strategies for generating diverse outputs from a <a href=https://en.wikipedia.org/wiki/Conditional_(computer_programming)>conditional language model</a>. In addition, we present a novel method where we over-sample candidates, then use <a href=https://en.wikipedia.org/wiki/Cluster_analysis>clustering</a> to remove similar sequences, thus achieving high diversity without sacrificing quality.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1366.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1366 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1366 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1366/>Retrieval-Enhanced Adversarial Training for Neural Response Generation</a></strong><br><a href=/people/q/qingfu-zhu/>Qingfu Zhu</a>
|
<a href=/people/l/lei-cui/>Lei Cui</a>
|
<a href=/people/w/weinan-zhang/>Wei-Nan Zhang</a>
|
<a href=/people/f/furu-wei/>Furu Wei</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1366><div class="card-body p-3 small">Dialogue systems are usually built on either generation-based or retrieval-based approaches, yet they do not benefit from the advantages of different models. In this paper, we propose a Retrieval-Enhanced Adversarial Training (REAT) method for neural response generation. Distinct from existing approaches, the REAT method leverages an encoder-decoder framework in terms of an adversarial training paradigm, while taking advantage of N-best response candidates from a retrieval-based system to construct the discriminator. An empirical study on a large scale public available benchmark dataset shows that the REAT method significantly outperforms the vanilla Seq2Seq model as well as the conventional adversarial training approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1367.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1367 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1367 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1367/>Vocabulary Pyramid Network : Multi-Pass Encoding and Decoding with Multi-Level Vocabularies for Response Generation</a></strong><br><a href=/people/c/cao-liu/>Cao Liu</a>
|
<a href=/people/s/shizhu-he/>Shizhu He</a>
|
<a href=/people/k/kang-liu/>Kang Liu</a>
|
<a href=/people/j/jun-zhao/>Jun Zhao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1367><div class="card-body p-3 small">We study the task of response generation. Conventional methods employ a fixed vocabulary and one-pass decoding, which not only make them prone to safe and general responses but also lack further refining to the first generated raw sequence. To tackle the above two problems, we present a Vocabulary Pyramid Network (VPN) which is able to incorporate multi-pass encoding and decoding with multi-level vocabularies into response generation. Specifically, the dialogue input and output are represented by multi-level vocabularies which are obtained from hierarchical clustering of raw words. Then, multi-pass encoding and decoding are conducted on the multi-level vocabularies. Since <a href=https://en.wikipedia.org/wiki/Virtual_private_network>VPN</a> is able to leverage rich encoding and decoding information with multi-level vocabularies, it has the potential to generate better responses. Experiments on English Twitter and Chinese Weibo datasets demonstrate that <a href=https://en.wikipedia.org/wiki/Virtual_private_network>VPN</a> remarkably outperforms strong <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1368.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1368 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1368 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1368/>On-device Structured and Context Partitioned Projection Networks</a></strong><br><a href=/people/s/sujith-ravi/>Sujith Ravi</a>
|
<a href=/people/z/zornitsa-kozareva/>Zornitsa Kozareva</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1368><div class="card-body p-3 small">A challenging problem in on-device text classification is to build highly accurate neural models that can fit in small memory footprint and have <a href=https://en.wikipedia.org/wiki/Latency_(engineering)>low latency</a>. To address this challenge, we propose an on-device neural network SGNN++ which dynamically learns compact projection vectors from raw text using structured and context-dependent partition projections. We show that this results in accelerated inference and performance improvements. We conduct extensive evaluation on multiple conversational tasks and languages such as <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a>, <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a> and <a href=https://en.wikipedia.org/wiki/French_language>French</a>. Our SGNN++ model significantly outperforms all baselines, improves upon existing on-device neural models and even surpasses <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>RNN</a>, CNN and BiLSTM models on dialog act and intent prediction. Through a series of ablation studies we show the impact of the partitioned projections and structured information leading to 10 % improvement. We study the impact of the model size on <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and introduce quatization-aware training for SGNN++ to further reduce the model size while preserving the same quality. Finally, we show fast <a href=https://en.wikipedia.org/wiki/Inference>inference</a> on <a href=https://en.wikipedia.org/wiki/Mobile_phone>mobile phones</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1369.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1369 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1369 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1369/>Proactive Human-Machine Conversation with Explicit Conversation Goal</a></strong><br><a href=/people/w/wenquan-wu/>Wenquan Wu</a>
|
<a href=/people/z/zhen-guo/>Zhen Guo</a>
|
<a href=/people/x/xiangyang-zhou/>Xiangyang Zhou</a>
|
<a href=/people/h/hua-wu/>Hua Wu</a>
|
<a href=/people/x/xiyuan-zhang/>Xiyuan Zhang</a>
|
<a href=/people/r/rongzhong-lian/>Rongzhong Lian</a>
|
<a href=/people/h/haifeng-wang/>Haifeng Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1369><div class="card-body p-3 small">Though great progress has been made for human-machine conversation, current dialogue system is still in its infancy : it usually converses passively and utters words more as a matter of response, rather than on its own initiatives. In this paper, we take a radical step towards building a human-like conversational agent : endowing it with the ability of proactively leading the conversation (introducing a new topic or maintaining the current topic). To facilitate the development of such conversation systems, we create a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> named Konv where one acts as a conversation leader and the other acts as the follower. The leader is provided with a <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graph</a> and asked to sequentially change the discussion topics, following the given conversation goal, and meanwhile keep the dialogue as natural and engaging as possible. Konv enables a very challenging task as the model needs to both understand dialogue and plan over the given <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graph</a>. We establish baseline results on this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> (about 270 K utterances and 30k dialogues) using several state-of-the-art models. Experimental results show that dialogue models that plan over the knowledge graph can make full use of related knowledge to generate more diverse multi-turn conversations. The <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline systems</a> along with the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> are publicly available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1371.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1371 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1371 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1371" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1371/>Learning to Abstract for Memory-augmented Conversational Response Generation</a></strong><br><a href=/people/z/zhiliang-tian/>Zhiliang Tian</a>
|
<a href=/people/w/wei-bi/>Wei Bi</a>
|
<a href=/people/x/xiaopeng-li/>Xiaopeng Li</a>
|
<a href=/people/n/nevin-l-zhang/>Nevin L. Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1371><div class="card-body p-3 small">Neural generative models for open-domain chit-chat conversations have become an active area of research in recent years. A critical issue with most existing <a href=https://en.wikipedia.org/wiki/Generative_model>generative models</a> is that the generated responses lack informativeness and <a href=https://en.wikipedia.org/wiki/Multiculturalism>diversity</a>. A few researchers attempt to leverage the results of retrieval models to strengthen the generative models, but these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are limited by the quality of the retrieval results. In this work, we propose a memory-augmented generative model, which learns to abstract from the training corpus and saves the useful information to the <a href=https://en.wikipedia.org/wiki/Memory>memory</a> to assist the response generation. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> clusters query-response samples, extracts characteristics of each cluster, and learns to utilize these characteristics for response generation. Experimental results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms other competitive baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1374.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1374 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1374 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1374.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1374.Software.tgz data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1374" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1374/>A Large-Scale Corpus for Conversation Disentanglement</a></strong><br><a href=/people/j/jonathan-k-kummerfeld/>Jonathan K. Kummerfeld</a>
|
<a href=/people/s/sai-r-gouravajhala/>Sai R. Gouravajhala</a>
|
<a href=/people/j/joseph-j-peper/>Joseph J. Peper</a>
|
<a href=/people/v/vignesh-athreya/>Vignesh Athreya</a>
|
<a href=/people/c/chulaka-gunasekara/>Chulaka Gunasekara</a>
|
<a href=/people/j/jatin-ganhotra/>Jatin Ganhotra</a>
|
<a href=/people/s/siva-sankalp-patel/>Siva Sankalp Patel</a>
|
<a href=/people/l/lazaros-c-polymenakos/>Lazaros C Polymenakos</a>
|
<a href=/people/w/walter-lasecki/>Walter Lasecki</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1374><div class="card-body p-3 small">Disentangling conversations mixed together in a single stream of messages is a difficult task, made harder by the lack of large manually annotated datasets. We created a new dataset of 77,563 messages manually annotated with reply-structure graphs that both disentangle conversations and define internal conversation structure. Our <a href=https://en.wikipedia.org/wiki/Data>data</a> is 16 times larger than all previously released datasets combined, the first to include adjudication of annotation disagreements, and the first to include <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context</a>. We use our data to re-examine prior work, in particular, finding that 89 % of conversations in a widely used dialogue corpus are either missing messages or contain extra messages. Our manually-annotated data presents an opportunity to develop robust data-driven methods for conversation disentanglement, which will help advance dialogue research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1375.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1375 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1375 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1375/>Self-Supervised Dialogue Learning</a></strong><br><a href=/people/j/jiawei-wu/>Jiawei Wu</a>
|
<a href=/people/x/xin-wang/>Xin Wang</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1375><div class="card-body p-3 small">The sequential order of utterances is often meaningful in coherent dialogues, and the order changes of utterances could lead to low-quality and incoherent conversations. We consider the order information as a crucial supervised signal for dialogue learning, which, however, has been neglected by many previous <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue systems</a>. Therefore, in this paper, we introduce a self-supervised learning task, inconsistent order detection, to explicitly capture the flow of conversation in dialogues. Given a sampled utterance pair triple, the task is to predict whether it is ordered or misordered. Then we propose a sampling-based self-supervised network SSN to perform the prediction with sampled triple references from previous dialogue history. Furthermore, we design a joint learning framework where <a href=https://en.wikipedia.org/wiki/Social_security_number>SSN</a> can guide the <a href=https://en.wikipedia.org/wiki/Dialogue_system>dialogue systems</a> towards more coherent and relevant dialogue learning through adversarial training. We demonstrate that the proposed methods can be applied to both open-domain and task-oriented dialogue scenarios, and achieve the new state-of-the-art performance on the OpenSubtitiles and Movie-Ticket Booking datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1376.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1376 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1376 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1376/>Are we there yet? Encoder-decoder neural networks as cognitive models of English past tense inflection<span class=acl-fixed-case>E</span>nglish past tense inflection</a></strong><br><a href=/people/m/maria-corkery/>Maria Corkery</a>
|
<a href=/people/y/yevgen-matusevych/>Yevgen Matusevych</a>
|
<a href=/people/s/sharon-goldwater/>Sharon Goldwater</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1376><div class="card-body p-3 small">The <a href=https://en.wikipedia.org/wiki/Cognition>cognitive mechanisms</a> needed to account for the English past tense have long been a subject of debate in <a href=https://en.wikipedia.org/wiki/Linguistics>linguistics</a> and <a href=https://en.wikipedia.org/wiki/Cognitive_science>cognitive science</a>. Neural network models were proposed early on, but were shown to have clear flaws. Recently, however, Kirov and Cotterell (2018) showed that modern encoder-decoder (ED) models overcome many of these flaws. They also presented evidence that ED models demonstrate humanlike performance in a nonce-word task. Here, we look more closely at the behaviour of their <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> in this task. We find that (1) the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> exhibits instability across multiple simulations in terms of its correlation with human data, and (2) even when results are aggregated across simulations (treating each simulation as an individual human participant), the fit to the human data is not strongworse than an older rule-based model. These findings hold up through several alternative training regimes and <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation measures</a>. Although other neural architectures might do better, we conclude that there is still insufficient evidence to claim that <a href=https://en.wikipedia.org/wiki/Artificial_neural_network>neural nets</a> are a good <a href=https://en.wikipedia.org/wiki/Cognitive_model>cognitive model</a> for this task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1377.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1377 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1377 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1377/>A Spreading Activation Framework for Tracking Conceptual Complexity of Texts</a></strong><br><a href=/people/i/ioana-hulpus/>Ioana Hulpuș</a>
|
<a href=/people/s/sanja-stajner/>Sanja Štajner</a>
|
<a href=/people/h/heiner-stuckenschmidt/>Heiner Stuckenschmidt</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1377><div class="card-body p-3 small">We propose an <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised approach</a> for assessing conceptual complexity of texts, based on <a href=https://en.wikipedia.org/wiki/Spreading_activation>spreading activation</a>. Using DBpedia knowledge graph as a proxy to <a href=https://en.wikipedia.org/wiki/Long-term_memory>long-term memory</a>, mentioned concepts become activated and trigger further activation as the text is sequentially traversed. Drawing inspiration from psycholinguistic theories of reading comprehension, we model memory processes such as <a href=https://en.wikipedia.org/wiki/Priming_(psychology)>semantic priming</a>, sentence wrap-up, and <a href=https://en.wikipedia.org/wiki/Forgetting>forgetting</a>. We show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> capture various aspects of conceptual text complexity and significantly outperform current <a href=https://en.wikipedia.org/wiki/State_of_the_art>state of the art</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1379.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1379 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1379 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1379/>Diachronic Sense Modeling with Deep Contextualized Word Embeddings : An Ecological View</a></strong><br><a href=/people/r/renfen-hu/>Renfen Hu</a>
|
<a href=/people/s/shen-li/>Shen Li</a>
|
<a href=/people/s/shichen-liang/>Shichen Liang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1379><div class="card-body p-3 small">Diachronic word embeddings have been widely used in detecting temporal changes. However, existing methods face the meaning conflation deficiency by representing a word as a single vector at each time period. To address this issue, this paper proposes a sense representation and tracking framework based on deep contextualized embeddings, aiming at answering not only what and when, but also how the word meaning changes. The experiments show that our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> is effective in representing fine-grained word senses, and it brings a significant improvement in word change detection task. Furthermore, we model the word change from an ecological viewpoint, and sketch two interesting sense behaviors in the process of <a href=https://en.wikipedia.org/wiki/Evolutionary_linguistics>language evolution</a>, i.e. sense competition and sense cooperation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1380.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1380 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1380 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1380.Supplementary.zip data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1380/>Miss Tools and Mr Fruit : Emergent Communication in Agents Learning about Object Affordances</a></strong><br><a href=/people/d/diane-bouchacourt/>Diane Bouchacourt</a>
|
<a href=/people/m/marco-baroni/>Marco Baroni</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1380><div class="card-body p-3 small">Recent research studies communication emergence in communities of deep network agents assigned a joint task, hoping to gain insights on human language evolution. We propose here a new task capturing crucial aspects of the human environment, such as natural object affordances, and of human conversation, such as full symmetry among the participants. By conducting a thorough pragmatic and semantic analysis of the emergent protocol, we show that the <a href=https://en.wikipedia.org/wiki/Intelligent_agent>agents</a> solve the shared task through genuine bilateral, referential communication. However, the <a href=https://en.wikipedia.org/wiki/Agency_(philosophy)>agents</a> develop multiple idiolects, which makes us conclude that full symmetry is not a sufficient condition for a <a href=https://en.wikipedia.org/wiki/Natural_language>common language</a> to emerge.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1381.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1381 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1381 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1381/>CNNs found to jump around more skillfully than RNNs : Compositional Generalization in Seq2seq Convolutional Networks<span class=acl-fixed-case>CNN</span>s found to jump around more skillfully than <span class=acl-fixed-case>RNN</span>s: Compositional Generalization in Seq2seq Convolutional Networks</a></strong><br><a href=/people/r/roberto-dessi/>Roberto Dessì</a>
|
<a href=/people/m/marco-baroni/>Marco Baroni</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1381><div class="card-body p-3 small">Lake and Baroni (2018) introduced the SCAN dataset probing the ability of seq2seq models to capture compositional generalizations, such as inferring the meaning of jump around 0-shot from the component words. Recurrent networks (RNNs) were found to completely fail the most challenging <a href=https://en.wikipedia.org/wiki/Generalization>generalization cases</a>. We test here a convolutional network (CNN) on these tasks, reporting hugely improved performance with respect to RNNs. Despite the big improvement, the CNN has however not induced systematic rules, suggesting that the difference between compositional and non-compositional behaviour is not clear-cut.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1385.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1385 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1385 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1385" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1385/>Attention-based Conditioning Methods for External Knowledge Integration</a></strong><br><a href=/people/k/katerina-margatina/>Katerina Margatina</a>
|
<a href=/people/c/christos-baziotis/>Christos Baziotis</a>
|
<a href=/people/a/alexandros-potamianos/>Alexandros Potamianos</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1385><div class="card-body p-3 small">In this paper, we present a novel approach for incorporating external knowledge in Recurrent Neural Networks (RNNs). We propose the integration of lexicon features into the self-attention mechanism of RNN-based architectures. This form of conditioning on the <a href=https://en.wikipedia.org/wiki/Attentional_control>attention distribution</a>, enforces the contribution of the most salient words for the task at hand. We introduce three methods, namely attentional concatenation, feature-based gating and <a href=https://en.wikipedia.org/wiki/Affine_transformation>affine transformation</a>. Experiments on six <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark datasets</a> show the effectiveness of our <a href=https://en.wikipedia.org/wiki/Methodology>methods</a>. Attentional feature-based gating yields consistent performance improvement across tasks. Our approach is implemented as a simple add-on module for RNN-based models with minimal computational overhead and can be adapted to any deep neural architecture.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1391.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1391 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1391 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1391.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1391/>Crowdsourcing and Validating Event-focused Emotion Corpora for <a href=https://en.wikipedia.org/wiki/German_language>German</a> and English<span class=acl-fixed-case>G</span>erman and <span class=acl-fixed-case>E</span>nglish</a></strong><br><a href=/people/e/enrica-troiano/>Enrica Troiano</a>
|
<a href=/people/s/sebastian-pado/>Sebastian Padó</a>
|
<a href=/people/r/roman-klinger/>Roman Klinger</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1391><div class="card-body p-3 small">Sentiment analysis has a range of corpora available across multiple languages. For emotion analysis, the situation is more limited, which hinders potential research on crosslingual modeling and the development of <a href=https://en.wikipedia.org/wiki/Predictive_modelling>predictive models</a> for other languages. In this paper, we fill this gap for <a href=https://en.wikipedia.org/wiki/German_language>German</a> by constructing deISEAR, a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> designed in analogy to the well-established English ISEAR emotion dataset. Motivated by Scherer&#8217;s appraisal theory, we implement a crowdsourcing experiment which consists of two steps. In step 1, participants create descriptions of <a href=https://en.wikipedia.org/wiki/Emotion>emotional events</a> for a given emotion. In step 2, five annotators assess the emotion expressed by the texts. We show that transferring an emotion classification model from the original English ISEAR to the German crowdsourced deISEAR via <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> does not, on average, cause a performance drop.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1393.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1393 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1393 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1393" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1393/>Does it Make Sense? And Why? A Pilot Study for Sense Making and Explanation</a></strong><br><a href=/people/c/cunxiang-wang/>Cunxiang Wang</a>
|
<a href=/people/s/shuailong-liang/>Shuailong Liang</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a>
|
<a href=/people/x/xiaonan-li/>Xiaonan Li</a>
|
<a href=/people/t/tian-gao/>Tian Gao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1393><div class="card-body p-3 small">Introducing <a href=https://en.wikipedia.org/wiki/Common_sense>common sense</a> to <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding systems</a> has received increasing research attention. It remains a fundamental question on how to evaluate whether a <a href=https://en.wikipedia.org/wiki/System>system</a> has the sense-making capability. Existing <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmarks</a> measure <a href=https://en.wikipedia.org/wiki/Common_sense>common sense knowledge</a> indirectly or without <a href=https://en.wikipedia.org/wiki/Reason>reasoning</a>. In this paper, we release a <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmark</a> to directly test whether a <a href=https://en.wikipedia.org/wiki/System>system</a> can differentiate natural language statements that make sense from those that do not make sense. In addition, a system is asked to identify the most crucial reason why a statement does not make sense. We evaluate <a href=https://en.wikipedia.org/wiki/Computer_simulation>models</a> trained over large-scale language modeling tasks as well as human performance, showing that there are different challenges for system sense-making.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1397.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1397 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1397 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1397/>Exploiting Invertible Decoders for Unsupervised Sentence Representation Learning</a></strong><br><a href=/people/s/shuai-tang/>Shuai Tang</a>
|
<a href=/people/v/virginia-r-de-sa/>Virginia R. de Sa</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1397><div class="card-body p-3 small">Encoder-decoder models for unsupervised sentence representation learning using the <a href=https://en.wikipedia.org/wiki/Distributional_hypothesis>distributional hypothesis</a> effectively constrain the learnt representation of a sentence to only that needed to reproduce the next sentence. While the <a href=https://en.wikipedia.org/wiki/Encoder>decoder</a> is important to constrain the representation, these models tend to discard the <a href=https://en.wikipedia.org/wiki/Encoder>decoder</a> after training since only the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> is needed to map the input sentence into a <a href=https://en.wikipedia.org/wiki/Vector_space>vector representation</a>. However, parameters learnt in the <a href=https://en.wikipedia.org/wiki/Codec>decoder</a> also contain useful information about the language. In order to utilise the <a href=https://en.wikipedia.org/wiki/Codec>decoder</a> after learning, we present two types of decoding functions whose inverse can be easily derived without expensive inverse calculation. Therefore, the inverse of the decoding function serves as another <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> that produces <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence representations</a>. We show that, with careful design of the decoding functions, the model learns good sentence representations, and the ensemble of the <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a> produced from the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> and the inverse of the <a href=https://en.wikipedia.org/wiki/Encoder>decoder</a> demonstrate even better generalisation ability and solid transferability.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1402.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1402 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1402 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1402" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1402/>Few-Shot Representation Learning for Out-Of-Vocabulary Words</a></strong><br><a href=/people/z/ziniu-hu/>Ziniu Hu</a>
|
<a href=/people/t/ting-chen/>Ting Chen</a>
|
<a href=/people/k/kai-wei-chang/>Kai-Wei Chang</a>
|
<a href=/people/y/yizhou-sun/>Yizhou Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1402><div class="card-body p-3 small">Existing approaches for learning word embedding often assume there are sufficient occurrences for each word in the corpus, such that the representation of words can be accurately estimated from their contexts. However, in real-world scenarios, out-of-vocabulary (a.k.a. OOV) words that do not appear in training corpus emerge frequently. How to learn accurate representations of these words to augment a pre-trained embedding by only a few observations is a challenging research problem. In this paper, we formulate the learning of OOV embedding as a few-shot regression problem by fitting a representation function to predict an oracle embedding vector (defined as <a href=https://en.wikipedia.org/wiki/Embedding>embedding</a> trained with abundant observations) based on limited contexts. Specifically, we propose a novel hierarchical attention network-based embedding framework to serve as the neural regression function, in which the context information of a word is encoded and aggregated from K observations. Furthermore, we propose to use Model-Agnostic Meta-Learning (MAML) for adapting the learned model to the new <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> fast and robustly. Experiments show that the proposed approach significantly outperforms existing methods in constructing an accurate <a href=https://en.wikipedia.org/wiki/Embedding>embedding</a> for OOV words and improves downstream tasks when the <a href=https://en.wikipedia.org/wiki/Embedding>embedding</a> is utilized.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1407.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1407 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1407 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1407/>Keeping Notes : Conditional Natural Language Generation with a Scratchpad Encoder</a></strong><br><a href=/people/r/ryan-benmalek/>Ryan Benmalek</a>
|
<a href=/people/m/madian-khabsa/>Madian Khabsa</a>
|
<a href=/people/s/suma-desu/>Suma Desu</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a>
|
<a href=/people/m/michele-banko/>Michele Banko</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1407><div class="card-body p-3 small">We introduce the Scratchpad Mechanism, a novel addition to the sequence-to-sequence (seq2seq) neural network architecture and demonstrate its effectiveness in improving the overall fluency of seq2seq models for natural language generation tasks. By enabling the decoder at each time step to write to all of the <a href=https://en.wikipedia.org/wiki/Encoder>encoder output layers</a>, <a href=https://en.wikipedia.org/wiki/Scratchpad>Scratchpad</a> can employ the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> as a <a href=https://en.wikipedia.org/wiki/Scratchpad_memory>scratchpad memory</a> to keep track of what has been generated so far and thereby guide future generation. We evaluate <a href=https://en.wikipedia.org/wiki/Scratchpad>Scratchpad</a> in the context of three well-studied natural language generation tasks <a href=https://en.wikipedia.org/wiki/Machine_translation>Machine Translation</a>, Question Generation, and Text Summarization and obtain state-of-the-art or comparable performance on standard datasets for each task. Qualitative assessments in the form of human judgements (question generation), attention visualization (MT), and sample output (summarization) provide further evidence of the ability of <a href=https://en.wikipedia.org/wiki/Scratchpad>Scratchpad</a> to generate fluent and expressive output.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1408.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1408 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1408 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385196786 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1408" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1408/>Using Automatically Extracted Minimum Spans to Disentangle Coreference Evaluation from Boundary Detection</a></strong><br><a href=/people/n/nafise-sadat-moosavi/>Nafise Sadat Moosavi</a>
|
<a href=/people/l/leo-born/>Leo Born</a>
|
<a href=/people/m/massimo-poesio/>Massimo Poesio</a>
|
<a href=/people/m/michael-strube/>Michael Strube</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1408><div class="card-body p-3 small">The common practice in <a href=https://en.wikipedia.org/wiki/Coreference_resolution>coreference resolution</a> is to identify and evaluate the maximum span of mentions. The use of maximum spans tangles coreference evaluation with the challenges of mention boundary detection like prepositional phrase attachment. To address this problem, minimum spans are manually annotated in smaller corpora. However, this additional annotation is costly and therefore, this solution does not scale to large corpora. In this paper, we propose the MINA algorithm for automatically extracting minimum spans to benefit from minimum span evaluation in all corpora. We show that the extracted minimum spans by MINA are consistent with those that are manually annotated by experts. Our experiments show that using minimum spans is in particular important in cross-dataset coreference evaluation, in which detected mention boundaries are noisier due to domain shift. We have integrated MINA into https://github.com/ns-moosavi/coval for reporting standard coreference scores based on both maximum and automatically detected minimum spans.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1410.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1410 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1410 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1410.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385254497 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1410" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1410/>A Unified Linear-Time Framework for Sentence-Level Discourse Parsing</a></strong><br><a href=/people/x/xiang-lin/>Xiang Lin</a>
|
<a href=/people/s/shafiq-joty/>Shafiq Joty</a>
|
<a href=/people/p/prathyusha-jwalapuram/>Prathyusha Jwalapuram</a>
|
<a href=/people/m/m-saiful-bari/>M Saiful Bari</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1410><div class="card-body p-3 small">We propose an efficient neural framework for sentence-level discourse analysis in accordance with Rhetorical Structure Theory (RST). Our framework comprises a discourse segmenter to identify the elementary discourse units (EDU) in a text, and a discourse parser that constructs a discourse tree in a top-down fashion. Both the segmenter and the <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> are based on Pointer Networks and operate in <a href=https://en.wikipedia.org/wiki/Time_complexity>linear time</a>. Our segmenter yields an F1 score of 95.4 %, and our parser achieves an F1 score of 81.7 % on the aggregated labeled (relation) metric, surpassing previous approaches by a good margin and approaching human agreement on both tasks (98.3 and 83.0 F1).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1411.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1411 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1411 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385254810 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1411/>Employing the Correspondence of Relations and Connectives to Identify Implicit Discourse Relations via Label Embeddings</a></strong><br><a href=/people/l/linh-the-nguyen/>Linh The Nguyen</a>
|
<a href=/people/l/linh-van-ngo/>Linh Van Ngo</a>
|
<a href=/people/k/khoat-than/>Khoat Than</a>
|
<a href=/people/t/thien-huu-nguyen/>Thien Huu Nguyen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1411><div class="card-body p-3 small">It has been shown that implicit connectives can be exploited to improve the performance of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> for implicit discourse relation recognition (IDRR). An important property of the implicit connectives is that they can be accurately mapped into the <a href=https://en.wikipedia.org/wiki/Discourse_relation>discourse relations</a> conveying their functions. In this work, we explore this property in a multi-task learning framework for IDRR in which the <a href=https://en.wikipedia.org/wiki/Binary_relation>relations</a> and the <a href=https://en.wikipedia.org/wiki/Binary_relation>connectives</a> are simultaneously predicted, and the mapping is leveraged to transfer knowledge between the two prediction tasks via the embeddings of relations and connectives. We propose several techniques to enable such knowledge transfer that yield the state-of-the-art performance for IDRR on several settings of the benchmark dataset (i.e., the Penn Discourse Treebank dataset).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1417.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1417 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1417 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385198664 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1417" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1417/>Improving <a href=https://en.wikipedia.org/wiki/Question_answering>Question Answering</a> over Incomplete KBs with Knowledge-Aware Reader<span class=acl-fixed-case>KB</span>s with Knowledge-Aware Reader</a></strong><br><a href=/people/w/wenhan-xiong/>Wenhan Xiong</a>
|
<a href=/people/m/mo-yu/>Mo Yu</a>
|
<a href=/people/s/shiyu-chang/>Shiyu Chang</a>
|
<a href=/people/x/xiaoxiao-guo/>Xiaoxiao Guo</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1417><div class="card-body p-3 small">We propose a new end-to-end question answering model, which learns to aggregate answer evidence from an incomplete knowledge base (KB) and a set of retrieved text snippets. Under the assumptions that structured data is easier to query and the acquired knowledge can help the understanding of unstructured text, our model first accumulates knowledge ofKB entities from a question-related KB sub-graph ; then reformulates the question in the latent space and reads the text with the accumulated entity knowledge at hand. The evidence from KB and <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>text</a> are finally aggregated to predict answers. On the widely-used KBQA benchmark WebQSP, our model achieves consistent improvements across settings with different extents of KB incompleteness.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1418.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1418 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1418 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1418.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1418/>AdaNSP : Uncertainty-driven Adaptive Decoding in Neural Semantic Parsing<span class=acl-fixed-case>A</span>da<span class=acl-fixed-case>NSP</span>: Uncertainty-driven Adaptive Decoding in Neural Semantic Parsing</a></strong><br><a href=/people/x/xiang-zhang/>Xiang Zhang</a>
|
<a href=/people/s/shizhu-he/>Shizhu He</a>
|
<a href=/people/k/kang-liu/>Kang Liu</a>
|
<a href=/people/j/jun-zhao/>Jun Zhao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1418><div class="card-body p-3 small">Neural semantic parsers utilize the encoder-decoder framework to learn an end-to-end model for semantic parsing that transduces a natural language sentence to the formal semantic representation. To keep the model aware of the underlying grammar in target sequences, many constrained decoders were devised in a multi-stage paradigm, which decode to the sketches or abstract syntax trees first, and then decode to target semantic tokens. We instead to propose an adaptive decoding method to avoid such intermediate representations. The <a href=https://en.wikipedia.org/wiki/Codec>decoder</a> is guided by model uncertainty and automatically uses deeper computations when necessary. Thus <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> can predict tokens adaptively. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms the state-of-the-art neural models and does not need any expertise like predefined grammar or <a href=https://en.wikipedia.org/wiki/Sketch_(drawing)>sketches</a> in the meantime.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1419.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1419 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1419 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1419.Supplementary.zip data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1419.Presentation.pdf data-toggle=tooltip data-placement=top title=Presentation><i class="fas fa-file-powerpoint"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385198774 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1419" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1419/>The Language of Legal and Illegal Activity on the <a href=https://en.wikipedia.org/wiki/Darknet>Darknet</a><span class=acl-fixed-case>D</span>arknet</a></strong><br><a href=/people/l/leshem-choshen/>Leshem Choshen</a>
|
<a href=/people/d/dan-eldad/>Dan Eldad</a>
|
<a href=/people/d/daniel-hershcovich/>Daniel Hershcovich</a>
|
<a href=/people/e/elior-sulem/>Elior Sulem</a>
|
<a href=/people/o/omri-abend/>Omri Abend</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1419><div class="card-body p-3 small">The non-indexed parts of the Internet (the Darknet) have become a haven for both legal and illegal anonymous activity. Given the magnitude of these <a href=https://en.wikipedia.org/wiki/Computer_network>networks</a>, scalably monitoring their activity necessarily relies on automated tools, and notably on <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP tools</a>. However, little is known about what characteristics texts communicated through the <a href=https://en.wikipedia.org/wiki/Darknet>Darknet</a> have, and how well do off-the-shelf NLP tools do on this domain. This paper tackles this gap and performs an in-depth investigation of the characteristics of legal and illegal text in the <a href=https://en.wikipedia.org/wiki/Darknet>Darknet</a>, comparing it to a clear net website with similar content as a control condition. Taking drugs-related websites as a test case, we find that texts for selling legal and illegal drugs have several linguistic characteristics that distinguish them from one another, as well as from the control condition, among them the distribution of POS tags, and the coverage of their named entities in <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1425.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1425 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1425 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1425/>Robust Neural Machine Translation with Doubly Adversarial Inputs</a></strong><br><a href=/people/y/yong-cheng/>Yong Cheng</a>
|
<a href=/people/l/lu-jiang/>Lu Jiang</a>
|
<a href=/people/w/wolfgang-macherey/>Wolfgang Macherey</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1425><div class="card-body p-3 small">Neural machine translation (NMT) often suffers from the vulnerability to noisy perturbations in the input. We propose an approach to improving the <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> of NMT models, which consists of two parts : (1) attack the translation model with adversarial source examples ; (2) defend the translation model with adversarial target inputs to improve its <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> against the adversarial source inputs. For the generation of adversarial inputs, we propose a gradient-based method to craft adversarial examples informed by the translation loss over the clean inputs. Experimental results on Chinese-English and English-German translation tasks demonstrate that our <a href=https://en.wikipedia.org/wiki/Software_development_process>approach</a> achieves significant improvements (2.8 and 1.6 BLEU points) over Transformer on standard clean benchmarks as well as exhibiting higher <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> on noisy data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1431.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1431 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1431 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385264668 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1431/>A2N : Attending to Neighbors for Knowledge Graph Inference<span class=acl-fixed-case>A</span>2<span class=acl-fixed-case>N</span>: Attending to Neighbors for Knowledge Graph Inference</a></strong><br><a href=/people/t/trapit-bansal/>Trapit Bansal</a>
|
<a href=/people/d/da-cheng-juan/>Da-Cheng Juan</a>
|
<a href=/people/s/sujith-ravi/>Sujith Ravi</a>
|
<a href=/people/a/andrew-mccallum/>Andrew McCallum</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1431><div class="card-body p-3 small">State-of-the-art models for knowledge graph completion aim at learning a fixed embedding representation of entities in a multi-relational graph which can generalize to infer unseen entity relationships at test time. This can be sub-optimal as it requires memorizing and generalizing to all possible entity relationships using these fixed representations. We thus propose a novel attention-based method to learn query-dependent representation of entities which adaptively combines the relevant graph neighborhood of an entity leading to more accurate KG completion. The proposed method is evaluated on two benchmark datasets for knowledge graph completion, and experimental results show that the proposed model performs competitively or better than existing <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a>, including recent methods for explicit multi-hop reasoning. Qualitative probing offers insight into how the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can reason about facts involving multiple hops in the <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graph</a>, through the use of neighborhood attention.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1432.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1432 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1432 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385264738 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1432/>Graph based Neural Networks for Event Factuality Prediction using Syntactic and Semantic Structures</a></strong><br><a href=/people/a/amir-pouran-ben-veyseh/>Amir Pouran Ben Veyseh</a>
|
<a href=/people/t/thien-huu-nguyen/>Thien Huu Nguyen</a>
|
<a href=/people/d/dejing-dou/>Dejing Dou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1432><div class="card-body p-3 small">Event factuality prediction (EFP) is the task of assessing the degree to which an event mentioned in a sentence has happened. For this task, both syntactic and semantic information are crucial to identify the important <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context words</a>. The previous work for EFP has only combined these information in a simple way that can not fully exploit their coordination. In this work, we introduce a novel graph-based neural network for EFP that can integrate the semantic and syntactic information more effectively. Our experiments demonstrate the advantage of the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> for EFP.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1433.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1433 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1433 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385203861 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1433" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1433/>Embedding Time Expressions for Deep Temporal Ordering Models</a></strong><br><a href=/people/t/tanya-goyal/>Tanya Goyal</a>
|
<a href=/people/g/greg-durrett/>Greg Durrett</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1433><div class="card-body p-3 small">Data-driven models have demonstrated state-of-the-art performance in inferring the temporal ordering of events in text. However, these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> often overlook explicit temporal signals, such as <a href=https://en.wikipedia.org/wiki/Calendar_date>dates</a> and time windows. Rule-based methods can be used to identify the temporal links between these time expressions (timexes), but they fail to capture timexes&#8217; interactions with events and are hard to integrate with the distributed representations of neural net models. In this paper, we introduce a framework to infuse temporal awareness into such <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> by learning a pre-trained model to embed timexes. We generate synthetic data consisting of pairs of <a href=https://en.wikipedia.org/wiki/Ternary_numeral_system>timexes</a>, then train a character LSTM to learn embeddings and classify the <a href=https://en.wikipedia.org/wiki/Ternary_numeral_system>timexes&#8217; temporal relation</a>. We evaluate the utility of these embeddings in the context of a strong neural model for event temporal ordering, and show a small increase in performance on the MATRES dataset and more substantial gains on an automatically collected dataset with more frequent event-timex interactions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1440.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1440 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1440 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1440" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1440/>Complex Question Decomposition for Semantic Parsing</a></strong><br><a href=/people/h/haoyu-zhang/>Haoyu Zhang</a>
|
<a href=/people/j/jingjing-cai/>Jingjing Cai</a>
|
<a href=/people/j/jianjun-xu/>Jianjun Xu</a>
|
<a href=/people/j/ji-wang/>Ji Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1440><div class="card-body p-3 small">In this work, we focus on complex question semantic parsing and propose a novel Hierarchical Semantic Parsing (HSP) method, which utilizes the decompositionality of complex questions for <a href=https://en.wikipedia.org/wiki/Semantic_parsing>semantic parsing</a>. Our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> is designed within a three-stage parsing architecture based on the idea of decomposition-integration. In the first stage, we propose a question decomposer which decomposes a complex question into a sequence of sub-questions. In the second stage, we design an <a href=https://en.wikipedia.org/wiki/Information_extraction>information extractor</a> to derive the type and predicate information of these questions. In the last stage, we integrate the generated information from previous stages and generate a <a href=https://en.wikipedia.org/wiki/Logical_form>logical form</a> for the complex question. We conduct experiments on COMPLEXWEBQUESTIONS which is a large scale complex question semantic parsing dataset, results show that our model achieves significant improvement compared to state-of-the-art methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1444.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1444 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1444 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1444.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1444" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1444/>Towards Complex Text-to-SQL in Cross-Domain Database with Intermediate Representation<span class=acl-fixed-case>SQL</span> in Cross-Domain Database with Intermediate Representation</a></strong><br><a href=/people/j/jiaqi-guo/>Jiaqi Guo</a>
|
<a href=/people/z/zecheng-zhan/>Zecheng Zhan</a>
|
<a href=/people/y/yan-gao/>Yan Gao</a>
|
<a href=/people/y/yan-xiao/>Yan Xiao</a>
|
<a href=/people/j/jian-guang-lou/>Jian-Guang Lou</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a>
|
<a href=/people/d/dongmei-zhang/>Dongmei Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1444><div class="card-body p-3 small">We present a neural approach called IRNet for complex and cross-domain Text-to-SQL. IRNet aims to address two challenges : 1) the mismatch between intents expressed in natural language (NL) and the implementation details in <a href=https://en.wikipedia.org/wiki/SQL>SQL</a> ; 2) the challenge in predicting columns caused by the large number of out-of-domain words. Instead of end-to-end synthesizing a <a href=https://en.wikipedia.org/wiki/SQL>SQL query</a>, IRNet decomposes the synthesis process into three phases. In the first phase, IRNet performs a schema linking over a question and a <a href=https://en.wikipedia.org/wiki/Database_schema>database schema</a>. Then, IRNet adopts a grammar-based neural model to synthesize a SemQL query which is an intermediate representation that we design to bridge <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NL</a> and <a href=https://en.wikipedia.org/wiki/SQL>SQL</a>. Finally, IRNet deterministically infers a <a href=https://en.wikipedia.org/wiki/SQL>SQL query</a> from the synthesized SemQL query with <a href=https://en.wikipedia.org/wiki/Domain_knowledge>domain knowledge</a>. On the challenging Text-to-SQL benchmark Spider, IRNet achieves 46.7 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, obtaining 19.5 % absolute improvement over previous <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>state-of-the-art approaches</a>. At the time of writing, IRNet achieves the first position on the Spider leaderboard.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1447.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1447 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1447 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1447/>Reranking for Neural Semantic Parsing</a></strong><br><a href=/people/p/pengcheng-yin/>Pengcheng Yin</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1447><div class="card-body p-3 small">Semantic parsing considers the task of transducing natural language (NL) utterances into machine executable meaning representations (MRs). While neural network-based semantic parsers have achieved impressive improvements over previous methods, results are still far from perfect, and cursory manual inspection can easily identify obvious problems such as lack of adequacy or coherence of the generated MRs. This paper presents a simple approach to quickly iterate and improve the performance of an existing neural semantic parser by reranking an n-best list of predicted MRs, using <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> that are designed to fix observed problems with baseline models. We implement our reranker in a competitive neural semantic parser and test on four semantic parsing (GEO, ATIS) and Python code generation (Django, CoNaLa) tasks, improving the strong baseline parser by up to 5.7 % absolute in BLEU (CoNaLa) and 2.9 % in accuracy (Django), outperforming the best published neural parser results on all four datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1448.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1448 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1448 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1448.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1448" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1448/>Representing Schema Structure with Graph Neural Networks for Text-to-SQL Parsing<span class=acl-fixed-case>SQL</span> Parsing</a></strong><br><a href=/people/b/ben-bogin/>Ben Bogin</a>
|
<a href=/people/j/jonathan-berant/>Jonathan Berant</a>
|
<a href=/people/m/matt-gardner/>Matt Gardner</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1448><div class="card-body p-3 small">Research on <a href=https://en.wikipedia.org/wiki/Parsing>parsing language</a> to <a href=https://en.wikipedia.org/wiki/SQL>SQL</a> has largely ignored the structure of the <a href=https://en.wikipedia.org/wiki/Database_schema>database (DB) schema</a>, either because the <a href=https://en.wikipedia.org/wiki/Database>DB</a> was very simple, or because it was observed at both training and test time. In spider, a recently-released text-to-SQL dataset, new and complex DBs are given at test time, and so the structure of the <a href=https://en.wikipedia.org/wiki/Database_schema>DB schema</a> can inform the predicted SQL query. In this paper, we present an encoder-decoder semantic parser, where the structure of the <a href=https://en.wikipedia.org/wiki/Database_schema>DB schema</a> is encoded with a graph neural network, and this representation is later used at both encoding and decoding time. Evaluation shows that encoding the schema structure improves our <a href=https://en.wikipedia.org/wiki/Parsing>parser accuracy</a> from 33.8 % to 39.4 %, dramatically above the current state of the art, which is at 19.7 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1449.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1449 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1449 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1449/>Human vs. Muppet : A Conservative Estimate of Human Performance on the GLUE Benchmark<span class=acl-fixed-case>GLUE</span> Benchmark</a></strong><br><a href=/people/n/nikita-nangia/>Nikita Nangia</a>
|
<a href=/people/s/samuel-bowman/>Samuel R. Bowman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1449><div class="card-body p-3 small">The GLUE benchmark (Wang et al., 2019b) is a suite of language understanding tasks which has seen dramatic progress in the past year, with average performance moving from 70.0 at launch to 83.9, state of the art at the time of writing (May 24, 2019). Here, we measure human performance on the <a href=https://en.wikipedia.org/wiki/Benchmarking>benchmark</a>, in order to learn whether significant headroom remains for further progress. We provide a conservative estimate of human performance on the benchmark through <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing</a> : Our annotators are non-experts who must learn each task from a brief set of instructions and 20 examples. In spite of limited training, these <a href=https://en.wikipedia.org/wiki/Annotation>annotators</a> robustly outperform the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state of the art</a> on six of the nine GLUE tasks and achieve an average score of 87.1. Given the fast pace of progress however, the headroom we observe is quite limited. To reproduce the data-poor setting that our annotators must learn in, we also train the BERT model (Devlin et al., 2019) in limited-data regimes, and conclude that low-resource sentence classification remains a challenge for modern neural network approaches to text understanding.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1450.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1450 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1450 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1450.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1450" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1450/>Compositional Semantic Parsing across Graphbanks</a></strong><br><a href=/people/m/matthias-lindemann/>Matthias Lindemann</a>
|
<a href=/people/j/jonas-groschwitz/>Jonas Groschwitz</a>
|
<a href=/people/a/alexander-koller/>Alexander Koller</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1450><div class="card-body p-3 small">Most semantic parsers that map sentences to graph-based meaning representations are hand-designed for specific graphbanks. We present a compositional neural semantic parser which achieves, for the first time, competitive accuracies across a diverse range of graphbanks. Incorporating BERT embeddings and multi-task learning improves the accuracy further, setting new states of the art on DM, PAS, PSD, AMR 2015 and EDS.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1452.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1452 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1452 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1452/>BERT Rediscovers the Classical NLP Pipeline<span class=acl-fixed-case>BERT</span> Rediscovers the Classical <span class=acl-fixed-case>NLP</span> Pipeline</a></strong><br><a href=/people/i/ian-tenney/>Ian Tenney</a>
|
<a href=/people/d/dipanjan-das/>Dipanjan Das</a>
|
<a href=/people/e/ellie-pavlick/>Ellie Pavlick</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1452><div class="card-body p-3 small">Pre-trained text encoders have rapidly advanced the state of the art on many NLP tasks. We focus on one such <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>, BERT, and aim to quantify where linguistic information is captured within the <a href=https://en.wikipedia.org/wiki/Neural_network>network</a>. We find that the model represents the steps of the traditional NLP pipeline in an interpretable and localizable way, and that the regions responsible for each step appear in the expected sequence : POS tagging, <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a>, NER, semantic roles, then <a href=https://en.wikipedia.org/wiki/Coreference>coreference</a>. Qualitative analysis reveals that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can and often does adjust this <a href=https://en.wikipedia.org/wiki/Pipeline_(software)>pipeline</a> dynamically, revising lower-level decisions on the basis of disambiguating information from higher-level representations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1454.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1454 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1454 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1454" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1454/>Second-Order Semantic Dependency Parsing with End-to-End Neural Networks</a></strong><br><a href=/people/x/xinyu-wang/>Xinyu Wang</a>
|
<a href=/people/j/jingxian-huang/>Jingxian Huang</a>
|
<a href=/people/k/kewei-tu/>Kewei Tu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1454><div class="card-body p-3 small">Semantic dependency parsing aims to identify semantic relationships between words in a sentence that form a <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graph</a>. In this paper, we propose a second-order semantic dependency parser, which takes into consideration not only individual dependency edges but also interactions between pairs of <a href=https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms>edges</a>. We show that second-order parsing can be approximated using mean field (MF) variational inference or loopy belief propagation (LBP). We can unfold both <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> as recurrent layers of a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> and therefore can train the <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> in an end-to-end manner. Our experiments show that our <a href=https://en.wikipedia.org/wiki/Scientific_method>approach</a> achieves state-of-the-art performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1455.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1455 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1455 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1455.Poster.pdf data-toggle=tooltip data-placement=top title=Poster><i class="fas fa-file-image"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1455" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1455/>Towards Multimodal Sarcasm Detection (An _ Obviously _ Perfect Paper)<span class=acl-fixed-case>O</span>bviously_ Perfect Paper)</a></strong><br><a href=/people/s/santiago-castro/>Santiago Castro</a>
|
<a href=/people/d/devamanyu-hazarika/>Devamanyu Hazarika</a>
|
<a href=/people/v/veronica-perez-rosas/>Verónica Pérez-Rosas</a>
|
<a href=/people/r/roger-zimmermann/>Roger Zimmermann</a>
|
<a href=/people/r/rada-mihalcea/>Rada Mihalcea</a>
|
<a href=/people/s/soujanya-poria/>Soujanya Poria</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1455><div class="card-body p-3 small">Sarcasm is often expressed through several verbal and non-verbal cues, e.g., a <a href=https://en.wikipedia.org/wiki/Tone_(linguistics)>change of tone</a>, overemphasis in a word, a drawn-out syllable, or a straight looking face. Most of the recent work in sarcasm detection has been carried out on <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>textual data</a>. In this paper, we argue that incorporating multimodal cues can improve the automatic classification of sarcasm. As a first step towards enabling the development of multimodal approaches for sarcasm detection, we propose a new sarcasm dataset, Multimodal Sarcasm Detection Dataset (MUStARD), compiled from popular TV shows. MUStARD consists of <a href=https://en.wikipedia.org/wiki/Audiovisual>audiovisual utterances</a> annotated with <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm labels</a>. Each utterance is accompanied by its context of historical utterances in the dialogue, which provides additional information on the scenario where the utterance occurs. Our initial results show that the use of multimodal information can reduce the relative error rate of sarcasm detection by up to 12.9 % in <a href=https://en.wikipedia.org/wiki/F-score>F-score</a> when compared to the use of individual modalities. The full dataset is publicly available for use at https://github.com/soujanyaporia/MUStARD.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1458.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1458 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1458 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1458/>An Investigation of Transfer Learning-Based Sentiment Analysis in <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a><span class=acl-fixed-case>J</span>apanese</a></strong><br><a href=/people/e/enkhbold-bataa/>Enkhbold Bataa</a>
|
<a href=/people/j/joshua-wu/>Joshua Wu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1458><div class="card-body p-3 small">Text classification approaches have usually required task-specific model architectures and huge labeled datasets. Recently, thanks to the rise of text-based transfer learning techniques, it is possible to pre-train a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> in an unsupervised manner and leverage them to perform effective on downstream tasks. In this work we focus on <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a> and show the potential use of <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning techniques</a> in <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a>. Specifically, we perform binary and multi-class sentiment classification on the Rakuten product review and Yahoo movie review datasets. We show that transfer learning-based approaches perform better than task-specific models trained on 3 times as much data. Furthermore, these approaches perform just as well for <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a> pre-trained on only 1/30 of the data. We release our <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>pre-trained models</a> and code as open source.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1459.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1459 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1459 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1459" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1459/>Probing Neural Network Comprehension of Natural Language Arguments</a></strong><br><a href=/people/t/timothy-niven/>Timothy Niven</a>
|
<a href=/people/h/hung-yu-kao/>Hung-Yu Kao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1459><div class="card-body p-3 small">We are surprised to find that BERT&#8217;s peak performance of 77 % on the Argument Reasoning Comprehension Task reaches just three points below the average untrained human baseline. However, we show that this result is entirely accounted for by exploitation of spurious statistical cues in the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. We analyze the nature of these <a href=https://en.wikipedia.org/wiki/Sensory_cue>cues</a> and demonstrate that a range of <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> all exploit them. This analysis informs the construction of an adversarial dataset on which all <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> achieve random accuracy. Our adversarial dataset provides a more robust assessment of argument comprehension and should be adopted as the standard in future work.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1461.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1461 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1461 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1461.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1461" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1461/>Toward Comprehensive Understanding of a Sentiment Based on Human Motives</a></strong><br><a href=/people/n/naoki-otani/>Naoki Otani</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1461><div class="card-body p-3 small">In sentiment detection, the natural language processing community has focused on determining holders, <a href=https://en.wikipedia.org/wiki/Facet_(psychology)>facets</a>, and <a href=https://en.wikipedia.org/wiki/Valence_(linguistics)>valences</a>, but has paid little attention to the reasons for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment decisions</a>. Our work considers <a href=https://en.wikipedia.org/wiki/Motivation>human motives</a> as the driver for <a href=https://en.wikipedia.org/wiki/Sentimentality>human sentiments</a> and addresses the problem of motive detection as the first step. Following a study in <a href=https://en.wikipedia.org/wiki/Psychology>psychology</a>, we define six basic motives that cover a wide range of topics appearing in review texts, annotate 1,600 texts in restaurant and laptop domains with the motives, and report the performance of baseline methods on this new dataset. We also show that cross-domain transfer learning boosts <a href=https://en.wikipedia.org/wiki/Detection_theory>detection</a> performance, which indicates that these universal motives exist across different domains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1462.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1462 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1462 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1462/>Context-aware Embedding for Targeted Aspect-based Sentiment Analysis</a></strong><br><a href=/people/b/bin-liang/>Bin Liang</a>
|
<a href=/people/j/jiachen-du/>Jiachen Du</a>
|
<a href=/people/r/ruifeng-xu/>Ruifeng Xu</a>
|
<a href=/people/b/binyang-li/>Binyang Li</a>
|
<a href=/people/h/hejiao-huang/>Hejiao Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1462><div class="card-body p-3 small">Attention-based neural models were employed to detect the different aspects and sentiment polarities of the same target in targeted aspect-based sentiment analysis (TABSA). However, existing methods do not specifically pre-train reasonable <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> for targets and aspects in TABSA. This may result in targets or aspects having the same <a href=https://en.wikipedia.org/wiki/Vector_graphics>vector representations</a> in different contexts and losing the context-dependent information. To address this problem, we propose a novel <a href=https://en.wikipedia.org/wiki/Methodology>method</a> to refine the embeddings of targets and aspects. Such pivotal embedding refinement utilizes a sparse coefficient vector to adjust the embeddings of target and aspect from the context. Hence the embeddings of targets and aspects can be refined from the highly correlative words instead of using context-independent or randomly initialized vectors. Experiment results on two benchmark datasets show that our approach yields the state-of-the-art performance in TABSA task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1466.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1466 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1466 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1466" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1466/>Learning Attention-based Embeddings for Relation Prediction in Knowledge Graphs</a></strong><br><a href=/people/d/deepak-nathani/>Deepak Nathani</a>
|
<a href=/people/j/jatin-chauhan/>Jatin Chauhan</a>
|
<a href=/people/c/charu-sharma/>Charu Sharma</a>
|
<a href=/people/m/manohar-kaul/>Manohar Kaul</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1466><div class="card-body p-3 small">The recent proliferation of knowledge graphs (KGs) coupled with incomplete or partial information, in the form of missing relations (links) between entities, has fueled a lot of research on knowledge base completion (also known as relation prediction). Several recent works suggest that convolutional neural network (CNN) based models generate richer and more expressive feature embeddings and hence also perform well on relation prediction. However, we observe that these KG embeddings treat triples independently and thus fail to cover the complex and hidden information that is inherently implicit in the <a href=https://en.wikipedia.org/wiki/Neighbourhood_(mathematics)>local neighborhood</a> surrounding a triple. To this effect, our paper proposes a novel attention-based feature embedding that captures both entity and relation features in any given entity&#8217;s neighborhood. Additionally, we also encapsulate relation clusters and multi-hop relations in our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. Our empirical study offers insights into the efficacy of our attention-based model and we show marked performance gains in comparison to state-of-the-art methods on all datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1467.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1467 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1467 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1467/>Neural Network Alignment for Sentential Paraphrases</a></strong><br><a href=/people/j/jessica-ouyang/>Jessica Ouyang</a>
|
<a href=/people/k/kathleen-mckeown/>Kathy McKeown</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1467><div class="card-body p-3 small">We present a monolingual alignment system for long, sentence- or clause-level alignments, and demonstrate that systems designed for word- or short phrase-based alignment are ill-suited for these longer alignments. Our <a href=https://en.wikipedia.org/wiki/System>system</a> is capable of aligning semantically similar spans of arbitrary length. We achieve significantly higher <a href=https://en.wikipedia.org/wiki/Recall_(memory)>recall</a> on aligning phrases of four or more words and outperform state-of-the- art aligners on the long alignments in the MSR RTE corpus.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1468.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1468 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1468 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1468" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1468/>Duality of Link Prediction and Entailment Graph Induction</a></strong><br><a href=/people/m/mohammad-javad-hosseini/>Mohammad Javad Hosseini</a>
|
<a href=/people/s/shay-b-cohen/>Shay B. Cohen</a>
|
<a href=/people/m/mark-johnson/>Mark Johnson</a>
|
<a href=/people/m/mark-steedman/>Mark Steedman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1468><div class="card-body p-3 small">Link prediction and entailment graph induction are often treated as different problems. In this paper, we show that these two <a href=https://en.wikipedia.org/wiki/Problem_solving>problems</a> are actually complementary. We train a link prediction model on a knowledge graph of assertions extracted from raw text. We propose an <a href=https://en.wikipedia.org/wiki/Logical_consequence>entailment score</a> that exploits the new facts discovered by the link prediction model, and then form entailment graphs between relations. We further use the learned <a href=https://en.wikipedia.org/wiki/Logical_consequence>entailments</a> to predict improved link prediction scores. Our results show that the two <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> can benefit from each other. The new entailment score outperforms prior state-of-the-art results on a standard entialment dataset and the new link prediction scores show improvements over the raw link prediction scores.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1470.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1470 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1470 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1470" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1470/>COMET : Commonsense Transformers for Automatic Knowledge Graph Construction<span class=acl-fixed-case>COMET</span>: Commonsense Transformers for Automatic Knowledge Graph Construction</a></strong><br><a href=/people/a/antoine-bosselut/>Antoine Bosselut</a>
|
<a href=/people/h/hannah-rashkin/>Hannah Rashkin</a>
|
<a href=/people/m/maarten-sap/>Maarten Sap</a>
|
<a href=/people/c/chaitanya-malaviya/>Chaitanya Malaviya</a>
|
<a href=/people/a/asli-celikyilmaz/>Asli Celikyilmaz</a>
|
<a href=/people/y/yejin-choi/>Yejin Choi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1470><div class="card-body p-3 small">We present the first comprehensive study on automatic knowledge base construction for two prevalent commonsense knowledge graphs : <a href=https://en.wikipedia.org/wiki/ATOMIC>ATOMIC</a> (Sap et al., 2019) and <a href=https://en.wikipedia.org/wiki/ConceptNet>ConceptNet</a> (Speer et al., 2017). Contrary to many conventional <a href=https://en.wikipedia.org/wiki/Knowledge_base>KBs</a> that store knowledge with canonical templates, commonsense KBs only store loosely structured open-text descriptions of knowledge. We posit that an important step toward automatic commonsense completion is the development of generative models of commonsense knowledge, and propose COMmonsEnse Transformers (COMET) that learn to generate rich and diverse commonsense descriptions in natural language. Despite the challenges of commonsense modeling, our investigation reveals promising results when <a href=https://en.wikipedia.org/wiki/Implicit_knowledge>implicit knowledge</a> from deep pre-trained language models is transferred to generate <a href=https://en.wikipedia.org/wiki/Explicit_knowledge>explicit knowledge</a> in commonsense knowledge graphs. Empirical results demonstrate that COMET is able to generate novel knowledge that humans rate as high quality, with up to 77.5 % (ATOMIC) and 91.7 % (ConceptNet) precision at top 1, which approaches human performance for these resources. Our findings suggest that using generative commonsense models for automatic commonsense KB completion could soon be a plausible alternative to extractive methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1476.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1476 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1476 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1476" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1476/>Generalized Tuning of Distributional Word Vectors for Monolingual and Cross-Lingual Lexical Entailment</a></strong><br><a href=/people/g/goran-glavas/>Goran Glavaš</a>
|
<a href=/people/i/ivan-vulic/>Ivan Vulić</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1476><div class="card-body p-3 small">Lexical entailment (LE ; also known as <a href=https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy>hyponymy-hypernymy</a> or is-a relation) is a core asymmetric lexical relation that supports tasks like <a href=https://en.wikipedia.org/wiki/Taxonomy_(general)>taxonomy induction</a> and text generation. In this work, we propose a simple and effective method for fine-tuning distributional word vectors for LE. Our Generalized Lexical ENtailment model (GLEN) is decoupled from the word embedding model and applicable to any distributional vector space. Yet unlike existing retrofitting models it captures a general specialization function allowing for LE-tuning of the entire distributional space and not only the vectors of words seen in lexical constraints. Coupled with a multilingual embedding space, GLEN seamlessly enables cross-lingual LE detection. We demonstrate the effectiveness of GLEN in graded LE and report large improvements (over 20 % in accuracy) over <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> in cross-lingual LE detection.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1478.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1478 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1478 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1478/>A Surprisingly Robust Trick for the Winograd Schema Challenge<span class=acl-fixed-case>W</span>inograd Schema Challenge</a></strong><br><a href=/people/v/vid-kocijan/>Vid Kocijan</a>
|
<a href=/people/a/ana-maria-cretu/>Ana-Maria Cretu</a>
|
<a href=/people/o/oana-maria-camburu/>Oana-Maria Camburu</a>
|
<a href=/people/y/yordan-yordanov/>Yordan Yordanov</a>
|
<a href=/people/t/thomas-lukasiewicz/>Thomas Lukasiewicz</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1478><div class="card-body p-3 small">The Winograd Schema Challenge (WSC) dataset WSC273 and its inference counterpart WNLI are popular benchmarks for <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a> and <a href=https://en.wikipedia.org/wiki/Commonsense_reasoning>commonsense reasoning</a>. In this paper, we show that the performance of three language models on WSC273 consistently and robustly improves when fine-tuned on a similar pronoun disambiguation problem dataset (denoted WSCR). We additionally generate a large unsupervised WSC-like dataset. By fine-tuning the BERT language model both on the introduced and on the WSCR dataset, we achieve overall accuracies of 72.5 % and 74.7 % on WSC273 and WNLI, improving the previous state-of-the-art solutions by 8.8 % and 9.6 %, respectively. Furthermore, our fine-tuned models are also consistently more accurate on the complex subsets of WSC273, introduced by Trichelair et al.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1482.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1482 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1482 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385265051 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1482/>A Hierarchical Reinforced Sequence Operation Method for Unsupervised Text Style Transfer</a></strong><br><a href=/people/c/chen-wu/>Chen Wu</a>
|
<a href=/people/x/xuancheng-ren/>Xuancheng Ren</a>
|
<a href=/people/f/fuli-luo/>Fuli Luo</a>
|
<a href=/people/x/xu-sun/>Xu Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1482><div class="card-body p-3 small">Unsupervised text style transfer aims to alter <a href=https://en.wikipedia.org/wiki/Style_guide>text styles</a> while preserving the content, without aligned data for <a href=https://en.wikipedia.org/wiki/Supervisor>supervision</a>. Existing seq2seq methods face three challenges : 1) the transfer is weakly interpretable, 2) generated outputs struggle in content preservation, and 3) the trade-off between content and style is intractable. To address these challenges, we propose a hierarchical reinforced sequence operation method, named Point-Then-Operate (PTO), which consists of a high-level agent that proposes operation positions and a low-level agent that alters the sentence. We provide comprehensive training objectives to control the fluency, style, and content of the outputs and a mask-based inference algorithm that allows for multi-step revision based on the single-step trained agents. Experimental results on two text style transfer datasets show that our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> significantly outperforms recent methods and effectively addresses the aforementioned challenges.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1487.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1487 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1487 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385213801 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1487/>Explain Yourself ! Leveraging <a href=https://en.wikipedia.org/wiki/Language_model>Language Models</a> for Commonsense Reasoning</a></strong><br><a href=/people/n/nazneen-fatema-rajani/>Nazneen Fatema Rajani</a>
|
<a href=/people/b/bryan-mccann/>Bryan McCann</a>
|
<a href=/people/c/caiming-xiong/>Caiming Xiong</a>
|
<a href=/people/r/richard-socher/>Richard Socher</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1487><div class="card-body p-3 small">Deep learning models perform poorly on tasks that require <a href=https://en.wikipedia.org/wiki/Commonsense_reasoning>commonsense reasoning</a>, which often necessitates some form of world-knowledge or reasoning over information not immediately present in the input. We collect human explanations for <a href=https://en.wikipedia.org/wiki/Commonsense_reasoning>commonsense reasoning</a> in the form of <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language sequences</a> and highlighted annotations in a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> called Common Sense Explanations (CoS-E). We use CoS-E to train language models to automatically generate explanations that can be used during <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training</a> and <a href=https://en.wikipedia.org/wiki/Statistical_inference>inference</a> in a novel Commonsense Auto-Generated Explanation (CAGE) framework. CAGE improves the state-of-the-art by 10 % on the challenging CommonsenseQA task. We further study <a href=https://en.wikipedia.org/wiki/Commonsense_reasoning>commonsense reasoning</a> in DNNs using both human and auto-generated explanations including transfer to out-of-domain tasks. Empirical results indicate that we can effectively leverage <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> for <a href=https://en.wikipedia.org/wiki/Commonsense_reasoning>commonsense reasoning</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1488.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1488 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1488 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385215761 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1488/>Interpretable Question Answering on <a href=https://en.wikipedia.org/wiki/Knowledge_base>Knowledge Bases</a> and Text</a></strong><br><a href=/people/a/alona-sydorova/>Alona Sydorova</a>
|
<a href=/people/n/nina-poerner/>Nina Poerner</a>
|
<a href=/people/b/benjamin-roth/>Benjamin Roth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1488><div class="card-body p-3 small">Interpretability of <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning (ML) models</a> becomes more relevant with their increasing adoption. In this work, we address the <a href=https://en.wikipedia.org/wiki/Interpretability>interpretability</a> of <a href=https://en.wikipedia.org/wiki/Question_answering>ML based question answering (QA) models</a> on a combination of <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge bases (KB)</a> and text documents. We adapt post hoc explanation methods such as LIME and input perturbation (IP) and compare them with the self-explanatory attention mechanism of the model. For this purpose, we propose an automatic evaluation paradigm for explanation methods in the context of <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA</a>. We also conduct a study with human annotators to evaluate whether explanations help them identify better QA models. Our results suggest that IP provides better explanations than LIME or <a href=https://en.wikipedia.org/wiki/Attention>attention</a>, according to both automatic and human evaluation. We obtain the same ranking of methods in both experiments, which supports the validity of our automatic evaluation paradigm.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1490.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1490 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1490 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1490.Supplementary.zip data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385216016 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1490/>Multilingual and Cross-Lingual Graded Lexical Entailment</a></strong><br><a href=/people/i/ivan-vulic/>Ivan Vulić</a>
|
<a href=/people/s/simone-paolo-ponzetto/>Simone Paolo Ponzetto</a>
|
<a href=/people/g/goran-glavas/>Goran Glavaš</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1490><div class="card-body p-3 small">Grounded in <a href=https://en.wikipedia.org/wiki/Cognitive_linguistics>cognitive linguistics</a>, graded lexical entailment (GR-LE) is concerned with fine-grained assertions regarding the directional hierarchical relationships between concepts on a continuous scale. In this paper, we present the first work on cross-lingual generalisation of GR-LE relation. Starting from HyperLex, the only available GR-LE dataset in <a href=https://en.wikipedia.org/wiki/English_language>English</a>, we construct new monolingual GR-LE datasets for three other languages, and combine those to create a set of six cross-lingual GR-LE datasets termed CL-HYPERLEX. We next present a novel method dubbed CLEAR (Cross-Lingual Lexical Entailment Attract-Repel) for effectively capturing graded (and binary) LE, both monolingually in different languages as well as across languages (i.e., on CL-HYPERLEX). Coupled with a <a href=https://en.wikipedia.org/wiki/Bilingual_dictionary>bilingual dictionary</a>, CLEAR leverages <a href=https://en.wikipedia.org/wiki/Taxonomy_(biology)>taxonomic LE knowledge</a> in a resource-rich language (e.g., English) and propagates it to other languages. Supported by cross-lingual LE transfer, CLEAR sets competitive baseline performance on three new monolingual GR-LE datasets and six cross-lingual GR-LE datasets. In addition, we show that CLEAR outperforms current <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a> on binary cross-lingual LE detection by a wide margin for diverse language pairs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1492.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1492 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1492 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385218856 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1492/>Analyzing the Limitations of Cross-lingual Word Embedding Mappings</a></strong><br><a href=/people/a/aitor-ormazabal/>Aitor Ormazabal</a>
|
<a href=/people/m/mikel-artetxe/>Mikel Artetxe</a>
|
<a href=/people/g/gorka-labaka/>Gorka Labaka</a>
|
<a href=/people/a/aitor-soroa/>Aitor Soroa</a>
|
<a href=/people/e/eneko-agirre/>Eneko Agirre</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1492><div class="card-body p-3 small">Recent research in cross-lingual word embeddings has almost exclusively focused on offline methods, which independently train <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> in different languages and map them to a shared space through <a href=https://en.wikipedia.org/wiki/Linear_map>linear transformations</a>. While several authors have questioned the underlying isomorphism assumption, which states that word embeddings in different languages have approximately the same structure, it is not clear whether this is an inherent limitation of mapping approaches or a more general issue when learning cross-lingual embeddings. So as to answer this question, we experiment with parallel corpora, which allows us to compare offline mapping to an extension of <a href=https://en.wikipedia.org/wiki/Skip-gram>skip-gram</a> that jointly learns both embedding spaces. We observe that, under these ideal conditions, joint learning yields to more <a href=https://en.wikipedia.org/wiki/Isomorphism>isomorphic embeddings</a>, is less sensitive to hubness, and obtains stronger results in bilingual lexicon induction. We thus conclude that current mapping methods do have strong limitations, calling for further research to jointly learn cross-lingual embeddings with a weaker cross-lingual signal.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1494.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1494 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1494 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385219132 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1494" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1494/>Bilingual Lexicon Induction through Unsupervised Machine Translation</a></strong><br><a href=/people/m/mikel-artetxe/>Mikel Artetxe</a>
|
<a href=/people/g/gorka-labaka/>Gorka Labaka</a>
|
<a href=/people/e/eneko-agirre/>Eneko Agirre</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1494><div class="card-body p-3 small">A recent research line has obtained strong results on bilingual lexicon induction by aligning independently trained word embeddings in two languages and using the resulting cross-lingual embeddings to induce word translation pairs through nearest neighbor or related retrieval methods. In this paper, we propose an alternative approach to this problem that builds on the recent work on unsupervised machine translation. This way, instead of directly inducing a <a href=https://en.wikipedia.org/wiki/Bilingual_lexicon>bilingual lexicon</a> from cross-lingual embeddings, we use them to build a phrase-table, combine it with a language model, and use the resulting machine translation system to generate a synthetic parallel corpus, from which we extract the <a href=https://en.wikipedia.org/wiki/Bilingual_lexicon>bilingual lexicon</a> using statistical word alignment techniques. As such, our method can work with any <a href=https://en.wikipedia.org/wiki/Word_embedding>word embedding</a> and cross-lingual mapping technique, and it does not require any additional resource besides the monolingual corpus used to train the embeddings. When evaluated on the exact same cross-lingual embeddings, our proposed method obtains an average improvement of 6 accuracy points over <a href=https://en.wikipedia.org/wiki/Nearest_neighbor_search>nearest neighbor</a> and 4 points over CSLS retrieval, establishing a new state-of-the-art in the standard MUSE dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1496.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1496 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1496 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385272712 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1496/>TWEETQA : A Social Media Focused Question Answering Dataset<span class=acl-fixed-case>TWEETQA</span>: A Social Media Focused Question Answering Dataset</a></strong><br><a href=/people/w/wenhan-xiong/>Wenhan Xiong</a>
|
<a href=/people/j/jiawei-wu/>Jiawei Wu</a>
|
<a href=/people/h/hong-wang/>Hong Wang</a>
|
<a href=/people/v/vivek-kulkarni/>Vivek Kulkarni</a>
|
<a href=/people/m/mo-yu/>Mo Yu</a>
|
<a href=/people/s/shiyu-chang/>Shiyu Chang</a>
|
<a href=/people/x/xiaoxiao-guo/>Xiaoxiao Guo</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1496><div class="card-body p-3 small">With <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> becoming increasingly popular on which lots of news and real-time events are reported, developing automated question answering systems is critical to the effective-ness of many applications that rely on real-time knowledge. While previous datasets have concentrated on <a href=https://en.wikipedia.org/wiki/Question_answering>question answering (QA)</a> for formal text like <a href=https://en.wikipedia.org/wiki/News>news</a> and <a href=https://en.wikipedia.org/wiki/Wikipedia>Wikipedia</a>, we present the first large-scale dataset for QA over <a href=https://en.wikipedia.org/wiki/Social_media>social media data</a>. To ensure that the tweets we collected are useful, we only gather tweets used by journalists to write <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a>. We then ask human annotators to write questions and answers upon these tweets. Unlike otherQA datasets like SQuAD in which the answers are extractive, we allow the answers to be abstractive. We show that two recently proposed neural models that perform well on <a href=https://en.wikipedia.org/wiki/Formal_language>formal texts</a> are limited in their performance when applied to our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. In addition, even the fine-tuned BERT model is still lagging behind human performance with a large margin. Our results thus point to the need of improved <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA systems</a> targeting <a href=https://en.wikipedia.org/wiki/Social_media>social media text</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1498.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1498 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1498 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385272871 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1498/>Tree LSTMs with Convolution Units to Predict Stance and Rumor Veracity in Social Media Conversations<span class=acl-fixed-case>LSTM</span>s with Convolution Units to Predict Stance and Rumor Veracity in Social Media Conversations</a></strong><br><a href=/people/s/sumeet-kumar/>Sumeet Kumar</a>
|
<a href=/people/k/kathleen-m-carley/>Kathleen Carley</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1498><div class="card-body p-3 small">Learning from social-media conversations has gained significant attention recently because of its applications in areas like rumor detection. In this research, we propose a new way to represent social-media conversations as binarized constituency trees that allows comparing features in source-posts and their replies effectively. Moreover, we propose to use convolution units in Tree LSTMs that are better at learning patterns in <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> obtained from the source and reply posts. Our Tree LSTM models employ multi-task (stance + rumor) learning and propagate the useful stance signal up in the tree for rumor classification at the root node. The proposed models achieve state-of-the-art performance, outperforming the current best model by 12 % and 15 % on F1-macro for rumor-veracity classification and stance classification tasks respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1503.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1503 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1503 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385219323 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1503" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1503/>Simple Unsupervised Summarization by Contextual Matching</a></strong><br><a href=/people/j/jiawei-zhou/>Jiawei Zhou</a>
|
<a href=/people/a/alexander-m-rush/>Alexander Rush</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1503><div class="card-body p-3 small">We propose an <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised method</a> for sentence summarization using only <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a>. The approach employs two <a href=https://en.wikipedia.org/wiki/Language_model>language models</a>, <a href=https://en.wikipedia.org/wiki/Monotonic_function>one</a> that is generic (i.e. pretrained), and the <a href=https://en.wikipedia.org/wiki/Other_(philosophy)>other</a> that is specific to the target domain. We show that by using a product-of-experts criteria these are enough for maintaining continuous contextual matching while maintaining output fluency. Experiments on both abstractive and extractive sentence summarization data sets show promising results of our method without being exposed to any paired data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1507.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1507 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1507 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1507.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385446129 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1507" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1507/>Relating Simple Sentence Representations in <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Neural Networks</a> and the Brain</a></strong><br><a href=/people/s/sharmistha-jat/>Sharmistha Jat</a>
|
<a href=/people/h/hao-tang/>Hao Tang</a>
|
<a href=/people/p/partha-talukdar/>Partha Talukdar</a>
|
<a href=/people/t/tom-mitchell/>Tom Mitchell</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1507><div class="card-body p-3 small">What is the relationship between <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence representations</a> learned by <a href=https://en.wikipedia.org/wiki/Deep_learning>deep recurrent models</a> against those encoded by the <a href=https://en.wikipedia.org/wiki/Brain>brain</a>? Is there any correspondence between hidden layers of these <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent models</a> and <a href=https://en.wikipedia.org/wiki/List_of_regions_in_the_human_brain>brain regions</a> when processing sentences? Can these deep models be used to synthesize brain data which can then be utilized in other extrinsic tasks? We investigate these questions using sentences with simple syntax and semantics (e.g., The bone was eaten by the dog.). We consider multiple neural network architectures, including recently proposed ELMo and BERT. We use magnetoencephalography (MEG) brain recording data collected from human subjects when they were reading these simple sentences. Overall, we find that BERT&#8217;s activations correlate the best with MEG brain data. We also find that the <a href=https://en.wikipedia.org/wiki/Deep_learning>deep network representation</a> can be used to generate <a href=https://en.wikipedia.org/wiki/Brain>brain data</a> from new sentences to augment existing <a href=https://en.wikipedia.org/wiki/Brain>brain data</a>. To the best of our knowledge, this is the first work showing that the <a href=https://en.wikipedia.org/wiki/Magnetoencephalography>MEG brain recording</a> when reading a word in a sentence can be used to distinguish earlier words in the sentence. Our exploration is also the first to use deep neural network representations to generate synthetic brain data and to show that it helps in improving subsequent stimuli decoding task accuracy.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1510.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1510 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1510 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1510/>NNE : A Dataset for Nested Named Entity Recognition in English Newswire<span class=acl-fixed-case>NNE</span>: A Dataset for Nested Named Entity Recognition in <span class=acl-fixed-case>E</span>nglish Newswire</a></strong><br><a href=/people/n/nicky-ringland/>Nicky Ringland</a>
|
<a href=/people/x/xiang-dai/>Xiang Dai</a>
|
<a href=/people/b/ben-hachey/>Ben Hachey</a>
|
<a href=/people/s/sarvnaz-karimi/>Sarvnaz Karimi</a>
|
<a href=/people/c/cecile-paris/>Cecile Paris</a>
|
<a href=/people/j/james-r-curran/>James R. Curran</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1510><div class="card-body p-3 small">Named entity recognition (NER) is widely used in <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language processing applications</a> and downstream tasks. However, most NER tools target flat annotation from popular <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, eschewing the semantic information available in nested entity mentions. We describe NNEa fine-grained, nested named entity dataset over the full Wall Street Journal portion of the Penn Treebank (PTB). Our <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a> comprises 279,795 mentions of 114 entity types with up to 6 layers of <a href=https://en.wikipedia.org/wiki/Nesting_(computing)>nesting</a>. We hope the public release of this large <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for English newswire will encourage development of new techniques for nested NER.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1511.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1511 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1511 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1511" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1511/>Sequence-to-Nuggets : Nested Entity Mention Detection via Anchor-Region Networks</a></strong><br><a href=/people/h/hongyu-lin/>Hongyu Lin</a>
|
<a href=/people/y/yaojie-lu/>Yaojie Lu</a>
|
<a href=/people/x/xianpei-han/>Xianpei Han</a>
|
<a href=/people/l/le-sun/>Le Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1511><div class="card-body p-3 small">Sequential labeling-based NER approaches restrict each word belonging to at most one entity mention, which will face a serious problem when recognizing nested entity mentions. In this paper, we propose to resolve this problem by modeling and leveraging the head-driven phrase structures of <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity mentions</a>, i.e., although a mention can nest other mentions, they will not share the same <a href=https://en.wikipedia.org/wiki/Headword>head word</a>. Specifically, we propose Anchor-Region Networks (ARNs), a sequence-to-nuggets architecture for nested mention detection. ARNs first identify anchor words (i.e., possible head words) of all mentions, and then recognize the mention boundaries for each anchor word by exploiting regular phrase structures. Furthermore, we also design Bag Loss, an <a href=https://en.wikipedia.org/wiki/Loss_function>objective function</a> which can train ARNs in an end-to-end manner without using any anchor word annotation. Experiments show that ARNs achieve the state-of-the-art performance on three standard nested entity mention detection benchmarks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1515.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1515 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1515 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1515/>Incorporating <a href=https://en.wikipedia.org/wiki/Linguistic_prescription>Linguistic Constraints</a> into Keyphrase Generation</a></strong><br><a href=/people/j/jing-zhao/>Jing Zhao</a>
|
<a href=/people/y/yuxiang-zhang/>Yuxiang Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1515><div class="card-body p-3 small">Keyphrases, that concisely describe the high-level topics discussed in a document, are very useful for a wide range of natural language processing tasks. Though existing keyphrase generation methods have achieved remarkable performance on this task, they generate many overlapping phrases (including sub-phrases or super-phrases) of keyphrases. In this paper, we propose the parallel Seq2Seq network with the coverage attention to alleviate the overlapping phrase problem. Specifically, we integrate the linguistic constraints of keyphrase into the basic Seq2Seq network on the source side, and employ the multi-task learning framework on the target side. In addition, in order to prevent from generating overlapping phrases of keyphrases with correct <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a>, we introduce the coverage vector to keep track of the attention history and to decide whether the parts of source text have been covered by existing generated keyphrases. Experimental results show that our method can outperform the state-of-the-art CopyRNN on scientific datasets, and is also more effective in news domain.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1518.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1518 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1518 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1518" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1518/>A Deep Reinforced Sequence-to-Set Model for Multi-Label Classification</a></strong><br><a href=/people/p/pengcheng-yang/>Pengcheng Yang</a>
|
<a href=/people/f/fuli-luo/>Fuli Luo</a>
|
<a href=/people/s/shuming-ma/>Shuming Ma</a>
|
<a href=/people/j/junyang-lin/>Junyang Lin</a>
|
<a href=/people/x/xu-sun/>Xu Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1518><div class="card-body p-3 small">Multi-label classification (MLC) aims to predict a set of labels for a given instance. Based on a pre-defined label order, the sequence-to-sequence (Seq2Seq) model trained via maximum likelihood estimation method has been successfully applied to the MLC task and shows powerful ability to capture high-order correlations between labels. However, the output labels are essentially an <a href=https://en.wikipedia.org/wiki/Unordered_set>unordered set</a> rather than an <a href=https://en.wikipedia.org/wiki/List_of_order_structures_in_mathematics>ordered sequence</a>. This inconsistency tends to result in some <a href=https://en.wikipedia.org/wiki/Intrinsic_and_extrinsic_properties_(philosophy)>intractable problems</a>, e.g., sensitivity to the label order. To remedy this, we propose a simple but effective sequence-to-set model. The proposed model is trained via <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a>, where <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reward feedback</a> is designed to be independent of the label order. In this way, we can reduce the dependence of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> on the label order, as well as capture high-order correlations between labels. Extensive experiments show that our approach can substantially outperform competitive baselines, as well as effectively reduce the sensitivity to the label order.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1521.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1521 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1521 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1521" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1521/>Cost-sensitive Regularization for Label Confusion-aware Event Detection</a></strong><br><a href=/people/h/hongyu-lin/>Hongyu Lin</a>
|
<a href=/people/y/yaojie-lu/>Yaojie Lu</a>
|
<a href=/people/x/xianpei-han/>Xianpei Han</a>
|
<a href=/people/l/le-sun/>Le Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1521><div class="card-body p-3 small">In supervised event detection, most of the mislabeling occurs between a small number of confusing type pairs, including trigger-NIL pairs and sibling sub-types of the same coarse type. To address this label confusion problem, this paper proposes cost-sensitive regularization, which can force the training procedure to concentrate more on optimizing confusing type pairs. Specifically, we introduce a cost-weighted term into the training loss, which penalizes more on mislabeling between confusing label pairs. Furthermore, we also propose two <a href=https://en.wikipedia.org/wiki/Estimator>estimators</a> which can effectively measure such label confusion based on instance-level or population-level statistics. Experiments on TAC-KBP 2017 datasets demonstrate that the proposed method can significantly improve the performances of different <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> in both English and Chinese event detection.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1523.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1523 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1523 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1523" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1523/>Improving <a href=https://en.wikipedia.org/wiki/Open_information_extraction>Open Information Extraction</a> via Iterative Rank-Aware Learning</a></strong><br><a href=/people/z/zhengbao-jiang/>Zhengbao Jiang</a>
|
<a href=/people/p/pengcheng-yin/>Pengcheng Yin</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1523><div class="card-body p-3 small">Open information extraction (IE) is the task of extracting open-domain assertions from <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language sentences</a>. A key step in open IE is confidence modeling, ranking the extractions based on their estimated quality to adjust <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a> and recall of extracted assertions. We found that the extraction likelihood, a confidence measure used by current supervised open IE systems, is not well calibrated when comparing the quality of assertions extracted from different sentences. We propose an additional binary classification loss to calibrate the likelihood to make it more globally comparable, and an iterative learning process, where extractions generated by the open IE model are incrementally included as training samples to help the model learn from trial and error. Experiments on OIE2016 demonstrate the effectiveness of our <a href=https://en.wikipedia.org/wiki/Methodology>method</a>. Code and data are available at https://github.com/jzbjyb/oie_rank.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1524.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1524 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1524 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1524.Supplementary.zip data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1524" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1524/>Towards Improving Neural Named Entity Recognition with Gazetteers</a></strong><br><a href=/people/t/tianyu-liu/>Tianyu Liu</a>
|
<a href=/people/j/jin-ge-yao/>Jin-Ge Yao</a>
|
<a href=/people/c/chin-yew-lin/>Chin-Yew Lin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1524><div class="card-body p-3 small">Most of the recently proposed neural models for <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a> have been purely data-driven, with a strong emphasis on getting rid of the efforts for collecting external resources or designing hand-crafted features. This could increase the chance of <a href=https://en.wikipedia.org/wiki/Overfitting>overfitting</a> since the models can not access any supervision signal beyond the small amount of annotated data, limiting their power to generalize beyond the annotated entities. In this work, we show that properly utilizing external gazetteers could benefit segmental neural NER models. We add a simple <a href=https://en.wikipedia.org/wiki/Modular_programming>module</a> on the recently proposed hybrid semi-Markov CRF architecture and observe some promising results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1529.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1529 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1529 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1529" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1529/>How to Best Use <a href=https://en.wikipedia.org/wiki/Syntax_(programming_languages)>Syntax</a> in Semantic Role Labelling</a></strong><br><a href=/people/y/yufei-wang/>Yufei Wang</a>
|
<a href=/people/m/mark-johnson/>Mark Johnson</a>
|
<a href=/people/s/stephen-wan/>Stephen Wan</a>
|
<a href=/people/y/yifang-sun/>Yifang Sun</a>
|
<a href=/people/w/wei-wang/>Wei Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1529><div class="card-body p-3 small">There are many different ways in which external information might be used in a NLP task. This paper investigates how external syntactic information can be used most effectively in the Semantic Role Labeling (SRL) task. We evaluate three different ways of encoding syntactic parses and three different ways of injecting them into a state-of-the-art neural ELMo-based SRL sequence labelling model. We show that using a constituency representation as input features improves performance the most, achieving a new state-of-the-art for non-ensemble SRL models on the in-domain CoNLL&#8217;05 and CoNLL&#8217;12 benchmarks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1530.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1530 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1530 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1530" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1530/>PTB Graph Parsing with Tree Approximation<span class=acl-fixed-case>PTB</span> Graph Parsing with Tree Approximation</a></strong><br><a href=/people/y/yoshihide-kato/>Yoshihide Kato</a>
|
<a href=/people/s/shigeki-matsubara/>Shigeki Matsubara</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1530><div class="card-body p-3 small">The Penn Treebank (PTB) represents syntactic structures as <a href=https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)>graphs</a> due to nonlocal dependencies. This paper proposes a method that approximates PTB graph-structured representations by <a href=https://en.wikipedia.org/wiki/Tree_(graph_theory)>trees</a>. By our approximation method, we can reduce nonlocal dependency identification and constituency parsing into single tree-based parsing. An experimental result demonstrates that our approximation method with an off-the-shelf tree-based constituency parser significantly outperforms the previous methods in nonlocal dependency identification.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1532.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1532 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1532 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1532/>A Prism Module for Semantic Disentanglement in Name Entity Recognition</a></strong><br><a href=/people/k/kun-liu/>Kun Liu</a>
|
<a href=/people/s/shen-li/>Shen Li</a>
|
<a href=/people/d/daqi-zheng/>Daqi Zheng</a>
|
<a href=/people/z/zhengdong-lu/>Zhengdong Lu</a>
|
<a href=/people/s/sheng-gao/>Sheng Gao</a>
|
<a href=/people/s/si-li/>Si Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1532><div class="card-body p-3 small">Natural Language Processing has been perplexed for many years by the problem that multiple <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> are mixed inside a word, even with the help of <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context</a>. To solve this problem, we propose a prism module to disentangle the semantic aspects of words and reduce noise at the input layer of a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>. In the prism module, some words are selectively replaced with task-related semantic aspects, then these denoised word representations can be fed into downstream tasks to make them easier. Besides, we also introduce a structure to train this <a href=https://en.wikipedia.org/wiki/Modular_programming>module</a> jointly with the downstream model without additional data. This module can be easily integrated into the downstream model and significantly improve the performance of <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> on named entity recognition (NER) task. The ablation analysis demonstrates the rationality of the <a href=https://en.wikipedia.org/wiki/Methodology>method</a>. As a side effect, the proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a> also provides a way to visualize the contribution of each word.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1534.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1534 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1534 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1534.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1534" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1534/>Towards Empathetic Open-domain Conversation Models : A New Benchmark and Dataset</a></strong><br><a href=/people/h/hannah-rashkin/>Hannah Rashkin</a>
|
<a href=/people/e/eric-michael-smith/>Eric Michael Smith</a>
|
<a href=/people/m/margaret-li/>Margaret Li</a>
|
<a href=/people/y/y-lan-boureau/>Y-Lan Boureau</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1534><div class="card-body p-3 small">One challenge for dialogue agents is recognizing feelings in the conversation partner and replying accordingly, a key communicative skill. While it is straightforward for humans to recognize and acknowledge others&#8217; feelings in a conversation, this is a significant challenge for <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>AI systems</a> due to the paucity of suitable publicly-available datasets for training and evaluation. This work proposes a new benchmark for empathetic dialogue generation and EmpatheticDialogues, a novel dataset of 25k conversations grounded in emotional situations. Our experiments indicate that dialogue models that use our dataset are perceived to be more empathetic by human evaluators, compared to <a href=https://en.wikipedia.org/wiki/Computer_simulation>models</a> merely trained on large-scale Internet conversation data. We also present empirical comparisons of dialogue model adaptations for empathetic responding, leveraging existing <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> or <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> without requiring lengthy re-training of the full model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1536.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1536 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1536 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1536/>Training Neural Response Selection for Task-Oriented Dialogue Systems</a></strong><br><a href=/people/m/matthew-henderson/>Matthew Henderson</a>
|
<a href=/people/i/ivan-vulic/>Ivan Vulić</a>
|
<a href=/people/d/daniela-gerz/>Daniela Gerz</a>
|
<a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/p/pawel-budzianowski/>Paweł Budzianowski</a>
|
<a href=/people/s/sam-coope/>Sam Coope</a>
|
<a href=/people/g/georgios-spithourakis/>Georgios Spithourakis</a>
|
<a href=/people/t/tsung-hsien-wen/>Tsung-Hsien Wen</a>
|
<a href=/people/n/nikola-mrksic/>Nikola Mrkšić</a>
|
<a href=/people/p/pei-hao-su/>Pei-Hao Su</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1536><div class="card-body p-3 small">Despite their popularity in the chatbot literature, retrieval-based models have had modest impact on task-oriented dialogue systems, with the main obstacle to their application being the low-data regime of most task-oriented dialogue tasks. Inspired by the recent success of pretraining in language modelling, we propose an effective method for deploying response selection in task-oriented dialogue. To train response selection models for task-oriented dialogue tasks, we propose a novel method which : 1) pretrains the response selection model on large general-domain conversational corpora ; and then 2) fine-tunes the pretrained model for the target dialogue domain, relying only on the small in-domain dataset to capture the nuances of the given dialogue domain. Our evaluation on five diverse application domains, ranging from <a href=https://en.wikipedia.org/wiki/E-commerce>e-commerce</a> to <a href=https://en.wikipedia.org/wiki/Bank>banking</a>, demonstrates the effectiveness of the proposed training method.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1537.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1537 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1537 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1537.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1537/>Collaborative Dialogue in Minecraft<span class=acl-fixed-case>M</span>inecraft</a></strong><br><a href=/people/a/anjali-narayan-chen/>Anjali Narayan-Chen</a>
|
<a href=/people/p/prashant-jayannavar/>Prashant Jayannavar</a>
|
<a href=/people/j/julia-hockenmaier/>Julia Hockenmaier</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1537><div class="card-body p-3 small">We wish to develop interactive agents that can communicate with humans to collaboratively solve tasks in grounded scenarios. Since <a href=https://en.wikipedia.org/wiki/PC_game>computer games</a> allow us to simulate such tasks without the need for physical robots, we define a Minecraft-based collaborative building task in which one player (A, the Architect) is shown a target structure and needs to instruct the other player (B, the Builder) to build this <a href=https://en.wikipedia.org/wiki/Structure>structure</a>. Both players interact via a <a href=https://en.wikipedia.org/wiki/Graphical_user_interface>chat interface</a>. A can observe B but can not place blocks. We present the Minecraft Dialogue Corpus, a collection of 509 conversations and game logs. As a first step towards our goal of developing fully interactive agents for this task, we consider the subtask of Architect utterance generation, and show how challenging it is.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1538.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1538 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1538 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1538/>Neural Response Generation with Meta-words</a></strong><br><a href=/people/c/can-xu/>Can Xu</a>
|
<a href=/people/w/wei-wu/>Wei Wu</a>
|
<a href=/people/c/chongyang-tao/>Chongyang Tao</a>
|
<a href=/people/h/huang-hu/>Huang Hu</a>
|
<a href=/people/m/matt-schuerman/>Matt Schuerman</a>
|
<a href=/people/y/ying-wang/>Ying Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1538><div class="card-body p-3 small">We present open domain dialogue generation with meta-words. A meta-word is a structured record that describes attributes of a response, and thus allows us to explicitly model the one-to-many relationship within open domain dialogues and perform response generation in an explainable and controllable manner. To incorporate meta-words into generation, we propose a novel goal-tracking memory network that formalizes meta-word expression as a goal in response generation and manages the generation process to achieve the goal with a state memory panel and a state controller. Experimental results from both automatic evaluation and human judgment on two large-scale data sets indicate that our model can significantly outperform state-of-the-art generation models in terms of response relevance, response diversity, and accuracy of meta-word expression.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1540.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1540 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1540 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1540/>Ordinal and Attribute Aware Response Generation in a Multimodal Dialogue System</a></strong><br><a href=/people/h/hardik-chauhan/>Hardik Chauhan</a>
|
<a href=/people/m/mauajama-firdaus/>Mauajama Firdaus</a>
|
<a href=/people/a/asif-ekbal/>Asif Ekbal</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1540><div class="card-body p-3 small">Multimodal dialogue systems have opened new frontiers in the traditional goal-oriented dialogue systems. The state-of-the-art dialogue systems are primarily based on unimodal sources, predominantly the text, and hence can not capture the information present in the other sources such as <a href=https://en.wikipedia.org/wiki/Video>videos</a>, <a href=https://en.wikipedia.org/wiki/Videotape>audios</a>, <a href=https://en.wikipedia.org/wiki/Digital_image>images</a> etc. With the availability of large scale multimodal dialogue dataset (MMD) (Saha et al., 2018) on the fashion domain, the visual appearance of the products is essential for understanding the intention of the user. Without capturing the information from both the text and image, the <a href=https://en.wikipedia.org/wiki/System>system</a> will be incapable of generating correct and desirable responses. In this paper, we propose a novel position and attribute aware attention mechanism to learn enhanced image representation conditioned on the user utterance. Our evaluation shows that the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> can generate appropriate responses while preserving the position and attribute information. Experimental results also prove that our proposed approach attains superior performance compared to the baseline models, and outperforms the state-of-the-art approaches on text similarity based evaluation metrics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1543.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1543 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1543 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1543/>Reading Turn by Turn : Hierarchical Attention Architecture for Spoken Dialogue Comprehension</a></strong><br><a href=/people/z/zhengyuan-liu/>Zhengyuan Liu</a>
|
<a href=/people/n/nancy-chen/>Nancy Chen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1543><div class="card-body p-3 small">Comprehending multi-turn spoken conversations is an emerging research area, presenting challenges different from <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a> of passages due to the interactive nature of information exchange from at least two speakers. Unlike passages, where sentences are often the default semantic modeling unit, in multi-turn conversations, a turn is a topically coherent unit embodied with immediately relevant context, making it a linguistically intuitive segment for computationally modeling verbal interactions. Therefore, in this work, we propose a hierarchical attention neural network architecture, combining turn-level and word-level attention mechanisms, to improve spoken dialogue comprehension performance. Experiments are conducted on a multi-turn conversation dataset, where nurses inquire and discuss symptom information with patients. We empirically show that the proposed approach outperforms standard attention baselines, achieves more efficient learning outcomes, and is more robust to lengthy and out-of-distribution test samples.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1544.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1544 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1544 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1544.Supplementary.zip data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1544" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1544/>A Novel Bi-directional Interrelated Model for Joint Intent Detection and Slot Filling</a></strong><br><a href=/people/h/haihong-e/>Haihong E</a>
|
<a href=/people/p/peiqing-niu/>Peiqing Niu</a>
|
<a href=/people/z/zhongfu-chen/>Zhongfu Chen</a>
|
<a href=/people/m/meina-song/>Meina Song</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1544><div class="card-body p-3 small">A spoken language understanding (SLU) system includes two main tasks, slot filling (SF) and intent detection (ID). The joint model for the two <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a> is becoming a tendency in SLU. But the bi-directional interrelated connections between the intent and slots are not established in the existing joint models. In this paper, we propose a novel bi-directional interrelated model for joint intent detection and slot filling. We introduce an SF-ID network to establish direct connections for the two <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> to help them promote each other mutually. Besides, we design an entirely new iteration mechanism inside the SF-ID network to enhance the bi-directional interrelated connections. The experimental results show that the relative improvement in the sentence-level semantic frame accuracy of our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> is 3.79 % and 5.42 % on ATIS and Snips datasets, respectively, compared to the state-of-the-art model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1545.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1545 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1545 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1545" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1545/>Dual Supervised Learning for Natural Language Understanding and Generation</a></strong><br><a href=/people/s/shang-yu-su/>Shang-Yu Su</a>
|
<a href=/people/c/chao-wei-huang/>Chao-Wei Huang</a>
|
<a href=/people/y/yun-nung-chen/>Yun-Nung Chen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1545><div class="card-body p-3 small">Natural language understanding (NLU) and natural language generation (NLG) are both critical research topics in the NLP and dialogue fields. Natural language understanding is to extract the core semantic meaning from the given utterances, while <a href=https://en.wikipedia.org/wiki/Natural-language_generation>natural language generation</a> is opposite, of which the goal is to construct corresponding sentences based on the given <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a>. However, such <a href=https://en.wikipedia.org/wiki/Dual_(grammatical_number)>dual relationship</a> has not been investigated in literature. This paper proposes a novel learning framework for <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language understanding</a> and generation on top of dual supervised learning, providing a way to exploit the <a href=https://en.wikipedia.org/wiki/Duality_(mathematics)>duality</a>. The preliminary experiments show that the proposed approach boosts the performance for both <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>, demonstrating the effectiveness of the <a href=https://en.wikipedia.org/wiki/Dual_relationship>dual relationship</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1549.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1549 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1549 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1549/>Modeling Semantic Relationship in Multi-turn Conversations with Hierarchical Latent Variables</a></strong><br><a href=/people/l/lei-shen/>Lei Shen</a>
|
<a href=/people/y/yang-feng/>Yang Feng</a>
|
<a href=/people/h/haolan-zhan/>Haolan Zhan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1549><div class="card-body p-3 small">Multi-turn conversations consist of complex semantic structures, and it is still a challenge to generate coherent and diverse responses given previous utterances. It&#8217;s practical that a conversation takes place under a background, meanwhile, the query and response are usually most related and they are consistent in topic but also different in content. However, little work focuses on such hierarchical relationship among utterances. To address this problem, we propose a Conversational Semantic Relationship RNN (CSRR) model to construct the dependency explicitly. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> contains <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variables</a> in three hierarchies. The discourse-level one captures the global background, the pair-level one stands for the common topic information between query and response, and the utterance-level ones try to represent differences in content. Experimental results show that our model significantly improves the quality of responses in terms of <a href=https://en.wikipedia.org/wiki/Fluency>fluency</a>, <a href=https://en.wikipedia.org/wiki/Coherence_(linguistics)>coherence</a>, and diversity compared to baseline methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1550.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1550 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1550 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1550/>Rationally Reappraising ATIS-based Dialogue Systems<span class=acl-fixed-case>ATIS</span>-based Dialogue Systems</a></strong><br><a href=/people/j/jingcheng-niu/>Jingcheng Niu</a>
|
<a href=/people/g/gerald-penn/>Gerald Penn</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1550><div class="card-body p-3 small">The Air Travel Information Service (ATIS) corpus has been the most common benchmark for evaluating Spoken Language Understanding (SLU) tasks for more than three decades since it was released. Recent state-of-the-art neural models have obtained <a href=https://en.wikipedia.org/wiki/F1_score>F1-scores</a> near 98 % on the task of slot filling. We developed a rule-based grammar for the ATIS domain that achieves a 95.82 % F1-score on our evaluation set. In the process, we furthermore discovered numerous shortcomings in the ATIS corpus annotation, which we have fixed. This paper presents a detailed account of these shortcomings, our proposed repairs, our rule-based grammar and the neural slot-filling architectures associated with ATIS. We also rationally reappraise the motivations for choosing a neural architecture in view of this account. Fixing the annotation errors results in a relative error reduction of between 19.4 and 52 % across all <a href=https://en.wikipedia.org/wiki/Computer_architecture>architectures</a>. We nevertheless argue that neural models must play a different role in ATIS dialogues because of the latter&#8217;s lack of variety.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1551.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1551 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1551 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1551" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1551/>Learning Latent Trees with Stochastic Perturbations and Differentiable Dynamic Programming</a></strong><br><a href=/people/c/caio-corro/>Caio Corro</a>
|
<a href=/people/i/ivan-titov/>Ivan Titov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1551><div class="card-body p-3 small">We treat projective dependency trees as <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variables</a> in our probabilistic model and induce them in such a way as to be beneficial for a downstream task, without relying on any direct tree supervision. Our approach relies on Gumbel perturbations and differentiable dynamic programming. Unlike previous approaches to latent tree learning, we stochastically sample global structures and our <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> is fully differentiable. We illustrate its effectiveness on <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> and natural language inference tasks. We also study its properties on a synthetic structure induction task. Ablation studies emphasize the importance of both <a href=https://en.wikipedia.org/wiki/Stochastic>stochasticity</a> and constraining <a href=https://en.wikipedia.org/wiki/Latent_variable>latent structures</a> to be projective trees.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1555.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1555 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1555 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1555" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1555/>Soft Contextual Data Augmentation for Neural Machine Translation</a></strong><br><a href=/people/f/fei-gao/>Fei Gao</a>
|
<a href=/people/j/jinhua-zhu/>Jinhua Zhu</a>
|
<a href=/people/l/lijun-wu/>Lijun Wu</a>
|
<a href=/people/y/yingce-xia/>Yingce Xia</a>
|
<a href=/people/t/tao-qin/>Tao Qin</a>
|
<a href=/people/x/xueqi-cheng/>Xueqi Cheng</a>
|
<a href=/people/w/wengang-zhou/>Wengang Zhou</a>
|
<a href=/people/t/tie-yan-liu/>Tie-Yan Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1555><div class="card-body p-3 small">While <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> is an important trick to boost the accuracy of <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning methods</a> in <a href=https://en.wikipedia.org/wiki/Computer_vision>computer vision tasks</a>, its study in <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language tasks</a> is still very limited. In this paper, we present a novel data augmentation method for neural machine translation. Different from previous augmentation methods that randomly drop, swap or replace words with other words in a sentence, we softly augment a randomly chosen word in a sentence by its contextual mixture of multiple related words. More accurately, we replace the one-hot representation of a word by a <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>distribution</a> (provided by a language model) over the vocabulary, i.e., replacing the embedding of this word by a weighted combination of multiple semantically similar words. Since the weights of those words depend on the contextual information of the word to be replaced, the newly generated sentences capture much richer information than previous augmentation methods. Experimental results on both small scale and large scale machine translation data sets demonstrate the superiority of our method over strong baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1556.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1556 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1556 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1556/>Reversing Gradients in Adversarial Domain Adaptation for Question Deduplication and Textual Entailment Tasks</a></strong><br><a href=/people/a/anush-kamath/>Anush Kamath</a>
|
<a href=/people/s/sparsh-gupta/>Sparsh Gupta</a>
|
<a href=/people/v/vitor-carvalho/>Vitor Carvalho</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1556><div class="card-body p-3 small">Adversarial domain adaptation has been recently proposed as an effective technique for textual matching tasks, such as question deduplication. Here we investigate the use of gradient reversal on adversarial domain adaptation to explicitly learn both shared and unshared (domain specific) representations between two textual domains. In doing so, gradient reversal learns features that explicitly compensate for domain mismatch, while still distilling domain specific knowledge that can improve target domain accuracy. We evaluate reversing gradients for adversarial adaptation on multiple domains, and demonstrate that it significantly outperforms other methods on question deduplication as well as on recognizing textual entailment (RTE) tasks, achieving up to 7 % absolute boost in base model accuracy on some datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1559.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1559 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1559 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1559.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1559/>Generating Fluent Adversarial Examples for Natural Languages</a></strong><br><a href=/people/h/huangzhao-zhang/>Huangzhao Zhang</a>
|
<a href=/people/h/hao-zhou/>Hao Zhou</a>
|
<a href=/people/n/ning-miao/>Ning Miao</a>
|
<a href=/people/l/lei-li/>Lei Li</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1559><div class="card-body p-3 small">Efficiently building an adversarial attacker for natural language processing (NLP) tasks is a real challenge. Firstly, as the sentence space is discrete, it is difficult to make <a href=https://en.wikipedia.org/wiki/Perturbation_theory_(quantum_mechanics)>small perturbations</a> along the direction of <a href=https://en.wikipedia.org/wiki/Gradient>gradients</a>. Secondly, the fluency of the generated examples can not be guaranteed. In this paper, we propose MHA, which addresses both problems by performing Metropolis-Hastings sampling, whose proposal is designed with the guidance of <a href=https://en.wikipedia.org/wiki/Gradient>gradients</a>. Experiments on <a href=https://en.wikipedia.org/wiki/IMDb>IMDB</a> and SNLI show that our proposed MHAoutperforms the baseline model on attacking capability. Adversarial training with MHA also leads to better robustness and performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1560.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1560 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1560 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1560/>Towards Explainable NLP : A Generative Explanation Framework for Text Classification<span class=acl-fixed-case>NLP</span>: A Generative Explanation Framework for Text Classification</a></strong><br><a href=/people/h/hui-liu/>Hui Liu</a>
|
<a href=/people/q/qingyu-yin/>Qingyu Yin</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1560><div class="card-body p-3 small">Building explainable systems is a critical problem in the field of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing (NLP)</a>, since most <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning models</a> provide no explanations for the predictions. Existing approaches for explainable machine learning systems tend to focus on interpreting the outputs or the connections between inputs and outputs. However, the fine-grained information (e.g. textual explanations for the labels) is often ignored, and the systems do not explicitly generate the human-readable explanations. To solve this problem, we propose a novel generative explanation framework that learns to make classification decisions and generate fine-grained explanations at the same time. More specifically, we introduce the explainable factor and the minimum risk training approach that learn to generate more reasonable explanations. We construct two new <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> that contain summaries, rating scores, and fine-grained reasons. We conduct experiments on both <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, comparing with several strong neural network baseline systems. Experimental results show that our method surpasses all baselines on both <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, and is able to generate concise explanations at the same time.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1561.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1561 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1561 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1561" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1561/>Combating Adversarial Misspellings with Robust Word Recognition</a></strong><br><a href=/people/d/danish-pruthi/>Danish Pruthi</a>
|
<a href=/people/b/bhuwan-dhingra/>Bhuwan Dhingra</a>
|
<a href=/people/z/zachary-c-lipton/>Zachary C. Lipton</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1561><div class="card-body p-3 small">To combat adversarial spelling mistakes, we propose placing a word recognition model in front of the downstream classifier. Our word recognition models build upon the RNN semi-character architecture, introducing several new backoff strategies for handling rare and unseen words. Trained to recognize words corrupted by random adds, drops, swaps, and keyboard mistakes, our <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> achieves 32 % relative (and 3.3 % absolute) <a href=https://en.wikipedia.org/wiki/Error_detection_and_correction>error reduction</a> over the vanilla semi-character model. Notably, our pipeline confers <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> on the downstream classifier, outperforming both adversarial training and off-the-shelf <a href=https://en.wikipedia.org/wiki/Spell_checker>spell checkers</a>. Against a <a href=https://en.wikipedia.org/wiki/Boolean_satisfiability_problem>BERT model</a> fine-tuned for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>, a single adversarially-chosen character attack lowers <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> from 90.3 % to 45.8 %. Our defense restores <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> to 75 %. Surprisingly, better <a href=https://en.wikipedia.org/wiki/Word_recognition>word recognition</a> does not always entail greater <a href=https://en.wikipedia.org/wiki/Robustness_(morphology)>robustness</a>. Our analysis reveals that robustness also depends upon a quantity that we denote the <a href=https://en.wikipedia.org/wiki/Sensitivity_and_specificity>sensitivity</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1562.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1562 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1562 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1562.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1562" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1562/>An Empirical Investigation of Structured Output Modeling for Graph-based Neural Dependency Parsing</a></strong><br><a href=/people/z/zhisong-zhang/>Zhisong Zhang</a>
|
<a href=/people/x/xuezhe-ma/>Xuezhe Ma</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1562><div class="card-body p-3 small">In this paper, we investigate the aspect of structured output modeling for the state-of-the-art graph-based neural dependency parser (Dozat and Manning, 2017). With evaluations on 14 treebanks, we empirically show that global output-structured models can generally obtain better performance, especially on the metric of sentence-level Complete Match. However, probably because neural models already learn good global views of the inputs, the improvement brought by structured output modeling is modest.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1563.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1563 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1563 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1563.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385223469 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1563" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1563/>Observing Dialogue in Therapy : Categorizing and Forecasting Behavioral Codes</a></strong><br><a href=/people/j/jie-cao/>Jie Cao</a>
|
<a href=/people/m/michael-tanana/>Michael Tanana</a>
|
<a href=/people/z/zac-imel/>Zac Imel</a>
|
<a href=/people/e/eric-poitras/>Eric Poitras</a>
|
<a href=/people/d/david-atkins/>David Atkins</a>
|
<a href=/people/v/vivek-srikumar/>Vivek Srikumar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1563><div class="card-body p-3 small">Automatically analyzing dialogue can help understand and guide behavior in domains such as <a href=https://en.wikipedia.org/wiki/List_of_counseling_topics>counseling</a>, where interactions are largely mediated by <a href=https://en.wikipedia.org/wiki/Conversation>conversation</a>. In this paper, we study modeling behavioral codes used to asses a psychotherapy treatment style called Motivational Interviewing (MI), which is effective for addressing substance abuse and related problems. Specifically, we address the problem of providing real-time guidance to therapists with a dialogue observer that (1) categorizes therapist and client MI behavioral codes and, (2) forecasts codes for upcoming utterances to help guide the conversation and potentially alert the therapist. For both tasks, we define <a href=https://en.wikipedia.org/wiki/Neural_network>neural network models</a> that build upon recent successes in dialogue modeling. Our experiments demonstrate that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> can outperform several <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> for both <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. We also report the results of a careful analysis that reveals the impact of the various network design tradeoffs for modeling therapy dialogue.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1565.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1565 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1565 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1565.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385223824 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1565" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1565/>Target-Guided Open-Domain Conversation</a></strong><br><a href=/people/j/jianheng-tang/>Jianheng Tang</a>
|
<a href=/people/t/tiancheng-zhao/>Tiancheng Zhao</a>
|
<a href=/people/c/chenyan-xiong/>Chenyan Xiong</a>
|
<a href=/people/x/xiaodan-liang/>Xiaodan Liang</a>
|
<a href=/people/e/eric-xing/>Eric Xing</a>
|
<a href=/people/z/zhiting-hu/>Zhiting Hu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1565><div class="card-body p-3 small">Many real-world open-domain conversation applications have specific goals to achieve during open-ended chats, such as <a href=https://en.wikipedia.org/wiki/Recommender_system>recommendation</a>, <a href=https://en.wikipedia.org/wiki/Psychotherapy>psychotherapy</a>, <a href=https://en.wikipedia.org/wiki/Education>education</a>, etc. We study the problem of imposing conversational goals on open-domain chat agents. In particular, we want a conversational system to chat naturally with human and proactively guide the conversation to a designated target subject. The problem is challenging as no <a href=https://en.wikipedia.org/wiki/Public_data>public data</a> is available for learning such a target-guided strategy. We propose a structured approach that introduces coarse-grained keywords to control the intended content of system responses. We then attain smooth conversation transition through turn-level supervised learning, and drive the conversation towards the target with <a href=https://en.wikipedia.org/wiki/Discourse_analysis>discourse-level constraints</a>. We further derive a keyword-augmented conversation dataset for the study. Quantitative and human evaluations show our <a href=https://en.wikipedia.org/wiki/System>system</a> can produce meaningful and effective conversations, significantly improving over other approaches</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1566.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1566 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1566 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385225678 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1566" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1566/>Persuasion for Good : Towards a Personalized Persuasive Dialogue System for Social Good</a></strong><br><a href=/people/x/xuewei-wang/>Xuewei Wang</a>
|
<a href=/people/w/weiyan-shi/>Weiyan Shi</a>
|
<a href=/people/r/richard-kim/>Richard Kim</a>
|
<a href=/people/y/yoojung-oh/>Yoojung Oh</a>
|
<a href=/people/s/sijia-yang/>Sijia Yang</a>
|
<a href=/people/j/jingwen-zhang/>Jingwen Zhang</a>
|
<a href=/people/z/zhou-yu/>Zhou Yu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1566><div class="card-body p-3 small">Developing intelligent persuasive conversational agents to change people&#8217;s opinions and actions for social good is the frontier in advancing the ethical development of automated dialogue systems. To do so, the first step is to understand the intricate organization of strategic disclosures and appeals employed in human persuasion conversations. We designed an online persuasion task where one participant was asked to persuade the other to donate to a specific charity. We collected a large dataset with 1,017 dialogues and annotated emerging <a href=https://en.wikipedia.org/wiki/Persuasion>persuasion strategies</a> from a subset. Based on the annotation, we built a baseline classifier with <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context information</a> and sentence-level features to predict the 10 <a href=https://en.wikipedia.org/wiki/Persuasion>persuasion strategies</a> used in the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>. Furthermore, to develop an understanding of personalized persuasion processes, we analyzed the relationships between individuals&#8217; demographic and psychological backgrounds including <a href=https://en.wikipedia.org/wiki/Personality>personality</a>, <a href=https://en.wikipedia.org/wiki/Morality>morality</a>, <a href=https://en.wikipedia.org/wiki/Value_(ethics)>value systems</a>, and their willingness for donation. Then, we analyzed which types of <a href=https://en.wikipedia.org/wiki/Persuasion>persuasion strategies</a> led to a greater amount of donation depending on the individuals&#8217; personal backgrounds. This work lays the ground for developing a personalized persuasive dialogue system.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1569.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1569 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1569 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385428418 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1569" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1569/>Language Modelling Makes Sense : Propagating Representations through <a href=https://en.wikipedia.org/wiki/WordNet>WordNet</a> for Full-Coverage Word Sense Disambiguation<span class=acl-fixed-case>W</span>ord<span class=acl-fixed-case>N</span>et for Full-Coverage Word Sense Disambiguation</a></strong><br><a href=/people/d/daniel-loureiro/>Daniel Loureiro</a>
|
<a href=/people/a/alipio-jorge/>Alípio Jorge</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1569><div class="card-body p-3 small">Contextual embeddings represent a new generation of semantic representations learned from Neural Language Modelling (NLM) that addresses the issue of meaning conflation hampering traditional word embeddings. In this work, we show that contextual embeddings can be used to achieve unprecedented gains in Word Sense Disambiguation (WSD) tasks. Our approach focuses on creating sense-level embeddings with full-coverage of <a href=https://en.wikipedia.org/wiki/WordNet>WordNet</a>, and without recourse to explicit knowledge of sense distributions or task-specific modelling. As a result, a simple Nearest Neighbors (k-NN) method using our representations is able to consistently surpass the performance of previous systems using powerful neural sequencing models. We also analyse the robustness of our approach when ignoring part-of-speech and lemma features, requiring disambiguation against the full sense inventory, and revealing shortcomings to be improved. Finally, we explore applications of our sense embeddings for concept-level analyses of contextual embeddings and their respective NLMs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1570.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1570 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1570 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385428467 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1570/>Word2Sense : Sparse Interpretable Word Embeddings<span class=acl-fixed-case>W</span>ord2<span class=acl-fixed-case>S</span>ense: Sparse Interpretable Word Embeddings</a></strong><br><a href=/people/a/abhishek-panigrahi/>Abhishek Panigrahi</a>
|
<a href=/people/h/harsha-vardhan-simhadri/>Harsha Vardhan Simhadri</a>
|
<a href=/people/c/chiranjib-bhattacharyya/>Chiranjib Bhattacharyya</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1570><div class="card-body p-3 small">We present an unsupervised method to generate Word2Sense word embeddings that are interpretable each dimension of the embedding space corresponds to a fine-grained sense, and the non-negative value of the embedding along the j-th dimension represents the relevance of the j-th sense to the word. The underlying LDA-based generative model can be extended to refine the representation of a polysemous word in a short context, allowing us to use the embedings in contextual tasks. On computational NLP tasks, Word2Sense embeddings compare well with other <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> generated by <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised methods</a>. Across tasks such as word similarity, <a href=https://en.wikipedia.org/wiki/Logical_consequence>entailment</a>, sense induction, and contextual interpretation, Word2Sense is competitive with the state-of-the-art method for that task. Word2Sense embeddings are at least as sparse and fast to compute as <a href=https://en.wikipedia.org/wiki/Prior_art>prior art</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1571.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1571 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1571 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385428643 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1571" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1571/>Modeling Semantic Compositionality with Sememe Knowledge</a></strong><br><a href=/people/f/fanchao-qi/>Fanchao Qi</a>
|
<a href=/people/j/junjie-huang/>Junjie Huang</a>
|
<a href=/people/c/chenghao-yang/>Chenghao Yang</a>
|
<a href=/people/z/zhiyuan-liu/>Zhiyuan Liu</a>
|
<a href=/people/x/xiao-chen/>Xiao Chen</a>
|
<a href=/people/q/qun-liu/>Qun Liu</a>
|
<a href=/people/m/maosong-sun/>Maosong Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1571><div class="card-body p-3 small">Semantic compositionality (SC) refers to the phenomenon that the meaning of a complex linguistic unit can be composed of the meanings of its constituents. Most related works focus on using complicated compositionality functions to model SC while few works consider external knowledge in <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. In this paper, we verify the effectiveness of <a href=https://en.wikipedia.org/wiki/Sememe>sememes</a>, the minimum semantic units of human languages, in modeling <a href=https://en.wikipedia.org/wiki/Semantic_space>SC</a> by a confirmatory experiment. Furthermore, we make the first attempt to incorporate sememe knowledge into SC models, and employ the sememe-incorporated models in learning representations of multiword expressions, a typical task of SC. In experiments, we implement our models by incorporating knowledge from a famous sememe knowledge base HowNet and perform both intrinsic and extrinsic evaluations. Experimental results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> achieve significant performance boost as compared to the baseline methods without considering sememe knowledge. We further conduct quantitative analysis and case studies to demonstrate the effectiveness of applying <a href=https://en.wikipedia.org/wiki/Sememe>sememe knowledge</a> in modeling SC.All the code and data of this paper can be obtained on https://github.com/thunlp/Sememe-SC.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1573.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1573 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1573 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385428708 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1573/>Empirical Linguistic Study of Sentence Embeddings</a></strong><br><a href=/people/k/katarzyna-krasnowska-kieras/>Katarzyna Krasnowska-Kieraś</a>
|
<a href=/people/a/alina-wroblewska/>Alina Wróblewska</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1573><div class="card-body p-3 small">The purpose of the research is to answer the question whether <a href=https://en.wikipedia.org/wiki/Linguistic_description>linguistic information</a> is retained in <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>vector representations of sentences</a>. We introduce a method of analysing the content of <a href=https://en.wikipedia.org/wiki/Sentence_embedding>sentence embeddings</a> based on universal probing tasks, along with the classification datasets for two contrasting languages. We perform a series of probing and downstream experiments with different types of <a href=https://en.wikipedia.org/wiki/Sentence_embedding>sentence embeddings</a>, followed by a thorough analysis of the experimental results. Aside from dependency parser-based embeddings, linguistic information is retained best in the recently proposed LASER sentence embeddings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1574.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1574 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1574 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385429181 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1574" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1574/>Probing for Semantic Classes : Diagnosing the Meaning Content of Word Embeddings</a></strong><br><a href=/people/y/yadollah-yaghoobzadeh/>Yadollah Yaghoobzadeh</a>
|
<a href=/people/k/katharina-kann/>Katharina Kann</a>
|
<a href=/people/t/timothy-j-hazen/>T. J. Hazen</a>
|
<a href=/people/e/eneko-agirre/>Eneko Agirre</a>
|
<a href=/people/h/hinrich-schutze/>Hinrich Schütze</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1574><div class="card-body p-3 small">Word embeddings typically represent different meanings of a word in a single conflated vector. Empirical analysis of embeddings of ambiguous words is currently limited by the small size of manually annotated resources and by the fact that word senses are treated as unrelated individual concepts. We present a large dataset based on manual Wikipedia annotations and <a href=https://en.wikipedia.org/wiki/Word_sense>word senses</a>, where <a href=https://en.wikipedia.org/wiki/Word_sense>word senses</a> from different words are related by <a href=https://en.wikipedia.org/wiki/Semantic_class>semantic classes</a>. This is the basis for novel diagnostic tests for an embedding&#8217;s content : we probe word embeddings for <a href=https://en.wikipedia.org/wiki/Semantic_class>semantic classes</a> and analyze the embedding space by classifying embeddings into <a href=https://en.wikipedia.org/wiki/Semantic_class>semantic classes</a>. Our main findings are : (i) Information about a sense is generally represented well in a single-vector embedding if the sense is frequent. (ii) A <a href=https://en.wikipedia.org/wiki/Classifier_(linguistics)>classifier</a> can accurately predict whether a word is single-sense or multi-sense, based only on its embedding. (iii) Although rare senses are not well represented in single-vector embeddings, this does not have negative impact on an NLP application whose performance depends on frequent senses.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1575.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1575 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1575 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385434363 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1575/>Deep Neural Model Inspection and Comparison via Functional Neuron Pathways</a></strong><br><a href=/people/j/james-fiacco/>James Fiacco</a>
|
<a href=/people/s/samridhi-choudhary/>Samridhi Choudhary</a>
|
<a href=/people/c/carolyn-rose/>Carolyn Rose</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1575><div class="card-body p-3 small">We introduce a general <a href=https://en.wikipedia.org/wiki/Methodology>method</a> for the interpretation and comparison of neural models. The method is used to factor a complex neural model into its functional components, which are comprised of sets of co-firing neurons that cut across layers of the <a href=https://en.wikipedia.org/wiki/Network_architecture>network architecture</a>, and which we call <a href=https://en.wikipedia.org/wiki/Neural_pathway>neural pathways</a>. The function of these pathways can be understood by identifying correlated task level and linguistic heuristics in such a way that this knowledge acts as a lens for approximating what the network has learned to apply to its intended <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. As a case study for investigating the utility of these <a href=https://en.wikipedia.org/wiki/Neural_pathway>pathways</a>, we present an examination of <a href=https://en.wikipedia.org/wiki/Neural_pathway>pathways</a> identified in models trained for two standard tasks, namely <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>Named Entity Recognition</a> and Recognizing Textual Entailment.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1579.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1579 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1579 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385226257 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1579/>Generalized Data Augmentation for Low-Resource Translation</a></strong><br><a href=/people/m/mengzhou-xia/>Mengzhou Xia</a>
|
<a href=/people/x/xiang-kong/>Xiang Kong</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1579><div class="card-body p-3 small">Low-resource language pairs with a paucity of parallel data pose challenges for <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> in terms of both adequacy and <a href=https://en.wikipedia.org/wiki/Fluency>fluency</a>. Data augmentation utilizing a large amount of monolingual data is regarded as an effective way to alleviate the problem. In this paper, we propose a general framework of <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> for low-resource machine translation not only using target-side monolingual data, but also by pivoting through a related high-resource language. Specifically, we experiment with a two-step pivoting method to convert high-resource data to the low-resource language, making best use of available resources to better approximate the true distribution of the low-resource language. First, we inject low-resource words into high-resource sentences through an induced bilingual dictionary. Second, we further edit the high-resource data injected with low-resource words using a modified unsupervised machine translation framework. Extensive experiments on four low-resource datasets show that under extreme low-resource settings, our data augmentation techniques improve translation quality by up to 1.5 to 8 BLEU points compared to supervised back-translation baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1581.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1581 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1581 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385434714 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1581/>Better OOV Translation with Bilingual Terminology Mining<span class=acl-fixed-case>OOV</span> Translation with Bilingual Terminology Mining</a></strong><br><a href=/people/m/matthias-huck/>Matthias Huck</a>
|
<a href=/people/v/viktor-hangya/>Viktor Hangya</a>
|
<a href=/people/a/alexander-fraser/>Alexander Fraser</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1581><div class="card-body p-3 small">Unseen words, also called out-of-vocabulary words (OOVs), are difficult for <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. In <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>neural machine translation</a>, byte-pair encoding can be used to represent OOVs, but they are still often incorrectly translated. We improve the translation of OOVs in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NMT</a> using easy-to-obtain monolingual data. We look for OOVs in the text to be translated and translate them using simple-to-construct bilingual word embeddings (BWEs). In our MT experiments we take the 5-best candidates, which is motivated by intrinsic mining experiments. Using all five of the proposed target language words as queries we mine target-language sentences. We then back-translate, forcing the <a href=https://en.wikipedia.org/wiki/Back-translation>back-translation</a> of each of the five proposed target-language OOV-translation-candidates to be the original source-language OOV. We show that by using this synthetic data to fine-tune our <a href=https://en.wikipedia.org/wiki/System>system</a> the translation of OOVs can be dramatically improved. In our experiments we use a system trained on <a href=https://en.wikipedia.org/wiki/Europarl>Europarl</a> and mine sentences containing <a href=https://en.wikipedia.org/wiki/Medical_terminology>medical terms</a> from <a href=https://en.wikipedia.org/wiki/Monolingualism>monolingual data</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1583.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1583 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1583 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385434805 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1583/>Target Conditioned Sampling : Optimizing Data Selection for Multilingual Neural Machine Translation</a></strong><br><a href=/people/x/xinyi-wang/>Xinyi Wang</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1583><div class="card-body p-3 small">To improve low-resource Neural Machine Translation (NMT) with multilingual corpus, training on the most related high-resource language only is generally more effective than us- ing all data available (Neubig and Hu, 2018). However, it remains a question whether a smart data selection strategy can further improve low-resource NMT with data from other auxiliary languages. In this paper, we seek to construct a <a href=https://en.wikipedia.org/wiki/Sampling_distribution>sampling distribution</a> over all multilingual data, so that it minimizes the <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training loss</a> of the low-resource language. Based on this formulation, we propose and efficient <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a>, (TCS), which first samples a target sentence, and then conditionally samples its source sentence. Experiments show TCS brings significant gains of up to 2 BLEU improvements on three of four languages we test, with minimal training overhead.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1585.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1585 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1585 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385226453 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1585" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1585/>Merge and Label : A Novel Neural Network Architecture for Nested NER<span class=acl-fixed-case>NER</span></a></strong><br><a href=/people/j/joseph-fisher/>Joseph Fisher</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1585><div class="card-body p-3 small">Named entity recognition (NER) is one of the best studied tasks in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. However, most approaches are not capable of handling nested structures which are common in many applications. In this paper we introduce a novel neural network architecture that first merges tokens and/or entities into entities forming nested structures, and then labels each of them independently. Unlike previous work, our merge and label approach predicts real-valued instead of discrete segmentation structures, which allow it to combine word and nested entity embeddings while maintaining differentiability. We evaluate our approach using the ACE 2005 Corpus, where it achieves state-of-the-art F1 of 74.6, further improved with contextual embeddings (BERT) to 82.4, an overall improvement of close to 8 F1 points over previous approaches trained on the same data. Additionally we compare it against BiLSTM-CRFs, the dominant approach for flat NER structures, demonstrating that its ability to predict nested structures does not impact performance in simpler cases.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1586.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1586 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1586 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385226574 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1586/>Low-resource Deep Entity Resolution with Transfer and Active Learning</a></strong><br><a href=/people/j/jungo-kasai/>Jungo Kasai</a>
|
<a href=/people/k/kun-qian/>Kun Qian</a>
|
<a href=/people/s/sairam-gurajada/>Sairam Gurajada</a>
|
<a href=/people/y/yunyao-li/>Yunyao Li</a>
|
<a href=/people/l/lucian-popa/>Lucian Popa</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1586><div class="card-body p-3 small">Entity resolution (ER) is the task of identifying different representations of the same real-world entities across databases. It is a key step for <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge base creation</a> and <a href=https://en.wikipedia.org/wiki/Text_mining>text mining</a>. Recent adaptation of deep learning methods for ER mitigates the need for dataset-specific feature engineering by constructing distributed representations of entity records. While these methods achieve state-of-the-art performance over benchmark data, they require large amounts of labeled data, which are typically unavailable in realistic ER applications. In this paper, we develop a deep learning-based method that targets low-resource settings for ER through a novel combination of <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> and <a href=https://en.wikipedia.org/wiki/Active_learning>active learning</a>. We design an <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> that allows us to learn a transferable model from a high-resource setting to a low-resource one. To further adapt to the target dataset, we incorporate active learning that carefully selects a few informative examples to fine-tune the transferred model. Empirical evaluation demonstrates that our method achieves comparable, if not better, performance compared to state-of-the-art learning-based methods while using an order of magnitude fewer labels.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1587.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1587 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1587 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1587.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385242676 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1587/>A Semi-Markov Structured Support Vector Machine Model for High-Precision Named Entity Recognition<span class=acl-fixed-case>M</span>arkov Structured Support Vector Machine Model for High-Precision Named Entity Recognition</a></strong><br><a href=/people/r/ravneet-arora/>Ravneet Arora</a>
|
<a href=/people/c/chen-tse-tsai/>Chen-Tse Tsai</a>
|
<a href=/people/k/ketevan-tsereteli/>Ketevan Tsereteli</a>
|
<a href=/people/p/prabhanjan-kambadur/>Prabhanjan Kambadur</a>
|
<a href=/people/y/yi-yang/>Yi Yang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1587><div class="card-body p-3 small">Named entity recognition (NER) is the backbone of many <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP solutions</a>. F1 score, the harmonic mean of precision and recall, is often used to select / evaluate the best <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. However, when <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a> needs to be prioritized over <a href=https://en.wikipedia.org/wiki/Precision_recall>recall</a>, a state-of-the-art <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> might not be the best choice. There is little in literature that directly addresses training-time modifications to achieve higher precision information extraction. In this paper, we propose a neural semi-Markov structured support vector machine model that controls the precision-recall trade-off by assigning weights to different types of errors in the loss-augmented inference during training. The semi-Markov property provides more accurate phrase-level predictions, thereby improving performance. We empirically demonstrate the advantage of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> when high <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a> is required by comparing against strong baselines based on CRF. In our experiments with the CoNLL 2003 dataset, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves a better precision-recall trade-off at various precision levels.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1589.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1589 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1589 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385243188 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1589/>Model-Agnostic Meta-Learning for Relation Classification with Limited Supervision</a></strong><br><a href=/people/a/abiola-obamuyide/>Abiola Obamuyide</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1589><div class="card-body p-3 small">In this paper we frame the task of supervised relation classification as an instance of <a href=https://en.wikipedia.org/wiki/Meta-learning>meta-learning</a>. We propose a model-agnostic meta-learning protocol for training relation classifiers to achieve enhanced predictive performance in limited supervision settings. During <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training</a>, we aim to not only learn good parameters for classifying relations with sufficient supervision, but also learn model parameters that can be fine-tuned to enhance predictive performance for relations with limited supervision. In experiments conducted on two relation classification datasets, we demonstrate that the proposed meta-learning approach improves the predictive performance of two state-of-the-art supervised relation classification models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1601.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1601 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1601 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1601" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1601/>Style Transformer : Unpaired Text Style Transfer without Disentangled Latent Representation</a></strong><br><a href=/people/n/ning-dai/>Ning Dai</a>
|
<a href=/people/j/jianze-liang/>Jianze Liang</a>
|
<a href=/people/x/xipeng-qiu/>Xipeng Qiu</a>
|
<a href=/people/x/xuan-jing-huang/>Xuanjing Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1601><div class="card-body p-3 small">Disentangling the content and style in the latent space is prevalent in unpaired text style transfer. However, two major issues exist in most of the current neural models. 1) It is difficult to completely strip the style information from the <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> for a sentence. 2) The recurrent neural network (RNN) based encoder and decoder, mediated by the latent representation, can not well deal with the issue of the long-term dependency, resulting in poor preservation of non-stylistic semantic content. In this paper, we propose the Style Transformer, which makes no assumption about the latent representation of source sentence and equips the power of attention mechanism in Transformer to achieve better style transfer and better content preservation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1603.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1603 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1603 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1603/>Learning to Control the Fine-grained Sentiment for Story Ending Generation</a></strong><br><a href=/people/f/fuli-luo/>Fuli Luo</a>
|
<a href=/people/d/damai-dai/>Damai Dai</a>
|
<a href=/people/p/pengcheng-yang/>Pengcheng Yang</a>
|
<a href=/people/t/tianyu-liu/>Tianyu Liu</a>
|
<a href=/people/b/baobao-chang/>Baobao Chang</a>
|
<a href=/people/z/zhifang-sui/>Zhifang Sui</a>
|
<a href=/people/x/xu-sun/>Xu Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1603><div class="card-body p-3 small">Automatic story ending generation is an interesting and challenging task in <a href=https://en.wikipedia.org/wiki/Natural-language_generation>natural language generation</a>. Previous studies are mainly limited to generate coherent, reasonable and diversified story endings, and few works focus on controlling the sentiment of story endings. This paper focuses on generating a story ending which meets the given fine-grained sentiment intensity. There are two major challenges to this task. First is the lack of story corpus which has fine-grained sentiment labels. Second is the difficulty of explicitly controlling sentiment intensity when generating <a href=https://en.wikipedia.org/wiki/Ending_(linguistics)>endings</a>. Therefore, we propose a generic and novel framework which consists of a <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analyzer</a> and a sentimental generator, respectively addressing the two challenges. The sentiment analyzer adopts a series of methods to acquire <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment intensities</a> of the <a href=https://en.wikipedia.org/wiki/Story_arc>story dataset</a>. The sentimental generator introduces the sentiment intensity into decoder via a Gaussian Kernel Layer to control the sentiment of the output. To the best of our knowledge, this is the first endeavor to control the fine-grained sentiment for story ending generation without manually annotating sentiment labels. Experiments show that our proposed <a href=https://en.wikipedia.org/wiki/Conceptual_framework>framework</a> can generate story endings which are not only more coherent and fluent but also able to meet the given sentiment intensity better.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1606.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1606 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1606 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1606/>Storyboarding of Recipes : Grounded Contextual Generation</a></strong><br><a href=/people/k/khyathi-chandu/>Khyathi Chandu</a>
|
<a href=/people/e/eric-nyberg/>Eric Nyberg</a>
|
<a href=/people/a/alan-w-black/>Alan W Black</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1606><div class="card-body p-3 small">Information need of humans is essentially multimodal in nature, enabling maximum exploitation of situated context. We introduce a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for sequential procedural (how-to) text generation from images in cooking domain. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> consists of 16,441 cooking recipes with 160,479 photos associated with different steps. We setup a baseline motivated by the best performing model in terms of human evaluation for the Visual Story Telling (ViST) task. In addition, we introduce two models to incorporate high level structure learnt by a Finite State Machine (FSM) in neural sequential generation process by : (1) Scaffolding Structure in Decoder (SSiD) (2) Scaffolding Structure in Loss (SSiL). Our best performing <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> (SSiL) achieves a <a href=https://en.wikipedia.org/wiki/METEOR>METEOR score</a> of 0.31, which is an improvement of 0.6 over the baseline model. We also conducted human evaluation of the generated grounded recipes, which reveal that 61 % found that our proposed (SSiL) model is better than the baseline model in terms of overall recipes. We also discuss analysis of the output highlighting key important NLP issues for prospective directions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1607.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1607 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1607 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1607/>Negative Lexically Constrained Decoding for <a href=https://en.wikipedia.org/wiki/Paraphrase_generation>Paraphrase Generation</a></a></strong><br><a href=/people/t/tomoyuki-kajiwara/>Tomoyuki Kajiwara</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1607><div class="card-body p-3 small">Paraphrase generation can be regarded as monolingual translation. Unlike bilingual machine translation, <a href=https://en.wikipedia.org/wiki/Paraphrase_generation>paraphrase generation</a> rewrites only a limited portion of an input sentence. Hence, previous methods based on <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> often perform conservatively to fail to make necessary rewrites. To solve this problem, we propose a neural model for <a href=https://en.wikipedia.org/wiki/Paraphrase_generation>paraphrase generation</a> that first identifies words in the source sentence that should be paraphrased. Then, these words are paraphrased by the negative lexically constrained decoding that avoids outputting these words as they are. Experiments on text simplification and formality transfer show that our model improves the quality of <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrasing</a> by making necessary rewrites to an input sentence.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1610.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1610 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1610 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1610" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1610/>Improving the <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>Robustness</a> of <a href=https://en.wikipedia.org/wiki/Question_answering>Question Answering Systems</a> to Question Paraphrasing</a></strong><br><a href=/people/w/wee-chung-gan/>Wee Chung Gan</a>
|
<a href=/people/h/hwee-tou-ng/>Hwee Tou Ng</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1610><div class="card-body p-3 small">Despite the advancement of question answering (QA) systems and rapid improvements on held-out test sets, their generalizability is a topic of concern. We explore the robustness of QA models to question paraphrasing by creating two test sets consisting of paraphrased SQuAD questions. Paraphrased questions from the first test set are very similar to the original questions designed to test QA models&#8217; over-sensitivity, while questions from the second test set are paraphrased using context words near an incorrect answer candidate in an attempt to confuse QA models. We show that both paraphrased test sets lead to significant decrease in performance on multiple state-of-the-art QA models. Using a neural paraphrasing model trained to generate multiple paraphrased questions for a given source question and a set of paraphrase suggestions, we propose a data augmentation approach that requires no human intervention to re-train the models for improved robustness to question paraphrasing.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1611.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1611 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1611 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1611" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1611/>RankQA : Neural Question Answering with Answer Re-Ranking<span class=acl-fixed-case>R</span>ank<span class=acl-fixed-case>QA</span>: Neural Question Answering with Answer Re-Ranking</a></strong><br><a href=/people/b/bernhard-kratzwald/>Bernhard Kratzwald</a>
|
<a href=/people/a/anna-eigenmann/>Anna Eigenmann</a>
|
<a href=/people/s/stefan-feuerriegel/>Stefan Feuerriegel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1611><div class="card-body p-3 small">The conventional paradigm in neural question answering (QA) for narrative content is limited to a two-stage process : first, relevant text passages are retrieved and, subsequently, a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> for machine comprehension extracts the likeliest answer. However, both stages are largely isolated in the status quo and, hence, information from the two phases is never properly fused. In contrast, this work proposes RankQA : RankQA extends the conventional two-stage process in neural QA with a third stage that performs an additional answer re-ranking. The re-ranking leverages different <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> that are directly extracted from the <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA pipeline</a>, i.e., a combination of retrieval and comprehension features. While our intentionally simple design allows for an efficient, data-sparse estimation, it nevertheless outperforms more complex QA systems by a significant margin : in fact, RankQA achieves state-of-the-art performance on 3 out of 4 benchmark datasets. Furthermore, its performance is especially superior in settings where the size of the corpus is dynamic. Here the answer re-ranking provides an effective remedy against the underlying noise-information trade-off due to a variable corpus size. As a consequence, RankQA represents a novel, powerful, and thus challenging baseline for future research in content-based QA.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1613.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1613 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1613 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1613" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1613/>Multi-hop Reading Comprehension through Question Decomposition and Rescoring</a></strong><br><a href=/people/s/sewon-min/>Sewon Min</a>
|
<a href=/people/v/victor-zhong/>Victor Zhong</a>
|
<a href=/people/l/luke-zettlemoyer/>Luke Zettlemoyer</a>
|
<a href=/people/h/hannaneh-hajishirzi/>Hannaneh Hajishirzi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1613><div class="card-body p-3 small">Multi-hop Reading Comprehension (RC) requires <a href=https://en.wikipedia.org/wiki/Reason>reasoning</a> and aggregation across several paragraphs. We propose a system for multi-hop RC that decomposes a compositional question into simpler sub-questions that can be answered by off-the-shelf single-hop RC models. Since annotations for such decomposition are expensive, we recast subquestion generation as a span prediction problem and show that our method, trained using only 400 labeled examples, generates sub-questions that are as effective as human-authored sub-questions. We also introduce a new global rescoring approach that considers each decomposition (i.e. the sub-questions and their answers) to select the best final answer, greatly improving overall performance. Our experiments on HotpotQA show that this approach achieves the state-of-the-art results, while providing explainable evidence for its decision making in the form of sub-questions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1614.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1614 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1614 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1614/>Combining Knowledge Hunting and Neural Language Models to Solve the Winograd Schema Challenge<span class=acl-fixed-case>W</span>inograd Schema Challenge</a></strong><br><a href=/people/a/ashok-prakash/>Ashok Prakash</a>
|
<a href=/people/a/arpit-sharma/>Arpit Sharma</a>
|
<a href=/people/a/arindam-mitra/>Arindam Mitra</a>
|
<a href=/people/c/chitta-baral/>Chitta Baral</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1614><div class="card-body p-3 small">Winograd Schema Challenge (WSC) is a pronoun resolution task which seems to require reasoning with commonsense knowledge. The needed knowledge is not present in the given text. Automatic extraction of the needed knowledge is a bottleneck in solving the challenge. The existing state-of-the-art approach uses the knowledge embedded in their pre-trained <a href=https://en.wikipedia.org/wiki/Language_model>language model</a>. However, the <a href=https://en.wikipedia.org/wiki/Conceptual_model_(computer_science)>language models</a> only embed part of the knowledge, the ones related to frequently co-existing concepts. This limits the performance of such <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on the WSC problems. In this work, we build-up on the language model based methods and augment them with a commonsense knowledge hunting (using automatic extraction from text) module and an explicit reasoning module. Our <a href=https://en.wikipedia.org/wiki/End-to-end_principle>end-to-end system</a> built in such a manner improves on the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of two of the available language model based approaches by 5.53 % and 7.7 % respectively. Overall our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves the state-of-the-art accuracy of 71.06 % on the WSC dataset, an improvement of 7.36 % over the previous best.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1615.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1615 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1615 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1615/>Careful Selection of Knowledge to Solve Open Book Question Answering</a></strong><br><a href=/people/p/pratyay-banerjee/>Pratyay Banerjee</a>
|
<a href=/people/k/kuntal-kumar-pal/>Kuntal Kumar Pal</a>
|
<a href=/people/a/arindam-mitra/>Arindam Mitra</a>
|
<a href=/people/c/chitta-baral/>Chitta Baral</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1615><div class="card-body p-3 small">Open book question answering is a type of natural language based QA (NLQA) where questions are expected to be answered with respect to a given set of open book facts, and <a href=https://en.wikipedia.org/wiki/Common_knowledge>common knowledge</a> about a topic. Recently a challenge involving such <a href=https://en.wikipedia.org/wiki/Quality_assurance>QA</a>, OpenBookQA, has been proposed. Unlike most other NLQA that focus on <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>linguistic understanding</a>, OpenBookQA requires deeper reasoning involving <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>linguistic understanding</a> as well as reasoning with <a href=https://en.wikipedia.org/wiki/Common_knowledge_(logic)>common knowledge</a>. In this paper we address QA with respect to the OpenBookQA dataset and combine state of the art language models with abductive information retrieval (IR), information gain based re-ranking, passage selection and <a href=https://en.wikipedia.org/wiki/Weighted_arithmetic_mean>weighted scoring</a> to achieve 72.0 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>, an 11.6 % improvement over the current state of the art.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1616.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1616 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1616 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1616" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1616/>Learning Representation Mapping for Relation Detection in Knowledge Base Question Answering</a></strong><br><a href=/people/p/peng-wu/>Peng Wu</a>
|
<a href=/people/s/shujian-huang/>Shujian Huang</a>
|
<a href=/people/r/rongxiang-weng/>Rongxiang Weng</a>
|
<a href=/people/z/zaixiang-zheng/>Zaixiang Zheng</a>
|
<a href=/people/j/jianbing-zhang/>Jianbing Zhang</a>
|
<a href=/people/x/xiaohui-yan/>Xiaohui Yan</a>
|
<a href=/people/j/jiajun-chen/>Jiajun Chen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1616><div class="card-body p-3 small">Relation detection is a core step in many <a href=https://en.wikipedia.org/wiki/Natural-language_user_interface>natural language process applications</a> including <a href=https://en.wikipedia.org/wiki/Question_answering>knowledge base question answering</a>. Previous efforts show that single-fact questions could be answered with high <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. However, one critical problem is that current approaches only get high <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> for questions whose relations have been seen in the training data. But for unseen relations, the performance will drop rapidly. The main reason for this problem is that the <a href=https://en.wikipedia.org/wiki/Representation_(mathematics)>representations</a> for unseen relations are missing. In this paper, we propose a simple mapping method, named representation adapter, to learn the <a href=https://en.wikipedia.org/wiki/Representation_theory>representation mapping</a> for both seen and unseen relations based on previously learned relation embedding. We employ the adversarial objective and the reconstruction objective to improve the <a href=https://en.wikipedia.org/wiki/Cartography>mapping</a> performance. We re-organize the popular SimpleQuestion dataset to reveal and evaluate the problem of detecting unseen relations. Experiments show that our method can greatly improve the performance of unseen relations while the performance for those seen part is kept comparable to the <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-the-art</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1621.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1621 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1621 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1621" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1621/>Are Red Roses Red? Evaluating Consistency of Question-Answering Models</a></strong><br><a href=/people/m/marco-tulio-ribeiro/>Marco Tulio Ribeiro</a>
|
<a href=/people/c/carlos-guestrin/>Carlos Guestrin</a>
|
<a href=/people/s/sameer-singh/>Sameer Singh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1621><div class="card-body p-3 small">Although current evaluation of <a href=https://en.wikipedia.org/wiki/Question_answering>question-answering systems</a> treats predictions in isolation, we need to consider the relationship between predictions to measure true understanding. A <a href=https://en.wikipedia.org/wiki/Model_(person)>model</a> should be penalized for answering no to Is the rose red? if it answers red to What color is the rose?. We propose a method to automatically extract such implications for instances from two QA datasets, VQA and SQuAD, which we then use to evaluate the consistency of models. Human evaluation shows these generated implications are well formed and valid. Consistency evaluation provides crucial insights into gaps in existing models, while retraining with implication-augmented data improves <a href=https://en.wikipedia.org/wiki/Consistency>consistency</a> on both synthetic and human-generated implications.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1623.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1623 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1623 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1623/>Reducing Word Omission Errors in Neural Machine Translation : A Contrastive Learning Approach</a></strong><br><a href=/people/z/zonghan-yang/>Zonghan Yang</a>
|
<a href=/people/y/yong-cheng/>Yong Cheng</a>
|
<a href=/people/y/yang-liu-ict/>Yang Liu</a>
|
<a href=/people/m/maosong-sun/>Maosong Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1623><div class="card-body p-3 small">While neural machine translation (NMT) has achieved remarkable success, NMT systems are prone to make word omission errors. In this work, we propose a contrastive learning approach to reducing word omission errors in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NMT</a>. The basic idea is to enable the NMT model to assign a higher probability to a ground-truth translation and a lower probability to an erroneous translation, which is automatically constructed from the ground-truth translation by omitting words. We design different types of negative examples depending on the number of omitted words, <a href=https://en.wikipedia.org/wiki/Word_frequency>word frequency</a>, and <a href=https://en.wikipedia.org/wiki/Part_of_speech>part of speech</a>. Experiments on Chinese-to-English, German-to-English, and Russian-to-English translation tasks show that our approach is effective in reducing word omission errors and achieves better <a href=https://en.wikipedia.org/wiki/Translation>translation</a> performance than three baseline methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1627.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1627 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1627 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1627" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1627/>An Automated Framework for Fast Cognate Detection and Bayesian Phylogenetic Inference in Computational Historical Linguistics<span class=acl-fixed-case>B</span>ayesian Phylogenetic Inference in Computational Historical Linguistics</a></strong><br><a href=/people/t/taraka-rama/>Taraka Rama</a>
|
<a href=/people/j/johann-mattis-list/>Johann-Mattis List</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1627><div class="card-body p-3 small">We present a fully automated workflow for phylogenetic reconstruction on large datasets, consisting of two novel methods, one for fast detection of cognates and one for fast Bayesian phylogenetic inference. Our results show that the <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>methods</a> take less than a few minutes to process <a href=https://en.wikipedia.org/wiki/Language_family>language families</a> that have so far required large amounts of time and computational power. Moreover, the <a href=https://en.wikipedia.org/wiki/Cognate>cognates</a> and the trees inferred from the method are quite close, both to gold standard cognate judgments and to expert language family trees. Given its speed and ease of application, our <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> is specifically useful for the exploration of very large datasets in <a href=https://en.wikipedia.org/wiki/Historical_linguistics>historical linguistics</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1628.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1628 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1628 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1628" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1628/>Sentence Centrality Revisited for Unsupervised Summarization</a></strong><br><a href=/people/h/hao-zheng/>Hao Zheng</a>
|
<a href=/people/m/mirella-lapata/>Mirella Lapata</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1628><div class="card-body p-3 small">Single document summarization has enjoyed renewed interest in recent years thanks to the popularity of <a href=https://en.wikipedia.org/wiki/Artificial_neural_network>neural network models</a> and the availability of <a href=https://en.wikipedia.org/wiki/Data_set>large-scale datasets</a>. In this paper we develop an <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised approach</a> arguing that it is unrealistic to expect large-scale and high-quality training data to be available or created for different types of summaries, domains, or languages. We revisit a popular graph-based ranking algorithm and modify how node (aka sentence) centrality is computed in two ways : (a) we employ BERT, a state-of-the-art neural representation learning model to better capture sentential meaning and (b) we build graphs with directed edges arguing that the contribution of any two nodes to their respective <a href=https://en.wikipedia.org/wiki/Centrality>centrality</a> is influenced by their relative position in a document. Experimental results on three news summarization datasets representative of different languages and writing styles show that our approach outperforms strong baselines by a wide margin.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1629.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1629 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1629 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1629.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file-code"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1629/>Discourse Representation Parsing for Sentences and Documents</a></strong><br><a href=/people/j/jiangming-liu/>Jiangming Liu</a>
|
<a href=/people/s/shay-b-cohen/>Shay B. Cohen</a>
|
<a href=/people/m/mirella-lapata/>Mirella Lapata</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1629><div class="card-body p-3 small">We introduce a novel semantic parsing task based on Discourse Representation Theory (DRT ; Kamp and Reyle 1993). Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> operates over Discourse Representation Tree Structures which we formally define for sentences and documents. We present a general <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> for parsing discourse structures of arbitrary length and granularity. We achieve this with a neural model equipped with a supervised hierarchical attention mechanism and a linguistically-motivated copy strategy. Experimental results on sentence- and document-level benchmarks show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms competitive baselines by a wide margin.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1631.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1631 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1631 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1631.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1631/>Incorporating Priors with Feature Attribution on Text Classification</a></strong><br><a href=/people/f/frederick-liu/>Frederick Liu</a>
|
<a href=/people/b/besim-avci/>Besim Avci</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1631><div class="card-body p-3 small">Feature attribution methods, proposed recently, help users interpret the predictions of <a href=https://en.wikipedia.org/wiki/Complex_system>complex models</a>. Our approach integrates feature attributions into the <a href=https://en.wikipedia.org/wiki/Loss_function>objective function</a> to allow machine learning practitioners to incorporate <a href=https://en.wikipedia.org/wiki/Prior_probability>priors</a> in model building. To demonstrate the effectiveness our technique, we apply it to two tasks : (1) mitigating unintended bias in text classifiers by neutralizing identity terms ; (2) improving <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> performance in scarce data setting by forcing model to focus on toxic terms. Our approach adds an L2 distance loss between feature attributions and task-specific prior values to the <a href=https://en.wikipedia.org/wiki/Object_(philosophy)>objective</a>. Our experiments show that i) a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> trained with our technique reduces undesired model biases without a tradeoff on the original task ; ii) incorporating prior helps model performance in scarce data settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1632.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1632 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1632 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1632" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1632/>Matching Article Pairs with Graphical Decomposition and Convolutions</a></strong><br><a href=/people/b/bang-liu/>Bang Liu</a>
|
<a href=/people/d/di-niu/>Di Niu</a>
|
<a href=/people/h/haojie-wei/>Haojie Wei</a>
|
<a href=/people/j/jinghong-lin/>Jinghong Lin</a>
|
<a href=/people/y/yancheng-he/>Yancheng He</a>
|
<a href=/people/k/kunfeng-lai/>Kunfeng Lai</a>
|
<a href=/people/y/yu-xu/>Yu Xu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1632><div class="card-body p-3 small">Identifying the relationship between two articles, e.g., whether two articles published from different sources describe the same <a href=https://en.wikipedia.org/wiki/Breaking_news>breaking news</a>, is critical to many document understanding tasks. Existing approaches for modeling and matching sentence pairs do not perform well in matching longer documents, which embody more complex interactions between the enclosed entities than a sentence does. To model article pairs, we propose the Concept Interaction Graph to represent an article as a graph of concepts. We then match a pair of articles by comparing the sentences that enclose the same concept vertex through a series of encoding techniques, and aggregate the matching signals through a graph convolutional network. To facilitate the evaluation of long article matching, we have created two <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>, each consisting of about 30 K pairs of <a href=https://en.wikipedia.org/wiki/Breaking_news>breaking news articles</a> covering diverse topics in the <a href=https://en.wikipedia.org/wiki/Open_domain>open domain</a>. Extensive evaluations of the proposed <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> on the two <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> demonstrate significant improvements over a wide range of state-of-the-art methods for natural language matching.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1636.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1636 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1636 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1636" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1636/>Large-Scale Multi-Label Text Classification on EU Legislation<span class=acl-fixed-case>EU</span> Legislation</a></strong><br><a href=/people/i/ilias-chalkidis/>Ilias Chalkidis</a>
|
<a href=/people/e/emmanouil-fergadiotis/>Emmanouil Fergadiotis</a>
|
<a href=/people/p/prodromos-malakasiotis/>Prodromos Malakasiotis</a>
|
<a href=/people/i/ion-androutsopoulos/>Ion Androutsopoulos</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1636><div class="card-body p-3 small">We consider Large-Scale Multi-Label Text Classification (LMTC) in the legal domain. We release a new dataset of 57k legislative documents from EUR-LEX, annotated with 4.3k EUROVOC labels, which is suitable for LMTC, few- and zero-shot learning. Experimenting with several neural classifiers, we show that BIGRUs with label-wise attention perform better than other current state of the art methods. Domain-specific WORD2VEC and context-sensitive ELMO embeddings further improve performance. We also find that considering only particular zones of the documents is sufficient. This allows us to bypass BERT&#8217;s maximum text length limit and fine-tune BERT, obtaining the best results in all but zero-shot learning cases.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1641.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1641 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1641 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1641/>Dense Procedure Captioning in Narrated Instructional Videos</a></strong><br><a href=/people/b/botian-shi/>Botian Shi</a>
|
<a href=/people/l/lei-ji/>Lei Ji</a>
|
<a href=/people/y/yaobo-liang/>Yaobo Liang</a>
|
<a href=/people/n/nan-duan/>Nan Duan</a>
|
<a href=/people/p/peng-chen/>Peng Chen</a>
|
<a href=/people/z/zhendong-niu/>Zhendong Niu</a>
|
<a href=/people/m/ming-zhou/>Ming Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1641><div class="card-body p-3 small">Understanding narrated instructional videos is important for both research and real-world web applications. Motivated by video dense captioning, we propose a model to generate procedure captions from narrated instructional videos which are a sequence of step-wise clips with description. Previous works on video dense captioning learn video segments and generate <a href=https://en.wikipedia.org/wiki/Closed_captioning>captions</a> without considering <a href=https://en.wikipedia.org/wiki/Transcript_(law)>transcripts</a>. We argue that transcripts in narrated instructional videos can enhance video representation by providing fine-grained complimentary and semantic textual information. In this paper, we introduce a framework to (1) extract procedures by a cross-modality module, which fuses video content with the entire transcript ; and (2) generate captions by encoding video frames as well as a snippet of transcripts within each extracted procedure. Experiments show that our model can achieve state-of-the-art performance in procedure extraction and captioning, and the ablation studies demonstrate that both the video frames and the transcripts are important for the task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1642.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1642 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1642 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1642" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1642/>Latent Variable Model for Multi-modal Translation</a></strong><br><a href=/people/i/iacer-calixto/>Iacer Calixto</a>
|
<a href=/people/m/miguel-rios/>Miguel Rios</a>
|
<a href=/people/w/wilker-aziz/>Wilker Aziz</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1642><div class="card-body p-3 small">In this work, we propose to model the interaction between visual and textual features for multi-modal neural machine translation (MMT) through a <a href=https://en.wikipedia.org/wiki/Latent_variable_model>latent variable model</a>. This <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variable</a> can be seen as a multi-modal stochastic embedding of an image and its description in a <a href=https://en.wikipedia.org/wiki/Foreign_language>foreign language</a>. It is used in a target-language decoder and also to predict <a href=https://en.wikipedia.org/wiki/Feature_(computer_vision)>image features</a>. Importantly, our model formulation utilises visual and textual inputs during training but does not require that images be available at test time. We show that our latent variable MMT formulation improves considerably over strong baselines, including a multi-task learning approach (Elliott and Kadar, 2017) and a conditional variational auto-encoder approach (Toyama et al., 2016). Finally, we show improvements due to (i) predicting image features in addition to only conditioning on them, (ii) imposing a <a href=https://en.wikipedia.org/wiki/Constraint_(mathematics)>constraint</a> on the KL term to promote models with non-negligible mutual information between inputs and <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variable</a>, and (iii) by training on additional target-language image descriptions (i.e. synthetic data).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1643.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1643 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1643 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1643" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1643/>Identifying Visible Actions in Lifestyle Vlogs</a></strong><br><a href=/people/o/oana-ignat/>Oana Ignat</a>
|
<a href=/people/l/laura-burdick/>Laura Burdick</a>
|
<a href=/people/j/jia-deng/>Jia Deng</a>
|
<a href=/people/r/rada-mihalcea/>Rada Mihalcea</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1643><div class="card-body p-3 small">We consider the task of identifying <a href=https://en.wikipedia.org/wiki/Human_behavior>human actions</a> visible in <a href=https://en.wikipedia.org/wiki/Online_video_platform>online videos</a>. We focus on the widely spread genre of lifestyle vlogs, which consist of videos of people performing actions while verbally describing them. Our goal is to identify if actions mentioned in the speech description of a video are visually present. We construct a dataset with crowdsourced manual annotations of visible actions, and introduce a multimodal algorithm that leverages information derived from visual and linguistic clues to automatically infer which actions are visible in a video.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1644.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1644 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1644 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1644.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i>
</a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1644" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1644/>A Corpus for Reasoning about Natural Language Grounded in <a href=https://en.wikipedia.org/wiki/Photograph>Photographs</a></a></strong><br><a href=/people/a/alane-suhr/>Alane Suhr</a>
|
<a href=/people/s/stephanie-zhou/>Stephanie Zhou</a>
|
<a href=/people/a/ally-zhang/>Ally Zhang</a>
|
<a href=/people/i/iris-zhang/>Iris Zhang</a>
|
<a href=/people/h/huajun-bai/>Huajun Bai</a>
|
<a href=/people/y/yoav-artzi/>Yoav Artzi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1644><div class="card-body p-3 small">We introduce a new dataset for joint reasoning about natural language and images, with a focus on semantic diversity, <a href=https://en.wikipedia.org/wiki/Compositionality>compositionality</a>, and visual reasoning challenges. The <a href=https://en.wikipedia.org/wiki/Data>data</a> contains 107,292 examples of <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>English sentences</a> paired with web photographs. The task is to determine whether a natural language caption is true about a pair of photographs. We crowdsource the <a href=https://en.wikipedia.org/wiki/Data>data</a> using sets of visually rich images and a compare-and-contrast task to elicit <a href=https://en.wikipedia.org/wiki/Linguistic_diversity>linguistically diverse language</a>. Qualitative analysis shows the <a href=https://en.wikipedia.org/wiki/Data>data</a> requires compositional joint reasoning, including about <a href=https://en.wikipedia.org/wiki/Physical_quantity>quantities</a>, comparisons, and <a href=https://en.wikipedia.org/wiki/Binary_relation>relations</a>. Evaluation using state-of-the-art visual reasoning methods shows the <a href=https://en.wikipedia.org/wiki/Data>data</a> presents a strong challenge.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1645.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1645 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1645 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1645/>Learning to Discover, Ground and Use Words with Segmental Neural Language Models</a></strong><br><a href=/people/k/kazuya-kawakami/>Kazuya Kawakami</a>
|
<a href=/people/c/chris-dyer/>Chris Dyer</a>
|
<a href=/people/p/phil-blunsom/>Phil Blunsom</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1645><div class="card-body p-3 small">We propose a segmental neural language model that combines the generalization power of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> with the ability to discover word-like units that are latent in unsegmented character sequences. In contrast to previous segmentation models that treat <a href=https://en.wikipedia.org/wiki/Word_segmentation>word segmentation</a> as an isolated task, our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> unifies word discovery, learning how words fit together to form sentences, and, by conditioning the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> on visual context, how words&#8217; meanings ground in representations of nonlinguistic modalities. Experiments show that the unconditional model learns predictive distributions better than character LSTM models, discovers words competitively with nonparametric Bayesian word segmentation models, and that modeling language conditional on visual context improves performance on both.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1647.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1647 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1647 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1647" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1647/>Symbolic Inductive Bias for Visually Grounded Learning of Spoken Language</a></strong><br><a href=/people/g/grzegorz-chrupala/>Grzegorz Chrupała</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1647><div class="card-body p-3 small">A widespread approach to processing <a href=https://en.wikipedia.org/wiki/Spoken_language>spoken language</a> is to first automatically transcribe it into text. An alternative is to use an <a href=https://en.wikipedia.org/wiki/End-to-end_principle>end-to-end approach</a> : recent works have proposed to learn semantic embeddings of spoken language from images with spoken captions, without an intermediate transcription step. We propose to use <a href=https://en.wikipedia.org/wiki/Multitask_learning>multitask learning</a> to exploit existing transcribed speech within the end-to-end setting. We describe a three-task architecture which combines the objectives of matching spoken captions with corresponding <a href=https://en.wikipedia.org/wiki/Image>images</a>, speech with text, and text with images. We show that the addition of the speech / text task leads to substantial performance improvements on <a href=https://en.wikipedia.org/wiki/Image_retrieval>image retrieval</a> when compared to training the speech / image task in isolation. We conjecture that this is due to a strong inductive bias transcribed speech provides to the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>, and offer supporting evidence for this.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1648.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1648 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1648 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1648/>Multi-step Reasoning via Recurrent Dual Attention for Visual Dialog</a></strong><br><a href=/people/z/zhe-gan/>Zhe Gan</a>
|
<a href=/people/y/yu-cheng/>Yu Cheng</a>
|
<a href=/people/a/ahmed-kholy/>Ahmed Kholy</a>
|
<a href=/people/l/linjie-li/>Linjie Li</a>
|
<a href=/people/j/jingjing-liu/>Jingjing Liu</a>
|
<a href=/people/j/jianfeng-gao/>Jianfeng Gao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1648><div class="card-body p-3 small">This paper presents a new model for visual dialog, Recurrent Dual Attention Network (ReDAN), using multi-step reasoning to answer a series of questions about an image. In each question-answering turn of a dialog, ReDAN infers the answer progressively through multiple reasoning steps. In each step of the reasoning process, the semantic representation of the question is updated based on the image and the previous dialog history, and the recurrently-refined representation is used for further reasoning in the subsequent step. On the VisDial v1.0 dataset, the proposed ReDAN model achieves a new state-of-the-art of 64.47 % NDCG score. Visualization on the reasoning process further demonstrates that ReDAN can locate context-relevant visual and textual clues via iterative refinement, which can lead to the correct answer step-by-step.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1650.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1650 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1650 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1650/>Informative Image Captioning with External Sources of Information</a></strong><br><a href=/people/s/sanqiang-zhao/>Sanqiang Zhao</a>
|
<a href=/people/p/piyush-sharma/>Piyush Sharma</a>
|
<a href=/people/t/tomer-levinboim/>Tomer Levinboim</a>
|
<a href=/people/r/radu-soricut/>Radu Soricut</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1650><div class="card-body p-3 small">An image caption should fluently present the essential information in a given <a href=https://en.wikipedia.org/wiki/Image>image</a>, including informative, fine-grained entity mentions and the manner in which these entities interact. However, current captioning models are usually trained to generate captions that only contain common object names, thus falling short on an important informativeness dimension. We present a mechanism for integrating <a href=https://en.wikipedia.org/wiki/Image>image information</a> together with fine-grained labels (assumed to be generated by some upstream models) into a caption that describes the <a href=https://en.wikipedia.org/wiki/Image>image</a> in a fluent and informative manner. We introduce a multimodal, multi-encoder model based on Transformer that ingests both <a href=https://en.wikipedia.org/wiki/Feature_(computer_vision)>image features</a> and multiple sources of entity labels. We demonstrate that we can learn to control the appearance of these entity labels in the output, resulting in captions that are both fluent and informative.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1653.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1653 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1653 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1653" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1653/>Distilling Translations with Visual Awareness</a></strong><br><a href=/people/j/julia-ive/>Julia Ive</a>
|
<a href=/people/p/pranava-swaroop-madhyastha/>Pranava Madhyastha</a>
|
<a href=/people/l/lucia-specia/>Lucia Specia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1653><div class="card-body p-3 small">Previous work on multimodal machine translation has shown that visual information is only needed in very specific cases, for example in the presence of ambiguous words where the textual context is not sufficient. As a consequence, <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> tend to learn to ignore this information. We propose a translate-and-refine approach to this <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> where <a href=https://en.wikipedia.org/wiki/Digital_image>images</a> are only used by a second stage decoder. This approach is trained jointly to generate a good first draft translation and to improve over this <a href=https://en.wikipedia.org/wiki/Draft_document>draft</a> by (i) making better use of the target language textual context (both left and right-side contexts) and (ii) making use of visual context. This <a href=https://en.wikipedia.org/wiki/Software_development_process>approach</a> leads to the state of the art results. Additionally, we show that <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> has the ability to recover from erroneous or missing words in the source language.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1654.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1654 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1654 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1654/>VIFIDEL : Evaluating the Visual Fidelity of Image Descriptions<span class=acl-fixed-case>VIFIDEL</span>: Evaluating the Visual Fidelity of Image Descriptions</a></strong><br><a href=/people/p/pranava-swaroop-madhyastha/>Pranava Madhyastha</a>
|
<a href=/people/j/josiah-wang/>Josiah Wang</a>
|
<a href=/people/l/lucia-specia/>Lucia Specia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1654><div class="card-body p-3 small">We address the task of evaluating image description generation systems. We propose a novel image-aware metric for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> : VIFIDEL. It estimates the faithfulness of a generated caption with respect to the content of the actual image, based on the <a href=https://en.wikipedia.org/wiki/Semantic_similarity>semantic similarity</a> between labels of objects depicted in images and words in the description. The <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> is also able to take into account the relative importance of objects mentioned in human reference descriptions during <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation</a>. Even if these human reference descriptions are not available, VIFIDEL can still reliably evaluate system descriptions. The <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> achieves high correlation with human judgments on two well-known <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> and is competitive with <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> that depend on and rely exclusively on human references.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1655.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1655 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1655 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1655.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1655/>Are You Looking? Grounding to Multiple Modalities in Vision-and-Language Navigation</a></strong><br><a href=/people/r/ronghang-hu/>Ronghang Hu</a>
|
<a href=/people/d/daniel-fried/>Daniel Fried</a>
|
<a href=/people/a/anna-rohrbach/>Anna Rohrbach</a>
|
<a href=/people/d/dan-klein/>Dan Klein</a>
|
<a href=/people/t/trevor-darrell/>Trevor Darrell</a>
|
<a href=/people/k/kate-saenko/>Kate Saenko</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1655><div class="card-body p-3 small">Vision-and-Language Navigation (VLN) requires grounding instructions, such as turn right and stop at the door, to routes in a visual environment. The actual grounding can connect language to the environment through multiple <a href=https://en.wikipedia.org/wiki/Linguistic_modality>modalities</a>, e.g. stop at the door might ground into visual objects, while turn right might rely only on the geometric structure of a route. We investigate where the <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a> empirically grounds under two recent state-of-the-art VLN models. Surprisingly, we discover that visual features may actually hurt these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> : <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> which only use route structure, ablating visual features, outperform their visual counterparts in unseen new environments on the benchmark Room-to-Room dataset. To better use all the available modalities, we propose to decompose the grounding procedure into a set of expert models with access to different modalities (including object detections) and ensemble them at prediction time, improving the performance of state-of-the-art models on the VLN task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1656.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1656 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1656 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1656" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1656/>Multimodal Transformer for Unaligned Multimodal Language Sequences</a></strong><br><a href=/people/y/yao-hung-hubert-tsai/>Yao-Hung Hubert Tsai</a>
|
<a href=/people/s/shaojie-bai/>Shaojie Bai</a>
|
<a href=/people/p/paul-pu-liang/>Paul Pu Liang</a>
|
<a href=/people/j/j-zico-kolter/>J. Zico Kolter</a>
|
<a href=/people/l/louis-philippe-morency/>Louis-Philippe Morency</a>
|
<a href=/people/r/ruslan-salakhutdinov/>Ruslan Salakhutdinov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1656><div class="card-body p-3 small">Human language is often multimodal, which comprehends a mixture of <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>, facial gestures, and acoustic behaviors. However, two major challenges in modeling such multimodal human language time-series data exist : 1) inherent data non-alignment due to variable sampling rates for the sequences from each modality ; and 2) long-range dependencies between elements across modalities. In this paper, we introduce the Multimodal Transformer (MulT) to generically address the above issues in an end-to-end manner without explicitly aligning the data. At the heart of our model is the directional pairwise crossmodal attention, which attends to interactions between multimodal sequences across distinct time steps and latently adapt streams from one modality to another. Comprehensive experiments on both aligned and non-aligned multimodal time-series show that our model outperforms state-of-the-art methods by a large margin. In addition, empirical analysis suggests that correlated crossmodal signals are able to be captured by the proposed crossmodal attention mechanism in MulT.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1657.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1657 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1657 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/P19-1657/>Show, Describe and Conclude : On Exploiting the Structure Information of Chest X-ray Reports<span class=acl-fixed-case>X</span>-ray Reports</a></strong><br><a href=/people/b/baoyu-jing/>Baoyu Jing</a>
|
<a href=/people/z/zeya-wang/>Zeya Wang</a>
|
<a href=/people/e/eric-xing/>Eric Xing</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1657><div class="card-body p-3 small">Chest X-Ray (CXR) images are commonly used for <a href=https://en.wikipedia.org/wiki/Screening_(medicine)>clinical screening and diagnosis</a>. Automatically writing reports for these images can considerably lighten the workload of radiologists for summarizing descriptive findings and conclusive impressions. The complex structures between and within sections of the reports pose a great challenge to the automatic report generation. Specifically, the section Impression is a diagnostic summarization over the section Findings ; and the appearance of normality dominates each section over that of abnormality. Existing studies rarely explore and consider this fundamental structure information. In this work, we propose a novel framework which exploits the structure information between and within report sections for generating CXR imaging reports. First, we propose a <a href=https://en.wikipedia.org/wiki/Two-stage_theory>two-stage strategy</a> that explicitly models the relationship between Findings and Impression. Second, we design a novel co-operative multi-agent system that implicitly captures the imbalanced distribution between abnormality and <a href=https://en.wikipedia.org/wiki/Normal_distribution>normality</a>. Experiments on two CXR report datasets show that our method achieves state-of-the-art performance in terms of various evaluation metrics. Our results expose that the proposed approach is able to generate high-quality <a href=https://en.wikipedia.org/wiki/Medical_record>medical reports</a> through integrating the structure information.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1658.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1658 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1658 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=P19-1658" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/P19-1658/>Visual Story Post-Editing</a></strong><br><a href=/people/t/ting-yao-hsu/>Ting-Yao Hsu</a>
|
<a href=/people/c/chieh-yang-huang/>Chieh-Yang Huang</a>
|
<a href=/people/y/yen-chia-hsu/>Yen-Chia Hsu</a>
|
<a href=/people/t/ting-hao-huang/>Ting-Hao Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1658><div class="card-body p-3 small">We introduce the first dataset for human edits of machine-generated visual stories and explore how these collected <a href=https://en.wikipedia.org/wiki/Editing>edits</a> may be used for the visual story post-editing task. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, VIST-Edit, includes 14,905 human-edited versions of 2,981 machine-generated visual stories. The <a href=https://en.wikipedia.org/wiki/Narrative>stories</a> were generated by two state-of-the-art visual storytelling models, each aligned to 5 human-edited versions. We establish baselines for the task, showing how a relatively small set of human edits can be leveraged to boost the performance of large visual storytelling models. We also discuss the weak correlation between automatic evaluation scores and human ratings, motivating the need for new automatic metrics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/P19-1660.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-P19-1660 data-toggle=collapse aria-expanded=false aria-controls=abstract-P19-1660 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/P19-1660.Supplementary.pdf data-toggle=tooltip data-placement=top title=Supplementary><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/P19-1660/>Learning to Relate from Captions and Bounding Boxes</a></strong><br><a href=/people/s/sarthak-garg/>Sarthak Garg</a>
|
<a href=/people/j/joel-ruben-antony-moniz/>Joel Ruben Antony Moniz</a>
|
<a href=/people/a/anshu-aviral/>Anshu Aviral</a>
|
<a href=/people/p/priyatham-bollimpalli/>Priyatham Bollimpalli</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-P19-1660><div class="card-body p-3 small">In this work, we propose a novel approach that predicts the relationships between various entities in an <a href=https://en.wikipedia.org/wiki/Image>image</a> in a weakly supervised manner by relying on <a href=https://en.wikipedia.org/wiki/Image>image captions</a> and object bounding box annotations as the sole source of supervision. Our proposed approach uses a top-down attention mechanism to align entities in captions to objects in the image, and then leverage the syntactic structure of the captions to align the relations. We use these alignments to train a relation classification network, thereby obtaining both grounded captions and dense relationships. We demonstrate the effectiveness of our model on the Visual Genome dataset by achieving a recall@50 of 15 % and recall@100 of 25 % on the relationships present in the image. We also show that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> successfully predicts relations that are not present in the corresponding captions.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>