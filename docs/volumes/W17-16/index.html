<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the First ACL Workshop on Ethics in Natural Language Processing - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/W17-16.pdf>Proceedings of the First <span class=acl-fixed-case>ACL</span> Workshop on Ethics in Natural Language Processing</a></h2><p class=lead><a href=/people/d/dirk-hovy/>Dirk Hovy</a>,
<a href=/people/s/shannon-l-spruit/>Shannon Spruit</a>,
<a href=/people/m/margaret-mitchell/>Margaret Mitchell</a>,
<a href=/people/e/emily-m-bender/>Emily M. Bender</a>,
<a href=/people/m/michael-strube/>Michael Strube</a>,
<a href=/people/h/hanna-wallach/>Hanna Wallach</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>W17-16</dd><dt>Month:</dt><dd>April</dd><dt>Year:</dt><dd>2017</dd><dt>Address:</dt><dd>Valencia, Spain</dd><dt>Venues:</dt><dd><a href=/venues/ethnlp/>EthNLP</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/W17-16>https://aclanthology.org/W17-16</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/W17-16 title="To the current version of the paper by DOI">10.18653/v1/W17-16</a></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/W17-16.pdf>https://aclanthology.org/W17-16.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/W17-16.pdf title="Open PDF of 'Proceedings of the First ACL Workshop on Ethics in Natural Language Processing'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+First+ACL+Workshop+on+Ethics+in+Natural+Language+Processing" title="Search for 'Proceedings of the First ACL Workshop on Ethics in Natural Language Processing' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1600.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1600/>Proceedings of the First <span class=acl-fixed-case>ACL</span> Workshop on Ethics in Natural Language Processing</a></strong><br><a href=/people/d/dirk-hovy/>Dirk Hovy</a>
|
<a href=/people/s/shannon-l-spruit/>Shannon Spruit</a>
|
<a href=/people/m/margaret-mitchell/>Margaret Mitchell</a>
|
<a href=/people/e/emily-m-bender/>Emily M. Bender</a>
|
<a href=/people/m/michael-strube/>Michael Strube</a>
|
<a href=/people/h/hanna-wallach/>Hanna Wallach</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1601.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1601 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1601 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1601/>Gender as a Variable in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural-Language Processing</a> : Ethical Considerations</a></strong><br><a href=/people/b/brian-larson/>Brian Larson</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1601><div class="card-body p-3 small">Researchers and practitioners in natural-language processing (NLP) and related fields should attend to ethical principles in study design, ascription of categories / variables to study participants, and reporting of findings or results. This paper discusses theoretical and ethical frameworks for using <a href=https://en.wikipedia.org/wiki/Gender>gender</a> as a variable in NLP studies and proposes four guidelines for researchers and practitioners. The principles outlined here should guide practitioners, researchers, and peer reviewers, and they may be applicable to other <a href=https://en.wikipedia.org/wiki/Social_class>social categories</a>, such as <a href=https://en.wikipedia.org/wiki/Race_(human_categorization)>race</a>, applied to human beings connected to <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP research</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1602.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1602 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1602 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1602/>These are not the Stereotypes You are Looking For : Bias and Fairness in Authorial Gender Attribution</a></strong><br><a href=/people/c/corina-koolen/>Corina Koolen</a>
|
<a href=/people/a/andreas-van-cranenburgh/>Andreas van Cranenburgh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1602><div class="card-body p-3 small">Stylometric and text categorization results show that author gender can be discerned in texts with relatively high <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. However, it is difficult to explain what gives rise to these results and there are many possible <a href=https://en.wikipedia.org/wiki/Confounding>confounding factors</a>, such as the domain, genre, and target audience of a text. More fundamentally, such classification efforts risk invoking <a href=https://en.wikipedia.org/wiki/Stereotype>stereotyping</a> and <a href=https://en.wikipedia.org/wiki/Essentialism>essentialism</a>. We explore this issue in two datasets of Dutch literary novels, using commonly used descriptive (LIWC, topic modeling) and predictive (machine learning) methods. Our results show the importance of controlling for variables in the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> and we argue for taking care not to overgeneralize from the results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1603.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1603 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1603 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1603/>A Quantitative Study of Data in the NLP community<span class=acl-fixed-case>NLP</span> community</a></strong><br><a href=/people/m/margot-mieskes/>Margot Mieskes</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1603><div class="card-body p-3 small">We present results on a quantitative analysis of publications in the NLP domain on collecting, publishing and availability of research data. We find that a wide range of publications rely on data crawled from the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>web</a>, but few give details on how potentially sensitive data was treated. Additionally, we find that while links to repositories of data are given, they often do not work even a short time after publication. We put together several suggestions on how to improve this situation based on publications from the <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP domain</a>, but also other research areas.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1604.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1604 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1604 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1604/>Ethical by Design : Ethics Best Practices for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a></a></strong><br><a href=/people/j/jochen-l-leidner/>Jochen L. Leidner</a>
|
<a href=/people/v/vassilis-plachouras/>Vassilis Plachouras</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1604><div class="card-body p-3 small">Natural language processing (NLP) systems analyze and/or generate <a href=https://en.wikipedia.org/wiki/Human_language>human language</a>, typically on users&#8217; behalf. One natural and necessary question that needs to be addressed in this context, both in research projects and in production settings, is the question how ethical the work is, both regarding the process and its outcome. Towards this end, we articulate a set of issues, propose a set of best practices, notably a process featuring an ethics review board, and sketch and how they could be meaningfully applied. Our main argument is that ethical outcomes ought to be achieved by design, i.e. by following a process aligned by <a href=https://en.wikipedia.org/wiki/Value_(ethics)>ethical values</a>. We also offer some response options for those facing <a href=https://en.wikipedia.org/wiki/Ethics>ethics issues</a>. While a number of previous works exist that discuss ethical issues, in particular around <a href=https://en.wikipedia.org/wiki/Big_data>big data</a> and <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning</a>, to the authors&#8217; knowledge this is the first account of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> and <a href=https://en.wikipedia.org/wiki/Ethics>ethics</a> from the perspective of a principled process.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1606.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1606 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1606 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1606/>Gender and Dialect Bias in YouTube’s Automatic Captions<span class=acl-fixed-case>Y</span>ou<span class=acl-fixed-case>T</span>ube’s Automatic Captions</a></strong><br><a href=/people/r/rachael-tatman/>Rachael Tatman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1606><div class="card-body p-3 small">This project evaluates the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of YouTube&#8217;s automatically-generated captions across two genders and five dialect groups. Speakers&#8217; dialect and gender was controlled for by using videos uploaded as part of the accent tag challenge, where speakers explicitly identify their language background. The results show robust differences in <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> across both gender and dialect, with lower <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> for 1) women and 2) speakers from Scotland. This finding builds on earlier research finding that speaker&#8217;s sociolinguistic identity may negatively impact their ability to use automatic speech recognition, and demonstrates the need for sociolinguistically-stratified validation of systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1607.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1607 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1607 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1607/>Integrating the Management of Personal Data Protection and <a href=https://en.wikipedia.org/wiki/Open_science>Open Science</a> with Research Ethics</a></strong><br><a href=/people/d/dave-lewis/>Dave Lewis</a>
|
<a href=/people/j/joss-moorkens/>Joss Moorkens</a>
|
<a href=/people/k/kaniz-fatema/>Kaniz Fatema</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1607><div class="card-body p-3 small">We examine the impact of the <a href=https://en.wikipedia.org/wiki/General_Data_Protection_Regulation>EU General Data Protection Regulation</a> and the push from research funders to provide open access research data on the current practices in Language Technology Research. We analyse the challenges that arise and the opportunities to address many of them through the use of existing open data practices. We discuss the impact of this also on current practice in <a href=https://en.wikipedia.org/wiki/Research_ethics>research ethics</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1608.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1608 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1608 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1608/>Ethical Considerations in NLP Shared Tasks<span class=acl-fixed-case>NLP</span> Shared Tasks</a></strong><br><a href=/people/c/carla-parra-escartin/>Carla Parra Escartín</a>
|
<a href=/people/w/wessel-reijers/>Wessel Reijers</a>
|
<a href=/people/t/teresa-lynn/>Teresa Lynn</a>
|
<a href=/people/j/joss-moorkens/>Joss Moorkens</a>
|
<a href=/people/a/andy-way/>Andy Way</a>
|
<a href=/people/c/chao-hong-liu/>Chao-Hong Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1608><div class="card-body p-3 small">Shared tasks are increasingly common in our field, and new challenges are suggested at almost every conference and workshop. However, as this has become an established way of pushing research forward, it is important to discuss how we researchers organise and participate in shared tasks, and make that information available to the community to allow further research improvements. In this paper, we present a number of <a href=https://en.wikipedia.org/wiki/Ethics>ethical issues</a> along with other areas of concern that are related to the competitive nature of shared tasks. As such issues could potentially impact on research ethics in the Natural Language Processing community, we also propose the development of a framework for the organisation of and participation in shared tasks that can help mitigate against these issues arising.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1609.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1609 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1609 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=W17-1609" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/W17-1609/>Social Bias in Elicited Natural Language Inferences</a></strong><br><a href=/people/r/rachel-rudinger/>Rachel Rudinger</a>
|
<a href=/people/c/chandler-may/>Chandler May</a>
|
<a href=/people/b/benjamin-van-durme/>Benjamin Van Durme</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1609><div class="card-body p-3 small">We analyze the Stanford Natural Language Inference (SNLI) corpus in an investigation of bias and stereotyping in NLP data. The SNLI human-elicitation protocol makes it prone to amplifying bias and stereotypical associations, which we demonstrate statistically (using pointwise mutual information) and with qualitative examples.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1610.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1610 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1610 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1610/>A Short Review of Ethical Challenges in Clinical Natural Language Processing</a></strong><br><a href=/people/s/simon-suster/>Simon Šuster</a>
|
<a href=/people/s/stephan-tulkens/>Stéphan Tulkens</a>
|
<a href=/people/w/walter-daelemans/>Walter Daelemans</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1610><div class="card-body p-3 small">Clinical NLP has an immense potential in contributing to how clinical practice will be revolutionized by the advent of large scale processing of clinical records. However, this potential has remained largely untapped due to slow progress primarily caused by strict data access policies for researchers. In this paper, we discuss the concern for <a href=https://en.wikipedia.org/wiki/Privacy>privacy</a> and the measures it entails. We also suggest sources of less sensitive data. Finally, we draw attention to biases that can compromise the validity of empirical research and lead to socially harmful applications.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1611.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1611 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1611 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1611/>Goal-Oriented Design for Ethical Machine Learning and NLP<span class=acl-fixed-case>NLP</span></a></strong><br><a href=/people/t/tyler-schnoebelen/>Tyler Schnoebelen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1611><div class="card-body p-3 small">The argument made in this paper is that to act ethically in <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning</a> and <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> requires focusing on goals. NLP projects are often classificatory systems that deal with <a href=https://en.wikipedia.org/wiki/Human_subject_research>human subjects</a>, which means that goals from people affected by the <a href=https://en.wikipedia.org/wiki/System>systems</a> should be included. The paper takes as its core example a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> that detects <a href=https://en.wikipedia.org/wiki/Crime>criminality</a>, showing the problems of training data, categories, and outcomes. The paper is oriented to the kinds of critiques on <a href=https://en.wikipedia.org/wiki/Power_(social_and_political)>power</a> and the reproduction of inequality that are found in <a href=https://en.wikipedia.org/wiki/Social_theory>social theory</a>, but it also includes concrete suggestions on how to put goal-oriented design into practice.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1612.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1612 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1612 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1612/>Ethical Research Protocols for Social Media Health Research</a></strong><br><a href=/people/a/adrian-benton/>Adrian Benton</a>
|
<a href=/people/g/glen-coppersmith/>Glen Coppersmith</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1612><div class="card-body p-3 small">Social media have transformed data-driven research in <a href=https://en.wikipedia.org/wiki/Political_science>political science</a>, the <a href=https://en.wikipedia.org/wiki/Social_science>social sciences</a>, <a href=https://en.wikipedia.org/wiki/Health>health</a>, and <a href=https://en.wikipedia.org/wiki/Medicine>medicine</a>. Since <a href=https://en.wikipedia.org/wiki/Medical_research>health research</a> often touches on sensitive topics that relate to ethics of treatment and patient privacy, similar ethical considerations should be acknowledged when using social media data in <a href=https://en.wikipedia.org/wiki/Medical_research>health research</a>. While much has been said regarding the ethical considerations of social media research, <a href=https://en.wikipedia.org/wiki/Medical_research>health research</a> leads to an additional set of concerns. We provide practical suggestions in the form of guidelines for researchers working with social media data in <a href=https://en.wikipedia.org/wiki/Medical_research>health research</a>. These guidelines can inform an IRB proposal for researchers new to social media health research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-1613.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-1613 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-1613 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-1613/>Say the Right Thing Right : Ethics Issues in Natural Language Generation Systems</a></strong><br><a href=/people/c/charese-smiley/>Charese Smiley</a>
|
<a href=/people/f/frank-schilder/>Frank Schilder</a>
|
<a href=/people/v/vassilis-plachouras/>Vassilis Plachouras</a>
|
<a href=/people/j/jochen-l-leidner/>Jochen L. Leidner</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-1613><div class="card-body p-3 small">We discuss the ethical implications of <a href=https://en.wikipedia.org/wiki/Natural-language_generation>Natural Language Generation systems</a>. We use one particular <a href=https://en.wikipedia.org/wiki/System>system</a> as a case study to identify and classify issues, and we provide an ethics checklist, in the hope that future system designers may benefit from conducting their own ethics reviews based on our checklist.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>