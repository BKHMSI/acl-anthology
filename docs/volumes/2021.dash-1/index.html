<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the Second Workshop on Data Science with Human in the Loop: Language Advances - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/2021.dash-1.pdf>Proceedings of the Second Workshop on Data Science with Human in the Loop: Language Advances</a></h2><p class=lead><a href=/people/e/eduard-dragut/>Eduard Dragut</a>,
<a href=/people/y/yunyao-li/>Yunyao Li</a>,
<a href=/people/l/lucian-popa/>Lucian Popa</a>,
<a href=/people/s/slobodan-vucetic/>Slobodan Vucetic</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2021.dash-1</dd><dt>Month:</dt><dd>June</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Online</dd><dt>Venues:</dt><dd><a href=/venues/dash/>DaSH</a>
| <a href=/venues/naacl/>NAACL</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.dash-1>https://aclanthology.org/2021.dash-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2021.dash-1.pdf>https://aclanthology.org/2021.dash-1.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2021.dash-1.pdf title="Open PDF of 'Proceedings of the Second Workshop on Data Science with Human in the Loop: Language Advances'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+Second+Workshop+on+Data+Science+with+Human+in+the+Loop%3A+Language+Advances" title="Search for 'Proceedings of the Second Workshop on Data Science with Human in the Loop: Language Advances' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dash-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.dash-1.0/>Proceedings of the Second Workshop on Data Science with Human in the Loop: Language Advances</a></strong><br><a href=/people/e/eduard-dragut/>Eduard Dragut</a>
|
<a href=/people/y/yunyao-li/>Yunyao Li</a>
|
<a href=/people/l/lucian-popa/>Lucian Popa</a>
|
<a href=/people/s/slobodan-vucetic/>Slobodan Vucetic</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dash-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dash-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dash-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.dash-1.3/>ViziTex : Interactive Visual Sense-Making of Text Corpora<span class=acl-fixed-case>V</span>izi<span class=acl-fixed-case>T</span>ex: Interactive Visual Sense-Making of Text Corpora</a></strong><br><a href=/people/n/natraj-raman/>Natraj Raman</a>
|
<a href=/people/s/sameena-shah/>Sameena Shah</a>
|
<a href=/people/t/tucker-balch/>Tucker Balch</a>
|
<a href=/people/m/manuela-veloso/>Manuela Veloso</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dash-1--3><div class="card-body p-3 small">Information visualization is critical to <a href=https://en.wikipedia.org/wiki/Analytical_reasoning>analytical reasoning</a> and <a href=https://en.wikipedia.org/wiki/Epistemology>knowledge discovery</a>. We present an interactive studio that integrates perceptive visualization techniques with powerful text analytics algorithms to assist humans in sense-making of large complex text corpora. The novel visual representations introduced here encode the features delivered by modern text mining models using advanced metaphors such as <a href=https://en.wikipedia.org/wiki/Hypergraph>hypergraphs</a>, nested topologies and <a href=https://en.wikipedia.org/wiki/Tessellation>tessellated planes</a>. They enhance human-computer interaction experience for various tasks such as summarization, exploration, organization and labeling of documents. We demonstrate the ability of the visuals to surface the structure, relations and concepts from documents across different domains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dash-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dash-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dash-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.dash-1.7/>Bridging Multi-disciplinary Collaboration Challenges in ML Development via Domain Knowledge Elicitation<span class=acl-fixed-case>ML</span> Development via Domain Knowledge Elicitation</a></strong><br><a href=/people/s/soya-park/>Soya Park</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dash-1--7><div class="card-body p-3 small">Building a <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning model</a> in a sophisticated domain is a time-consuming process, partially due to the steep learning curve of <a href=https://en.wikipedia.org/wiki/Domain_knowledge>domain knowledge</a> for <a href=https://en.wikipedia.org/wiki/Data_science>data scientists</a>. We introduce Ziva, an interface for supporting <a href=https://en.wikipedia.org/wiki/Domain_knowledge>domain knowledge</a> from domain experts to data scientists in two ways : (1) a concept creation interface where domain experts extract important concept of the domain and (2) five kinds of justification elicitation interfaces that solicit elicitation how the domain concept are expressed in data instances.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dash-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dash-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dash-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.dash-1.9/>Towards integrated, interactive, and extensible text data analytics with Leam</a></strong><br><a href=/people/p/peter-griggs/>Peter Griggs</a>
|
<a href=/people/c/cagatay-demiralp/>Cagatay Demiralp</a>
|
<a href=/people/s/sajjadur-rahman/>Sajjadur Rahman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dash-1--9><div class="card-body p-3 small">From <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a> to <a href=https://en.wikipedia.org/wiki/Review>product reviews</a>, <a href=https://en.wikipedia.org/wiki/Plain_text>text</a> is ubiquitous on the web and often contains valuable information for both enterprises and consumers. However, the online text is generally noisy and incomplete, requiring users to process and analyze the data to extract insights. While there are systems effective for different stages of <a href=https://en.wikipedia.org/wiki/Text_mining>text analysis</a>, users lack extensible platforms to support interactive text analysis workflows end-to-end. To facilitate integrated text analytics, we introduce LEAM, which aims at combining the strengths of <a href=https://en.wikipedia.org/wiki/Spreadsheet>spreadsheets</a>, <a href=https://en.wikipedia.org/wiki/Computational_notebook>computational notebooks</a>, and interactive visualizations. LEAM supports interactive analysis via GUI-based interactions and provides a declarative specification language, implemented based on a visual text algebra, to enable user-guided analysis. We evaluate LEAM through two <a href=https://en.wikipedia.org/wiki/Case_study>case studies</a> using two popular Kaggle text analytics workflows to understand the strengths and weaknesses of the <a href=https://en.wikipedia.org/wiki/System>system</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dash-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dash-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dash-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.dash-1.10/>Data Cleaning Tools for Token Classification Tasks</a></strong><br><a href=/people/k/karthik-muthuraman/>Karthik Muthuraman</a>
|
<a href=/people/f/frederick-reiss/>Frederick Reiss</a>
|
<a href=/people/h/hong-xu/>Hong Xu</a>
|
<a href=/people/b/bryan-cutler/>Bryan Cutler</a>
|
<a href=/people/z/zachary-eichenberger/>Zachary Eichenberger</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dash-1--10><div class="card-body p-3 small">Human-in-the-loop systems for cleaning NLP training data rely on automated sieves to isolate potentially-incorrect labels for manual review. We have developed a novel technique for flagging potentially-incorrect labels with high sensitivity in named entity recognition corpora. We incorporated our <a href=https://en.wikipedia.org/wiki/Sieve_theory>sieve</a> into an end-to-end system for cleaning NLP corpora, implemented as a modular collection of Jupyter notebooks built on extensions to the Pandas DataFrame library. We used this system to identify incorrect labels in the CoNLL-2003 corpus for English-language named entity recognition (NER), one of the most influential corpora for NER model research. Unlike previous work that only looked at a subset of the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>&#8217;s validation fold, our automated sieve enabled us to examine the entire corpus in depth. Across the entire CoNLL-2003 corpus, we identified over 1300 incorrect labels (out of 35089 in the corpus). We have published our corrections, along with the code we used in our experiments. We are developing a repeatable version of the process we used on the CoNLL-2003 corpus as an open-source library.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dash-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dash-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dash-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.dash-1.11/>Building Low-Resource NER Models Using Non-Speaker Annotations<span class=acl-fixed-case>NER</span> Models Using Non-Speaker Annotations</a></strong><br><a href=/people/t/tatiana-tsygankova/>Tatiana Tsygankova</a>
|
<a href=/people/f/francesca-marini/>Francesca Marini</a>
|
<a href=/people/s/stephen-mayhew/>Stephen Mayhew</a>
|
<a href=/people/d/dan-roth/>Dan Roth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dash-1--11><div class="card-body p-3 small">In low-resource natural language processing (NLP), the key problems are a lack of target language training data, and a lack of native speakers to create it. Cross-lingual methods have had notable success in addressing these concerns, but in certain common circumstances, such as insufficient pre-training corpora or languages far from the source language, their performance suffers. In this work we propose a complementary approach to building low-resource Named Entity Recognition (NER) models using non-speaker (NS) annotations, provided by annotators with no prior experience in the target language. We recruit 30 participants in a carefully controlled annotation experiment with <a href=https://en.wikipedia.org/wiki/Indonesian_language>Indonesian</a>, <a href=https://en.wikipedia.org/wiki/Russian_language>Russian</a>, and <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a>. We show that use of NS annotators produces results that are consistently on par or better than cross-lingual methods built on modern contextual representations, and have the potential to outperform with additional effort. We conclude with observations of common annotation patterns and recommended implementation practices, and motivate how NS annotations can be used in addition to prior methods for improved performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dash-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dash-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dash-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.dash-1.13" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.dash-1.13/>CrossCheck : Rapid, Reproducible, and Interpretable Model Evaluation<span class=acl-fixed-case>C</span>ross<span class=acl-fixed-case>C</span>heck: Rapid, Reproducible, and Interpretable Model Evaluation</a></strong><br><a href=/people/d/dustin-arendt/>Dustin Arendt</a>
|
<a href=/people/z/zhuanyi-shaw/>Zhuanyi Shaw</a>
|
<a href=/people/p/prasha-shrestha/>Prasha Shrestha</a>
|
<a href=/people/e/ellyn-ayton/>Ellyn Ayton</a>
|
<a href=/people/m/maria-glenski/>Maria Glenski</a>
|
<a href=/people/s/svitlana-volkova/>Svitlana Volkova</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dash-1--13><div class="card-body p-3 small">Evaluation beyond aggregate performance metrics, e.g. F1-score, is crucial to both establish an appropriate level of trust in <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning models</a> and identify avenues for future <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> improvements. In this paper we demonstrate CrossCheck, an interactive capability for rapid cross-model comparison and reproducible error analysis. We describe the tool, discuss design and implementation details, and present three NLP use cases named entity recognition, <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a>, and clickbait detection that show the benefits of using the tool for model evaluation. CrossCheck enables users to make informed decisions when choosing between multiple models, identify when the models are correct and for which examples, investigate whether the models are making the same mistakes as humans, evaluate models&#8217; generalizability and highlight models&#8217; limitations, strengths and weaknesses. Furthermore, CrossCheck is implemented as a <a href=https://en.wikipedia.org/wiki/Jupyter>Jupyter widget</a>, which allows for rapid and convenient integration into existing model development workflows.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dash-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dash-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dash-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.dash-1.14" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.dash-1.14/>TopGuNN : Fast NLP Training Data Augmentation using Large Corpora<span class=acl-fixed-case>T</span>op<span class=acl-fixed-case>G</span>u<span class=acl-fixed-case>NN</span>: Fast <span class=acl-fixed-case>NLP</span> Training Data Augmentation using Large Corpora</a></strong><br><a href=/people/r/rebecca-iglesias-flores/>Rebecca Iglesias-Flores</a>
|
<a href=/people/m/megha-mishra/>Megha Mishra</a>
|
<a href=/people/a/ajay-patel/>Ajay Patel</a>
|
<a href=/people/a/akanksha-malhotra/>Akanksha Malhotra</a>
|
<a href=/people/r/reno-kriz/>Reno Kriz</a>
|
<a href=/people/m/martha-palmer/>Martha Palmer</a>
|
<a href=/people/c/chris-callison-burch/>Chris Callison-Burch</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dash-1--14><div class="card-body p-3 small">Acquiring training data for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing systems</a> can be expensive and time-consuming. Given a few training examples crafted by experts, large corpora can be mined for thousands of semantically similar examples that provide useful variability to improve model generalization. We present TopGuNN, a fast contextualized k-NN retrieval system that can efficiently index and search over contextual embeddings generated from large corpora. TopGuNN is demonstrated for a training data augmentation use case over the Gigaword corpus. Using approximate k-NN and an efficient <a href=https://en.wikipedia.org/wiki/Computer_architecture>architecture</a>, TopGuNN performs queries over an <a href=https://en.wikipedia.org/wiki/Glossary_of_graph_theory_terms>embedding space</a> of 4.63 TB (approximately 1.5B embeddings) in less than a day.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.dash-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--dash-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.dash-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.dash-1.16/>A <a href=https://en.wikipedia.org/wiki/Computational_model>Computational Model</a> for Interactive Transcription</a></strong><br><a href=/people/w/william-lane/>William Lane</a>
|
<a href=/people/m/mat-bettinson/>Mat Bettinson</a>
|
<a href=/people/s/steven-bird/>Steven Bird</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--dash-1--16><div class="card-body p-3 small">Transcribing low resource languages can be challenging in the absence of a good lexicon and trained transcribers. Accordingly, we seek a way to enable interactive transcription whereby the machine amplifies human efforts. This paper presents a <a href=https://en.wikipedia.org/wiki/Data_model>data model</a> and a <a href=https://en.wikipedia.org/wiki/Systems_architecture>system architecture</a> for interactive transcription, supporting multiple modes of <a href=https://en.wikipedia.org/wiki/Interactivity>interactivity</a>, increasing the likelihood of finding tasks that engage local participation in language work. The approach also supports other <a href=https://en.wikipedia.org/wiki/Application_software>applications</a> which are useful in our context, including spoken document retrieval and <a href=https://en.wikipedia.org/wiki/Language_acquisition>language learning</a>.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>