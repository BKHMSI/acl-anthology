<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/2021.semeval-1.pdf>Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)</a></h2><p class=lead><a href=/people/a/alexis-palmer/>Alexis Palmer</a>,
<a href=/people/n/nathan-schneider/>Nathan Schneider</a>,
<a href=/people/n/natalie-schluter/>Natalie Schluter</a>,
<a href=/people/g/guy-emerson/>Guy Emerson</a>,
<a href=/people/a/aurelie-herbelot/>Aurelie Herbelot</a>,
<a href=/people/x/xiaodan-zhu/>Xiaodan Zhu</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2021.semeval-1</dd><dt>Month:</dt><dd>August</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Online</dd><dt>Venues:</dt><dd><a href=/venues/acl/>ACL</a>
| <a href=/venues/ijcnlp/>IJCNLP</a>
| <a href=/venues/semeval/>SemEval</a></dd><dt>SIG:</dt><dd><a href=/sigs/siglex/>SIGLEX</a></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.semeval-1>https://aclanthology.org/2021.semeval-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2021.semeval-1.pdf>https://aclanthology.org/2021.semeval-1.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2021.semeval-1.pdf title="Open PDF of 'Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+15th+International+Workshop+on+Semantic+Evaluation+%28SemEval-2021%29" title="Search for 'Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.0/>Proceedings of the 15th International Workshop on Semantic Evaluation (SemEval-2021)</a></strong><br><a href=/people/a/alexis-palmer/>Alexis Palmer</a>
|
<a href=/people/n/nathan-schneider/>Nathan Schneider</a>
|
<a href=/people/n/natalie-schluter/>Natalie Schluter</a>
|
<a href=/people/g/guy-emerson/>Guy Emerson</a>
|
<a href=/people/a/aurelie-herbelot/>Aurelie Herbelot</a>
|
<a href=/people/x/xiaodan-zhu/>Xiaodan Zhu</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.1/>SemEval-2021 Task 1 : Lexical Complexity Prediction<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 1: Lexical Complexity Prediction</a></strong><br><a href=/people/m/matthew-shardlow/>Matthew Shardlow</a>
|
<a href=/people/r/richard-evans/>Richard Evans</a>
|
<a href=/people/g/gustavo-paetzold/>Gustavo Henrique Paetzold</a>
|
<a href=/people/m/marcos-zampieri/>Marcos Zampieri</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--1><div class="card-body p-3 small">This paper presents the results and main findings of SemEval-2021 Task 1-Lexical Complexity Prediction. We provided participants with an augmented version of the CompLex Corpus (Shardlow et al. CompLex is an English multi-domain corpus in which words and multi-word expressions (MWEs) were annotated with respect to their complexity using a five point Likert scale. SemEval-2021 Task 1 featured two Sub-tasks : Sub-task 1 focused on single words and Sub-task 2 focused on MWEs. The competition attracted 198 teams in total, of which 54 teams submitted official runs on the test data to <a href=https://en.wikipedia.org/wiki/Task_(computing)>Sub-task 1</a> and 37 to <a href=https://en.wikipedia.org/wiki/Task_(computing)>Sub-task 2</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.7/>SemEval-2021 Task 6 : Detection of Persuasion Techniques in Texts and Images<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 6: Detection of Persuasion Techniques in Texts and Images</a></strong><br><a href=/people/d/dimitar-dimitrov/>Dimitar Dimitrov</a>
|
<a href=/people/b/bishr-bin-ali/>Bishr Bin Ali</a>
|
<a href=/people/s/shaden-shaar/>Shaden Shaar</a>
|
<a href=/people/f/firoj-alam/>Firoj Alam</a>
|
<a href=/people/f/fabrizio-silvestri/>Fabrizio Silvestri</a>
|
<a href=/people/h/hamed-firooz/>Hamed Firooz</a>
|
<a href=/people/p/preslav-nakov/>Preslav Nakov</a>
|
<a href=/people/g/giovanni-da-san-martino/>Giovanni Da San Martino</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--7><div class="card-body p-3 small">We describe SemEval-2021 task 6 on Detection of Persuasion Techniques in Texts and Images : the data, the annotation guidelines, the evaluation setup, the results, and the participating systems. The task focused on <a href=https://en.wikipedia.org/wiki/Meme>memes</a> and had three subtasks : (i) detecting the techniques in the <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>text</a>, (ii) detecting the text spans where the techniques are used, and (iii) detecting techniques in the entire meme, i.e., both in the text and in the image. It was a popular <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, attracting 71 registrations, and 22 teams that eventually made an official submission on the test set. The evaluation results for the third subtask confirmed the importance of both <a href=https://en.wikipedia.org/wiki/Modality_(semiotics)>modalities</a>, the <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>text</a> and the image. Moreover, some teams reported benefits when not just combining the two modalities, e.g., by using early or late fusion, but rather modeling the interaction between them in a joint model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.8.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--8 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.8 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.8/>Alpha at SemEval-2021 Task 6 : Transformer Based Propaganda Classification<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 6: Transformer Based Propaganda Classification</a></strong><br><a href=/people/z/zhida-feng/>Zhida Feng</a>
|
<a href=/people/j/jiji-tang/>Jiji Tang</a>
|
<a href=/people/j/jiaxiang-liu/>Jiaxiang Liu</a>
|
<a href=/people/w/weichong-yin/>Weichong Yin</a>
|
<a href=/people/s/shikun-feng/>Shikun Feng</a>
|
<a href=/people/y/yu-sun/>Yu Sun</a>
|
<a href=/people/l/li-chen/>Li Chen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--8><div class="card-body p-3 small">This paper describes our system participated in Task 6 of SemEval-2021 : the task focuses on multimodal propaganda technique classification and it aims to classify given image and text into 22 classes. In this paper, we propose to use transformer based architecture to fuse the clues from both image and text. We explore two branches of techniques including fine-tuning the text pretrained transformer with extended visual features, and fine-tuning the multimodal pretrained transformers. For the visual features, we have tested both grid features based on <a href=https://en.wikipedia.org/wiki/ResNet>ResNet</a> and salient region features from pretrained object detector. Among the pretrained multimodal transformers, we choose ERNIE-ViL, a two-steam cross-attended transformers pretrained on large scale image-caption aligned data. Fine-tuing ERNIE-ViL for our task produce a better performance due to general joint multimodal representation for <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>text</a> and image learned by ERNIE-ViL. Besides, as the distribution of the classification labels is very unbalanced, we also make a further attempt on the <a href=https://en.wikipedia.org/wiki/Loss_function>loss function</a> and the experiment result shows that focal loss would perform better than cross entropy loss. Last we have won first for subtask C in the final competition.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.9/>SemEval 2021 Task 7 : HaHackathon, Detecting and Rating Humor and Offense<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val 2021 Task 7: <span class=acl-fixed-case>H</span>a<span class=acl-fixed-case>H</span>ackathon, Detecting and Rating Humor and Offense</a></strong><br><a href=/people/j/j-a-meaney/>J. A. Meaney</a>
|
<a href=/people/s/steven-wilson/>Steven Wilson</a>
|
<a href=/people/l/luis-chiruzzo/>Luis Chiruzzo</a>
|
<a href=/people/a/adam-lopez/>Adam Lopez</a>
|
<a href=/people/w/walid-magdy/>Walid Magdy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--9><div class="card-body p-3 small">SemEval 2021 Task 7, HaHackathon, was the first shared task to combine the previously separate domains of humor detection and offense detection. We collected 10,000 texts from <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> and the Kaggle Short Jokes dataset, and had each annotated for humor and offense by 20 annotators aged 18-70. Our subtasks were binary humor detection, prediction of humor and offense ratings, and a novel controversy task : to predict if the variance in the humor ratings was higher than a specific threshold. The subtasks attracted 36-58 submissions, with most of the participants choosing to use pre-trained language models. Many of the highest performing teams also implemented additional optimization techniques, including task-adaptive training and adversarial training. The results suggest that the participating <a href=https://en.wikipedia.org/wiki/System>systems</a> are well suited to humor detection, but that humor controversy is a more challenging task. We discuss which <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> excel in this task, which auxiliary techniques boost their performance, and analyze the errors which were not captured by the best <a href=https://en.wikipedia.org/wiki/System>systems</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.11/>Complex words identification using word-level features for SemEval-2020 Task 1<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2020 Task 1</a></strong><br><a href=/people/j/jenny-a-ortiz-zambrano/>Jenny A. Ortiz-Zambrano</a>
|
<a href=/people/a/arturo-montejo-raez/>Arturo Montejo-Ráez</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--11><div class="card-body p-3 small">This article describes a system to predict the complexity of words for the Lexical Complexity Prediction (LCP) shared task hosted at SemEval 2021 (Task 1) with a new annotated English dataset with a <a href=https://en.wikipedia.org/wiki/Likert_scale>Likert scale</a>. Located in the Lexical Semantics track, the task consisted of predicting the complexity value of the words in context. A machine learning approach was carried out based on the frequency of the words and several characteristics added at word level. Over these <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a>, a supervised random forest regression algorithm was trained. Several runs were performed with different values to observe the performance of the <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a>. For the <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation</a>, our best results reported a M.A.E score of 0.07347, M.S.E. of 0.00938, and R.M.S.E. of 0.096871. Our experiments showed that, with a greater number of <a href=https://en.wikipedia.org/wiki/Phenotypic_trait>characteristics</a>, the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>precision</a> of the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> increases.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.15/>Uppsala NLP at SemEval-2021 Task 2 : Multilingual Language Models for Fine-tuning and Feature Extraction in Word-in-Context Disambiguation<span class=acl-fixed-case>U</span>ppsala <span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 2: Multilingual Language Models for Fine-tuning and Feature Extraction in Word-in-Context Disambiguation</a></strong><br><a href=/people/h/huiling-you/>Huiling You</a>
|
<a href=/people/x/xingran-zhu/>Xingran Zhu</a>
|
<a href=/people/s/sara-stymne/>Sara Stymne</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--15><div class="card-body p-3 small">We describe the Uppsala NLP submission to SemEval-2021 Task 2 on multilingual and cross-lingual word-in-context disambiguation. We explore the usefulness of three pre-trained multilingual language models, XLM-RoBERTa (XLMR), Multilingual BERT (mBERT) and multilingual distilled BERT (mDistilBERT). We compare these three <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> in two setups, <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> and as <a href=https://en.wikipedia.org/wiki/Software_feature>feature extractors</a>. In the second case we also experiment with using dependency-based information. We find that <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> is better than <a href=https://en.wikipedia.org/wiki/Feature_extraction>feature extraction</a>. XLMR performs better than mBERT in the cross-lingual setting both with <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> and <a href=https://en.wikipedia.org/wiki/Feature_extraction>feature extraction</a>, whereas these two models give a similar performance in the multilingual setting. mDistilBERT performs poorly with <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> but gives similar results to the other <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> when used as a feature extractor. We submitted our two best <a href=https://en.wikipedia.org/wiki/System>systems</a>, fine-tuned with XLMR and mBERT.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.16/>SkoltechNLP at SemEval-2021 Task 2 : Generating Cross-Lingual Training Data for the Word-in-Context Task<span class=acl-fixed-case>S</span>koltech<span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 2: Generating Cross-Lingual Training Data for the Word-in-Context Task</a></strong><br><a href=/people/a/anton-razzhigaev/>Anton Razzhigaev</a>
|
<a href=/people/n/nikolay-arefyev/>Nikolay Arefyev</a>
|
<a href=/people/a/alexander-panchenko/>Alexander Panchenko</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--16><div class="card-body p-3 small">In this paper, we present a <a href=https://en.wikipedia.org/wiki/System>system</a> for the solution of the cross-lingual and multilingual word-in-context disambiguation task. Task organizers provided monolingual data in several languages, but no cross-lingual training data were available. To address the lack of the officially provided cross-lingual training data, we decided to generate such <a href=https://en.wikipedia.org/wiki/Data>data</a> ourselves. We describe a simple yet effective approach based on <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> and back translation of the lexical units to the original language used in the context of this shared task. In our experiments, we used a neural system based on the XLM-R, a pre-trained transformer-based masked language model, as a baseline. We show the effectiveness of the proposed approach as it allows to substantially improve the performance of this strong neural baseline model. In addition, in this study, we present multiple types of the XLM-R based classifier, experimenting with various ways of mixing information from the first and second occurrences of the target word in two samples.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.semeval-1.17" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.17/>Zhestyatsky at SemEval-2021 Task 2 : ReLU over Cosine Similarity for BERT Fine-tuning<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 2: <span class=acl-fixed-case>R</span>e<span class=acl-fixed-case>LU</span> over Cosine Similarity for <span class=acl-fixed-case>BERT</span> Fine-tuning</a></strong><br><a href=/people/b/boris-zhestiankin/>Boris Zhestiankin</a>
|
<a href=/people/m/maria-ponomareva/>Maria Ponomareva</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--17><div class="card-body p-3 small">This paper presents our contribution to SemEval-2021 Task 2 : Multilingual and Cross-lingual Word-in-Context Disambiguation (MCL-WiC). Our experiments cover English (EN-EN) sub-track from the multilingual setting of the task. We experiment with several pre-trained language models and investigate an impact of different top-layers on <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a>. We find the combination of <a href=https://en.wikipedia.org/wiki/Cosine_similarity>Cosine Similarity</a> and ReLU activation leading to the most effective fine-tuning procedure. Our best <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> results in <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> 92.7 %, which is the fourth-best score in EN-EN sub-track.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.18.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--18 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.18 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.18/>SzegedAI at SemEval-2021 Task 2 : Zero-shot Approach for Multilingual and Cross-lingual Word-in-Context Disambiguation<span class=acl-fixed-case>S</span>zeged<span class=acl-fixed-case>AI</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 2: Zero-shot Approach for Multilingual and Cross-lingual Word-in-Context Disambiguation</a></strong><br><a href=/people/g/gabor-berend/>Gábor Berend</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--18><div class="card-body p-3 small">In this paper, we introduce our <a href=https://en.wikipedia.org/wiki/System>system</a> that we participated with at the multilingual and cross-lingual word-in-context disambiguation SemEval 2021 shared task. In our experiments, we investigated the possibility of using an all-words fine-grained word sense disambiguation system trained purely on sense-annotated data in English and draw predictions on the semantic equivalence of words in context based on the similarity of the ranked lists of the (English) WordNet synsets returned for the target words decisions had to be made for. We overcame the multi,-and cross-lingual aspects of the shared task by applying a multilingual transformer for encoding the texts written in either <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a>, <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/French_language>French</a>, <a href=https://en.wikipedia.org/wiki/Russian_language>Russian</a> and <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>. While our results lag behind top scoring submissions, it has the benefit that it not only provides a binary flag whether two words in their context have the same meaning, but also provides a more tangible output in the form of a ranked list of (English) WordNet synsets irrespective of the language of the input texts. As our framework is designed to be as generic as possible, it can be applied as a baseline for basically any language (supported by the multilingual transformed architecture employed) even in the absence of any additional form of language specific training data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.20.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--20 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.20 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.20/>ECNU_ICA_1 SemEval-2021 Task 4 : Leveraging Knowledge-enhanced Graph Attention Networks for Reading Comprehension of Abstract Meaning<span class=acl-fixed-case>ECNU</span>_<span class=acl-fixed-case>ICA</span>_1 <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 4: Leveraging Knowledge-enhanced Graph Attention Networks for Reading Comprehension of Abstract Meaning</a></strong><br><a href=/people/p/pingsheng-liu/>Pingsheng Liu</a>
|
<a href=/people/l/linlin-wang/>Linlin Wang</a>
|
<a href=/people/q/qian-zhao/>Qian Zhao</a>
|
<a href=/people/h/hao-chen/>Hao Chen</a>
|
<a href=/people/y/yuxi-feng/>Yuxi Feng</a>
|
<a href=/people/x/xin-lin/>Xin Lin</a>
|
<a href=/people/l/liang-he/>Liang He</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--20><div class="card-body p-3 small">This paper describes our <a href=https://en.wikipedia.org/wiki/System>system</a> for SemEval-2021 Task 4 : Reading Comprehension of Abstract Meaning. To accomplish this task, we utilize the Knowledge-Enhanced Graph Attention Network (KEGAT) architecture with a novel semantic space transformation strategy. It leverages heterogeneous knowledge to learn adequate evidences, and seeks for an effective semantic space of abstract concepts to better improve the ability of a machine in understanding the abstract meaning of natural language. Experimental results show that our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves strong performance on this task in terms of both <a href=https://en.wikipedia.org/wiki/Perception>imperceptibility</a> and <a href=https://en.wikipedia.org/wiki/Sensitivity_and_specificity>nonspecificity</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.semeval-1.21" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.21/>LRG at SemEval-2021 Task 4 : Improving Reading Comprehension with Abstract Words using Augmentation, Linguistic Features and Voting<span class=acl-fixed-case>LRG</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 4: Improving Reading Comprehension with Abstract Words using Augmentation, Linguistic Features and Voting</a></strong><br><a href=/people/a/abheesht-sharma/>Abheesht Sharma</a>
|
<a href=/people/h/harshit-pandey/>Harshit Pandey</a>
|
<a href=/people/g/gunjan-chhablani/>Gunjan Chhablani</a>
|
<a href=/people/y/yash-bhartia/>Yash Bhartia</a>
|
<a href=/people/t/tirtharaj-dash/>Tirtharaj Dash</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--21><div class="card-body p-3 small">We present our approaches and methods for SemEval-2021 Task-4 Reading Comprehension of Abstract Meaning. Given a question with a fill-in-the-blank, and a corresponding context, the task is to predict the most suitable word from a list of 5 options. There are three subtasks : Imperceptibility, Non-Specificity and <a href=https://en.wikipedia.org/wiki/Intersection>Intersection</a>. We use encoders of transformers-based models pretrained on the MLM task to build our Fill-in-the-blank (FitB) models. Moreover, to model imperceptibility, we define certain linguistic features, and to model non-specificity, we leverage information from <a href=https://en.wikipedia.org/wiki/Hypernymy>hypernyms</a> and <a href=https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy>hyponyms</a> provided by a <a href=https://en.wikipedia.org/wiki/Lexical_database>lexical database</a>. Specifically, for non-specificity, we try out augmentation techniques, and other <a href=https://en.wikipedia.org/wiki/Statistics>statistical techniques</a>. We also propose variants, namely Chunk Voting and Max Context, to take care of input length restrictions for BERT, etc. Additionally, we perform a thorough ablation study, and use Integrated Gradients to explain our predictions on a few samples. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> achieve accuracies of 75.31 % and 77.84 %, on the test sets for subtask-I and subtask-II, respectively. For subtask-III, we achieve accuracies of 65.64 % and 64.27 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.23.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--23 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.23 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.23/>NLP-IIS@UT at SemEval-2021 Task 4 : Machine Reading Comprehension using the Long Document Transformer<span class=acl-fixed-case>NLP</span>-<span class=acl-fixed-case>IIS</span>@<span class=acl-fixed-case>UT</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 4: Machine Reading Comprehension using the Long Document Transformer</a></strong><br><a href=/people/h/hossein-basafa/>Hossein Basafa</a>
|
<a href=/people/s/sajad-movahedi/>Sajad Movahedi</a>
|
<a href=/people/a/ali-ebrahimi/>Ali Ebrahimi</a>
|
<a href=/people/a/azadeh-shakery/>Azadeh Shakery</a>
|
<a href=/people/h/heshaam-faili/>Heshaam Faili</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--23><div class="card-body p-3 small">This paper presents a technical report of our submission to the 4th task of SemEval-2021, titled : Reading Comprehension of Abstract Meaning. In this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, we want to predict the correct answer based on a question given a context. Usually, contexts are very lengthy and require a large <a href=https://en.wikipedia.org/wiki/Receptive_field>receptive field</a> from the <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a>. Thus, common contextualized language models like BERT miss fine representation and performance due to the limited capacity of the input tokens. To tackle this problem, we used the longformer model to better process the sequences. Furthermore, we utilized the <a href=https://en.wikipedia.org/wiki/Methodology>method</a> proposed in the longformer benchmark on wikihop dataset which improved the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on our <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task data</a> from (23.01 % and 22.95 %) achieved by the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> for subtask 1 and 2, respectively, to (70.30 % and 64.38 %).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.31.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--31 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.31 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.semeval-1.31.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.semeval-1.31/>HamiltonDinggg at SemEval-2021 Task 5 : Investigating Toxic Span Detection using RoBERTa Pre-training<span class=acl-fixed-case>H</span>amilton<span class=acl-fixed-case>D</span>inggg at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 5: Investigating Toxic Span Detection using <span class=acl-fixed-case>R</span>o<span class=acl-fixed-case>BERT</span>a Pre-training</a></strong><br><a href=/people/h/huiyang-ding/>Huiyang Ding</a>
|
<a href=/people/d/david-jurgens/>David Jurgens</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--31><div class="card-body p-3 small">This paper presents our system submission to task 5 : Toxic Spans Detection of the SemEval-2021 competition. The <a href=https://en.wikipedia.org/wiki/Competition>competition</a> aims at detecting the spans that make a toxic span toxic. In this paper, we demonstrate our system for detecting toxic spans, which includes expanding the toxic training set with Local Interpretable Model-Agnostic Explanations (LIME), fine-tuning RoBERTa model for detection, and error analysis. We found that feeding the model with an expanded training set using Reddit comments of polarized-toxicity and labeling with LIME on top of logistic regression classification could help RoBERTa more accurately learn to recognize toxic spans. We achieved a span-level F1 score of 0.6715 on the testing phase. Our quantitative and qualitative results show that the predictions from our <a href=https://en.wikipedia.org/wiki/System>system</a> could be a good supplement to the gold training set&#8217;s annotations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.32.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--32 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.32 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.semeval-1.32" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.32/>WVOQ at SemEval-2021 Task 6 : BART for Span Detection and Classification<span class=acl-fixed-case>WVOQ</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 6: <span class=acl-fixed-case>BART</span> for Span Detection and Classification</a></strong><br><a href=/people/c/cees-roele/>Cees Roele</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--32><div class="card-body p-3 small">Simultaneous span detection and classification is a <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> not currently addressed in standard NLP frameworks. The present paper describes why and how an EncoderDecoder model was used to combine span detection and <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> to address subtask 2 of SemEval-2021 Task 6.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.33.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--33 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.33 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.33/>HumorHunter at SemEval-2021 Task 7 : Humor and Offense Recognition with Disentangled Attention<span class=acl-fixed-case>H</span>umor<span class=acl-fixed-case>H</span>unter at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 7: Humor and Offense Recognition with Disentangled Attention</a></strong><br><a href=/people/y/yubo-xie/>Yubo Xie</a>
|
<a href=/people/j/junze-li/>Junze Li</a>
|
<a href=/people/p/pearl-pu/>Pearl Pu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--33><div class="card-body p-3 small">In this paper, we describe our system submitted to SemEval 2021 Task 7 : HaHackathon : Detecting and Rating Humor and Offense. The task aims at predicting whether the given text is humorous, the average humor rating given by the annotators, and whether the humor rating is controversial. In addition, the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> also involves predicting how offensive the text is. Our approach adopts the DeBERTa architecture with disentangled attention mechanism, where the attention scores between words are calculated based on their content vectors and relative position vectors. We also took advantage of the pre-trained language models and fine-tuned the DeBERTa model on all the four subtasks. We experimented with several BERT-like structures and found that the large DeBERTa model generally performs better. During the evaluation phase, our system achieved an <a href=https://en.wikipedia.org/wiki/F-score>F-score</a> of 0.9480 on subtask 1a, an RMSE of 0.5510 on subtask 1b, an <a href=https://en.wikipedia.org/wiki/F-score>F-score</a> of 0.4764 on subtask 1c, and an RMSE of 0.4230 on subtask 2a (rank 3 on the leaderboard).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.34.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--34 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.34 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.34/>Grenzlinie at SemEval-2021 Task 7 : Detecting and Rating Humor and Offense<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 7: Detecting and Rating Humor and Offense</a></strong><br><a href=/people/r/renyuan-liu/>Renyuan Liu</a>
|
<a href=/people/x/xiaobing-zhou/>Xiaobing Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--34><div class="card-body p-3 small">This paper introduces the result of Team Grenzlinie&#8217;s experiment in SemEval-2021 task 7 : HaHackathon : Detecting and Rating Humor and Offense. This <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a> has two <a href=https://en.wikipedia.org/wiki/Task_(computing)>subtasks</a>. Subtask1 includes the humor detection task, the humor rating prediction task, and the humor controversy detection task. Subtask2 is an offensive rating prediction task. Detection task is a binary classification task, and the rating prediction task is a regression task between 0 to 5. 0 means the task is not humorous or not offensive, 5 means the task is very humorous or very offensive. For all the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>, this paper chooses RoBERTa as the pre-trained model. In classification tasks, Bi-LSTM and <a href=https://en.wikipedia.org/wiki/Adversarial_learning>adversarial training</a> are adopted. In the <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression task</a>, the Bi-LSTM is also adopted. And then we propose a new <a href=https://en.wikipedia.org/wiki/Methodology>approach</a> named compare method. Finally, our system achieves an <a href=https://en.wikipedia.org/wiki/F-number>F1-score</a> of 95.05 % in the humor detection task, <a href=https://en.wikipedia.org/wiki/F-number>F1-score</a> of 61.74 % in the humor controversy detection task, 0.6143 RMSE in humor rating task, 0.4761 RMSE in the offensive rating task on the test datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.36.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--36 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.36 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.semeval-1.36" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.36/>Humor@IITK at SemEval-2021 Task 7 : Large Language Models for Quantifying Humor and Offensiveness<span class=acl-fixed-case>IITK</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 7: Large Language Models for Quantifying Humor and Offensiveness</a></strong><br><a href=/people/a/aishwarya-gupta/>Aishwarya Gupta</a>
|
<a href=/people/a/avik-pal/>Avik Pal</a>
|
<a href=/people/b/bholeshwar-khurana/>Bholeshwar Khurana</a>
|
<a href=/people/l/lakshay-tyagi/>Lakshay Tyagi</a>
|
<a href=/people/a/ashutosh-modi/>Ashutosh Modi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--36><div class="card-body p-3 small">Humor and Offense are highly subjective due to multiple <a href=https://en.wikipedia.org/wiki/Word_sense>word senses</a>, <a href=https://en.wikipedia.org/wiki/Cultural_knowledge>cultural knowledge</a>, and pragmatic competence. Hence, accurately detecting humorous and offensive texts has several compelling use cases in <a href=https://en.wikipedia.org/wiki/Recommender_system>Recommendation Systems</a> and Personalized Content Moderation. However, due to the lack of an extensive labeled dataset, most prior works in this domain have n&#8217;t explored large neural models for subjective humor understanding. This paper explores whether large neural models and their ensembles can capture the intricacies associated with humor / offense detection and rating. Our experiments on the SemEval-2021 Task 7 : HaHackathon show that we can develop reasonable humor and offense detection systems with such models. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> are ranked 3rd in subtask 1b and consistently ranked around the top 33 % of the leaderboard for the remaining subtasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.37.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--37 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.37 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.37/>RoMa at SemEval-2021 Task 7 : A Transformer-based Approach for Detecting and Rating Humor and Offense<span class=acl-fixed-case>R</span>o<span class=acl-fixed-case>M</span>a at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 7: A Transformer-based Approach for Detecting and Rating Humor and Offense</a></strong><br><a href=/people/r/roberto-labadie/>Roberto Labadie</a>
|
<a href=/people/m/mariano-jason-rodriguez/>Mariano Jason Rodriguez</a>
|
<a href=/people/r/reynier-ortega/>Reynier Ortega</a>
|
<a href=/people/p/paolo-rosso/>Paolo Rosso</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--37><div class="card-body p-3 small">In this paper we describe the systems used by the RoMa team in the shared task on Detecting and Rating Humor and Offense (HaHackathon) at SemEval 2021. Our systems rely on data representations learned through fine-tuned neural language models. Particularly, we explore two distinct <a href=https://en.wikipedia.org/wiki/Computer_architecture>architectures</a>. The first one is based on a Siamese Neural Network (SNN) combined with a graph-based clustering method. The SNN model is used for learning a latent space where instances of <a href=https://en.wikipedia.org/wiki/Humour>humor</a> and non-humor can be distinguished. The clustering method is applied to build prototypes of both classes which are used for training and classifying new messages. The second one combines neural language model representations with a <a href=https://en.wikipedia.org/wiki/Linear_regression>linear regression model</a> which makes the final ratings. Our systems achieved the best results for humor classification using <a href=https://en.wikipedia.org/wiki/Conceptual_model>model one</a>, whereas for offensive and humor rating the second <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> obtained better performance. In the case of the controversial humor prediction, the most significant improvement was achieved by a <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a> of the neural language model. In general, the results achieved are encouraging and give us a starting point for further improvements.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.43.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--43 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.43 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.43/>BLCUFIGHT at SemEval-2021 Task 10 : Novel Unsupervised Frameworks For Source-Free Domain Adaptation<span class=acl-fixed-case>BLCUFIGHT</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 10: Novel Unsupervised Frameworks For Source-Free Domain Adaptation</a></strong><br><a href=/people/w/weikang-wang/>Weikang Wang</a>
|
<a href=/people/y/yi-wu/>Yi Wu</a>
|
<a href=/people/y/yixiang-liu/>Yixiang Liu</a>
|
<a href=/people/p/pengyuan-liu/>Pengyuan Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--43><div class="card-body p-3 small">Domain adaptation assumes that samples from source and target domains are freely accessible during a training phase. However, such assumption is rarely plausible in the real-world and may causes data-privacy issues, especially when the label of the source domain can be a sensitive attribute as an identifier. SemEval-2021 task 10 focuses on these issues. We participate in the task and propose novel <a href=https://en.wikipedia.org/wiki/Conceptual_framework>frameworks</a> based on self-training method. In our <a href=https://en.wikipedia.org/wiki/System>systems</a>, two different <a href=https://en.wikipedia.org/wiki/Software_framework>frameworks</a> are designed to solve <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a> and <a href=https://en.wikipedia.org/wiki/Sequence_labeling>sequence labeling</a>. These approaches are tested to be effective which ranks the third among all system in subtask A, and ranks the first among all system in subtask B.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.52.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--52 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.52 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.52/>BOUN at SemEval-2021 Task 9 : Text Augmentation Techniques for Fact Verification in Tabular Data<span class=acl-fixed-case>BOUN</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 9: Text Augmentation Techniques for Fact Verification in Tabular Data</a></strong><br><a href=/people/a/abdullatif-koksal/>Abdullatif Köksal</a>
|
<a href=/people/y/yusuf-yuksel/>Yusuf Yüksel</a>
|
<a href=/people/b/bekir-yildirim/>Bekir Yıldırım</a>
|
<a href=/people/a/arzucan-ozgur/>Arzucan Özgür</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--52><div class="card-body p-3 small">In this paper, we present our text augmentation based approach for the Table Statement Support Subtask (Phase A) of SemEval-2021 Task 9. We experiment with different text augmentation techniques such as <a href=https://en.wikipedia.org/wiki/Back_translation>back translation</a> and synonym swapping using Word2Vec and <a href=https://en.wikipedia.org/wiki/WordNet>WordNet</a>. We show that text augmentation techniques lead to 2.5 % improvement in F1 on the test set. Further, we investigate the impact of <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> and joint learning on fact verification in tabular data by utilizing the SemTabFacts and TabFact datasets. We observe that joint learning improves the F1 scores on the SemTabFacts and TabFact test sets by 3.31 % and 0.77 %, respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.53.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--53 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.53 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.53/>IITK at SemEval-2021 Task 10 : Source-Free Unsupervised Domain Adaptation using Class Prototypes<span class=acl-fixed-case>IITK</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 10: Source-Free Unsupervised Domain Adaptation using Class Prototypes</a></strong><br><a href=/people/h/harshit-kumar-iit/>Harshit Kumar</a>
|
<a href=/people/j/jinang-shah/>Jinang Shah</a>
|
<a href=/people/n/nidhi-hegde/>Nidhi Hegde</a>
|
<a href=/people/p/priyanshu-gupta/>Priyanshu Gupta</a>
|
<a href=/people/v/vaibhav-jindal/>Vaibhav Jindal</a>
|
<a href=/people/a/ashutosh-modi/>Ashutosh Modi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--53><div class="card-body p-3 small">Recent progress in <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> has primarily been fueled by the availability of large amounts of annotated data that is obtained from highly expensive manual annotating pro-cesses. To tackle this issue of availability of annotated data, a lot of research has been done on unsupervised domain adaptation that tries to generate systems for an unlabelled target domain data, given labeled source domain data. However, the availability of annotated or labelled source domain dataset ca n&#8217;t always be guaranteed because of <a href=https://en.wikipedia.org/wiki/Data_privacy>data-privacy issues</a>. This is especially the case with medical data, as <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> may contain sensitive information of the patients. Source-free domain adaptation (SFDA) aims to resolve this issue by us-ing <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> trained on the <a href=https://en.wikipedia.org/wiki/Data>source data</a> instead of using the original annotated source data. In this work, we try to build SFDA systems for <a href=https://en.wikipedia.org/wiki/Semantic_processing>semantic processing</a> by specifically focusing on the negation detection subtask of the SemEval2021 Task 10. We propose two approaches -ProtoAUGandAdapt-ProtoAUGthat use the idea of <a href=https://en.wikipedia.org/wiki/Self-entropy>self-entropy</a> to choose reliable and high confidence samples, which are then used for <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> and subsequent training of the models. Our methods report an improvement of up to 7 % in <a href=https://en.wikipedia.org/wiki/F1_score>F1 score</a> over the <a href=https://en.wikipedia.org/wiki/Baseline_(medicine)>baseline</a> for the Negation Detection subtask.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.54.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--54 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.54 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.54/>PTST-UoM at SemEval-2021 Task 10 : Parsimonious Transfer for Sequence Tagging<span class=acl-fixed-case>PTST</span>-<span class=acl-fixed-case>U</span>o<span class=acl-fixed-case>M</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 10: Parsimonious Transfer for Sequence Tagging</a></strong><br><a href=/people/k/kemal-kurniawan/>Kemal Kurniawan</a>
|
<a href=/people/l/lea-frermann/>Lea Frermann</a>
|
<a href=/people/p/philip-schulz/>Philip Schulz</a>
|
<a href=/people/t/trevor-cohn/>Trevor Cohn</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--54><div class="card-body p-3 small">This paper describes PTST, a source-free unsupervised domain adaptation technique for sequence tagging, and its application to the SemEval-2021 Task 10 on time expression recognition. PTST is an extension of the cross-lingual parsimonious parser transfer framework, which uses high-probability predictions of the source model as a supervision signal in self-training. We extend the <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> to a sequence prediction setting, and demonstrate its applicability to unsupervised domain adaptation. PTST achieves F1 score of 79.6 % on the official test set, with the <a href=https://en.wikipedia.org/wiki/Precision_(statistics)>precision</a> of 90.1 %, the highest out of 14 submissions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.55.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--55 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.55 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.55/>Self-Adapter at SemEval-2021 Task 10 : Entropy-based Pseudo-Labeler for Source-free Domain Adaptation<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 10: Entropy-based Pseudo-Labeler for Source-free Domain Adaptation</a></strong><br><a href=/people/s/sangwon-yoon/>Sangwon Yoon</a>
|
<a href=/people/y/yanghoon-kim/>Yanghoon Kim</a>
|
<a href=/people/k/kyomin-jung/>Kyomin Jung</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--55><div class="card-body p-3 small">Source-free domain adaptation is an emerging line of work in deep learning research since it is closely related to the real-world environment. We study the domain adaption in the sequence labeling problem where the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> trained on the source domain data is given. We propose two <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> : Self-Adapter and Selective Classifier Training. Self-Adapter is a <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training method</a> that uses sentence-level pseudo-labels filtered by the <a href=https://en.wikipedia.org/wiki/Self-entropy>self-entropy threshold</a> to provide supervision to the whole model. Selective Classifier Training uses token-level pseudo-labels and supervises only the classification layer of the model. The proposed <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>methods</a> are evaluated on data provided by SemEval-2021 task 10 and Self-Adapter achieves 2nd rank performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.56.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--56 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.56 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.56/>The University of Arizona at SemEval-2021 Task 10 : Applying Self-training, Active Learning and Data Augmentation to Source-free Domain Adaptation<span class=acl-fixed-case>U</span>niversity of <span class=acl-fixed-case>A</span>rizona at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 10: Applying Self-training, Active Learning and Data Augmentation to Source-free Domain Adaptation</a></strong><br><a href=/people/x/xin-su/>Xin Su</a>
|
<a href=/people/y/yiyun-zhao/>Yiyun Zhao</a>
|
<a href=/people/s/steven-bethard/>Steven Bethard</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--56><div class="card-body p-3 small">This paper describes our systems for negation detection and time expression recognition in SemEval 2021 Task 10, Source-Free Domain Adaptation for Semantic Processing. We show that self-training, <a href=https://en.wikipedia.org/wiki/Active_learning_(machine_learning)>active learning</a> and data augmentation techniques can improve the generalization ability of the model on the unlabeled target domain data without accessing source domain data. We also perform detailed ablation studies and error analyses for our time expression recognition systems to identify the source of the performance improvement and give constructive feedback on the temporal normalization annotation guidelines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.58.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--58 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.58 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.58/>YNU-HPCC at SemEval-2021 Task 11 : Using a BERT Model to Extract Contributions from NLP Scholarly Articles<span class=acl-fixed-case>YNU</span>-<span class=acl-fixed-case>HPCC</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 11: Using a <span class=acl-fixed-case>BERT</span> Model to Extract Contributions from <span class=acl-fixed-case>NLP</span> Scholarly Articles</a></strong><br><a href=/people/x/xinge-ma/>Xinge Ma</a>
|
<a href=/people/j/jin-wang/>Jin Wang</a>
|
<a href=/people/x/xuejie-zhang/>Xuejie Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--58><div class="card-body p-3 small">This paper describes the system we built as the YNU-HPCC team in the SemEval-2021 Task 11 : NLPContributionGraph. This task involves first identifying sentences in the given natural language processing (NLP) scholarly articles that reflect research contributions through binary classification ; then identifying the core scientific terms and their relation phrases from these contribution sentences by sequence labeling ; and finally, these scientific terms and relation phrases are categorized, identified, and organized into subject-predicate-object triples to form a <a href=https://en.wikipedia.org/wiki/Knowledge_graph>knowledge graph</a> with the help of <a href=https://en.wikipedia.org/wiki/Multiclass_classification>multiclass classification</a> and <a href=https://en.wikipedia.org/wiki/Multi-label_classification>multi-label classification</a>. We developed a system for this task using a pre-trained language representation model called BERT that stands for Bidirectional Encoder Representations from Transformers, and achieved good results. The average F1-score for Evaluation Phase 2, Part 1 was 0.4562 and ranked 7th, and the average F1-score for Evaluation Phase 2, Part 2 was 0.6541, and also ranked 7th.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.59.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--59 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.59 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.59/>ITNLP at SemEval-2021 Task 11 : Boosting BERT with Sampling and Adversarial Training for Knowledge Extraction<span class=acl-fixed-case>ITNLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 11: Boosting <span class=acl-fixed-case>BERT</span> with Sampling and Adversarial Training for Knowledge Extraction</a></strong><br><a href=/people/g/genyu-zhang/>Genyu Zhang</a>
|
<a href=/people/y/yu-su/>Yu Su</a>
|
<a href=/people/c/changhong-he/>Changhong He</a>
|
<a href=/people/l/lei-lin/>Lei Lin</a>
|
<a href=/people/c/cheng-jie-sun/>Chengjie Sun</a>
|
<a href=/people/l/lili-shan/>Lili Shan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--59><div class="card-body p-3 small">This paper describes the winning system in the End-to-end Pipeline phase for the NLPContributionGraph task. The system is composed of three BERT-based models and the three <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> are used to extract sentences, entities and triples respectively. Experiments show that sampling and adversarial training can greatly boost the <a href=https://en.wikipedia.org/wiki/System>system</a>. In End-to-end Pipeline phase, our <a href=https://en.wikipedia.org/wiki/System>system</a> got an average F1 of 0.4703, significantly higher than the second-placed system which got an average F1 of 0.3828.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.60.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--60 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.60 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.60/>Duluth at SemEval-2021 Task 11 : Applying DeBERTa to Contributing Sentence Selection and Dependency Parsing for Entity Extraction<span class=acl-fixed-case>D</span>uluth at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 11: Applying <span class=acl-fixed-case>D</span>e<span class=acl-fixed-case>BERT</span>a to Contributing Sentence Selection and Dependency Parsing for Entity Extraction</a></strong><br><a href=/people/a/anna-martin/>Anna Martin</a>
|
<a href=/people/t/ted-pedersen/>Ted Pedersen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--60><div class="card-body p-3 small">This paper describes the Duluth system that participated in SemEval-2021 Task 11, NLP Contribution Graph. It details the extraction of contribution sentences and scientific entities and their relations from scholarly articles in the domain of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a>. Our solution uses deBERTa for multi-class sentence classification to extract the contributing sentences and their type, and dependency parsing to outline each sentence and extract subject-predicate-object triples. Our system ranked fifth of seven for Phase 1 : end-to-end pipeline, sixth of eight for Phase 2 Part 1 : phrases and triples, and fifth of eight for Phase 2 Part 2 : triples extraction.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.61.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--61 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.61 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.61/>INNOVATORS at SemEval-2021 Task-11 : A Dependency Parsing and BERT-based model for Extracting Contribution Knowledge from Scientific Papers<span class=acl-fixed-case>INNOVATORS</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task-11: A Dependency Parsing and <span class=acl-fixed-case>BERT</span>-based model for Extracting Contribution Knowledge from Scientific Papers</a></strong><br><a href=/people/h/hardik-arora/>Hardik Arora</a>
|
<a href=/people/t/tirthankar-ghosal/>Tirthankar Ghosal</a>
|
<a href=/people/s/sandeep-kumar/>Sandeep Kumar</a>
|
<a href=/people/s/suraj-patwal/>Suraj Patwal</a>
|
<a href=/people/p/phil-gooch/>Phil Gooch</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--61><div class="card-body p-3 small">In this work, we describe our system submission to the SemEval 2021 Task 11 : NLP Contribution Graph Challenge. We attempt all the three sub-tasks in the challenge and report our results. Subtask 1 aims to identify the contributing sentences in a given publication. Subtask 2 follows from Subtask 1 to extract the scientific term and predicate phrases from the identified contributing sentences. The final Subtask 3 entails extracting triples (subject, predicate, object) from the phrases and categorizing them under one or more defined information units. With the NLPContributionGraph Shared Task, the organizers formalized the building of a scholarly contributions-focused graph over NLP scholarly articles as an automated task. Our approaches include a BERT-based classification model for identifying the contributing sentences in a research publication, a rule-based dependency parsing for phrase extraction, followed by a CNN-based model for information units classification, and a set of rules for triples extraction. The quantitative results show that we obtain the 5th, 5th, and 7th rank respectively in three evaluation phases. We make our codes available at https://github.com/HardikArora17/SemEval-2021-INNOVATORS.<i>triples</i> (subject, predicate, object) from the phrases and categorizing them under one or more defined information units. With the NLPContributionGraph Shared Task, the organizers formalized the building of a scholarly contributions-focused graph over NLP scholarly articles as an automated task. Our approaches include a BERT-based classification model for identifying the contributing sentences in a research publication, a rule-based dependency parsing for phrase extraction, followed by a CNN-based model for information units classification, and a set of rules for triples extraction. The quantitative results show that we obtain the 5th, 5th, and 7th rank respectively in three evaluation phases. We make our codes available at https://github.com/HardikArora17/SemEval-2021-INNOVATORS.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.63.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--63 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.63 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.63/>HITSZ-HLT at SemEval-2021 Task 5 : Ensemble Sequence Labeling and Span Boundary Detection for Toxic Span Detection<span class=acl-fixed-case>HITSZ</span>-<span class=acl-fixed-case>HLT</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 5: Ensemble Sequence Labeling and Span Boundary Detection for Toxic Span Detection</a></strong><br><a href=/people/q/qinglin-zhu/>Qinglin Zhu</a>
|
<a href=/people/z/zijie-lin/>Zijie Lin</a>
|
<a href=/people/y/yice-zhang/>Yice Zhang</a>
|
<a href=/people/j/jingyi-sun/>Jingyi Sun</a>
|
<a href=/people/x/xiang-li/>Xiang Li</a>
|
<a href=/people/q/qihui-lin/>Qihui Lin</a>
|
<a href=/people/y/yixue-dang/>Yixue Dang</a>
|
<a href=/people/r/ruifeng-xu/>Ruifeng Xu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--63><div class="card-body p-3 small">This paper presents the winning <a href=https://en.wikipedia.org/wiki/System>system</a> that participated in SemEval-2021 Task 5 : Toxic Spans Detection. This task aims to locate those spans that attribute to the text&#8217;s toxicity within a text, which is crucial for semi-automated moderation in online discussions. We formalize this task as the Sequence Labeling (SL) problem and the Span Boundary Detection (SBD) problem separately and employ three state-of-the-art models. Next, we integrate predictions of these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> to produce a more credible and complement result. Our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves a char-level score of 70.83 %, ranking 1/91. In addition, we also explore the lexicon-based method, which is strongly interpretable and flexible in practice.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.65.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--65 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.65 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.65/>UPB at SemEval-2021 Task 8 : Extracting Semantic Information on Measurements as Multi-Turn Question Answering<span class=acl-fixed-case>UPB</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 8: Extracting Semantic Information on Measurements as Multi-Turn Question Answering</a></strong><br><a href=/people/a/andrei-marius-avram/>Andrei-Marius Avram</a>
|
<a href=/people/g/george-eduard-zaharia/>George-Eduard Zaharia</a>
|
<a href=/people/d/dumitru-clementin-cercel/>Dumitru-Clementin Cercel</a>
|
<a href=/people/m/mihai-dascalu/>Mihai Dascalu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--65><div class="card-body p-3 small">Extracting semantic information on measurements and counts is an important topic in terms of analyzing scientific discourses. The 8th task of SemEval-2021 : Counts and Measurements (MeasEval) aimed to boost research in this direction by providing a new dataset on which participants train their models to extract meaningful information on measurements from scientific texts. The competition is composed of five subtasks that build on top of each other : (1) quantity span identification, (2) unit extraction from the identified quantities and their value modifier classification, (3) span identification for measured entities and measured properties, (4) qualifier span identification, and (5) relation extraction between the identified quantities, measured entities, measured properties, and qualifiers. We approached these challenges by first identifying the quantities, extracting their units of measurement, classifying them with corresponding modifiers, and afterwards using them to jointly solve the last three subtasks in a multi-turn question answering manner. Our best performing <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> obtained an overlapping F1-score of 36.91 % on the test set.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.66.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--66 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.66 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.66/>IITK@LCP at SemEval-2021 Task 1 : Classification for Lexical Complexity Regression Task<span class=acl-fixed-case>IITK</span>@<span class=acl-fixed-case>LCP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 1: Classification for Lexical Complexity Regression Task</a></strong><br><a href=/people/n/neil-shirude/>Neil Shirude</a>
|
<a href=/people/s/sagnik-mukherjee/>Sagnik Mukherjee</a>
|
<a href=/people/t/tushar-shandhilya/>Tushar Shandhilya</a>
|
<a href=/people/a/ananta-mukherjee/>Ananta Mukherjee</a>
|
<a href=/people/a/ashutosh-modi/>Ashutosh Modi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--66><div class="card-body p-3 small">This paper describes our contribution to SemEval 2021 Task 1 (Shardlow et al., 2021): Lexical Complexity Prediction. In our approach, we leverage the ELECTRA model and attempt to mirror the data annotation scheme. Although the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is a <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression task</a>, we show that we can treat it as an aggregation of several <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification and regression models</a>. This somewhat counter-intuitive approach achieved an MAE score of 0.0654 for Sub-Task 1 and MAE of 0.0811 on Sub-Task 2. Additionally, we used the concept of weak supervision signals from Gloss-BERT in our work, and it significantly improved the MAE score in Sub-Task 1.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.67.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--67 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.67 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.67/>LCP-RIT at SemEval-2021 Task 1 : Exploring Linguistic Features for Lexical Complexity Prediction<span class=acl-fixed-case>LCP</span>-<span class=acl-fixed-case>RIT</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 1: Exploring Linguistic Features for Lexical Complexity Prediction</a></strong><br><a href=/people/a/abhinandan-tejalkumar-desai/>Abhinandan Tejalkumar Desai</a>
|
<a href=/people/k/kai-north/>Kai North</a>
|
<a href=/people/m/marcos-zampieri/>Marcos Zampieri</a>
|
<a href=/people/c/christopher-homan/>Christopher Homan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--67><div class="card-body p-3 small">This paper describes team LCP-RIT&#8217;s submission to the SemEval-2021 Task 1 : Lexical Complexity Prediction (LCP). The task organizers provided participants with an augmented version of CompLex (Shardlow et al., 2020), an English multi-domain dataset in which words in context were annotated with respect to their <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a> using a five point Likert scale. Our system uses <a href=https://en.wikipedia.org/wiki/Logistic_regression>logistic regression</a> and a wide range of <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>linguistic features</a> (e.g. psycholinguistic features, <a href=https://en.wikipedia.org/wiki/N-gram>n-grams</a>, <a href=https://en.wikipedia.org/wiki/Word_frequency>word frequency</a>, POS tags) to predict the complexity of single words in this dataset. We analyze the impact of different linguistic features on the classification performance and we evaluate the results in terms of <a href=https://en.wikipedia.org/wiki/Mean_absolute_error>mean absolute error</a>, <a href=https://en.wikipedia.org/wiki/Mean_squared_error>mean squared error</a>, <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>Pearson correlation</a>, and <a href=https://en.wikipedia.org/wiki/Spearman_correlation>Spearman correlation</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.69.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--69 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.69 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.69/>CompNA at SemEval-2021 Task 1 : Prediction of lexical complexity analyzing heterogeneous features<span class=acl-fixed-case>C</span>omp<span class=acl-fixed-case>NA</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 1: Prediction of lexical complexity analyzing heterogeneous features</a></strong><br><a href=/people/g/giuseppe-vettigli/>Giuseppe Vettigli</a>
|
<a href=/people/a/antonio-sorgente/>Antonio Sorgente</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--69><div class="card-body p-3 small">This paper describes the CompNa model that has been submitted to the Lexical Complexity Prediction (LCP) shared task hosted at SemEval 2021 (Task 1). The solution is based on combining features of different nature through an ensambling method based on <a href=https://en.wikipedia.org/wiki/Decision_tree_learning>Decision Trees</a> and trained using <a href=https://en.wikipedia.org/wiki/Gradient_boosting>Gradient Boosting</a>. We discuss the results of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> and highlight the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> with more predictive capabilities.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.73.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--73 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.73 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.73/>CS-UM6P at SemEval-2021 Task 1 : A Deep Learning Model-based Pre-trained Transformer Encoder for Lexical Complexity<span class=acl-fixed-case>CS</span>-<span class=acl-fixed-case>UM</span>6<span class=acl-fixed-case>P</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 1: A Deep Learning Model-based Pre-trained Transformer Encoder for Lexical Complexity</a></strong><br><a href=/people/n/nabil-el-mamoun/>Nabil El Mamoun</a>
|
<a href=/people/a/abdelkader-el-mahdaouy/>Abdelkader El Mahdaouy</a>
|
<a href=/people/a/abdellah-el-mekki/>Abdellah El Mekki</a>
|
<a href=/people/k/kabil-essefar/>Kabil Essefar</a>
|
<a href=/people/i/ismail-berrada/>Ismail Berrada</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--73><div class="card-body p-3 small">Lexical Complexity Prediction (LCP) involves assigning a difficulty score to a particular word or expression, in a text intended for a target audience. In this paper, we introduce a new deep learning-based system for this challenging <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. The proposed system consists of a <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning model</a>, based on pre-trained transformer encoder, for word and Multi-Word Expression (MWE) complexity prediction. First, on top of the encoder&#8217;s contextualized word embedding, our model employs an attention layer on the input context and the complex word or MWE. Then, the <a href=https://en.wikipedia.org/wiki/Attentional_control>attention output</a> is concatenated with the pooled output of the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> and passed to a <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression module</a>. We investigate both single-task and joint training on both Sub-Tasks data using multiple pre-trained transformer-based encoders. The obtained results are very promising and show the effectiveness of fine-tuning pre-trained transformers for LCP task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.79.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--79 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.79 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.79/>RG PA at SemEval-2021 Task 1 : A Contextual Attention-based Model with RoBERTa for Lexical Complexity Prediction<span class=acl-fixed-case>RG</span> <span class=acl-fixed-case>PA</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 1: A Contextual Attention-based Model with <span class=acl-fixed-case>R</span>o<span class=acl-fixed-case>BERT</span>a for Lexical Complexity Prediction</a></strong><br><a href=/people/g/gang-rao/>Gang Rao</a>
|
<a href=/people/m/maochang-li/>Maochang Li</a>
|
<a href=/people/x/xiaolong-hou/>Xiaolong Hou</a>
|
<a href=/people/l/lianxin-jiang/>Lianxin Jiang</a>
|
<a href=/people/y/yang-mo/>Yang Mo</a>
|
<a href=/people/j/jianping-shen/>Jianping Shen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--79><div class="card-body p-3 small">In this paper we propose a contextual attention based model with two-stage fine-tune training using RoBERTa. First, we perform the first-stage fine-tune on corpus with RoBERTa, so that the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> can learn some prior <a href=https://en.wikipedia.org/wiki/Domain_knowledge>domain knowledge</a>. Then we get the contextual embedding of context words based on the token-level embedding with the fine-tuned model. And we use Kfold cross-validation to get K models and ensemble them to get the final result. Finally, we attain the 2nd place in the final evaluation phase of sub-task 2 with <a href=https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>pearson correlation</a> of 0.8575.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.81.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--81 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.81 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.81/>CLULEX at SemEval-2021 Task 1 : A Simple System Goes a Long Way<span class=acl-fixed-case>CLULEX</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 1: A Simple System Goes a Long Way</a></strong><br><a href=/people/g/greta-smolenska/>Greta Smolenska</a>
|
<a href=/people/p/peter-kolb/>Peter Kolb</a>
|
<a href=/people/s/sinan-tang/>Sinan Tang</a>
|
<a href=/people/m/mironas-bitinis/>Mironas Bitinis</a>
|
<a href=/people/h/hector-hernandez/>Héctor Hernández</a>
|
<a href=/people/e/elin-asklov/>Elin Asklöv</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--81><div class="card-body p-3 small">This paper presents the <a href=https://en.wikipedia.org/wiki/System>system</a> we submitted to the first Lexical Complexity Prediction (LCP) Shared Task 2021. The Shared Task provides participants with a new English dataset that includes context of the target word. We participate in the single-word complexity prediction sub-task and focus on <a href=https://en.wikipedia.org/wiki/Feature_engineering>feature engineering</a>. Our best system is trained on <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>linguistic features</a> and <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> (Pearson&#8217;s score of 0.7942). We demonstrate, however, that a simpler <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature set</a> achieves comparable results and submit a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> trained on 36 <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>linguistic features</a> (Pearson&#8217;s score of 0.7925).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.83.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--83 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.83 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.83/>UNBNLP at SemEval-2021 Task 1 : Predicting lexical complexity with masked language models and character-level encoders<span class=acl-fixed-case>UNBNLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 1: Predicting lexical complexity with masked language models and character-level encoders</a></strong><br><a href=/people/m/milton-king/>Milton King</a>
|
<a href=/people/a/ali-hakimi-parizi/>Ali Hakimi Parizi</a>
|
<a href=/people/s/samin-fakharian/>Samin Fakharian</a>
|
<a href=/people/p/paul-cook/>Paul Cook</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--83><div class="card-body p-3 small">In this paper, we present three <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised systems</a> for English lexical complexity prediction of single and multiword expressions for SemEval-2021 Task 1. We explore the use of statistical baseline features, masked language models, and character-level encoders to predict the complexity of a target token in context. Our best <a href=https://en.wikipedia.org/wiki/System>system</a> combines information from these three sources. The results indicate that information from masked language models and <a href=https://en.wikipedia.org/wiki/Character_encoding>character-level encoders</a> can be combined to improve lexical complexity prediction.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.92.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--92 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.92 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.semeval-1.92" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.92/>GX at SemEval-2021 Task 2 : BERT with Lemma Information for MCL-WiC Task<span class=acl-fixed-case>GX</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 2: <span class=acl-fixed-case>BERT</span> with Lemma Information for <span class=acl-fixed-case>MCL</span>-<span class=acl-fixed-case>W</span>i<span class=acl-fixed-case>C</span> Task</a></strong><br><a href=/people/w/wanying-xie/>Wanying Xie</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--92><div class="card-body p-3 small">This paper presents the GX system for the Multilingual and Cross-lingual Word-in-Context Disambiguation (MCL-WiC) task. The purpose of the MCL-WiC task is to tackle the challenge of capturing the polysemous nature of words without relying on a fixed sense inventory in a multilingual and cross-lingual setting. To solve the problems, we use context-specific word embeddings from BERT to eliminate the ambiguity between words in different contexts. For languages without an available training corpus, such as <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>, we use neuron machine translation model to translate the English data released by the organizers to obtain available pseudo-data. In this paper, we apply our <a href=https://en.wikipedia.org/wiki/System>system</a> to the English and Chinese multilingual setting and the experimental results show that our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> has certain advantages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.93.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--93 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.93 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.93/>PALI at SemEval-2021 Task 2 : Fine-Tune XLM-RoBERTa for Word in Context Disambiguation<span class=acl-fixed-case>PALI</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 2: Fine-Tune <span class=acl-fixed-case>XLM</span>-<span class=acl-fixed-case>R</span>o<span class=acl-fixed-case>BERT</span>a for Word in Context Disambiguation</a></strong><br><a href=/people/s/shuyi-xie/>Shuyi Xie</a>
|
<a href=/people/j/jian-ma/>Jian Ma</a>
|
<a href=/people/h/haiqin-yang/>Haiqin Yang</a>
|
<a href=/people/l/lianxin-jiang/>Lianxin Jiang</a>
|
<a href=/people/y/yang-mo/>Yang Mo</a>
|
<a href=/people/j/jianping-shen/>Jianping Shen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--93><div class="card-body p-3 small">This paper presents the PALI team&#8217;s winning system for SemEval-2021 Task 2 : Multilingual and Cross-lingual Word-in-Context Disambiguation. We fine-tune XLM-RoBERTa model to solve the task of word in context disambiguation, i.e., to determine whether the target word in the two contexts contains the same meaning or not. In implementation, we first specifically design an input tag to emphasize the target word in the contexts. Second, we construct a new vector on the fine-tuned embeddings from XLM-RoBERTa and feed it to a fully-connected network to output the probability of whether the target word in the context has the same meaning or not. The new <a href=https://en.wikipedia.org/wiki/Vector_(mathematics_and_physics)>vector</a> is attained by concatenating the embedding of the [ CLS ] token and the embeddings of the target word in the contexts. In training, we explore several tricks, such as the Ranger optimizer, <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a>, and adversarial training, to improve the <a href=https://en.wikipedia.org/wiki/Prediction>model prediction</a>. Consequently, we attain the first place in all four cross-lingual tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.96.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--96 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.96 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.96/>Cambridge at SemEval-2021 Task 2 : Neural WiC-Model with Data Augmentation and Exploration of Representation<span class=acl-fixed-case>C</span>ambridge at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 2: Neural <span class=acl-fixed-case>W</span>i<span class=acl-fixed-case>C</span>-Model with Data Augmentation and Exploration of Representation</a></strong><br><a href=/people/z/zheng-yuan/>Zheng Yuan</a>
|
<a href=/people/d/david-strohmaier/>David Strohmaier</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--96><div class="card-body p-3 small">This paper describes the system of the Cambridge team submitted to the SemEval-2021 shared task on Multilingual and Cross-lingual Word-in-Context Disambiguation. Building on top of a pre-trained masked language model, our system is first pre-trained on out-of-domain data, and then fine-tuned on in-domain data. We demonstrate the effectiveness of the proposed two-step training strategy and the benefits of <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> from both existing examples and new resources. We further investigate different <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a> and show that the addition of distance-based features is helpful in the word-in-context disambiguation task. Our system yields highly competitive results in the cross-lingual track without training on any cross-lingual data ; and achieves state-of-the-art results in the multilingual track, ranking first in two languages (Arabic and Russian) and second in <a href=https://en.wikipedia.org/wiki/French_language>French</a> out of 171 submitted systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.103.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--103 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.103 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.103/>LIORI at SemEval-2021 Task 2 : Span Prediction and Binary Classification approaches to Word-in-Context Disambiguation<span class=acl-fixed-case>LIORI</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 2: Span Prediction and Binary Classification approaches to Word-in-Context Disambiguation</a></strong><br><a href=/people/a/adis-davletov/>Adis Davletov</a>
|
<a href=/people/n/nikolay-arefyev/>Nikolay Arefyev</a>
|
<a href=/people/d/denis-gordeev/>Denis Gordeev</a>
|
<a href=/people/a/alexey-rey/>Alexey Rey</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--103><div class="card-body p-3 small">This paper presents our approaches to SemEval-2021 Task 2 : Multilingual and Cross-lingual Word-in-Context Disambiguation task. The first approach attempted to reformulate the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> as a <a href=https://en.wikipedia.org/wiki/Question_answering>question answering problem</a>, while the second one framed it as a binary classification problem. Our best system, which is an ensemble of XLM-R based binary classifiers trained with data augmentation, is among the 3 best-performing systems for <a href=https://en.wikipedia.org/wiki/Russian_language>Russian</a>, <a href=https://en.wikipedia.org/wiki/French_language>French</a> and <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a> in the multilingual subtask. In the post-evaluation period, we experimented with <a href=https://en.wikipedia.org/wiki/Batch_normalization>batch normalization</a>, subword pooling and target word occurrence aggregation methods, resulting in further performance improvements.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.104.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--104 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.104 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.104/>FII_CROSS at SemEval-2021 Task 2 : Multilingual and Cross-lingual Word-in-Context Disambiguation<span class=acl-fixed-case>FII</span>_<span class=acl-fixed-case>CROSS</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 2: Multilingual and Cross-lingual Word-in-Context Disambiguation</a></strong><br><a href=/people/c/ciprian-bodnar/>Ciprian Bodnar</a>
|
<a href=/people/a/andrada-tapuc/>Andrada Tapuc</a>
|
<a href=/people/c/cosmin-pintilie/>Cosmin Pintilie</a>
|
<a href=/people/d/daniela-gifu/>Daniela Gifu</a>
|
<a href=/people/d/diana-trandabat/>Diana Trandabat</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--104><div class="card-body p-3 small">This paper presents a word-in-context disambiguation system. The task focuses on capturing the polysemous nature of words in a multilingual and cross-lingual setting, without considering a strict inventory of word meanings. The system applies Natural Language Processing algorithms on datasets from SemEval 2021 Task 2, being able to identify the meaning of words for the languages <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a>, <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>, <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/French_language>French</a> and <a href=https://en.wikipedia.org/wiki/Russian_language>Russian</a>, without making use of any additional mono- or multilingual resources.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.106.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--106 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.106 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.106/>UoR at SemEval-2021 Task 4 : Using Pre-trained BERT Token Embeddings for Question Answering of Abstract Meaning<span class=acl-fixed-case>U</span>o<span class=acl-fixed-case>R</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 4: Using Pre-trained <span class=acl-fixed-case>BERT</span> Token Embeddings for Question Answering of Abstract Meaning</a></strong><br><a href=/people/t/thanet-markchom/>Thanet Markchom</a>
|
<a href=/people/h/huizhi-liang/>Huizhi Liang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--106><div class="card-body p-3 small">Most <a href=https://en.wikipedia.org/wiki/Question_answering>question answering tasks</a> focuses on <a href=https://en.wikipedia.org/wiki/Prediction>predicting concrete answers</a>, e.g., <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entities</a>. These <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> can be normally achieved by understanding the contexts without additional information required. In Reading Comprehension of Abstract Meaning (ReCAM) task, the abstract answers are introduced. To understand <a href=https://en.wikipedia.org/wiki/Abstract_and_concrete>abstract meanings</a> in the context, additional knowledge is essential. In this paper, we propose an approach that leverages the pre-trained BERT Token embeddings as a prior knowledge resource. According to the results, our approach using the pre-trained BERT outperformed the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a>. It shows that the pre-trained BERT token embeddings can be used as additional knowledge for understanding abstract meanings in <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.107.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--107 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.107 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.107/>Noobs at Semeval-2021 Task 4 : Masked Language Modeling for abstract answer prediction<span class=acl-fixed-case>S</span>emeval-2021 Task 4: Masked Language Modeling for abstract answer prediction</a></strong><br><a href=/people/s/shikhar-shukla/>Shikhar Shukla</a>
|
<a href=/people/s/sarthak-sarthak/>Sarthak Sarthak</a>
|
<a href=/people/k/karm-veer-arya/>Karm Veer Arya</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--107><div class="card-body p-3 small">This paper presents the <a href=https://en.wikipedia.org/wiki/System>system</a> developed by our team for Semeval 2021 Task 4 : Reading Comprehension of Abstract Meaning. The aim of the task was to benchmark the NLP techniques in understanding the abstract concepts present in a passage, and then predict the missing word in a human written summary of the passage. We trained a Roberta-Large model trained with a masked language modeling objective. In cases where this <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> failed to predict one of the available options, another Roberta-Large model trained as a <a href=https://en.wikipedia.org/wiki/Binary_classifier>binary classifier</a> was used to predict correct and incorrect options. We used passage summary generated by Pegasus model and question as inputs. Our best solution was an ensemble of these 2 systems. We achieved an accuracy of 86.22 % on subtask 1 and 87.10 % on subtask 2.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.109.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--109 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.109 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.109/>PINGAN Omini-Sinitic at SemEval-2021 Task 4 : Reading Comprehension of Abstract Meaning<span class=acl-fixed-case>PINGAN</span> Omini-Sinitic at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 4:Reading Comprehension of Abstract Meaning</a></strong><br><a href=/people/y/ye-wang/>Ye Wang</a>
|
<a href=/people/y/yanmeng-wang/>Yanmeng Wang</a>
|
<a href=/people/h/haijun-zhu/>Haijun Zhu</a>
|
<a href=/people/b/bo-zeng/>Bo Zeng</a>
|
<a href=/people/z/zhenghong-hao/>Zhenghong Hao</a>
|
<a href=/people/s/shaojun-wang/>Shaojun Wang</a>
|
<a href=/people/j/jing-xiao/>Jing Xiao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--109><div class="card-body p-3 small">This paper describes the winning system for subtask 2 and the second-placed system for subtask 1 in SemEval 2021 Task 4 : ReadingComprehension of Abstract Meaning. We propose to use pre-trianed Electra discriminator to choose the best abstract word from five candidates. An upper attention and auto denoising mechanism is introduced to process the long sequences. The experiment results demonstrate that this contribution greatly facilitatesthe contextual language modeling in <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension task</a>. The ablation study is also conducted to show the validity of our proposed methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.114.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--114 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.114 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.114/>GHOST at SemEval-2021 Task 5 : Is explanation all you need?<span class=acl-fixed-case>GHOST</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 5: Is explanation all you need?</a></strong><br><a href=/people/k/kamil-plucinski/>Kamil Pluciński</a>
|
<a href=/people/h/hanna-klimczak/>Hanna Klimczak</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--114><div class="card-body p-3 small">This paper discusses different approaches to the Toxic Spans Detection task. The problem posed by the task was to determine which words contribute mostly to recognising a document as toxic. As opposed to <a href=https://en.wikipedia.org/wiki/Binary_classification>binary classification</a> of entire texts, word-level assessment could be of great use during <a href=https://en.wikipedia.org/wiki/Moderation_system>comment moderation</a>, also allowing for a more in-depth comprehension of the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s predictions. As the main goal was to ensure transparency and understanding, this paper focuses on the current state-of-the-art approaches based on the explainable AI concepts and compares them to a supervised learning solution with word-level labels. The work consists of two xAI approaches that automatically provide the explanation for models trained for binary classification of toxic documents : an LSTM model with attention as a model-specific approach and the Shapley values for interpreting BERT predictions as a model-agnostic method. The competing approach considers this <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> as supervised token classification, where models like BERT and its modifications were tested. The paper aims to explore, compare and assess the quality of predictions for different <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> on the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. The advantages of each <a href=https://en.wikipedia.org/wiki/Scientific_method>approach</a> and further research direction are also discussed.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.115.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--115 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.115 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.115/>GoldenWind at SemEval-2021 Task 5 : Orthrus-An Ensemble Approach to Identify Toxicity<span class=acl-fixed-case>G</span>olden<span class=acl-fixed-case>W</span>ind at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 5: Orthrus - An Ensemble Approach to Identify Toxicity</a></strong><br><a href=/people/m/marco-palomino/>Marco Palomino</a>
|
<a href=/people/d/dawid-grad/>Dawid Grad</a>
|
<a href=/people/j/james-bedwell/>James Bedwell</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--115><div class="card-body p-3 small">Many new developments to detect and mitigate <a href=https://en.wikipedia.org/wiki/Toxicity>toxicity</a> are currently being evaluated. We are particularly interested in the correlation between <a href=https://en.wikipedia.org/wiki/Toxicity>toxicity</a> and the <a href=https://en.wikipedia.org/wiki/Emotion>emotions</a> expressed in online posts. While <a href=https://en.wikipedia.org/wiki/Toxicity>toxicity</a> may be disguised by amending the wording of posts, <a href=https://en.wikipedia.org/wiki/Emotion>emotions</a> will not. Therefore, we describe here an ensemble method to identify toxicity and classify the emotions expressed on a corpus of annotated posts published by Task 5 of SemEval 2021our analysis shows that the majority of such posts express <a href=https://en.wikipedia.org/wiki/Anger>anger</a>, sadness and <a href=https://en.wikipedia.org/wiki/Fear>fear</a>. Our method to identify <a href=https://en.wikipedia.org/wiki/Toxicity>toxicity</a> combines a lexicon-based approach, which on its own achieves an F1 score of 61.07 %, with a <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised learning approach</a>, which on its own achieves an F1 score of 60 %. When both <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> are combined, the <a href=https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)>ensemble</a> achieves an F1 score of 66.37 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.119.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--119 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.119 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.119/>NLP_UIOWA at Semeval-2021 Task 5 : Transferring Toxic Sets to Tag Toxic Spans<span class=acl-fixed-case>NLP</span>_<span class=acl-fixed-case>UIOWA</span> at <span class=acl-fixed-case>S</span>emeval-2021 Task 5: Transferring Toxic Sets to Tag Toxic Spans</a></strong><br><a href=/people/j/jonathan-rusert/>Jonathan Rusert</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--119><div class="card-body p-3 small">We leverage a BLSTM with <a href=https://en.wikipedia.org/wiki/Attention>attention</a> to identify toxic spans in texts. We explore different <a href=https://en.wikipedia.org/wiki/Dimension>dimensions</a> which affect the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>&#8217;s performance. The first dimension explored is the toxic set the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is trained on. Besides the provided <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>, we explore the transferability of 5 different toxic related sets, including offensive, toxic, abusive, and hate sets. We find that the solely offensive set shows the highest promise of transferability. The second dimension we explore is <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a>, including leveraging <a href=https://en.wikipedia.org/wiki/Attention>attention</a>, employing a greedy remove method, using a <a href=https://en.wikipedia.org/wiki/Frequency_ratio>frequency ratio</a>, and examining hybrid combinations of multiple methods. We conduct an error analysis to examine which types of toxic spans were missed and which were wrongly inferred as toxic along with the main reasons why they occurred. Finally, we extend our method via ensembles, which achieves our highest F1 score of 55.1.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.120.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--120 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.120 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.120/>S-NLP at SemEval-2021 Task 5 : An Analysis of Dual Networks for Sequence Tagging<span class=acl-fixed-case>S</span>-<span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 5: An Analysis of Dual Networks for Sequence Tagging</a></strong><br><a href=/people/v/viet-anh-nguyen/>Viet Anh Nguyen</a>
|
<a href=/people/t/tam-minh-nguyen/>Tam Minh Nguyen</a>
|
<a href=/people/h/huy-quang-dao/>Huy Quang Dao</a>
|
<a href=/people/q/quang-huu-pham/>Quang Huu Pham</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--120><div class="card-body p-3 small">The SemEval 2021 task 5 : Toxic Spans Detection is a task of identifying considered-toxic spans in text, which provides a valuable, automatic tool for moderating online contents. This paper represents the second-place method for the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, an ensemble of two <a href=https://en.wikipedia.org/wiki/Methodology>approaches</a>. While one approach relies on combining different embedding methods to extract diverse semantic and syntactic representations of words in context ; the other utilizes extra data with a slightly customized Self-training, a semi-supervised learning technique, for sequence tagging problems. Both of our <a href=https://en.wikipedia.org/wiki/Software_architecture>architectures</a> take advantage of a strong <a href=https://en.wikipedia.org/wiki/Language_model>language model</a>, which was fine-tuned on a toxic classification task. Although experimental evidence indicates higher effectiveness of the first approach than the second one, combining them leads to our best results of 70.77 F1-score on the test dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.124.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--124 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.124 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.semeval-1.124" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.124/>MIPT-NSU-UTMN at SemEval-2021 Task 5 : Ensembling Learning with Pre-trained Language Models for Toxic Spans Detection<span class=acl-fixed-case>MIPT</span>-<span class=acl-fixed-case>NSU</span>-<span class=acl-fixed-case>UTMN</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 5: Ensembling Learning with Pre-trained Language Models for Toxic Spans Detection</a></strong><br><a href=/people/m/mikhail-kotyushev/>Mikhail Kotyushev</a>
|
<a href=/people/a/anna-glazkova/>Anna Glazkova</a>
|
<a href=/people/d/dmitry-morozov/>Dmitry Morozov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--124><div class="card-body p-3 small">This paper describes our <a href=https://en.wikipedia.org/wiki/System>system</a> for SemEval-2021 Task 5 on Toxic Spans Detection. We developed ensemble models using BERT-based neural architectures and post-processing to combine tokens into spans. We evaluated several pre-trained language models using various ensemble techniques for toxic span identification and achieved sizable improvements over our baseline fine-tuned BERT models. Finally, our <a href=https://en.wikipedia.org/wiki/System>system</a> obtained a F1-score of 67.55 % on test data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.125.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--125 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.125 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.125/>UIT-E10dot3 at SemEval-2021 Task 5 : Toxic Spans Detection with Named Entity Recognition and Question-Answering Approaches<span class=acl-fixed-case>UIT</span>-E10dot3 at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 5: Toxic Spans Detection with Named Entity Recognition and Question-Answering Approaches</a></strong><br><a href=/people/p/phu-gia-hoang/>Phu Gia Hoang</a>
|
<a href=/people/l/luan-thanh-nguyen/>Luan Thanh Nguyen</a>
|
<a href=/people/k/kiet-nguyen/>Kiet Nguyen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--125><div class="card-body p-3 small">The increment of toxic comments on online space is causing tremendous effects on other vulnerable users. For this reason, considerable efforts are made to deal with this, and SemEval-2021 Task 5 : Toxic Spans Detection is one of those. This task asks competitors to extract spans that have <a href=https://en.wikipedia.org/wiki/Toxicity>toxicity</a> from the given texts, and we have done several analyses to understand its structure before doing experiments. We solve this task by two approaches, <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>Named Entity Recognition</a> with spaCy&#8217;s library and <a href=https://en.wikipedia.org/wiki/Question_answering>Question-Answering</a> with RoBERTa combining with ToxicBERT, and the former gains the highest <a href=https://en.wikipedia.org/wiki/F-number>F1-score</a> of 66.99 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.130.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--130 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.130 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.semeval-1.130" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.130/>YoungSheldon at SemEval-2021 Task 5 : Fine-tuning Pre-trained Language Models for Toxic Spans Detection using Token classification Objective<span class=acl-fixed-case>Y</span>oung<span class=acl-fixed-case>S</span>heldon at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 5: Fine-tuning Pre-trained Language Models for Toxic Spans Detection using Token classification Objective</a></strong><br><a href=/people/m/mayukh-sharma/>Mayukh Sharma</a>
|
<a href=/people/i/ilanthenral-kandasamy/>Ilanthenral Kandasamy</a>
|
<a href=/people/w/w-b-vasantha/>W.b. Vasantha</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--130><div class="card-body p-3 small">In this paper, we describe our <a href=https://en.wikipedia.org/wiki/System>system</a> used for SemEval 2021 Task 5 : Toxic Spans Detection. Our proposed <a href=https://en.wikipedia.org/wiki/System>system</a> approaches the <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> as a token classification task. We trained our model to find toxic words and concatenate their spans to predict the toxic spans within a sentence. We fine-tuned Pre-trained Language Models (PLMs) for identifying the toxic words. For fine-tuning, we stacked the classification layer on top of the PLM features of each word to classify if it is toxic or not. PLMs are pre-trained using different objectives and their performance may differ on downstream tasks. We, therefore, compare the performance of BERT, ELECTRA, RoBERTa, XLM-RoBERTa, T5, XLNet, and MPNet for identifying toxic spans within a sentence. Our best performing <a href=https://en.wikipedia.org/wiki/System>system</a> used RoBERTa. It performed well, achieving an F1 score of 0.6841 and secured a rank of 16 on the official leaderboard.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.134.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--134 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.134 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.134/>SINAI at SemEval-2021 Task 5 : Combining Embeddings in a BiLSTM-CRF model for Toxic Spans Detection<span class=acl-fixed-case>SINAI</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 5: Combining Embeddings in a <span class=acl-fixed-case>B</span>i<span class=acl-fixed-case>LSTM</span>-<span class=acl-fixed-case>CRF</span> model for Toxic Spans Detection</a></strong><br><a href=/people/f/flor-miriam-plaza-del-arco/>Flor Miriam Plaza-del-Arco</a>
|
<a href=/people/p/pilar-lopez-ubeda/>Pilar López-Úbeda</a>
|
<a href=/people/l/l-alfonso-urena-lopez/>L. Alfonso Ureña-López</a>
|
<a href=/people/m/m-teresa-martin-valdivia/>M. Teresa Martín-Valdivia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--134><div class="card-body p-3 small">This paper describes the participation of SINAI team at Task 5 : Toxic Spans Detection which consists of identifying spans that make a text toxic. Although several resources and systems have been developed so far in the context of <a href=https://en.wikipedia.org/wiki/Profanity>offensive language</a>, both <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a> and tasks have mainly focused on classifying whether a text is offensive or not. However, detecting toxic spans is crucial to identify why a text is toxic and can assist human moderators to locate this type of content on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. In order to accomplish the task, we follow a deep learning-based approach using a Bidirectional variant of a Long Short Term Memory network along with a stacked Conditional Random Field decoding layer (BiLSTM-CRF). Specifically, we test the performance of the combination of different pre-trained word embeddings for recognizing toxic entities in text. The results show that the combination of word embeddings helps in detecting offensive content. Our team ranks 29th out of 91 participants.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.135.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--135 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.135 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.135/>CSECU-DSG at SemEval-2021 Task 5 : Leveraging Ensemble of Sequence Tagging Models for Toxic Spans Detection<span class=acl-fixed-case>CSECU</span>-<span class=acl-fixed-case>DSG</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 5: Leveraging Ensemble of Sequence Tagging Models for Toxic Spans Detection</a></strong><br><a href=/people/t/tashin-hossain/>Tashin Hossain</a>
|
<a href=/people/j/jannatun-naim/>Jannatun Naim</a>
|
<a href=/people/f/fareen-tasneem/>Fareen Tasneem</a>
|
<a href=/people/r/radiathun-tasnia/>Radiathun Tasnia</a>
|
<a href=/people/a/abu-nowshed-chy/>Abu Nowshed Chy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--135><div class="card-body p-3 small">The upsurge of prolific <a href=https://en.wikipedia.org/wiki/Blog>blogging</a> and <a href=https://en.wikipedia.org/wiki/Microblogging>microblogging platforms</a> enabled the abusers to spread negativity and <a href=https://en.wikipedia.org/wiki/Threat>threats</a> greater than ever. Detecting the toxic portions substantially aids to moderate or exclude the abusive parts for maintaining sound online platforms. This paper describes our participation in the SemEval 2021 toxic span detection task. The <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> requires detecting spans that convey toxic remarks from the given text. We explore an ensemble of sequence labeling models including the BiLSTM-CRF, spaCy NER model with custom toxic tags, and fine-tuned BERT model to identify the toxic spans. Finally, a majority voting ensemble method is used to determine the unified toxic spans. Experimental results depict the competitive performance of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> among the participants.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.140.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--140 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.140 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.semeval-1.140" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.140/>AIMH at SemEval-2021 Task 6 : Multimodal Classification Using an Ensemble of Transformer Models<span class=acl-fixed-case>AIMH</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 6: Multimodal Classification Using an Ensemble of Transformer Models</a></strong><br><a href=/people/n/nicola-messina/>Nicola Messina</a>
|
<a href=/people/f/fabrizio-falchi/>Fabrizio Falchi</a>
|
<a href=/people/c/claudio-gennaro/>Claudio Gennaro</a>
|
<a href=/people/g/giuseppe-amato/>Giuseppe Amato</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--140><div class="card-body p-3 small">This paper describes the <a href=https://en.wikipedia.org/wiki/System>system</a> used by the AIMH Team to approach the SemEval Task 6. We propose an approach that relies on an architecture based on the transformer model to process multimodal content (text and images) in memes. Our architecture, called DVTT (Double Visual Textual Transformer), approaches Subtasks 1 and 3 of Task 6 as multi-label classification problems, where the text and/or images of the meme are processed, and the probabilities of the presence of each possible persuasion technique are returned as a result. DVTT uses two complete networks of transformers that work on text and images that are mutually conditioned. One of the two <a href=https://en.wikipedia.org/wiki/Methodology>modalities</a> acts as the main one and the second one intervenes to enrich the first one, thus obtaining two distinct ways of operation. The two transformers outputs are merged by averaging the inferred probabilities for each possible label, and the overall <a href=https://en.wikipedia.org/wiki/Neural_network>network</a> is trained end-to-end with a binary cross-entropy loss.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.142.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--142 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.142 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.142/>1213Li at SemEval-2021 Task 6 : Detection of Propaganda with Multi-modal Attention and Pre-trained Models<span class=acl-fixed-case>L</span>i at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 6: Detection of Propaganda with Multi-modal Attention and Pre-trained Models</a></strong><br><a href=/people/p/peiguang-li/>Peiguang Li</a>
|
<a href=/people/x/xuan-li/>Xuan Li</a>
|
<a href=/people/x/xian-sun/>Xian Sun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--142><div class="card-body p-3 small">This paper presents the solution proposed by the 1213Li team for subtask 3 in SemEval-2021 Task 6 : identifying the multiple persuasion techniques used in the multi-modal content of the meme. We explored various approaches in <a href=https://en.wikipedia.org/wiki/Feature_extraction>feature extraction</a> and the detection of persuasion labels. Our final model employs pre-trained models including RoBERTa and ResNet-50 as a feature extractor for texts and images, respectively, and adopts a label embedding layer with multi-modal attention mechanism to measure the similarity of labels with the multi-modal information and fuse features for label prediction. Our proposed method outperforms the provided baseline method and achieves 3rd out of 16 participants with 0.54860/0.22830 for Micro / Macro F1 scores.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.143.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--143 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.143 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.143/>NLyticsFKIE at SemEval-2021 Task 6 : Detection of Persuasion Techniques In Texts And Images<span class=acl-fixed-case>NL</span>ytics<span class=acl-fixed-case>FKIE</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 6: Detection of Persuasion Techniques In Texts And Images</a></strong><br><a href=/people/a/albert-pritzkau/>Albert Pritzkau</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--143><div class="card-body p-3 small">The following system description presents our approach to the detection of persuasion techniques in <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>texts</a> and <a href=https://en.wikipedia.org/wiki/Digital_image>images</a>. The given <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> has been framed as a multi-label classification problem with the different techniques serving as class labels. The multi-label classification problem is one in which a list of target variables such as our class labels is associated with every input chunk and assumes that a document can simultaneously and independently be assigned to multiple labels or classes. In order to assign class labels to the given memes, we opted for RoBERTa (A Robustly Optimized BERT Pretraining Approach) as a neural network architecture for token and sequence classification. Starting off with a pre-trained model for language representation we fine-tuned this <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> on the given classification task with the provided annotated data in supervised training steps. To incorporate image features in the multi-modal setting, we rely on the pre-trained VGG-16 model architecture.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.144.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--144 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.144 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.144/>YNU-HPCC at SemEval-2021 Task 6 : Combining ALBERT and Text-CNN for Persuasion Detection in Texts and Images<span class=acl-fixed-case>YNU</span>-<span class=acl-fixed-case>HPCC</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 6: Combining <span class=acl-fixed-case>ALBERT</span> and Text-<span class=acl-fixed-case>CNN</span> for Persuasion Detection in Texts and Images</a></strong><br><a href=/people/x/xingyu-zhu/>Xingyu Zhu</a>
|
<a href=/people/j/jin-wang/>Jin Wang</a>
|
<a href=/people/x/xuejie-zhang/>Xuejie Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--144><div class="card-body p-3 small">In recent years, <a href=https://en.wikipedia.org/wiki/Meme>memes</a> combining image and text have been widely used in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>, and <a href=https://en.wikipedia.org/wiki/Meme>memes</a> are one of the most popular types of content used in online disinformation campaigns. In this paper, our study on the detection of persuasion techniques in <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>texts</a> and <a href=https://en.wikipedia.org/wiki/Image>images</a> in SemEval-2021 Task 6 is summarized. For propaganda technology detection in text, we propose a combination model of both ALBERT and Text CNN for text classification, as well as a BERT-based multi-task sequence labeling model for propaganda technology coverage span detection. For the meme classification task involved in text understanding and visual feature extraction, we designed a parallel channel model divided into text and image channels. Our <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>method</a> achieved a good performance on subtasks 1 and 3. The micro F1-scores of 0.492, 0.091, and 0.446 achieved on the test sets of the three subtasks ranked 12th, 7th, and 11th, respectively, and all are higher than the baseline model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.147.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--147 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.147 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.147/>NLPIITR at SemEval-2021 Task 6 : RoBERTa Model with Data Augmentation for Persuasion Techniques Detection<span class=acl-fixed-case>NLPIITR</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 6: <span class=acl-fixed-case>R</span>o<span class=acl-fixed-case>BERT</span>a Model with Data Augmentation for Persuasion Techniques Detection</a></strong><br><a href=/people/v/vansh-gupta/>Vansh Gupta</a>
|
<a href=/people/r/raksha-sharma/>Raksha Sharma</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--147><div class="card-body p-3 small">This paper describes and examines different systems to address Task 6 of SemEval-2021 : Detection of Persuasion Techniques In Texts And Images, Subtask 1. The task aims to build a model for identifying rhetorical and psycho- logical techniques (such as causal oversimplification, name-calling, smear) in the textual content of a meme which is often used in a disinformation campaign to influence the users. The paper provides an extensive comparison among various <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning systems</a> as a solution to the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. We elaborate on the pre-processing of the <a href=https://en.wikipedia.org/wiki/Text_file>text data</a> in favor of the task and present ways to overcome the class imbalance. The results show that fine-tuning a RoBERTa model gave the best results with an <a href=https://en.wikipedia.org/wiki/F-number>F1-Micro score</a> of 0.51 on the development set.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.150.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--150 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.150 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.150/>MinD at SemEval-2021 Task 6 : Propaganda Detection using Transfer Learning and Multimodal Fusion<span class=acl-fixed-case>M</span>in<span class=acl-fixed-case>D</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 6: Propaganda Detection using Transfer Learning and Multimodal Fusion</a></strong><br><a href=/people/j/junfeng-tian/>Junfeng Tian</a>
|
<a href=/people/m/min-gui/>Min Gui</a>
|
<a href=/people/c/chenliang-li/>Chenliang Li</a>
|
<a href=/people/m/ming-yan/>Ming Yan</a>
|
<a href=/people/w/wenming-xiao/>Wenming Xiao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--150><div class="card-body p-3 small">We describe our systems of subtask1 and subtask3 for SemEval-2021 Task 6 on Detection of Persuasion Techniques in Texts and Images. The purpose of subtask1 is to identify <a href=https://en.wikipedia.org/wiki/Propaganda_techniques>propaganda techniques</a> given textual content, and the goal of subtask3 is to detect them given both textual and visual content. For subtask1, we investigate <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> based on pre-trained language models (PLMs) such as <a href=https://en.wikipedia.org/wiki/BERT>BERT</a>, RoBERTa to solve data sparsity problems. For subtask3, we extract <a href=https://en.wikipedia.org/wiki/Homogeneity_and_heterogeneity>heterogeneous visual representations</a> (i.e., face features, <a href=https://en.wikipedia.org/wiki/Optical_character_recognition>OCR features</a>, and multimodal representations) and explore various multimodal fusion strategies to combine the textual and visual representations. The official evaluation shows our ensemble model ranks 1st for subtask1 and 2nd for subtask3.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.151.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--151 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.151 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.151/>CSECU-DSG at SemEval-2021 Task 6 : Orchestrating Multimodal Neural Architectures for Identifying Persuasion Techniques in Texts and Images<span class=acl-fixed-case>CSECU</span>-<span class=acl-fixed-case>DSG</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 6: Orchestrating Multimodal Neural Architectures for Identifying Persuasion Techniques in Texts and Images</a></strong><br><a href=/people/t/tashin-hossain/>Tashin Hossain</a>
|
<a href=/people/j/jannatun-naim/>Jannatun Naim</a>
|
<a href=/people/f/fareen-tasneem/>Fareen Tasneem</a>
|
<a href=/people/r/radiathun-tasnia/>Radiathun Tasnia</a>
|
<a href=/people/a/abu-nowshed-chy/>Abu Nowshed Chy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--151><div class="card-body p-3 small">Inscribing persuasion techniques in <a href=https://en.wikipedia.org/wiki/Meme>memes</a> is the most impactful way to influence peoples&#8217; mindsets. People are more inclined to memes as they are more stimulating and convincing and hence <a href=https://en.wikipedia.org/wiki/Meme>memes</a> are often exploited by tactfully engraving propaganda in its context with the intent of attaining specific agenda. This paper describes our participation in the three subtasks featured by SemEval 2021 task 6 on the detection of persuasion techniques in <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>texts</a> and <a href=https://en.wikipedia.org/wiki/Image>images</a>. We utilize a fusion of <a href=https://en.wikipedia.org/wiki/Logistic_regression>logistic regression</a>, <a href=https://en.wikipedia.org/wiki/Decision_tree_learning>decision tree</a>, and fine-tuned DistilBERT for tackling subtask 1. As for subtask 2, we propose a system that consolidates a span identification model and a multi-label classification model based on pre-trained BERT. We address the multi-modal multi-label classification of memes defined in subtask 3 by utilizing a ResNet50 based image model, DistilBERT based text model, and a multi-modal architecture based on multikernel CNN+LSTM and MLP model. The outcomes illustrated the competitive performance of our <a href=https://en.wikipedia.org/wiki/System>systems</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.152.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--152 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.152 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.semeval-1.152" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.152/>UMUTeam at SemEval-2021 Task 7 : Detecting and Rating Humor and Offense with Linguistic Features and Word Embeddings<span class=acl-fixed-case>UMUT</span>eam at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 7: Detecting and Rating Humor and Offense with Linguistic Features and Word Embeddings</a></strong><br><a href=/people/j/jose-antonio-garcia-diaz/>José Antonio García-Díaz</a>
|
<a href=/people/r/rafael-valencia-garcia/>Rafael Valencia-García</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--152><div class="card-body p-3 small">In writing, <a href=https://en.wikipedia.org/wiki/Humour>humor</a> is mainly based on <a href=https://en.wikipedia.org/wiki/Literal_and_figurative_language>figurative language</a> in which words and expressions change their conventional meaning to refer to something without saying it directly. This flip in the meaning of the words prevents <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a> from revealing the real intention of a communication and, therefore, reduces the effectiveness of tasks such as <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a> or <a href=https://en.wikipedia.org/wiki/Emotion_detection>Emotion Detection</a>. In this manuscript we describe the participation of the UMUTeam in HaHackathon 2021, whose objective is to detect and rate humorous and controversial content. Our proposal is based on the combination of <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>linguistic features</a> with contextual and non-contextual word embeddings. We participate in all the proposed subtasks achieving our best result in the controversial humor subtask.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.153.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--153 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.153 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.153/>ES-JUST at SemEval-2021 Task 7 : Detecting and Rating Humor and Offensive Text Using <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Learning</a><span class=acl-fixed-case>ES</span>-<span class=acl-fixed-case>JUST</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 7: Detecting and Rating Humor and Offensive Text Using Deep Learning</a></strong><br><a href=/people/e/emran-al-bashabsheh/>Emran Al Bashabsheh</a>
|
<a href=/people/s/sanaa-abu-alasal/>Sanaa Abu Alasal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--153><div class="card-body p-3 small">This research presents the work of the team&#8217;s ES-JUST at semEval-2021 task 7 for detecting and rating humor and offensive text using <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a>. The team evaluates several approaches (i.e. Bert, Roberta, XLM-Roberta, and Bert embedding + Bi-LSTM) that employ in four sub-tasks. The first sub-task deal with whether the text is humorous or not. The second sub-task is the degree of <a href=https://en.wikipedia.org/wiki/Humour>humor</a> in the text if the first <a href=https://en.wikipedia.org/wiki/Task_(project_management)>sub-task</a> is humorous. The third sub-task represents the text is controversial or not if it is humorous. While in the last task is the degree of an offensive in the text. However, Roberta pre-trained model outperforms other approaches and score the highest in all sub-tasks. We rank on the leader board at the evaluation phase are 14, 15, 20, and 5 through 0.9564 <a href=https://en.wikipedia.org/wiki/F-score>F-score</a>, 0.5709 <a href=https://en.wikipedia.org/wiki/Randomized_controlled_trial>RMSE</a>, 0.4888 <a href=https://en.wikipedia.org/wiki/F-score>F-score</a>, and 0.4467 RMSE results, respectively, for each of the first, second, third, and fourth sub-task, respectively.<i>i.e.Bert, Roberta, XLM-Roberta, and Bert embedding + Bi-LSTM</i>) that employ in four sub-tasks. The first sub-task deal with whether the text is humorous or not. The second sub-task is the degree of humor in the text if the first sub-task is humorous. The third sub-task represents the text is controversial or not if it is humorous. While in the last task is the degree of an offensive in the text. However, Roberta pre-trained model outperforms other approaches and score the highest in all sub-tasks. We rank on the leader board at the evaluation phase are 14, 15, 20, and 5 through 0.9564 F-score, 0.5709 RMSE, 0.4888 F-score, and 0.4467 RMSE results, respectively, for each of the first, second, third, and fourth sub-task, respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.154.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--154 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.154 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.154/>Tsia at SemEval-2021 Task 7 : Detecting and Rating Humor and Offense<span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 7: Detecting and Rating Humor and Offense</a></strong><br><a href=/people/z/zhengyi-guan/>Zhengyi Guan</a>
|
<a href=/people/x/xiaobing-zxb-zhou/>Xiaobing ZXB Zhou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--154><div class="card-body p-3 small">This paper describes our contribution to SemEval-2021 Task 7 : Detecting and Rating Humor and Of-fense. This task contains two sub-tasks, sub-task 1and sub-task 2. Among them, sub-task 1 containsthree <a href=https://en.wikipedia.org/wiki/Task_(project_management)>sub-tasks</a>, sub-task 1a, sub-task 1b and sub-task 1c. Sub-task 1a is to predict if the text would beconsidered humorous. Sub-task 1c is described asfollows : if the text is classed as humorous, predictif the humor rating would be considered controver-sial, i.e. the variance of the rating between annota-tors is higher than the median.we combined threepre-trained model with CNN to complete these twoclassification sub-tasks. Sub-task 1b is to judge thedegree of <a href=https://en.wikipedia.org/wiki/Humour>humor</a>. Sub-task 2 aims to predict how of-fensive a text would be with values between 0 and5.We use the idea of <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression</a> to deal with thesetwo sub-tasks. We analyze the performance of ourmethod and demonstrate the contribution of eachcomponent of our architecture. We have achievedgood results under the combination of multiple pre-training models and optimization methods.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.169.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--169 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.169 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.semeval-1.169" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.169/>DuluthNLP at SemEval-2021 Task 7 : Fine-Tuning RoBERTa Model for Humor Detection and Offense Rating<span class=acl-fixed-case>D</span>uluth<span class=acl-fixed-case>NLP</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 7: Fine-Tuning <span class=acl-fixed-case>R</span>o<span class=acl-fixed-case>BERT</span>a Model for Humor Detection and Offense Rating</a></strong><br><a href=/people/s/samuel-akrah/>Samuel Akrah</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--169><div class="card-body p-3 small">This paper presents the DuluthNLP submission to Task 7 of the SemEval 2021 competition on Detecting and Rating Humor and Offense. In it, we explain the approach used to train the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> together with the process of fine-tuning our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> in getting the results. We focus on humor detection, rating, and of-fense rating, representing three out of the four subtasks that were provided. We show that optimizing hyper-parameters for learning rate, batch size and number of epochs can increase the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and <a href=https://en.wikipedia.org/wiki/F-number>F1 score</a> for humor detection</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.172.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--172 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.172 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.172/>EndTimes at SemEval-2021 Task 7 : Detecting and Rating Humor and Offense with BERT and Ensembles<span class=acl-fixed-case>E</span>nd<span class=acl-fixed-case>T</span>imes at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 7: Detecting and Rating Humor and Offense with <span class=acl-fixed-case>BERT</span> and Ensembles</a></strong><br><a href=/people/c/chandan-kumar-pandey/>Chandan Kumar Pandey</a>
|
<a href=/people/c/chirag-singh/>Chirag Singh</a>
|
<a href=/people/k/karan-mangla/>Karan Mangla</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--172><div class="card-body p-3 small">This paper describes Humor-BERT, a set of BERT Large based models that we used in the SemEval-2021 Task 7 : Detecting and Rating Humor and Offense. It presents pre and post processing techniques, variable threshold learning, meta learning and Ensemble approach to solve various sub-tasks that were part of the challenge. We also present a comparative analysis of various <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> we tried. Our method was ranked 4th in Humor Controversy Detection, 8th in Humor Detection, 19th in Average Offense Score prediction and 40th in Average Humor Score prediction globally. F1 score obtained for <a href=https://en.wikipedia.org/wiki/Humorism>Humor classification</a> was 0.9655 and for Controversy detection it was 0.6261. Our user name on the leader board is ThisIstheEnd and team name is EndTimes.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.173.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--173 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.173 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.173/>IIITH at SemEval-2021 Task 7 : Leveraging transformer-based humourous and offensive text detection architectures using lexical and hurtlex features and task adaptive pretraining<span class=acl-fixed-case>IIITH</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 7: Leveraging transformer-based humourous and offensive text detection architectures using lexical and hurtlex features and task adaptive pretraining</a></strong><br><a href=/people/t/tathagata-raha/>Tathagata Raha</a>
|
<a href=/people/i/ishan-sanjeev-upadhyay/>Ishan Sanjeev Upadhyay</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a>
|
<a href=/people/v/vasudeva-varma/>Vasudeva Varma</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--173><div class="card-body p-3 small">This paper describes our approach (IIITH) for SemEval-2021 Task 5 : HaHackathon : Detecting and Rating Humor and Offense. Our results focus on two major objectives : (i) Effect of task adaptive pretraining on the performance of transformer based models (ii) How does lexical and hurtlex features help in quantifying humour and offense. In this paper, we provide a detailed description of our approach along with comparisions mentioned above.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.180.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--180 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.180 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.semeval-1.180" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.180/>Volta at SemEval-2021 Task 9 : Statement Verification and Evidence Finding with Tables using TAPAS and Transfer Learning<span class=acl-fixed-case>V</span>olta at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 9: Statement Verification and Evidence Finding with Tables using <span class=acl-fixed-case>TAPAS</span> and Transfer Learning</a></strong><br><a href=/people/d/devansh-gautam/>Devansh Gautam</a>
|
<a href=/people/k/kshitij-gupta/>Kshitij Gupta</a>
|
<a href=/people/m/manish-shrivastava/>Manish Shrivastava</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--180><div class="card-body p-3 small">Tables are widely used in various kinds of documents to present information concisely. Understanding tables is a challenging problem that requires an understanding of language and table structure, along with numerical and logical reasoning. In this paper, we present our systems to solve Task 9 of SemEval-2021 : Statement Verification and Evidence Finding with Tables (SEM-TAB-FACTS). The task consists of two subtasks : (A) Given a table and a statement, predicting whether the table supports the statement and (B) Predicting which cells in the table provide evidence for / against the statement. We fine-tune TAPAS (a model which extends BERT&#8217;s architecture to capture tabular structure) for both the subtasks as it has shown state-of-the-art performance in various table understanding tasks. In subtask A, we evaluate how <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> and standardizing tables to have a single header row improves TAPAS&#8217; performance. In subtask B, we evaluate how different fine-tuning strategies can improve TAPAS&#8217; performance. Our systems achieve an <a href=https://en.wikipedia.org/wiki/International_Federation_of_the_Phonographic_Industry>F1 score</a> of 67.34 in subtask A three-way classification, 72.89 in subtask A <a href=https://en.wikipedia.org/wiki/International_Federation_of_the_Phonographic_Industry>two-way classification</a>, and 62.95 in subtask B.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.184.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--184 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.184 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.184/>YNU-HPCC at SemEval-2021 Task 10 : Using a Transformer-based Source-Free Domain Adaptation Model for Semantic Processing<span class=acl-fixed-case>YNU</span>-<span class=acl-fixed-case>HPCC</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 10: Using a Transformer-based Source-Free Domain Adaptation Model for Semantic Processing</a></strong><br><a href=/people/z/zhewen-yu/>Zhewen Yu</a>
|
<a href=/people/j/jin-wang/>Jin Wang</a>
|
<a href=/people/x/xuejie-zhang/>Xuejie Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--184><div class="card-body p-3 small">Data sharing restrictions are common in NLP datasets. The purpose of this task is to develop a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> trained in a source domain to make predictions for a target domain with related domain data. To address the issue, the organizers provided the <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> that fine-tuned a large number of source domain data on pre-trained models and the dev data for participants. But the source domain data was not distributed. This paper describes the provided <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to the NER (Name entity recognition) task and the ways to develop the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. As a little data provided, pre-trained models are suitable to solve the cross-domain tasks. The models fine-tuned by large number of another domain could be effective in new domain because the task had no change.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.semeval-1.186.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--semeval-1--186 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.semeval-1.186 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.semeval-1.186/>UOR at SemEval-2021 Task 12 : On Crowd Annotations ; Learning with Disagreements to optimise crowd truth<span class=acl-fixed-case>UOR</span> at <span class=acl-fixed-case>S</span>em<span class=acl-fixed-case>E</span>val-2021 Task 12: On Crowd Annotations; Learning with Disagreements to optimise crowd truth</a></strong><br><a href=/people/e/emmanuel-osei-brefo/>Emmanuel Osei-Brefo</a>
|
<a href=/people/t/thanet-markchom/>Thanet Markchom</a>
|
<a href=/people/h/huizhi-liang/>Huizhi Liang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--semeval-1--186><div class="card-body p-3 small">Crowdsourcing has been ubiquitously used for annotating enormous collections of data. However, the major obstacles to using crowd-sourced labels are <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noise</a> and errors from non-expert annotations. In this work, two approaches dealing with the <a href=https://en.wikipedia.org/wiki/Noise>noise</a> and errors in crowd-sourced labels are proposed. The first approach uses Sharpness-Aware Minimization (SAM), an optimization technique robust to noisy labels. The other approach leverages a neural network layer called softmax-Crowdlayer specifically designed to learn from crowd-sourced annotations. According to the results, the proposed approaches can improve the performance of the Wide Residual Network model and Multi-layer Perception model applied on crowd-sourced datasets in the image processing domain. It also has similar and comparable results with the majority voting technique when applied to the sequential data domain whereby the Bidirectional Encoder Representations from Transformers (BERT) is used as the base model in both instances.</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>