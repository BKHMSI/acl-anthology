<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title><a href=https://aclanthology.org/K18-2.pdf>Proceedings of the <span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>NLL</span> 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</a></h2><p class=lead><a href=/people/d/daniel-zeman/>Daniel Zeman</a>,
<a href=/people/j/jan-hajic/>Jan Hajič</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>K18-2</dd><dt>Month:</dt><dd>October</dd><dt>Year:</dt><dd>2018</dd><dt>Address:</dt><dd>Brussels, Belgium</dd><dt>Venue:</dt><dd><a href=/venues/conll/>CoNLL</a></dd><dt>SIG:</dt><dd><a href=/sigs/signll/>SIGNLL</a></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/K18-2>https://aclanthology.org/K18-2</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/K18-2.pdf>https://aclanthology.org/K18-2.pdf</a></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/K18-2.pdf title="Open PDF of 'Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF&nbsp;<small>(full)</small></span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+the+CoNLL+2018+Shared+Task%3A+Multilingual+Parsing+from+Raw+Text+to+Universal+Dependencies" title="Search for 'Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K18-2000.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K18-2000/>Proceedings of the <span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>NLL</span> 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</a></strong><br><a href=/people/d/daniel-zeman/>Daniel Zeman</a>
|
<a href=/people/j/jan-hajic/>Jan Hajič</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K18-2003.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K18-2003 data-toggle=collapse aria-expanded=false aria-controls=abstract-K18-2003 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=K18-2003" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/K18-2003/>CEA LIST : Processing Low-Resource Languages for CoNLL 2018<span class=acl-fixed-case>CEA</span> <span class=acl-fixed-case>LIST</span>: Processing Low-Resource Languages for <span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>NLL</span> 2018</a></strong><br><a href=/people/e/elie-duthoo/>Elie Duthoo</a>
|
<a href=/people/o/olivier-mesnard/>Olivier Mesnard</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K18-2003><div class="card-body p-3 small">In this paper, we describe the <a href=https://en.wikipedia.org/wiki/System>system</a> used for our first participation at the CoNLL 2018 shared task. The submitted <a href=https://en.wikipedia.org/wiki/System>system</a> largely reused the state of the art <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> from CoNLL 2017 (). We enhanced this system for morphological features predictions, and we used all available resources to provide accurate models for low-resource languages. We ranked 5th of 27 participants in MLAS for building morphology aware dependency trees, 2nd for morphological features only, and 3rd for tagging (UPOS) and parsing (LAS) low-resource languages.<url>https://github.com/tdozat/Parser-v2</url>). We enhanced this system for morphological features predictions, and we used all available resources to provide accurate models for low-resource languages. We ranked 5th of 27 participants in MLAS for building morphology aware dependency trees, 2nd for morphological features only, and 3rd for tagging (UPOS) and parsing (LAS) low-resource languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K18-2004.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K18-2004 data-toggle=collapse aria-expanded=false aria-controls=abstract-K18-2004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=K18-2004" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/K18-2004/>Semi-Supervised Neural System for <a href=https://en.wikipedia.org/wiki/Tag_(metadata)>Tagging</a>, <a href=https://en.wikipedia.org/wiki/Parsing>Parsing</a> and Lematization</a></strong><br><a href=/people/p/piotr-rybak/>Piotr Rybak</a>
|
<a href=/people/a/alina-wroblewska/>Alina Wróblewska</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K18-2004><div class="card-body p-3 small">This paper describes the ICS PAS system which took part in CoNLL 2018 shared task on Multilingual Parsing from Raw Text to Universal Dependencies. The system consists of jointly trained <a href=https://en.wikipedia.org/wiki/Tagger>tagger</a>, <a href=https://en.wikipedia.org/wiki/Lemmatizer>lemmatizer</a>, and <a href=https://en.wikipedia.org/wiki/Dependency_grammar>dependency parser</a> which are based on features extracted by a biLSTM network. The <a href=https://en.wikipedia.org/wiki/System>system</a> uses both fully connected and dilated convolutional neural architectures. The novelty of our approach is the use of an additional <a href=https://en.wikipedia.org/wiki/Loss_function>loss function</a>, which reduces the number of cycles in the predicted dependency graphs, and the use of self-training to increase the system performance. The proposed <a href=https://en.wikipedia.org/wiki/System>system</a>, i.e. ICS PAS (Warszawa), ranked 3th/4th in the official evaluation obtaining the following overall results : 73.02 (LAS), 60.25 (MLAS) and 64.44 (BLEX).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K18-2005.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K18-2005 data-toggle=collapse aria-expanded=false aria-controls=abstract-K18-2005 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=K18-2005" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/K18-2005/>Towards Better UD Parsing : Deep Contextualized Word Embeddings, Ensemble, and Treebank Concatenation<span class=acl-fixed-case>UD</span> Parsing: Deep Contextualized Word Embeddings, Ensemble, and Treebank Concatenation</a></strong><br><a href=/people/w/wanxiang-che/>Wanxiang Che</a>
|
<a href=/people/y/yijia-liu/>Yijia Liu</a>
|
<a href=/people/y/yuxuan-wang/>Yuxuan Wang</a>
|
<a href=/people/b/bo-zheng/>Bo Zheng</a>
|
<a href=/people/t/ting-liu/>Ting Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K18-2005><div class="card-body p-3 small">This paper describes our system (HIT-SCIR) submitted to the CoNLL 2018 shared task on Multilingual Parsing from Raw Text to Universal Dependencies. We base our submission on Stanford&#8217;s winning system for the CoNLL 2017 shared task and make two effective extensions : 1) incorporating deep contextualized word embeddings into both the part of speech tagger and <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> ; 2) ensembling parsers trained with different initialization. We also explore different ways of concatenating <a href=https://en.wikipedia.org/wiki/Treebank>treebanks</a> for further improvements. Experimental results on the development data show the effectiveness of our <a href=https://en.wikipedia.org/wiki/Methodology>methods</a>. In the final evaluation, our <a href=https://en.wikipedia.org/wiki/System>system</a> was ranked first according to <a href=https://en.wikipedia.org/wiki/Level_of_service>LAS</a> (75.84 %) and outperformed the other <a href=https://en.wikipedia.org/wiki/System>systems</a> by a large margin.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K18-2006.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K18-2006 data-toggle=collapse aria-expanded=false aria-controls=abstract-K18-2006 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=K18-2006" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/K18-2006/>Joint Learning of POS and Dependencies for Multilingual Universal Dependency Parsing<span class=acl-fixed-case>POS</span> and Dependencies for Multilingual <span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependency Parsing</a></strong><br><a href=/people/z/zuchao-li/>Zuchao Li</a>
|
<a href=/people/s/shexia-he/>Shexia He</a>
|
<a href=/people/z/zhuosheng-zhang/>Zhuosheng Zhang</a>
|
<a href=/people/h/hai-zhao/>Hai Zhao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K18-2006><div class="card-body p-3 small">This paper describes the system of team LeisureX in the CoNLL 2018 Shared Task : Multilingual Parsing from Raw Text to Universal Dependencies. Our <a href=https://en.wikipedia.org/wiki/System>system</a> predicts the <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tag</a> and dependency tree jointly. For the basic tasks, including <a href=https://en.wikipedia.org/wiki/Lexical_analysis>tokenization</a>, <a href=https://en.wikipedia.org/wiki/Lemmatization>lemmatization</a> and <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphology prediction</a>, we employ the official baseline model (UDPipe). To train the low-resource languages, we adopt a <a href=https://en.wikipedia.org/wiki/Sampling_(statistics)>sampling method</a> based on other richresource languages. Our <a href=https://en.wikipedia.org/wiki/System>system</a> achieves a macro-average of 68.31 % LAS F1 score, with an improvement of 2.51 % compared with the UDPipe.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K18-2008.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K18-2008 data-toggle=collapse aria-expanded=false aria-controls=abstract-K18-2008 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=K18-2008" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/K18-2008/>An Improved Neural Network Model for Joint POS Tagging and Dependency Parsing<span class=acl-fixed-case>POS</span> Tagging and Dependency Parsing</a></strong><br><a href=/people/d/dat-quoc-nguyen/>Dat Quoc Nguyen</a>
|
<a href=/people/k/karin-verspoor/>Karin Verspoor</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K18-2008><div class="card-body p-3 small">We propose a novel neural network model for joint part-of-speech (POS) tagging and dependency parsing. Our model extends the well-known BIST graph-based dependency parser (Kiperwasser and Goldberg, 2016) by incorporating a BiLSTM-based tagging component to produce automatically predicted POS tags for the <a href=https://en.wikipedia.org/wiki/Parsing>parser</a>. On the benchmark English Penn treebank, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> obtains strong UAS and LAS scores at 94.51 % and 92.87 %, respectively, producing 1.5+% absolute improvements to the BIST graph-based parser, and also obtaining a state-of-the-art POS tagging accuracy at 97.97 %. Furthermore, experimental results on parsing 61 big Universal Dependencies treebanks from raw texts show that our model outperforms the baseline UDPipe (Straka and Strakova, 2017) with 0.8 % higher average POS tagging score and 3.6 % higher average LAS score. In addition, with our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>, we also obtain state-of-the-art downstream task scores for biomedical event extraction and opinion analysis applications. Our code is available together with all pre-trained models at :<url>https://github.com/datquocnguyen/jPTDP</url>\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K18-2009.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K18-2009 data-toggle=collapse aria-expanded=false aria-controls=abstract-K18-2009 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K18-2009/>IBM Research at the CoNLL 2018 Shared Task on Multilingual Parsing<span class=acl-fixed-case>IBM</span> Research at the <span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>NLL</span> 2018 Shared Task on Multilingual Parsing</a></strong><br><a href=/people/h/hui-wan/>Hui Wan</a>
|
<a href=/people/t/tahira-naseem/>Tahira Naseem</a>
|
<a href=/people/y/young-suk-lee/>Young-Suk Lee</a>
|
<a href=/people/v/vittorio-castelli/>Vittorio Castelli</a>
|
<a href=/people/m/miguel-ballesteros/>Miguel Ballesteros</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K18-2009><div class="card-body p-3 small">This paper presents the IBM Research AI submission to the CoNLL 2018 Shared Task on Parsing Universal Dependencies. Our system implements a new joint transition-based parser, based on the Stack-LSTM framework and the Arc-Standard algorithm, that handles <a href=https://en.wikipedia.org/wiki/Lexical_analysis>tokenization</a>, <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tagging</a>, morphological tagging and dependency parsing in one single model. By leveraging a combination of character-based modeling of words and recursive composition of partially built linguistic structures we qualified 13th overall and 7th in low resource. We also present a new sentence segmentation neural architecture based on Stack-LSTMs that was the 4th best overall.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K18-2011.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K18-2011 data-toggle=collapse aria-expanded=false aria-controls=abstract-K18-2011 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K18-2011/>82 Treebanks, 34 Models : Universal Dependency Parsing with Multi-Treebank Models<span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependency Parsing with Multi-Treebank Models</a></strong><br><a href=/people/a/aaron-smith/>Aaron Smith</a>
|
<a href=/people/b/bernd-bohnet/>Bernd Bohnet</a>
|
<a href=/people/m/miryam-de-lhoneux/>Miryam de Lhoneux</a>
|
<a href=/people/j/joakim-nivre/>Joakim Nivre</a>
|
<a href=/people/y/yan-shao/>Yan Shao</a>
|
<a href=/people/s/sara-stymne/>Sara Stymne</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K18-2011><div class="card-body p-3 small">We present the Uppsala system for the CoNLL 2018 Shared Task on universal dependency parsing. Our system is a pipeline consisting of three components : the first performs joint word and sentence segmentation ; the second predicts <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tags</a> and <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphological features</a> ; the third predicts dependency trees from words and tags. Instead of training a single parsing model for each <a href=https://en.wikipedia.org/wiki/Treebank>treebank</a>, we trained <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> with multiple treebanks for one language or closely related languages, greatly reducing the number of <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a>. On the official test run, we ranked 7th of 27 teams for the LAS and MLAS metrics. Our system obtained the best scores overall for <a href=https://en.wikipedia.org/wiki/Word_segmentation>word segmentation</a>, universal POS tagging, and <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphological features</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K18-2012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K18-2012 data-toggle=collapse aria-expanded=false aria-controls=abstract-K18-2012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=K18-2012" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/K18-2012/>Tree-Stack LSTM in Transition Based Dependency Parsing<span class=acl-fixed-case>LSTM</span> in Transition Based Dependency Parsing</a></strong><br><a href=/people/o/omer-kirnap/>Ömer Kırnap</a>
|
<a href=/people/e/erenay-dayanik/>Erenay Dayanık</a>
|
<a href=/people/d/deniz-yuret/>Deniz Yuret</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K18-2012><div class="card-body p-3 small">We introduce tree-stack LSTM to model state of a transition based parser with <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural networks</a>. Tree-stack LSTM does not use any parse tree based or hand-crafted features, yet performs better than models with these features. We also develop new set of <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> from raw features to enhance the performance. There are 4 main components of this model : stack&#8217;s -LSTM, buffer&#8217;s -LSTM, actions&#8217; LSTM and tree-RNN. All <a href=https://en.wikipedia.org/wiki/Linear_time-invariant_system>LSTMs</a> use continuous dense feature vectors (embeddings) as an input. Tree-RNN updates these <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> based on transitions. We show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> improves performance with low resource languages compared with its predecessors. We participate in CoNLL 2018 UD Shared Task as the KParse team and ranked 16th in LAS, 15th in BLAS and BLEX metrics, of 27 participants parsing 82 test sets from 57 languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K18-2014.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K18-2014 data-toggle=collapse aria-expanded=false aria-controls=abstract-K18-2014 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=K18-2014" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/K18-2014/>SEx BiST : A Multi-Source Trainable Parser with Deep Contextualized Lexical Representations<span class=acl-fixed-case>SE</span>x <span class=acl-fixed-case>B</span>i<span class=acl-fixed-case>ST</span>: A Multi-Source Trainable Parser with Deep Contextualized Lexical Representations</a></strong><br><a href=/people/k/kyungtae-lim/>KyungTae Lim</a>
|
<a href=/people/c/cheoneum-park/>Cheoneum Park</a>
|
<a href=/people/c/changki-lee/>Changki Lee</a>
|
<a href=/people/t/thierry-poibeau/>Thierry Poibeau</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K18-2014><div class="card-body p-3 small">We describe the SEx BiST parser (Semantically EXtended Bi-LSTM parser) developed at Lattice for the CoNLL 2018 Shared Task (Multilingual Parsing from Raw Text to Universal Dependencies). The main characteristic of our work is the encoding of three different modes of contextual information for <a href=https://en.wikipedia.org/wiki/Parsing>parsing</a> : (i) Treebank feature representations, (ii) Multilingual word representations, (iii) ELMo representations obtained via <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised learning</a> from external resources. Our <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> performed well in the official end-to-end evaluation (73.02 LAS 4th/26 teams, and 78.72 UAS 2nd/26) ; remarkably, we achieved the best UAS scores on all the English corpora by applying the three suggested feature representations. Finally, we were also ranked 1st at the optional event extraction task, part of the 2018 Extrinsic Parser Evaluation campaign.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K18-2018.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K18-2018 data-toggle=collapse aria-expanded=false aria-controls=abstract-K18-2018 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=K18-2018" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/K18-2018/>Towards JointUD : <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>Part-of-speech Tagging</a> and <a href=https://en.wikipedia.org/wiki/Lemmatization>Lemmatization</a> using Recurrent Neural Networks<span class=acl-fixed-case>J</span>oint<span class=acl-fixed-case>UD</span>: Part-of-speech Tagging and Lemmatization using Recurrent Neural Networks</a></strong><br><a href=/people/g/gor-arakelyan/>Gor Arakelyan</a>
|
<a href=/people/k/karen-hambardzumyan/>Karen Hambardzumyan</a>
|
<a href=/people/h/hrant-khachatrian/>Hrant Khachatrian</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K18-2018><div class="card-body p-3 small">This paper describes our submission to CoNLL UD Shared Task 2018. We have extended an LSTM-based neural network designed for sequence tagging to additionally generate character-level sequences. The network was jointly trained to produce <a href=https://en.wikipedia.org/wiki/Lemma_(morphology)>lemmas</a>, <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>part-of-speech tags</a> and <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphological features</a>. Sentence segmentation, <a href=https://en.wikipedia.org/wiki/Lexical_analysis>tokenization</a> and <a href=https://en.wikipedia.org/wiki/Dependency_grammar>dependency parsing</a> were handled by UDPipe 1.2 baseline. The results demonstrate the viability of the proposed multitask architecture, although its performance still remains far from state-of-the-art.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K18-2019.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K18-2019 data-toggle=collapse aria-expanded=false aria-controls=abstract-K18-2019 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K18-2019/>CUNI x-ling : Parsing Under-Resourced Languages in CoNLL 2018 UD Shared Task<span class=acl-fixed-case>CUNI</span> x-ling: Parsing Under-Resourced Languages in <span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>NLL</span> 2018 <span class=acl-fixed-case>UD</span> Shared Task</a></strong><br><a href=/people/r/rudolf-rosa/>Rudolf Rosa</a>
|
<a href=/people/d/david-marecek/>David Mareček</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K18-2019><div class="card-body p-3 small">This is a system description paper for the CUNI x-ling submission to the CoNLL 2018 UD Shared Task. We focused on parsing under-resourced languages, with no or little training data available. We employed a wide range of approaches, including simple word-based treebank translation, combination of delexicalized parsers, and exploitation of available morphological dictionaries, with a dedicated setup tailored to each of the languages. In the official evaluation, our submission was identified as the clear winner of the Low-resource languages category.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K18-2021.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K18-2021 data-toggle=collapse aria-expanded=false aria-controls=abstract-K18-2021 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K18-2021/>Universal Morpho-Syntactic Parsing and the Contribution of Lexica : Analyzing the ONLP Lab Submission to the CoNLL 2018 Shared Task<span class=acl-fixed-case>ONLP</span> Lab Submission to the <span class=acl-fixed-case>C</span>o<span class=acl-fixed-case>NLL</span> 2018 Shared Task</a></strong><br><a href=/people/a/amit-seker/>Amit Seker</a>
|
<a href=/people/a/amir-more/>Amir More</a>
|
<a href=/people/r/reut-tsarfaty/>Reut Tsarfaty</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K18-2021><div class="card-body p-3 small">We present the contribution of the ONLP lab at the Open University of Israel to the UD shared task on multilingual parsing from raw text to Universal Dependencies. Our contribution is based on a transition-based parser called &#8216;yap yet another parser&#8217;, which includes a standalone morphological model, a standalone dependency model, and a joint morphosyntactic model. In the <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a> we used yap&#8216;s standalone dependency parser to parse input morphologically disambiguated by UDPipe, and obtained the official score of 58.35 LAS. In our follow up investigation we use yap to show how the incorporation of morphological and lexical resources may improve the performance of end-to-end raw-to-dependencies parsing in the case of a morphologically-rich and low-resource language, Modern <a href=https://en.wikipedia.org/wiki/Hebrew_language>Hebrew</a>. Our results on <a href=https://en.wikipedia.org/wiki/Hebrew_language>Hebrew</a> underscore the importance of CoNLL-UL, a UD-compatible standard for accessing external lexical resources, for enhancing end-to-end UD parsing, in particular for morphologically rich and low-resource languages. We thus encourage the community to create, convert, or make available more such lexica in future tasks.<i>yap</i>&#8216;s standalone dependency parser to parse input morphologically disambiguated by UDPipe, and obtained the official score of 58.35 LAS. In our follow up investigation we use yap to show how the incorporation of morphological and lexical resources may improve the performance of end-to-end raw-to-dependencies parsing in the case of a <i>morphologically-rich</i> and <i>low-resource</i> language, Modern Hebrew. Our results on Hebrew underscore the importance of CoNLL-UL, a UD-compatible standard for accessing external lexical resources, for enhancing end-to-end UD parsing, in particular for morphologically rich and low-resource languages. We thus encourage the community to create, convert, or make available more such lexica in future tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/K18-2023.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-K18-2023 data-toggle=collapse aria-expanded=false aria-controls=abstract-K18-2023 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/K18-2023/>ELMoLex : Connecting ELMo and Lexicon Features for Dependency Parsing<span class=acl-fixed-case>ELM</span>o<span class=acl-fixed-case>L</span>ex: Connecting <span class=acl-fixed-case>ELM</span>o and Lexicon Features for Dependency Parsing</a></strong><br><a href=/people/g/ganesh-jawahar/>Ganesh Jawahar</a>
|
<a href=/people/b/benjamin-muller/>Benjamin Muller</a>
|
<a href=/people/a/amal-fethi/>Amal Fethi</a>
|
<a href=/people/l/louis-martin/>Louis Martin</a>
|
<a href=/people/e/eric-villemonte-de-la-clergerie/>Éric Villemonte de la Clergerie</a>
|
<a href=/people/b/benoit-sagot/>Benoît Sagot</a>
|
<a href=/people/d/djame-seddah/>Djamé Seddah</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-K18-2023><div class="card-body p-3 small">In this paper, we present the details of the neural dependency parser and the neural tagger submitted by our team &#8216;ParisNLP&#8217; to the CoNLL 2018 Shared Task on parsing from raw text to Universal Dependencies. We augment the deep Biaffine (BiAF) parser (Dozat and Manning, 2016) with novel features to perform competitively : we utilize an indomain version of ELMo features (Peters et al., 2018) which provide context-dependent word representations ; we utilize disambiguated, embedded, morphosyntactic features from lexicons (Sagot, 2018), which complements the existing feature set. Henceforth, we call our <a href=https://en.wikipedia.org/wiki/System>system</a> &#8216;ELMoLex&#8217;. In addition to incorporating character embeddings, ELMoLex benefits from pre-trained word vectors, ELMo and morphosyntactic features (whenever available) to correctly handle rare or unknown words which are prevalent in languages with complex morphology. ELMoLex ranked 11th by Labeled Attachment Score metric (70.64 %), Morphology-aware LAS metric (55.74 %) and ranked 9th by Bilexical dependency metric (60.70 %).</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>