<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Proceedings of LT4HALA 2020 - 1st Workshop on Language Technologies for Historical and Ancient Languages - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Proceedings of LT4HALA 2020 - 1st Workshop on Language Technologies for Historical and Ancient Languages</h2><p class=lead><a href=/people/r/rachele-sprugnoli/>Rachele Sprugnoli</a>,
<a href=/people/m/marco-passarotti/>Marco Passarotti</a>
<span class=text-muted>(Editors)</span><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><dl><dt>Anthology ID:</dt><dd>2020.lt4hala-1</dd><dt>Month:</dt><dd>May</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Marseille, France</dd><dt>Venues:</dt><dd><a href=/venues/lrec/>LREC</a>
| <a href=/venues/lt4hala/>LT4HALA</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>European Language Resources Association (ELRA)</dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.lt4hala-1>https://aclanthology.org/2020.lt4hala-1</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bib Export formats:</dt><dd class=acl-button-row></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Proceedings+of+LT4HALA+2020+-+1st+Workshop+on+Language+Technologies+for+Historical+and+Ancient+Languages" title="Search for 'Proceedings of LT4HALA 2020 - 1st Workshop on Language Technologies for Historical and Ancient Languages' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a></div></div><hr><div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lt4hala-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lt4hala-1.0/>Proceedings of LT4HALA 2020 - 1st Workshop on Language Technologies for Historical and Ancient Languages</a></strong><br><a href=/people/r/rachele-sprugnoli/>Rachele Sprugnoli</a>
|
<a href=/people/m/marco-passarotti/>Marco Passarotti</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lt4hala-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lt4hala-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lt4hala-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lt4hala-1.6/>Using LatInfLexi for an Entropy-Based Assessment of Predictability in Latin Inflection<span class=acl-fixed-case>L</span>at<span class=acl-fixed-case>I</span>nf<span class=acl-fixed-case>L</span>exi for an Entropy-Based Assessment of Predictability in <span class=acl-fixed-case>L</span>atin Inflection</a></strong><br><a href=/people/m/matteo-pellegrini/>Matteo Pellegrini</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lt4hala-1--6><div class="card-body p-3 small">This paper presents LatInfLexi, a large inflected lexicon of Latin providing information on all the <a href=https://en.wikipedia.org/wiki/List_of_Latin-script_digraphs>inflected wordforms</a> of 3,348 verbs and 1,038 nouns. After a description of the structure of the resource and some data on its size, the procedure followed to obtain the lexicon from the database of the Lemlat 3.0 morphological analyzer is detailed, as well as the choices made regarding overabundant and defective cells. The way in which the data of LatInfLexi can be exploited in order to perform a quantitative assessment of predictability in Latin verb inflection is then illustrated : results obtained by computing the conditional entropy of guessing the content of a paradigm cell assuming knowledge of one wordform or multiple wordforms are presented in turn, highlighting the descriptive and theoretical relevance of the analysis. Lastly, the paper envisages the advantages of an inclusion of LatInfLexi into the LiLa knowledge base, both for the presented resource and for the knowledge base itself.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lt4hala-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lt4hala-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lt4hala-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.lt4hala-1.7" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.lt4hala-1.7/>A Tool for Facilitating OCR Postediting in Historical Documents<span class=acl-fixed-case>OCR</span> Postediting in Historical Documents</a></strong><br><a href=/people/a/alberto-poncelas/>Alberto Poncelas</a>
|
<a href=/people/m/mohammad-aboomar/>Mohammad Aboomar</a>
|
<a href=/people/j/jan-buts/>Jan Buts</a>
|
<a href=/people/j/james-hadley/>James Hadley</a>
|
<a href=/people/a/andy-way/>Andy Way</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lt4hala-1--7><div class="card-body p-3 small">Optical character recognition (OCR) for <a href=https://en.wikipedia.org/wiki/Historical_document>historical documents</a> is a complex procedure subject to a unique set of material issues, including inconsistencies in <a href=https://en.wikipedia.org/wiki/Typeface>typefaces</a> and low quality scanning. Consequently, even the most sophisticated <a href=https://en.wikipedia.org/wiki/Optical_character_recognition>OCR engines</a> produce errors. This paper reports on a tool built for postediting the output of Tesseract, more specifically for correcting common errors in digitized historical documents. The proposed <a href=https://en.wikipedia.org/wiki/Tool>tool</a> suggests alternatives for <a href=https://en.wikipedia.org/wiki/Linguistic_description>word forms</a> not found in a specified vocabulary. The assumed error is replaced by a presumably correct alternative in the post-edition based on the scores of a Language Model (LM). The <a href=https://en.wikipedia.org/wiki/Tool>tool</a> is tested on a chapter of the book An Essay Towards Regulating the Trade and Employing the Poor of this Kingdom (Cary, 1719). As demonstrated below, the <a href=https://en.wikipedia.org/wiki/Tool>tool</a> is successful in correcting a number of common errors. If sometimes unreliable, <a href=https://en.wikipedia.org/wiki/It_(2017_film)>it</a> is also transparent and subject to human intervention.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lt4hala-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lt4hala-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lt4hala-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lt4hala-1.10/>A Thesaurus for Biblical Hebrew<span class=acl-fixed-case>H</span>ebrew</a></strong><br><a href=/people/m/miriam-azar/>Miriam Azar</a>
|
<a href=/people/a/aliza-pahmer/>Aliza Pahmer</a>
|
<a href=/people/j/joshua-waxman/>Joshua Waxman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lt4hala-1--10><div class="card-body p-3 small">We built a thesaurus for <a href=https://en.wikipedia.org/wiki/Biblical_Hebrew>Biblical Hebrew</a>, with connections between roots based on phonetic, semantic, and distributional similarity. To this end, we apply established <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> to find connections between <a href=https://en.wikipedia.org/wiki/Headword>headwords</a> based on existing lexicons and other digital resources. For semantic similarity, we utilize the cosine-similarity of tf-idf vectors of English gloss text of Hebrew headwords from Ernest Klein&#8217;s A Comprehensive Etymological Dictionary of the Hebrew Language for Readers of English as well as to Brown-Driver-Brigg&#8217;s Hebrew Lexicon. For phonetic similarity, we digitize part of Matityahu Clark&#8217;s Etymological Dictionary of Biblical Hebrew, grouping Hebrew roots into phonemic classes, and establish phonetic relationships between headwords in Klein&#8217;s Dictionary. For distributional similarity, we consider the cosine similarity of PPMI vectors of Hebrew roots and also, in a somewhat novel approach, apply Word2Vec to a Biblical corpus reduced to its lexemes. The resulting resource is helpful to those trying to understand <a href=https://en.wikipedia.org/wiki/Biblical_Hebrew>Biblical Hebrew</a>, and also stands as a good basis for programs trying to process the Biblical text.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lt4hala-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lt4hala-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lt4hala-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.lt4hala-1.12" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.lt4hala-1.12/>Comparing Statistical and Neural Models for Learning Sound Correspondences</a></strong><br><a href=/people/c/clementine-fourrier/>Clémentine Fourrier</a>
|
<a href=/people/b/benoit-sagot/>Benoît Sagot</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lt4hala-1--12><div class="card-body p-3 small">Cognate prediction and proto-form reconstruction are key tasks in computational historical linguistics that rely on the study of sound change regularity. Solving these tasks appears to be very similar to <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, though methods from that field have barely been applied to <a href=https://en.wikipedia.org/wiki/Historical_linguistics>historical linguistics</a>. Therefore, in this paper, we investigate the learnability of sound correspondences between a proto-language and daughter languages for two machine-translation-inspired models, one statistical, the other neural. We first carry out our experiments on plausible artificial languages, without <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noise</a>, in order to study the role of each parameter on the algorithms respective performance under almost perfect conditions. We then study real languages, namely <a href=https://en.wikipedia.org/wiki/Latin>Latin</a>, <a href=https://en.wikipedia.org/wiki/Italian_language>Italian</a> and <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>, to see if those performances generalise well. We show that both model types manage to learn sound changes despite data scarcity, although the best performing model type depends on several parameters such as the size of the training data, the ambiguity, and the prediction direction.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lt4hala-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lt4hala-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lt4hala-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lt4hala-1.14/>Latin-Spanish Neural Machine Translation : from the Bible to Saint Augustine<span class=acl-fixed-case>L</span>atin-<span class=acl-fixed-case>S</span>panish Neural Machine Translation: from the <span class=acl-fixed-case>B</span>ible to Saint Augustine</a></strong><br><a href=/people/e/eva-martinez-garcia/>Eva Martínez Garcia</a>
|
<a href=/people/a/alvaro-garcia-tejedor/>Álvaro García Tejedor</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lt4hala-1--14><div class="card-body p-3 small">Although there are several sources where to find historical texts, they usually are available in the original language that makes them generally inaccessible. This paper presents the development of state-of-the-art Neural Machine Systems for the low-resourced Latin-Spanish language pair. First, we build a Transformer-based Machine Translation system on the Bible parallel corpus. Then, we build a comparable corpus from <a href=https://en.wikipedia.org/wiki/Augustine_of_Hippo>Saint Augustine texts</a> and their translations. We use this <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> to study the domain adaptation case from the <a href=https://en.wikipedia.org/wiki/Bible>Bible texts</a> to Saint Augustine&#8217;s works. Results show the difficulties of handling a low-resourced language as Latin. First, we noticed the importance of having enough data, since the <a href=https://en.wikipedia.org/wiki/System>systems</a> do not achieve high BLEU scores. Regarding <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a>, results show how using in-domain data helps <a href=https://en.wikipedia.org/wiki/System>systems</a> to achieve a better quality translation. Also, we observed that it is needed a higher amount of data to perform an effective vocabulary extension that includes in-domain vocabulary.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lt4hala-1.19.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lt4hala-1--19 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lt4hala-1.19 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lt4hala-1.19/>A Gradient Boosting-Seq2Seq System for Latin POS Tagging and <a href=https://en.wikipedia.org/wiki/Lemmatization>Lemmatization</a><span class=acl-fixed-case>S</span>eq2<span class=acl-fixed-case>S</span>eq System for <span class=acl-fixed-case>L</span>atin <span class=acl-fixed-case>POS</span> Tagging and Lemmatization</a></strong><br><a href=/people/g/giuseppe-g-a-celano/>Giuseppe G. A. Celano</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lt4hala-1--19><div class="card-body p-3 small">The paper presents the system used in the EvaLatin shared task to POS tag and lemmatize Latin. It consists of two components. A gradient boosting machine (LightGBM) is used for POS tagging, mainly fed with pre-computed word embeddings of a window of seven contiguous tokensthe token at hand plus the three preceding and following onesper target feature value. Word embeddings are trained on the texts of the <a href=https://en.wikipedia.org/wiki/Perseus_Digital_Library>Perseus Digital Library</a>, <a href=https://en.wikipedia.org/wiki/Patrologia_Latina>Patrologia Latina</a>, and Biblioteca Digitale di Testi Tardo Antichi, which together comprise a high number of texts of different genres from the Classical Age to Late Antiquity. Word forms plus the outputted POS labels are used to feed a seq2seq algorithm implemented in <a href=https://en.wikipedia.org/wiki/Keras>Keras</a> to predict lemmas. The final shared-task accuracies measured for Classical Latin texts are in line with state-of-the-art POS taggers (0.96) and lemmatizers (0.95).</div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>