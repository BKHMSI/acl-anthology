<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Countering hate on social media : Large scale classification of hate and counter speech - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="Countering hate on social media : Large scale classification of hate and counter speech" name=citation_title><meta content="Joshua Garland" name=citation_author><meta content="Keyan Ghazi-Zahedi" name=citation_author><meta content="Jean-Gabriel Young" name=citation_author><meta content="Laurent Hébert-Dufresne" name=citation_author><meta content="Mirta Galesic" name=citation_author><meta content="Proceedings of the Fourth Workshop on Online Abuse and Harms" name=citation_conference_title><meta content="2020/11" name=citation_publication_date><meta content="https://aclanthology.org/2020.alw-1.13.pdf" name=citation_pdf_url><meta content="102" name=citation_firstpage><meta content="112" name=citation_lastpage><meta content="10.18653/v1/2020.alw-1.13" name=citation_doi><meta property="og:title" content="Countering hate on social media : Large scale classification of hate and counter speech"><meta property="og:image" content="https://aclanthology.org/thumb/2020.alw-1.13.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2020.alw-1.13"><meta property="og:description" content="Joshua Garland, Keyan Ghazi-Zahedi, Jean-Gabriel Young, Laurent Hébert-Dufresne, Mirta Galesic. Proceedings of the Fourth Workshop on Online Abuse and Harms. 2020."><link rel=canonical href=https://aclanthology.org/2020.alw-1.13></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2020.alw-1.13.pdf>Countering hate on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> : Large scale classification of hate and counter speech</a>
<a id=af_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Tel haat op sosiale media: Groot skaal klasifikasie van haat en teenwoord</a>
<a id=am_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>በማኅበራዊ ሚዲያ ላይ ጥላትን እየቆጣጠር፣ ጥላቻን እና ቃላትን የሚቃወም ትልቅ ክፍል</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>مكافحة الكراهية على وسائل التواصل الاجتماعي: تصنيف واسع النطاق للكراهية والخطاب المضاد</a>
<a id=az_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Sosyal medialarda nifrəti saymaq: Büyük ölçüdə nifrət və danışmaq</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Противодействие на омразата в социалните медии: мащабна класификация на омразата и контраречта</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>সামাজিক প্রচার মাধ্যমে ঘৃণা হিসেবে: ঘৃণা এবং বিরোধী বক্তৃতার ব্যাপারে বিশাল পরিমাণ বিভাগ</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>སྤྱི་ཚོགས་འབྲེལ་མཐུད་དྲ་ཐོག་ཏུ་བརྩོན་དགོས་པ་ཞིག་ལས། ཕྱིར་ཉེན་དང་ཁ་བརྗོད་བྱེད་པའི་ཚད་ཆེ་བའི་</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Brojanje mržnje na društvenim medijima: Velika klasifikacija mržnje i protivnog govora</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Contra l'odi als mitjans socials: Una gran classificació de l'odi i el contradiscurs</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Proti nenávisti na sociálních médiích: klasifikace nenávisti a protiřeči ve velkém měřítku</a>
<a id=da_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Bekæmpelse af had på sociale medier: Storskalig klassificering af had og modtale</a>
<a id=de_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Hassbekämpfung in sozialen Medien: Große Klassifizierung von Hass und Gegenrede</a>
<a id=el_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Αντιμετώπιση του μίσους στα μέσα κοινωνικής δικτύωσης: Μεγάλη κλίμακα ταξινόμηση του μίσους και της αντι-ομιλίας</a>
<a id=es_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Lucha contra el odio en las redes sociales: clasificación a gran escala del odio y el discurso contrario</a>
<a id=et_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Vihkamise vastu võitlemine sotsiaalmeedias: viha ja vastukõne laiaulatuslik klassifikatsioon</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>مقدار نفرت در رسانه‌های اجتماعی: کل‌سازی بزرگ از نفرت و سخنرانی مخالف</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Vihan torjuminen sosiaalisessa mediassa: Vihan ja vastapuheen laajamittainen luokitus</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Lutter contre la haine sur les réseaux sociaux : classification à grande échelle de la haine et du contre-discours</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Dul i ngleic le fuath ar na meáin shóisialta: Aicmiú mórscála ar fhuath agus ar fhrithchaint</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Ana ƙaddara ƙiyayi a kan mitandai masu jamii: Large scale classified of hatsi and anti-hoto</a>
<a id=he_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>נגד שנאה בתקשורת חברתית: קליזציה גדולה של שנאה ונגד נאום</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>सोशल मीडिया पर नफरत का मुकाबला करना: नफरत और काउंटर भाषण का बड़े पैमाने पर वर्गीकरण</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Brojanje mržnje na društvenim medijima: Velika klasifikacija mržnje i protivnog govora</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>A gyűlölet elleni küzdelem a közösségi médiában: a gyűlölet és a beszéd elleni küzdelem nagyszabású besorolása</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Սոցիալական լրատվամիջոցների ատելության դեմ: ատելության և հակախոսքի մեծ դասակարգման</a>
<a id=id_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Melawan kebencian di media sosial: Klasifikasi skala besar kebencian dan pembicaraan melawan</a>
<a id=is_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Contro l'odio sui social media: classificazione su larga scala dell'odio e contro il discorso</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>ソーシャルメディアでのヘイトスピーチ対策：ヘイトスピーチとカウンタースピーチの大規模な分類</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>to</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>სოციალური მედიაში მპატის წინასწორება: დიდი მაგალითი კლასიფიკაცია მპატის და წინასწორების წინასწორება</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Социалдық медиақтардың қарсы қарсы: Үлкен масштабы қарсы және қарсы сөйлесу</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>소셜 미디어에서의 반증오: 증오와 반언론의 대규모 분류</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Kova su neapykanta socialinėje žiniasklaidoje: didelė neapykantos ir priešingos kalbos klasifikacija</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Борбата против омразата на социјалните медиуми: Голема класификација на омразата и против говорот</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>സോഷ്യല്‍ മീഡിയയില്‍ വെറുപ്പ് കണക്കാക്കുന്നു:</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Нийгмийн мэдээллийн хэрэглэгчдийн үзэн ядуурлыг тооцоолж байна: Хөрийллийн, эсрэг ярианы том хэлбэр</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Countering hate on social media: Large scale classification of hate and counter speech</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Il-ġlieda kontra l-mibegħda fuq il-midja soċjali: Klassifikazzjoni fuq skala kbira tal-mibegħda u kontra d-diskors</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Haat tegengaan op sociale media: Grootschalige classificatie van haat en tegenspraak</a>
<a id=no_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Telling av hatt på sosiale media: Stor skala klassifisering av hatt og mottale</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Przeciwdziałanie nienawiści w mediach społecznościowych: klasyfikacja nienawiści na dużą skalę i przeciw mowie</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Combatendo o ódio nas mídias sociais: classificação em larga escala de ódio e contra-discurso</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Combaterea ura pe rețelele sociale: clasificarea la scară largă a urăi și a discursului de combatere</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Противодействие ненависти в социальных сетях: крупномасштабная классификация ненависти и контрречи</a>
<a id=si_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>සාමාජික මාධ්‍යමයේ විරෝධ විශ්වාස කරනවා: ලොකු ප්‍රමාණයේ විරෝධ විශේෂණය සහ විරෝ</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Proti sovraštvu na družbenih omrežjih: obsežna klasifikacija sovraštva in nasprotnega govora</a>
<a id=so_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Cadhada nacayb ku saabsan shabakada bulshada: fasaxa aad u weyn ee nacayb iyo hadal ka gees ah</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Kundërshtimi i urrejtjes në mediat shoqërore: Klasifikimi i madh i urrejtjes dhe kundër fjalimit</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Brojanje mržnje na društvenim medijima: Velika klasifikacija mržnje i protivnog govora</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Att motverka hat på sociala medier: Storskalig klassificering av hat och mottal</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Kuhesabu chuki kwenye mitandao ya kijamii: kutanganisha kwa kiwango kikubwa cha chuki na hotuba ya kupinga</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>சமூக ஊடகங்களில் வெறுப்பு எண்ணிக்கை</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Sosyal medýdançasynda ýigrenýänlik sany: Ullakan ýigrenýänlik we çykyş</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>سوسیلی میڈیا میں دشمنی کا شمار کرنا: دشمنی اور مخالف بات کا بڑا مقدار</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Jamiyat media'da kuchni hisoblashni hisoblash: kuch va diqqat fikrlarining katta darajada</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>Chống lại thù hận trên truyền thông xã hội: Đánh giá quy mô lớn của thù hận và phản phát biểu</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2020.alw-1.13.pdf>在社交媒体抗仇,大类反言</a></h2><p class=lead><a href=/people/j/joshua-garland/>Joshua Garland</a>,
<a href=/people/k/keyan-ghazi-zahedi/>Keyan Ghazi-Zahedi</a>,
<a href=/people/j/jean-gabriel-young/>Jean-Gabriel Young</a>,
<a href=/people/l/laurent-hebert-dufresne/>Laurent Hébert-Dufresne</a>,
<a href=/people/m/mirta-galesic/>Mirta Galesic</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Hateful rhetoric is plaguing <a href=https://en.wikipedia.org/wiki/Online_discourse>online discourse</a>, fostering <a href=https://en.wikipedia.org/wiki/Extremism>extreme societal movements</a> and possibly giving rise to <a href=https://en.wikipedia.org/wiki/Violence>real-world violence</a>. A potential solution to this growing global problem is citizen-generated counter speech where citizens actively engage with <a href=https://en.wikipedia.org/wiki/Hate_speech>hate speech</a> to restore <a href=https://en.wikipedia.org/wiki/Civil_discourse>civil non-polarized discourse</a>. However, its actual effectiveness in curbing the spread of <a href=https://en.wikipedia.org/wiki/Hatred>hatred</a> is unknown and hard to quantify. One major obstacle to researching this question is a lack of large labeled data sets for training <a href=https://en.wikipedia.org/wiki/Statistical_classification>automated classifiers</a> to identify counter speech. Here we use a unique situation in <a href=https://en.wikipedia.org/wiki/Germany>Germany</a> where self-labeling groups engaged in organized online hate and counter speech. We use an ensemble learning algorithm which pairs a variety of paragraph embeddings with regularized logistic regression functions to classify both hate and counter speech in a corpus of millions of relevant tweets from these two groups. Our <a href=https://en.wikipedia.org/wiki/Pipeline_(software)>pipeline</a> achieves macro F1 scores on out of sample balanced test sets ranging from 0.76 to 0.97accuracy in line and even exceeding the state of the art. We then use the classifier to discover hate and counter speech in more than 135,000 fully-resolved Twitter conversations occurring from 2013 to 2018 and study their frequency and interaction. Altogether, our results highlight the potential of automated methods to evaluate the impact of coordinated counter speech in stabilizing conversations on <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nogtige retoriek is om online diskursie te plaas, uitermende samelewing te versterk en moontlik die verhoog van reël-wêreld geweld te bring. 'n Potansieële oplossing vir hierdie groei globale probleem is by die burgers gegenereer teenwoord waar die burgers aktief met haatspraat verwerp om siviele nie-polariseerde diskursie te herstel. Maar sy werklike effektiviteit in die uitbreiding van haat is onbekende en moeilik om te kvantifikaat. Een groot hinders om hierdie vraag te hersien is 'n ontbreek van groot gemerkte data stel vir ontoefening outomatiese klassifiseerders om teenwoord te identifiseer. Hier gebruik ons 'n unieke situasie in Duitsland waar self-etiketting groepe in die organiseerde online haat en teenspreek is. Ons gebruik 'n ensemble leer algoritme wat paar 'n verskillende paragraaf inbettings met regulariseerde logistike regresie funksies om beide haat en teenwoord in 'n korpus van miljoene relevante tweete van hierdie twee groepe te klassifiseer. Ons pyperlyn bereik makro F1 telling op uit voorbeeld balanse toets stel vanaf 0. 76 tot 0. 97- presies in lyn en selfs oorskyn die staat van die kuns. Ons gebruik dan die klassifiseerder om haat en teenwoord te ontdek in meer as 135,000 volledig opgelos Twitter gesprekke wat van 2013 tot 2018 voorkom en hulle frekwensie en interaksie ondersoek. Totaal, ons resultate verlig die potensiale van outomatiese metodes om die effek van koordineerde teenspraak te evalueer in die stabiliseering van gesprekke op sosiale media.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ጠማማ ንግግር በመስመር ውይይት ላይ ነው፤ እጅግ ብዙ ማኅበራዊ እንቅስቃሴን ለማድረግ እና እውነተኛ ዓለምን ግጭት ማድረግ ይችላል፡፡ ይህ በዓለምአቀፍ መከራ የሚነካው መልስ የዜጎች ተቃዋሚ ንግግር ሲሆን ዜጎች በጥል ንግግር ለመመለስ የሲቪል ያልpolarized ንግግር ለመመለስ የሚችል ነው፡፡ ነገር ግን የጥል ስፋትን ለመቀላቀል የእውነቱ ፍቃድ ሳይታወቅ እና ማሰናከል ጭንቅ ነው፡፡ ይህንን ጥያቄ ለመመርመርመር የሚችል አንዲት መግለጫ የአካባቢ ንግግርን ለማግኘት በራሳቸው ተሳካሪዎችን ለማስተምር የዳታ ማሰናከል ነው፡፡ ወደዚህ በጀርመን የራሳቸውን የጥል እና የተቃውሞ ንግግር የተጋጠሙትን የፖለቲካ ጉባኤ እና የውይይት ግንኙነት እንጠይቃለን፡፡ ጥላቻን እና ቃላትን በመሊዮን ሚሊዮን በተቃውሞ ትዊተሮች በቆርፓስ እና በሚያነሳው የፖለቲካ አካባቢ አግሪትምን እናስማራለን፡፡ Our pipeline achieves macro F1 scores on out of sample balanced test sets ranging from 0.76 to 0.97-accuracy in line and even exceeding the state of the art. ከዚያም በኋላ ጥላቻን እና ተቃዋሚውን ንግግር ለማግኘት እናስጠጋለን፤ ከ2013 ጀምሮ እስከ 2018 ድረስ የኢትዮጵያውያን ንግግር ከ135 ሺህ በላይ የተፈጸመ ትዊተር ውይይት እና ፍጥረታቸውን እናስተምር፡፡ በተጨማሪም፣ ፍሬዎቻችን በማኅበራዊ አውታር ላይ የተቃውሞ ቋንቋን ለማስተካከል የሥልጣን ሥልጣናዎችን በማስተካከል ያስችላል፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>إن خطاب الكراهية يصيب الخطاب على الإنترنت ، ويعزز الحركات المجتمعية المتطرفة ، وربما يؤدي إلى العنف في العالم الحقيقي. يتمثل أحد الحلول المحتملة لهذه المشكلة العالمية المتنامية في الخطاب المضاد الذي يولده المواطنون حيث ينخرط المواطنون بنشاط في خطاب الكراهية لاستعادة الخطاب المدني غير المستقطب. ومع ذلك ، فإن فعاليتها الفعلية في الحد من انتشار الكراهية غير معروفة ويصعب تحديدها. تتمثل إحدى العقبات الرئيسية أمام البحث في هذا السؤال في الافتقار إلى مجموعات بيانات معنونة كبيرة لتدريب المصنفين الآليين لتحديد الكلام المضاد. هنا نستخدم وضعًا فريدًا في ألمانيا حيث تنخرط المجموعات ذاتية التصنيف في خطاب كراهية وخطاب مضاد منظم عبر الإنترنت. نحن نستخدم خوارزمية التعلم الجماعي التي تجمع بين مجموعة متنوعة من حفلات الزفاف مع وظائف الانحدار اللوجستي المنظم لتصنيف كل من الكراهية والخطاب المضاد في مجموعة من ملايين التغريدات ذات الصلة من هاتين المجموعتين. يحقق خط الأنابيب لدينا درجات F1 الكلية على مجموعات اختبار متوازنة خارج العينة تتراوح من 0.76 إلى 0.97 - دقة في الخط وحتى تتجاوز أحدث ما توصلت إليه التقنية. ثم نستخدم المصنف لاكتشاف الكراهية والخطاب المضاد في أكثر من 135000 محادثة على Twitter تم حلها بالكامل من 2013 إلى 2018 ودراسة تكرارها وتفاعلها. إجمالاً ، تسلط نتائجنا الضوء على إمكانات الأساليب الآلية لتقييم تأثير الخطاب المضاد المنسق في استقرار المحادثات على وسائل التواصل الاجتماعي.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nefqətli sözlər onlayn sözlərini dağıtmaq, aşırı sosyal hərəkətləri artırmaq və mümkün olaraq həqiqət dünya şiddətinə yetişdirmək. Bu qlobal problemin müvəffəqiyyəti artırmağı mümkün bir çətinlikdir ki, vatandaşlar təşkil edilmiş mübahisədir. Şeytanlar nifrət sözləri sivil təşkil edilməmiş mübahisədən geri qaytarmaq üçün istifadə edirlər. Halbuki, nifrətin yayılmasını qadağan etmək əslində əsl etkinlik bilinməz və hesablamaq çətindir. Bu soruşmayı təhsil etmək üçün böyük bir səbəb - müxtəlif sözləri təhsil etmək üçün otomatik klasifikatorların təhsil edilməsi üçün böyük etiketli məlumat qurğuları yoxdur. Burada özlərini etiketləndirmək qruplarının online nifrəti və çəkinməsi barəsində təhsil edilən təhsil olaraq Alemaniyada istifadə edirik. Biz bu iki dəstədən milyonlarca mövcud tweet-lərlə birlikdə nifrət və danışmaq üçün müxtəlif parçalanmış rəngresiya funksiyaları ilə birlikdə olan ensemble öyrənmə algoritmi kullanırıq. Bizim bor çubuğumuz nümunə çəkilən sınama çubuqlarından makro F1 nöqtəsini 0,76-dən 0,97-dən düzəldir və hətta sanatın durumundan aşırır. Sonra 2013-dən 2018-dən daha çox çəkilən Twitter danışmalarında nifrəti və danışmağı öyrənmək üçün seçimləri istifadə edirik. Əlbəttə, sonuçlarımız sosyal media danışmalarını stabilizaşdırmaq üçün koordinatlı danışma təsirlərinin təsirini müəyyən etmək üçün avtomatik metodların potensialini aydınlaşdırır.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Омразената реторика тормози онлайн дискурса, насърчава екстремни обществени движения и вероятно води до насилие в реалния свят. Потенциално решение на този нарастващ глобален проблем е генерираната от гражданите контрареч, в която гражданите активно се ангажират с речта на омразата, за да възстановят гражданския неполяризиран дискурс. Въпреки това, действителната му ефективност в ограничаването на разпространението на омразата е неизвестна и трудно се определя количествено. Една от основните пречки за проучването на този въпрос е липсата на големи маркирани набори от данни за обучение на автоматизирани класификатори за идентифициране на контраречта. Тук използваме уникална ситуация в Германия, където самоетикетиращи се групи се занимават с организирана онлайн омраза и контрареч. Използваме алгоритъм за обучение на ансамбъл, който съчетава различни вграждания на абзаци с регламентирани логистични регресионни функции, за да класифицираме както омразата, така и контраречта в корпус от милиони релевантни туитове от тези две групи. Нашият тръбопровод постига макро резултати от балансирани тестови комплекти, вариращи от 0,76 до 0,97-точност в линията и дори надвишаващи най-новите технологии. След това използваме класификатора, за да открием омразата и контраречта в повече от 135 000 напълно решени разговори в Туитър, които се случват от 2013 до 2018 г., и да изучаваме тяхната честота и взаимодействие. Като цяло нашите резултати подчертават потенциала на автоматизираните методи за оценка на въздействието на координираната контрареч в стабилизирането на разговорите в социалните медии.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>বিরক্তিকর বৃত্তান্ত অনলাইনে কথোপকথন প্রকাশ করছে, অত্যন্ত সামাজিক আন্দোলন উৎপাদন করছে এবং সম্ভবত বাস্তবতা বিশ্বের সহিংসতার কারণ A potential solution to this growing global problem is citizen-generated counter speech where citizens actively engage with hate speech to restore civil non-polarized discourse. তবে ঘৃণার ছড়িয়ে দেওয়ার প্রকৃত কার্যক্রম অজানা এবং পরিমাপের জন্য কঠিন। এই প্রশ্ন গবেষণার একটি প্রধান বাধা হচ্ছে বিশাল লেবেলেড ডাটা সেটের অভাব, স্বয়ংক্রিয়ভাবে প্রশিক্ষণ করার জন্য প্রশিক্ষণের জন্ এখানে আমরা জার্মানীতে এক বিশেষ পরিস্থিতি ব্যবহার করি যেখানে নিজেদের লেবেলিং গ্রুপ সংগঠিত অনলাইনের ঘৃণা এবং বি এই দুই দলের কোর্পাস থেকে হাজার লক্ষ লক্ষ টুইটের মাধ্যমে ঘৃণা এবং বিরোধী বক্তৃতাকে বিভিন্ন বিভিন্ন প্যারাফ বিভিন্ন বিভিন্ন ক্ষেত্রে জোড়ায়। আমাদের পাইপেলাইন ম্যাক্রো এফ১ স্কোর অর্জন করেছে নমুনাল পরীক্ষার সেট থেকে ০. তারপর আমরা ব্যবহার করি তাদের ঘৃণা এবং বিরোধী বক্তৃতা আবিষ্কার করতে এবং ২০১৩ সাল থেকে ২০১৮ সাল থেকে পুরোপুরি সমাধানের টুইটারের কথোপকথন আবিষ এছাড়াও, আমাদের ফলাফল সামাজিক প্রচার মাধ্যমে কথোপকথন স্থির করার জন্য স্বয়ংক্রিয় পদ্ধতির সম্ভাবনা তুলে ধরেছে।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>རེ་བཞིན་མཁན་གྱི་གཟུགས་སྐོར་ནི་དྲ་རྒྱའི་ཁ་བརྡ་སྤྲོད་དང་། སྤྱི་ཚོགས་འབྲེལ་གྱི་གནས་སྟངས་ཁྱབ་པར་མཐུན་རྐྱེན་སྤྲོད་ཡོད། རྒྱལ་ཁབ་ཀྱི་དཀའ ཡིན་ནའང་། དེའི་ལས་སྡུག་གྱིས་དགའ་ཕྱུར་འགྲོས་ཀྱིས་བདེ་སྐྱིད་པ་ཞིག་འཇུག་རྒྱུ་མ་རེད། One major obstacle to researching this question is a lack of large labeled data sets for training automated classifiers to identify counter speech. འདིར་ང་ཚོས་རང་ཉིད་ཀྱི་མིང་རྟགས་བཀོད་པའི་སྐབས་སུ་དབུལ་གྱི་གནས་སྟངས་གཅིག་སྤྱོད་ཀྱི་ཡོད། We use an ensemble learning algorithm which pairs a variety of paragraph embeddings with regularized logistic regression functions to classify both hate and counter speech in a corpus of millions of relevant tweets from these two groups. The following two groups are: Our pipeline achieves macro F1 scores on out of sample balanced test sets ranging from 0.76 to 0.97-accuracy in line and even exceeding the state of the art. འོན་ཀྱང་། ང་ཚོས་དབྱེ་བ་འདིའི་ནང་དུ་དབྱིན་དགའ་ཕྱོགས་དང་གདོང་གཏད་པ་ཞིག་བཙུགས་རྒྱུ་ཙམ་བྱེད་ཀྱི་ཡོད། འཇིག་རྟེན། ང་ཚོའི་གྲུབ་འབྲས་གྱིས་རང་འགུལ་གྱིས་ཐབས་ལམ་གཙོ་བ་ཡོད་པ་དེ་གིས་སྤྱི་ཚོགས་འབྲེལ་མཐུད་གྱི་གཏམ་གླེང</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nežna retorika je uključivanje online diskursa, poticanje ekstremnih društvenih pokreta i vjerojatno povećanje nasilja u stvarnom svijetu. Potencijalno rješenje ovog rastućeg globalnog problema je protivni govor iz građana u kojem građani aktivno uključuju govor mržnje kako bi obnovili građanski nepolizirani govor. Međutim, njena stvarna učinkovitost u ometanju širenja mržnje je nepoznata i teško je kvantificirati. Jedna velika prepreka istraživanja ovog pitanja je nedostatak velikih označenih podataka za obuku automatskih klasifikatora da identifikuju kontragovor. Ovdje koristimo jedinstvenu situaciju u Njemačkoj gdje su grupe samoznačivanja uključene u organiziranu online mržnju i protivnu govor. Koristimo algoritam za učenje ensemble koji pare razne paragrafske integracije sa regulariziranim funkcijama logističke regresije kako bi klasifikovali mržnju i protivnu govor u korpusu milijuna relevantnih tweeta iz te dve grupe. Naša cijevina postiže makro F1 rezultate iz balanciranih testova uzoraka od 0,76 do 0,97 tačnosti u liniji i čak preko stanja umjetnosti. Potom koristimo klasifikatora da otkrijemo mržnju i protivni govor u više od 135.000 potpuno rešenih Twitter razgovora koji se događaju od 2013. do 2018. i proučavamo njihovu frekvenciju i interakciju. Uglavnom, naši rezultati naglašavaju potencijal automatskih metoda za procjenu utjecaja koordiniranog protivnog govora u stabilizaciji razgovora na društvenim medijima.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>La retòrica odiosa està plagant el discurs on-line, fomentant moviments socials extrems i possiblement donant lloc a la violència del món real. Una solució potencial a aquest problema mundial creixent és el contradiscurs generat pels ciutadans on els ciutadans es dediquen activament al discurs d'odi per restaurar el discurs civil no polaritzat. No obstant això, la seva efectivitat real en limitar la propagació de l'odi és desconeguda i difícil de quantificar. One major obstacle to researching this question is a lack of large labeled data sets for training automated classifiers to identify counter speech. Aquí utilitzem una situació única a Alemanya on grups d'auto-etiquetadors involucrats en odi organitzat en línia i contra-discurs. Utilitzem un algoritme d'aprenentatge conjunt que parell una varietat d'incorporacions de paràgrafs amb funcions de regressió logística regularitzada per classificar tant l'odi com la contradicció en un cos de milions de tweets pertinents d'aquests dos grups. Our pipeline achieves macro F1 scores on out of sample balanced test sets ranging from 0.76 to 0.97-accuracy in line and even exceeding the state of the art. Després utilitzem el classificador per descobrir odi i contraparlar en més de 135.000 converses completament resoldues a Twitter que ocorren del 2013 al 2018 i estudiar la seva freqüència i interacció. En conjunt, els nostres resultats destaquen el potencial de mètodes automatitzats per avaluar l'impacte de la contradicció coordinada en estabilitar les converses en els mitjans socials.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nenávistná rétorika trápí on-line diskurz, podporuje extrémní společenská hnutí a možná vede k násilí v reálném světě. Potenciálním řešením tohoto rostoucího globálního problému je protiřeč generovaný občanem, kde se občané aktivně zapojují do nenávistné řeči, aby obnovili občanský nepolarizovaný diskurs. Jeho skutečná účinnost při potlačení šíření nenávisti však není známá a těžko se kvantifikuje. Jednou z hlavních překážek výzkumu této otázky je nedostatek velkých označených datových sad pro výcvik automatizovaných klasifikátorů k identifikaci protiřeči. Zde využíváme unikátní situaci v Německu, kdy se samoznačující skupiny zabývající se organizovanou online nenávistí a protiřečí. Používáme algoritmus učení souborů, který kombinuje různé vkládání odstavců s regularizovanými logistickými regresními funkcemi pro klasifikaci nenávisti i protiřeči do korpusu milionů relevantních tweetů z těchto dvou skupin. Naše potrubí dosahuje makro F1 skóre u mimo vzorek vyvážených testovacích sad v rozsahu od 0,76 až 0,97-přesnosti v řadě a dokonce překračuje stav techniky. Poté používáme klasifikátor k odhalení nenávisti a protiřeči ve více než 135.000 plně rozlišených Twitterových konverzacích probíhajících od 2013 do 2018 a studování jejich frekvence a interakce. Celkově naše výsledky zdůrazňují potenciál automatizovaných metod hodnocení vlivu koordinovaného protiřeči na stabilizaci konverzací na sociálních médiích.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Hadefuld retorik plager online diskurs, fremmer ekstreme samfundsmæssige bevægelser og muligvis giver anledning til vold i den virkelige verden. En potentiel løsning på dette voksende globale problem er borgernes modtale, hvor borgerne aktivt engagerer sig i had tale for at genoprette civil ikke-polariseret diskurs. Men dens faktiske effektivitet med hensyn til at bremse spredningen af had er ukendt og svær at kvantificere. En stor hindring for undersøgelsen af dette spørgsmål er manglen på store mærkede datasæt til uddannelse af automatiserede klassificerere til at identificere modtale. Her bruger vi en unik situation i Tyskland, hvor selvmærkende grupper engagerer sig i organiseret online had og modtale. Vi bruger en ensemble læringsalgoritme, der parrer en række afsnitsindlejringer med regulerede logistiske regressionsfunktioner til at klassificere både had og modtale i et korpus af millioner af relevante tweets fra disse to grupper. Vores pipeline opnår makro F1-scorer på prøvebalancerede testsæt, der spænder fra 0,76 til 0,97-nøjagtighed i linje og endda overskrider den nyeste teknologi. Vi bruger derefter klassificeringen til at opdage had og modtale tale i mere end 135.000 fuldt løste Twitter samtaler, der finder sted fra 2013 til 2018, og undersøge deres hyppighed og interaktion. Alt i alt fremhæver vores resultater potentialet i automatiserede metoder til at evaluere effekten af koordineret modtale i stabilisering af samtaler på sociale medier.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Hassvolle Rhetorik plagt den Online-Diskurs, fördert extreme gesellschaftliche Bewegungen und führt möglicherweise zu realer Gewalt. Eine mögliche Lösung für dieses wachsende globale Problem ist bürgergenerierte Gegenrede, bei der sich Bürger aktiv mit Hassreden auseinandersetzen, um zivilen, nicht polarisierten Diskurs wiederherzustellen. Seine tatsächliche Wirksamkeit bei der Eindämmung der Ausbreitung von Hass ist jedoch unbekannt und schwer zu quantifizieren. Ein großes Hindernis für die Erforschung dieser Frage ist der Mangel an großen markierten Datensätzen für die Schulung automatisierter Klassifikatoren zur Identifizierung von Gegensprachen. Hier nutzen wir eine einzigartige Situation in Deutschland, in der Selbstkennzeichnungsgruppen organisierte Online-Hass- und Gegenreden betreiben. Wir verwenden einen Ensemble-Lernalgorithmus, der eine Vielzahl von Absatzeinbettungen mit regularisierten logistischen Regressionsfunktionen kombiniert, um Hass- und Gegenreden in einem Korpus von Millionen relevanter Tweets dieser beiden Gruppen zu klassifizieren. Unsere Pipeline erzielt Makro-F1-Scores auf nicht sample balanced Testsets, die von 0,76 bis 0,97-Genauigkeit in der Linie reichen und sogar den Stand der Technik übertreffen. Anschließend verwenden wir den Klassifikator, um Hass und Gegenreden in mehr als 135.000 vollständig aufgelösten Twitter-Unterhaltungen von 2013 bis 2018 zu entdecken und deren Häufigkeit und Interaktion zu untersuchen. Insgesamt verdeutlichen unsere Ergebnisse das Potenzial automatisierter Methoden, den Einfluss koordinierter Gegenrede auf die Stabilisierung von Gesprächen in sozialen Medien zu bewerten.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Η ρητορική μίσους μαστίζει τον διαδικτυακό διάλογο, προωθεί ακραία κοινωνικά κινήματα και ενδεχομένως προκαλεί πραγματική βία. Μια πιθανή λύση σε αυτό το αυξανόμενο παγκόσμιο πρόβλημα είναι η αντι-ομιλία που δημιουργείται από τους πολίτες, όπου οι πολίτες ασχολούνται ενεργά με τη ρητορική μίσους για να αποκαταστήσουν τον πολιτικό μη πολωμένο λόγο. Ωστόσο, η πραγματική αποτελεσματικότητά του στην καταπολέμηση της εξάπλωσης του μίσους είναι άγνωστη και δύσκολο να ποσοτικοποιηθεί. Ένα σημαντικό εμπόδιο στην έρευνα αυτού του ερωτήματος είναι η έλλειψη μεγάλων ετικετών συνόλων δεδομένων για την εκπαίδευση αυτοματοποιημένων ταξινομητών για τον προσδιορισμό της αντίστροφης ομιλίας. Εδώ χρησιμοποιούμε μια μοναδική κατάσταση στη Γερμανία όπου αυτομαρκαριστικές ομάδες εμπλέκονται σε οργανωμένο διαδικτυακό μίσος και αντίθετη ομιλία. Χρησιμοποιούμε έναν αλγόριθμο εκμάθησης συνόλων που συνδυάζει μια ποικιλία ενσωμάτωσης παραγράφου με κανονικές λειτουργίες λογιστικής παλινδρόμησης για να ταξινομήσουμε τόσο το μίσος όσο και την αντίθετη ομιλία σε ένα σώμα εκατομμυρίων σχετικών tweets από αυτές τις δύο ομάδες. Ο αγωγός μας επιτυγχάνει μακροχρόνιες βαθμολογίες σε εκτός δείγματος ισορροπημένα σύνολα δοκιμών που κυμαίνονται από 0.76 έως 0.97-ακρίβεια στη γραμμή και ακόμη και υπερβαίνουν την κατάσταση της τεχνολογίας. Στη συνέχεια, χρησιμοποιούμε τον ταξινομητή για να ανακαλύψουμε το μίσος και την αντίθετη ομιλία σε περισσότερες από 135.000 πλήρως επιλυμένες συνομιλίες στο Twitter που συμβαίνουν από 2013 έως 2018 και να μελετήσουμε τη συχνότητα και την αλληλεπίδρασή τους. Συνολικά, τα αποτελέσματά μας αναδεικνύουν τις δυνατότητες των αυτοματοποιημένων μεθόδων για την αξιολόγηση του αντίκτυπου της συντονισμένης αντιπαράθεσης ομιλίας στη σταθεροποίηση των συνομιλιών στα μέσα κοινωνικής δικτύωσης.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>La retórica odiosa está plagando el discurso en línea, fomentando movimientos sociales extremos y posiblemente dando lugar a la violencia en el mundo real. Una posible solución a este creciente problema mundial es el discurso contrario generado por los ciudadanos, en el que los ciudadanos se comprometen activamente con el discurso de odio para restaurar el discurso civil no polarizado. Sin embargo, se desconoce su eficacia real para frenar la propagación del odio y es difícil de cuantificar. Un obstáculo importante para investigar esta cuestión es la falta de grandes conjuntos de datos etiquetados para capacitar a los clasificadores automatizados para identificar el discurso contrario. Aquí utilizamos una situación única en Alemania, donde los grupos de autoetiquetado participaban en actividades organizadas en línea de odio y contra discurso. Utilizamos un algoritmo de aprendizaje conjunto que combina una variedad de inserciones de párrafos con funciones regularizadas de regresión logística para clasificar tanto el odio como el discurso contrario en un corpus de millones de tuits relevantes de estos dos grupos. Nuestro canal logra puntuaciones F1 macro en conjuntos de pruebas balanceadas fuera de la muestra que van de 0.76 a 0.97, precisión en la línea e incluso superior al estado de la técnica. Luego, utilizamos el clasificador para descubrir el odio y el discurso contrario en más de 135 000 conversaciones de Twitter totalmente resueltas que tuvieron lugar entre 2013 y 2018 y estudiamos su frecuencia e interacción. En conjunto, nuestros resultados destacan el potencial de los métodos automatizados para evaluar el impacto del contradiscurso coordinado en la estabilización de las conversaciones en las redes sociales.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vihkamine retoorika vaevab internetidiskursust, edendab äärmuslikke ühiskondlikke liikumisi ja võib-olla põhjustab reaalset vägivalda. Võimalikuks lahenduseks sellele kasvavale globaalsele probleemile on kodanike tekitatud vastukõne, kus kodanikud tegelevad aktiivselt vihakõnega, et taastada kodanikuühiskonna mittepolariseeritud diskursus. Kuid selle tegelik tõhusus vihkamise leviku piiramisel on teadmata ja seda on raske kvantifitseerida. Üks peamine takistus selle küsimuse uurimisel on suurte märgistatud andmekogumite puudumine automatiseeritud klassifitseerijate koolitamiseks vastukõne tuvastamiseks. Siin kasutame ainulaadset olukorda Saksamaal, kus isemärgistavad rühmad tegelevad organiseeritud online viha- ja vastukõnedega. Kasutame ansambli õppealgoritmi, mis ühendab erinevaid lõigupõimimisi regulaarsete logistiliste regressioonifunktsioonidega, et klassifitseerida nii viha- kui ka vastukõne miljonitest nende kahe rühma asjakohastest säutsudest koosnevasse korpusesse. Meie torustik saavutab makro F1 skoorid valimi tasakaalustatud testikomplektide puhul, mis ulatuvad 0,76 kuni 0,97 täpsusega joonel ja isegi ületavad tehnika taseme. Seejärel kasutame klassifitseerijat viha- ja vastukõne avastamiseks enam kui 135 000 täielikult lahendatud Twitteri vestluses ajavahemikul 2013–2018 ning nende sageduse ja suhtluse uurimiseks. Kokkuvõttes rõhutavad meie tulemused automatiseeritud meetodite potentsiaali hinnata koordineeritud vastukõne mõju sotsiaalmeedias peetavate vestluste stabiliseerimisel.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>سخنرانی ناخوشایند در آنلاین سخنرانی می‌کند، به وسیله حرکت جامعه‌های زیادی و احتمالا به خشونت دنیای واقعی رشد می‌دهد. یک راه حل محتمل برای این مشکل جهانی رشد کردن، سخنرانی مخالف از شهروندان است که شهروندان فعالی با سخنرانی از نفرت برای بازگرداندن سخنرانی غیر قطعه‌ای شهروندان در کار دارند. با این حال، فعالیت واقعی آن در کاهش گسترش نفرت ناشناخته و مقداری سخت است. یک obstacle بزرگی برای تحقیق این سوال این است که کمی از مجموعه‌های اطلاعات بزرگ‌ترین نقاشی برای آموزش گروه‌های خودکار برای شناسایی سخنرانی مخالف است. در اینجا از موقعیت متفاوتی در آلمان استفاده می کنیم که گروهی که خود برگزار می کنند در مورد تنفر و سخنرانی مخالف آنلاین سازمان می شوند. ما از آلگوریتم یادگیری از آلگوریتم‌های فرانسوی استفاده می‌کنیم که در جفت‌های مختلف پاراگرافی با عملکرد بازگشت لوژیک‌های معمولی به عنوان کلاس‌گذاری از نفرت و سخنرانی مخالف در یک جفت میلیون‌ها از tweets متعلق از این دو گروه است. خط لوله ما امتحان مکرو F1 را از طریق نمونه‌های مقایسه‌ای از 0.76 تا 0.97 دقیق خط می‌رساند و حتی بیشتر از وضعیت هنر است. سپس از محرمانه استفاده می کنیم تا از ۲۰۱۳ تا ۲۰۱۸ نفرت و سخنرانی مخالف را در بیشتر از ۲۰۱۳ هزار صحبت توئیتر کامل حل کنیم و فرکانس و تعامل آنها را مطالعه کنیم. در کل، نتیجه‌هایمان پتانسیل روش‌های خودکار را برای ارزیابی تاثیر سخنرانی‌های مخالفت‌سازی در استوار‌سازی گفتگو در رسانه‌های اجتماعی مشخص می‌کند.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Vihanhimoinen retoriikka piinaa verkkokeskustelua, edistää äärimmäisiä yhteiskunnallisia liikkeitä ja mahdollisesti aiheuttaa todellista väkivaltaa. Mahdollinen ratkaisu tähän kasvavaan globaaliin ongelmaan on kansalaisten tuottama vastapuhe, jossa kansalaiset sitoutuvat aktiivisesti vihapuheeseen palauttaakseen kansalaisen polarisoitumattoman keskustelun. Sen tosiasiallinen tehokkuus vihan leviämisen hillitsemisessä on kuitenkin tuntematonta ja sitä on vaikea mitata määrällisesti. Yksi merkittävä este tämän kysymyksen tutkimiselle on suurten merkittyjen tietokokonaisuuksien puute automaattisten luokittelijoiden kouluttamiseksi vastapuheen tunnistamiseksi. Tässä käytämme ainutlaatuista tilannetta Saksassa, jossa itseleimaavat ryhmät osallistuivat järjestäytyneeseen viha- ja vastapuheeseen verkossa. Käytämme ensemble-oppimisalgoritmia, joka yhdistää erilaisia kappaleiden upotuksia säännöllisiin logistisiin regressiofunktioihin luokitellaksemme sekä viha- että vastapuheen miljoonien relevanttien tweettien korpuseen näistä kahdesta ryhmästä. Putkistomme saavuttaa makro F1 -pisteet näytteiden tasapainotetuista testisarjoista, jotka vaihtelevat 0,76–0,97-tarkkuudella linjassa ja jopa ylittävät uusimman tekniikan. Tämän jälkeen käytämme luokittelijaa löytääksemme viha- ja vastapuheen yli 135 000 täysin ratkaistussa Twitter-keskustelussa vuosina 2013–2018 ja tutkiaksemme niiden taajuutta ja vuorovaikutusta. Kaiken kaikkiaan tulokset korostavat automatisoitujen menetelmien mahdollisuuksia arvioida koordinoidun vastapuheen vaikutusta sosiaalisen median keskustelujen vakauttamiseen.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>La rhétorique haineuse empoisonne le discours en ligne, favorise des mouvements sociétaux extrêmes et peut même donner lieu à de la violence dans le monde réel. Une solution potentielle à ce problème mondial croissant est le contre-discours généré par les citoyens, dans lequel les citoyens s'engagent activement dans des discours de haine afin de rétablir un discours civil non polarisé. Cependant, son efficacité réelle pour freiner la propagation de la haine est inconnue et difficile à quantifier. L'un des principaux obstacles à la recherche de cette question est le manque de grands ensembles de données étiquetés pour entraîner les classificateurs automatisés à identifier les contre-discours. Nous utilisons ici une situation unique en Allemagne où des groupes auto-étiquetés se sont engagés dans des discours de haine et de contre-discours organisés en ligne. Nous utilisons un algorithme d'apprentissage d'ensemble qui associe une variété d'intégrations de paragraphes à des fonctions de régression logistique régularisées afin de classer à la fois le discours haineux et le contre-discours dans un corpus de millions de tweets pertinents provenant de ces deux groupes. Notre pipeline obtient des scores macro F1 sur des ensembles de tests équilibrés hors échantillon allant de 0,76 à 0,97, une précision en ligne et même supérieure à l'état de la technique. Nous utilisons ensuite le classificateur pour découvrir la haine et le contre-discours dans plus de 135 000 conversations Twitter entièrement résolues entre 2013 et 2018 et pour étudier leur fréquence et leur interaction. Dans l'ensemble, nos résultats mettent en évidence le potentiel des méthodes automatisées pour évaluer l'impact du contre-discours coordonné sur la stabilisation des conversations sur les réseaux sociaux.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tá reitric ghránna ag cur as do dhioscúrsa ar líne, ag cothú gluaiseachtaí foircneacha sochaíocha agus b’fhéidir ina gcúis le foréigean sa saol fíor. Réiteach féideartha ar an bhfadhb dhomhanda seo atá ag dul i méid is ea frithchaint a ghintear leis na saoránaigh ina mbíonn saoránaigh i ngleic go gníomhach le fuathchaint chun dioscúrsa sibhialta neamhpholachaithe a athbhunú. Mar sin féin, ní fios a éifeachtúlacht iarbhír chun srian a chur le scaipeadh an fhuath agus tá sé deacair a thomhas. Constaic mhór amháin le taighde a dhéanamh ar an gceist seo is ea an easpa tacair shonraí lipéadaithe mhóra chun aicmitheoirí uathoibrithe a thraenáil chun frithchaint a aithint. Bainimid úsáid anseo as cás uathúil sa Ghearmáin ina raibh grúpaí féinlipéadaithe i mbun fuatha agus frithchaint eagraithe ar líne. Bainimid úsáid as algartam foghlama ensemble a phéireálann éagsúlacht de leabú ailt le feidhmeanna aischéimniúcháin lóistíochta rialta chun fuath agus frithchaint a rangú i gcorpas na milliún tweets ábhartha ón dá ghrúpa seo. Baineann ár bpíblíne scóir mhacra F1 amach ar thacair thrialacha chothromaithe eiseamláireacha idir 0.76 agus 0.97 - cruinneas ar aon dul agus fiú níos mó ná an úrscothacht. Úsáidimid an t-aicmitheoir ansin chun fuath agus frithchaint a fháil amach i níos mó ná 135,000 comhrá lán-réiteach Twitter a tharla ó 2013 go 2018 agus déanaimid staidéar ar a minicíocht agus ar a n-idirghníomhaíocht. San iomlán, leagann ár dtorthaí béim ar an bpoitéinseal a bhaineann le modhanna uathoibrithe chun tionchar na frithchainteanna comhordaithe i gcobhsú comhráite ar na meáin shóisialta a mheas.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Haka'ani na ƙyãma yana fassara magana masu shagala, kuma yana ƙara haramta masu kami da jamii na yiwuwa ta ƙara a kan tunza-duniya halinsa. Jami'a mai yiwuwa ga wannan masu ƙara a cikin duniya, shi ne ma'abũta-wanda aka haife shi da magana na motsi, inda mutane ke yin husũma da magana na ƙi dõmin su kõma magana na sihirin da ba'a suriyar da shi ba. A lokacin da yake da amfani a kan curbinta firi-ƙeta ba'a sani ba kuma yana kasancẽwa mai ƙunci ga iya ƙaddara. Babu mai girma ga yin fitina na kan wannan tambayi yana da haske da tsari mai girma wa data na fasahan farat ɗaya dõmin su gane magana na motsi. A nan, munã amfani da wani halin wanda ke so a cikin Jajeriya, a inda jama'a masu samun mutane da suka yi jiyya da takaki na danganta a bakin Online. Tuna amfani da algoritin da za'a karanta algoritm wanda ke fito da wasu misãlai na rubutu masu da functionin tarajiya na daɗa ɗaɗayya dõmin ya rarraba tsakanin hatsi da baka magana a cikin makampin millions na mutane daga waɗannan ƙungiya biyu. Pilinmu ya sãmu macro F1 score daga matsayin jarrabo masu daidaita samfani mai tsawo tsawo daga 0.76 zuwa 0.97 tsari cikin linje da kuma kõ mafi ƙaranci halin sanar. Sa'an nan kuma muna amfani da mai fassarwa dõmin mu gane hoton ƙiyayya da motsi a cikin wasu hotunan da suka samu 135,000 da aka cika rabo na Twitter daga 2013 zuwa 2018 kuma mu karanta fomat da kashfiyarsu. Kayya, matsalayinmu na ƙayyade ikon hanyõyin farat ɗaya dõmin su evaluate haske ta'a ga muhimmin hoton da ke da haɗuwa da shi a cikin tabbatar mazaɓa a kan mitandata jamii.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>רטוריקה שונאת מגעילה דיבור באינטרנט, עודדת תנועות חברתיות קיצוניות ואולי נותנת מקום לאלימות בעולם האמיתי. פתרון פוטנציאלי לבעיה הגלובלית הגדולה הזו הוא נאום נגד יוצר ע"י אזרחים שבו אזרחים מתעסקים באופן פעיל עם נאום שנאה כדי לשחזר דיבור אזרחי לא פולאריז. עם זאת, היעילות האמיתית שלה בכדי למנוע את התפשטות השנאה אינה ידועה וקשה להכיר. מכשול גדול אחד לחקור את השאלה הזאת הוא חוסר קבוצות מידע גדולות עם תווים לאימון מסווגים אוטומטיים לזהות נאום נגד. Here we use a unique situation in Germany where self-labeling groups engaged in organized online hate and counter speech. אנו משתמשים באלגוריתם ללמוד אנסמבל שזווים מגוון של פרסמים עם תפקידים רגרסיונים לוגיסטיים קבועים כדי לקlassifiק גם שנאה וגם נאום נגד בקורפוס של מיליוני טוויטים רלוונטיים משני הקבוצות האלה. צינור שלנו משיג נקודות מקרו F1 על מחוץ למבחנים מאוזנים של דגימות מגוונים מ 0.76 עד 0.97 בדיקת בשורה ואפילו מעבר למצב האמנות. ואז אנו משתמשים בכיתון כדי לגלות שנאה ונאום נגד נאום ב יותר מ-135,000 שיחות טוויטר פתרונות לחלוטין שמתרחשות בין 2013 ל-2018 וללמד את התדר והאינטראקציה שלהם. ביחד, התוצאות שלנו מזכירות את הפוטנציאל של שיטות אוטומטיות כדי להעריך את ההשפעה של נאום נגד מתאים</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>घृणित बयानबाजी ऑनलाइन प्रवचन को परेशान कर रही है, चरम सामाजिक आंदोलनों को बढ़ावा दे रही है और संभवतः वास्तविक दुनिया की हिंसा को जन्म दे रही है। इस बढ़ती वैश्विक समस्या का एक संभावित समाधान नागरिक-जनित काउंटर भाषण है जहां नागरिक नागरिक गैर-ध्रुवीकृत प्रवचन को बहाल करने के लिए सक्रिय रूप से घृणा स्पीच के साथ संलग्न होते हैं। हालांकि, नफरत के प्रसार को रोकने में इसकी वास्तविक प्रभावशीलता अज्ञात और मात्रा निर्धारित करना मुश्किल है। इस प्रश्न पर शोध करने के लिए एक प्रमुख बाधा काउंटर भाषण की पहचान करने के लिए स्वचालित क्लासिफायरों के प्रशिक्षण के लिए बड़े लेबल वाले डेटा सेट की कमी है। यहां हम जर्मनी में एक अनूठी स्थिति का उपयोग करते हैं जहां स्व-लेबलिंग समूह संगठित ऑनलाइन नफरत और काउंटर भाषण में लगे हुए हैं। हम एक पहनावा सीखने एल्गोरिथ्म का उपयोग करते हैं जो इन दो समूहों से लाखों प्रासंगिक ट्वीट्स के कॉर्पस में नफरत और काउंटर भाषण दोनों को वर्गीकृत करने के लिए नियमित रसद प्रतिगमन कार्यों के साथ विभिन्न प्रकार के पैराग्राफ एम्बेडिंग जोड़ता है। हमारी पाइपलाइन 0.76 से 0.97 तक के नमूने के संतुलित परीक्षण सेटों में से मैक्रो एफ 1 स्कोर प्राप्त करती है- लाइन में सटीकता और यहां तक कि कला की स्थिति से अधिक भी। फिर हम 2013 से 2018 तक होने वाली 135,000 से अधिक पूरी तरह से हल की गई ट्विटर वार्तालापों में नफरत और काउंटर भाषण की खोज करने और उनकी आवृत्ति और बातचीत का अध्ययन करने के लिए क्लासिफायर का उपयोग करते हैं। कुल मिलाकर, हमारे परिणाम सोशल मीडिया पर बातचीत को स्थिर करने में समन्वित काउंटर भाषण के प्रभाव का मूल्यांकन करने के लिए स्वचालित तरीकों की क्षमता को उजागर करते हैं।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nežna retorika prikazuje internetske diskursije, poticava ekstremne društvene pokrete i vjerojatno povećava nasilje u stvarnom svijetu. Potencijalno rješenje ovog rastućeg globalnog problema je protivni govor iz građana koji se građani aktivno uključuju s govorom mržnje kako bi obnovili građanski nepolizirani govor. Međutim, njena stvarna učinkovitost u ometanju širenja mržnje je nepoznata i teško je kvantificirati. Jedan od velikih prepreka istraživanja ovog pitanja je nedostatak velikih označenih podataka za obuku automatskih klasifikatora za identifikaciju kontragovora. Ovdje koristimo jedinstvenu situaciju u Njemačkoj gdje su grupe samoznačivanja uključene u organiziranu online mržnju i protivnu govor. Koristimo algoritam za učenje ensemble koji pare različite uloge paragrafa sa regulariziranim funkcijama logističke regresije kako bi klasifikirali mržnju i protivnu govor u korpusu milijuna relevantnih tweeta iz te dvije grupe. Naša cijevina postiže makro F1 rezultate iz balanciranih testova uzoraka od 0,76 do 0,97 tačnosti u liniji i čak i preko stanja umjetnosti. Potom koristimo klasifikatora da otkrijemo mržnju i protivni govor u više od 135.000 potpuno rješenih Twitter razgovora koji se događaju od 2013. do 2018. i proučavamo njihovu frekvenciju i interakciju. Uglavnom, naši rezultati naglašavaju potencijal automatskih metoda za procjenu utjecaja koordiniranog protivnog govora u stabilizaciji razgovora na društvenim medijima.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A gyűlöletes retorika sújtja az online diskurzust, támogatja a szélsőséges társadalmi mozgalmakat és valószínűleg valós erőszakot okoz. E növekvő globális probléma potenciális megoldása a polgárok által generált ellenbeszéd, ahol a polgárok aktívan részt vesznek a gyűlöletbeszédben, hogy helyreállítsák a civil, nem polarizált diskurzust. Azonban a gyűlölet terjedésének visszaszorításában való tényleges hatékonysága nem ismert és nehéz számszerűsíteni. A kérdés kutatásának egyik fő akadálya az, hogy hiányzik a nagyméretű címkézett adatkészletek, amelyek az automatizált osztályozók képzésére szolgálnak az ellenbeszéd azonosítására. Itt egy egyedülálló helyzetet használunk Németországban, ahol az öncímkéző csoportok szervezett online gyűlölet- és ellenbeszédet folytatnak. Egy olyan együttes tanulási algoritmust használunk, amely különböző bekezdésbeágyazásokat és szabályozott logisztikai regressziós függvényeket párosít, hogy mind a gyűlölet, mind az ellenbeszéd besorolását e két csoport több millió releváns tweetjében osztályozzuk. Csővezetékünk makró F1 pontszámokat ér el a mintán kívül kiegyensúlyozott tesztkészletek 0,76 és 0,97 közötti pontossággal vonalban, sőt, meghaladja a legkorszerűbb technológiát. Ezután az osztályozót használjuk, hogy felfedezzük a gyűlölet és a beszéd elleni beszédet több mint 135 000 teljesen feloldott Twitter beszélgetésben 2013 és 2018 között, és tanulmányozzuk azok gyakoriságát és interakcióját. Eredményeink összességében rávilágítanak az automatizált módszerekben rejlő lehetőségekre, amelyek értékelik a koordinált beszéd hatását a közösségi médiában folytatott beszélgetések stabilizálásában.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Վատելի ռետորիկան առցանց խոսակցությունն է, խրախուսում է ծայրահեղ հասարակության շարժումները և հավանաբար հանգեցնում է իրական աշխարհի բռնության: Այս աճող համաշխարհային խնդրի պոտենցիալ լուծումը քաղաքացիների կողմից ստեղծված հակախոսակցությունն է, որտեղ քաղաքացիները ակտիվ ներգրավվում են ատելության խոսակցությամբ, որպեսզի վերականգնեն քաղաքացիական Այնուամենայնիվ, ատելության տարածման սահմանափակ արդյունավետությունը անհայտ է և դժվար է չափել: Այս հարցի ուսումնասիրելու հիմնական խոչընդոտը մեծ պիտակուցված տվյալների բացակայությունն է, որպեսզի ավտոմատիկ դասավորողները սովորեցնեն հակառակ խոսքի հայտնաբերելու համար: Այստեղ մենք օգտագործում ենք գերմանիայում յուրահատուկ իրավիճակ, որտեղ ինքնապիտակ խմբերը, որոնք գործում են կազմակերպված առցանց ատելության և հակառակ խոսքի մեջ: We use an ensemble learning algorithm which pairs a variety of paragraph embeddings with regularized logistic regression functions to classify both hate and counter speech in a corpus of millions of relevant tweets from these two groups. Մեր խողովակաշարը ստանում է մակրո F1 գնահատականներ նմուշների հավասարակշռությունից, որոնք տարբերվում են 0.76-ից մինչև 0.97 ճշգրտությունից և նույնիսկ գերազանցությունից: Այնուհետև մենք օգտագործում ենք դասակարգիչը ատելության և հակառակ խոսքի հայտնաբերելու համար ավելի քան 135,000 լիովին լուծված Թվիթերի զրույցներում, որոնք տեղի են ունենում 2013-2018 թվականներից, ուսումնասիրելու համար նրանց հաճախականությունը և փոխազդեցությունը: Ընդհանուր առմամբ, մեր արդյունքները ներկայացնում են ավտոմատիկ մեթոդների պոտենցիալը, որպեսզի գնահատենք կոորդինացված հակառակ խոսքի ազդեցությունը հասարակական լրատվամիջոցների վրա հակառակցված խոսակցու</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Retorik benci merusak pidato online, mendukung gerakan masyarakat ekstrim dan mungkin menyebabkan kekerasan dunia nyata. Sebuah solusi potensial untuk masalah global yang tumbuh ini adalah pidato yang dihasilkan oleh warga negara di mana warga negara aktif terlibat dengan pidato kebencian untuk mengembalikan pidato sipil yang tidak polarizasi. Namun, efektifitas sebenarnya dalam mengurangi penyebaran kebencian tidak diketahui dan sulit untuk dikwantifikasi. One major obstacle to researching this question is a lack of large labeled data sets for training automated classifiers to identify counter speech. Di sini kita menggunakan situasi unik di Jerman di mana kelompok self-labeling terlibat dalam organisasi kebencian online dan pembicaraan balas. Kami menggunakan algoritma pembelajaran ensemble yang memperpasangkan berbagai jenis penerbangan paragraf dengan fungsi regresi logistik yang regularised untuk mengklasifikasi baik kebencian maupun pembicaraan melawan dalam sebuah korpus jutaan tweet relevan dari dua kelompok ini. Pipeline kita mencapai skor makro F1 dari set tes yang seimbang sampel yang berlangsung dari 0,76 hingga 0,97-akurasi dalam baris dan bahkan melebihi keadaan seni. Kemudian kami menggunakan klasifikasi untuk menemukan kebencian dan pembicaraan melawan dalam lebih dari 135.000 percakapan Twitter yang sepenuhnya selesai yang terjadi dari 2013 sampai 2018 dan mempelajari frekuensi dan interaksi mereka. Bersama-sama, hasil kita menunjukkan potensi dari metode otomatis untuk mengevaluasi dampak dari kata-kata yang koordinasi dalam stabilisasi konversasi di media sosial.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>La retorica odiosa sta affliggendo il discorso online, promuovendo movimenti sociali estremi e forse dando luogo alla violenza nel mondo reale. Una potenziale soluzione a questo crescente problema globale è il controdiscorso generato dai cittadini in cui i cittadini si impegnano attivamente con discorsi di odio per ripristinare il discorso civile non polarizzato. Tuttavia, la sua effettiva efficacia nel frenare la diffusione dell'odio è sconosciuta e difficile da quantificare. Uno dei principali ostacoli alla ricerca di questa domanda è la mancanza di grandi set di dati etichettati per formare i classificatori automatici per identificare il counter speech. Qui usiamo una situazione unica in Germania in cui gruppi di auto-etichettatura impegnati in odio e contro discorsi organizzati online. Usiamo un algoritmo di apprendimento ensemble che associa una varietà di incorporazioni di paragrafi con funzioni di regressione logistica regolarizzate per classificare sia l'odio che il controdiscorso in un corpus di milioni di tweet pertinenti di questi due gruppi. La nostra pipeline raggiunge punteggi macro F1 su set di test bilanciati fuori campione che vanno da 0,76 a 0,97-precisione in linea e persino superando lo stato dell'arte. Usiamo quindi il classificatore per scoprire l'odio e contrastare il discorso in più di 135.000 conversazioni Twitter completamente risolte che si verificano dal 2013 al 2018 e studiarne la frequenza e l'interazione. Complessivamente, i nostri risultati evidenziano le potenzialità dei metodi automatizzati per valutare l'impatto del controdiscorso coordinato nella stabilizzazione delle conversazioni sui social media.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>憎悪に満ちた言説は、オンライン上の議論を悩ませ、極端な社会運動を助長し、現実の暴力を引き起こす可能性があります。 この増大する世界的な問題に対する潜在的な解決策は、市民が積極的にヘイトスピーチに関与して市民の非分極的な言説を回復する市民生成のカウンタースピーチです。 しかし、憎悪の広がりを抑制するための実際の効果は不明であり、数値化することは困難である。 この質問を研究するための大きな障害の1つは、カウンタースピーチを識別するための自動分類子をトレーニングするための大きなラベル付けされたデータセットの欠如です。 ここでは、ドイツで組織的なオンラインヘイトスピーチやカウンタースピーチに従事するセルフラベル団体が独自の状況を使用しています。 私たちは、様々な段落埋め込みと正規化されたロジスティック回帰関数をペアにして、これらの2つのグループからの数百万の関連するツイートのコーパスでヘイトスピーチとカウンタースピーチの両方を分類するアンサンブル学習アルゴリズムを使用しています。 当社のパイプラインは、サンプルバランス試験セットのマクロF 1スコアを0.76から0.97の範囲で達成し、最先端の精度を超えています。 その後、分類子を使用して、2013年から2018年にかけて発生した135,000件を超える完全に解決されたTwitterの会話でヘイトスピーチとカウンタースピーチを発見し、その頻度と相互作用を調査します。 総じて、当社の結果は、ソーシャルメディア上の会話を安定させるための協調的なカウンタースピーチの影響を評価するための自動化された方法の可能性を強調しています。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Lah Panjenengan langgar kuwi nglanggar tarjamahan liyane, nglanggar ijol-ijolan sing paling maneh lan ijol-ijolan sing mengko iso nggawe gerakan kanggo ngilanggar barang langgar uwong. Apa bener sing perusahaan kanggo nggawe perusahaan iki ning acara nik sabên kelas nguasai perusahaan winih sing dirangkat sabên gerakan kanggo nguasai perusahaan kuwi mau. politenessoffpolite"), and when there is a change ("assertivepoliteness politenessoffpolite"), and when there is a change ("assertivepoliteness Mungkin awak dhéwé ngerasakno sing nyelehake ning alam kuwi nggawe gerakan kelas nang ngerasakno dumadhi lan nganggep kuwi mau. Awak dhéwé éntukno Algorithm sing beraksi kanggo ngilanggar alih podho dipun nguasakno Taning Awak dhéwé éntuk kelas nang ingkang nggawe kesalakno karo pawaran ugih-pukan karo pertualangan kanggo tah-pukan sing katêpakan maning, pertualangan kanggo tah-pukan sing katêpakan karo 2013 lan 2008. Laha luwih-luwih, ditambahak dhéwé nggawe perusahaan sistem sing otomatik kanggo nggawe barang nggawe barang nggawe barang nggawe gerakan kanggo ngilangno komunikasi sotiki.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ბედნიერი რეტორიკა ინტერნეტიური დისკურსების შესაძლებელობა, საზოგადოებო მოძრაობა და შესაძლებელია რეალური მსოფლიოს ძალადობას. ეს გლობალური პრობლემის პრობლემის პრობლემის პრობლემის პრობლემის პრობლემის შესაძლებელი პრობლემენტია, რომელიც ადამიანები აქტიურად მპატიური საუბლემი მაგრამ, მისი რეალური ეფექტიურობა წარმოადგენისთვის წარმოადგენისთვის უცნობილი და ძალიან კვანტიფიკაცია. ამ კითხვის შესახებ ერთი მნიშვნელოვანი გახსნა არის დიდი მონაცემების კოლეფიკაციების შესახებ ავტომატურებული კლასიფიკაციების განათვისება. აქ ჩვენ ვიყენებთ განსხვავებული სიტუაციაში გერმანეთში, სადაც თავისუფლიო სიტუაციის ჯგუფები, რომელიც ორგანიზაციული ინტერნეტიური მპატი და ჩვენ გამოყენებთ ანსენმბლური სწავლების ალგორიტიმ, რომელიც ამ ორი ჯგუფიდან მილიონის შესახებ შესახებ განსხვავებული პრაგრაფიკური რეგრესიის ფუნქციების განსხვავებას, რომელიც განსხვავებული პრაგრაფიკური ჩვენი ფეხლინი მიღებს მაკრო F1 მონაცემების გადასრულებული ტესტის ნაცემების ნაცემები 0,76-დან 0,97 წერტილიდან და უფრო უფრო უფრო უფრო მეტია. შემდეგ ჩვენ კლასიფიკაციას გამოყენებთ, რომ განვიხოვოთ მპატი და კონტაქტი საუკეთესო საუკეთესო საუკეთესო საუკეთესო საუკეთესო საუკეთესო საუკეთეს ყველაფერი, ჩვენი შედეგი აღწერა ავტომატიკური მეტების პროცენტის შესახებ, რომელიც კონტაქტირებული კონტაქტიური საუკეთესო მუშაობაში სოციალური მედი</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Реторика онлайн дискурстарын жасау, әлемдік жылжытуларды көтеру және шын әлемдік қамтамасына көтеру мүмкін. Бұл әлемдік мәселеге мүмкіндік шешім - қатынас құрылған қарсы сөйлесу - қатынасдар қарсы сөйлесу үшін қатынасыз сөйлесу үшін қатынасыз сөйлесу үшін қатынасыз сөйлесу. Бірақ оның шындық әсер етілігі жетістіктерін өзгерту үшін беймәлім және есептеу үшін қатты. Бұл сұрақты зерттеу үшін бір негізгі бұл, автоматты классификацияларды оқыту үшін, қарсы сөздерді анықтау үшін үлкен деректер жиындары жоқ. Мұнда біз Германияда бірнеше жағдай қолданып, онлайн жетілдірілген жетістік және қарсы сөйлейтін топтар қолданып тұрмыз. Біз бұл екі топтардың миллиондардың қасиетті tweets корпусында қарсылық және қарсылық сөйлейтін алгоритмді бір түрлі ақпарат ендіру алгоритмін қолданамыз. Қызықтық F1 макро нәтижелерін 0,76- ден 0,97- ден жұлдыздың дұрыстығынан және олардың күйінен артық болады. Содан кейін біз классификациясын жек және қарсы сөйлесу үшін 135 000 жылдан артық Твиттердің сөйлесуді 2013 жылдан 2018 жылдан кейін табу үшін қолданып, олардың жиілігін және қатынасын зерттеу үші Барлық нәтижелеріміз, әлеуметтік медиақтардың сөйлесуді тәуелдеу үшін координативті сөйлесудің нәтижесін бағалау мүмкіндігін автоматты түрде көрсетеді.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>원한 언론은 인터넷 언론을 괴롭히고 극단적인 사회운동을 조장하며 현실 세계의 폭력을 유발할 수 있다.날로 심각해지는 전 세계 문제를 해결하는 잠재적인 방법은 공민이 발생하는 반언론, 즉 공민이 증오언론에 적극적으로 참여하여 공민의 비극화된 언어를 회복하는 것이다.그러나 증오의 만연을 억제하는 데 실질적인 효과는 아직 명확하지 않고 계량화하기도 어렵다.이 문제를 연구하는 주요 장애는 자동 분류기가 반음성을 식별하도록 훈련하는 데 쓰이는 대형 표기 데이터 집합이 부족하다는 것이다.여기서 우리는 독일의 독특한 상황, 즉 자기 표기 단체가 조직적인 온라인 증오와 반언론에 참여하는 것을 사용했다.우리는 통합 학습 알고리즘을 사용하여 각종 단락을 정규화logistic 회귀 함수와 조합하여 이 두 그룹의 수백만 개의 관련 추문 자료 라이브러리에 삽입하여 증오와 반언을 분류한다.우리의 제품 라인은 견본 외 균형 테스트 집합에서 매크로F1 점수를 얻었는데 그 정확도는 0.76에서 0.97 사이이며 심지어 가장 선진적인 수준을 초과했다.그리고 분류기를 이용해 2013년부터 2018년까지 발생한 1천35천여 개의 완전히 해석된 트위터 대화에서 증오와 반언을 발견하고 그 빈도와 상호작용을 연구했다.한 마디로 하면 우리의 연구 결과는 자동화 방법의 잠재력을 두드러지게 하고 조화로운 반강연이 소셜 미디어 대화를 안정시키는 데 미친 영향을 평가할 수 있다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nekenčiama retorika užgriauna internetinę diskusiją, skatina ekstremalius visuomenės judėjimus ir galbūt sukelia real ų smurtą. Galimas šios augančios pasaulinės problemos sprendimas yra piliečių sukelta priešinga kalba, kurioje piliečiai aktyviai dalyvauja neapykantos kalboje, kad atkurtų pilietinę nespoliarizuotą diskursą. Tačiau faktinis neapykantos plitimo mažinimo veiksmingumas nežinomas ir sunku kiekybiškai įvertinti. Viena svarbiausių kliūčių šiam klausimui išnagrinėti yra didelių pažymėtų duomenų rinkinių trūkumas, skirtas automatizuotiems klasifikatoriams mokyti nustatyti priešingą kalbą. Čia naudojame unikalią padėtį Vokietijoje, kur saviregistravančios grupės dalyvauja organizuotoje internetinėje neapykantoje ir priešingoje kalboje. Naudojame komplekso mokymosi algoritmą, kuris sutampa su įvairiomis pastraipomis su reguliuojamomis logistinės regresijos funkcijomis, kad klasifikuotume neapykantą ir priešingą kalbą milijonuose atitinkamų šių dviejų grupių tweetų. Mūsų vamzdynas gauna makro F1 rezultatus iš mėginių subalansuotų bandymų rinkinių, kurie svyruoja nuo 0,76 iki 0,97 tikslumo linijoje ir net viršija pažangiausią pažangą. Tuomet naudojame klasifikatorių, kad atskleistume neapykantą ir priešingai kalbą daugiau kaip 135 000 visiškai išspręstų pokalbių su Twitter, vykstančių 2013–2018 m., ir ištirtume jų dažnumą ir sąveiką. Iš viso mūsų rezultatai pabrėžia automatizuotų metodų galimybę įvertinti koordinuotos priešingos kalbos poveikį stabilizuojant pokalbius social in ėje žiniasklaidoje.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ненавидливата реторика е прекршување на онлајн дискурсот, поттикнување на екстремни општествени движења и веројатно предизвикување на насилство во реалниот свет. Потенцијално решение на овој растечки глобален проблем е контраговорот генериран од граѓаните каде граѓаните активно се вклучуваат во говорот на омраза за враќање на граѓанскиот неполаризиран дискурс. Сепак, нејзината реална ефикасност во намалувањето на ширењето на омразата е непозната и тешко да се квантификува. Една од главните пречки во истражувањето на ова прашање е недостатокот на големи обележани податоци за обука на автоматизираните класификатори за идентификување на противговорот. Овде користиме уникатна ситуација во Германија каде што групите за самозначување се занимаваат со организирана онлајн омраза и противговор. We use an ensemble learning algorithm which pairs a variety of paragraph embeddings with regularized logistic regression functions to classify both hate and counter speech in a corpus of millions of relevant tweets from these two groups. Нашиот гасовод постигнува макро-Ф1 резултати од балансираните тестови на примероци кои се движат од 0,76 до 0,97 точност во редот и дури и надминуваат најсовремената тест. Потоа го користиме класификаторот за да откриеме омраза и противговор во повеќе од 135.000 целосно решени Твитер разговори кои се случуваат од 2013 до 2018 година и да ја проучуваме нивната фреквенција и интеракција. Заедно, нашите резултати го истакнуваат потенцијалот на автоматизираните методи за проценка на влијанието на координираниот противговор во стабилизацијата на разговорите на социјалните медиуми.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>വെറുപ്പുള്ള വാക്കുകള്‍ ഓണ്‍ലൈന്‍ സംസാരിക്കുന്നു, വളരെ സാമൂഹ്യത്തിലുള്ള നീക്കങ്ങള്‍ വളര്‍ത്തുന്നു. ശരിക്കും ലോകത്തെ ഘ ഈ വളര്‍ന്ന പ്രശ്നത്തിന് ഒരു സാധ്യതയുള്ള പരിഹാരം സംസാരിക്കാന്‍ സാധ്യതയുള്ള പ്രശ്നത്തില്‍ സംസാരിക്കുന്നത് പൌരന്മാര്‍ക്ക് ജന എന്നാലും, വെറുപ്പുകള്‍ വിതരണം ചെയ്യുന്നത് തടസ്സമാക്കുന്നതില്‍ അതിന്‍റെ യഥാര്‍ത്ഥ പ്രഭാവം അറിയാത്തതാണ ഈ ചോദ്യത്തില്‍ പരിശോധിക്കാന്‍ ഒരു പ്രധാനതടസ്സമാണ് വലിയ വിവരങ്ങളുടെ കുറ്റമില്ലാത്തത്, കോണ്ടര്‍ സംസാരം തിരിച്ചറിയാന്‍ ഇവിടെ നമ്മള്‍ ജര്‍മ്മനിയില്‍ ഒരു പ്രത്യേക സ്ഥിതി ഉപയോഗിക്കുന്നു. അവിടെ സ്വന്തം ലേബിള്‍ ഗ്രൂപ്പുകള്‍ സംഘടിച്ച് ഈ രണ്ടു കൂട്ടത്തില്‍ നിന്നും വെറുപ്പും പ്രസംഗിക്കുന്ന കണക്കിന് വ്യത്യസ്തമായ ലോഗിസ്റ്റിക്ക് റിക്രഷന്‍ ഫങ്ഷനുമായി ഒരു ആല്‍ഗോരിത്മ് പഠിക്കുന്ന Our pipeline achieves macro F1 scores on out of sample balanced test sets ranging from 0.76 to 0.97-accuracy in line and even exceeding the state of the art. പിന്നീട് ഞങ്ങള്‍ വെറുപ്പും വിരോധ സംസാരം കണ്ടുപിടിക്കാന്‍ പിന്നെ ക്ലാസ്ഫിക്കര്‍ ഉപയോഗിക്കുന്നു. 2013 മുതല്‍ 2018 വരെ വെറുപ്പും പ്രധാനപ അതുകൊണ്ട്, നമ്മുടെ ഫലങ്ങള്‍ സാമൂഹ്യ മീഡിയില്‍ സംസാരം സ്ഥിരമാക്കുന്നതിനായി സ്വയമായി സംസാരിക്കുന്ന രീതികളുടെ സാധ്യതകള്‍ വി</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Харамсалтай яриа нь онлайн яриаг тайлбарлаж, нийгэм хөдөлгөөнийг дэмжиж, бодит ертөнцийн хүчирхийллийг нэмэгдүүлж байна. Энэ дэлхийн асуудлын тулд дэлхийн өссөн асуудлын шийдэл бол иргэн төрөлхтний эсрэг илтгэл, иргэн төрөлхтний эсрэг илтгэлцүүлэлтэй холбогдож иргэн төрөлхтний бус талаар яр Гэвч тэр үнэндээ үзэн ядлын тархалтыг зогсоохын тулд үнэндээ үр дүнтэй байдал нь мэдэхгүй, хэмжээнд хэцүү. Энэ асуултыг судлах нэг чухал бэрхшээл нь эсрэг яриаг тодорхойлдохын тулд автоматжуулан ангилалдаг хүмүүст автоматжуулан ангилалдаг өгөгдлийн сангууд байхгүй. Энд бид Германд өөрийгөө тэмдэглэх бүлгүүд онлайн үзэн ядах, эсрэг ярианд оролцсон гайхалтай нөхцөл байдал хэрэглэдэг. Бид эдгээр хоёр бүлгээрээ сая сая хамааралтай tweets болон үзэн ядах, эсэргүүцэх алгоритмыг хэрэглэдэг. Бидний хоолойн шугам нь 0.76-аас 0.97 шугамны зөвхөн урлагийн байдлаас ч илүү баланслагдсан шалгалтын макро F1 оноо гаргадаг. Дараа нь бид хэлэлцэгчдийг үзэн ядуурлаа, эсрэг яриаг 2013-2018 оны турш бүрэн шийдвэрлэгдсэн Твиттерийн яриагаар олон 135 мянган яриагаар ашиглаж, тэдний давхар, харилцаа судлах хэрэгтэй. Эцэст нь бидний үр дүнд нийгмийн мэдээлэл дээр ярилцлага тогтворжуулахын тулд координацийн эсрэг илтгэлийн нөлөөг үнэлэх автоматжуулсан арга замын боломжуудыг тодорхойлж байна.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Retorik yang benci adalah menyebabkan pembicaraan online, meningkatkan pergerakan masyarakat ekstrim dan mungkin menyebabkan kekerasan dunia nyata. Sebuah penyelesaian potensi untuk masalah global yang berkembang ini adalah ucapan lawan yang dihasilkan oleh warga negara di mana warga negara aktif bergabung dengan ucapan kebencian untuk mengembalikan ucapan warga negara yang tidak polarizasi. Namun, efektivitasnya dalam mengendalikan penyebaran kebencian tidak diketahui dan sukar untuk dikwantifikasikan. One major obstacle to researching this question is a lack of large labeled data sets for training automated classifiers to identify counter speech. Di sini kita menggunakan situasi unik di Jerman di mana kumpulan-kumpulan self-labeling terlibat dalam kebencian dan ucapan menentang secara online terorganisir. Kami menggunakan algoritma pembelajaran ensemble yang pasangkan pelbagai penerbangan paragraf dengan fungsi regresi logistik yang ditetapkan untuk mengklasifikasi kedua-dua kebencian dan ucapan menentang dalam korpus jutaan tweet yang relevan dari dua kumpulan ini. Saluran paip kita mencapai skor makro F1 pada set ujian seimbang sampel yang berlainan dari 0.76 hingga 0.97-akuran dalam baris dan bahkan melebihi keadaan seni. Kemudian kami menggunakan pengklasifikasi untuk menemukan kebencian dan ucapan menentang dalam lebih dari 135,000 perbualan Twitter yang selesai sepenuhnya berlaku dari 2013 hingga 2018 dan mempelajari frekuensi dan interaksi mereka. Altogether, our results highlight the potential of automated methods to evaluate the impact of coordinated counter speech in stabilizing conversations on social media.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ir-retorika mibegħda qed tippreġudika d-diskors onlajn, trawwem movimenti tas-soċjetà estremi u possibbilment twassal għal vjolenza fid-dinja reali. Soluzzjoni potenzjali għal din il-problema globali li qed tikber hija d-diskors kontro-ġenerat miċ-ċittadini fejn iċ-ċittadini jimpenjaw ruħhom b’mod attiv mad-diskors ta’ mibegħda biex jerġgħu jsir diskors ċivili mhux polarizzat. Madankollu, l-effettività attwali tiegħu fit-trażżin tal-firxa tal-mibegħda mhijiex magħrufa u diffiċli biex tiġi kkwantifikata. Ostaklu ewlieni għall-investigazzjoni ta’ din il-kwistjoni huwa n-nuqqas ta’ settijiet ta’ dejta ttikkettati kbar għat-taħriġ ta’ klassifikaturi awtomatizzati biex jidentifikaw kontro-diskors. Hawnhekk a ħna nużaw sitwazzjoni unika fil-Ġermanja fejn gruppi ta’ tikkettar indipendenti involuti f’mibegħda organizzata onlajn u kontra d-diskors. Aħna nużaw algoritmu ta' tagħlim ta' ensemble li jgħaqqad varjetà ta' inkorporazzjonijiet ta' paragrafi ma' funzjonijiet ta' rigressjoni loġistika regolati biex jikklassifikaw kemm il-mibegħda kif ukoll il-kontro-diskors f'korpus ta' miljuni ta' tweets rilevanti minn dawn iż-żewġ gruppi. Il-pajpijiet tagħna jilħqu punteġġi makro F1 fuq settijiet ta’ testijiet ibbilanċjati barra mill-kampjun li jvarjaw minn 0.76 sa 0.97 preċiżjoni f’linja u saħansitra jaqbżu l-istat tal-aħħar. We then use the classifier to discover hate and counter speech in more than 135,000 fully-resolved Twitter conversations occurring from 2013 to 2018 and study their frequency and interaction. B’mod ġenerali, ir-riżultati tagħna jenfasizzaw il-potenzjal ta’ metodi awtomatizzati biex jevalwaw l-impatt ta’ kontro-diskors ikkoordinat fl-istabbilizzazzjoni tal-konversazzjonijiet fuq il-midja soċjali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Haatvoedige retoriek plaagt online discours, stimuleert extreme maatschappelijke bewegingen en geeft mogelijk aanleiding tot echt geweld. Een mogelijke oplossing voor dit groeiende mondiale probleem is door burgers gegenereerde tegenspraak waarbij burgers actief bezig zijn met haatspraak om het civiele niet-gepolariseerde discours te herstellen. De daadwerkelijke effectiviteit ervan bij het tegengaan van de verspreiding van haat is echter onbekend en moeilijk te kwantificeren. Een groot obstakel voor het onderzoeken van deze vraag is een gebrek aan grote gelabelde datasets voor het trainen van geautomatiseerde classificatoren om tegenspraak te identificeren. Hier maken we gebruik van een unieke situatie in Duitsland waar zelflabelende groepen bezig zijn met georganiseerde online haat en tegenspraak. We gebruiken een ensemble learning algoritme dat een verscheidenheid aan alinea embeddings koppelt met geregulariseerde logistieke regressiefuncties om zowel haat als tegenspraak te classificeren in een corpus van miljoenen relevante tweets van deze twee groepen. Onze pipeline bereikt macro F1 scores op uitgebalanceerde testsets die variëren van 0.76 tot 0.97-nauwkeurigheid in lijn en zelfs overtreffen de state of the art. Vervolgens gebruiken we de classificator om haat en tegenspraak te ontdekken in meer dan 135.000 volledig opgeloste Twitter-gesprekken die plaatsvinden van 2013 tot 2018 en bestuderen we hun frequentie en interactie. Al met al benadrukken onze resultaten het potentieel van geautomatiseerde methoden om de impact van gecoördineerde tegenspraak op het stabiliseren van gesprekken op sociale media te evalueren.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Hateful rhetoric is placing online discourses, fostering extreme societal movements and possibly giving rise to real-world violence. Eit potensielt løysing for denne økende globale problemet er borgere generert mottale der borgere aktivt arbeider med hatespråk for å gjenoppretta sivile ikkje-polariserte diskursar. Den faktiske effektiviteten for å krympe spreidda av hatt er imidlertid ukjent og vanskeleg å kvantifisera. Eit viktig hindring til å gjenoppretta dette spørsmålet er ein mangling av store merkelige datasett for å trenga automatiske klassifikatorar for å identifisera mottale. Her bruker vi ein unikt situasjon i Tyskland der selvmerkelige grupper er engasjert i organiserte netthatt og mottale. Vi bruker ein algoritme for læring av ensemble, som parer ulike avsnittsamlingar med regulære logistiske regresjonsfunksjonar for å klassifisera både hatt og mottale i ein korpus av millioner av relevante tweeter frå desse to gruppene. Røytlinjen vårt gjer makro F1- poeng på ut av prøvebalanserte testsett frå 0,76 til 0,97- nøyaktighet i linje og til og med oversikt av kunststanden. Vi bruker så klassifiseringen for å oppdaga hatt og mottale i fleire enn 135 000 fullstendige Twitter-samtaler som skjer frå 2013 til 2018 og studerer frekvensen og interaksjonen deres. Resultatet våre har altså markert potensialen av automatiske metodar for å evaluera effekten av koordinerte mottale i stabilisering av samtaler på sosiale media.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nienawiść retoryka dręczy dyskurs online, wspiera skrajne ruchy społeczne i może powoduje przemoc w rzeczywistym świecie. Potencjalnym rozwiązaniem tego rosnącego globalnego problemu jest przemowa generowana przez obywateli, w której obywatele aktywnie angażują się w mowę nienawiści, aby przywrócić cywilny niespolaryzowany dyskurs. Jednak jego rzeczywista skuteczność w ograniczaniu rozprzestrzeniania się nienawiści jest nieznana i trudna do określenia ilościowego. Jedną z głównych przeszkód w badaniu tego pytania jest brak dużych etykietowanych zbiorów danych dla szkolenia zautomatyzowanych klasyfikatorów w celu identyfikacji przeciwnej mowy. Tutaj wykorzystujemy wyjątkową sytuację w Niemczech, w której grupy samoznakowujące zaangażowane są w zorganizowaną online nienawiść i przeciwko mowie. Używamy algorytmu uczenia się zespołu, który łączy różne osadzenia akapitów z regularyzowanymi funkcjami regresji logistycznej, aby klasyfikować zarówno nienawiść, jak i przeciw mowie w korpusie milionów istotnych tweetów z tych dwóch grup. Nasz rurociąg osiąga wyniki makro F1 na zbalansowanych zestawach testowych od 0,76 do 0,97-dokładności w linii, a nawet przekracza stan techniki. Następnie używamy klasyfikatora, aby odkryć nienawiść i przeciwko mowie w ponad 135.000 w pełni rozdzielczych rozmowach na Twitterze zachodzących od 2013 do 2018 oraz badać ich częstotliwość i interakcje. Ogólnie rzecz biorąc, nasze wyniki podkreślają potencjał zautomatyzowanych metod oceny wpływu skoordynowanej mowy przeciw stabilizacji rozmów w mediach społecznościowych.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A retórica odiosa está assolando o discurso online, promovendo movimentos sociais extremos e possivelmente dando origem à violência no mundo real. Uma solução potencial para esse problema global crescente é o contra-discurso gerado pelo cidadão, no qual os cidadãos se envolvem ativamente com o discurso de ódio para restaurar o discurso civil não polarizado. No entanto, sua eficácia real em conter a disseminação do ódio é desconhecida e difícil de quantificar. Um grande obstáculo para pesquisar essa questão é a falta de grandes conjuntos de dados rotulados para treinar classificadores automatizados para identificar contra-fala. Aqui usamos uma situação única na Alemanha, onde grupos de auto-rotulagem se engajaram em ódio online organizado e contra-discurso. Usamos um algoritmo de aprendizado de conjunto que combina uma variedade de embeddings de parágrafos com funções de regressão logística regularizada para classificar tanto o ódio quanto o contra-discurso em um corpus de milhões de tweets relevantes desses dois grupos. Nosso pipeline atinge pontuações macro F1 em conjuntos de teste balanceados fora de amostra, variando de 0,76 a 0,97 - precisão na linha e até mesmo excedendo o estado da arte. Em seguida, usamos o classificador para descobrir ódio e contra-discurso em mais de 135.000 conversas totalmente resolvidas no Twitter que ocorreram de 2013 a 2018 e estudamos sua frequência e interação. Ao todo, nossos resultados destacam o potencial de métodos automatizados para avaliar o impacto do contra-discurso coordenado na estabilização de conversas nas mídias sociais.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Retorica plină de ură afectează discursul online, încurajează mișcările sociale extreme și, eventual, dă naștere la violență în lumea reală. O soluție potențială la această problemă globală în creștere este contradiscursul generat de cetățeni, în care cetățenii se angajează activ cu discursul de ură pentru a restabili discursul civil nepolarizat. Cu toate acestea, eficacitatea sa reală în combaterea răspândirii urii este necunoscută și greu de cuantificat. Un obstacol major în calea cercetării acestei întrebări este lipsa unor seturi mari de date etichetate pentru instruirea clasificatorilor automatizați în vederea identificării contravorbirii. Aici folosim o situație unică în Germania în care grupurile auto-etichetate se angajează în organizarea online a urăi și a discursului de contracarare. Folosim un algoritm de învățare a ansamblului care asociază o varietate de încorporări de paragrafe cu funcții de regresie logistică regularizate pentru a clasifica atât ură, cât și contravorbire într-un corpus de milioane de tweet-uri relevante din aceste două grupuri. Conducta noastră obține scoruri macro F1 pe seturi de testare echilibrate din eșantion variind de la 0,76 la 0,97-precizie în linie și chiar depășind starea de tehnologie. Apoi folosim clasificatorul pentru a descoperi ură și a contracara vorbirea în peste 135.000 de conversații Twitter complet rezolvate care au loc în perioada 2013-2018 și pentru a studia frecvența și interacțiunea acestora. În ansamblu, rezultatele noastre evidențiază potențialul metodelor automatizate de evaluare a impactului discursului coordonat în stabilizarea conversațiilor pe social media.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ненавистническая риторика разжигает онлайн-дискурс, поощряя экстремистские общественные движения и, возможно, порождая насилие в реальном мире. Потенциальным решением этой растущей глобальной проблемы являются сгенерированные гражданами контрречи, в которых граждане активно участвуют в ненавистнических высказываниях, чтобы восстановить гражданский неполяризованный дискурс. Однако его фактическая эффективность в сдерживании распространения ненависти неизвестна и трудно поддается количественной оценке. Одним из основных препятствий для исследования этого вопроса является отсутствие больших маркированных наборов данных для обучения автоматизированных классификаторов для идентификации встречной речи. Здесь мы используем уникальную ситуацию в Германии, где группы самомаркировки занимаются организованным онлайн ненавистью и контрречью. Мы используем ансамблевый алгоритм обучения, который соединяет множество вложений абзацев с регуляризованными функциями логистической регрессии, чтобы классифицировать как ненавистнические, так и встречные высказывания в корпусе из миллионов релевантных твитов из этих двух групп. Наш трубопровод достигает макро- F1 баллов на из образца сбалансированных тестовых наборов в диапазоне от 0,76 до 0,97-погрешность в линии и даже превышает современный уровень. Затем мы используем классификатор, чтобы обнаружить ненависть и контрречи в более чем 135 000 полностью разрешенных разговоров в Twitter, происходящих с 2013 по 2018 год, и изучить их частоту и взаимодействие. В целом, наши результаты подчеркивают потенциал автоматизированных методов оценки влияния согласованной встречной речи на стабилизацию разговоров в социальных сетях.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ප්‍රශ්නයක් තමයි ඇන්ලයින් කතා කරනවා, ප්‍රශ්නයක් සාමාජික විදියට ප්‍රශ්නයක් කරනවා, සමහරවිට ඇත්ත ලෝක විදිය මේ සාමාන්‍ය ප්‍රශ්නයක් විශ්වාස කරන්න පුළුවන් ප්‍රශ්නයක් තමයි නිවාසිකයෙන් නිර්මාණය කරපු කතාවක් නිර්මාණය ක නමුත්, ඒකේ ඇත්තටම ප්‍රශ්නයක් විශ්වාස කරන්න විශ්වාස කරනවා නමුත් විශ්වාස කරලා තියෙන්නේ නෑ මේ ප්‍රශ්නය පරීක්ෂණා කරන්න ප්‍රධාන ප්‍රශ්නයක් තමයි ස්වයංක්‍රීය විශ්වාස කරගන්න ස්වයංක්‍රීය කරුණු මෙතන අපි ජර්මනියේ විශේෂ තත්වයක් භාවිතා කරනවා තමයි ස්වයංග ලේබිල් කණ්ඩායම් සංවිධානය කරල අපි පාවිච්චි කරනවා ඇන්ස්ම්බුල් ඉගෙන ගන්න ඇල්ගෝරිතම් එකක් භාවිත කරනවා මේ දෙන්නි කණ්ඩායම් වලින් සම්බන්ධ විදියට සම්බන්ධ විදියට අපේ පායිප්ලායින් මැක්රෝ F1 ස්කෝර් සැමැල් සැකසුම් වලින් පරීක්ෂා සැකසුම් වලින් පරීක්ෂා සැකසුම් වලින් 0.76 වල 0.97 වලි ඊට පස්සේ අපි විශේෂකය පාවිච්චි කරනවා විරෝධය සහ විරෝධ කතාවක් හොයාගන්න පුළුවන් දුන්නා දුන්නා දුන්නා දුන්නා දු සම්පූර්ණයෙන්, අපේ ප්‍රතිචාර ප්‍රතිචාරයක් සාමාජික මාධ්‍යමයේ කතාව ස්ථිර කරනවා සංවාදය කරනවා කියලා සං</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Sovražna retorika nadleguje spletni diskurz, spodbuja ekstremna družbena gibanja in morda povzroča nasilje v realnem svetu. Potencialna rešitev tega naraščajočega globalnega problema je nasprotni govor, ki ga ustvarijo državljani, kjer se državljani aktivno ukvarjajo s sovražnim govorom, da bi obnovili civilni nepolarizirani diskurz. Vendar pa njegova dejanska učinkovitost pri omejevanju širjenja sovraštva ni znana in je težko kvantificirati. Ena od glavnih ovir za raziskovanje tega vprašanja je pomanjkanje velikih označenih podatkovnih nizov za usposabljanje avtomatiziranih klasifikatorjev za prepoznavanje nasprotnega govora. Tukaj uporabljamo edinstveno situacijo v Nemčiji, kjer se samooznačevalne skupine ukvarjajo z organiziranim spletnim sovraštvom in nasprotnim govorom. Uporabljamo algoritem za učenje ansambla, ki združuje različne vdelave odstavkov z urejenimi logističnimi regresijskimi funkcijami za razvrstitev sovražnega in protipostavnega govora v korpus milijonov relevantnih tweetov teh dveh skupin. Naš cevovod dosega makro rezultate F1 na izven vzorčnih uravnoteženih testnih nizov, ki segajo od 0,76 do 0,97 natančnosti v liniji in celo presegajo najsodobnejše. Nato uporabljamo klasifikator za odkrivanje sovraštva in nasprotnega govora v več kot 135.000 popolnoma razrešenih pogovorih na Twitterju, ki potekajo od leta 2013 do 2018, ter preučevanje njihove frekvence in interakcije. Naši rezultati skupaj poudarjajo potencial avtomatiziranih metod za ocenjevanje vpliva koordiniranega protipogovora na stabilizacijo pogovorov na družbenih omrežjih.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Macluumaadka aad u xanuunsan wuxuu ku hadlaa shabakada internetka, wuxuuna korinayaa dhaqdhaqaaqa bulshada aad u dheer iyo suurtowda in uu koriyo dagaal caalami ah. Xafiiska arimahan caalamiga ah oo suurtagal ah waa hadal ka gees ah ee muwaadiniinta ah, kuwaas oo muwaadiniintu si firfircoon ugu qabanqaabiyaan hadal nacayb si ay u soo celiyaan hadal aan baaritaanka bulshada ahayn. Si kastaba ha ahaatee, faa’iidadeeda runta ah ee la xiriira faa’iidada cadownimadu ma taqaan oo waa ku adag tahay in la qiyaaso. Qaar ka mid ah qalabka baaritaanka su'aalahan waa baahida koobab macluumaad oo waaweyn oo la xiriira waxbarashada fasaxyada si ay u aqoonsadaan hadalka ka ka geesta ah. Halkan waxaynu ku isticmaalnaa xaalad gaar ah ee Jarmalka, kaas oo ay koox iskuul u leeyihiin oo ku qabanqaabiyey hadalka nacsi iyo ka geesta ah ee internetka. Waxaynu isticmaalnaa algorithm barashada oo kala duduwan kooxaha kala duduwan oo qoraalka ka soo gala shaqooyin la xereeyey jimicsiga dib u celinta si a an u kala qaybsanno nebcaad iyo hadalka ka ka geesta ah, kaas oo ah kooxaha labadan kooxood ka mid ah kun oo twitter. Heefile-heerkayadu waxay gaadhaa koox macro F1 oo samooyin samooyin balaaseed ka soo baxa 0.76 ilaa 0.97 si saxda ah oo ku qoran iyo xittaa aad u badatay xaalada farshaxanka. Markaas waxaynu u isticmaalnaa fasaxa si aan u ogaano hadalka nacayb iyo ka geesta ah wax ka badan 135,000 oo wada xalaal ah oo kala hadlaya Twitterka oo ka horeeya 2013-2018 kadibna waxaynu baranaynaa frequencooyinkooda iyo isku xiriirkooda. Altogether, our results highlight the potential of automated methods to evaluate the impact of coordinated counter speech in stabilizing conversations on social media.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Retorika e urrejtur është duke plagosur diskursin online, duke nxitur lëvizje ekstreme shoqërore dhe ndoshta duke dhënë origjinë ndaj dhunës në botën reale. Një zgjidhje e mundshme për këtë problem botëror në rritje është kundërfjalimi i gjeneruar nga shtetasit ku shtetasit angazhohen aktivisht me fjalimin e urrejtjes për të rivendosur diskursin civil jo-polarizuar. Megjithatë, efektshmëria e tij në kufizimin e përhapjes së urrejtjes është e panjohur dhe e vështirë për të cilësuar. Një pengesë kryesore për kërkimin e kësaj pyetjeje është mungesa e grupeve të mëdha të të dhënave të etiketuara për trainimin e klasifikuesve automatikë për të identifikuar kundër fjalimit. Këtu ne përdorim një situatë unike në Gjermani ku grupet vetë-etiketuese të angazhuar në urrejtjen e organizuar online dhe kundër fjalimit. Ne përdorim një algoritëm mësimi të ensembleve që lidh një shumëllojshmëri të paragrameve me funksionet e rregulluara të regresionit logjistik për të klasifikuar si urrejtjen ashtu edhe kundër fjalimit në një korpus prej miliona tweets relevante nga këto dy grupe. Tubacioni ynë arrin rezultate makro F1 nga grupet e ekuilibruara të provës që shkojnë nga 0.76 deri 0.97 saktësi në linjë dhe madje tejkalojnë gjendjen e teknologjisë. Pastaj përdorim klasifikuesin për të zbuluar urrejtjen dhe kundër fjalimit në më shumë se 135,000 bisedime plotësisht të zgjidhur në Twitter që ndodhin nga 2013 deri në 2018 dhe për të studiuar frekuencën dhe ndërveprimin e tyre. Altogether, our results highlight the potential of automated methods to evaluate the impact of coordinated counter speech in stabilizing conversations on social media.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nežna retorika je uključivanje internetskih diskursa, poticanje ekstremnih društvenih pokreta i verovatno povećanje nasilja u stvarnom svetu. Potencijalno rješenje ovog rastućeg globalnog problema je protivni govor od građana u kojem građani aktivno uključuju govor mržnje kako bi vratili građanski nepolerisani govor. Međutim, njegova stvarna efikasnost prekida širenja mržnje je nepoznata i teško je kvantificirati. Jedna velika prepreka istraživanja ovog pitanja je nedostatak velikih označenih podataka za obuku automatskih klasifikatora da identifikuju kontragovor. Ovde koristimo jedinstvenu situaciju u Njemačkoj gde su grupe samoznačivanja uključene u organizovanu online mržnju i protivnu govor. Koristimo algoritam za učenje ensemble koji pare razne paragrafske integracije sa regulariziranim logističkim regresijama kako bi klasifikovali mržnju i protivnu govor u korpusu milijuna relevantnih tweeta iz te dve grupe. Naša cijevina postiže makro F1 rezultate iz balanciranih testova uzorka od 0,76 do 0,97 tačnosti u liniji i čak preko stanja umjetnosti. Potom koristimo klasifikatora da otkrijemo mržnju i protivni govor u više od 135.000 potpuno rešenih Twitter razgovora koji se događaju od 2013. do 2018. i proučavamo njihovu frekvenciju i interakciju. U potpunosti, naši rezultati naglašavaju potencijal automatskih metoda da proceni utjecaj koordiniranog protivnog govora u stabilizaciji razgovora na društvenim medijima.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Hatisk retorik plågar nätdiskurser, främjar extrema samhällsrörelser och ger möjligen upphov till verkligt våld. En potentiell lösning på detta växande globala problem är medborgargenererat mottal där medborgarna aktivt engagerar sig i hattal för att återställa civil icke-polariserad diskurs. Men dess faktiska effektivitet när det gäller att begränsa spridningen av hat är okänd och svår att kvantifiera. Ett stort hinder för att undersöka denna fråga är bristen på stora märkta datauppsättningar för att utbilda automatiserade klassificerare för att identifiera mottal. Här använder vi oss av en unik situation i Tyskland där självmärkningsgrupper engagerar sig i organiserat hat och mottal på nätet. Vi använder en ensemble learning algoritm som kombinerar en mängd olika styckeinbäddningar med regulariserade logistiska regressionsfunktioner för att klassificera både hat och mottal i en korpus av miljontals relevanta tweets från dessa två grupper. Vår pipeline uppnår makro F1 poäng på provbalanserade testuppsättningar som sträcker sig från 0,76 till 0,97-noggrannhet i linje och till och med överstiger den senaste tekniken. Vi använder sedan klassificeraren för att upptäcka hat och motverka tal i mer än 135 000 fullupplösta Twitter-konversationer som äger rum från 2013 till 2018 och studera deras frekvens och interaktion. Sammantaget belyser våra resultat potentialen med automatiserade metoder för att utvärdera effekten av samordnat mottal för att stabilisera konversationer på sociala medier.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Habari za kutisha inazungumzia mazungumzo ya mtandaoni, inayosababisha vuguvugu kubwa za kijamii na inawezekana kuongezeka kwa vurugu halisi za dunia. A potential solution to this growing global problem is citizen-generated counter speech where citizens actively engage with hate speech to restore civil non-polarized discourse. Hata hivyo, ufanisi wake wa kweli katika kukabiliana na kusambaza chuki haujajua na ni vigumu kupata kiasi. Kizuizi kimoja kikubwa cha kutafiti swali hili ni ukosefu wa seti kubwa za takwimu zinazoonyesha kwa ajili ya kuwafundisha wataalamu waliojitenga kutambua hotuba ya wapinzani. Hapa tunatumia hali ya kipekee nchini Ujerumani ambapo makundi ya kujitambulisha yaliyojihusisha na chuki na hotuba ya kupinga mtandaoni. Tunatumia algorithi ya kujifunza yenye mifano mbalimbali ya paragraph iliyokuwa ikifungua kazi za kudhibitiwa kwa ajili ya kutangaza chuki na hotuba za kupinga chuki katika makampuni ya mamilioni ya twiti zinazohusiana na makundi haya mawili. Our pipeline achieves macro F1 scores on out of sample balanced test sets ranging from 0.76 to 0.97-accuracy in line and even exceeding the state of the art. Kisha tunatumia mwandishi wa kutambua hotuba ya chuki na kuipinga katika zaidi ya mazungumzo ya Twita 135,000 yaliyothibitishwa vizuri yaliyotokea mwaka 2013 hadi 2018 na kutafiti kiwango na mahusiano yao. Zaidi ya hayo, matokeo yetu yanaonyesha uwezekano wa njia za kujitegemea kutathmini athari ya hotuba ya upinzani katika kuimarisha mazungumzo katika mitandao ya kijamii.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>வெறுப்பு விவரங்கள் ஆன்லைன் பேச்சை பேசுகிறது, மிகவும் முக்கியமான சமூகத்தார் நகர்வுகளை வளர்த்துகிறது மற்றும் உண்மையான உல இந்த வளரும் உலக பிரச்சினையின் தீர்வு ஒரு சாத்தியமான தீர்வு என்னவென்றால் குடிமக்கள் வெறுப்பு பேச்சில் செயல்படுத்தப்படுகின However, its actual effectiveness in curbing the spread of hatred is unknown and hard to quantify. இந்த கேள்வியை ஆய்வு செய்ய ஒரு முக்கியமான தடை எதிர் பேச்சை கண்டுபிடிக்க பெரிய குறிப்பிட்ட தகவல் அமைப்பு இங்கே நாம் ஜெர்மனியில் ஒரு தனிப்பட்ட நிலையை பயன்படுத்துகிறோம் அதில் தன்னியக்க குழுக்கள் சேர்ந்துகொண்டிருக இந்த இரண்டு குழுக்களில் இருந்து மில்லியன் தொடர்புடைய தொடர்புகளை வகைப்படுத்தும் வெறுப்பு மற்றும் பேச்சு பொருட்களை வெளிப்படுத்தும் பொருட்களில் பல்வேற எங்கள் கைப்பேலின் மாதிரி F1 புள்ளிகள் பெறுகிறது மாதிரி நிலையில் நிறைந்த சோதனை அமைப்புகளிலிருந்து 0. 76 வரை 0. 97 வரிசையில் சரியாக பின்னர் நாம் வகுப்பாளரை பயன்படுத்தி வெறுப்பு மற்றும் எதிர் பேச்சை கண்டுபிடிக்க பயன்படுத்துகிறோம் 135,000 முழுமையாக தீர்மானிக்கப் மேலும், எங்கள் முடிவு</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nesip s철zleri internetde g체rr체흫leri d철w체rmektedir, jemgy첵et챌ilik hereket etm채ge k철mek edip, belki-de d체n첵채de 첵agda첵 t철weregini artyp biler. Halkara 철s첵채n bu d체n첵채 meselelerini흫 챌철z체mi ta첵dan adamlar tarapyndan 챌ykyp 챌yky힊 챌yky힊ynda vatanda힊lar i흫 첵igren첵채n 챌yky힊yny gutarmak 체챌in 챌yky힊 챌yky힊yny흫 체stine alyp bar첵arlar. 횦철ne 첵igren첵채n 첵igren첵채ni흫 첵체z체ni 챌ykarmak 체챌in 챌yky힊lygyny tanama첵ar we 챌ykmak kyndyr. Bu soragy 철흫lemek 체챌in esasy engel bolup ge챌mek 체챌in otomatik klasifikat챌ylara durmu힊y tanamak 체챌in uly etiketli maglumat d체z체mleri 첵ok. Bu 첵erde, Germani첵ada 철zlerini etiketle첵채n topardan 챌yky힊 we 챌yky힊 bilen d체zenlenen 첵igren챌 we 챌yky힊 g체rr체흫de gatna힊an 첵erleri ulan첵arys. Biz bu iki topardan milyonlary흫 m철h체m tweets k철p체sinde 첵igren챌 we 챌yky힊 etmek 체챌in bir 철wrenme algoritmi ulan첵arys. Bizi흫 pipelini흫 makro F1 sanlaryny 철r채n 챌yky힊 derejesinden 0,76-den 0,97-den dogrylykdan we hatda sungaty흫 durumyndan 체st체n ed첵채r. Sonra 2013-nji 첵yldan 2018-nji 첵yldan b채ri 첵igren챌 we 챌yky힊 챌yky힊yny a챌mak 체챌in klasifikat챌ylary ulan첵arys. Hemi힊e, netijelerimiz sosyal med첵danlary흫 g체rle힊melerini stabilize etmek 체챌in awtomatik ta첵첵arlanan metodlary흫 etkisini 챌철zmesi 체챌in okaylandyryl첵ar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ناپسندیدہ بات آنلاین کی صحبت کرتی ہے، بہت زیادہ اجتماعی حرکتوں کو فعال کرتی ہے اور شاید حقیقی دنیا کی خشونت کو اضافہ کرتی ہے۔ یہ بڑھنے والی مسئلہ کے لئے ایک مسئلہ حل ہے جہاں شہروں کے پیدا ہونے والی مخالف بات ہے جہاں شہروں نے ناپسند بات کے ساتھ فعال کرلیا ہے کہ شہروں کی غیر قطعی صحبت کو دوبارہ پلٹا سکیں۔ لیکن اس کی حقیقی اثبات نفرت کے گھیرنے کے لئے غیر معلوم اور شمار کرنے کے لئے سخت ہے اس سؤال کی تحقیق کرنے کے لئے ایک بڑی روکا ہے کہ کانٹر کی بات شناسایی کرنے کے لئے اٹوٹ کلاسیٹر کی آموزش کے لئے بڑی لابلیٹ ڈیٹ سٹ کی کمی ہے. یہاں ہم جرمن میں ایک مختلف موقعیت استعمال کرتے ہیں جہاں خود لیبلینگ گروہوں نے سازمان آنلاین کے نفرت اور مخالف بات میں مشغول ہوا ہے. ہم نے ایک ایسمبل سیکھنے الگوریتم کا استعمال کرتا ہے جو ان دو گروہوں میں سے ایک میلیونوں متعلق توئیٹوں کا کلاس کرتا ہے جو ان میں سے ناپسند اور کنٹر کی بات کا جوڑا کرتا ہے۔ ہمارے پائپ لین مکرو F1 اسکور پہنچ رہے ہیں نمونہ میں مطابق مطابق تست سیٹوں سے 0.76 سے 0.97 دقیق لین میں اور هنر کی حالت سے بھی زیادہ بھی زیادہ. پھر ہم نے کلاسفار کا استعمال کرتا ہے کہ اس سے زیادہ 135,000 سے زیادہ سخنرانی تلاش کریں اور ان کی فرکانس اور تعامل کا تحقیق کریں۔ ہمارے نتیجے، سوسیل میڈیا پر باتوں کو ثابت قدم رکھنے کے لئے آٹوٹی طریقوں کی امکانات کو مطالبہ کرنے کے لئے تغییر دیتے ہیں.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Aniqlik so'zlar tarmoqni o'zgartiradi, juda qiziq jamiyat harakatlarini foydalanadi va balki dunyoning haqiqiqiy volati sababchi bo'lishi mumkin. A potential solution to this growing global problem is citizen-generated counter speech where citizens actively engage with hate speech to restore civil non-polarized discourse. Lekin, kuchlikni kattalashtirishning asosiy effekti nomaʼlum va to'anish qiyin. Bu savollarni o'rganish uchun eng muhim obstacollari - bu tizimni tasdiqlash uchun avtomatik tasdiqlash uchun katta maʼlumot tizimi yoʻq. Bu yerda, Olmoniyadagi unik holatdan foydalanamiz, bu yerda o'z o'zimni o'zgartirish orqali shaxsiy keladigan guruhlarni o'zgartiradi. Biz bir misol o'rganish algorithidan foydalanamiz, bu ikkita guruhdan millionlab bog'liq twitlardan foydalanuvchi qo'llangan bir necha qo'llangan qo'shish funksiyalari bilan boshlanadi. Bizning pipelining makro F1 qiymatlarini samol balandlik tizimdan 0.76 dan 0.97 darajadagi darajaga olib keladi va sananing holatidan ko'proq. Keyin biz faqat va boshqaruvchi gapirishni aniqlash uchun foydalanamiz, 2013-2018-yildan faqat va boshqaruvchidan 135 mingdan ortiq xabar qiladigan Twitterning muloqatlarini ko'rsatuvchimiz va ularning frekvens va interfektlarini o'rganamiz. Ko'rsatganda, bizning natijalarimiz jamiyat media bilan suhbatlarni saqlash uchun avtomatik foydalanuvchilarning effektini qiymatish natijalarini ko'rsatadi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Những lời hùng biện đáng căm ghét đang làm lũng đoạn trực tuyến, thúc đẩy các động thái xã hội cực đoan và có thể gây ra bạo lực thế giới thực. Một giải pháp tiềm năng cho vấn đề to àn cầu ngày càng lớn là phát biểu phản đối của công dân nơi công dân tận tâm tập trung với bài phát biểu căm ghét để khôi phục nền văn học. Tuy nhiên, hiệu quả thực sự của nó trong việc kiềm chế sự lan rộng hận thù là không rõ và khó để xác định. Một cản trở lớn để nghiên cứu câu hỏi này là sự thiếu các bộ dữ liệu nổi tiếng để huấn luyện các phân loại tự động để xác định đối tượng. Ở đây chúng tôi sử dụng một tình huống đặc biệt ở Đức nơi những nhóm tự đánh dấu được tổ chức trên mạng thù ghét và đối thoại. Chúng tôi sử dụng một thuật to án học chung kết hợp các đoạn nhúng vào các chức năng phục hồi hàng loạt để phân loại cả sự căm ghét và phản phát biểu trong tập hợp hàng triệu dòng tweet liên quan từ hai nhóm này. Trong đường ống của chúng tôi đạt được điểm số F1 vĩ đại trên các bộ thử mẫu cân bằng, từ 0.Thank đến 0.97-chính xác theo dòng và thậm chí vượt quá trạng thái nghệ thuật. Chúng tôi sử dụng người phân loại để phát hiện thù ghét và đối thoại trong nhiều hơn 135,000 cuộc nói chuyện Twitter được giải quyết đầy đủ diễn ra từ 133 đến 208 và nghiên cứu tần số và giao tiếp của họ. Tóm lại, kết quả của chúng tôi nhấn mạnh khả năng của các phương pháp tự động để đánh giá tác động của phản phát biểu phối phối hợp trong việc ổn định cuộc đối thoại trên mạng xã hội.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>仇言方困网络语,助极动,可以发世力。 解此日甚者全球一在解决方案乃公民之反言,公民积极参与仇言,以复公民非两极分化之语。 然其遏怨延蔓之实未知,难以量化。 论其大要,阙大标数集,所以练自类器以识反语音也。 吾用德国之独,自标团体在线仇反之言也。 吾辈用一集成算法,当算法将诸段落嵌正则化逻辑归函数配对,以关二组之数百万条推文语料库仇反言之类。 吾产品线于 0.76 至 0.97 样本衡试集上得宏观 F1 分数,准确率中程度,甚于先进。 然后用类器2013年至2018年之间有过135者,000一切决之Twitter对以仇怨反言,究其频率相用。 总而言之,吾论之矣自动化术在评反言定社交媒体对言化之力也。</span></div></div><dl><dt>Anthology ID:</dt><dd>2020.alw-1.13</dd><dt>Volume:</dt><dd><a href=/volumes/2020.alw-1/>Proceedings of the Fourth Workshop on Online Abuse and Harms</a></dd><dt>Month:</dt><dd>November</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Online</dd><dt>Venues:</dt><dd><a href=/venues/alw/>ALW</a>
| <a href=/venues/emnlp/>EMNLP</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>102–112</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.alw-1.13>https://aclanthology.org/2020.alw-1.13</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/2020.alw-1.13 title="To the current version of the paper by DOI">10.18653/v1/2020.alw-1.13</a></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">garland-etal-2020-countering</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Joshua Garland, Keyan Ghazi-Zahedi, Jean-Gabriel Young, Laurent Hébert-Dufresne, and Mirta Galesic. 2020. <a href=https://aclanthology.org/2020.alw-1.13>Countering hate on social media : Large scale classification of hate and counter speech</a>. In <i>Proceedings of the Fourth Workshop on Online Abuse and Harms</i>, pages 102–112, Online. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2020.alw-1.13>Countering hate on social media : Large scale classification of hate and counter speech</a> (Garland et al., ALW 2020)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2020.alw-1.13.pdf>https://aclanthology.org/2020.alw-1.13.pdf</a></dd><dt class=acl-button-row>Optional supplementary material:</dt><dd class=acl-button-row><a href=https://aclanthology.org/attachments/2020.alw-1.13.OptionalSupplementaryMaterial.pdf class="btn btn-attachment btn-sm"><i class="fas fa-file"></i>
&nbsp;2020.alw-1.13.OptionalSupplementaryMaterial.pdf</a></dd><dt class=acl-button-row>Video:</dt><dd class=acl-button-row><a href=https://slideslive.com/38939518 class="btn btn-attachment btn-sm"><i class="fas fa-video"></i>&nbsp;https://slideslive.com/38939518</a></dd><dt>Data</dt><dd><a href=https://paperswithcode.com/dataset/hate-counter>Hate Counter</a>,&nbsp;<a href=https://paperswithcode.com/dataset/hate-speech>Hate Speech</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2020.alw-1.13.pdf title="Open PDF of 'Countering hate on social media : Large scale classification of hate and counter speech'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Countering+hate+on+social+media+%3A+Large+scale+classification+of+hate+and+counter+speech" title="Search for 'Countering hate on social media : Large scale classification of hate and counter speech' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'Countering hate on social media : Large scale classification of hate and counter speech'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a>
<a class="btn btn-attachment d-flex flex-wrap justify-content-center" href=https://aclanthology.org/attachments/2020.alw-1.13.OptionalSupplementaryMaterial.pdf title="Open optional supplementary material for 'Countering hate on social media : Large scale classification of hate and counter speech'"><span class="align-self-center px-1"><i class="fas fa-file"></i></span>
<span class=px-1>Optional supplementary material</span></a>
<a class="btn btn-attachment d-flex flex-wrap justify-content-center" href=https://slideslive.com/38939518 title="Open video for 'Countering hate on social media : Large scale classification of hate and counter speech'"><span class="align-self-center px-1"><i class="fas fa-video"></i></span>
<span class=px-1>Video</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[Countering hate on social media : Large scale classification of hate and counter speech](https://aclanthology.org/2020.alw-1.13) (Garland et al., ALW 2020)</p><ul class=mt-2><li><a href=https://aclanthology.org/2020.alw-1.13>Countering hate on social media : Large scale classification of hate and counter speech</a> (Garland et al., ALW 2020)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Joshua Garland, Keyan Ghazi-Zahedi, Jean-Gabriel Young, Laurent Hébert-Dufresne, and Mirta Galesic. 2020. <a href=https://aclanthology.org/2020.alw-1.13>Countering hate on social media : Large scale classification of hate and counter speech</a>. In <i>Proceedings of the Fourth Workshop on Online Abuse and Harms</i>, pages 102–112, Online. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>