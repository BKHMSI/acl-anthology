<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Word Embeddings as Tuples of Feature Probabilities - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="Word Embeddings as Tuples of Feature Probabilities" name=citation_title><meta content="Siddharth Bhat" name=citation_author><meta content="Alok Debnath" name=citation_author><meta content="Souvik Banerjee" name=citation_author><meta content="Manish Shrivastava" name=citation_author><meta content="Proceedings of the 5th Workshop on Representation Learning for NLP" name=citation_conference_title><meta content="2020/7" name=citation_publication_date><meta content="https://aclanthology.org/2020.repl4nlp-1.4.pdf" name=citation_pdf_url><meta content="24" name=citation_firstpage><meta content="33" name=citation_lastpage><meta content="10.18653/v1/2020.repl4nlp-1.4" name=citation_doi><meta property="og:title" content="Word Embeddings as Tuples of Feature Probabilities"><meta property="og:image" content="https://aclanthology.org/thumb/2020.repl4nlp-1.4.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2020.repl4nlp-1.4"><meta property="og:description" content="Siddharth Bhat, Alok Debnath, Souvik Banerjee, Manish Shrivastava. Proceedings of the 5th Workshop on Representation Learning for NLP. 2020."><link rel=canonical href=https://aclanthology.org/2020.repl4nlp-1.4></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Word Embeddings as Tuples of Feature Probabilities</a>
<a id=af_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Woord Inbêding as Tuples van Funksie Moontlikheid</a>
<a id=am_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>የፊደል ቅርጽ ምርጫዎች</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>تضمين كلمة على أنها مجموعات من احتمالات الميزة</a>
<a id=az_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>S칬zl칲k 캻fad톛l톛ri 칐l칞칲s칲 M칲mk칲nl칲kl톛ri kimi S칬zl칲k 캻fad톛l톛ri</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Вградвания на думи като двойки от вероятности за характеристика</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>বৈশিষ্ট্য সম্ভাবনার টাইপল হিসেবে শব্দ বিবরণ</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>ཆོས་ཆོས་ལུགས་ཀྱི་དཔེ་དབྱིབས་སྔོན་སྒྲིག་ཀྱི་ཡིག་ཚན་བསྡུས་པ</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Uklapanje riječi kao vrpce mogućnosti karaktera</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Incorporació de paraules com tubles de probabilitats de característiques</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Vložení slov jako Tuples pravděpodobností funkcí</a>
<a id=da_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Word Embeddings as Tuples of Feature Sandsynligheder</a>
<a id=de_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Wort-Einbettungen als Tupel von Feature-Wahrscheinlichkeiten</a>
<a id=el_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Ενσωματώσεις λέξεων ως Tuples πιθανών χαρακτηριστικών</a>
<a id=es_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Incrustaciones de palabras como tuplas de probabilidades de características</a>
<a id=et_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Sõnade põimimised funktsioonide tõenäosuste tuplitena</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>وارد کردن کلمات به عنوان مثال احتمالات ویژه</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Sanaupotukset ominaisuustodennĂ¤kĂ¶isyyksien tupleina</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Les intégrations de mots en tant que tuples de probabilités de caractéristiques</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Leabú Focal mar Thuplaí de Dhóchúlachtaí Gné</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>@ action</a>
<a id=he_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>קידום מילים ככפולות של סבירות תכונות</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Word एम्बेडिंग सुविधा संभावनाओं के Tuples के रूप में</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Usporavanje riječi kao vrpce mogućnosti karaktera</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Szóbeágyazások, mint a funkciók valószínűségeinek tupletei</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Բառերի ներգրավումը որպես առանձնահատկությունների խումբ</a>
<a id=id_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Pencampuran kata sebagai Tuples of Feature Probabilities</a>
<a id=is_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Embedding delle parole come Tuples of Feature Probabilities</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>フィーチャーの確率のタプルとしてのWord埋め込み</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>structural navigation</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>სიტყვების შესაძლებლობების სიტყვები როგორც სიტყვების შესაძლებლობა</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Сөздің ендіру мүмкіндіктерінің мәліметтері ретінде</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>특징 확률 원조로서의 단어 삽입</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>žodžių įterpimas kaip galimų požymių vamzdeliai</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Вклучување на зборови како купки на веројатности</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>വാക്ക് എംബെഡിങ്ങുകള്‍ സാധ്യതകളുടെ ടൂപ്ലുകളായി വാക്കുകള്‍</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Үг нэвтрүүлэх боломжуудын Tuples of Feature Probabilities</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Name</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>L-inkorporazzjoni tal-kliem bħala Tuples of Feature Probabilities</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Woordinsluitingen als Tuples van Feature Waarschijnlijkheid</a>
<a id=no_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Innebygging av ord som eksemplar av funksjonssannsynlighetar</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Wkładanie słów jako Tuples prawdopodobieństw funkcji</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Incorporações de palavras como tuplas de probabilidades de recursos</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Încorporarea cuvintelor ca Tuples de probabilități ale caracteristicilor</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Встраивание слов в виде кортежей вероятностей признаков</a>
<a id=si_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Name</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Vgradnje besed kot vzorci verjetnosti lastnosti</a>
<a id=so_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Heeganka hadalka sida tusaale ahaan suurtagalka ah</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Përfshirja e fjalëve si Tuples of Feature Probabilities</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Времена речи као Вероватности функција</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Ordinbäddningar som bitar av funktionssannolikheter</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Matokeo ya Matokeo kama Tuzo ya Tafadhali</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>வார்த்தை உட்பொதிக்கும் பண்புகளின் சிக்கல்களாக</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Mahsuratyň Mumkinçiliki Däpli Sözler</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>ویڈ انڈینگ کے طور پر ویڈ انڈینگ</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Comment</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>Thiết lập chữ làm ống kính dự tính</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>为特征概率元组词嵌之</a></h2><p class=lead><a href=/people/s/siddharth-bhat/>Siddharth Bhat</a>,
<a href=/people/a/alok-debnath/>Alok Debnath</a>,
<a href=/people/s/souvik-banerjee/>Souvik Banerjee</a>,
<a href=/people/m/manish-shrivastava/>Manish Shrivastava</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In this paper, we provide an alternate perspective on <a href=https://en.wikipedia.org/wiki/Word_(group_theory)>word representations</a>, by reinterpreting the dimensions of the vector space of a <a href=https://en.wikipedia.org/wiki/Word_embedding>word embedding</a> as a collection of <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a>. In this reinterpretation, every component of the word vector is normalized against all the word vectors in the vocabulary. This idea now allows us to view each vector as an n-tuple (akin to a fuzzy set), where n is the dimensionality of the word representation and each element represents the probability of the word possessing a <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature</a>. Indeed, this representation enables the use fuzzy set theoretic operations, such as <a href=https://en.wikipedia.org/wiki/Union_(set_theory)>union</a>, <a href=https://en.wikipedia.org/wiki/Intersection_(set_theory)>intersection</a> and <a href=https://en.wikipedia.org/wiki/Subtraction>difference</a>. Unlike previous attempts, we show that this representation of words provides a notion of similarity which is inherently asymmetric and hence closer to human similarity judgements. We compare the performance of this representation with various <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmarks</a>, and explore some of the unique properties including function word detection, detection of polysemous words, and some insight into the interpretability provided by set theoretic operations.<tex-math>n</tex-math>-tuple (akin to a fuzzy set), where <tex-math>n</tex-math> is the dimensionality of the word representation and each element represents the probability of the word possessing a feature. Indeed, this representation enables the use fuzzy set theoretic operations, such as union, intersection and difference. Unlike previous attempts, we show that this representation of words provides a notion of similarity which is inherently asymmetric and hence closer to human similarity judgements. We compare the performance of this representation with various benchmarks, and explore some of the unique properties including function word detection, detection of polysemous words, and some insight into the interpretability provided by set theoretic operations.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In hierdie papier, ons verskaf 'n alternatiewe perspektief op woord voorstellings deur die dimensies van die vektor ruimte van 'n woord ingesluit as 'n versameling van funksies te hervertrek. In hierdie herterpretasie, elke komponent van die woord vektor is normaliseer teen al die woord vektore in die woordeboek. Hierdie idee laat ons nou toe om elke vektor te besigtig as 'n n- tuple (gelyk a an 'n verdwyn stel), waar n is die dimensionaliteit van die woord verteenwoording en elke element verteenwoordig die waarskynlikheid van die woord besit 'n funksie. Werklik, hierdie verteenwoording laat die gebruik van verdwyn stel teorieese operasies, soos union, interseksie en verskil. Ongelyks soos vorige probeers, wys ons dat hierdie voorstelling van woorde 'n notie van gelykheid verskaf wat inherent asymmetries is en daarom naby aan menslike oordelinge. Ons vergelyk die prestasie van hierdie verteenwoording met verskeie benchmarke, en ondersoek sommige van die unieke eienskappe insluitend funksie woord opdekking, opdekking van polisemose woorde, en sommige inkennisse in die uitleggingsverklaring wat deur teorieese operasies verskaf word.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>በዚህ ፕሮግራም፣ ለቃላት መልዕክቶች እናስቀራለን፡፡ በዚህ መግለጫ፣ የቃላት vector ሁሉም ክፍል በአብሪካዊው ቃላት vectors ላይ የተደገመ ነው፡፡ ይህም አሳብ እያንዳንዱን vector እንደ n-ጭብጥ (የጨዋታ መስመር) ማየት ይፈቅዳል፡፡ እርግጠኛ፣ ይህ መልዕክት የተጠቃሚ ተግባር፣ እንደ ዩኒያዊ፣ ግንኙነት እና ልዩነት የሚደረገውን ጥያቄ ያስችላል፡፡ Unlike previous attempts, we show that this representation of words provides a notion of similarity which is inherently asymmetric and hence closer to human similarity judgements. የዚህን መልዕክት አካሄዱን በተለያዩ ደብዳቤዎች እናስተያየዋለን፣ የቃላትን ማግኘት፣ የፖሊስቲካዊ ቃላትን ማግኘት እናደርጋለን፣ አንዳንዶችም የtheoretica ተግባር በተደረገው ትርጓሜ እናደርጋለን፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>في هذه الورقة ، نقدم منظورًا بديلاً لتمثيل الكلمات ، من خلال إعادة تفسير أبعاد فضاء متجه لتضمين كلمة كمجموعة من الميزات. في إعادة التفسير هذه ، يتم تطبيع كل مكون من متجه الكلمات مقابل جميع متجهات الكلمات في المفردات. تتيح لنا هذه الفكرة الآن عرض كل متجه على أنه n-tuple (على غرار مجموعة ضبابية) ، حيث n هي أبعاد تمثيل الكلمة ويمثل كل عنصر احتمال امتلاك الكلمة لميزة. في الواقع ، يتيح هذا التمثيل استخدام العمليات النظرية لمجموعة ضبابية ، مثل الاتحاد والتقاطع والاختلاف. على عكس المحاولات السابقة ، نظهر أن تمثيل الكلمات هذا يوفر فكرة تشابه غير متماثلة بطبيعتها وبالتالي فهي أقرب إلى أحكام التشابه البشري. نحن نقارن أداء هذا التمثيل بمعايير مختلفة ، ونستكشف بعض الخصائص الفريدة بما في ذلك اكتشاف الكلمات الوظيفية ، واكتشاف الكلمات متعددة المعاني ، وبعض التبصر في التفسير الذي توفره العمليات النظرية المحددة.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bu kağızda, sözlərin göstərilmələri barəsində başqa bir perspektiv təyin edirik, özelliklərin koleksiyonu olaraq içərisində olan bir sözün vektör boşluğunun ölçülərini yenidən dəyişdirərək. Bu tərzdə, sözlərin vektorunun hər komponenti sözlərin vektorlarına qarşı normalizlənir. Bu fikir indi hər vektörü n-tuple kimi görünməyə imkan verir, n sözlərin göstəricisinin ölçülüyü və hər elementi bir fəaliyyət sahibi sözlərin ehtimalın ı göstərir. Əslində, bu göstəricisi istifadə etməyi fərqli təriqli təriqli işləri, birlikləri, fərqli və fərqli kimi fərqli təriqli təriqlərə qadirdir. Əvvəlki çabaların bənzərinə baxmayaraq, bu sözlərin göstərilməsi, bənzər bir fikir göstərir ki, bənzər bir qədər asymetrik və buna görə də insanların bənzər hökmlərinə daha yaxın olur. Biz bu göstərişlərin performansını müxtəlif benchmarklərlə qarşılaşdırırıq, fərqli sözləri keşfetmək, polizm sözlərin keşfetməsi və teoriqli işləri təyin etmək üçün təfsil edilən təfsil edilməsi barəsində bəzi xüsusiyyətləri keşfetirik.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>В тази статия ние предлагаме алтернативна перспектива за представянето на думи, като реинтерпретираме размерите на векторното пространство на една дума, вградена като колекция от функции. При това повторно тълкуване всеки компонент на вектора на думата се нормализира спрямо всички вектори на думата в речника. Тази идея сега ни позволява да разглеждаме всеки вектор като n-тупъл (подобно на мъглив набор), където n е размерността на словото представяне и всеки елемент представлява вероятността думата да притежава дадена характеристика. Всъщност, това представяне позволява използването на мъгливи теоретични операции, като обединение, пресичане и разлика. За разлика от предишните опити, ние показваме, че това представяне на думите осигурява понятие за сходство, което по своята същност е асиметрично и следователно по-близо до човешките преценки за сходство. Сравняваме ефективността на това представяне с различни референтни показатели и изследваме някои от уникалните свойства, включително функция откриване на думи, откриване на многослойни думи и известно разбиране за интерпретацията, предоставена от теоретичните операции на множеството.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>এই কাগজটিতে আমরা শব্দের প্রতিনিধিত্বের বিপরীত দৃষ্টিভঙ্গি প্রদান করি, ভেক্টরের স্থান পুনরায় বিশেষ করে একটি শব্দের সংগ্রহ হিসেবে প্রবেশ এই পুনঃপ্রতিষ্ঠানে শব্দ ভেক্টরের প্রত্যেক অংশ স্বাভাবিক ভেক্টরের বিরুদ্ধে স্বাভাবিক। এই চিন্তা এখন আমাদের প্রত্যেক ভেক্টর একটি n-টাপেল হিসেবে দেখতে পাচ্ছে (যেখানে একটি অজ্ঞাত সেটের মতো), যেখানে শব্দের প্রতিনিধিত্বের মাত্রার মাত্রা এব সত্যিই, এই প্রতিনিধিত্ব ব্যবহারকারীদের ব্যবহারের ক্ষেত্রে ততীতিহীন কার্যক্রম, যেমন ইউনিয়ন, বিভিন্ন বিভিন্ন পূর্ববর্তী প্রচেষ্টার ভিন্ন ভিন্ন ভিন্ন ভিন্ন প্রতিনিধিত্ব দেখাচ্ছি যে এই শব্দের প্রতিনিধিত্বের একটি ধারণা প্রদান করা হয়েছে যা প্র আমরা এই প্রতিনিধিত্বের প্রকৃতির তুলনা করি বিভিন্ন বেনমার্কের সাথে এবং কিছু বৈশিষ্ট্যের বৈশিষ্ট্য অনুসন্ধান করি, যার মধ্যে ফাংশন শব্দ আবিষ্কার, বহুব</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ང་ཚོས་ཤོག་བུ་འདིའི་ནང་དུ་ཡི་གེ་ལ་ངོས་ཚོའི་རྩ་སྒྲིག་ཕྱོགས་གཞན་གྱི་ལྟ་བ་ཞིག་བྱེད་ཀྱི་ཡོད་པ་ཚོའི་ནང་ནས་ཕན་ཚུན་གྱི་བར་སྟོང་ འདིའི་རྗེས་སུ་འབྱེད་སྐབས་ཐོག་གི་ཆ་ཤས་རེ་རེ་བ་དེ་ཚོའི་ཐོག་རིམ་ནང་གི་ཚགས་རྣམས་མེད་རྒྱུན་གྱིས་བཟོས་ཚར This idea now allows us to view each vector as a n n-tuple (akin to a fuzzy set), where n is the dimensionality of the word representation and each element represents the probability of the word possessing a feature. དངོས་འབྲེལ་བ་འདིས་སྤྱི་ཁྱད་པར་ཕྱིར་བཏོན་པའི་གཞི་རྩལ་བ་སྒྲིག་ལྟར་བཀོད་སྤྱོད་ལ་ནུས་ཡོད། ང་ཚོས་དུས་མའི་དཔའ་བཅས་ལ་འགྱུར་བ་དེ་ལྟ་བུའི་ནང་གི་ཡིག་གི་གསལ་བཤད་འདི་གི་དོན་དག་མི་འདྲ་བ་དང་། བྱས་ཙང་མི་འདྲ་བ་དང་མི་འདྲ་བ་བསྐྱེད་ We compare the performance of this representation with various benchmarks, and explore some of the unique properties including function word detection, detection of polysemous words, and some insight into the interpretability provided by set theoretic operations.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>U ovom papiru pružamo alternativnu perspektivu predstavljanja riječi, ponovno pretvaranjem dimenzija vektorskog prostora riječi koja se uključuje kao kolekcija funkcija. U ovoj reinterpretaciji, svaki komponent riječi vektora se normalizira protiv svih vektora riječi u rečniku. Ova ideja nam sada omogućava da vidimo svaki vektor kao n-tuple (sličan n a fuzzy set), gdje n je dimenzionalnost predstavljanja riječi i svaki element predstavlja vjerojatnost riječi koja posjeduje funkciju. Zapravo, ova predstava omogućava korištenje nepristojnih teorijskih operacija, poput sindikata, prekidanja i razlike. Za razliku od prethodnih pokušaja, pokazujemo da ova predstavljanja riječi pruža pojam sličnosti koja je inherentno asimetrična i stoga bliže osuđivanju ljudske sličnosti. Uspoređujemo učinkovitost ove predstave sa različitim kriterijama, i istražujemo neke od jedinstvenih vlasništva, uključujući otkrivanje funkcionalnih riječi, otkrivanje polizemnih riječi, i neke uvide o interpretabilnosti pruženoj teoretičkim operacijama.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>En aquest paper, proporcionem una perspectiva alternativa a les representacions de paraules, reinterpretant les dimensions de l'espai vector d'una paraula incorporada com una col·lecció de característiques. En aquesta reinterpretació, cada component de la paraula vector es normalitza en contra de tots els paraules vectors del vocabulari. Aquesta idea ara ens permet veure cada vector com un n-tuple (semblant a un conjunt confus), on n és la dimensionalitat de la representació de paraula i cada element representa la probabilitat de la paraula que posseeix una característica. De fet, aquesta representació permet l'ús d'operacions teòriques confuses, com la unió, la intersecció i la diferència. A diferència dels intents anteriors, demostram que aquesta representació de paraules proporciona una noció de similitud que és inherentment asimètrica i, per tant, més a prop dels judicis de similitud humana. Comparem el desempeny d'aquesta representació amb diversos punts de referència, i explorem algunes de les propietats únices, incloent la detecció de paraules de funció, la detecció de paraules polisemoses i alguna comprensió de l'interpretabilitat proporcionada per operacions teòriques.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>V tomto článku poskytujeme alternativní pohled na slovní reprezentace reinterpretací rozměrů vektorového prostoru vloženého slova jako sbírku prvků. V této reinterpretaci je každá složka slovního vektoru normalizována proti všem slovním vektorům ve slovní zásobě. Tato myšlenka nám nyní umožňuje vidět každý vektor jako n-tuple (podobný rozmazané množině), kde n je dimenzionalita slova reprezentace a každý prvek představuje pravděpodobnost, že slovo má vlastnost. Tato reprezentace umožňuje použití fuzzy množinových teoretických operací, jako jsou sjednocení, průsečík a rozdíl. Na rozdíl od předchozích pokusů ukazujeme, že tato reprezentace slov poskytuje představu podobnosti, která je z podstaty asymetrická a tudíž blíže k lidským úsudkům podobnosti. Porovnáváme výkon této reprezentace s různými benchmarky a zkoumáme některé z jedinečných vlastností včetně detekce funkčních slov, detekce polyemozních slov a některý vhled do interpretovatelnosti poskytované množinovými teoretickými operacemi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>I denne artikel giver vi et alternativt perspektiv på ordrepræsentationer ved at gentolke dimensionerne af vektorrummet i et ord, der indlejres som en samling af funktioner. I denne nyfortolkning normaliseres hver komponent i ordet vektor mod alle ordvektorer i ordforrådet. Denne idé giver os nu mulighed for at se hver vektor som en n-tuple (beslægtet med et fuzzy sæt), hvor n er dimensionen af ordet repræsentation og hvert element repræsenterer sandsynligheden for ordet besidder en funktion. Faktisk muliggør denne repræsentation brugen af fuzzy sæt teoretiske operationer, såsom union, skæring og forskel. I modsætning til tidligere forsøg viser vi, at denne repræsentation af ord giver et begreb om lighed, der i sig selv er asymmetrisk og dermed tættere på menneskelige lighedsdomme. Vi sammenligner ydeevnen af denne repræsentation med forskellige benchmarks, og undersøger nogle af de unikke egenskaber, herunder funktion orddetektion, detektion af polystemøse ord og noget indsigt i fortolkningen af sætteteoretiske operationer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In diesem Beitrag stellen wir eine alternative Perspektive auf Wortdarstellungen zur Verfügung, indem wir die Dimensionen des Vektorraums einer Worteinbettung als Sammlung von Merkmalen neu interpretieren. Bei dieser Neuinterpretation wird jede Komponente des Wortvektors gegenüber allen Wortvektoren im Vokabular normalisiert. Diese Idee erlaubt es uns nun, jeden Vektor als n-Tupel (ähnlich einer unscharfen Menge) zu betrachten, wobei n die Dimensionalität der Wortdarstellung ist und jedes Element die Wahrscheinlichkeit repräsentiert, dass das Wort ein Merkmal besitzt. Tatsächlich ermöglicht diese Darstellung die Verwendung von fuzzy set theoretischen Operationen, wie Vereinigung, Schnittmenge und Differenz. Im Gegensatz zu früheren Versuchen zeigen wir, dass diese Darstellung von Wörtern einen Begriff von Ähnlichkeit liefert, der inhärent asymmetrisch ist und daher näher an menschlichen Ähnlichkeitsurteilen ist. Wir vergleichen die Leistung dieser Repräsentation mit verschiedenen Benchmarks und untersuchen einige der einzigartigen Eigenschaften, einschließlich Funktionsworterkennung, Erkennung polyemotionaler Wörter und einige Einblicke in die Interpretierbarkeit von mengentheoretischen Operationen.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Στην παρούσα εργασία, παρέχουμε μια εναλλακτική προοπτική για τις αναπαραστάσεις λέξεων, επανερμηνεύοντας τις διαστάσεις του διανυσματικού χώρου μιας λέξης που ενσωματώνεται ως συλλογή χαρακτηριστικών. Σε αυτή την επανερμηνεία, κάθε συστατικό του διανύσματος της λέξης κανονικοποιείται σε σχέση με όλα τα διανύσματα λέξεων στο λεξιλόγιο. Αυτή η ιδέα μας επιτρέπει τώρα να δούμε κάθε διάνυσμα ως ένα N-Tuple (παρόμοιο με ένα ασαφές σύνολο), όπου n είναι η διαστασιμότητα της λέξης αναπαράσταση και κάθε στοιχείο αντιπροσωπεύει την πιθανότητα της λέξης να κατέχει ένα χαρακτηριστικό. Πράγματι, αυτή η αναπαράσταση επιτρέπει τη χρήση θεωρητικών λειτουργιών ασαφής συνόλου, όπως η ένωση, η τομή και η διαφορά. Σε αντίθεση με προηγούμενες προσπάθειες, δείχνουμε ότι αυτή η αναπαράσταση των λέξεων παρέχει μια έννοια ομοιότητας η οποία είναι εγγενώς ασύμμετρη και ως εκ τούτου πιο κοντά στις ανθρώπινες εκτιμήσεις ομοιότητας. Συγκρίνουμε την απόδοση αυτής της αναπαράστασης με διάφορα κριτήρια αναφοράς, και εξερευνούμε μερικές από τις μοναδικές ιδιότητες, συμπεριλαμβανομένης της ανίχνευσης λέξεων συνάρτησης, της ανίχνευσης πολυσυναισθηματικών λέξεων, και κάποια κατανόηση της ερμηνείας που παρέχεται από τις θεωρητικές λειτουργίες συνόλων.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>En este artículo, ofrecemos una perspectiva alternativa sobre las representaciones de palabras, reinterpretando las dimensiones del espacio vectorial de una palabra incrustada como una colección de características. En esta reinterpretación, cada componente del vector de palabras se normaliza con respecto a todos los vectores de palabras del vocabulario. Esta idea ahora nos permite ver cada vector como una n-tupla (similar a un conjunto difuso), donde n es la dimensionalidad de la representación de la palabra y cada elemento representa la probabilidad de que la palabra posea una característica. De hecho, esta representación permite el uso de operaciones teóricas de conjuntos difusos, como unión, intersección y diferencia. A diferencia de intentos anteriores, demostramos que esta representación de palabras proporciona una noción de similitud que es inherentemente asimétrica y, por lo tanto, más cercana a los juicios de similitud humana. Comparamos el rendimiento de esta representación con varios puntos de referencia y exploramos algunas de las propiedades únicas, incluida la detección de palabras de función, la detección de palabras polisémicas y algunos conocimientos sobre la interpretabilidad que proporcionan las operaciones teóricas de conjuntos.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Käesolevas töös pakume alternatiivset perspektiivi sõnade esitustele, tõlgendades uuesti vektoriruumi mõõtmeid sõna manustamisel funktsioonide kogumina. Selles ümbertõlgendamises normaliseeritakse sõnavaraktori iga komponent kõigi sõnavaraktori sõnavaraktorite suhtes. See idee võimaldab meil nüüd vaadata iga vektorit n-tuplina (sarnane udusele hulgale), kus n on sõna representatsiooni dimensioonilisus ja iga element esindab sõna omamise tõenäosust. Tõepoolest, see esitamine võimaldab kasutada hägune hulk teoreetilisi operatsioone, nagu liit, ristumine ja erinevus. Erinevalt varasematest katsetest näitame, et see sõnade esitamine annab sarnasuse mõiste, mis on olemuslikult asümmeetriline ja seega lähemal inimese sarnasuse otsustele. Me võrdleme selle esituse jõudlust erinevate võrdlusnäitajatega ja uurime mõningaid unikaalseid omadusi, sealhulgas funktsioonisõna tuvastamist, polüsemoossete sõnade tuvastamist ja mõningast ülevaadet komplekti teoreetiliste operatsioonide tõlgendatavusest.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>در این کاغذ، ما یک نگاه تغییر در مورد نمایش‌های کلمه را به عنوان مجموعه‌ی ویکتوری به عنوان مجموعه‌ی ویکتوری تغییر می‌دهیم. در این تغییرات، هر قسمتی از ویکتور کلمه نسبت به تمام ویکتور کلمه‌ها در کلمه‌ای معمولاً متعادل می‌شود. این ایده به ما اجازه می دهد که هر vektor را به عنوان یک مجموعه n-tuple ببینیم (مانند یک مجموعه غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر غیر در حقیقت، این نمایش به استفاده از عملیات نظریه‌ای که به عنوان اتحادیه، تقسیم و تفاوت می‌دهد اجازه می‌دهد. برخلاف تلاش قبلی، نشان می دهیم که این نمایش کلمات یک نظر شبیه‌ای را می‌دهد که در اصل شبیه‌ای است و بنابراین به حکم‌های شبیه‌ای انسان نزدیک تر است. ما عملکرد این نمایش را با برچسب‌های مختلف مقایسه می‌کنیم، و بعضی از ویژه‌های متفاوتی را که شامل شناسایی کلمه‌های فعالیت، شناسایی کلمه‌های متفاوتی، و بعضی مشاهده‌ها در تعبیر قابلیت توسط عملکرد‌های نظریه‌ای قرار داده می‌</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tässä työssä tarjoamme vaihtoehtoisen näkökulman sanaesityksiin tulkitsemalla uudelleen sanan upottamisen vektoriavaruuden ulottuvuudet ominaisuuksien kokoelmana. Tässä uudelleentulkinnassa sanavektorin jokainen komponentti normalisoidaan sanaston kaikkia sanavektoreita vastaan. Tämän idean avulla voimme nyt tarkastella jokaista vektoria n-tuplana (samankaltainen sumea joukko), jossa n on sanan edustuksen ulottuvuus ja jokainen elementti edustaa todennäköisyyttä, että sana omistaa ominaisuuden. Itse asiassa tämä esitys mahdollistaa fuzzy joukko teoreettisia toimintoja, kuten liitos, leikkaus ja ero. Toisin kuin aikaisemmat yritykset, osoitamme, että tämä sanojen esittäminen tarjoaa samankaltaisuuden käsitteen, joka on luonnostaan epäsymmetrinen ja siten lähempänä ihmisen samankaltaisuusarvioita. Vertaamme tämän esityksen suorituskykyä erilaisiin vertailuarvoihin ja tutkimme joitain ainutlaatuisia ominaisuuksia, kuten funktiosanojen havaitsemista, polyemoisten sanojen havaitsemista ja joitakin näkemyksiä joukkoteoreettisten operaatioiden tulkinnasta.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Dans cet article, nous proposons une perspective alternative sur les représentations de mots, en réinterprétant les dimensions de l'espace vectoriel d'un incorporation de mots comme un ensemble de caractéristiques. Dans cette réinterprétation, chaque composant du vecteur de mot est normalisé par rapport à tous les vecteurs de mots du vocabulaire. Cette idée nous permet maintenant de voir chaque vecteur comme un n-uplet (similaire à un ensemble flou), où n est la dimensionnalité de la représentation du mot et chaque élément représente la probabilité que le mot possède une caractéristique. En effet, cette représentation permet d'utiliser des opérations théoriques d'ensembles flous, telles que l'union, l'intersection et la différence. Contrairement aux tentatives précédentes, nous montrons que cette représentation des mots fournit une notion de similitude qui est intrinsèquement asymétrique et donc plus proche des jugements de similitude humaine. Nous comparons les performances de cette représentation avec divers points de référence et explorons certaines des propriétés uniques, notamment la détection de mots de fonction, la détection de mots polysémiques et un aperçu de l'interprétabilité fournie par les opérations théoriques des ensembles.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Sa pháipéar seo, cuirimid peirspictíocht mhalartach ar fáil ar léirithe focal, trí thoisí an spáis veicteora a bhaineann le neadú focal a athléiriú mar bhailiúchán gnéithe. San athléiriú seo, normalaítear gach comhpháirt den fhocal veicteoir i gcoinne gach veicteoir focal sa stór focal. Ligeann an smaoineamh seo dúinn anois féachaint ar gach veicteoir mar n-tuple (cosúil le tacair doiléir), áit arb é n toiseachas léiriú an fhocail agus seasann gach eilimint don dóchúlacht go bhfuil gné ag an bhfocal. Go deimhin, cuireann an léiriú seo ar chumas oibríochtaí teoiriciúla tacair doiléir a úsáid, amhail aontas, trasnú agus difríocht. Murab ionann agus iarrachtaí roimhe seo, léirímid go soláthraíonn an léiriú seo ar fhocail nóisean cosúlachta atá neamhshiméadrach ó dhúchas agus mar sin níos gaire do bhreithiúnais chosúlachta daonna. Déanaimid comparáid idir feidhmíocht na hionadaíochta seo agus tagarmharcanna éagsúla, agus déanaimid iniúchadh ar roinnt de na hairíonna uathúla lena n-áirítear brath focal feidhme, braite focail ilghnéitheacha, agus roinnt léargas ar an inléiritheacht a sholáthraíonn oibríochtaí teoiriciúla socraithe.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In this paper, we provide an alternate perspective on word representations, by reinterpreting the dimensions of the vector space of a word embedding as a collection of features. @ info: whatsthis Wannan idãnun yanzu yana yarda mu nuna kõwa mai shiryarwa kamar n-tipple (akin da wani set mai zartar da aiki), inda n ke da sifilanci n a maganar kuma duk ƙanshi na ƙayyade sannanan maganar da ya ƙunsa da wani zafi. In da gaske, wannan shirin zai iya amfani da aikin mai zartar da amfani da matsayin teori, kamar shirin kwamfyuta, guda da sãɓãni. Babu motsi da jarrabi da suka gabãta, Munã nuna cewa wannan mai gayarwa ga kalmõmi yana da wani noti na daidaita wanda ke cikin asymmetric da kuma daga wannan yana makusanta ga masu daidaita ga mutane. Kana samfani da aikin wannan rubutu da mistakardan misãlai masu yawa, kuma Munã samfani wasu properties na daban, kamar kunnufi maganar aiki, da gane magana na Polsemi, da wani gane cikin fassarar da aka ƙayyade aikin teori.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>בעיתון הזה, אנחנו מספקים פרספקטיבה חלופית על מיצוגי מילים, על ידי להפריע מחדש את המימדים של מרחב הוקטורים של מילה מוקפת כאוסף של תכונות. בפרשנות מחדש הזאת, כל רכיב של הוקטור המילה נורמלי נגד כל הוקטורים המילים במילים. הרעיון הזה מאפשר לנו עכשיו לראות כל ווקטור כn-כפול (דומה לקבוצה מעורפלת), שבו n הוא המימד של מייצג המילה וכל אלמנט מייצג את הסבירות של המילה שיש לה תכונה. למעשה, היציגה הזאת מאפשרת להשתמש במבצעים תיאורטיים מסודרים, כמו איגוד, חיצום וההבדל. בניגוד לנסיונות קודמות, אנו מראים שהמייצג הזה של מילים מספק רעיון של דמיון שהוא באופן טבעי אסימטרי ולכן קרוב יותר לשיפוטים של דמיון אנושי. We compare the performance of this representation with various benchmarks, and explore some of the unique properties including function word detection, detection of polysemous words, and some insight into the interpretability provided by set theoretic operations.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>इस पेपर में, हम शब्दों के प्रतिनिधित्व पर एक वैकल्पिक परिप्रेक्ष्य प्रदान करते हैं, सुविधाओं के संग्रह के रूप में एम्बेडिंग शब्द के वेक्टर स्पेस के आयामों को फिर से व्याख्या करके। इस पुनर्व्याख्या में, शब्द वेक्टर के प्रत्येक घटक को शब्दावली में सभी शब्द वैक्टरों के खिलाफ सामान्यीकृत किया जाता है। यह विचार अब हमें प्रत्येक वेक्टर को एन-टुपल (एक फजी सेट के समान) के रूप में देखने की अनुमति देता है, जहां एन शब्द प्रतिनिधित्व की आयामीता है और प्रत्येक तत्व एक विशेषता रखने वाले शब्द की संभावना का प्रतिनिधित्व करता है। दरअसल, यह प्रतिनिधित्व फजी सेट सैद्धांतिक संचालन, जैसे संघ, प्रतिच्छेदन और अंतर के उपयोग को सक्षम बनाता है। पिछले प्रयासों के विपरीत, हम दिखाते हैं कि शब्दों का यह प्रतिनिधित्व समानता की धारणा प्रदान करता है जो स्वाभाविक रूप से असममित है और इसलिए मानव समानता के फैसले के करीब है। हम विभिन्न बेंचमार्क के साथ इस प्रतिनिधित्व के प्रदर्शन की तुलना करते हैं, और फ़ंक्शन वर्ड डिटेक्शन, पॉलीसेमस शब्दों का पता लगाने और सेट सैद्धांतिक संचालन द्वारा प्रदान की गई व्याख्याक्षमता में कुछ अंतर्दृष्टि सहित कुछ अद्वितीय गुणों का पता लगाते हैं।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>U ovom papiru pružamo alternativnu perspektivu predstavljanja riječi, ponovno pretvaranjem dimenzija vektorskog prostora riječi uključujući kao kolekciju funkcija. U ovoj ponovnoj pretvaranju, svaka komponenta riječnog vektora normalizira se protiv svih riječnih vektora u rečniku. Ova ideja nam sada omogućava da gledamo svaki vektor kao n-tuple (sličan n a fuzzy set), gdje n je dimenzionalnost predstavljanja riječi i svaki element predstavlja vjerojatnost riječi koja posjeduje funkciju. Zapravo, ova predstava omogućava korištenje neobičnih teorijskih operacija, poput sindikata, prekidanja i razlike. Za razliku od prethodnih pokušaja, pokazujemo da ova predstavljanje riječi pruža pojam sličnosti koja je inherentno asimetrična i stoga bliže osuđivanju ljudske sličnosti. Uspoređujemo učinkovitost te predstave s različitim kriterijama, i istražujemo neke jedinstvene vlasti uključujući otkrivanje funkcionalnih riječi, otkrivanje polizemnih riječi, i neke uvide o interpretabilnosti pruženoj teoretičkim operacijama.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ebben a tanulmányban alternatív perspektívát nyújtunk a szóreprezentációkra, úgy, hogy újraértelmezzük egy szó vektortérének dimenzióit, mint jellemzők gyűjteményét. Ebben az újraértelmezésben a szó vektorának minden összetevője normalizálódik a szókincs összes vektorával szemben. Ez az ötlet lehetővé teszi, hogy minden vektort n-tuple-ként tekintsünk (hasonló egy fuzzy halmazhoz), ahol n a szó ábrázolásának dimenziója és minden elem azt a valószínűséget jelenti, hogy a szó rendelkezik egy funkcióval. Valójában ez az ábrázolás lehetővé teszi a fuzzy halmaz elméleti műveletek használatát, mint például unió, metszés és különbség. A korábbi próbálkozásokkal ellentétben azt mutatjuk, hogy ez a szavak ábrázolása olyan hasonlóság fogalmát biztosítja, amely eredendően aszimmetrikus, és így közelebb kerül az emberi hasonlósági ítéletekhez. Összehasonlítjuk ennek az ábrázolásnak a teljesítményét különböző referenciaértékekkel, és feltárjuk néhány egyedi tulajdonságot, beleértve a függvényszó felismerését, a poliszemózus szavak felismerését, valamint a halmazelméleti műveletek értelmezhetőségét.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Այս թղթի մեջ մենք տալիս ենք բառերի ներկայացումների փոխարինական տեսանկյուն, վերարտացոլով վեկտորի տարածության չափերը բառի ներառման որպես հատկանիշների հավաքածու: In this reinterpretation, every component of the word vector is normalized against all the word vectors in the vocabulary. Այս գաղափարը հիմա թույլ է տալիս մեզ տեսնել յուրաքանչյուր վեկտոր որպես n-անգամ (նման է խառնաշփոթ համակարգին), որտեղ n բառի ներկայացման չափսերը և յուրաքանչյուր տարր ներկայացնում է բառի հավանականությունը, որն ունի հատկություն: Իրականում, այս ներկայացումը հնարավորություն է տալիս օգտագործել խառնաշփոթ տեսական գործողություններ, ինչպիսիք են միավորումը, խաչը և տարբերությունը: Ի տարբերություն նախորդ փորձերին, մենք ցույց ենք տալիս, որ բառերի ներկայացումը ստեղծում է նմանության գաղափար, որը բնական անհամաչափ է և հետևաբար ավելի մոտ մարդկային նմանության դատողություններին: Մենք համեմատում ենք այս ներկայացումի արտադրությունը տարբեր համեմատային նպատակների հետ և ուսումնասիրում ենք որոշ առանձնահատկություններ, ներառյալ ֆունկցիոնալ բառերի հայտնաբերումը, պոլիզեմային բառերի հայտնաբերումը և որոշ ընկալումներ տեսական գործողությունների միջո</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Dalam kertas ini, kami menyediakan perspektif alternatif pada representation kata, dengan menggambarkan kembali dimensi ruang vektor dari sebuah kata yang memasukkan sebagai koleksi fitur. Dalam interpretasi ulang ini, setiap komponen dari vektor kata normalisasi melawan semua vektor kata dalam vokabular. Ide ini sekarang memungkinkan kita untuk melihat setiap vektor sebagai n-tuple (mirip dengan set kabur), di mana n adalah dimensionalitas representation kata dan setiap elemen mewakili kemungkinan kata yang memiliki fitur. Sebenarnya, perwakilan ini memungkinkan penggunaan operasi teori set kabur, seperti union, intersection dan perbedaan. Tidak seperti percobaan sebelumnya, kami menunjukkan bahwa perwakilan kata ini memberikan gagasan persamaan yang secara alami tidak simetri dan oleh itu lebih dekat dengan penilaian persamaan manusia. Kami membandingkan prestasi representation ini dengan berbagai benchmark, dan mengeksplorasi beberapa properti unik termasuk deteksi kata fungsi, deteksi kata polisemus, dan beberapa pandangan ke dalam interpretabilitas yang diberikan oleh set operasi teori.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In questo articolo, forniamo una prospettiva alternativa sulle rappresentazioni di parole, reinterpretando le dimensioni dello spazio vettoriale di una parola che incorpora come una raccolta di caratteristiche. In questa reinterpretazione, ogni componente del vettore della parola viene normalizzato rispetto a tutti i vettori della parola nel vocabolario. Questa idea ci permette ora di vedere ogni vettore come una n-tupla (simile ad un insieme sfocato), dove n è la dimensionalità della rappresentazione della parola e ogni elemento rappresenta la probabilità che la parola possieda una caratteristica. Infatti, questa rappresentazione consente l'uso di operazioni teoriche di set fuzzy, come unione, intersezione e differenza. A differenza dei tentativi precedenti, mostriamo che questa rappresentazione delle parole fornisce una nozione di somiglianza intrinsecamente asimmetrica e quindi più vicina ai giudizi di somiglianza umana. Confrontiamo le prestazioni di questa rappresentazione con vari parametri di riferimento ed esploriamo alcune delle proprietà uniche tra cui il rilevamento delle parole funzione, il rilevamento di parole polisemose e alcune informazioni sull'interpretabilità fornita dalle operazioni teoriche degli insiemi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>本稿では、単語埋め込みのベクトル空間の次元を特徴の集合として再解釈することにより、単語表現に関する別の視点を提供する。 この再解釈では、単語ベクトルのすべての成分は、語彙内のすべての単語ベクトルに対して正規化される。 このアイデアにより、各ベクトルをnタプル（曖昧な集合に似ている）と見なすことができます。ここで、nは単語表現の次元数であり、各要素は、特徴を持つ単語の確率を表します。 実際、この表現は、結合、交差、差分などのファジィ集合論的演算の使用を可能にする。 これまでの試みとは異なり、この言葉の表現は、本質的に非対称であり、したがって人間の類似性の判断に近い類似性の概念を提供することを示している。 この表現のパフォーマンスを様々なベンチマークと比較し、機能単語の検出、多義的単語の検出、およびセット理論的操作によって提供される解釈可能性に関するいくつかの洞察を含む固有の特性のいくつかを探索します。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Enter the vector space of a word To This idée nung iné permet us to view every vector as a n n-taple (like a FBI set), Where n is the size of the word representation and every item represents the likely of the word Open source Awak dhéwé éntuk kiper perbudhak, kita ngomatngon kuwi tindakan nyebuturan gambar nggawe sapa ngono kuwi duluran sing gak bener tentang karo akeh apik lan dadi iki sak duluran gambar uwong. Awak dhéwé nggawe geraraning nggawe representasi iki gambar nggambar aturan kanggo ngilangno karo perusahaan winih sing nyimpen, gambar nggambar kelas kuwi operasi layar, jatatan kelas polisemus lan kelas pangrungu nggawe gerarané perusahaan theoretik.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ამ გვერდიში, ჩვენ გვაქვს სხვადასხვა პერსპექტიკური პერსპექტიკური სიტყვების გამოსახულების განზომილებების განზომილებით, რომლებიც სიტყვების კოლექტიკური განზომილებები ამ განსხვავებაში, ყველა სიტყვის გვექტორის კომპონენტი ნორმალიზებულია ყველა სიტყვის გვექტორის განმავლობაში. ამ იდეა ახლა გვაქვს, რომ ყოველ გვეკტორის n-tuple (როგორც მუშაობელი ნაწილი), სადაც n არის სიტყვის გამოსახულების განზომილებელობა და ყოველ ელემენტი გამოსახულება სიტყვის შესაძლებლობა. ეს გამოყენება შესაძლებელია გამოყენება თეორეტიკური операциები, როგორც საერთო, საშუალოდ და განსხვავება. წინა პროცემების განმავლობაში, ჩვენ ჩვენ ჩვენ ჩვენ აჩვენებთ, რომ ეს სიტყვების გამოსახულება იყოს სხვადასხვების წარმოდგენა, რომელიც საშუალოდ არიმეტრიული და ამიტომ ადამიანის სხვად ჩვენ ამ გამოსახულების გამოსახულებას განსხვავებული ბენქმარკებით შემდგენებთ და განსხვავებთ განსხვავებული განსხვავებების განსხვავებას, ფუნქციის სიტყვების განსხვავებას, პოლისემის სიტყვების განსხვავებას</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Бұл қағазда сөздерді түсіндіру үшін басқа перспективті келтіреміз. Бұл сөздерді қайта түсіндіру үшін ендірілген сөздердің өлшемдерін қайта түсіндіреміз. Бұл қайта аудару үшін сөздің векторының әрбір компоненті сөздің векторының барлық сөздеріне қарсы нормализацияланады. Бұл идея қазір біз әрбір векторды n- tuple ретінде қарауға мүмкіндік береді (бұл бұл бұл бұл бұл бұл бұл бұл бұл бұл бұл бұл бұл бұл бұл бұл бұл бұл бұл бұл бұл б Шынымен, бұл түсініктеме теоретикалық операцияларды қолдану мүмкіндігін мүмкіндік береді, мысалы, бірлік, бөлшектеу және айырмашылығы. Алдыңғы әрекеттерге сәйкес, біз сөздердің көрсетілімі бұл сөздердің ұқсас тәртіпсіздігін көрсетеді, сондықтан адамдардың ұқсас тәртіпсіздігіне жақын көрсетеді. Біз бұл кескіндікті түрлі белгілерден салыстырып, функциялық сөздерді анықтау, полиземді сөздерді анықтау және теоретикалық операцияларды орнату үшін кейбір түсініктемелерді қалаймыз.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>본고에서 우리는 단어가 삽입된 벡터 공간의 차원을 하나의 특징으로 재해석함으로써 단어의 표시에 또 다른 시각을 제공했다.이런 재해석에서 단어 벡터의 모든 구성 부분은 어휘표의 모든 단어 벡터를 규범화한 것이다.이 아이디어는 현재 우리가 모든 벡터를 하나의 n원조(모호집과 유사)로 볼 수 있게 한다. 그 중에서 n은 단어가 표시하는 차원이고 모든 요소는 단어가 특징을 가진 확률을 나타낸다.사실상 이런 표시는 모호 집합론 연산을 사용할 수 있게 한다. 예를 들어 병합, 교화차 등이다.이전의 시도와 달리 우리는 이런 단어의 표시가 내재된 비대칭적인 유사성 개념을 제공하기 때문에 인류의 유사성 판단에 더욱 가깝다는 것을 보여준다.우리는 이러한 표현법의 성능을 각종 기준과 비교하고 허사 검측, 다의어 검측, 집합론 조작에 대한 해석 가능한 견해를 포함한 독특한 특성을 탐색했다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Šiame dokumente teikiame alternatyvią perspektyvą žodžių atspindėjimų atžvilgiu, iš naujo aiškindami vektoriaus erdvės matmenis žodžio įterpimo kaip savybių rinkinio. Šiame reinterpretacijoje kiekvienas žodžio vektoriaus komponentas normalizuojamas prieš visus žodžio vektorius žodyne. Ši idėja dabar leidžia mums žiūrėti į kiekvieną vektorių kaip n-dublą (panašų į apgaulingą rinkinį), kur n yra žodžio reprezentacijos matmenys ir kiekvienas element as rodo žodžio, turinčio savybę, tikimybę. Iš tiesų, šis atstovavimas leidžia naudoti netinkamas teorines operacijas, pvz., sąjungą, skerspjūvį ir skirtumą. Priešingai nei ankstesni bandymai, mes rodome, kad šis žodžių atstovavimas suteikia panašumo sąvoką, kuri iš esmės yra asimetriška ir todėl artimesnė žmogaus panašumo vertinimams. Palyginame šio atvaizdavimo rezultatus su įvairiais lyginamaisiais rodikliais ir tiriame kai kurias unikalias savybes, įskaitant funkcijos žodžių aptikimą, polizieminių žodžių aptikimą ir tam tikrą supratimą apie aiškinamumą, kurį suteikia teorinės operacijos.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Во овој весник, ние обезбедуваме алтернативна перспектива за претставувањата на зборовите, со реинтерпретација на димензиите на векторниот простор на зборот вграден како колекција на карактеристики. In this reinterpretation, every component of the word vector is normalized against all the word vectors in the vocabulary. Оваа идеја сега ни овозможува да го гледаме секој вектор како n-tuple (сличен на нејасниот сет), каде n е димензионалноста на репрезентацијата на зборот и секој елемент ја претставува веројатноста на зборот кој поседува функционалност. Всушност, ова претставување овозможува употреба на теоретски операции, како што се синдикат, премин и разлика. За разлика од претходните обиди, покажуваме дека ова претставување на зборовите обезбедува идеја за сличност која е природно асиметрична и оттука поблиску до судиите за човечка сличност. Ги споредуваме изведувањата на оваа претстава со различни референтни значки, и истражуваме некои од уникатните сопствености вклучувајќи детекција на функционалните зборови, детекција на полисемни зборови, и некои погледи во интерпретабилноста обезбедена од поставени теоретички опера</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ഈ പത്രത്തില്‍, വാക്കിന്റെ പ്രതിനിധികളെ വെക്റ്റര്‍ സ്ഥലത്തിന്റെ ഭാഗങ്ങള്‍ വീണ്ടും ചേര്‍ക്കുന്ന വാക്കുകളുടെ വിശേഷത്തിന്റെ വ്യത്യസ ഈ വാക്ക് വെക്റ്ററിന്റെ എല്ലാ ഭാഗങ്ങളും വാക്ക് വെക്റ്ററുകള്‍ക്കെതിരെ സാധാരണമാക്കിയിരിക്കുന്നു. ഈ ഐഡിയ ഇപ്പോള്‍ നമ്മള്‍ ഓരോ വെക്റ്റര്‍ക്കും n-ടുപ്പിള്‍ ആയി കാണാന്‍ അനുവദിക്കുന്നു. വാക്കിന്റെ പ്രതിനിധിയുടെ സ്ഥിതിയില്‍ നിന്നും വാക്കിന്റെ സാധ സത്യത്തില്‍, ഈ പ്രതിനിധിയില്‍ പ്രദര്‍ശിപ്പിക്കുന്നത് തിയോറിറ്റിക് പ്രവര്‍ത്തനങ്ങള്‍ സജ്ജീകരിക്കുന്നത് പോലെ മുമ്പുള്ള ശ്രമം വ്യത്യസ്തമായിരുന്നു, ഈ വാക്കുകളുടെ പ്രതിനിധിയില്‍ ഒരുപോലെയുള്ള ഒരു ആശയം കൊടുക്കുന്നു. അതിനാല്‍ അതിനാല്‍ മനുഷ്യരുട ഈ പ്രതിനിധിയുടെ പ്രഭാവം വ്യത്യസ്ത ബെന്‍മാര്‍ക്കുകളോടൊപ്പം താല്‍പ്പിക്കുകയും, ചില പ്രതിനിധികള്‍ പരിശോധിക്കുകയും, ഫങ്ഷന്‍ വാക്ക് കണ്ടുപിടിക്കു</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Энэ цаасан дээр бид үг илэрхийллийн тухай өөрчлөлт харагдаж, өөрчлөгдөж буй хэмжээсүүдийг өөрчлөгдөж, өөрчлөгдөж буй хэмжээсүүдийн хэмжээсүүдийг өөрчлөгдөж байна. Энэ дахин ойлголтын тулд, үгийн векторын бүх хэсэг нь үгийн бүх векторуудын эсрэг нормалтай байдаг. Энэ санаа одоо бидэнд вектор бүрийг n-tuple гэж үзэх боломжтой болгодог. n нь үгийн илэрхийллийн хэмжээсүүд ба элемент бүр үгийн магадлалыг илэрхийлдэг. Үнэндээ энэ илэрхийлэл нь холбоотой, холбоотой, ялгааг ашиглаж чадна. Өмнөх хичээлийн эсрэгээр бид энэ үгнүүдийн үзүүлэлт нь нэг төстэй төстэй ойлголтыг харуулж байна. Энэ нь хүний төстэй төстэй шүүмжүүдэд илүү ойрхон байдаг. Бид энэ илтгэлийн үйл ажиллагааг олон тоонуудыг харьцуулж, функцын үг олох, полизим үг олох, теоретикийн үйл ажиллагаанд өгсөн утгыг олох боломжтой байдлыг судалж байна.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Dalam kertas ini, kita menyediakan perspektif alternatif pada perwakilan perkataan, dengan menerangkan semula dimensi ruang vektor perkataan yang ditambah sebagai koleksi ciri-ciri. Dalam penerangan semula ini, setiap komponen vektor perkataan normalisasi melawan semua vektor perkataan dalam vokbulari. Idea ini kini membolehkan kita melihat setiap vektor sebagai n-tuple (sama dengan set berlebihan), di mana n ialah dimensi perwakilan perkataan dan setiap elemen mewakili kebarangkalian perkataan yang mempunyai ciri. Indeed, this representation enables the use fuzzy set theoretic operations, such as union, intersection and difference. Unlike previous attempts, we show that this representation of words provides a notion of similarity which is inherently asymmetric and hence closer to human similarity judgements. Kami membandingkan prestasi perwakilan ini dengan berbagai tanda referensi, dan mengeksplorasi beberapa ciri-ciri unik termasuk pengesan perkataan fungsi, pengesan perkataan polisemus, dan beberapa pandangan ke dalam pengenalan yang diberikan oleh set operasi teori.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>F’dan id-dokument, nagħtu perspettiva alternattiva dwar ir-rappreżentazzjonijiet tal-kliem, billi ninterpretaw mill-ġdid id-dimensjonijiet tal-ispazju tal-vetturi ta’ kelma inkorporata bħala ġabra ta’ karatteristiċi. F’din l-interpretazzjoni mill-ġdid, kull komponent tal-kelma vector huwa normalizzat kontra l-kelma vectors kollha fil-vokabulari. This idea now allows us to view each vector as an n-tuple (akin to a fuzzy set), where n is the dimensionality of the word representation and each element represents the probability of the word possessing a feature. Tabilħaqq, din ir-rappreżentanza tippermetti l-użu ta’ operazzjonijiet teoretiċi ssettjati f’daqqa, bħall-unjoni, l-intersezzjoni u d-differenza. Għall-kuntrarju ta’ tentattivi preċedenti, nuru li din ir-rappreżentazzjoni tal-kliem tipprovdi kunċett ta’ similarità li huwa inerentement asimetriku u għalhekk eqreb lejn ġudizzji ta’ similarità umana. Aħna nqabblu l-prestazzjoni ta’ din ir-rappreżentazzjoni ma’ diversi punti ta’ riferiment, u nesploraw xi wħud mill-karatteristiċi uniċi inklużi l-individwazzjoni tal-kliem tal-funzjoni, l-individwazzjoni tal-kliem poliżimu, u xi ħarsa lejn l-interpretabbiltà pprovduta minn operazzjonijiet teoretiċi stabbiliti.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In dit artikel bieden we een alternatief perspectief op woordrepresentaties, door de afmetingen van de vectorruimte van een woord te herinterpreteren als een verzameling van kenmerken. Bij deze herinterpretatie wordt elke component van de woordvector genormaliseerd ten opzichte van alle woordvectoren in de woordenschat. Dit idee stelt ons nu in staat om elke vector te bekijken als een n-tupel (vergelijkbaar met een fuzzy set), waarbij n de dimensionaliteit van de woordweergave is en elk element de waarschijnlijkheid vertegenwoordigt dat het woord een kenmerk bezit. Inderdaad, deze representatie maakt het gebruik van fuzzy set theoretische operaties mogelijk, zoals vereniging, kruising en verschil. In tegenstelling tot eerdere pogingen laten we zien dat deze voorstelling van woorden een idee van gelijkenis biedt die inherent asymmetrisch is en dus dichter bij menselijke gelijkenisoordelen ligt. We vergelijken de prestaties van deze representatie met verschillende benchmarks, en onderzoeken enkele van de unieke eigenschappen, waaronder functiewoorddetectie, detectie van polyemotionele woorden, en enig inzicht in de interpreteerbaarheid van verzameltheoretische bewerkingen.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>I denne papiret gir vi ein alternativ perspektiv på ordrepresentasjonar ved å gjenoppretta dimensjonane av vektorrommet til eit ord innebygd som samling av funksjonar. I denne omsetjinga vert kvar komponent av ordvektoren normalisert mot alle ordvektorane i ordboka. Denne ideen gjer oss n å å sjå kvar vektor som n-tuple (liknande til eit utrygt sett), der n er dimensjonaliteten av ordrepresentasjonen og kvar element representerer sannsynligheten for ordet som har ein funksjon. Dette representasjonen slår på at bruken av tråd sett teoretiske operasjonar, som union, kryss av og forskjellen. I motsetjing til førre forsøk viser vi at denne representasjonen av ord gjev eit noe på likningar som er innehaldet asymmetrisk og derfor nærmere menneskelige forsøk. Vi samanliknar utviklinga av denne representasjonen med ulike benchmarker, og utforsk nokre av dei unike eigenskapane, inkludert funksjonsoppdaging av ord, oppdaging av polysemiske ord, og nokre innsikt i uttolkinga gjeven av teoretiske operasjonar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>W niniejszym artykule przedstawiamy alternatywną perspektywę reprezentacji słów poprzez reinterpretację wymiarów przestrzeni wektorowej osadzonego słowa jako zbiór cech. W tej reinterpretacji każdy składnik wektora słowa jest znormalizowany w stosunku do wszystkich wektorów słowa w słownictwie. Pomysł ten pozwala nam teraz spojrzeć na każdy wektor jako n-kropel (podobny do zbioru rozmytego), gdzie n jest wymiarowością reprezentacji słowa, a każdy element reprezentuje prawdopodobieństwo, że słowo posiada cechę. Rzeczywiście, ta reprezentacja umożliwia wykorzystanie operacji teoretycznych zbiorów rozmytych, takich jak unia, przecięcie i różnica. W przeciwieństwie do poprzednich prób, pokazujemy, że ta reprezentacja słów daje pojęcie podobieństwa, które jest z natury asymetryczne, a tym samym bliższe ludzkiej ocenie podobieństwa. Porównujemy wydajność tej reprezentacji z różnymi wskaźnikami referencyjnymi i badamy niektóre z unikalnych właściwości, w tym wykrywanie słów funkcyjnych, wykrywanie słów wielosemicznych i pewne wglądy w interpretowalność zapewnianą przez operacje teoretyczne zbiorów.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Neste artigo, fornecemos uma perspectiva alternativa sobre representações de palavras, reinterpretando as dimensões do espaço vetorial de uma incorporação de palavras como uma coleção de recursos. Nesta reinterpretação, cada componente do vetor de palavras é normalizado em relação a todos os vetores de palavras no vocabulário. Essa ideia agora nos permite ver cada vetor como uma n-tupla (semelhante a um conjunto fuzzy), onde n é a dimensionalidade da representação da palavra e cada elemento representa a probabilidade da palavra possuir uma característica. De fato, essa representação possibilita o uso de operações teóricas de conjuntos fuzzy, como união, interseção e diferença. Ao contrário de tentativas anteriores, mostramos que essa representação de palavras fornece uma noção de semelhança inerentemente assimétrica e, portanto, mais próxima dos julgamentos de semelhança humanos. Comparamos o desempenho dessa representação com vários benchmarks e exploramos algumas das propriedades exclusivas, incluindo detecção de palavras funcionais, detecção de palavras polissêmicas e algumas informações sobre a interpretabilidade fornecida pelas operações teóricas de conjuntos.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>În această lucrare, oferim o perspectivă alternativă asupra reprezentărilor cuvintelor, prin reinterpretarea dimensiunilor spațiului vectorial al unui cuvânt încorporat ca o colecție de caracteristici. În această reinterpretare, fiecare componentă a vectorului cuvântului este normalizată în raport cu toți vectorii de cuvânt din vocabular. Această idee ne permite acum să vedem fiecare vector ca un n-tuple (asemănător cu un set neclar), unde n este dimensiunea reprezentării cuvântului și fiecare element reprezintă probabilitatea ca cuvântul să aibă o caracteristică. Într-adevăr, această reprezentare permite utilizarea operațiunilor teoretice ale setului fuzzy, cum ar fi uniunea, intersecția și diferența. Spre deosebire de încercările anterioare, arătăm că această reprezentare a cuvintelor oferă o noțiune de similitudine care este inerent asimetrică și, prin urmare, mai aproape de judecățile de similitudine umane. Comparăm performanța acestei reprezentări cu diferite criterii de referință și explorăm unele dintre proprietățile unice, inclusiv detectarea cuvintelor funcționale, detectarea cuvintelor polisemoase și o perspectivă asupra interpretabilității oferite de operațiunile teoretice set.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>В этой статье мы представляем альтернативную точку зрения на представления слов, переосмысливая размеры векторного пространства вложения слов как совокупность признаков. В этой повторной интерпретации каждый компонент слова-вектора нормируется относительно всех слов-векторов в словаре. Эта идея теперь позволяет рассматривать каждый вектор как n-кортеж (сродни нечеткому множеству), где n - размерность представления слова и каждый элемент представляет вероятность того, что слово обладает признаком. Действительно, это представление позволяет использовать теоретические операции нечеткого множества, такие как объединение, пересечение и разность. В отличие от предыдущих попыток, мы показываем, что это представление слов обеспечивает понятие сходства, которое по своей сути асимметрично и, следовательно, ближе к суждениям о человеческом сходстве. Мы сравниваем производительность этого представления с различными критериями и исследуем некоторые уникальные свойства, включая обнаружение функциональных слов, обнаружение многозначных слов и некоторое понимание интерпретируемости, обеспечиваемой множеством теоретических операций.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>මේ පැත්තේ, අපි වචන ප්‍රතිරූපයක් ගැන වෙනස් ප්‍රතිරූපයක් දෙනවා, වචන ප්‍රතිරූපයක් වගේ වෙක්ටර් අවසානයේ වචන අවසානයේ මේ ආපහු ප්‍රවේශනයේදී, වචන වෙක්ටර්ගේ හැම අංකයක්ම සාමාන්‍ය වෙක්ටර් වලින් වචන වෙක්ටර් වලට සාමාන්‍ය මේ අදහසය දැන් අපිට අවශ්‍ය කරන්න පුළුවන් හැම වෙක්ටර්ටර්ටර්ටර්ටර්ටර්ටර්ටර්ටර්ටර්ටර්ටර් n- ටුප්ල් වගේ බලන්න (පුළුවන් සෙට් වග ඇත්තටම, මේ ප්‍රතිනිධානය ප්‍රයෝජනය කරන්න පුළුවන් වෙන්න පුළුවන් විදිහට සාධාන්‍ය ව්‍යාපෘතික වැඩ අපි පෙන්වන්නේ මුලින් උත්සාහ කරපු විදියට, මේ වචනේ ප්‍රතිචාරයක් ප්‍රතිචාරයක් ප්‍රතිචාරයක් වෙනවා කියලා ප්‍රතිචාරයක් අපි මේ ප්‍රතිනිධානයේ විවිධ බෙන්ච්මාර්ක්ස් එක්ක සම්බන්ධ කරනවා, සමහර විශේෂ වචන පරික්ෂණය සමහර විශේෂ වචන පරික්ෂණය සමහර විශ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>V prispevku zagotavljamo alternativno perspektivo besednih predstavitev, tako da ponovno interpretiramo dimenzije vektorskega prostora besedne vdelave kot zbirko značilnosti. V tej ponovni razlagi se vsaka komponenta besednega vektorja normalizira glede na vse besedne vektorje v besedišču. Ta ideja nam zdaj omogoča, da vidimo vsak vektor kot n-tuplo (podobno meglenemu množici), kjer je n dimenzionalnost besedne reprezentacije in vsak element predstavlja verjetnost, da ima beseda značilnost. Ta predstavitev namreč omogoča uporabo teoretičnih operacij meglenih množic, kot so unija, presečišče in razlika. Za razliko od prejšnjih poskusov pokažemo, da ta predstavitev besed zagotavlja pojem podobnosti, ki je po sebi asimetričen in s tem bližje človeškim podobnim presojam. Učinkovitost te reprezentacije primerjamo z različnimi referenčnimi vrednostmi in raziskujemo nekatere edinstvene lastnosti, vključno z zaznavanjem funkcijskih besed, zaznavanjem poličemskih besed in nekaj vpogledov v interpretabilnost, ki jo zagotavljajo teoretične operacije množic.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Qoraalkan waxaynu ku siinaynaa aragti kale oo ku saabsan qofka hadalka la soo jeedo, kaas oo ku qoraya qaybaha goobta vectorka ee ereyga ku qoran waxyaabo badan. Qayb kasta oo qeyb ka mid ah waxqabadka ereyga waxaa lagu caadi karaa wax walba oo ka gees ah vectoryada hadalka ee hadalka ku qoran. Fikirkaasi wuxuu inagu ogolaan karaa inaan wax walbo ka aragno n-tijaab (sida saxda dhibaato ah), meesha ay ku jirto taxadirka hadalka, qayb kastana waxaa ka mid ah suurtagalka ereyga oo haysta tayo. Sida xaqiiqada ah muuqashadan waxaa suurtogal ah in isticmaalka la isticmaalayo la sameyn karo waxqabadyo cilmi ah, tusaale ahaan urur, kala duwan iyo kala duwan. Unlike previous attempts, we show that this representation of words provides a notion of similarity which is inherently asymmetric and hence closer to human similarity judgements. Dhaqashadan waxaynu isbarbardhignaa waxyaabaha kala duduwan, waxaana baaraynaa qaar gaar ah oo ah aqoonta hadalka shaqada, garitaanka hadalka polysemiga ah, iyo waxyaabaha qaar ka mid ah turjubaanka ay sameeyaan waxqabadka theoretika ah.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Në këtë letër, ne ofrojmë një perspektivë alternative mbi përfaqësimet e fjalëve, duke përsëritur dimensionet e hapësirës vectore të një fjale të përfshirë si një koleksion karakteristike. Në këtë përsëritje, çdo komponent i vektorit të fjalës është normalizuar kundër të gjitha vektorëve të fjalës në fjalorë. Kjo ide n a lejon tani të shohim çdo vektor si një n-tuple (si një set i ngatërruar), ku n është dimensionaliteti i përfaqësimit të fjalës dhe çdo element përfaqëson probabilitetin e fjalës që posedon një funksion. Në fakt, ky përfaqësim lejon përdorimin e operacioneve teorike të vështira, të tilla si bashkimi, ndërprerje dhe ndryshimi. Në ndryshim nga përpjekjet e mëparshme, ne tregojmë se ky përfaqësim i fjalëve ofron një koncept të ngjashmërisë që është në vetvete asimetrike dhe kështu më pranë gjykimeve të ngjashmërisë njerëzore. Ne e krahasojmë performancën e kësaj përfaqësimi me pika të ndryshme referimi dhe eksplorojmë disa nga pronësitë unike duke përfshirë zbulimin e fjalëve të funksionit, zbulimin e fjalëve polisemore dhe disa pamje në interpretueshmërinë e ofruar nga operacionet teorike të vendosura.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>U ovom papiru pružamo alternativnu perspektivu predstavljanja reèi, ponovno pretvaranjem dimenzija vektorskog prostora reèi koja se ukljuèuje kao kolekcija karakteristika. U ovoj reinterpretaciji, svaki komponent rečenog vektora se normalizira protiv svih rečenih vektora u rečniku. Ova ideja nam sada omogućava da gledamo svaki vektor kao n-tuple (sličan n a fuzzy set), gdje n je dimenzionalnost predstavljanja riječi i svaki element predstavlja verovatnoću reči koja posjeduje funkciju. Zapravo, ova predstava omogućava korištenje neobičnih teorijskih operacija, poput sindikata, prekidanja i razlike. Za razliku od prethodnih pokušaja, pokazujemo da ova predstavljanja reèi pruža pojam sliènosti koja je inherentno asimetrična i stoga bliže osuđivanju ljudske sliènosti. Uspoređujemo provedbu ove predstave sa različitim kriterijama, i istražujemo neke od jedinstvenih vlasništva uključujući otkrivanje funkcionalnih reči, otkrivanje polizemnih reči, i neke uvide o interpretabilnosti pruženoj teoretičkim operacijama.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>I den här uppsatsen ger vi ett alternativt perspektiv på ordrepresentationer genom att omtolka dimensionerna av vektorrymden hos ett ord som bäddas in som en samling funktioner. I denna omtolkning normaliseras varje komponent i ordvektorn mot alla ordvektorer i ordförrådet. Denna idé tillåter oss nu att se varje vektor som en n-tuple (besläktad med en fuzzy set), där n är dimensionen av ordet representation och varje element representerar sannolikheten för ordet innehar en funktion. Faktum är att denna representation möjliggör användning av fuzzy set teoretiska operationer, såsom union, skärning och skillnad. Till skillnad från tidigare försök visar vi att denna representation av ord ger en uppfattning om likhet som i sig är asymmetrisk och därmed närmare mänskliga likheter bedömningar. Vi jämför prestandan för denna representation med olika riktmärken, och utforskar några av de unika egenskaperna inklusive funktionsordsdetektion, detektering av polystemösa ord och viss insikt i tolkningen av uppsättningsteoretiska operationer.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Katika karatasi hii, tunatoa mtazamo mbadala wa uwakilishi wa maneno, kwa kuingiza upande wa nafasi ya vector wa neno linalojumuisha kama mkusanyiko wa tabia. Katika upande huu, kila sehemu ya vector wa neno linalazimika dhidi ya vector zote za maneno katika lugha hii. Wazo hili kwa sasa linaturuhusu kuona kila vector kama kituo cha n-tiba (akilinganisha n a seti yenye tatizo), ambapo kuna ukubwa wa uwakilishi wa neno na kila element inawakilisha uwezekano wa neno linalo tayari. Kwa hakika, uwakilishi huu unawezesha matumizi ya ajabu kutengeneza shughuli za nadharia, kama vile umoja, tofauti na tofauti. Tofauti na majaribio yaliyopita, tunaonyesha kuwa uwakilishi huu wa maneno yanatoa wazo la usawa wa watu ambao ni kwa kiasi kikubwa na hivyo karibu zaidi na maamuzi yanayofanana na binadamu. Tunawalinganisha ufanisi wa uwakilishi huu na misingi mbalimbali, na kutafuta baadhi ya utaalam wa kipekee ikiwa ni pamoja na kutambua neno la kazi, kutambua maneno ya kijamii, na baadhi ya uelewa wa tafsiri iliyotolewa na shughuli za nadharia.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>In this paper, we provide an alternate perspective on word representations, by reinterpreting the dimensions of the vector space of a word embedding as a collection of features. இந்த மீண்டும் பொருளில், வார்த்தை நெறியின் ஒவ்வொரு பொருளும் சொல்வளத்தின் வார்த்தை நெறிக்கும் எதிராக இயல்பாக இந்த கருத்து ஒவ்வொரு நெறியையும் n- துப்பீட்டாக பார்க்க அனுமதிக்கிறது (குறிப்பாக்கும் அமைப்புகளுக்கு, அதில் n என்பது வார்த்தை குறிப்பிடும் தனிப உண்மையில், இந்த குறிப்பிட்ட பயன்பாட்டை செயல்படுத்த முடியும், யூனியன், இடைவெட்டு மற்றும் வேறுபாடு முந்தைய முயற்சிகளை வித்தியாசமாக, இந்த வார்த்தைகளின் பிரதிநிதியை காட்டுகிறோம் என்பதை நாம் காண்பிக்கிறோம், அது உட்பொழுது ஒத்த நாம் இந்த குறிப்பிட்ட செயல்பாட்டை பல குறிப்புகளுடன் ஒப்பிடுகிறோம், செயல்பாடு வார்த்தையை கண்டுபிடிக்க, பலவிதமான வார்த்தைகளை கண்டுபிடிக்க</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bu kağıt içinde, kelime ifadeleri üzerinde başka bir perspektiv sunuyoruz, içinde bulunan bir kelime alanın vektör alanının ölçülerini bir toplantı olarak tekrar dönüştürerek. - - Bu tercüme, kelime vektörünün her parçası kelime vektörlerine karşı normaldir. Bu fikir şu and a her vektöre n-tuple gibi görünmemizi sağlar ve n kelime temsilcisinin ölçüsü ve her elemente bir özelliğin sahip olduğu kelimenin muhtemeleni gösterir. Çünkü bu representasyon, birlik, kesişikler we farklygy ýaly çalşyrlyk teoriýa işlerini mümkin edir. Önceki denemelere benzemediğimize göre, bu kelimelerin ifadesi içerisinde asymmetrik bir fikir sağlayan ve bu yüzden insan benzeri kararlarına daha yakın olduğunu gösteriyoruz. Biz bu temsilin etkinliğini farklı kayıtlar ile karşılaştırıp, fonksiyonlu kelime keşfetme, polizem kelimelerin tanımlaması ve teoretik operasyonlar tarafından verilen yorumluluklara göz önüne alıyoruz.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>اس کاغذ میں، ہم کلمات کی تصویر پر ایک دوسری نظر دیتے ہیں، ایک کلمات کی جگہ کے اندازے دوبارہ تغییر دیتے ہیں اس دوبارہ تفسیر میں، کلمات ویکتور کی ہر قسمت ویکتوری کے مقابلہ میں سارے کلمات ویکتوروں کے مقابلہ میں عام کیا جاتا ہے. یہ ایڈیو اب ہمیں ہر ویکتور کو n-tuple کے مطابق دیکھنے کی اجازت دیتا ہے، جہاں n کلمات کی تصویر ہے اور ہر عنصر کلمات کی تصویر کے مطابق ایک ویکتوری کے مطابق ہے. بے شک، یہ نمایش اسے مضبوط استعمال کرنا امکان دیتی ہے، جیسے اتحادیہ، متفرقہ اور تفرقہ. پہلے کی کوشش کے مطابق، ہم دکھاتے ہیں کہ یہ کلمات کی نمونش ایک ایسی نظریہ پیش کرتا ہے جو اس کے دل میں برابر ہے اور اسی طرح انسان کی برابری کے فیصلے سے زیادہ قریب ہے ہم اس نمایش کی عملکرد کو مختلف بنچم مارک سے مقایسہ کرتے ہیں، اور بعض مختلف خصوصیات کا تحقیق کرتے ہیں، فنقش کلمات شناسایی، پالیس کلمات کی شناسایی، اور بعض نظریہ نظریہ عملکرد کے ذریعہ تفسیر کی تعبیر کے ذریعہ۔</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bu qogʻozda, biz soʻzning tashkilotlarini o'zgartirish imkoniyatini o'zgartiraymiz va vektorning joylarini qaytadan qo'yish mumkin. Ushbu qaytadan qaytadan, so'zlar vektorining har bir komponent soʻzlarning hamma so'zlar vektorlariga qoʻllaniladi. Bu g'oya bizga har bir vectorni n-tutlik sifatida ko'rsatishga ruxsat beradi. Bu yerda so'zning chegaraligi va har bir element imkoniyatlarni qoʻllash mumkin. Hullas, bu tashkilotni foydalanish imkoniyatlariga, birlashtirish, birlashtirish va ўзгартириш imkoniyatini beradi. Oldingi jarayonlarni o'xshash ko'rsatganimiz, bu so'zlar tashkilotlarini ko'rsatumiz, bu asymmetrik va shunday qilib odamning bir xil xususiyatlariga яқин. Biz bu tashkilotning natijasini ko'plab bog'lamalar bilan birlashtiramiz, uning xossalarini qidirib, muloqat so'zlarni aniqlash, va bir necha narsalarni teoretik amallar qo'llash orzularini o'rganish mumkin.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Trong tờ giấy này, chúng tôi cung cấp một góc nhìn khác nhau về các biểu tượng từ, bằng cách tái hiểu lại các kích thước của các chiều của các chữ nhúng vào như một bộ sưu tập các tính năng. Trong phiên dịch lại này, mỗi thành phần của véc- tơ từ được tổng hợp lại với tất cả các véc- tơ từ trong từ. Ý tưởng n ày cho phép chúng ta xem mỗi véc- tơ như một v (giống với một bộ màu lục, nơi n là chiều không của từ đại diện và mỗi nguyên tố là xác suất của từ sở hữu một tính năng. Thật ra, sự đại diện này cho phép sử dụng các thao tác lí thuyết trên tập thất, như liên kết, giao nhau và khác nhau. Không giống như những nỗ lực trước đây, chúng tôi cho thấy rằng sự mô tả từ ngữ này mang lại một khái niệm về nét giống nhau vốn không đồng nhất và gần hơn so với các phán đoán về nét giống người. Chúng tôi so sánh hiệu quả của sự đại diện này với nhiều tiêu chuẩn khác nhau, và khám phá một số tính chất độc nhất, gồm khả năng phát hiện từ hàm, phát hiện từ dạng polysemous, và một số hiểu biết về sự thể dịch được cung cấp bởi các thao định lý.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>本文中,重解向量空维度为特徵所集,供单词一视角。 词向量者,词汇之所有词向量规范化。 今许以向量为一n元组(类模糊集),其n单词之维数,元素单词有征概率。 实者,使能用模糊集论运算,如并集、交集、差分。 异乎前,单词有相似性名,非其名也,近人之相似性也。 校其性,原其独,包其功能,多义词其检测,与集论可解释性之见。</span></div></div><dl><dt>Anthology ID:</dt><dd>2020.repl4nlp-1.4</dd><dt>Volume:</dt><dd><a href=/volumes/2020.repl4nlp-1/>Proceedings of the 5th Workshop on Representation Learning for NLP</a></dd><dt>Month:</dt><dd>July</dd><dt>Year:</dt><dd>2020</dd><dt>Address:</dt><dd>Online</dd><dt>Venues:</dt><dd><a href=/venues/acl/>ACL</a>
| <a href=/venues/repl4nlp/>RepL4NLP</a>
| <a href=/venues/ws/>WS</a></dd><dt>SIG:</dt><dd><a href=/sigs/sigrep/>SIGREP</a></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>24–33</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2020.repl4nlp-1.4>https://aclanthology.org/2020.repl4nlp-1.4</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/2020.repl4nlp-1.4 title="To the current version of the paper by DOI">10.18653/v1/2020.repl4nlp-1.4</a></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">bhat-etal-2020-word</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Siddharth Bhat, Alok Debnath, Souvik Banerjee, and Manish Shrivastava. 2020. <a href=https://aclanthology.org/2020.repl4nlp-1.4>Word Embeddings as Tuples of Feature Probabilities</a>. In <i>Proceedings of the 5th Workshop on Representation Learning for NLP</i>, pages 24–33, Online. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2020.repl4nlp-1.4>Word Embeddings as Tuples of Feature Probabilities</a> (Bhat et al., RepL4NLP 2020)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2020.repl4nlp-1.4.pdf>https://aclanthology.org/2020.repl4nlp-1.4.pdf</a></dd><dt class=acl-button-row>Video:</dt><dd class=acl-button-row><a href=http://slideslive.com/38929770 class="btn btn-attachment btn-sm"><i class="fas fa-video"></i>&nbsp;http://slideslive.com/38929770</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2020.repl4nlp-1.4.pdf title="Open PDF of 'Word Embeddings as Tuples of Feature Probabilities'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Word+Embeddings+as+Tuples+of+Feature+Probabilities" title="Search for 'Word Embeddings as Tuples of Feature Probabilities' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'Word Embeddings as Tuples of Feature Probabilities'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a>
<a class="btn btn-attachment d-flex flex-wrap justify-content-center" href=http://slideslive.com/38929770 title="Open video for 'Word Embeddings as Tuples of Feature Probabilities'"><span class="align-self-center px-1"><i class="fas fa-video"></i></span>
<span class=px-1>Video</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[Word Embeddings as Tuples of Feature Probabilities](https://aclanthology.org/2020.repl4nlp-1.4) (Bhat et al., RepL4NLP 2020)</p><ul class=mt-2><li><a href=https://aclanthology.org/2020.repl4nlp-1.4>Word Embeddings as Tuples of Feature Probabilities</a> (Bhat et al., RepL4NLP 2020)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Siddharth Bhat, Alok Debnath, Souvik Banerjee, and Manish Shrivastava. 2020. <a href=https://aclanthology.org/2020.repl4nlp-1.4>Word Embeddings as Tuples of Feature Probabilities</a>. In <i>Proceedings of the 5th Workshop on Representation Learning for NLP</i>, pages 24–33, Online. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>