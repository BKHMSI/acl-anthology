<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Multilingual and Zero-Shot is Closing in on Monolingual Web Register Classification - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="Multilingual and Zero-Shot is Closing in on Monolingual Web Register Classification" name=citation_title><meta content="Samuel Rönnqvist" name=citation_author><meta content="Valtteri Skantsi" name=citation_author><meta content="Miika Oinonen" name=citation_author><meta content="Veronika Laippala" name=citation_author><meta content="Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa)" name=citation_conference_title><meta content="2021" name=citation_publication_date><meta content="https://aclanthology.org/2021.nodalida-main.16.pdf" name=citation_pdf_url><meta content="157" name=citation_firstpage><meta content="165" name=citation_lastpage><meta property="og:title" content="Multilingual and Zero-Shot is Closing in on Monolingual Web Register Classification"><meta property="og:image" content="https://aclanthology.org/thumb/2021.nodalida-main.16.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2021.nodalida-main.16"><meta property="og:description" content="Samuel Rönnqvist, Valtteri Skantsi, Miika Oinonen, Veronika Laippala. Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa). 2021."><link rel=canonical href=https://aclanthology.org/2021.nodalida-main.16></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2021.nodalida-main.16.pdf>Multilingual and Zero-Shot is Closing in on Monolingual Web Register Classification</a>
<a id=af_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Multilingual en Zero-Shot sluit op Monolingueel Web Register Klassifikasie</a>
<a id=am_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Multilingual and Zero-Shot are closing in Monolingual Web Register Classification</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>متعدد اللغات و Zero-Shot يقترب من تصنيف سجل الويب أحادي اللغة</a>
<a id=az_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Çoxlu dil və Sıfır-Shot Monoling Web Register Klasifikasyonunda Qapılır</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Многоезичният и нулевият изстрел наближава класификацията на едноезичния уеб регистър</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>মোনোলোলিভাল ওয়েব রেজিস্টার ক্লাসিকেশনে অনেক ভাষা এবং শুট বন্ধ হচ্ছে</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>སྐད་རིགས་དབྱེ་སྤྱོད་དང་Zero-Shot Monolingual Web Register སྒྲིག་འཛིན་གྱི་ནང་དུ་སྒོ་རྒྱག་ཡོད་པ</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Većina jezika i nula pucnjava se zatvara u klasifikaciji jednojezičkog web registra</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Multilingüe i zero-Shot s'encerra a la classificació del registre web monolingüe</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Vícejazyčný a Zero-Shot se blíží na jednojjazyčném webovém rejstříku Klasifikace</a>
<a id=da_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Flersproget og Zero-Shot er ved at lukke ind på ensproget webregisterklassificering</a>
<a id=de_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Multilingual und Zero-Shot nähern sich der Monolingual Web Register Klassifizierung</a>
<a id=el_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Η πολύγλωσση και μηδενική βολή πλησιάζει στο μονογλωσσικό μητρώο ιστού Ταξινόμηση</a>
<a id=es_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Multilingüe y Zero-Shot se acerca a la clasificación de registros web monolingües</a>
<a id=et_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Mitmekeelne ja Zero-Shot läheneb ühekeelsele veebiregistri klassifikatsioonile</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>تعداد زبان‌های زیادی و صفر-شلیک در کلاس ثبت‌نامه‌ی وب یک زبان بسته می‌شود</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Monikielinen ja Zero-Shot lähestyvät monikielistä verkkorekisteriä</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Multilingue et Zero-Shot se rapproche de la classification monolingue des registres Web</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Tá Ilteangach agus Urchar Nialasach ag druidim le hAicmiú Clár Gréasáin Aonteangach</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>KCharselect unicode block name</a>
<a id=he_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>רישום רב-שפתי ואפס סוגרים את שיעור רשום האינטרנט Monolingual</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>बहुभाषी और शून्य-शॉट मोनोलिंगुअल वेब रजिस्टर वर्गीकरण पर बंद हो रहा है</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Većina jezika i nula pucnjava se zatvara na jednojezičkom registraciji web registracije</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Többnyelvű és Zero-Shot bezáródik az egynyelvű webes regiszterek osztályozására</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Բազլեզու և զրո-կրակը փակվում է MonoLingue վեբ ռեժիստրի դասակարգում</a>
<a id=id_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Multilingual and Zero-Shot is Closing in on Monolingual Web Register Classification</a>
<a id=is_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Multilingue e Zero-Shot si stanno avvicinando alla classificazione del registro web monolingue</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>多言語およびゼロショットは、単語ウェブレジスタ分類でクローズインしています</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Multilenguang lan nulo-shot iku diputalo ning Monolngual web regiter</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>მრავალენგური და ნულ- სურათი კლასიფიკაციაში დახურება</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Көп тілді және нөл- жол бір тілді Веб регистр классификациясында жабылады</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>다중 언어와 제로 렌즈가 단어 네트워크 어역 분류에 접근하고 있습니다</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Daugiakalbis ir nulinis tirpalas užbaigiamas Monolingual Web Registry klasifikacijoje</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Мултијазичен и нула- пукање се затвора на класификацијата на монолингвален веб- регистар</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>മണോളില്‍ വെബ് റിജിസ്റ്റര്‍ ക്ലാസിഷനില്‍ അടച്ചുകൊണ്ടിരിക്കുന്നു</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Олон хэл болон Zero-Shot нь Монолингийн Веб Регистр Классификацийн хувьд</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Multilingual and Zero-Shot is Closing in on Monolingual Web Register Classification</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Il-Klassifikazzjoni tar-Reġistru Monolingwali tal-Internet Multilingual u Zero-Shot qed tingħalaq</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Meertalig en Zero-Shot nadert op Monolingual Web Register Classification</a>
<a id=no_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Fleirspråk og null-skytt lukkar i ved å klassifisera mellomspråk nettregistrering</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Wielojęzyczny i Zero-Shot zbliża się do jednojęzycznego rejestru internetowego</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Multilíngue e Zero-Shot estão se aproximando da classificação de registro monolíngue da Web</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Multilingv și Zero-Shot se apropie de clasificarea registrului web monolingv</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Многоязычный и нулевой снимки приближаются к одноязычной классификации веб-регистров</a>
<a id=si_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Multilanguage and Zero-Shot are close in Monolingual Web Recorder Classified</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Večjezični in Zero-Shot se približujeta enojezični spletni register Klasifikacija</a>
<a id=so_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Luuqado badan iyo suurtogal-shoo waxay ku xidhan yihiin fasaxa diiwaangelinta internetka ee Monolingual</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Multilingual and Zero-Shot is Closing in on Monolingual Web Register Classification</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Većina jezika i nula pucnjava se zatvara u klasifikaciji jednojezičkog web registra</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Flerspråkiga och Zero-Shot närmar sig en enspråkig webbregisterklassificering</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Mpigo wa lugha nyingi na risasi zisizo na maandishi yanafungwa kwenye tovuti ya uandikishaji wa Kimonolinguli</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>பல மொழி மற்றும் பூஜ்ஜி- ஷாட் மோனோலிங்கல் இணைய பதிவு வகைப்படுத்தலில் மூடுகிறது</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Çoklu diller we Zero-Shot Monoli Dilli Web Register Seçgisinde ýapylýar</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Multilingual and Zero-Shot are closing in Monolingual Web Register Classification</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Name</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>Nhiều ngôn ngữ và Zero-Shot đang đóng cửa vào đơn vị Đánh dấu mạng.</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2021.nodalida-main.16.pdf>多言与零镜头方近单语网络寄存器类</a></h2><p class=lead><a href=/people/s/samuel-ronnqvist/>Samuel Rönnqvist</a>,
<a href=/people/v/valtteri-skantsi/>Valtteri Skantsi</a>,
<a href=/people/m/miika-oinonen/>Miika Oinonen</a>,
<a href=/people/v/veronika-laippala/>Veronika Laippala</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>This article studies register classification of documents from the unrestricted web, such as news articles or opinion blogs, in a multilingual setting, exploring both the benefit of training on multiple languages and the capabilities for zero-shot cross-lingual transfer. While the wide range of linguistic variation found on the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>web</a> poses challenges for register classification, recent studies have shown that good levels of cross-lingual transfer from the extensive English CORE corpus to other languages can be achieved. In this study, we show that training on multiple languages 1) benefits languages with limited amounts of register-annotated data, 2) on average achieves performance on par with monolingual models, and 3) greatly improves upon previous zero-shot results in <a href=https://en.wikipedia.org/wiki/Finnish_language>Finnish</a>, <a href=https://en.wikipedia.org/wiki/French_language>French</a> and <a href=https://en.wikipedia.org/wiki/Swedish_language>Swedish</a>. The best results are achieved with the multilingual XLM-R model. As data, we use the CORE corpus series featuring register annotated data from the unrestricted web.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Hierdie artikel studiereer klasifikasie van dokumente registreer van die onverstrekte web, soos nuusartikels of besonderhede blogs, in 'n veelvuldige instelling, ondersoek beide die voordeel van onderwerp op veelvuldige tale en die kapasiteite vir nul-skoot kruistale oordrag. Alhoewel die wyde omvang van lingwisiese veranderinge gevind op die web poseer uitdagings vir registrasie klasifikasie, het onlangse studie vertoon dat goeie vlakke van kruistale oordrag van die uitbreidige Engelske korpus na ander tale kan bereik word. In hierdie studie, wys ons dat onderwerp op veelvuldige tale 1) voordeel tale met beperkte hoeveelheid registreerde data, 2) op gemiddelde bereik uitvoeging op par met monolinge modele, en 3) baie verbeter op vorige nul-skoot resultate in Finnish, Frans en Sweedse. Die beste resultate word bereik met die multilinglike XLM-R model. As data, gebruik ons die CORE corpus reeks wat die registrasie aangetelde data van die ongestrekte web.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ይህ ጽሑፍ በብዛት ቋንቋዎች ላይ የመጠቀም ጥቅም እና በክፍለ ቋንቋ መቀናቀል የክፍል ቋንቋ መቃወሚያ የሚችሉትን የሰነዶች ክፍልፍሎች ማነሳትን እና የክፍል ቋንቋ መቀናቀል የሚችሉትን አካባቢነትን በመጠቀም ያስተምራል፡፡ While the wide range of linguistic variation found on the web poses challenges for register classification, recent studies have shown that good levels of cross-lingual transfer from the extensive English CORE corpus to other languages can be achieved. በዚህ ትምህርት፣ በብዛት ቋንቋዎች ላይ የተጠቃሚ ቋንቋ 1) የተጠቃሚ ቁጥጥር የመረጃ ዳታዎችን የሚጠቅመውን ቋንቋዎች (2) በመተካከለኛውም ብዛት በሞሎንቋል ዓይነቶች ላይ ድምፅን ያገኛል፡፡ የበለጠ ፍሬዎች በብዙ ቋንቋ በXLM-R ሞዴል የተደረገ ነው፡፡ እንደ ዳራዎች፣ CORE ኮርፓስ ተርሚዛን እናስቀምጣለን፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>تسجل دراسات هذه المقالة تصنيف المستندات من الويب غير المقيد ، مثل المقالات الإخبارية أو مدونات الرأي ، في بيئة متعددة اللغات ، واستكشاف كل من فوائد التدريب على لغات متعددة وإمكانيات النقل عبر اللغات بدون طلقة. في حين أن النطاق الواسع للتنوع اللغوي الموجود على الويب يشكل تحديات لتصنيف التسجيل ، فقد أظهرت الدراسات الحديثة أنه يمكن تحقيق مستويات جيدة من النقل عبر اللغات من مجموعة CORE الإنجليزية الشاملة إلى لغات أخرى. في هذه الدراسة ، نوضح أن التدريب على لغات متعددة 1) يفيد اللغات بكميات محدودة من البيانات المشروحة بالتسجيل ، 2) يحقق متوسط الأداء على قدم المساواة مع النماذج أحادية اللغة ، و 3) يتحسن بشكل كبير على النتائج الصفرية السابقة باللغة الفنلندية ، الفرنسية والسويدية. يتم تحقيق أفضل النتائج مع نموذج XLM-R متعدد اللغات. كبيانات ، نستخدم سلسلة CORE corpus التي تعرض تسجيل البيانات المشروحة من الويب غير المقيد.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bu m…ôktub √ßoxlu dil qurńüularńĪnda, √ßoxlu dil qurńüularńĪnda t…ôhsil etm…ô faydalarńĪnńĪ v…ô sńĪfńĪr-shot √ßoxlu dil transferisinin f…ôaliyy…ôtini t…ôhsil edir. ńįnternet i√ßind…ô bulunan dil d…ôyiŇüiklikl…ôrinin geniŇüliyi s…ôb…ôbi register klasifikasyonu √ľ√ß√ľn √ß…ôtinlikl…ôr…ô m…ôcbur ed…ôrk…ôn, son d…ôyiŇüiklikl…ôrin √ßox geniŇüliyi ńįngilis CORE korpusundan baŇüqa dill…ôr…ô istifad…ô edil…ô bil…ôc…ôyini g√∂st…ôrdil…ôr. Bu t…ôcr√ľb…ôd…ô, √ßoxlu dill…ôrd…ô t…ôcr√ľb…ô 1 il…ô m√ľ…ôyy…ôn edil…ôn dill…ôr…ô m√ľ…ôyy…ôn edilmiŇü m…ôlumatlarńĪn m…ônf…ô…ôti verir, 2 il…ô ortalama t…ôcr√ľb…ôsi monodil modell…ôri il…ô m√ľ…ôyy…ôn edilir v…ô 3) Finlandiya, FransńĪzca v…ô Ňěvediyada …ôvv…ôlki n√∂qt…ôsin sonu√ßlarńĪnńĪ √ßox yaxŇüńĪlaŇüdńĪrńĪr. ∆Źn yaxŇüńĪ sonu√ßlar √ßoxlu dil XLM-R modeli il…ô baŇüarńĪlńĪr. M…ôlumatlar kimi, CORE korpus serisini istifad…ô edirik ki, m√ľ…ôyy…ôn edilm…ômiŇü web t…ôr…ôfind…ôn m…ôlumatlarńĪ m…ôlumatlarńĪnńĪ bel…ô g√∂st…ôrir.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Тази статия изучава класификацията на документите от неограничената интернет мрежа, като например статии с новини или блогове с мнения, в многоезична обстановка, изследвайки както ползите от обучението на няколко езика, така и възможностите за нулев междуезичен трансфер. Въпреки че широката гама от езикови вариации, открити в интернет, поставя предизвикателства за класификацията на регистрите, последните проучвания показват, че могат да бъдат постигнати добри нива на междуезичен трансфер от обширния английски корпус CORE към други езици. В това проучване ние показваме, че обучението на няколко езика 1) облагодетелства езици с ограничено количество анотирани данни от регистъра, 2) средно постига представяне на ниво едноезични модели и 3) значително се подобрява спрямо предишните нулеви резултати на финландски, френски и шведски език. Най-добрите резултати се постигат с многоезичния модел. Като данни използваме корпусната серия с анотирани регистри данни от неограничената интернет страница.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>এই প্রবন্ধটি অন্যান্য ভাষায় সংবাদ প্রবন্ধ বা মতামত ব্লগের নথিগুলোর বিভাগ নিবন্ধকতা গবেষণা করছে, যেমন সংবাদ প্রবন্ধ বা ব্লগ, অনেক ভাষায় বিভিন্ন ভাষায় প্রশিক্ষণের সু While the wide range of linguistic variation found on the web poses challenges for register classification, recent studies have shown that good levels of cross-lingual transfer from the extensive English CORE corpus to other languages can be achieved. এই গবেষণায় আমরা দেখাচ্ছি যে বেশ কয়েকটি ভাষায় প্রশিক্ষণের প্রশিক্ষণ সীমিত ভাষায় সুবিধা প্রদান করা হয়েছে যার সাথে সীমিত নিবন্ধন-বিজ্ঞাত তথ্য, ২) সাধারণ ভাষায় সাধারণ ভা বহুভাষায় XLM-R মডেল দিয়ে সবচেয়ে ভাল ফলাফল অর্জন করা হয়েছে। তথ্য হিসেবে আমরা কোর্পাস সিরিজ ব্যবহার করি যেখানে রেজিস্টারের বিস্তারিত তথ্য প্রকাশ করা হয়েছে অথচ ওয়েব থেকে।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>This article studies register classification of documents from the unrestricted web, such as news articles or opinion blogs, in a multilingual setting, exploring both the benefit of training on multiple languages and the capabilities for zero-shot cross-lingual transfer. While the wide range of linguistic variation found on the web poses challenges for register classification, recent studies have shown that good levels of cross-lingual transfer from the extensive English CORE corpus to other languages can be achieved. In this study, we show that training on multiple languages 1) benefits with limited amounts of register-annotated data, 2) on average achieves performance on par with monolingual models, and 3) greatly improves in previous zero-shot results in Finnish, French and Swedish. A variety of languages on this study shows that training on multiple languages 1) benefits with limited amounts of register-annotated data, 2) on average achieves performance on par with monolingual models, and 3) greatly improve དབྱིབས་འབྲས་ཤོས་ཚད་མང་ཆེ་ཤོས་ཡོད་པའི་སྐད་རིགས་XLM-R་མ་དབྱིབས་ཡོད་པ་རེད། འུ་ཅག་གིས་སྐྱོན་འབྲེལ་མཐུད་མཁན་གྱི་ཞབས་ཞུ་སྤྱོད་བཞིན་པ་ལྟར་བཀོད་ཡོད་མེད་པའི་དྲ་རྒྱའི་ནང་ནས་གསལ་བཀོད</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ovaj članak proučava registraciju klasifikacije dokumenta iz neograničene mreže, kao što su novinski članovi ili blogovi mišljenja, u multijezičkom stanju, istražujući i korist obuke na višestrukim jezicima i sposobnosti za prebacivanje jezika nulog snimka. Iako širok niz lingvističkih varijacija nalaženih na internetu predstavlja izazove za klasifikaciju registracija, nedavno ispitivanje pokazalo je da se mogu postići dobar nivo prekograničnog prijenosa iz širokog engleskog korpusa CORE na druge jezike. U ovom ispitivanju pokazujemo da obuka na višestrukim jezicima 1) koristi jezike sa ograničenim količinama podataka o registraciji, 2) na prosjeku postiže učinkovitost na par sa monojezičkim modelima, a 3) veoma poboljšava na prethodnim rezultatima nule snimanja na finskom, francuskom i švedskom. Najbolji rezultati su postignuti sa multijezičkim XLM-R modelom. Kao podaci, koristimo seriju CORE korpusa koja uključuje registrirane annotirane podatke iz neograničene mreže.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Aquest article estudia la classificació de documents de la web sense restriccions, com articles de notícies o blogs d'opinió, en un entorn multilingüi, explorant tant el benefici de l'entrenament en múltiples llengües com les capacitats de transfer ència translingüística de fotografies zero. Mentre que la gran varietat de variacions lingüístices trobadas a la web posen reptes per a la classificació del registre, estudis recents han demostrat que es poden aconseguir bons nivells de transfer ència translingüística del corps anglès CORE a altres llengües. En aquest estudi, demostram que la formació en múltiples llengües 1) beneficia les llengües amb quantitats limitades de dades anotats en registre, 2) aconsegueix un rendiment mitjà igual que els models monolingües, i 3) millora molt en finlandès, francès i suec els resultats anteriors de fotografia zero. Els millors resultats s'aconsegueixen amb el model XLM-R multilingüe. Com a dades, utilitzem la sèrie CORE corpus amb registres de dades anotates de la Web sense restriccions.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tento článek studuje klasifikaci dokumentů z neomezeného webu, jako jsou zpravodajské články nebo blogy o názorech, ve vícejazyčném prostředí, zkoumá jak přínosy školení na více jazycích, tak možnosti nulového přenosu mezi jazyky. Zatímco široká škála jazykových variací nalezených na webu představuje výzvu pro klasifikaci registrů, nedávné studie ukázaly, že lze dosáhnout dobré úrovně přenosu mezi jazyky z rozsáhlého anglického korpusu CORE do jiných jazyků. V této studii ukazujeme, že školení na více jazycích 1) přináší prospěch jazyků s omezeným množstvím dat v registru, 2) v průměru dosahuje výkonu stejného jako monojazyčné modely a 3) výrazně zlepšuje předchozí nulové výsledky ve finštině, francouzštině a švédštině. Nejlepších výsledků dosahuje vícejazyčný model XLM-R. Jako data používáme korpusovou řadu CORE obsahující registrovaná data z neomezeného webu.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Denne artikel undersøger klassificeringen af dokumenter fra det ubegrænsede web, såsom nyhedsartikler eller meningsblogge, i en flersproget miljø, og undersøger både fordelene ved træning i flere sprog og mulighederne for nulskud tværsproget overførsel. Mens den brede vifte af sproglige variationer, der findes på nettet, udgør udfordringer for registerklassificering, har nylige undersøgelser vist, at der kan opnås gode niveauer af tværsproget overførsel fra det omfattende engelske CORE korpus til andre sprog. I denne undersøgelse viser vi, at træning på flere sprog 1) gavner sprog med begrænsede mængder registernoterede data, 2) i gennemsnit opnår resultater på samme niveau som ensprogede modeller, og 3) forbedrer betydeligt i forhold til tidligere nulskudsresultater på finsk, fransk og svensk. De bedste resultater opnås med den flersprogede XLM-R model. Som data bruger vi CORE corpus serien med registernoterede data fra det ubegrænsede web.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Dieser Artikel untersucht die Registerklassifizierung von Dokumenten aus dem uneingeschränkten Web, wie Nachrichtenartikel oder Meinungsblogs, in einem mehrsprachigen Umfeld und untersucht sowohl den Nutzen von Schulungen in mehreren Sprachen als auch die Möglichkeiten für den Zero-Shot-crosslingualen Transfer. Während das breite Spektrum an sprachlichen Variationen im Web Herausforderungen für die Registerklassifizierung darstellt, haben aktuelle Studien gezeigt, dass ein guter translingualer Transfer vom umfangreichen englischen CORE-Korpus in andere Sprachen erreicht werden kann. In dieser Studie zeigen wir, dass das Training in mehreren Sprachen 1) Sprachen mit begrenzter Menge an Registerannotierten Daten zugute kommt, 2) im Durchschnitt Leistung auf Augenhöhe mit einsprachigen Modellen erzielt und 3) die bisherigen Null-Shot-Ergebnisse in Finnisch, Französisch und Schwedisch deutlich verbessert. Die besten Ergebnisse werden mit dem mehrsprachigen XLM-R Modell erzielt. Als Daten verwenden wir die CORE-Korpusserie mit Registerkommentierungen aus dem uneingeschränkten Web.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Αυτό το άρθρο μελετά την ταξινόμηση εγγράφων από τον απεριόριστο ιστό, όπως άρθρα ειδήσεων ή ιστολόγια γνώμης, σε ένα πολύγλωσσο περιβάλλον, διερευνώντας τόσο το όφελος της κατάρτισης σε πολλές γλώσσες όσο και τις δυνατότητες για μηδενική διασυνοριακή μεταφορά. Ενώ το ευρύ φάσμα γλωσσικών παραλλαγών που υπάρχουν στο διαδίκτυο θέτει προκλήσεις για την ταξινόμηση μητρώων, πρόσφατες μελέτες έχουν δείξει ότι μπορούν να επιτευχθούν καλά επίπεδα διασυνοριακής μεταφοράς από το εκτεταμένο αγγλικό σώμα CORE σε άλλες γλώσσες. Στην παρούσα μελέτη, καταδεικνύουμε ότι η εκπαίδευση σε πολλαπλές γλώσσες 1) ωφελεί τις γλώσσες με περιορισμένες ποσότητες σχολιασμένων δεδομένων, 2) κατά μέσο όρο επιτυγχάνει απόδοση ίση με τα μονογλωσσικά μοντέλα, και 3) βελτιώνει σημαντικά σε σχέση με τα προηγούμενα αποτελέσματα μηδενικής λήψης στα φινλανδικά, γαλλικά και σουηδικά. Τα καλύτερα αποτελέσματα επιτυγχάνονται με το πολύγλωσσο μοντέλο. Ως δεδομένα, χρησιμοποιούμε τη σειρά Corpus CORE που περιλαμβάνει δεδομένα με σχόλια μητρώου από τον απεριόριστο ιστό.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Este artículo estudia la clasificación de registros de documentos de la web sin restricciones, como artículos de noticias o blogs de opinión, en un entorno multilingüe, explorando tanto el beneficio de la capacitación en múltiples idiomas como las capacidades de transferencia interlingüística sin posibilidad de transferencia interlingüística. Si bien la amplia gama de variaciones lingüísticas que se encuentran en la web plantea desafíos para la clasificación de registros, estudios recientes han demostrado que se pueden lograr buenos niveles de transferencia multilingüe del extenso corpus CORE en inglés a otros idiomas. En este estudio, mostramos que la capacitación en varios idiomas 1) beneficia a los idiomas con cantidades limitadas de datos anotados por el registro, 2) en promedio logra un rendimiento a la par de los modelos monolingües y 3) mejora en gran medida los resultados previos de tiro cero en finés, francés y sueco. Los mejores resultados se obtienen con el modelo XLM-R multilingüe. Como datos, utilizamos la serie de corpus CORE que incluye datos anotados de registro de la web sin restricciones.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Käesolevas artiklis uuritakse piiramatu veebi dokumentide, näiteks uudisteartiklite või arvamusblogide registreerimist mitmekeelses keskkonnas, uurides nii mitmekeelse koolituse eeliseid kui ka võimalusi mitmekeelseks ülekandmiseks. Kuigi veebis leiduv keeleline varieeruvus tekitab registrite klassifitseerimisele probleeme, on hiljutised uuringud näidanud, et on võimalik saavutada hea taseme keeltevahelise ülekande ulatuslikust inglise CORE korpusest teistesse keeltesse. Käesolevas uuringus näitame, et mitme keele koolitus 1) toob kasu keeltele, kus on piiratud kogus registreeritud andmeid, 2) saavutab keskmiselt võrdse tulemuse ühekeelsete mudelitega ja 3) paraneb oluliselt varasematest nullkatse tulemustest soome, prantsuse ja rootsi keeles. Parimad tulemused saavutatakse mitmekeelse XLM-R mudeliga. Andmetena kasutame CORE korpuse seeriat, mis sisaldavad piiramatult veebist registreeritud annoteeritud andmeid.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>این مقاله تحقیقات گروه‌بندی سند‌ها را از وب غیرمحدود ثبت می‌کند، مانند مقاله‌های خبری یا بلاگ نظر، در یک تنظیم بسیاری زبان، در جستجو هر دو سود آموزش بر زبان‌های متعدد و توانایی برای انتقال زبان‌های متعدد صفر، تحقیق می‌کند. در حالی که مدت گسترده تغییرات زبان‌شناسی که در وب یافته‌اند، چالش‌هایی برای گروه‌شناسی ثبت می‌کند، تحقیقات اخیرا نشان داده‌اند که سطح خوبی از انتقال متفاوت زبان‌های زیادی از کورپوس انگلیسی CORE به زبان‌های در این مطالعه، ما نشان می دهیم که آموزش روی زبانهای متعدد 1) به زبانها سود می دهد که با تعداد محدودیت داده‌های ثبت شده، ۲) در میانگین عملکرد را با مدل‌های متعدد زبان می‌رساند، و ۳) در نتیجه‌های صفر پیشین در فنلاندی، فرانسوی و سوئدی بهتر می‌شود. بهترین نتایج با مدل XLM-R چند زبان رسیده می شوند. به عنوان اطلاعات، ما از مجموعه CORE corpus استفاده می کنیم که از وب غیرمحدودیت اطلاعات آشنا شده را مشخص می کنیم.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Tässä artikkelissa tutkitaan rajattomasta verkosta peräisin olevien asiakirjojen, kuten uutisartikkeleiden tai mielipitebloggien, rekisteriluokittelua monikielisessä ympäristössä, ja tutkitaan sekä monikielisen koulutuksen hyötyjä että mahdollisuuksia nollakieliseen siirtoon. Vaikka verkossa esiintyvä kielellinen vaihtelu asettaa haasteita rekisteriluokittelulle, viimeaikaiset tutkimukset ovat osoittaneet, että laaja englanninkielinen CORE-korpus voi siirtyä hyvin eri kielille. Tässä tutkimuksessa osoitetaan, että monikielinen koulutus 1) hyödyttää kieliä, joilla on rajallinen määrä rekisterimerkintöjä, 2) saavuttaa keskimäärin suorituskykyä yksikielisten mallien kanssa ja 3) parantaa huomattavasti aikaisempia nollatuloksia suomeksi, ranskaksi ja ruotsiksi. Parhaat tulokset saavutetaan monikielisellä XLM-R-mallilla. Käytämme aineistona CORE-korpussarjoja, joissa on rekisterimerkinnällä merkitty tieto rajattomasta verkosta.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Cet article étudie la classification des registres de documents provenant du Web non restreint, tels que des articles de presse ou des blogs d'opinion, dans un environnement multilingue, en explorant à la fois les avantages de la formation dans plusieurs langues et les possibilités de transfert multilingue zero-shot. Alors que le large éventail de variations linguistiques trouvées sur le Web pose des défis pour la classification des registres, des études récentes ont montré qu'il est possible d'atteindre de bons niveaux de transfert interlinguistique du vaste corpus anglais CORE vers d'autres langues. Dans cette étude, nous montrons que la formation sur plusieurs langues 1) profite aux langues avec des quantités limitées de données annotées dans les registres, 2) atteint en moyenne des performances comparables à celles des modèles monolingues et 3) améliore considérablement les résultats zero-shot précédents en finnois, en français et en suédois. Les meilleurs résultats sont obtenus avec le modèle XLM-R multilingue. En tant que données, nous utilisons la série de corpus CORE contenant des données annotées de registre provenant du Web non restreint.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Déanann an t-alt seo staidéar ar aicmiú doiciméad ón ngréasán neamhshrianta, ar nós ailt nuachta nó blaganna tuairime, i suíomh ilteangach, ag fiosrú an tairbhe a bhaineann le hoiliúint ar iltheangacha agus na hacmhainní le haghaidh aistrithe trasteangacha gan urchar. Cé go gcruthaíonn an raon leathan éagsúlachta teanga atá le fáil ar an ngréasán dúshláin maidir le haicmiú cláir, léirigh staidéir a rinneadh le déanaí gur féidir leibhéil mhaithe aistrithe tras-teanga a bhaint amach ó chorpas fairsing Béarla CORE go teangacha eile. Sa staidéar seo, léirímid go dtéann oiliúint ar iltheangacha 1) chun sochair do theangacha le méideanna teoranta sonraí cláraithe, 2) go mbaintear amach feidhmíocht ar chomhchéim le samhlacha aonteangacha, agus 3) go bhfeabhsaítear go mór é ar thorthaí nialasacha san Fhionlainnis roimhe seo, Fraincis agus Sualainnis. Baintear na torthaí is fearr amach leis an tsamhail ilteangach XLM-R. Mar shonraí, úsáidimid an tsraith CORE corpus ina bhfuil sonraí anótáilte cláir ón ngréasán neamhshrianta.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Wannan makala na karanta fasalin takardar kwamfyutan da ba'a rubutu ba, kamar makarantar da masu basu'a da suniyoyi, a cikin muhalli na multi-lingui, sunã jarraba laban amfani da amfani da yin wa'anar wa masu yawa da abincin wa transfer na-nau'in-sifanci. A lokacin da kewayen variantun linguistic wanda aka sãmu a kan web yana da zane-zane wa tsarin lissafi, masu ƙarami sun nuna cewa, zane da zane-zane mai kyau na shige-linguin-na'ura daga makamps na Ingiriya ya faɗi zuwa wasu harshen, za'a iya sãmun. Daga wannan lõkaci, Munã nũna wa mafarinta a cikin wasu harshe 1) yana amfani da wasu zane da aka ƙayyade yawan data na rubũtar da-yanzu, 2) a kan kawaici, yana sãmun babban rabo a par da misãlai masu monoli'in, kuma 3) yana ƙaranci mai girma a gabanin jarrabo na sifanci ta farko a cikin Finnish, Faransiya da Iswidishki. An sami mafi kyaun matsala da misalin XLM-R-na'ura multi-lingui. Kama da data, za mu yi amfani da jumla'in COER na shirin wasu mutane na rubutun da aka sanar da shi daga tare webi wanda ba'a saɓa ba.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>המאמר הזה לומד רשום קליזציה של מסמכים מהרשת הלא מוגבלת, כמו מאמרים חדשות או בלוגים דעות, במסגרת רבות שפות, לחקור את היתרון של האימונים על שפות רבות וכל היכולות להעברת שפות דרך אפס צילומים. While the wide range of linguistic variation found on the web poses challenges for register classification, recent studies have shown that good levels of cross-lingual transfer from the extensive English CORE corpus to other languages can be achieved. במחקר הזה, אנחנו מראים שאימונים על שפות רבות 1) שפות מועילות עם כמויות מוגבלות של נתונים רשומים, 2) בממוצע משיגים ביצועים באותה מידה עם דוגמנים monolingual, 3) משתפרים באופן גדול על תוצאות אפס קודמות בפינים, צרפתיים ושוודיים. התוצאות הטובות ביותר ניתן להשיג עם מודל XLM-R רב-שפתי. בתור נתונים, אנו משתמשים בסדרת CORE corpus המכילה רשום נתונים מועטפים מהרשת ללא מוגבלות.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>यह लेख अप्रतिबंधित वेब से दस्तावेजों के वर्गीकरण को पंजीकृत करता है, जैसे कि समाचार लेख या राय ब्लॉग, एक बहुभाषी सेटिंग में, कई भाषाओं पर प्रशिक्षण के लाभ और शून्य-शॉट क्रॉस-लिंगुअल ट्रांसफर की क्षमताओं दोनों की खोज करते हैं। जबकि वेब पर पाए जाने वाले भाषाई भिन्नता की विस्तृत श्रृंखला रजिस्टर वर्गीकरण के लिए चुनौतियां पैदा करती है, हाल के अध्ययनों से पता चला है कि व्यापक अंग्रेजी कोर कॉर्पस से अन्य भाषाओं में क्रॉस-लिंगुअल हस्तांतरण के अच्छे स्तर प्राप्त किए जा सकते हैं। इस अध्ययन में, हम दिखाते हैं कि कई भाषाओं पर प्रशिक्षण 1) सीमित मात्रा में रजिस्टर-एनोटेटेड डेटा के साथ भाषाओं को लाभ पहुंचाता है, 2) औसतन मोनोलिंगुअल मॉडल के बराबर प्रदर्शन प्राप्त करता है, और 3) फिनिश, फ्रेंच और स्वीडिश में पिछले शून्य-शॉट परिणामों पर बहुत सुधार करता है। बहुभाषी XLM-R मॉडल के साथ सर्वोत्तम परिणाम प्राप्त किए जाते हैं। डेटा के रूप में, हम अप्रतिबंधित वेब से रजिस्टर एनोटेट डेटा की विशेषता वाली कोर कॉर्पस श्रृंखला का उपयोग करते हैं।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ovaj članak proučava registriranje klasifikacije dokumenta iz neograničene mreže, kao što su novinski članovi ili blogovi mišljenja, u multijezičkom postavljanju, istražujući i korist obuke na višestrukim jezicima i mogućnosti prijenosa s nulom snimkom preko jezika. Iako širok raspon lingvističkih promjena nalaženih na internetu predstavlja izazove za klasifikaciju registracija, nedavna ispitivanja pokazala su da se mogu postići dobra razina preko jezika prebacivanja iz širokog engleskog korpusa CORE na druge jezike. U ovom ispitivanju pokazujemo da obuka na višestrukim jezicima 1) koristi jezike s ograničenim količinama podataka o registraciji, 2) na prosjeku postiže učinkovitost na par s monojezičkim modelima, a 3) značajno poboljšava na prethodnim rezultatima nule snimanja na finskom, francuskom i švedskom. Najbolji rezultati su postignuti s multijezičkim XLM-R modelom. Kao podaci, koristimo seriju korpusa CORE-a koja uključuje registraciju annotiranih podataka iz neograničene mreže.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ez a cikk a korlátozás nélküli internetről származó dokumentumok, például hírek vagy vélemény blogok osztályozását tanulmányozza többnyelvű környezetben, feltárva mind a többnyelvű képzés előnyeit, mind pedig a nulla-shot keresztnyelvű transzfer lehetőségeit. Míg az interneten található nyelvi variációk széles skálája kihívásokat jelent a nyilvántartások besorolása szempontjából, a közelmúltbeli tanulmányok azt mutatták, hogy a kiterjedt angol CORE korpusztól más nyelvekre való átvitel jó szintje érhető el. Ebben a tanulmányban azt mutatjuk, hogy a több nyelven folytatott képzés 1) korlátozott mennyiségű regisztrációs adattal rendelkező nyelveket használ, 2) átlagosan az egynyelvű modellekkel egyenlő teljesítményt ér el, és 3) jelentősen javul a korábbi nulla-shot eredményekhez képest finn, francia és svéd nyelven. A legjobb eredményeket a többnyelvű XLM-R modell érheti el. Adatként a korlátozás nélküli internetről származó jegyzetelt adatokat tartalmazó CORE corpus sorozatot használjuk.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Այս հոդվածը ուսումնասիրում է անսահմանափակ ցանցի փաստաթղթերի դասակարգումը, ինչպիսիք են նորությունների հոդվածները կամ կարծիքի բլոգերը, բազլեզվով միջավայրում, ուսումնասիրելով բազմալեզվով լեզուների ուսումնասիրության առավելությունը, ինչպես նաև զրոյի Մինչդեռ ցանցում գտնվող լեզվաբանական տարբերությունների լայն տարբերակը դժվարություններ է առաջացնում ռեստորանների դասակարգման համար, վերջին ուսումնասիրությունները ցույց են տալիս, որ կարելի է հասնել լեզվաբանական փոխանցման լավ մակարդակներին անգլերենի CORECorpus-ից այլ լեզուների Այս ուսումնասիրության ընթացքում մենք ցույց ենք տալիս, որ բազմալեզուների ուսումնասիրությունը 1) օգտակար է լեզուներին, որոնք ունեն սահմանափակ քանակությամբ գրված տվյալներ, 2) միջինում հասնում են մեկլեզու մոդելների և 3) մեծ բարելավում են ֆինլարենի, ֆրանսիացի և շվեդիացի դեպքում առաջին զրոյ Լավագույն արդյունքները հասնում են XLM-R բազլեզու մոդելի միջոցով: Որպես տվյալներ, մենք օգտագործում ենք CORECorpus-ի շարքը, որը ներկայացնում է անսահմանափակ ցանցի գրված տվյալներ:</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>This article studies register classification of documents from the unrestricted web, such as news articles or opinion blogs, in a multilingual setting, exploring both the benefit of training on multiple languages and the capabilities for zero-shot cross-lingual transfer. Sementara jangkauan luas variasi bahasa yang ditemukan di web menunjukkan tantangan untuk klasifikasi register, penelitian baru-baru ini menunjukkan bahwa tingkat yang baik dari transfer saling bahasa dari CORE corpus Inggris ekstensif ke bahasa lain dapat dicapai. Dalam penelitian ini, kami menunjukkan bahwa pelatihan dalam berbagai bahasa 1) bahasa keuntungan dengan jumlah terbatas data-annotasi register, 2) rata-rata mencapai prestasi yang sama dengan model monobahasa, dan 3) meningkat jauh pada hasil zero-shot sebelumnya dalam Finlandia, Perancis dan Swedia. Hasil terbaik dicapai dengan model XLM-R berbilang bahasa. Sebagai data, kami menggunakan seri CORE corpus yang menampilkan register data annotasi dari web yang tidak terbatas.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Questo articolo studia la classificazione dei documenti provenienti dal web senza restrizioni, come articoli di notizie o blog di opinione, in un ambiente multilingue, esplorando sia i vantaggi della formazione su più lingue che le capacità di trasferimento cross-lingual zero shot. Mentre l'ampia gamma di variazioni linguistiche rilevate sul web pone sfide per la classificazione dei registri, studi recenti hanno dimostrato che è possibile raggiungere buoni livelli di trasferimento translinguale dall'ampio corpus inglese CORE ad altre lingue. In questo studio, mostriamo che la formazione su più lingue 1) favorisce le lingue con quantità limitate di dati annotati nel registro, 2) raggiunge in media prestazioni alla pari dei modelli monolingue e 3) migliora notevolmente rispetto ai precedenti risultati zero-shot in finlandese, francese e svedese. I migliori risultati si ottengono con il modello XLM-R multilingue. Come dati, utilizziamo la serie CORE corpus con dati annotati dal web senza restrizioni.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>この記事では、多言語環境でのニュース記事やオピニオンブログなどの制限のないウェブからの文書の分類を研究し、複数言語でのトレーニングの利点とゼロショットのクロスリンガル転送機能の両方を探求します。ウェブ上で発見された幅広い言語変動は、レジスタ分類に課題をもたらすが、最近の研究では、広範な英語のコアコーパスから他の言語への良好なレベルのクロスリンガル転送を達成できることが示されている。この研究では、複数の言語に関するトレーニングが、1 ）登録されたデータの量が限られている言語に利益をもたらすこと、2 ）平均的に単一言語モデルと同等のパフォーマンスを達成すること、3 ）以前のフィンランド語、フランス語、スウェーデン語のゼロショット結果よりも大幅に改善することを示しています。最良の結果は、多言語XLM - Rモデルで達成されます。データとしては、制限のないウェブからの注釈付きデータを登録することを特徴とするコアコーパスシリーズを使用しています。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Artik iki diputara bener winih sing nggawe dokumen ning web sing or a bisa dianggawe, kaya Artik balêr nggawe winih dhéwé, lan uga sistem hukum kanggo sistem hukum sistem plural, ndheke dhéwé éntukno sistem sing gawe nguasai perusahaan langkung sampeyan sak Where's the last language Genjer-genjer diunting akeh akeh operasi nggawe ing web punika ingkang diputara winih sing nggawe winih sing, winih sing ngendalikno wong dhéwé kuwi tindakan luwih apik-langkung Nang barêng-barêng iki, kéné iso nglanggar tarjamahan kanggo langgar sapa luwih lan ingkang 1) kayané perusahaan kanggo mbangaké kantor kantor nggawe data, 2) ngono nglanggar tarjamahan kanggo nyenggap kanggo nyenggap tarjamahan karo model Monolyanse, lan 3) sing beraksi kanggo nyenggap tarjamahan liyané sing nyenggap kanggo nyenggap tarjamahan Laptop" and "Desktop Sampeyan data, kita gambar kelompus cor</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ამ წესტის შესწავლობა უფრო მრავალური წესების კლასიფიკაცია, როგორც ახალგაზრულები ან მინდომის ბლოგები, მრავალური წესების კონფიკაციაში, მრავალური წესების გამოსახულების გამოსახულების და უფ თუმცა ინგლისტიკური განსხვავებები, რომელიც ინგლისტიკური კორიფიკაციის განსხვავებულია, განსხვავებული კორიფიკაციის განსხვავებებისთვის განსხვავებულია, შემდეგ განსხვავებული კორიფიკაციის შესაძლებელია, რომ ამ კვლევაში ჩვენ ჩვენ აჩვენებთ, რომ მრავალ ენაზე განაკეთება 1) გამოიყენება ენაზე, რომლებიც რეგისტრის ანოტირებული მონაცემების ზომა, 2) სინამდვილეში მონაცემებით მონაცემებით მონაცემებით მონაცემებით, და 3) წ ყველაზე საუკეთესო შედეგი მოდელი იქნება მრავალენგური XLM-R მოდელზე. როგორც მონაცემები, ჩვენ გამოყენებთ CORE corpus სერია, რომელსაც რეგისტრისტის მონაცემები არსებული ინტერფეტიდან გამოყენება.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Бұл мақала, жаңалық мақалалар немесе ойлау блогтар секілді, көптеген тілдерде, бірнеше тілдердің оқыту мүмкіндіктерін және нөл тілдердің көптеген аудару мүмкіндіктерін зерттеу үшін құжаттарды сақтау жүйесін зерт Интернетте табылған лингвистикалық айырмашылығының көпшілігі категориялау үшін өзгерістерді көрсетеді, соңғы зерттеулер тілдерді көпшілікті CORE корпусынан басқа тілдерге жеткізуге болады. Бұл зерттеулерде бірнеше тілдерді оқыту (1) тілдерді көмектесу үшін көмектесетін деректердің шектелген мөлшерлері бар, 2) орташа бірнеше тілдердің монолингі үлгілері бар, және 3) алдыңғы нөл шарттарының Финляндия, Француз Ең жақсы нәтижелер көп тілді XLM- R үлгісімен жетілді. Деректер үшін CORE корпус сериясын қолданамыз. Керек емес веб- тегінен жазылған деректерді көрсетеді.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>본고는 다중 언어 환경에서 비제한 네트워크에서 온 문서(예를 들어 뉴스 기사나 관점 블로그)를 등록 분류하고 다중 언어 교육의 장점과 제로 크로스 언어 이동 능력을 연구했다.비록 인터넷에서 발견된 광범위한 언어 변이가 어역 분류에 도전을 가져왔지만 최근의 연구에 의하면 대량의 영어 핵심 어료 라이브러리에서 다른 언어로의 양호한 크로스 언어 이동을 실현할 수 있다고 한다.이 연구에서 우리는 다양한 언어의 훈련 1)이 어역 주석 데이터량이 제한된 언어에 유리하고, 2) 평균적으로 단어 모델과 비슷한 성능에 이르는 것을 발견했다. 3) 핀란드어, 프랑스어, 스웨덴어에서의 제로 포 결과를 크게 개선했다.다국어 XLM-R 모델을 사용하면 최상의 효과를 얻을 수 있습니다.데이터로서 우리는 핵심 어료 라이브러리 시리즈를 사용하는데 그 중에서 무제한 네트워크에서 온 등록 주석 데이터를 포함한다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Šiame straipsnyje tiriamas neribotų interneto dokumentų, pavyzdžiui, naujienų straipsnių ar nuomonės blogų, klasifikavimas daugiakalbėje aplinkoje, išnagrinėjant mokymo įvairiomis kalbomis naudą ir galimybes neperdirbti tarpkalbinį perdavimą. Nors internete nustatytas didelis kalbų skirtumas kelia iššūkių registrų klasifikavimui, neseniai atlikti tyrimai parodė, kad galima pasiekti gerą tarpkalbinio perkėlimo lygį iš plataus anglų CORE corpus į kitas kalbas. Šiame tyrime parodome, kad mokymas įvairiomis kalbomis 1) naudingas kalboms, kuriose registruose yra ribotas duomenų kiekis, 2) vidutiniškai pasiekia rezultatus lygiaverčius vienkalbiniams modeliams ir 3) gerokai pagerėja ankstesnių nulinių rezultatų suomių, prancūzų ir švedų kalbomis. Geriausi rezultatai pasiekti naudojant daugiakalbį XLM-R model į. Kaip duomenys naudojame CORE corpus seriją, kurioje registruojami neribotos interneto anotacijos duomenys.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Оваа статија ја проучува класификацијата на документите од неограничениот веб, како што се новинските статии или блоговите за мислење, во мултијазични услови, истражувајќи ја и користта од обуката на повеќе јазици како и способностите за нула-снимка крстојазичен трансфер. И покрај тоа што широкиот опсег на јазични варијации пронајдени на веб-страницата претставува предизвици за класификација на регистарите, неодамнешните студии покажаа дека може да се постигнат добри нивоа на прекујазичен трансфер од екстремниот англиски корпус CORE на други јази Во оваа студија покажуваме дека обуката на повеќекратни јазици 1) има корист од јазиците со ограничени количини на регистарски анотирани податоци, 2) во просек постигнува резултати во споредба со монојазичните модели и 3) значително се подобрува со претходните резултати со нула снимка на фински, француски Најдобрите резултати се постигнати со мултијазичкиот модел XLM-R. Како податоци, ја користиме серијата CORE corpus со регистрирање на анотирани податоци од неограничен интернет.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>വെബില്‍ നിന്നും അസ്ഥിരപ്പെടാത്ത രേഖകളുടെ വിവരങ്ങളുടെ ക്ലാസ്ഫികേഷന്‍ രേജിസ്റ്റ് ചെയ്യുന്നു. വാര്‍ത്തകള്‍ അല്ലെങ്കില്‍ തിരിച്ചറിയുന്ന വ്യാഖ്യാപങ് വെബ് പോസിന്റെ വ്യത്യാസങ്ങളില്‍ കണ്ടെത്തിയിരിക്കുന്ന വ്യത്യാസങ്ങള്‍ക്ക് വേണ്ടി രേജിസ്റ്റര്‍ ക്ലാസ്ഫിക്ഷനുള്ള വിലാസങ്ങള്‍ക്ക് വേണ്ടി വെച്ച് ഈ പഠനത്തില്‍ നമ്മള്‍ കാണിക്കുന്നു, പല ഭാഷകളില്‍ പരിശീലിക്കുന്നത് നാം കാണിച്ചിരിക്കുന്നു. നിര്‍ണ്ണയിക്കപ്പെട്ട വിവരങ്ങളുടെ കൂട്ടത്തില്‍ നിര്‍ണ്ണയിക്കപ്പെട്ട വ ഏറ്റവും മികച്ച ഫലങ്ങള്‍ ഏറ്റവും മികച്ച ഭാഷ എക്സ്‌എല്‍എംആര്‍ മോഡലില്‍ എത്തിയിരിക്കുന്നു. വിവരങ്ങളായി നമ്മള്‍ കോര്‍പ്പുസ് സീരിസില്‍ ഉപയോഗിക്കുന്നു. റെജിസ്റ്റര്‍ വെബില്‍ നിന്നും വിവരിച്ചുകൊടുക്കുന</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Энэ баримтын судалгаагаар хэлний хэл дээр дасгал хөдөлгөөн болон тэгш хэлний шилжүүлэх боломжуудыг олон хэлний хэл дээр суралцах боломжтой боломжуудыг судалж байна. Веб дээр олон олон хэлний өөрчлөлт бичиж буй хэлний хэлбэрээс өөрчлөлт бичиж буй хэлбэрээс илүү сайн хэлний шилжүүлэлтийг харуулж байна. Энэ судалгаанд бид олон хэл дээр суралцах нь 1) хэл дээр хязгаарлагдсан өгөгдлийн хэмжээтэй ашигтай, 2) дунджаар нэг хэл загвартай үйл ажиллагааг гаргадаг, 3) Финляндын, Француз, Шведийн өмнөх 0 шат үр дүнд их сайжруулдаг. Хамгийн сайн үр дүн нь олон хэл XLM-R загвартай гарч ирсэн. Өгөгдлийн хувьд бид CORE корпус цувралыг ашиглаж байна. Хязгааргүй веб-ээс зарцуулсан мэдээллийг харуулж байна.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Artikel ini mempelajari klasifikasi dokumen dari web yang tidak terhalang, seperti artikel berita atau blog pendapat, dalam tetapan berbilang bahasa, mengeksplorasi kedua-dua keuntungan latihan dalam bahasa berbilang dan kemampuan untuk pemindahan saling bahasa tanpa tembakan sifar. Sementara julat luas variasi bahasa yang ditemui di web mengakibatkan cabaran untuk klasifikasi daftar, kajian baru-baru ini menunjukkan bahawa tahap yang baik pemindahan saling bahasa dari CORE corpus Inggeris yang luas ke bahasa lain boleh dicapai. Dalam kajian ini, kami menunjukkan bahawa latihan dalam bahasa berbilang 1) bahasa keuntungan dengan jumlah terbatas data yang dicatat-daftar, 2) rata-rata mencapai prestasi sama dengan model monobahasa, dan 3) meningkat jauh pada keputusan 0-shot terdahulu dalam bahasa Finlandia, Perancis dan Swedia. Hasil terbaik dicapai dengan model XLM-R berbilang bahasa. Sebagai data, kami menggunakan siri CORE corpus yang mengandungi daftar data yang dicatat dari web yang tidak terhalang.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Dan l-artikolu jistudja l-klassifikazzjoni tad-dokumenti mill-internet mhux ristrett, bħal artikoli tal-a ħbarijiet jew blogs tal-opinjonijiet, f’ambjent multilingwi, li jesplora kemm il-benefiċċju tat-taħriġ dwar lingwi multipli kif ukoll il-kapaċitajiet għal trasferiment translingwi b’ritratt żero. Filwaqt li l-firxa wiesgħa ta’ varjazzjoni lingwistika misjuba fuq l-internet to ħloq sfidi għall-klassifikazzjoni tar-reġistri, studji riċenti wrew li jistgħu jinkisbu livelli tajbin ta’ trasferiment translingwistiku mill-CORE corpus estensiv Ingliż għal lingwi oħra. F’dan l-istudju, nagħmlu evidenza li t-taħriġ dwar diversi lingwi 1) jibbenefika lingwi b’ammonti limitati ta’ dejta annotata fir-reġistru, 2) bħala medja jikseb prestazzjoni daqs mudelli monolingwi, u 3) itejjeb ħafna fuq riżultati preċedenti b’ritratt żero fil-Finlandiż, Franċiż u Svediż. L-aħjar riżultati jinkisbu bil-mudell XLM-R multilingwi. Bħala dejta, aħna nużaw is-serje CORE corpus li fiha reġistru tad-dejta annotata mill-internet mhux ristrett.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Dit artikel bestudeert registerclassificatie van documenten van het onbeperkte web, zoals nieuwsberichten of opinieblogs, in een meertalige omgeving, waarbij zowel het voordeel van training in meerdere talen als de mogelijkheden voor zero-shot cross-lingual transfer wordt onderzocht. Hoewel de grote verscheidenheid aan taalkundige variaties op het web uitdagingen oplevert voor de classificatie van registers, hebben recente studies aangetoond dat goede niveaus van trans-linguale overdracht van het uitgebreide Engelse CORE-corpus naar andere talen kunnen worden bereikt. In deze studie tonen we aan dat training in meerdere talen ten goede komt aan talen met beperkte hoeveelheden gegevens met aantekeningen in het register, 2) gemiddeld prestaties behaalt die vergelijkbaar zijn met eentalige modellen, en 3) aanzienlijk verbetert ten opzichte van eerdere zero-shot resultaten in het Fins, Frans en Zweeds. De beste resultaten worden bereikt met het meertalige XLM-R model. Als data gebruiken we de CORE corpusserie met registergeannoteerde gegevens uit het onbeperkte web.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Denne artikkelen studierer registrering av klassifikasjon av dokument frå ikkje-strekte nettet, slik som nye artikler eller synleg bloggar, i ein fleirspråk innstilling, og utforskar både nyttigheten på trening på fleire språk og kapasiteten for null-shot krysspråk overføring. Mens det brede området av lingviske variasjonar funne på nettet poserer utfordringar for registreringsklassifikasjon, har nyleg studiar vist at gode nivåar av krysspråk-overføring frå den ekstra engelske korpusen CORE til andre språk kan oppnå. I denne studien viser vi at opplæring på fleire språk 1) nyttar språk med begrensede mengdar av registrerte data, 2) gjennomsnittlig gjennomsnittlig gjennomsnittlig gjennomsnittlig gjennomsnittlig utvikling på par med monospråk modeller, og 3) er stort forbetra ved førre nullsatt resultat i finsk, fransk og svensk Den beste resultatene er oppnådd med den fleire språk XLM-R-modellen. Som data, bruker vi CORE-korpusserien som inneheld registrerte data frå nettet utan streking.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Niniejszy artykuł bada klasyfikację dokumentów pochodzących z nieograniczonej sieci internetowej, takich jak artykuły informacyjne czy blogi opinii, w wielojęzycznym otoczeniu, badając zarówno korzyści płynące ze szkolenia z wielu języków, jak i możliwości zerowego transferu między językami. Podczas gdy szeroki zakres zróżnicowań językowych znajdujących się w internecie stanowi wyzwanie dla klasyfikacji rejestru, ostatnie badania wykazały, że można osiągnąć dobry poziom transferu między językami z obszernego angielskiego korpusu CORE na inne języki. W niniejszym badaniu pokazujemy, że szkolenie z wieloma językami 1) korzysta z języków z ograniczoną ilością danych z adnotacjami rejestru, 2) średnio osiąga wydajność na równi z modelami jednojęzycznymi, a 3) znacznie poprawia wcześniej wyniki zero-shot w języku fińskim, francuskim i szwedzkim. Najlepsze rezultaty osiąga się z wielojęzycznym modelem XLM-R. Jako dane wykorzystujemy serię korpusów CORE zawierającą dane z adnotacji rejestru z nieograniczonej sieci internetowej.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Este artigo estuda a classificação de registros de documentos da web irrestrita, como artigos de notícias ou blogs de opinião, em um ambiente multilíngue, explorando tanto o benefício do treinamento em vários idiomas quanto os recursos para transferência de vários idiomas. Embora a ampla variedade de variações linguísticas encontradas na web represente desafios para a classificação de registros, estudos recentes mostraram que bons níveis de transferência entre idiomas do extenso corpus CORE inglês para outros idiomas podem ser alcançados. Neste estudo, mostramos que o treinamento em vários idiomas 1) beneficia idiomas com quantidades limitadas de dados anotados por registro, 2) em média alcança desempenho equivalente a modelos monolíngues e 3) melhora muito os resultados anteriores de tiro zero em finlandês, francês e sueco. Os melhores resultados são alcançados com o modelo multilíngue XLM-R. Como dados, utilizamos a série CORE corpus com dados cadastrais anotados da web irrestrita.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Acest articol studiază clasificarea documentelor de pe web fără restricții, cum ar fi articole de știri sau bloguri de opinie, într-un cadru multilingv, explorând atât beneficiile instruirii în mai multe limbi, cât și capacitățile de transfer încrucișat de zero-shot. În timp ce gama largă de variații lingvistice găsite pe internet reprezintă provocări în ceea ce privește clasificarea registrelor, studiile recente au arătat că pot fi atinse niveluri bune de transfer translingvistic de la corpul extins CORE în limba engleză la alte limbi. În acest studiu, demonstrăm că instruirea pe mai multe limbi 1) beneficiază limbile cu cantități limitate de date adnotate în registru, 2) atinge în medie performanțe egale cu modelele monolingve și 3) îmbunătățește considerabil rezultatele anterioare zero-shot în finlandeză, franceză și suedeză. Cele mai bune rezultate sunt obținute cu modelul XLM-R multilingv. Ca date, folosim seria CORE corpus care conține date adnotate de registru de pe web nelimitat.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>В этой статье изучается классификация документов из неограниченного Интернета, таких как новостные статьи или блоги мнений, в многоязычной среде, исследуя как преимущества обучения на нескольких языках, так и возможности для межязычной передачи с нулевым выстрелом. Хотя в связи с широким диапазоном лингвистических различий, наблюдаемых в Интернете, возникают проблемы с классификацией регистров, недавние исследования показали, что можно добиться хорошего уровня межязыкового перехода от обширного ОСНОВНОГО НАБОРА английских языков к другим языкам. В этом исследовании мы показываем, что обучение на нескольких языках 1) приносит пользу языкам с ограниченным объемом регистровых аннотированных данных, 2) в среднем достигает производительности наравне с одноязычными моделями и 3) значительно улучшается по сравнению с предыдущими результатами нулевого снимка на финском, французском и шведском языках. Наилучшие результаты достигаются с помощью многоязычной модели XLM-R. В качестве данных мы используем БАЗОВУЮ серию корпусов, содержащую регистровые аннотированные данные из неограниченной сети.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>මේ ලේඛනය අධ්‍යාස කරන්නේ නැති වෙබ් වලින් ලේඛනයේ ලේඛනය ලේඛනය ලේඛනය ලේඛනය ලේඛනය හා විශ්වාස බ්ලෝග් වලින්, බොහොම භාෂාවක සැකසුම් වලින් ප වෙබ් එකේ හොයාගත්ත භාෂාවික වෙනස් විසින් විසින් විසින් විසින් විසින් අවශ්‍ය වෙනුවෙන් විසින් විසින් විසින් විසින් විසින් ප්‍ර මේ පරීක්ෂණයේදී, අපි පෙන්වන්නේ වැඩි භාෂාවල් 1) භාෂාවට ප්‍රයෝජනය කරන්න පුළුවන් භාෂාවට ප්‍රයෝජනය කරන්න, 2) පරීක්ෂණයෙන් ප්‍රයෝජනයෙන් ප්‍රයෝජන හොඳම ප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිප්‍රතිය XLM-R ම දත්ත විදියට, අපි CORE කෝර්පුස් සීමාව පාවිච්චි කරනවා, ප්‍රතිස්ථාපනය කරන්නේ නැති වෙබ් වලින් ප්‍රති</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ta članek proučuje registrsko klasifikacijo dokumentov iz neomejenega spleta, kot so novinarski članki ali mnenjski blogi, v večjezičnem okolju, pri čemer raziskuje koristi usposabljanja o več jezikih in zmožnosti za brezposelni medjezični prenos. Medtem ko širok obseg jezikovnih različic, ki jih najdemo na spletu, predstavlja izzive za klasifikacijo registrov, so nedavne študije pokazale, da je mogoče doseči dobro raven medjezikovnega prenosa iz obsežnega angleškega korpusa CORE v druge jezike. V tej študiji smo pokazali, da usposabljanje na več jezikih 1) koristi jezikom z omejenimi količinami registriranih podatkov, 2) v povprečju doseže enako uspešnost kot enojezični modeli in 3) močno izboljša od prejšnjih ničelnih rezultatov v finščini, francoščini in švedščini. Najboljše rezultate dosežemo z večjezičnim modelom XLM-R. Kot podatki uporabljamo serijo korpusov CORE, ki vsebuje registrske podatke z oznakami iz neomejenega spleta.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Warqaddaas wuxuu ka baranayaa qoraalka qoraalka dukumentiyada ee internetka aan rasmi lahayn, tusaale ahaan warqadaha warqadaha ama bogagga aragtida, kaas oo ku baaraandegaya faa'iidada waxbarashada luuqadaha badan iyo awoodda wareejinta luuqadaha nooca ah. Inta lagu jiro iskuulka diiwaangelinta waxaa laga helaa dhibaatooyin kala duduwan oo luuqadaha kala duduwan, waxbarashada ugu dambeysayna waxay caddaynayeen in heerarka wanaagsan ee laga soo wareejiyo qoraalka afka ingiriisiga ee CORE ilaa luuqadaha kale. Waxbarashadan waxaynu tusnaynaa in waxbarasho ku qoran luuqado kala duduwan 1) lagu faa'iido luuqado ah oo ku qoran macluumaad diiwaangelinta, 2) ugu badnaan waxyaabaha lagu sameyn karo tusaalaha afka noocyada ah, iyo 3) waxey aad u bedeshaa arimaha hore oo lagu qoray Finnish, Faraansiis iyo Iswidishka. Midhaha ugu wanaagsan waxaa lagu helaa modelka XLM-R ee luuqadaha kala duduwan. Wixii macluumaad ah, waxaynu isticmaalnaa safarka CORE oo ku qoran macluumaadka diiwaangelinta oo la caddeeyey bogagga aan la isticmaalin.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>This article studies register classification of documents from the unrestricted web, such as news articles or opinion blogs, in a multilingual setting, exploring both the benefit of training on multiple languages and the capabilities for zero-shot cross-lingual transfer. Ndërsa gama e gjerë e variacioneve gjuhësore e gjetur në internet paraqet sfida për klasifikimin e regjistrimit, studimet e fundit kanë treguar se nivele të mira të transferimit ndërgjuhësor nga korpusi i gjerë anglez CORE në gjuhë të tjera mund të arrihen. In this study, we show that training on multiple languages 1) benefits languages with limited amounts of register-annotated data, 2) on average achieves performance on par with monolingual models, and 3) greatly improves upon previous zero-shot results in Finnish, French and Swedish. Rezultatet më të mira arrihen me modelin XLM-R shumëgjuhës. Si të dhëna, ne përdorim serinë CORE corpus që paraqet të dhëna të regjistruara nga rrjeti i pa kufizuar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ovaj članak proučava registriranje klasifikacije dokumenta iz neograničene mreže, kao što su novinski članovi ili blogovi mišljenja, u multijezičkom stanju, istražujući i korist obuke na višestrukim jezicima i mogućnosti za prebacivanje jezika nulog snimka. Iako širok raspon lingvističkih varijacija nalaženih na internetu predstavlja izazove za klasifikaciju registracija, nedavno ispitivanje pokazalo je da se mogu postići dobar nivo prevođenja preko jezika iz širokog engleskog korpusa CORE na druge jezike. U ovom ispitivanju pokazujemo da obuka na višestrukim jezicima 1) koristi jezike sa ograničenim količinama podataka o registraciji, 2) na prosjeku postiže učinkovitost na par sa monojezičkim modelima, a 3) veoma poboljšava na prethodnim rezultatima nule snimanja na finskom, francuskom i švedskom. Najbolji rezultati su postignuti sa multijezičkim XLM-R modelom. Kao podaci, koristimo seriju korpusa CORE-a koja uključuje registraciju annotiranih podataka iz neograničene mreže.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Denna artikel studerar klassificering av dokument från den obegränsade webben, såsom nyhetsartiklar eller opinionsbloggar, i en flerspråkig miljö, och undersöker både fördelarna med utbildning i flera språk och möjligheterna för noll-skott tvärspråklig överföring. Även om det breda utbudet av språkliga variationer som finns på webben innebär utmaningar för registerklassificering, har nyligen genomförda studier visat att goda nivåer av tvärspråklig överföring från den omfattande engelska CORE-korpusen till andra språk kan uppnås. I denna studie visar vi att utbildning på flera språk 1) gynnar språk med begränsade mängder registernoterade data, 2) i genomsnitt uppnår prestanda i nivå med enspråkiga modeller och 3) förbättrar avsevärt jämfört med tidigare nollskottsresultat på finska, franska och svenska. De bästa resultaten uppnås med den flerspråkiga XLM-R modellen. Som data använder vi CORE corpus-serien med registerkommenterade data från den obegränsade webben.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Makala hii inasoma kutangaza usambazaji wa nyaraka kutoka tovuti isiyo sahihi, kama vile makala za habari au blogu za maoni, katika mazingira ya lugha mbalimbali, kwa kutambua faida ya mafunzo katika lugha mbalimbali na uwezo wa usafirishaji wa lugha zisizo na sifa. Wakati mabadiliko mengi ya lugha yanayopatikana kwenye mtandao unaposhindwa changamoto za kutangazwa kwa ajili ya uandishi wa kujiandikisha, tafiti za hivi karibuni zimeonyesha kuwa kiwango vizuri cha uhamiaji wa lugha mbalimbali kutoka makampuni ya Kiingereza ya CORE hadi lugha nyingine zinaweza kufanikiwa. Katika utafiti huu, tunaonyesha kuwa mafunzo katika lugha mbalimbali ya 1) yanafaidia lugha zenye idadi kubwa ya taarifa zinazoandikishwa, 2) kwa wastani hufanikiwa utendaji wa mifano ya lugha za kimonolinguli, na 3) kwa kiwango kikubwa kinaongezeka kwa matokeo yasiyo na sifa iliyopita katika Kifinishi, Kifaransa na Kiswadishi. Matokeo bora yamefanishwa na modeli ya XLM-R ya lugha mbalimbali. Kama taarifa, tunatumia mfululizo wa makampuni ya CORE na kuonyesha taarifa zilizotajwa kutoka kwenye tovuti isiyo sahihi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>இந்த கட்டுரையில் அறியாத இணையத்திலிருந்து ஆவணங்கள் வகைப்படுத்தலை படிக்கும், செய்தி கட்டுரைகள் அல்லது கருத்துரைகள் போன்ற, பல மொழிகள் அமைப்பில், பல மொழிகளில் பயிற்ச While the wide range of linguistic variation found on the web poses challenges for register classification, recent studies have shown that good levels of cross-lingual transfer from the extensive English CORE corpus to other languages can be achieved. இந்த ஆராய்ச்சியில், நாம் பல மொழிகளில் பயிற்சியை காட்டுகிறோம் என்று காண்பிக்கிறோம் அது எல்லாம் பதிவேட்டில் குறிப்பிட்ட தகவல்களுடன் பயன்படுத்தப்படும் மொழிகளில் ஒர பல மொழி XLM-R மாதிரியால் சிறந்த முடிவுகள் அடையப்பட்டது. தகவலாக, நாம் CORE கார்ப்ஸ் தொடர்களை பயன்படுத்துகிறோம் வெளிப்படுத்தப்படாத இணையத்திலிருந்து பதிவு அறிவிக்கப்பட்ட தக</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Bu makala çykyş edilmedik web sahypalaryndan, täzelikler ýa-da düşünýän bloglary ýaly, bir näçe dil düzümlerinde, birnäçe diller üçin okuw gurmanyň faydasyny we zerw atly dillerden geçirmek üçin mümkinçilikleri bardyr. Web içinde bulunan lingwistiki üýtgeşmeler klasifikasy üçin kynçylyklar döredip görkezilýär, soňky araştyrmalar iňlisçe CORE korpusdan başga dillere ýetip bilýärler. Bu aramda, biz birnäçe diller üçin bilim taýýarlanmasy 1) sany diýmek isleýän dillerden, 2) ortalamada monolingw modelleri bilen taýýarlanmasy üçin gowurar, we 3) öňki 0-atak netijelerini Finlandiýa, fransuzça we Şwediýada gowurar. Iň gowy netijeler birnäçe dilli XLM-R modeli bilen berilýär. Maglumat hökmünde biz CORE korpus serisini ulanýarys, daýalanmaýan web tarapyndan berilen ýazylan maglumaty barýarlar.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>یہ لکھا بغیر محدودیت ویب سے لکھی ہوئی دلیلیں کا کلیسٹ کریسٹر کی تعلیم کرتا ہے، جیسے اخبار لکھائی یا منظور بلاگ، ایک بہت سی زبان تنظیم میں، دونوں کی تعلیم کے فائدہ کا تحقیق کرتا ہے بہت سی زبانوں پر اور صفر-شٹ کریسٹ While the wide range of linguistic variation found on the web poses challenges for register classification, recent studies have shown that cross-lingual transfer levels from the extensive English CORE corpus to other languages can be achieved. اس تحقیق میں ہم دکھاتے ہیں کہ تعلیم کئی زبانوں پر 1) لکھی زبانوں کا فائدہ پہنچاتا ہے جن کے ذریعہ سے محدودہ دکھائے گئے ہیں، 2) متوسط سے ایک زبان مدل کے ساتھ فائدہ پہنچاتا ہے، اور 3) فنلاندی, فرانسوی اور سوئدی کے پہلے صفر شوٹ نتیجے پر بہت اضافہ ہوتا بہترین نتیجے ملتی زبان کے XLM-R موڈل سے پہنچ جاتے ہیں. ہم نے CORE کورپوس سریریس کے طور پر استعمال کیا ہے جس میں رسیسٹر کے ذریعہ غیر محدودہ ویب سے اظہار کیا گیا ہے.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ushbu maqola mavjud boʻlmagan veb tarkibidagi hujjatlarni tahrirlash imkoniyatini o'rganadi, masalan news maqolalari yoki maoni bog'lanuvchilari, ko'plab tillarda, ko'plab tillar uchun trening foydalanishini va ikkita tillar orqali o'zgartirish imkoniyatini o'rganadi. Veb- saytda ko'p tillar o'zgarishning kengaytmalari qo'shish uchun muammolar bo'ladi. Yaqinda o'rganishlar qo'shilgan ingliz tilidan bogʻliq tillardan CORE corpusdan boshqa tillardan uzoq darajalari imkoniyatini ko'rsatadi. Bu taʼminotda biz bir necha tillar bilan bir xil tilda taʼminlov qilishni ko'rsatdik, boshqa tillar qo'llangan maʼlumotlar bilan chegara bo'lgan tillar bilan foydalanadi, 2) o'rtasida o'rtacha monolingual modellar bilan bajarishni bajaradi va 3) oldingi nuqta ishlatilgan natijalari Finnish, Fransuzcha va Sh Ko'pchilik tili XLM-R modeli bilan eng yaxshi natijalar bajarildi. Maʼlumotlar sifatida, biz CORE corpus seriидан foydalanamiz, oʻrnatilmagan veb- sahifa haqida yangilangan maʼlumotni tanlash mumkin.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>This article studies register classification of documents from the hạn chế web, such as news articles hay ý kiến blog, in a multiple settle, exploret both the condition of đào tạo on multiple languages and the capacity for zero-shot cross-ngôn ngữ. Trong khi những nghiên cứu gần đây đầy đủ các biến đổi ngôn ngữ trên trang web gây ra nhiều thử thách cho việc phân loại đăng ký, nhưng cũng có những nghiên cứu cho thấy có khả năng truyền qua ngôn ngữ rộng rãi từ tập đoàn Cortland tiếng Anh sang các ngôn ngữ khác. Trong nghiên cứu này, chúng tôi cho thấy giáo dục về nhiều ngôn ngữ Những kết quả tốt nhất được đạt được với mô hình XLM-R đa dạng. Là dữ liệu, chúng tôi sử dụng bộ R.E. với dữ liệu ghi chú từ mạng nội bộ không hạn chế.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>本文究于多言之境网络(如新闻文论博客)注册分类于文档,讨多种语言培训之益,及零次跨语移之功。 虽于网络上见广言语异于注册分类,而近者研明,从广英语CORE语料库到他语之跨言移水平可致也。 于此论之,多种语言之教1)使注册注有限之言受益,2)均至与单语相似,3)大改前芬兰语,法语与瑞典语之零拍摄也。 用多言 XLM-R 模可获得最佳效。 为数者,吾用CORE语料库系列,其包自不拘者网络注注数也。</span></div></div><dl><dt>Anthology ID:</dt><dd>2021.nodalida-main.16</dd><dt>Volume:</dt><dd><a href=/volumes/2021.nodalida-main/>Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa)</a></dd><dt>Month:</dt><dd>May 31--2 June</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Reykjavik, Iceland (Online)</dd><dt>Venue:</dt><dd><a href=/venues/nodalida/>NoDaLiDa</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Linköping University Electronic Press, Sweden</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>157–165</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.nodalida-main.16>https://aclanthology.org/2021.nodalida-main.16</a></dd><dt>DOI:</dt><dd></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">ronnqvist-etal-2021-multilingual</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Samuel Rönnqvist, Valtteri Skantsi, Miika Oinonen, and Veronika Laippala. 2021. <a href=https://aclanthology.org/2021.nodalida-main.16>Multilingual and Zero-Shot is Closing in on Monolingual Web Register Classification</a>. In <i>Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa)</i>, pages 157–165, Reykjavik, Iceland (Online). Linköping University Electronic Press, Sweden.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2021.nodalida-main.16>Multilingual and Zero-Shot is Closing in on Monolingual Web Register Classification</a> (Rönnqvist et al., NoDaLiDa 2021)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2021.nodalida-main.16.pdf>https://aclanthology.org/2021.nodalida-main.16.pdf</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2021.nodalida-main.16.pdf title="Open PDF of 'Multilingual and Zero-Shot is Closing in on Monolingual Web Register Classification'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=Multilingual+and+Zero-Shot+is+Closing+in+on+Monolingual+Web+Register+Classification" title="Search for 'Multilingual and Zero-Shot is Closing in on Monolingual Web Register Classification' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'Multilingual and Zero-Shot is Closing in on Monolingual Web Register Classification'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[Multilingual and Zero-Shot is Closing in on Monolingual Web Register Classification](https://aclanthology.org/2021.nodalida-main.16) (Rönnqvist et al., NoDaLiDa 2021)</p><ul class=mt-2><li><a href=https://aclanthology.org/2021.nodalida-main.16>Multilingual and Zero-Shot is Closing in on Monolingual Web Register Classification</a> (Rönnqvist et al., NoDaLiDa 2021)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Samuel Rönnqvist, Valtteri Skantsi, Miika Oinonen, and Veronika Laippala. 2021. <a href=https://aclanthology.org/2021.nodalida-main.16>Multilingual and Zero-Shot is Closing in on Monolingual Web Register Classification</a>. In <i>Proceedings of the 23rd Nordic Conference on Computational Linguistics (NoDaLiDa)</i>, pages 157–165, Reykjavik, Iceland (Online). Linköping University Electronic Press, Sweden.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>