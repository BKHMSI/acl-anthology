<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>A Package for Learning on Tabular and Text Data with Transformers - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css><meta content="A Package for Learning on Tabular and Text Data with Transformers" name=citation_title><meta content="Ken Gu" name=citation_author><meta content="Akshay Budhkar" name=citation_author><meta content="Proceedings of the Third Workshop on Multimodal Artificial Intelligence" name=citation_conference_title><meta content="2021/6" name=citation_publication_date><meta content="https://aclanthology.org/2021.maiworkshop-1.10.pdf" name=citation_pdf_url><meta content="69" name=citation_firstpage><meta content="73" name=citation_lastpage><meta content="10.18653/v1/2021.maiworkshop-1.10" name=citation_doi><meta property="og:title" content="A Package for Learning on Tabular and Text Data with Transformers"><meta property="og:image" content="https://aclanthology.org/thumb/2021.maiworkshop-1.10.jpg"><meta property="og:image:alt" content="First page of paper PDF."><meta property="og:type" content="article"><meta property="og:site_name" content="ACL Anthology"><meta property="og:url" content="https://aclanthology.org/2021.maiworkshop-1.10"><meta property="og:description" content="Ken Gu, Akshay Budhkar. Proceedings of the Third Workshop on Multimodal Artificial Intelligence. 2021."><link rel=canonical href=https://aclanthology.org/2021.maiworkshop-1.10></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><div><h2 id=title><a id=en_title href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>A Package for Learning on Tabular and Text Data with Transformers</a>
<a id=af_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Name</a>
<a id=am_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Table and Text Data with Transformers</a>
<a id=ar_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>حزمة للتعلم على البيانات الجدولية والنصية باستخدام المحولات</a>
<a id=az_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>T톛rc칲m톛 v톛 Metin Veril톛ri il톛 칐yr톛nm톛k 칲칞칲n Paket</a>
<a id=bg_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Пакет за обучение на таблици и текстови данни с трансформатори</a>
<a id=bn_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Name</a>
<a id=bo_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>ཤོག་བྱང་དང་ཡི་གེའི་ཆ་འཕྲིན་ཡིག་ཆ་དང་བསུབ་པའི་སྒྲིག་སྟངས</a>
<a id=bs_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Paket za učenje na tabularnim i tekstnim podacima s transformatorima</a>
<a id=ca_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Un paquet d'aprenentatge a les dades tabulars i textuals amb transformadors</a>
<a id=cs_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Balíček pro výuku tabulkových a textových dat s transformátory</a>
<a id=da_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>En pakke til læring om tabel- og tekstdata med transformatorer</a>
<a id=de_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Ein Paket zum Lernen von Tabellen- und Textdaten mit Transformatoren</a>
<a id=el_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Ένα πακέτο για τη μάθηση σε δεδομένα πίνακα και κειμένου με μετασχηματιστές</a>
<a id=es_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Un paquete para aprender datos tabulares y de texto con Transformers</a>
<a id=et_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Pakett tabel- ja tekstiandmete õppimiseks transformaatoritega</a>
<a id=fa_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Name</a>
<a id=fi_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Paketti taulukkotietojen ja tekstitietojen oppimiseen muuntajien avulla</a>
<a id=fl_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf></a>
<a id=fr_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Un package pour l'apprentissage des données tabulaires et textuelles avec Transformers</a>
<a id=ga_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Pacáiste le haghaidh Foghlama ar Shonraí Tábla agus Téacs le Claochladáin</a>
<a id=ha_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>A Package for Learning on Tabular and Text Data with Transformers</a>
<a id=he_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>חבילה ללמוד על מידע טקסט ולשולחן עם מעצבים</a>
<a id=hi_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>ट्रांसफॉर्मर के साथ सारणीबद्ध और पाठ डेटा पर सीखने के लिए एक पैकेज</a>
<a id=hr_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Paket za učenje na tabularnim i tekstnim podacima s transformatorima</a>
<a id=hu_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Táblázatos és szöveges adatok tanulására szolgáló csomag transzformátorokkal</a>
<a id=hy_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Comment</a>
<a id=id_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Pakej untuk Belajar di Data Tabular dan Teks dengan Transformer</a>
<a id=is_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf></a>
<a id=it_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Un pacchetto per imparare sui dati tabulari e di testo con i trasformatori</a>
<a id=ja_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>変圧器を使用した表形式およびテキストデータの学習パッケージ</a>
<a id=jv_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Name</a>
<a id=ka_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Name</a>
<a id=kk_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Қойындық мен мәтін деректерінің оқыту дестесіName</a>
<a id=ko_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Transformers 학습 표 및 텍스트 데이터를 사용하는 패키지</a>
<a id=lt_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>A Package for Learning on Tabular and Text Data with Transformers</a>
<a id=mk_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Пакет за учење на таблички и текстови податоци со трансформирачиName</a>
<a id=ml_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Name</a>
<a id=mn_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Хүснэгт болон Текст өгөгдлийн тухай сурах багц</a>
<a id=ms_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>A Package for Learning on Tabular and Text Data with Transformers</a>
<a id=mt_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Pakkett għat-Tagħlim fuq Dejta Tabulari u tat-Test bi Trasformaturi</a>
<a id=nl_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Een pakket voor leren over tabelvormige en tekstgegevens met transformers</a>
<a id=no_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Name</a>
<a id=pl_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Pakiet do nauki o danych tabelarnych i tekstowych z transformatorami</a>
<a id=pt_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Um pacote para aprendizado em dados tabulares e de texto com transformadores</a>
<a id=ro_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Un pachet pentru învățarea datelor tabulare și text cu transformatoare</a>
<a id=ru_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Пакет для обучения табличным и текстовым данным с трансформаторами</a>
<a id=si_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Name</a>
<a id=sk_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Paket za učenje tabelarnih in besedilnih podatkov s transformatorji</a>
<a id=so_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>A package for Learning on Table and Text Data with Transformers</a>
<a id=sq_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Një paketë për mësim në të dhënat tabelore dhe tekstore me transformues</a>
<a id=sr_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Paket za učenje na tabularnim i tekstskim podacima sa transformatorima</a>
<a id=sv_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Ett paket för att lära sig om tabeller och textdata med transformatorer</a>
<a id=sw_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Mpaka wa kujifunza kwenye Taarifa za Tabili na Matandao yenye Wasafiri</a>
<a id=ta_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Name</a>
<a id=tr_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Täbler we Metin Maglumaty Üýtgetmek üçin bir Paket</a>
<a id=uk_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf></a>
<a id=ur_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Name</a>
<a id=uz_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Name</a>
<a id=vi_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>Một gói tin để học trên các hình ảnh và các dữ liệu văn bản có biến hình</a>
<a id=zh_title style=display:none href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>用转换器学表格及文本数软件包</a></h2><p class=lead><a href=/people/k/ken-gu/>Ken Gu</a>,
<a href=/people/a/akshay-budhkar/>Akshay Budhkar</a></p></div><hr><div class="row acl-paper-details"><div class="col col-lg-10 order-2"><div class="card bg-light mb-2 mb-lg-3" id=en_abstract><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Recent progress in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> has led to Transformer architectures becoming the predominant model used for natural language tasks. However, in many real- world datasets, additional modalities are included which the <a href=https://en.wikipedia.org/wiki/Transformer>Transformer</a> does not directly leverage. We present Multimodal- Toolkit, an open-source Python package to incorporate text and tabular (categorical and numerical) data with Transformers for downstream applications. Our toolkit integrates well with Hugging Face&#8217;s existing API such as tokenization and the model hub which allows easy download of different pre-trained models.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=af_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Onlangse vordering in natuurlike taal-prosessering het gelei na Transformer-arkitekturke wat die voordekende model gebruik word vir natuurlike taal-taak. Alhoewel, in baie reël- wêreld datastelle, is addisionele modaliteite ingesluit wat die Transformer nie direk verwyder nie. Ons voorsien Multimodal- Nutsbalk, 'n oop- bron Python pakket om teks en tabulêer (kategoriese en numeriese) data te inkorpreer met Transformers vir onderstreem toepassings. Ons nutsbalkit integreer goed met Hugging Face se bestaande API soos tokenisasie en die model hub wat maklik laat af van verskillende voorafoerende modele toe.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=am_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>አዲስ የፍጥረት ቋንቋ ማቀናጃ ውስጥ የሚደረግ ግንኙነትን ለፍጥረት ቋንቋ ስራ የሚጠቀሙት መሠረት መሆኑን አቀረበ፡፡ ምንም እንኳን፣ በብዙ እውነተኛ- ዓለም ዳታዎች ውስጥ፣ በተጨማሪው ድርጅቶች በተጨማሪው ድርጅቶች ውስጥ የተገቡ ናቸው፡፡ Multimodal-Toolkit, open-source Python ጥቅል እና tabular (categorical and numerical) data with Transformers for downstream applications ለማግባት ነው፡፡ የመልኮታችን መሣሪያዎች የHugging ፊታችንን እንደምሳሌ ማስታወቂያ እና የሞዴል ክፍል በተለየ የፊደል ሞዴላዎችን ማውረድ የሚያስቀላል ነው፡፡</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ar_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>أدى التقدم الأخير في معالجة اللغة الطبيعية إلى أن تصبح معماريات Transformer هي النموذج السائد المستخدم في مهام اللغة الطبيعية. ومع ذلك ، في العديد من مجموعات البيانات في العالم الحقيقي ، يتم تضمين طرائق إضافية لا يستفيد منها المحول بشكل مباشر. نقدم مجموعة الأدوات متعددة الوسائط ، وهي حزمة Python مفتوحة المصدر لدمج البيانات النصية والجداول (الفئوية والرقمية) مع المحولات للتطبيقات النهائية. تتكامل مجموعة الأدوات الخاصة بنا بشكل جيد مع واجهة برمجة التطبيقات الحالية لـ Hugging Face مثل الرمز المميز ومحور النموذج الذي يسمح بتنزيل نماذج مختلفة مُدربة مسبقًا بسهولة.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=az_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Təbiətli dil işləməsində son tədbir tədbir edilməsi təbiətli dil işləri üçün istifadə edilən təbiətli modellərə çevrildi. Ancaq bir çox real dünya verilən qurğularında, Transformer'in düzgün istifadə etmədiyi papildu modüllər daxil edilir. Biz çoxlu-modal-araç çubuğunu, aşağı-aşağı proqramlar üçün Transformers üçün metin və tabular (kategorik və numerik) məlumatları birləşdirmək üçün açıq-kaynak Python paketini göstəririk. Bizim vasitələrimiz Hugging Face'in mövcuddur API ilə yaxşı birləşdirir, çünki tokenizasyon və modeli hub kimi, farklı əvvəlcə təhsil edilmiş modellərin asanlıqlarını indirməyə imkan verir.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bg_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Последният напредък в обработката на естествения език доведе до превръщането на архитектурите на трансформаторите в преобладаващия модел, използван за задачи с естествен език. Въпреки това, в много реални набори от данни са включени допълнителни модификации, които трансформаторът не използва пряко. Представяме Мултимодален инструментариум, пакет с отворен код за включване на текстови и таблични (категорични и цифрови) данни с трансформатори за приложения надолу по веригата. Нашият инструментариум се интегрира добре със съществуващия API като токенизация и моделния хъб, който позволява лесно изтегляне на различни предварително обучени модели.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>প্রাকৃতিক ভাষা প্রক্রিয়ায় সাম্প্রতিক অগ্রগতি প্রাকৃতিক ভাষার কাজের জন্য ব্যবহৃত প্রাকৃতিক ভাষার কাজের জন্য তবে অনেক বাস্তব-বিশ্বের তথ্য সেটে, যার মধ্যে অন্তর্ভুক্ত বৈষম্য রয়েছে যার মধ্যে ট্রান্সফার্নার নির্দেশ দেয় টেক্সট এবং ট্যাবুল (ক্যাটারেক্টারিক্যাল এবং সংখ্যা) ডাটার অন্তর্ভুক্ত করার জন্য আমরা মাল্টিমোডাল- টুলিকিট, একটি খোলা সোর্স পাইথন আমাদের টুলিকিট হুগিং মুখের বিদ্যমান এপিআই-এর সাথে ভালোভাবে একত্রিত করেছে, যেমন চিহ্নিত বিভিন্ন প্রশিক্ষিত মডেলের সহজে ডাউনলোড</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bo_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>རང་བཞིན་གྱི་སྐད་རིགས་ལས་སྦྱོར་བའི་འཕེལ་རིམ་དེ་ནི་བཟོ་བཅོས་ཁང་གཟུགས་རིས་ལ་མཐུན་ནུས་མེད་པའི་རྣམ་གྲངས་སྤ ཡིན་ནའང་། ངོ་མ་འཛམ་གླིང་ཡོད་པའི་གནས་ཚུལ་སྒྲིག་འགོད་མང་པོ་ཞིག་ལ་བཟོ་བཅོས་བྱེད་སྣང་བའི་ཐབས་ལམ་ཁྱབ་སྤྱོད་ We present Multimodal- Toolkit, an open-source Python package to incorporate text and tabular (categorical and numerical) data with Transformers for downstream applications. Our toolkit integrates well with Hugging Face's existing API such as tokenization and the model hub which allows easy download of different pre-trained models.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=bs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nedavno napredak u procesu prirodnog jezika doveo je do transformerske arhitekture da postanu glavni model koji se koristi za prirodne jezičke zadatke. Međutim, u mnogim podacima stvarnog svijeta uključuju se dodatni modaliteti koje Transformer ne utiče direktno. Predstavljamo Multimodalni Toolkit, paket Python otvorenog izvora za uključenje teksta i tabularnih (kategorijskih i numeričkih) podataka sa transformatorima za programe za snimke. Naš alat se dobro integrira sa postojećim API Hugging Face-om kao što su tokenizacija i model hub koji omogućava lako skinuti različite predobučene modele.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ca_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>El progrés recent en el processament natural de llenguatges ha portat a que les arquitectures Transformer es converteixin en el model predominant utilitzat per a tasques de llenguatges naturals. No obstant això, en molts conjunts de dades del món real, s'inclouen modalitats adicionals que el Transformer no utilitza directament. Presentam Multimodal-Toolkit, un paquet de Python de codi obert per incorporar text i dades tabulars (categóriques i numèriques) amb Transformers per aplicacions avall. El nostre conjunt d'eines s'integra bé amb l'API existent d'Hugging Face, com la tocenització i el centre model que permet descarregar fàcilment diferents models pré-entrenats.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=cs_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nedávný pokrok ve zpracování přirozeného jazyka vedl k tomu, že architektury Transformer se staly dominantním modelem používaným pro úlohy přirozeného jazyka. Nicméně v mnoha skutečných datových sadách jsou zahrnuty další modality, které Transformer přímo nevyužívá. Představujeme Multimodal- Toolkit, open-source Python balíček pro začlenění textových a tabulkových (kategorických a číselných) dat s transformátory pro následné aplikace. Náš nástroj se dobře integruje s existujícím API Hugging Face, jako je tokenizace a modelový hub, který umožňuje snadné stahování různých předškolených modelů.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=da_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nylige fremskridt inden for behandling af naturligt sprog har ført til, at Transformer-arkitekturer er blevet den dominerende model, der anvendes til opgaver med naturligt sprog. Men i mange datasæt i den virkelige verden, er yderligere modaliteter inkluderet, som Transformeren ikke direkte udnytter. Vi præsenterer Multimodal-Toolkit, en open source Python pakke til at indarbejde tekst og tabel (kategoriske og numeriske) data med Transformers til downstream applikationer. Vores værktøjssæt integrerer godt med Hugging Face's eksisterende API såsom tokenisering og model hub, som gør det nemt at downloade forskellige præ-trænede modeller.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=de_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Die jüngsten Fortschritte in der Verarbeitung natürlicher Sprache haben dazu geführt, dass Transformer-Architekturen das vorherrschende Modell für Aufgaben natürlicher Sprache geworden sind. In vielen realen Datensätzen sind jedoch zusätzliche Modalitäten enthalten, die der Transformer nicht direkt nutzt. Wir präsentieren Multimodal-Toolkit, ein Open-Source Python-Paket, das Text und tabellarische (kategorische und numerische) Daten mit Transformern für nachgelagerte Anwendungen integriert. Unser Toolkit lässt sich gut mit Hugging Face's bestehender API wie Tokenisierung und dem Model Hub integrieren, der einen einfachen Download verschiedener vortrainierter Modelle ermöglicht.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=el_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Η πρόσφατη πρόοδος στην επεξεργασία φυσικής γλώσσας έχει οδηγήσει στις αρχιτεκτονικές μετασχηματιστών να γίνουν το κυρίαρχο μοντέλο που χρησιμοποιείται για εργασίες φυσικής γλώσσας. Ωστόσο, σε πολλά σύνολα δεδομένων πραγματικού κόσμου, περιλαμβάνονται πρόσθετες λεπτομέρειες τις οποίες ο μετασχηματιστής δεν αξιοποιεί άμεσα. Παρουσιάζουμε ένα πακέτο ανοιχτού κώδικα για την ενσωμάτωση κειμένου και πινάκων (κατηγορηματικών και αριθμητικών) δεδομένων με μετασχηματιστές για μεταγενέστερες εφαρμογές. Η εργαλειοθήκη μας ενσωματώνεται καλά με το υπάρχον όπως η επισήμανση και ο κόμβος μοντέλου που επιτρέπει την εύκολη λήψη διαφορετικών προ-εκπαιδευμένων μοντέλων.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=es_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>El progreso reciente en el procesamiento del lenguaje natural ha llevado a que las arquitecturas Transformer se conviertan en el modelo predominante utilizado para las tareas del lenguaje natural. Sin embargo, en muchos conjuntos de datos del mundo real, se incluyen modalidades adicionales que el Transformer no aprovecha directamente. Presentamos Multimodal- Toolkit, un paquete Python de código abierto para incorporar texto y datos tabulares (categóricos y numéricos) con Transformers para aplicaciones posteriores. Nuestro kit de herramientas se integra bien con la API existente de Hugging Face, como la tokenización y el centro de modelos, que permite descargar fácilmente diferentes modelos previamente entrenados.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=et_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Hiljutised edusammud looduskeele töötlemisel on viinud Transformeri arhitektuuride muutumiseni peamiseks mudeliks, mida kasutatakse looduskeele ülesannetes. Paljudes reaalmaailma andmekogumites on siiski lisatud täiendavad meetodid, mida Transformer otseselt ei kasuta. Esitleme Multimodal- Toolkit, avatud lähtekoodiga Pythoni paketti, mis sisaldab teksti- ja tabeliandmeid (kategoorialised ja numbrilised) Transformeritega alljärgnevate rakenduste jaoks. Meie tööriistakomplekt integreerub hästi Hugging Face olemasoleva API-ga, nagu tokeniseerimine ja mudeli hub, mis võimaldab lihtsalt alla laadida erinevaid eeltreenitud mudeleid.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fa_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>پیشرفت اخیرا در پردازش زبان طبیعی به معماری تغییر دهنده به عنوان مدل پیشوایی که برای کار زبان طبیعی استفاده می‌شود تبدیل می‌شود. با این حال، در بسیاری از مجموعه‌های داده‌های واقعی دنیا، modalities additional include which the Transformer does not directly leverage. ما کیت multimodal- Toolkit را نشان می‌دهیم، یک بسته Python منبع باز برای شامل کردن متن و اطلاعات تبلیک (kategorical and numerical) با تغییردهندگان برای کاربردهای پایین سیستم. وسیله‌های ما با API موجود Hugging Face مثل توکین کردن و مدل‌هایی که اجازه می‌دهد آسان دانلود از مدل‌های پیش آموزش متفاوت را فراهم کند.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Luonnonkielen käsittelyn viimeaikainen kehitys on johtanut siihen, että Transformer-arkkitehtuurista on tullut luonnollisissa kielitehtävissä vallitseva malli. Moniin reaalimaailman datakokonaisuuksiin sisältyy kuitenkin muita menetelmiä, joita muuntaja ei suoraan hyödynnä. Esittelemme Multimodal- Toolkit, avoimen lähdekoodin Python-paketin, joka sisältää teksti- ja taulukkotietoja (kategorinen ja numeerinen) Transformers-ohjelmistojen kanssa jatko-sovelluksiin. Työkalupakkimme integroituu hyvin Hugging Facen olemassa olevaan API-rajapintaan, kuten tokenisointiin ja mallikeskukseen, joka mahdollistaa erilaisten esikoulutettujen mallien helpon lataamisen.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=fr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Les récents progrès dans le traitement du langage naturel ont conduit les architectures Transformer à devenir le modèle prédominant utilisé pour les tâches en langage naturel. Cependant, dans de nombreux ensembles de données du monde réel, des modalités supplémentaires sont incluses que le Transformer n'exploite pas directement. Nous présentons Multimodal-Toolkit, un package Python open source permettant d'intégrer du texte et des données tabulaires (catégoriques et numériques) avec Transformers pour les applications en aval. Notre boîte à outils s'intègre parfaitement à l'API existante de Hugging Face, telle que la tokenisation et le hub de modèles, qui permet de télécharger facilement différents modèles pré-entraînés.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ga_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Mar gheall ar an dul chun cinn a rinneadh le déanaí i bpróiseáil teanga nádúrtha is í ailtireacht Claochladáin an príomh-mhúnla a úsáidtear do thascanna nádúrtha teanga. Mar sin féin, i go leor tacar sonraí den fhíorshaol, cuirtear módúlachtaí breise san áireamh nach ndéanann an Trasfhoirmeoir giaráil díreach orthu. Cuirimid i láthair Multimodal- Toolkit, pacáiste foinse oscailte Python chun téacs agus sonraí tábla (catagóireacha agus uimhriúla) a ionchorprú le Transformers le haghaidh feidhmchláir iartheachtacha. Comhtháthaíonn ár bhfoireann uirlisí go maith leis an API atá ann cheana féin Hugging Face ar nós tokenization agus an mol múnla a cheadaíonn samhlacha réamhoilte éagsúla a íoslódáil go héasca.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ha_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>@ info: whatsthis Amma, cikin masu yawa na danna-duniya masu gaske, akwai wasu shiryoyin dabam da Transformer bã ya gaurar da hanya. Tuna halatar da Shirin Ayuka na Kwamfyuta Tsarin kayan aiki na sami da shirin Hugging Face na da ke gaba kamar shirin ayuka da kwamfyutan ayuka da ke yarda da download masu motsi na daban-danne.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=he_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>התקדמות האחרונה בעבודת שפת טבעית הובילה לארכיטקטורות טרנספורטר להפוך למודל הכי גדול שמשתמש למשימות שפת טבעיות. בכל אופן, במערכות נתונים רבות בעולם האמיתי, מודליות נוספות כוללות שהטרנספורטר לא משתמש באופן ישיר. אנחנו מציגים ערכת כלים מורכבת, חבילה Python מקור פתוח כדי לכלול טקסט ומידע טבלה (קטגורית ומספרית) עם Transformers לתוכניות מתחתיות. חבילת הכלים שלנו משתלבת היטב עם API הקיום של Hugging Face כמו tokenization והמרכז המודל שמאפשר להוריד בקלות של דוגמנים מאומנים מראש.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>प्राकृतिक भाषा प्रसंस्करण में हाल की प्रगति ने ट्रांसफॉर्मर आर्किटेक्चर को प्राकृतिक भाषा कार्यों के लिए उपयोग किया जाने वाला प्रमुख मॉडल बनने के लिए प्रेरित किया है। हालांकि, कई वास्तविक दुनिया के डेटासेट में, अतिरिक्त तौर-तरीकों को शामिल किया गया है जो ट्रांसफॉर्मर सीधे लाभ नहीं उठाता है। हम मल्टीमॉडल-टूलकिट, डाउनस्ट्रीम अनुप्रयोगों के लिए ट्रांसफॉर्मर के साथ पाठ और सारणीबद्ध (स्पष्ट और संख्यात्मक) डेटा को शामिल करने के लिए एक ओपन-सोर्स पायथन पैकेज प्रस्तुत करते हैं। हमारा टूलकिट फेस के मौजूदा एपीआई जैसे टोकनाइजेशन और मॉडल हब को गले लगाने के साथ अच्छी तरह से एकीकृत करता है जो विभिन्न पूर्व-प्रशिक्षित मॉडलों के आसान डाउनलोड की अनुमति देता है।</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nedavno napredak prirodnog obrazovanja jezika doveo je do arhitekture transformera postajući predsjednik koji se koristi za prirodne jezičke zadatke. Međutim, u mnogim podacima stvarnog svijeta uključuju se dodatni modaliteti koje Transformer ne primjenjuje direktno. Predstavljamo Multimodalni Toolkit, otvoreni Python paket za uključivanje teksta i tabularnih (kategorijskih i brojnih) podataka s transformacijama za prijave za dolje. Naš alat se dobro uključuje s postojećim API Hugging Face-om kao što su tokenizacija i model hub koji omogućava lako preuzimanje različitih predobučenih modela.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hu_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>A természetes nyelv feldolgozásának közelmúltbeli fejlődése miatt a Transformer architektúrák a természetes nyelvi feladatok meghatározó modelljévé váltak. Számos valós adatkészletben azonban további módszereket is tartalmaznak, amelyeket a Transzformátor nem használ közvetlenül. Bemutatjuk a Multimodális- Toolkit-et, egy nyílt forráskódú Python csomagot, amely szöveget és táblázatos (kategorikus és numerikus) adatokat foglal magába a transzformátorokkal downstream alkalmazásokhoz. Eszközkészletünk jól integrálódik a Hugging Face meglévő API-jával, mint például a tokenizáció és a modell hub, amely lehetővé teszi a különböző előre képzett modellek egyszerű letöltését.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=hy_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Վերջերս բնական լեզուների վերաբերյալ զարգացումը հանգեցրեց, որ տրանսֆերմերի ճարտարապետությունները դառնան բնական լեզուների խնդիրների համար օգտագործվող գլխավոր մոդելը: Այնուամենայնիվ, շատ իրական աշխարհի տվյալների համակարգերում ներառված են ավելացյալ մեթոդներ, որոնք Transforme-ը անմիջապես չի ազդում: Մենք ներկայացնում ենք Բազմամոդալ-Գործիքների համակարգ, բաց աղբյուր Պիթոն փաթեթ, որը ներառում է տեքստի և տախտային (կատեգորիկական և թվային) տվյալներ Transforme-ների հետ հետագա ծրագրերի համար: Մեր գործիքների շարքը լավ ինտեգրվում է Հուգինգ Ֆեյսի գոյություն ունեցող API-ի հետ, ինչպիսիք են թոկենիզացիան և մոդելի կենտրոնը, որը հնարավորություն է տալիս հեշտ ներբեռնել տարբեր նախապատրաստված մոդելներ:</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=id_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kemajuan baru-baru ini dalam proses bahasa alam telah menyebabkan arsitektur Transformer menjadi model dominan yang digunakan untuk tugas bahasa alam. Namun, dalam banyak set data dunia nyata, modalitas tambahan termasuk yang Transformer tidak secara langsung mengambil alih. Kami mempersembahkan Multimodal- Toolkit, sebuah paket Python sumber terbuka untuk memasukkan teks dan data tabular (kategori dan numerik) dengan Transformers untuk aplikasi turun. Paket alat kita terintegrasi dengan API yang ada Hugging Face seperti tokenization dan model hub yang memungkinkan muat turun mudah dari model yang berlatih.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=it_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>I recenti progressi nell'elaborazione del linguaggio naturale hanno portato le architetture Transformer a diventare il modello predominante utilizzato per le attività di linguaggio naturale. Tuttavia, in molti dataset del mondo reale, sono incluse modalità aggiuntive che il Transformer non sfrutta direttamente. Vi presentiamo Multimodal- Toolkit, un pacchetto Python open source per incorporare testo e dati tabulari (categorici e numerici) con Transformers per applicazioni downstream. Il nostro toolkit si integra bene con l'API esistente di Hugging Face come la tokenizzazione e l'hub del modello che consente di scaricare facilmente diversi modelli pre-addestrati.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ja_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>自然言語処理の最近の進歩により、Transformerアーキテクチャは自然言語タスクに使用される主なモデルになりました。しかし、多くの現実世界のデータセットでは、トランスフォーマーが直接レバレッジしない追加のモダリティが含まれています。マルチモーダルツールキットは、オープンソースのPythonパッケージで、下流アプリケーションのためのTransformersとのテキストおよび表形式（カテゴリおよび数値）データを組み込むことができます。当社のツールキットは、トークン化やモデルハブなど、Hugging Faceの既存のAPIとうまく統合されており、さまざまな事前にトレーニングを受けたモデルを簡単にダウンロードできます。</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=jv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>FindOK politenessoffpolite"), and when there is a change ("assertivepoliteness We present Multimodal- Tool lkit, an open-source Arkit-tool sing ditambah gambaran karo Api yang saben nggawe, lagi tokenizer karo model</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ka_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>მიმდინარე პროგრესი თავისუფალური ენის პროცესის შესახებ ტრანფორმეტრის აქტიქტიქტურების შესახებ, რომელიც თავისუფალური ენის დავალებებისთვის გამ მაგრამ, ბევრი რეალური მსოფლიოს მონაცემების კონფიგურაციაში, დამატებული მოდილიტები ჩვენებულია, რომლებიც ტრანფიგურაციატორი არ ექსტურ ჩვენ მრავალმედიალური ხელსაწყობილობის კონფიგურაცია, გახსნილი Python ფოკეტის პაკეტი, რომელიც ტექსტის და ტაბულური (კატეგორიალური და ციფრიური) მონაცემების შეყვარე ჩვენი ხელსაწყოთა კიტი ძალიან ინტერგურაცია, როგორც ტოკენიზაცია და მოდელური ჰუბი, რომელიც განსხვავებული პრე-განსწავლებული მოდელების განმავლობაში ადვილი გადატანა.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=kk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Табиғи тіл процессінің жаңа жағдайда архитектураларды түрлендіру үшін табиғи тіл тапсырмалар үшін қолданылатын үлгі болады. Бірақ көптеген шын әлемдегі деректер қорларында Трансформациясы тікелей тәртіпке жеткізбейтін қосымша әдістер қосылады. Мәтін мен кестелер (сандар мен сандар) деректерін төменгі қолданбалар үшін Трансформациялау құралдарының көшірмесі Python бағдарламасының көшірмесі. Біздің құралдар панеліміз Hugging Face- дің барлық API мен бірге біріктіреді, мысалы, токенизациялау мен өзгертілген алдындағы моделдерді оңай жүктеуге мүмкіндік беретін моделдерді.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ko_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>자연 언어 처리의 최신 진전은 변환기 구조를 자연 언어 임무의 주요 모델로 만들었다.그러나 많은 실제 세계의 데이터가 집중되어 변압기가 직접적으로 이용하지 않는 다른 모델을 포함하고 있다.우리는 텍스트와 표 (분류, 디지털) 데이터를 변환기와 결합시켜 하위 응용 프로그램에 사용하는Multimodal-Toolkit을 보여 줍니다.Google 패키지는 Hugging Face의 기존 API(예를 들어 표기화)와 모델 센터(model hub)와 잘 통합되어 서로 다른 예비 트레이닝 모델을 쉽게 다운로드할 수 있습니다.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=lt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Pastaruoju metu gamtinės kalbos apdorojimo pažanga lėmė, kad transformuotojų architektūros tapo vyraujančiu gamtinės kalbos užduotims naudojamu modeliu. However, in many real- world datasets, additional modalities are included which the Transformer does not directly leverage. Mes pristatome Multimodal- Toolkit, atviro kodo Python paketą, kuriame bus įtraukti teksto ir lentelių (kategorijinių ir skaitmeninių) duomenys su Transformers tolesnėms programoms. Mūs ų įrankių rinkinys gerai integruojamas su esama Hugging Face API, pvz., tokenizacija ir modelio centras, kuris leidžia lengvai parsisiųsti įvairius iš anksto parengtus modelius.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Неодамнешниот напредок во природното обработување на јазиците доведе до трансформарните архитектури да станат претежниот модел кој се користи за природните јазични задачи. Сепак, во многу податоци од реалниот свет се вклучени дополнителни модијали кои Трансформерот не ги влијае директно. We present Multimodal- Toolkit, an open-source Python package to incorporate text and tabular (categorical and numerical) data with Transformers for downstream applications. Our toolkit integrates well with Hugging Face's existing API such as tokenization and the model hub which allows easy download of different pre-trained models.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ml_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>സ്വാഭാവിക ഭാഷയുടെ പ്രക്രിയഭാഷയുടെ അടുത്തുള്ള പുരോഗതി സ്വാഭാവിക ഭാഷയുടെ ജോലികള്‍ക്കായി ഉപയോഗിക്കുന്ന പ്രകൃ എന്നാലും, പലതും യഥാര്‍ത്ഥ ലോക ഡാറ്റാസറ്റുകളില്‍, കൂടുതല്‍ മാറ്റങ്ങള്‍ നേരിട്ട് ട്രാന്‍സ്ഫോര്‍മാര്‍ നേരിട്ട് ടെക്സ്റ്റും ടാബുളും (categorical and numerical) ഡേറ്ററുകളുമായി ട്രാന്‍സ്ട്രീമില്‍ പ്രയോഗങ്ങള്‍ക്ക് വേണ്ടി ട്രാന്‍സ്ഫോര്‍മാരുമായി ഒരു തുറന്ന സോ ഞങ്ങളുടെ ഉപകരണക്കിടം ഹുഗിംഗ് മുഖം നിലവിലുള്ള ഏപിഐ പോലെ ഒരുമിച്ചിരിക്കുന്നു. ടോണിക്ഷനേഷനും മോഡല്‍ ഹുബും പോലെ വ്യത്യസ്ത പരിശീ</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mn_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Байгалийн хэл үйлдвэрлэлийн саяхан хөгжлийн үр дүнд байгалийн хэл үйлдвэрлэлд хэрэглэгддэг архитектурууд Трансфер архитектурууд болж ирсэн. Гэхдээ маш олон бодит ертөнцийн өгөгдлийн санд Трансформатор шууд хэрэглэхгүй нэмэлт арга замыг нэмэгдүүлдэг. Бид олон моделийн хэрэгсэл бөгөөд, нээлттэй эх үүсвэртэй Python багцлагыг өгөгдлийг доорх хэрэглэмжүүдийн Трансформ болон таблицын (категорийн болон тоон) өгөгдлийг нэгтгэх болно. Бидний хэрэгслийн суурь нь Hugging Face-ийн суурилсан API-тэй сайн нэгтгэдэг. Яг л тодорхойлолт, загварын холбоотой. Энэ нь өөр олон сургалтын өмнө сургалтын загваруудыг хялбар авах боломжтой бол</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ms_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Kemajuan baru-baru ini dalam pemprosesan bahasa alami telah menyebabkan arkitektur Transformer menjadi model utama yang digunakan untuk tugas bahasa alami. Bagaimanapun, dalam banyak set data dunia nyata, modaliti tambahan termasuk yang Transformer tidak secara langsung mengambil alih. Kami perkenalkan Multimodal- Toolkit, pakej Python sumber terbuka untuk menggabungkan teks dan data tabular (kategori dan nombor) dengan Transformers untuk aplikasi turun. Kit alat kami menyertai dengan baik dengan API yang wujud Hugging Face seperti tokenization dan hub model yang membolehkan muat turun mudah bagi model yang berlainan yang dilatih.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=mt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Recent progress in natural language processing has led to Transformer architectures becoming the predominant model used for natural language tasks. However, in many real- world datasets, additional modalities are included which the Transformer does not directly leverage. We present Multimodal- Toolkit, an open-source Python package to incorporate text and tabular (categorical and numerical) data with Transformers for downstream applications. Our toolkit integrates well with Hugging Face's existing API such as tokenization and the model hub which allows easy download of different pre-trained models.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=nl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Recente vooruitgang in de verwerking van natuurlijke taal heeft ertoe geleid dat Transformer architecturen het dominante model zijn geworden voor natuurlijke taaltaken. In veel real-world datasets zijn echter aanvullende modaliteiten opgenomen die de Transformer niet direct benut. We presenteren Multimodal-Toolkit, een open-source Python pakket om tekst en tabulaire (categorische en numerieke) gegevens te integreren met Transformers voor downstream toepassingen. Onze toolkit integreert goed met Hugging Face's bestaande API, zoals tokenization en de model hub, waardoor verschillende voorgetrainde modellen eenvoudig kunnen worden gedownload.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=no_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nyleg framgang i naturspråkshandtering har ført til å transformera arkitektur bli den viktigste modellen brukt for naturspråksoppgåver. I mange verdsetata er imidlertid tilleggsmodular som Transformeren ikkje direkte leverer. Vi presenterer multimodal verktøykassett, eit opna kjeldepakke for Python som inkluderer tekst og tabulatordata (kategorisk og numerisk) med Transformerer for nedstrekkprogram. Vårt verktøykassett integrerer godt med den eksisterande API til Hugging Face som tokenisering og modellhuben som tillater enkelt nedlasting av ulike føretrengde modeller.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pl_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Ostatnie postępy w przetwarzaniu języka naturalnego doprowadziły do tego, że architektury Transformera stały się dominującym modelem stosowanym do zadań języka naturalnego. Jednak w wielu zbiorach danych świata rzeczywistego zawiera się dodatkowe modalności, których Transformer nie wykorzystuje bezpośrednio. Przedstawiamy Multimodal- Toolkit, open-source pakiet Pythona, który umożliwia włączenie danych tekstowych i tabelarnych (kategorycznych i numerycznych) z Transformerami do dalszych aplikacji. Nasz zestaw narzędzi dobrze integruje się z istniejącym interfejsem API Hugging Face, takim jak tokenizacja i centrum modelu, który umożliwia łatwe pobieranie różnych wstępnie przeszkolonych modeli.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=pt_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>O progresso recente no processamento de linguagem natural fez com que as arquiteturas Transformer se tornassem o modelo predominante usado para tarefas de linguagem natural. No entanto, em muitos conjuntos de dados do mundo real, são incluídas modalidades adicionais que o Transformer não aproveita diretamente. Apresentamos o Multimodal- Toolkit, um pacote Python de código aberto para incorporar texto e dados tabulares (categóricos e numéricos) com Transformers para aplicativos downstream. Nosso kit de ferramentas se integra bem com a API existente do Hugging Face, como tokenização e o hub de modelos, que permite o download fácil de diferentes modelos pré-treinados.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ro_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Progresele recente în procesarea limbajului natural au condus la arhitecturile Transformer devenind modelul predominant utilizat pentru sarcinile de limbaj natural. Cu toate acestea, în multe seturi de date din lumea reală, sunt incluse modalități suplimentare pe care Transformerul nu le utilizează direct. Vă prezentăm Multimodal- Toolkit, un pachet Python open-source pentru a încorpora text și date tabulare (categorice și numerice) cu Transformers pentru aplicații din aval. Setul nostru de instrumente se integrează bine cu API-ul existent al Hugging Face, cum ar fi tokenizarea și hub-ul modelului, care permite descărcarea ușoară a diferitelor modele pre-instruite.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ru_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Недавний прогресс в обработке естественного языка привел к тому, что архитектуры трансформаторов стали преобладающей моделью, используемой для задач естественного языка. Тем не менее, во многих наборах данных реального мира включены дополнительные модальности, которые Трансформер напрямую не использует. Мы представляем Multimodal- Toolkit, пакет Python с открытым исходным кодом для интеграции текстовых и табличных (категориальных и числовых) данных с Трансформаторами для последующего применения. Наш инструментарий хорошо интегрируется с существующим API Hugging Face, таким как токенизация и концентратор моделей, который позволяет легко загружать различные предварительно обученные модели.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=si_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>ස්වාභාවික භාෂාව ප්‍රක්‍රියාපනයේ අන්තිම ප්‍රභාවිත විද්‍යාපනය විද්‍යාපනය කරනවා ස්වාභික භාෂා නමුත්, ඇත්ත- ලෝකයේ දත්ත සෙට් වලින්, තවත් මොඩියුල් සම්බන්ධ වෙලා තියෙන්නේ මොඩියුල් තියෙන්නේ ම Name අපේ උපකරණ කිට් හොඳටම හුගින් ෆේස්ගේ තියෙන ඉන්න API වලින් ටොකෙනිස් සහ මොඩේල් හුබ් වලින් සමහර විවිධ ප්‍රධානය කරපු</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sk_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nedavni napredek pri obdelavi naravnega jezika je pripeljal do tega, da so arhitekture transformatorjev postale prevladujoči model, ki se uporablja za naloge naravnega jezika. Vendar pa so v številnih resničnih zbirkah podatkov vključene dodatne načine, ki jih transformator ne uporablja neposredno. Predstavljamo Multimodal- Toolkit, odprtokodni paket Python, ki vključuje besedilo in tabularne (kategorične in numerične) podatke s transformatorji za nadaljnje aplikacije. Naš komplet orodij se dobro integrira z obstoječim API-jem Hugging Face, kot sta žetonizacija in vozlišče modela, ki omogoča enostaven prenos različnih predhodno usposobljenih modelov.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=so_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Horumarinta ugu dambeysa ee baaraandegista luqada dabiicadda ah wuxuu u keenay dhismaha wareejinta oo ay noqdaan modelkii ugu horeeya ee loo isticmaalay shaqooyinka afka dabiicadda ah. Si kastaba ha ahaatee, waxaa ku jira habab dheeraad ah oo uu turjubaanku si toos ah u isticmaalayo. We present Multimodal- Toolkit, an open-source Python package to incorporate text and tabular (categorical and numerical) data with Transformers for downstream applications. Qorigayada qalabka ayaa si wanaagsan u qabsada afka Hugging ee uu heysto API, tusaale ahaan calaamad iyo muusikada, kaas oo sahlan soo dejin kara modello kala duduwan oo horay loo tababaray.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sq_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Përparimi i fundit në procesimin natyror të gjuhës ka shpjerë në arkitekturat Transformer të bëhen modeli mbizotërues i përdorur për detyrat natyrore të gjuhës. Megjithatë, në shumë grupe të dhënash të botës reale, janë përfshirë modalitete shtesë që Transformuesi nuk përfshin drejtpërdrejt. Ne paraqesim Multimodal- Toolkit, një paketë Python me burim të hapur për të përfshirë tekst dhe të dhëna tabulare (kategorike dhe numerike) me Transformers për aplikimet e poshtme. Paketa jonë mjete integrohet mirë me API ekzistuese të Hugging Face si tokenization dhe model hub që lejon shkarkimin e lehtë të modeleve të ndryshme të paratrajnuara.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Nedavno napredak u procesu prirodnog jezika doveo je do transformerske arhitekture da postanu predominantni model koji se koristi za prirodne jezičke zadatke. Međutim, u mnogim stvarnim svijetskim podacima, uključuju se dodatni modaliteti koje Transformer ne utiče direktno. Predstavljamo Multimodalni Toolkit, paket otvorenog izvora Python za uključenje teksta i tabularnih (kategorijskih i numeričkih) podataka sa transformacijama za programe koji se nalaze niz stranu. Naš toolkit se dobro integrira sa postojećim API Hugging Face-om kao što su tokenizacija i model hub koji omogućava lako skinuti različite predobučene modele.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sv_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>De senaste framstegen inom bearbetningen av naturligt språk har lett till att Transformer-arkitekturer blivit den dominerande modellen som används för naturliga språkuppgifter. Men i många verkliga datauppsättningar ingår ytterligare metoder som Transformern inte direkt utnyttjar. Vi presenterar Multimodal- Toolkit, ett Python-paket med öppen källkod för att införliva text och tabelldata (kategoriska och numeriska) med Transformers för nedströms applikationer. Vår verktygslåda integreras väl med Hugging Faces befintliga API såsom tokenisering och modellhubben som gör det enkelt att ladda ner olika förintränade modeller.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=sw_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Maendeleo ya hivi karibuni katika upasuaji wa lugha za asili yamesababisha majengo ya Kupitisha kuwa modeli muhimu inayotumiwa kwa ajili ya kazi za lugha za asili. Hata hivyo, katika seti nyingi za taarifa za dunia halisi, mbinu za ziada zinajumuisha ambazo WaTransfer hawatumii moja kwa moja. Tunaweza kuweka kituo cha Kifaa cha Multimodal-Tool, kitengele cha Python kilicho wazi kwa ajili ya kuingiza taarifa za maandishi na tabia (makundi na tarakimu) kwa ajili ya matumizi ya mitandao ya chini. Vifaa vyetu vinaunganisha vizuri na API iliyopo Hugging Face kama vile uthibitisho na kituo cha modeli ambacho kinaruhusu kupandisha mifano tofauti ya mafunzo ya awali.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ta_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>சமீபத்தில் இயல்பான மொழி செயல்படுத்தலின் முன்னேற்றம் இயல்பான மொழி பணிகளுக்கு பயன்படுத்தப்பட்ட முக்கிய மாதிரியான ம ஆனால், பல உண்மையான- உலக தரவுத்தளங்களில், மாற்றி நேரடியாக ஒப்புக்கொள்ளாத கூடுதல் வகைகள் உள்ளன. நாங்கள் பல மூலக் கருவிப்புக்கூட்டு, ஒரு திறந்த மூலத்தின் பைதான் தொகுப்பு, உரையை மற்றும் அட்டவணை (வகையான மற்றும் எண்ணிக்கை) தகவல்களை கூட்டு எங்கள் கருவிப்பெட்டி ஹங்கிங் முகத்தில் இருக்கும் API போன்ற ஒருங்கிணைக்கும், அது வேறு முன் பயிற்சிக்கப்பட்ட மாதிரிகளின் எளிதாக</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=tr_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Doýal diller işlemeginiň öňki täzelikleri tebigy diller üçin ullanýan arhitekturlary üýtgedir. Ýöne, birnäçe sanat dünýäde maglumat setirlerinde, esasy modlerde terjime etmeýän modlerde dahil edildi. Biz Multimodal-Esbap zolaky, Açyk-çeşme Python paketi metin we täblikler (kategoriýal we sayyk) maglumaty aşaky uygulamalar üçin terjime etmek üçin bir paketi görkeýäris Biziň alet çykyşlarymyz Hugging Face'iň bar API bilen gowy birleştirilýär. Öňünden öňünden bilinmiş modelleriň ýeňil ýüklemegine mümkin edýän nusgalary.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=ur_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>طبیعی زبان پردازی میں اچھی پیشرفت کی وجہ سے تغییر معماری بنانے کے لئے طبیعی زبان کے کاموں کے لئے استعمال کیا جاتا ہے۔ However, in many real- world datasets, additional modalities are included which the Transformer does not directly leverage. ہم ملٹی موڈال- تولکیٹ کو پیش کریں گے، ایک کھولی- سورس پیٹون پاکس کے لئے پاکستان اور ٹاکلور (کاٹی اور شماری) ڈائٹ ڈونسٹریم کاربریوں کے ساتھ تغییرات کرنے والوں کے ساتھ شامل کریں گے۔ ہماری تولیک کیٹ ہیونگ فیس کے موجود API کے ساتھ اچھی طرح تفسیر کرتی ہے جیسے ٹوکنیزی اور موڈل ہب جو مختلف پیش آموزش کی موڈلیوں کے آسان ڈونلوڈ کی اجازت دیتا ہے.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=uz_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>@ info: whatsthis Ammo, ko'pchilik dunyo maʼlumotlar tarkibida, Transfer toʻgʻri ishlatilmagan qoʻshimcha usullar bor. @ info: whatsthis Bizning asboblar kitoblarimiz Hugging Faceb mavjud API bilan birga birlashtiriladi. Bu model hub boshqa taʼminlovchi modellarni yozib olish imkoniyatini yordam beradi.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=vi_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>Sự tiến bộ gần đây trong việc xử lý ngôn ngữ tự nhiên đã khiến các kiến trúc biến hình thành mô hình nổi bật sử dụng cho các nhiệm vụ ngôn ngữ tự nhiên. Tuy nhiên, trong nhiều bộ dữ liệu thế giới thực, có thêm phương thức mà Transformer không trực tiếp hoạt động. Chúng tôi giới thiệu các tập cụ đa phương, một gói Python mở nguồn để cung cấp các dữ liệu cấu hình (và số) dứt điểm với các biến hình cho các ứng dụng xuôi dòng. Bộ hỗ trợ của chúng ta hòa hợp tốt với API hiện có của Huging Face như tokenition và mô hình trung tâm cho phép tải tải xuống dễ dàng các mẫu đã được huấn luyện.</span></div></div><div class="card bg-light mb-2 mb-lg-3" id=zh_abstract style=display:none><div class="card-body acl-abstract"><h5 class=card-title>Abstract</h5><span>自然语言理之最新进展Transformer架构为自然语言务大体。 然世界数集,变形金刚无径用者模态。 余言Multimodal-Toolkit,此一开源Python包也,以合文本与表格(数)数与Transformers并为下流应用程序。 吾工具包与Hugging Face之见API善相聚,若标化与中心,可以轻下载异者。</span></div></div><dl><dt>Anthology ID:</dt><dd>2021.maiworkshop-1.10</dd><dt>Volume:</dt><dd><a href=/volumes/2021.maiworkshop-1/>Proceedings of the Third Workshop on Multimodal Artificial Intelligence</a></dd><dt>Month:</dt><dd>June</dd><dt>Year:</dt><dd>2021</dd><dt>Address:</dt><dd>Mexico City, Mexico</dd><dt>Venues:</dt><dd><a href=/venues/naacl/>NAACL</a>
| <a href=/venues/maiworkshop/>maiworkshop</a></dd><dt>SIG:</dt><dd></dd><dt>Publisher:</dt><dd>Association for Computational Linguistics</dd><dt>Note:</dt><dd></dd><dt>Pages:</dt><dd>69–73</dd><dt>Language:</dt><dd></dd><dt>URL:</dt><dd><a href=https://aclanthology.org/2021.maiworkshop-1.10>https://aclanthology.org/2021.maiworkshop-1.10</a></dd><dt>DOI:</dt><dd><a href=http://dx.doi.org/10.18653/v1/2021.maiworkshop-1.10 title="To the current version of the paper by DOI">10.18653/v1/2021.maiworkshop-1.10</a></dd><dt class=acl-button-row>Bibkey:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citePaperBibkey><i class="far fa-clipboard"></i><span id=citePaperBibkey class="pl-2 text-monospace">gu-budhkar-2021-package</span></button></dd><dt>Cite (ACL):</dt><dd><span id=citeACL>Ken Gu and Akshay Budhkar. 2021. <a href=https://aclanthology.org/2021.maiworkshop-1.10>A Package for Learning on Tabular and Text Data with Transformers</a>. In <i>Proceedings of the Third Workshop on Multimodal Artificial Intelligence</i>, pages 69–73, Mexico City, Mexico. Association for Computational Linguistics.</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeACL><i class="far fa-clipboard"></i></button></dd><dt>Cite (Informal):</dt><dd><span id=citeRichText><a href=https://aclanthology.org/2021.maiworkshop-1.10>A Package for Learning on Tabular and Text Data with Transformers</a> (Gu & Budhkar, maiworkshop 2021)</span><button type=button class="btn btn-clipboard btn-secondary btn-sm d-none ml-2" data-clipboard-target=#citeRichText><i class="far fa-clipboard"></i></button></dd><dt class=acl-button-row>Copy Citation:</dt><dd class=acl-button-row><button type=button class="btn btn-clipboard-outside btn-secondary btn-sm d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Markdown</button>
<button type=button class="btn btn-secondary btn-sm" data-toggle=modal data-target=#citeModal>More options…</button></dd><dt>PDF:</dt><dd><a href=https://aclanthology.org/2021.maiworkshop-1.10.pdf>https://aclanthology.org/2021.maiworkshop-1.10.pdf</a></dd><dt>Terminologies:</dt><dd id=terms></dd></dl></div><div class=acl-paper-link-block><a class="btn btn-primary" href=https://aclanthology.org/2021.maiworkshop-1.10.pdf title="Open PDF of 'A Package for Learning on Tabular and Text Data with Transformers'"><i class="far fa-file-pdf"></i><span class=pl-2>PDF</span></a>
<a class="btn btn-secondary" href="https://www.semanticscholar.org/search?q=A+Package+for+Learning+on+Tabular+and+Text+Data+with+Transformers" title="Search for 'A Package for Learning on Tabular and Text Data with Transformers' on Semantic Scholar"><i class="ai ai-semantic-scholar"></i><span class="pl-sm-2 d-none d-sm-inline">Search</span></a>
<a class="btn btn-dark" data-toggle=modal data-target=#translateModal title="Translate for 'A Package for Learning on Tabular and Text Data with Transformers'" style=color:#fff><i class="fas fa-language"></i><span class=pl-2>Translate</span></a></div></div><hr><div class="modal fade" id=citeModal tabindex=-1 role=dialog aria-labelledby=citeModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel>Export citation</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><ul class="nav nav-tabs mb-2" id=citeFormats role=tablist><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeBibtex role=tab aria-controls=citeBibtex aria-selected=false>BibTeX</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeMods role=tab aria-controls=citeMods aria-selected=false>MODS XML</a></li><li class=nav-item><a class="nav-link disabled" data-toggle=list href=#citeEndnote role=tab aria-controls=citeEndnote aria-selected=false>Endnote</a></li><li class=nav-item><a class="nav-link active" data-toggle=list href=#citeMarkdown role=tab aria-controls=citeMarkdown aria-selected=true>Preformatted</a></li></ul><div class=tab-content id=citeFormatsContent><div class="tab-pane active" id=citeBibtex role=tabpanel></div><div class=tab-pane id=citeMods role=tabpanel></div><div class=tab-pane id=citeEndnote role=tabpanel></div><div class=tab-pane id=citeMarkdown role=tabpanel><h5>Markdown (Informal)</h5><p id=citeMarkdownContent class="text-monospace small bg-light border p-2">[A Package for Learning on Tabular and Text Data with Transformers](https://aclanthology.org/2021.maiworkshop-1.10) (Gu & Budhkar, maiworkshop 2021)</p><ul class=mt-2><li><a href=https://aclanthology.org/2021.maiworkshop-1.10>A Package for Learning on Tabular and Text Data with Transformers</a> (Gu & Budhkar, maiworkshop 2021)</li></ul><h5>ACL</h5><ul class=mt-2><li id=citeACLstyleContent>Ken Gu and Akshay Budhkar. 2021. <a href=https://aclanthology.org/2021.maiworkshop-1.10>A Package for Learning on Tabular and Text Data with Transformers</a>. In <i>Proceedings of the Third Workshop on Multimodal Artificial Intelligence</i>, pages 69–73, Mexico City, Mexico. Association for Computational Linguistics.</li></ul><div class="modal-footer pb-1"><button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeMarkdownContent><i class="far fa-clipboard pr-2"></i>Copy Markdown to Clipboard</button>
<button type=button class="btn btn-clipboard btn-primary d-none" data-clipboard-target=#citeACLstyleContent><i class="far fa-clipboard pr-2"></i>Copy ACL to Clipboard</button></div></div></div></div></div></div></div><div class="modal fade" id=translateModal tabindex=-1 role=dialog aria-labelledby=translateModalLabel aria-hidden=true><div class="modal-dialog modal-lg" role=document><div class=modal-content><div class=modal-header><h5 class=modal-title id=citeModalLabel><i class="fas fa-language"></i> Translate</h5><button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body style=text-align:center><input id=lang_query type=text class="form-control mr-sm-2" style="width:50%;margin:0 auto!important" name=language placeholder=Search...><br><div id=buttons></div></div></div></div></div></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script><script src=/js/clipboard.min.js></script>
<script>let lang_codes=["af","sq","am","ar","hy","az","bn","bs","bg","ca","zh","hr","cs","da","nl","et","fl","fi","fr","ka","de","el","ha","he","hi","hu","is","id","ga","it","ja","jv","kk","ko","lt","mk","ms","ml","mt","mn","no","fa","pl","pt","ro","ru","sr","si","sk","so","es","sw","sv","ta","bo","tr","uk","ur","uz","vi","en"],languages=["Afrikaans","Albanian","Amharic","Arabic","Armenian","Azerbaijani","Bengali","Bosnian","Bulgarian","Catalan","Chinese","Croatian","Czech","Danish","Dutch","Estonian","Filipino","Finnish","French","Georgian","German","Greek","Hausa","Hebrew","Hindi","Hungarian","Icelandic","Indonesian","Irish","Italian","Japanese","Javanese","Kazakh","Korean","Lithuanian","Macedonian","Malay","Malayalam","Maltese","Mongolian","Norwegian","Persian","Polish","Portuguese","Romanian","Russian","Serbian","Sinhala","Slovak","Somali","Spanish","Swahili","Swedish","Tamil","Tibetan","Turkish","Ukranian","Urdu","Uzbek","Vietnamese","English"];$(document).ready(function(){if(create_buttons(),ClipboardJS.isSupported()){success_fn=function(t){var e=$(t.trigger);e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check"),t.clearSelection(),setTimeout(function(){e.toggleClass("btn-success"),e.children("i").toggleClass("far fa-clipboard fas fa-clipboard-check")},2e3)};var e,t=new ClipboardJS(".btn-clipboard");t.on("success",success_fn),$(".btn-clipboard").removeClass("d-none"),e=new ClipboardJS(".btn-clipboard-outside",{text:function(e){var t=e.getAttribute("data-clipboard-target");return $(t).text()}}),e.on("success",success_fn),$(".btn-clipboard-outside").removeClass("d-none")}}),$("#lang_query").on("input",function(){var e=$(this),t=e.val();let n=document.getElementById("buttons");if(n.innerHTML="",e.data("lastval")!=t){e.data("lastval",t);for(let e in languages){let s=languages[e],o=lang_codes[e];s.includes(t)&&(n.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${o}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${s}</span></button>`)}}});function create_buttons(){let e=document.getElementById("buttons");for(let t in languages){let n=languages[t],s=lang_codes[t];e.innerHTML+=`<button class='btn btn-secondary' onclick="show_lang('${s}')" data-dismiss='modal' style='margin:10px; width:120px; text-align: center;'><span class='pl-2'>${n}</span></button>`}}function show_lang(e){hide_all(),console.log(e),$("#"+e+"_abstract").show(),$("#"+e+"_title").show()}function hide_all(){for(let t in lang_codes){let e=lang_codes[t];$("#"+e+"_abstract").hide(),$("#"+e+"_title").hide()}}</script></body></html>