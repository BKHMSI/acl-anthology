<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Transactions of the Association for Computational Linguistics (2018) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Transactions of the Association for Computational Linguistics (2018)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#q18-1>Transactions of the Association for Computational Linguistics, Volume 6</a>
<span class="badge badge-info align-middle ml-1">31&nbsp;papers</span></li></ul></div></div><div id=q18-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/Q18-1/>Transactions of the Association for Computational Linguistics, Volume 6</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/Q18-1000/>Transactions of the Association for Computational Linguistics, Volume 6</a></strong><br><a href=/people/l/lillian-lee/>Lillian Lee</a>
|
<a href=/people/m/mark-johnson/>Mark Johnson</a>
|
<a href=/people/k/kristina-toutanova/>Kristina Toutanova</a>
|
<a href=/people/b/brian-roark/>Brian Roark</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1001.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1001 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1001 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285805531 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q18-1001" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/Q18-1001/>Whodunnit? Crime Drama as a Case for Natural Language Understanding</a></strong><br><a href=/people/l/lea-frermann/>Lea Frermann</a>
|
<a href=/people/s/shay-b-cohen/>Shay B. Cohen</a>
|
<a href=/people/m/mirella-lapata/>Mirella Lapata</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1001><div class="card-body p-3 small">In this paper we argue that <a href=https://en.wikipedia.org/wiki/Crime_film>crime drama</a> exemplified in television programs such as CSI : Crime Scene Investigation is an ideal testbed for approximating real-world natural language understanding and the complex inferences associated with it. We propose to treat <a href=https://en.wikipedia.org/wiki/Crime_film>crime drama</a> as a new inference task, capitalizing on the fact that each episode poses the same basic question (i.e., who committed the crime) and naturally provides the answer when the perpetrator is revealed. We develop a new dataset based on CSI episodes, formalize perpetrator identification as a sequence labeling problem, and develop an LSTM-based model which learns from multi-modal data. Experimental results show that an incremental inference strategy is key to making accurate guesses as well as learning from representations fusing textual, visual, and acoustic input.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1004.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1004 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1004 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285802158 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q18-1004" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/Q18-1004/>Representation Learning for Grounded Spatial Reasoning</a></strong><br><a href=/people/m/michael-janner/>Michael Janner</a>
|
<a href=/people/k/karthik-narasimhan/>Karthik Narasimhan</a>
|
<a href=/people/r/regina-barzilay/>Regina Barzilay</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1004><div class="card-body p-3 small">The interpretation of spatial references is highly contextual, requiring <a href=https://en.wikipedia.org/wiki/Bayesian_inference>joint inference</a> over both language and the environment. We consider the task of <a href=https://en.wikipedia.org/wiki/Spatial&#8211;temporal_reasoning>spatial reasoning</a> in a <a href=https://en.wikipedia.org/wiki/Simulation>simulated environment</a>, where an agent can act and receive rewards. The proposed <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> learns a representation of the world steered by instruction text. This design allows for precise alignment of local neighborhoods with corresponding verbalizations, while also handling global references in the instructions. We train our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> with <a href=https://en.wikipedia.org/wiki/Reinforcement_learning>reinforcement learning</a> using a variant of generalized value iteration. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms state-of-the-art approaches on several metrics, yielding a 45 % reduction in goal localization error.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1005.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1005 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1005 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/276396538 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q18-1005" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/Q18-1005/>Learning Structured Text Representations</a></strong><br><a href=/people/y/yang-liu-edinburgh/>Yang Liu</a>
|
<a href=/people/m/mirella-lapata/>Mirella Lapata</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1005><div class="card-body p-3 small">In this paper, we focus on learning structure-aware document representations from data without recourse to a discourse parser or additional <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a>. Drawing inspiration from recent efforts to empower neural networks with a structural bias (Cheng et al., 2016 ; Kim et al., 2017), we propose a model that can encode a document while automatically inducing rich structural dependencies. Specifically, we embed a differentiable non-projective parsing algorithm into a neural model and use <a href=https://en.wikipedia.org/wiki/Attentional_control>attention mechanisms</a> to incorporate the structural biases. Experimental evaluations across different tasks and datasets show that the proposed model achieves state-of-the-art results on document modeling tasks while inducing intermediate structures which are both interpretable and meaningful.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1007.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1007 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1007 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/276372446 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/Q18-1007/>Towards Evaluating Narrative Quality In Student Writing</a></strong><br><a href=/people/s/swapna-somasundaran/>Swapna Somasundaran</a>
|
<a href=/people/m/michael-flor/>Michael Flor</a>
|
<a href=/people/m/martin-chodorow/>Martin Chodorow</a>
|
<a href=/people/h/hillary-molloy/>Hillary Molloy</a>
|
<a href=/people/b/binod-gyawali/>Binod Gyawali</a>
|
<a href=/people/l/laura-mcculla/>Laura McCulla</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1007><div class="card-body p-3 small">This work lays the foundation for automated assessments of narrative quality in student writing. We first manually score <a href=https://en.wikipedia.org/wiki/Essay>essays</a> for narrative-relevant traits and sub-traits, and measure inter-annotator agreement. We then explore linguistic features that are indicative of good narrative writing and use them to build an automated scoring system. Experiments show that our <a href=https://en.wikipedia.org/wiki/Software_feature>features</a> are more effective in scoring specific aspects of <a href=https://en.wikipedia.org/wiki/Narrative>narrative quality</a> than a state-of-the-art <a href=https://en.wikipedia.org/wiki/Software_feature>feature set</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1008.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1008 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1008 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/277670053 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/Q18-1008/>Evaluating the Stability of Embedding-based Word Similarities</a></strong><br><a href=/people/m/maria-antoniak/>Maria Antoniak</a>
|
<a href=/people/d/david-mimno/>David Mimno</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1008><div class="card-body p-3 small">Word embeddings are increasingly being used as a tool to study <a href=https://en.wikipedia.org/wiki/Word_association>word associations</a> in specific corpora. However, it is unclear whether such embeddings reflect enduring properties of language or if they are sensitive to inconsequential variations in the source documents. We find that nearest-neighbor distances are highly sensitive to small changes in the training corpus for a variety of <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a>. For all <a href=https://en.wikipedia.org/wiki/Methodology>methods</a>, including specific documents in the training set can result in substantial variations. We show that these effects are more prominent for smaller training corpora. We recommend that users never rely on single embedding models for distance calculations, but rather average over multiple bootstrap samples, especially for small corpora.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1010.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1010 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1010 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q18-1010" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/Q18-1010/>Learning Representations Specialized in Spatial Knowledge : Leveraging Language and Vision</a></strong><br><a href=/people/g/guillem-collell/>Guillem Collell</a>
|
<a href=/people/m/marie-francine-moens/>Marie-Francine Moens</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1010><div class="card-body p-3 small">Spatial understanding is crucial in many real-world problems, yet little progress has been made towards building <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a> that capture <a href=https://en.wikipedia.org/wiki/Spatial_memory>spatial knowledge</a>. Here, we move one step forward in this direction and learn such <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a> by leveraging a task consisting in predicting continuous 2D spatial arrangements of objects given object-relationship-object instances (e.g., cat under chair) and a simple <a href=https://en.wikipedia.org/wiki/Neural_network>neural network model</a> that learns the task from <a href=https://en.wikipedia.org/wiki/Annotation>annotated images</a>. We show that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> succeeds in this task and, furthermore, that it is capable of predicting correct spatial arrangements for unseen objects if either CNN features or <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> of the objects are provided. The differences between visual and linguistic features are discussed. Next, to evaluate the spatial representations learned in the previous <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, we introduce a <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> and a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> consisting in a set of crowdsourced human ratings of spatial similarity for object pairs. We find that both CNN (convolutional neural network) features and word embeddings predict human judgments of similarity well and that these vectors can be further specialized in spatial knowledge if we update them when training the model that predicts spatial arrangements of objects. Overall, this paper paves the way towards building distributed spatial representations, contributing to the understanding of spatial expressions in language.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1011.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1011 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1011 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q18-1011" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/Q18-1011/>Modeling Past and Future for Neural Machine Translation</a></strong><br><a href=/people/z/zaixiang-zheng/>Zaixiang Zheng</a>
|
<a href=/people/h/hao-zhou/>Hao Zhou</a>
|
<a href=/people/s/shujian-huang/>Shujian Huang</a>
|
<a href=/people/l/lili-mou/>Lili Mou</a>
|
<a href=/people/x/xinyu-dai/>Xinyu Dai</a>
|
<a href=/people/j/jiajun-chen/>Jiajun Chen</a>
|
<a href=/people/z/zhaopeng-tu/>Zhaopeng Tu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1011><div class="card-body p-3 small">Existing neural machine translation systems do not explicitly model what has been translated and what has not during the decoding phase. To address this problem, we propose a novel mechanism that separates the source information into two parts : translated Past contents and untranslated Future contents, which are modeled by two additional recurrent layers. The Past and Future contents are fed to both the attention model and the decoder states, which provides Neural Machine Translation (NMT) systems with the knowledge of translated and untranslated contents. Experimental results show that the proposed approach significantly improves the performance in Chinese-English, German-English, and English-German translation tasks. Specifically, the proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms the conventional coverage model in terms of both the translation quality and the alignment error rate.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1012.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1012 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1012 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/282338901 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q18-1012" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/Q18-1012/>Mapping to Declarative Knowledge for Word Problem Solving</a></strong><br><a href=/people/s/subhro-roy/>Subhro Roy</a>
|
<a href=/people/d/dan-roth/>Dan Roth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1012><div class="card-body p-3 small">Math word problems form a natural abstraction to a range of quantitative reasoning problems, such as understanding <a href=https://en.wikipedia.org/wiki/Finance>financial news</a>, <a href=https://en.wikipedia.org/wiki/Sports_journalism>sports results</a>, and <a href=https://en.wikipedia.org/wiki/Casualty_(person)>casualties of war</a>. Solving such problems requires the understanding of several mathematical concepts such as <a href=https://en.wikipedia.org/wiki/Dimensional_analysis>dimensional analysis</a>, subset relationships, etc. In this paper, we develop declarative rules which govern the translation of natural language description of these <a href=https://en.wikipedia.org/wiki/Concept>concepts</a> to <a href=https://en.wikipedia.org/wiki/Expression_(mathematics)>math expressions</a>. We then present a <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> for incorporating such <a href=https://en.wikipedia.org/wiki/Descriptive_knowledge>declarative knowledge</a> into word problem solving. Our method learns to map arithmetic word problem text to math expressions, by learning to select the relevant declarative knowledge for each operation of the solution expression. This provides a way to handle multiple <a href=https://en.wikipedia.org/wiki/Concept>concepts</a> in the same problem while, at the same time, supporting interpretability of the answer expression. Our method models the mapping to declarative knowledge as a <a href=https://en.wikipedia.org/wiki/Latent_variable>latent variable</a>, thus removing the need for expensive annotations. Experimental evaluation suggests that our domain knowledge based solver outperforms all other systems, and that it generalizes better in the realistic case where the training data it is exposed to is biased in a different way than the test data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1013.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1013 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1013 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/Q18-1013/>Video Captioning with Multi-Faceted Attention</a></strong><br><a href=/people/x/xiang-long/>Xiang Long</a>
|
<a href=/people/c/chuang-gan/>Chuang Gan</a>
|
<a href=/people/g/gerard-de-melo/>Gerard de Melo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1013><div class="card-body p-3 small">Video captioning has attracted an increasing amount of interest, due in part to its potential for improved <a href=https://en.wikipedia.org/wiki/Accessibility>accessibility</a> and <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval</a>. While existing methods rely on different kinds of <a href=https://en.wikipedia.org/wiki/Visual_system>visual features</a> and model architectures, they do not make full use of pertinent semantic cues. We present a unified and extensible framework to jointly leverage multiple sorts of <a href=https://en.wikipedia.org/wiki/Feature_(computer_vision)>visual features</a> and <a href=https://en.wikipedia.org/wiki/Semantic_Web>semantic attributes</a>. Our novel <a href=https://en.wikipedia.org/wiki/Architecture>architecture</a> builds on LSTMs with two multi-faceted attention layers. These first learn to automatically select the most salient visual features or semantic attributes, and then yield overall representations for the input and output of the sentence generation component via custom feature scaling operations. Experimental results on the challenging MSVD and MSR-VTT datasets show that our framework outperforms previous work and performs robustly even in the presence of added noise to the features and attributes.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1015.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1015 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1015 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/276898240 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/Q18-1015/>Knowledge Completion for Generics using Guided Tensor Factorization</a></strong><br><a href=/people/h/hanie-sedghi/>Hanie Sedghi</a>
|
<a href=/people/a/ashish-sabharwal/>Ashish Sabharwal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1015><div class="card-body p-3 small">Given a <a href=https://en.wikipedia.org/wiki/Knowledge_base>knowledge base</a> or <a href=https://en.wikipedia.org/wiki/Knowledge_base>KB</a> containing (noisy) facts about common nouns or generics, such as all trees produce oxygen or some animals live in forests, we consider the problem of inferring additional such facts at a precision similar to that of the starting KB. Such KBs capture general knowledge about the world, and are crucial for various <a href=https://en.wikipedia.org/wiki/Application_software>applications</a> such as <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a>. Different from commonly studied named entity KBs such as <a href=https://en.wikipedia.org/wiki/Freebase>Freebase</a>, generics KBs involve quantification, have more complex underlying regularities, tend to be more incomplete, and violate the commonly used locally closed world assumption (LCWA). We show that existing KB completion methods struggle with this new <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, and present the first approach that is successful. Our results demonstrate that external information, such as relation schemas and <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity taxonomies</a>, if used appropriately, can be a surprisingly powerful tool in this setting. First, our simple yet effective knowledge guided tensor factorization approach achieves state-of-the-art results on two generics KBs (80 % precise) for science, doubling their size at 74%86 % precision. Second, our novel taxonomy guided, submodular, active learning method for collecting annotations about rare entities (e.g., oriole, a bird) is 6x more effective at inferring further new facts about them than multiple active learning baselines.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1016.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1016 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1016 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/277673890 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q18-1016" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/Q18-1016/>Unsupervised Grammar Induction with Depth-bounded PCFG<span class=acl-fixed-case>PCFG</span></a></strong><br><a href=/people/l/lifeng-jin/>Lifeng Jin</a>
|
<a href=/people/f/finale-doshi-velez/>Finale Doshi-Velez</a>
|
<a href=/people/t/timothy-miller/>Timothy Miller</a>
|
<a href=/people/w/william-schuler/>William Schuler</a>
|
<a href=/people/l/lane-schwartz/>Lane Schwartz</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1016><div class="card-body p-3 small">There has been recent interest in applying cognitively- or empirically-motivated bounds on recursion depth to limit the search space of grammar induction models (Ponvert et al., 2011 ; Noji and Johnson, 2016 ; Shain et al., 2016). This work extends this depth-bounding approach to probabilistic context-free grammar induction (DB-PCFG), which has a smaller parameter space than hierarchical sequence models, and therefore more fully exploits the space reductions of depth-bounding. Results for this model on <a href=https://en.wikipedia.org/wiki/Grammar>grammar acquisition</a> from transcribed child-directed speech and newswire text exceed or are competitive with those of other models when evaluated on parse accuracy. Moreover, <a href=https://en.wikipedia.org/wiki/Grammar>grammars</a> acquired from this <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> demonstrate a consistent use of category labels, something which has not been demonstrated by other acquisition models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1017.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1017 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1017 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/Q18-1017/>Scheduled Multi-Task Learning : From Syntax to Translation</a></strong><br><a href=/people/e/eliyahu-kiperwasser/>Eliyahu Kiperwasser</a>
|
<a href=/people/m/miguel-ballesteros/>Miguel Ballesteros</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1017><div class="card-body p-3 small">Neural encoder-decoder models of <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> have achieved impressive results, while learning linguistic knowledge of both the source and target languages in an implicit end-to-end manner. We propose a framework in which our model begins learning <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a> and translation interleaved, gradually putting more focus on <a href=https://en.wikipedia.org/wiki/Translation>translation</a>. Using this approach, we achieve considerable improvements in terms of BLEU score on relatively large parallel corpus (WMT14 English to German) and a low-resource (WIT German to English) setup.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1019.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1019 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1019 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/277673973 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q18-1019" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/Q18-1019/>Do latent tree learning models identify meaningful structure in sentences?</a></strong><br><a href=/people/a/adina-williams/>Adina Williams</a>
|
<a href=/people/a/andrew-drozdov/>Andrew Drozdov</a>
|
<a href=/people/s/samuel-bowman/>Samuel R. Bowman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1019><div class="card-body p-3 small">Recent work on the problem of latent tree learning has made it possible to train neural networks that learn to both parse a sentence and use the resulting <a href=https://en.wikipedia.org/wiki/Parsing>parse</a> to interpret the sentence, all without exposure to ground-truth parse trees at training time. Surprisingly, these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> often perform better at sentence understanding tasks than <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that use parse trees from conventional <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a>. This paper aims to investigate what these latent tree learning models learn. We replicate two such models in a shared codebase and find that (i) only one of these models outperforms conventional tree-structured models on sentence classification, (ii) its parsing strategies are not especially consistent across random restarts, (iii) the parses it produces tend to be shallower than standard Penn Treebank (PTB) parses, and (iv) they do not resemble those of PTB or any other semantic or syntactic formalism that the authors are aware of.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1020.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1020 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1020 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/Q18-1020/>Bootstrap Domain-Specific Sentiment Classifiers from Unlabeled Corpora</a></strong><br><a href=/people/a/andrius-mudinas/>Andrius Mudinas</a>
|
<a href=/people/d/dell-zhang/>Dell Zhang</a>
|
<a href=/people/m/mark-levene/>Mark Levene</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1020><div class="card-body p-3 small">There is often the need to perform sentiment classification in a particular domain where no labeled document is available. Although we could make use of a general-purpose off-the-shelf sentiment classifier or a pre-built one for a different domain, the effectiveness would be inferior. In this paper, we explore the possibility of building domain-specific sentiment classifiers with unlabeled documents only. Our investigation indicates that in the word embeddings learned from the unlabeled corpus of a given domain, the distributed word representations (vectors) for opposite sentiments form distinct clusters, though those clusters are not transferable across domains. Exploiting such a clustering structure, we are able to utilize <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning algorithms</a> to induce a quality domain-specific sentiment lexicon from just a few typical sentiment words (seeds). An important finding is that simple linear model based supervised learning algorithms (such as linear SVM) can actually work better than more sophisticated semi-supervised / transductive learning algorithms which represent the state-of-the-art technique for sentiment lexicon induction. The induced lexicon could be applied directly in a lexicon-based method for sentiment classification, but a higher performance could be achieved through a two-phase bootstrapping method which uses the induced lexicon to assign positive / negative sentiment scores to unlabeled documents first, a nd t hen u ses those documents found to have clear sentiment signals as pseudo-labeled examples to train a document sentiment classifier v ia supervised learning algorithms (such as LSTM).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1022.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1022 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1022 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/Q18-1022/>Leveraging Orthographic Similarity for Multilingual Neural Transliteration</a></strong><br><a href=/people/a/anoop-kunchukuttan/>Anoop Kunchukuttan</a>
|
<a href=/people/m/mitesh-m-khapra/>Mitesh Khapra</a>
|
<a href=/people/g/gurneet-singh/>Gurneet Singh</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1022><div class="card-body p-3 small">We address the task of joint training of transliteration models for multiple language pairs (multilingual transliteration). This is an instance of <a href=https://en.wikipedia.org/wiki/Multitask_learning>multitask learning</a>, where individual tasks (language pairs) benefit from sharing knowledge with related tasks. We focus on <a href=https://en.wikipedia.org/wiki/Transliteration>transliteration</a> involving related <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> i.e., <a href=https://en.wikipedia.org/wiki/Language_family>languages sharing writing systems</a> and <a href=https://en.wikipedia.org/wiki/Phoneme>phonetic properties</a> (orthographically similar languages). We propose a modified neural encoder-decoder model that maximizes parameter sharing across language pairs in order to effectively leverage orthographic similarity. We show that multilingual transliteration significantly outperforms bilingual transliteration in different scenarios (average increase of 58 % across a variety of languages we experimented with). We also show that multilingual transliteration models can generalize well to languages / language pairs not encountered during training and hence perform well on the zeroshot transliteration task. We show that further improvements can be achieved by using phonetic feature input.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1023.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1023 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1023 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285804931 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/Q18-1023/>The NarrativeQA Reading Comprehension Challenge<span class=acl-fixed-case>N</span>arrative<span class=acl-fixed-case>QA</span> Reading Comprehension Challenge</a></strong><br><a href=/people/t/tomas-kocisky/>Tomáš Kočiský</a>
|
<a href=/people/j/jonathan-schwarz/>Jonathan Schwarz</a>
|
<a href=/people/p/phil-blunsom/>Phil Blunsom</a>
|
<a href=/people/c/chris-dyer/>Chris Dyer</a>
|
<a href=/people/k/karl-moritz-hermann/>Karl Moritz Hermann</a>
|
<a href=/people/g/gabor-melis/>Gábor Melis</a>
|
<a href=/people/e/edward-grefenstette/>Edward Grefenstette</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1023><div class="card-body p-3 small">Reading comprehension (RC)in contrast to information retrievalrequires integrating information and reasoning about events, <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entities</a>, and their relations across a full document. Question answering is conventionally used to assess RC ability, in both <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>artificial agents</a> and children learning to read. However, existing RC datasets and <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> are dominated by questions that can be solved by selecting answers using superficial information (e.g., local context similarity or global term frequency) ; they thus fail to test for the essential integrative aspect of RC. To encourage progress on deeper comprehension of language, we present a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> and set of <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> in which the reader must answer questions about stories by reading entire books or <a href=https://en.wikipedia.org/wiki/Screenplay>movie scripts</a>. These tasks are designed so that successfully answering their questions requires understanding the underlying narrative rather than relying on shallow pattern matching or <a href=https://en.wikipedia.org/wiki/Salience_(neuroscience)>salience</a>. We show that although humans solve the <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a> easily, standard RC models struggle on the <a href=https://en.wikipedia.org/wiki/Task_(computing)>tasks</a> presented here. We provide an analysis of the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> and the challenges it presents.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1024.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1024 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1024 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285802410 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q18-1024" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/Q18-1024/>Native Language Cognate Effects on Second Language Lexical Choice</a></strong><br><a href=/people/e/ella-rabinovich/>Ella Rabinovich</a>
|
<a href=/people/y/yulia-tsvetkov/>Yulia Tsvetkov</a>
|
<a href=/people/s/shuly-wintner/>Shuly Wintner</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1024><div class="card-body p-3 small">We present a computational analysis of cognate effects on the spontaneous linguistic productions of advanced non-native speakers. Introducing a large corpus of highly competent non-native English speakers, and using a set of carefully selected lexical items, we show that the lexical choices of non-natives are affected by cognates in their native language. This effect is so powerful that we are able to reconstruct the <a href=https://en.wikipedia.org/wiki/Phylogenetic_tree>phylogenetic language tree</a> of the <a href=https://en.wikipedia.org/wiki/Indo-European_languages>Indo-European language family</a> solely from the frequencies of specific lexical items in the English of authors with various native languages. We quantitatively analyze non-native lexical choice, highlighting cognate facilitation as one of the important phenomena shaping the language of non-native speakers.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1027.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1027 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1027 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/Q18-1027/>Polite Dialogue Generation Without Parallel Data</a></strong><br><a href=/people/t/tong-niu/>Tong Niu</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1027><div class="card-body p-3 small">Stylistic dialogue response generation, with valuable applications in personality-based conversational agents, is a challenging task because the response needs to be fluent, contextually-relevant, as well as paralinguistically accurate. Moreover, <a href=https://en.wikipedia.org/wiki/Parallel_computing>parallel datasets</a> for regular-to-stylistic pairs are usually unavailable. We present three weakly-supervised models that can generate diverse, polite (or rude) dialogue responses without parallel data. Our late fusion model (Fusion) merges the decoder of an encoder-attention-decoder dialogue model with a language model trained on stand-alone polite utterances. Our label-finetuning (LFT) model prepends to each source sequence a politeness-score scaled label (predicted by our state-of-the-art politeness classifier) during training, and at test time is able to generate polite, neutral, and rude responses by simply scaling the label embedding by the corresponding score. Our reinforcement learning model (Polite-RL) encourages politeness generation by assigning rewards proportional to the politeness classifier score of the sampled response. We also present two retrievalbased, polite dialogue model baselines. Human evaluation validates that while the Fusion and the retrieval-based models achieve <a href=https://en.wikipedia.org/wiki/Politeness>politeness</a> with poorer context-relevance, the LFT and Polite-RL models can produce significantly more polite responses without sacrificing dialogue quality.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1029.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1029 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1029 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q18-1029" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/Q18-1029/>Learning to Remember Translation History with a Continuous Cache</a></strong><br><a href=/people/z/zhaopeng-tu/>Zhaopeng Tu</a>
|
<a href=/people/y/yang-liu-ict/>Yang Liu</a>
|
<a href=/people/s/shuming-shi/>Shuming Shi</a>
|
<a href=/people/t/tong-zhang/>Tong Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1029><div class="card-body p-3 small">Existing neural machine translation (NMT) models generally translate sentences in isolation, missing the opportunity to take advantage of document-level information. In this work, we propose to augment NMT models with a very light-weight cache-like memory network, which stores recent hidden representations as translation history. The <a href=https://en.wikipedia.org/wiki/Probability_distribution>probability distribution</a> over generated words is updated online depending on the translation history retrieved from the <a href=https://en.wikipedia.org/wiki/Computer_memory>memory</a>, endowing NMT models with the capability to dynamically adapt over time. Experiments on multiple domains with different topics and styles show the effectiveness of the proposed approach with negligible impact on the <a href=https://en.wikipedia.org/wiki/Computational_cost>computational cost</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1031.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1031 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1031 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285801187 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q18-1031" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/Q18-1031/>Generating Sentences by Editing Prototypes</a></strong><br><a href=/people/k/kelvin-guu/>Kelvin Guu</a>
|
<a href=/people/t/tatsunori-b-hashimoto/>Tatsunori B. Hashimoto</a>
|
<a href=/people/y/yonatan-oren/>Yonatan Oren</a>
|
<a href=/people/p/percy-liang/>Percy Liang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1031><div class="card-body p-3 small">We propose a new generative language model for sentences that first samples a prototype sentence from the training corpus and then edits it into a new sentence. Compared to traditional language models that generate from scratch either left-to-right or by first sampling a latent sentence vector, our prototype-then-edit model improves perplexity on language modeling and generates higher quality outputs according to human evaluation. Furthermore, the model gives rise to a latent edit vector that captures interpretable semantics such as sentence similarity and sentence-level analogies.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1032.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1032 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1032 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/Q18-1032/>Language Modeling for Morphologically Rich Languages : Character-Aware Modeling for Word-Level Prediction</a></strong><br><a href=/people/d/daniela-gerz/>Daniela Gerz</a>
|
<a href=/people/i/ivan-vulic/>Ivan Vulić</a>
|
<a href=/people/e/edoardo-ponti/>Edoardo Ponti</a>
|
<a href=/people/j/jason-naradowsky/>Jason Naradowsky</a>
|
<a href=/people/r/roi-reichart/>Roi Reichart</a>
|
<a href=/people/a/anna-korhonen/>Anna Korhonen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1032><div class="card-body p-3 small">Neural architectures are prominent in the construction of language models (LMs). However, word-level prediction is typically agnostic of subword-level information (characters and character sequences) and operates over a closed vocabulary, consisting of a limited word set. Indeed, while subword-aware models boost performance across a variety of NLP tasks, previous work did not evaluate the ability of these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> to assist next-word prediction in language modeling tasks. Such subword-level informed models should be particularly effective for morphologically-rich languages (MRLs) that exhibit high type-to-token ratios. In this work, we present a large-scale LM study on 50 typologically diverse languages covering a wide variety of <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphological systems</a>, and offer new LM benchmarks to the community, while considering subword-level information. The main technical contribution of our work is a novel method for injecting subword-level information into semantic word vectors, integrated into the neural language modeling training, to facilitate word-level prediction. We conduct experiments in the LM setting where the number of infrequent words is large, and demonstrate strong perplexity gains across our 50 languages, especially for morphologically-rich languages. Our code and data sets are publicly available.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1033.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1033 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1033 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/285803587 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/Q18-1033/>Detecting Institutional Dialog Acts in Police Traffic Stops</a></strong><br><a href=/people/v/vinodkumar-prabhakaran/>Vinodkumar Prabhakaran</a>
|
<a href=/people/c/camilla-griffiths/>Camilla Griffiths</a>
|
<a href=/people/h/hang-su/>Hang Su</a>
|
<a href=/people/p/prateek-verma/>Prateek Verma</a>
|
<a href=/people/n/nelson-morgan/>Nelson Morgan</a>
|
<a href=/people/j/jennifer-l-eberhardt/>Jennifer L. Eberhardt</a>
|
<a href=/people/d/dan-jurafsky/>Dan Jurafsky</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1033><div class="card-body p-3 small">We apply computational dialog methods to police body-worn camera footage to model conversations between police officers and community members in <a href=https://en.wikipedia.org/wiki/Traffic_stop>traffic stops</a>. Relying on the theory of institutional talk, we develop a labeling scheme for police speech during traffic stops, and a tagger to detect institutional dialog acts (Reasons, Searches, Offering Help) from transcribed text at the turn (78 % F-score) and stop (89 % F-score) level. We then develop speech recognition and segmentation algorithms to detect these acts at the stop level from raw camera audio (81 % F-score, with even higher accuracy for crucial acts like conveying the reason for the stop). We demonstrate that the dialog structures produced by our tagger could reveal whether officers follow law enforcement norms like introducing themselves, explaining the reason for the stop, and asking permission for searches. This work may therefore inform and aid efforts to ensure the procedural justice of police-community interactions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1036.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1036 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1036 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q18-1036" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/Q18-1036/>Neural Lattice Language Models</a></strong><br><a href=/people/j/jacob-buckman/>Jacob Buckman</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1036><div class="card-body p-3 small">In this work, we propose a new language modeling paradigm that has the ability to perform both prediction and moderation of information flow at multiple granularities : neural lattice language models. These models construct a lattice of possible paths through a sentence and marginalize across this <a href=https://en.wikipedia.org/wiki/Lattice_(group)>lattice</a> to calculate sequence probabilities or optimize parameters. This approach allows us to seamlessly incorporate linguistic intuitions including <a href=https://en.wikipedia.org/wiki/Polysemy>polysemy</a> and the existence of multiword lexical items into our <a href=https://en.wikipedia.org/wiki/Language_model>language model</a>. Experiments on multiple language modeling tasks show that English neural lattice language models that utilize polysemous embeddings are able to improve <a href=https://en.wikipedia.org/wiki/Perplexity>perplexity</a> by 9.95 % relative to a word-level baseline, and that a Chinese model that handles multi-character tokens is able to improve <a href=https://en.wikipedia.org/wiki/Perplexity>perplexity</a> by 20.94 % relative to a character-level baseline.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1037.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1037 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1037 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q18-1037" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/Q18-1037/>Planning, Inference and Pragmatics in Sequential Language Games</a></strong><br><a href=/people/f/fereshte-khani/>Fereshte Khani</a>
|
<a href=/people/n/noah-goodman/>Noah D. Goodman</a>
|
<a href=/people/p/percy-liang/>Percy Liang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1037><div class="card-body p-3 small">We study sequential language games in which two players, each with private information, communicate to achieve a common goal. In such games, a successful player must (i) infer the partner&#8217;s private information from the partner&#8217;s messages, (ii) generate messages that are most likely to help with the goal, and (iii) reason pragmatically about the partner&#8217;s strategy. We propose a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> that captures all three characteristics and demonstrate their importance in capturing <a href=https://en.wikipedia.org/wiki/Human_behavior>human behavior</a> on a new goal-oriented dataset we collected using <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1038.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1038 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1038 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/Q18-1038/>Probabilistic Verb Selection for Data-to-Text Generation</a></strong><br><a href=/people/d/dell-zhang/>Dell Zhang</a>
|
<a href=/people/j/jiahao-yuan/>Jiahao Yuan</a>
|
<a href=/people/x/xiaoling-wang/>Xiaoling Wang</a>
|
<a href=/people/a/adam-foster/>Adam Foster</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1038><div class="card-body p-3 small">In data-to-text Natural Language Generation (NLG) systems, computers need to find the right words to describe phenomena seen in the data. This paper focuses on the problem of choosing appropriate verbs to express the direction and magnitude of a percentage change (e.g., in stock prices). Rather than simply using the same verbs again and again, we present a principled data-driven approach to this problem based on Shannon&#8217;s noisy-channel model so as to bring variation and naturalness into the generated text. Our experiments on three large-scale real-world news corpora demonstrate that the proposed probabilistic model can be learned to accurately imitate human authors&#8217; pattern of usage around verbs, outperforming the state-of-the-art method significantly.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1039.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1039 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1039 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/306129914 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q18-1039" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/Q18-1039/>Adversarial Deep Averaging Networks for Cross-Lingual Sentiment Classification</a></strong><br><a href=/people/x/xilun-chen/>Xilun Chen</a>
|
<a href=/people/y/yu-sun/>Yu Sun</a>
|
<a href=/people/b/ben-athiwaratkun/>Ben Athiwaratkun</a>
|
<a href=/people/c/claire-cardie/>Claire Cardie</a>
|
<a href=/people/k/kilian-weinberger/>Kilian Weinberger</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1039><div class="card-body p-3 small">In recent years great success has been achieved in sentiment classification for <a href=https://en.wikipedia.org/wiki/English_language>English</a>, thanks in part to the availability of copious annotated resources. Unfortunately, most languages do not enjoy such an abundance of <a href=https://en.wikipedia.org/wiki/Data_(computing)>labeled data</a>. To tackle the sentiment classification problem in low-resource languages without adequate annotated data, we propose an Adversarial Deep Averaging Network (ADAN1) to transfer the knowledge learned from labeled data on a resource-rich source language to low-resource languages where only unlabeled data exist. ADAN has two discriminative branches : a sentiment classifier and an adversarial language discriminator. Both branches take input from a shared feature extractor to learn hidden representations that are simultaneously indicative for the classification task and invariant across languages. Experiments on Chinese and Arabic sentiment classification demonstrate that ADAN significantly outperforms state-of-the-art systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1041.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1041 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1041 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/359686057 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/Q18-1041/>Data Statements for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a> : Toward Mitigating System Bias and Enabling Better Science</a></strong><br><a href=/people/e/emily-m-bender/>Emily M. Bender</a>
|
<a href=/people/b/batya-friedman/>Batya Friedman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1041><div class="card-body p-3 small">In this paper, we propose data statements as a design solution and professional practice for natural language processing technologists, in both research and development. Through the adoption and widespread use of data statements, the field can begin to address critical scientific and ethical issues that result from the use of data from certain populations in the development of <a href=https://en.wikipedia.org/wiki/Technology>technology</a> for other populations. We present a form that <a href=https://en.wikipedia.org/wiki/Statement_(computer_science)>data statements</a> can take and explore the implications of adopting them as part of regular practice. We argue that data statements will help alleviate issues related to exclusion and bias in language technology, lead to better precision in claims about how natural language processing research can generalize and thus better engineering results, protect companies from public embarrassment, and ultimately lead to language technology that meets its users in their own preferred linguistic style and furthermore does not misrepresent them to others.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1044.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1044 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1044 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://vimeo.com/385255818 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=Q18-1044" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/Q18-1044/>Integrating Weakly Supervised Word Sense Disambiguation into Neural Machine Translation</a></strong><br><a href=/people/x/xiao-pu/>Xiao Pu</a>
|
<a href=/people/n/nikolaos-pappas/>Nikolaos Pappas</a>
|
<a href=/people/j/james-henderson/>James Henderson</a>
|
<a href=/people/a/andrei-popescu-belis/>Andrei Popescu-Belis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1044><div class="card-body p-3 small">This paper demonstrates that word sense disambiguation (WSD) can improve neural machine translation (NMT) by widening the source context considered when modeling the senses of potentially ambiguous words. We first introduce three adaptive clustering algorithms for WSD, based on <a href=https://en.wikipedia.org/wiki/K-means_clustering>k-means</a>, Chinese restaurant processes, and <a href=https://en.wikipedia.org/wiki/Random_walk>random walks</a>, which are then applied to large word contexts represented in a low-rank space and evaluated on SemEval shared-task data. We then learn word vectors jointly with sense vectors defined by our best WSD method, within a state-of-the-art NMT system. We show that the concatenation of these <a href=https://en.wikipedia.org/wiki/Vector_space>vectors</a>, and the use of a sense selection mechanism based on the weighted average of sense vectors, outperforms several baselines including sense-aware ones. This is demonstrated by <a href=https://en.wikipedia.org/wiki/Translation>translation</a> on five language pairs. The improvements are more than 1 BLEU point over strong NMT baselines, +4 % accuracy over all ambiguous nouns and verbs, or +20 % when scored manually over several challenging words.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1046.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1046 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1046 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/Q18-1046/>Surface Statistics of an Unknown Language Indicate How to Parse It</a></strong><br><a href=/people/d/dingquan-wang/>Dingquan Wang</a>
|
<a href=/people/j/jason-eisner/>Jason Eisner</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1046><div class="card-body p-3 small">We introduce a novel <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> for delexicalized dependency parsing in a <a href=https://en.wikipedia.org/wiki/Programming_language>new language</a>. We show that useful features of the target language can be extracted automatically from an unparsed corpus, which consists only of gold part-of-speech (POS) sequences. Providing these <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> to our neural parser enables <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> to parse sequences like those in the corpus. Strikingly, our <a href=https://en.wikipedia.org/wiki/System>system</a> has no supervision in the target language. Rather, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> is a multilingual system that is trained end-to-end on a variety of other languages, so <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> learns a <a href=https://en.wikipedia.org/wiki/Feature_extraction>feature extractor</a> that works well. We show experimentally across multiple languages : (1) Features computed from the unparsed corpus improve parsing accuracy. (2) Including thousands of <a href=https://en.wikipedia.org/wiki/Synthetic_language>synthetic languages</a> in the training yields further improvement. (3) Despite being computed from unparsed corpora, our learned task-specific features beat previous work&#8217;s interpretable typological features that require parsed corpora or expert categorization of the language. Our best method improved attachment scores on held-out test languages by an average of 5.6 percentage points over past work that does not inspect the unparsed data (McDonald et al., 2011), and by 20.7 points over past grammar induction work that does not use training languages (Naseem et al., 2010).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/Q18-1047.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-Q18-1047 data-toggle=collapse aria-expanded=false aria-controls=abstract-Q18-1047 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/Q18-1047/>Attentive Convolution : Equipping CNNs with RNN-style Attention Mechanisms<span class=acl-fixed-case>CNN</span>s with <span class=acl-fixed-case>RNN</span>-style Attention Mechanisms</a></strong><br><a href=/people/w/wenpeng-yin/>Wenpeng Yin</a>
|
<a href=/people/h/hinrich-schutze/>Hinrich Schütze</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-Q18-1047><div class="card-body p-3 small">In <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, convolutional neural networks (CNNs) have benefited less than recurrent neural networks (RNNs) from attention mechanisms. We hypothesize that this is because the <a href=https://en.wikipedia.org/wiki/Attention>attention</a> in CNNs has been mainly implemented as attentive pooling (i.e., it is applied to pooling) rather than as attentive convolution (i.e., it is integrated into <a href=https://en.wikipedia.org/wiki/Convolution>convolution</a>). Convolution is the differentiator of CNNs in that it can powerfully model the higher-level representation of a word by taking into account its local fixed-size context in the input text tx. In this work, we propose an attentive convolution network, ATTCONV. It extends the context scope of the convolution operation, deriving higher-level features for a word not only from local context, but also from information extracted from nonlocal context by the attention mechanism commonly used in RNNs. This nonlocal context can come (i) from parts of the input text tx that are distant or (ii) from extra (i.e., external) contexts ty. Experiments on sentence modeling with zero-context (sentiment analysis), single-context (textual entailment) and multiple-context (claim verification) demonstrate the effectiveness of ATTCONV in sentence representation learning with the incorporation of context. In particular, attentive convolution outperforms attentive pooling and is a strong competitor to popular attentive RNNs.1</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>