<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>The Third Workshop on New Frontiers in Summarization (NewSum 2021) (2021) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>The Third Workshop on New Frontiers in Summarization (NewSum 2021) (2021)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#2021newsum-1>Proceedings of the Third Workshop on New Frontiers in Summarization</a>
<span class="badge badge-info align-middle ml-1">9&nbsp;papers</span></li></ul></div></div><div id=2021newsum-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2021.newsum-1/>Proceedings of the Third Workshop on New Frontiers in Summarization</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.newsum-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.newsum-1.0/>Proceedings of the Third Workshop on New Frontiers in Summarization</a></strong><br><a href=/people/g/giuseppe-carenini/>Giuseppe Carenini</a>
|
<a href=/people/j/jackie-chi-kit-cheung/>Jackie Chi Kit Cheung</a>
|
<a href=/people/y/yue-dong/>Yue Dong</a>
|
<a href=/people/f/fei-liu-utdallas/>Fei Liu</a>
|
<a href=/people/l/lu-wang/>Lu Wang</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.newsum-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--newsum-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.newsum-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.newsum-1.1" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.newsum-1.1/>Sentence-level Planning for Especially Abstractive Summarization</a></strong><br><a href=/people/a/andreas-marfurt/>Andreas Marfurt</a>
|
<a href=/people/j/james-henderson/>James Henderson</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--newsum-1--1><div class="card-body p-3 small">Abstractive summarization models heavily rely on copy mechanisms, such as the pointer network or <a href=https://en.wikipedia.org/wiki/Attention>attention</a>, to achieve good performance, measured by textual overlap with reference summaries. As a result, the generated summaries stay close to the formulations in the source document. We propose the * sentence planner * model to generate more abstractive summaries. It includes a hierarchical decoder that first generates a <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representation</a> for the next summary sentence, and then conditions the word generator on this <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representation</a>. Our generated summaries are more abstractive and at the same time achieve high ROUGE scores when compared to human reference summaries. We verify the effectiveness of our design decisions with extensive evaluations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.newsum-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--newsum-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.newsum-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.newsum-1.2/>Template-aware Attention Model for Earnings Call Report Generation</a></strong><br><a href=/people/y/yangchen-huang/>Yangchen Huang</a>
|
<a href=/people/p/prashant-k-dhingra/>Prashant K. Dhingra</a>
|
<a href=/people/s/seyed-danial-mohseni-taheri/>Seyed Danial Mohseni Taheri</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--newsum-1--2><div class="card-body p-3 small">Earning calls are among important resources for investors and analysts for updating their price targets. Firms usually publish corresponding transcripts soon after earnings events. However, raw transcripts are often too long and miss the coherent structure. To enhance the clarity, analysts write well-structured reports for some important earnings call events by analyzing them, requiring time and effort. In this paper, we propose TATSum (Template-Aware aTtention model for Summarization), a generalized neural summarization approach for structured report generation, and evaluate its performance in the earnings call domain. We build a large corpus with thousands of transcripts and reports using historical earnings events. We first generate a candidate set of reports from the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> as potential soft templates which do not impose actual rules on the output. Then, we employ an encoder model with margin-ranking loss to rank the candidate set and select the best quality template. Finally, the transcript and the selected soft template are used as input in a seq2seq framework for report generation. Empirical results on the earnings call dataset show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> significantly outperforms state-of-the-art models in terms of informativeness and structure.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.newsum-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--newsum-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.newsum-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.newsum-1.6/>Evaluation of Summarization Systems across Gender, Age, and Race</a></strong><br><a href=/people/a/anna-jorgensen/>Anna Jørgensen</a>
|
<a href=/people/a/anders-sogaard/>Anders Søgaard</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--newsum-1--6><div class="card-body p-3 small">Summarization systems are ultimately evaluated by human annotators and raters. Usually, annotators and raters do not reflect the demographics of end users, but are recruited through student populations or crowdsourcing platforms with skewed demographics. For two different evaluation scenarios evaluation against gold summaries and system output ratings we show that summary evaluation is sensitive to protected attributes. This can severely bias system development and evaluation, leading us to build models that cater for some groups rather than others.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.newsum-1.8.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--newsum-1--8 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.newsum-1.8 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.newsum-1.8/>Capturing Speaker Incorrectness : Speaker-Focused Post-Correction for Abstractive Dialogue Summarization</a></strong><br><a href=/people/d/dongyub-lee/>Dongyub Lee</a>
|
<a href=/people/j/jungwoo-lim/>Jungwoo Lim</a>
|
<a href=/people/t/taesun-whang/>Taesun Whang</a>
|
<a href=/people/c/chanhee-lee/>Chanhee Lee</a>
|
<a href=/people/s/seungwoo-cho/>Seungwoo Cho</a>
|
<a href=/people/m/mingun-park/>Mingun Park</a>
|
<a href=/people/h/heui-seok-lim/>Heuiseok Lim</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--newsum-1--8><div class="card-body p-3 small">In this paper, we focus on improving the quality of the summary generated by neural abstractive dialogue summarization systems. Even though pre-trained language models generate well-constructed and promising results, it is still challenging to summarize the conversation of multiple participants since the summary should include a description of the overall situation and the actions of each speaker. This paper proposes self-supervised strategies for speaker-focused post-correction in abstractive dialogue summarization. Specifically, our model first discriminates which type of speaker correction is required in a draft summary and then generates a revised summary according to the required type. Experimental results show that our proposed method adequately corrects the draft summaries, and the revised summaries are significantly improved in both quantitative and qualitative evaluations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.newsum-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--newsum-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.newsum-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.newsum-1.11/>Context or No Context? A preliminary exploration of human-in-the-loop approach for Incremental Temporal Summarization in meetings</a></strong><br><a href=/people/n/nicole-beckage/>Nicole Beckage</a>
|
<a href=/people/s/shachi-h-kumar/>Shachi H Kumar</a>
|
<a href=/people/s/saurav-sahay/>Saurav Sahay</a>
|
<a href=/people/r/ramesh-manuvinakurike/>Ramesh Manuvinakurike</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--newsum-1--11><div class="card-body p-3 small">Incremental meeting temporal summarization, summarizing relevant information of partial multi-party meeting dialogue, is emerging as the next challenge in summarization research. Here we examine the extent to which human abstractive summaries of the preceding increments (context) can be combined with extractive meeting dialogue to generate abstractive summaries. We find that previous context improves ROUGE scores. Our findings further suggest that contexts begin to outweigh the dialogue. Using <a href=https://en.wikipedia.org/wiki/Keyphrase_extraction>keyphrase extraction</a> and semantic role labeling (SRL), we find that SRL captures relevant information without overwhelming the the model architecture. By compressing the previous contexts by ~70 %, we achieve better ROUGE scores over our baseline models. Collectively, these results suggest that context matters, as does the way in which context is presented to the model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.newsum-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--newsum-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.newsum-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.newsum-1.12/>Are We Summarizing the Right Way? A Survey of Dialogue Summarization Data Sets</a></strong><br><a href=/people/d/don-tuggener/>Don Tuggener</a>
|
<a href=/people/m/margot-mieskes/>Margot Mieskes</a>
|
<a href=/people/j/jan-milan-deriu/>Jan Deriu</a>
|
<a href=/people/m/mark-cieliebak/>Mark Cieliebak</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--newsum-1--12><div class="card-body p-3 small">Dialogue summarization is a long-standing task in the field of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, and several data sets with <a href=https://en.wikipedia.org/wiki/Dialogue>dialogues</a> and associated human-written summaries of different styles exist. However, it is unclear for which type of dialogue which type of summary is most appropriate. For this reason, we apply a linguistic model of dialogue types to derive matching summary items and NLP tasks. This allows us to map existing dialogue summarization data sets into this <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> and identify gaps and potential directions for future work. As part of this process, we also provide an extensive overview of existing dialogue summarization data sets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.newsum-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--newsum-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.newsum-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.newsum-1.13" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.newsum-1.13/>Modeling Endorsement for Multi-Document Abstractive Summarization</a></strong><br><a href=/people/l/logan-lebanoff/>Logan Lebanoff</a>
|
<a href=/people/b/bingqing-wang/>Bingqing Wang</a>
|
<a href=/people/z/zhe-feng/>Zhe Feng</a>
|
<a href=/people/f/fei-liu-utdallas/>Fei Liu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--newsum-1--13><div class="card-body p-3 small">A crucial difference between single- and multi-document summarization is how <a href=https://en.wikipedia.org/wiki/Salience_(neuroscience)>salient content</a> manifests itself in the document(s). While such <a href=https://en.wikipedia.org/wiki/Content_(media)>content</a> may appear at the beginning of a single document, essential information is frequently reiterated in a set of documents related to a particular topic, resulting in an endorsement effect that increases information salience. In this paper, we model the cross-document endorsement effect and its utilization in multiple document summarization. Our method generates a synopsis from each document, which serves as an endorser to identify salient content from other documents. Strongly endorsed text segments are used to enrich a neural encoder-decoder model to consolidate them into an abstractive summary. The method has a great potential to learn from fewer examples to identify salient content, which alleviates the need for costly retraining when the set of documents is dynamically adjusted. Through extensive experiments on benchmark multi-document summarization datasets, we demonstrate the effectiveness of our proposed method over strong published baselines. Finally, we shed light on future research directions and discuss broader challenges of this task using a case study.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.newsum-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--newsum-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.newsum-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.newsum-1.14/>SUBSUME : A Dataset for Subjective Summary Extraction from Wikipedia Documents<span class=acl-fixed-case>SUBSUME</span>: A Dataset for Subjective Summary Extraction from <span class=acl-fixed-case>W</span>ikipedia Documents</a></strong><br><a href=/people/n/nishant-yadav/>Nishant Yadav</a>
|
<a href=/people/m/matteo-brucato/>Matteo Brucato</a>
|
<a href=/people/a/anna-fariha/>Anna Fariha</a>
|
<a href=/people/o/oscar-youngquist/>Oscar Youngquist</a>
|
<a href=/people/j/julian-killingback/>Julian Killingback</a>
|
<a href=/people/a/alexandra-meliou/>Alexandra Meliou</a>
|
<a href=/people/p/peter-haas/>Peter Haas</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--newsum-1--14><div class="card-body p-3 small">Many <a href=https://en.wikipedia.org/wiki/Application_software>applications</a> require generation of summaries tailored to the user&#8217;s information needs, i.e., their intent. Methods that express intent via explicit user queries fall short when query interpretation is subjective. Several <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> exist for <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization</a> with objective intents where, for each document and intent (e.g., weather), a single summary suffices for all users. No <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> exist, however, for <a href=https://en.wikipedia.org/wiki/Intention_(philosophy)>subjective intents</a> (e.g., interesting places) where different users will provide different summaries. We present <a href=https://en.wikipedia.org/wiki/Subset>SUBSUME</a>, the first <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for evaluation of SUBjective SUMmary Extraction systems. SUBSUME contains 2,200 (document, intent, summary) triplets over 48 Wikipedia pages, with ten intents of varying subjectivity, provided by 103 individuals over Mechanical Turk. We demonstrate statistically that the intents in <a href=https://en.wikipedia.org/wiki/Subspecies>SUBSUME</a> vary systematically in <a href=https://en.wikipedia.org/wiki/Subjectivity>subjectivity</a>. To indicate SUBSUME&#8217;s usefulness, we explore a collection of baseline algorithms for subjective extractive summarization and show that (i) as expected, example-based approaches better capture subjective intents than query-based ones, and (ii) there is ample scope for improving upon the baseline algorithms, thereby motivating further research on this challenging problem.</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>