<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Workshop on Cognitive Aspects of the Lexicon (2020) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Workshop on Cognitive Aspects of the Lexicon (2020)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#2020cogalex-1>Proceedings of the Workshop on the Cognitive Aspects of the Lexicon</a>
<span class="badge badge-info align-middle ml-1">8&nbsp;papers</span></li></ul></div></div><div id=2020cogalex-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.cogalex-1/>Proceedings of the Workshop on the Cognitive Aspects of the Lexicon</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.cogalex-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.cogalex-1.0/>Proceedings of the Workshop on the Cognitive Aspects of the Lexicon</a></strong><br><a href=/people/m/michael-zock/>Michael Zock</a>
|
<a href=/people/e/emmanuele-chersoni/>Emmanuele Chersoni</a>
|
<a href=/people/a/alessandro-lenci/>Alessandro Lenci</a>
|
<a href=/people/e/enrico-santus/>Enrico Santus</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.cogalex-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--cogalex-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.cogalex-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.cogalex-1.1/>Individual corpora predict fast memory retrieval during reading</a></strong><br><a href=/people/m/markus-j-hofmann/>Markus J. Hofmann</a>
|
<a href=/people/l/lara-muller/>Lara Müller</a>
|
<a href=/people/a/andre-rolke/>Andre Rölke</a>
|
<a href=/people/r/ralph-radach/>Ralph Radach</a>
|
<a href=/people/c/chris-biemann/>Chris Biemann</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--cogalex-1--1><div class="card-body p-3 small">The <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a>, from which a <a href=https://en.wikipedia.org/wiki/Predictive_modelling>predictive language model</a> is trained, can be considered the experience of a semantic system. We recorded everyday reading of two participants for two months on a tablet, generating individual corpus samples of 300/500 K tokens. Then we trained word2vec models from individual corpora and a 70 million-sentence newspaper corpus to obtain individual and norm-based long-term memory structure. To test whether individual corpora can make better predictions for a cognitive task of long-term memory retrieval, we generated stimulus materials consisting of 134 sentences with uncorrelated individual and norm-based word probabilities. For the subsequent eye tracking study 1-2 months later, our <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression analyses</a> revealed that individual, but not norm-corpus-based word probabilities can account for first-fixation duration and first-pass gaze duration. Word length additionally affected gaze duration and total viewing duration. The results suggest that corpora representative for an individual&#8217;s <a href=https://en.wikipedia.org/wiki/Long-term_memory>long-term memory structure</a> can better explain reading performance than a norm corpus, and that recently acquired information is lexically accessed rapidly.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.cogalex-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--cogalex-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.cogalex-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.cogalex-1.4" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.cogalex-1.4/>Less is Better : A cognitively inspired unsupervised model for language segmentation</a></strong><br><a href=/people/j/jinbiao-yang/>Jinbiao Yang</a>
|
<a href=/people/s/stefan-l-frank/>Stefan L. Frank</a>
|
<a href=/people/a/antal-van-den-bosch/>Antal van den Bosch</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--cogalex-1--4><div class="card-body p-3 small">Language users process utterances by segmenting them into many cognitive units, which vary in their sizes and <a href=https://en.wikipedia.org/wiki/Linguistic_description>linguistic levels</a>. Although we can do such unitization / segmentation easily, its <a href=https://en.wikipedia.org/wiki/Cognition>cognitive mechanism</a> is still not clear. This paper proposes an <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised model</a>, Less-is-Better (LiB), to simulate the human cognitive process with respect to language unitization / segmentation. LiB follows the principle of least effort and aims to build a lexicon which minimizes the number of unit tokens (alleviating the effort of analysis) and number of unit types (alleviating the effort of storage) at the same time on any given corpus. LiB&#8217;s workflow is inspired by empirical cognitive phenomena. The design makes the mechanism of LiB cognitively plausible and the computational requirement light-weight. The lexicon generated by LiB performs the best among different types of lexicons (e.g. ground-truth words) both from an information-theoretical view and a cognitive view, which suggests that the LiB lexicon may be a plausible proxy of the <a href=https://en.wikipedia.org/wiki/Mental_lexicon>mental lexicon</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.cogalex-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--cogalex-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.cogalex-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.cogalex-1.5/>The CogALex Shared Task on Monolingual and Multilingual Identification of Semantic Relations<span class=acl-fixed-case>C</span>og<span class=acl-fixed-case>AL</span>ex Shared Task on Monolingual and Multilingual Identification of Semantic Relations</a></strong><br><a href=/people/r/rong-xiang/>Rong Xiang</a>
|
<a href=/people/e/emmanuele-chersoni/>Emmanuele Chersoni</a>
|
<a href=/people/l/luca-iacoponi/>Luca Iacoponi</a>
|
<a href=/people/e/enrico-santus/>Enrico Santus</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--cogalex-1--5><div class="card-body p-3 small">The shared task of the CogALex-VI workshop focuses on the monolingual and multilingual identification of semantic relations. We provided training and validation data for the following languages : <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/German_language>German</a> and <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a>. Given a word pair, systems had to be trained to identify which relation holds between them, with possible choices being <a href=https://en.wikipedia.org/wiki/Synonym>synonymy</a>, <a href=https://en.wikipedia.org/wiki/Opposite_(semantics)>antonymy</a>, <a href=https://en.wikipedia.org/wiki/Hyponymy_and_hypernymy>hypernymy</a> and no relation at all. Two test sets were released for evaluating the participating <a href=https://en.wikipedia.org/wiki/System>systems</a>. One containing pairs for each of the training languages (systems were evaluated in a monolingual fashion) and the other proposing a surprise language to test the crosslingual transfer capabilities of the systems. Among the submitted systems, top performance was achieved by a transformer-based model in both the monolingual and in the multilingual setting, for all the tested languages, proving the potentials of this recently-introduced neural architecture. The shared task description and the results are available at https://sites.google.com/site/cogalexvisharedtask/.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.cogalex-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--cogalex-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.cogalex-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.cogalex-1.7" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.cogalex-1.7/>CogALex-VI Shared Task : Transrelation-A Robust Multilingual Language Model for Multilingual Relation Identification<span class=acl-fixed-case>C</span>og<span class=acl-fixed-case>AL</span>ex-<span class=acl-fixed-case>VI</span> Shared Task: Transrelation - A Robust Multilingual Language Model for Multilingual Relation Identification</a></strong><br><a href=/people/l/lennart-wachowiak/>Lennart Wachowiak</a>
|
<a href=/people/c/christian-lang/>Christian Lang</a>
|
<a href=/people/b/barbara-heinisch/>Barbara Heinisch</a>
|
<a href=/people/d/dagmar-gromann/>Dagmar Gromann</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--cogalex-1--7><div class="card-body p-3 small">We describe our submission to the CogALex-VI shared task on the identification of multilingual paradigmatic relations building on XLM-RoBERTa (XLM-R), a robustly optimized and multilingual BERT model. In spite of several experiments with data augmentation, data addition and ensemble methods with a Siamese Triple Net, Translrelation, the XLM-R model with a <a href=https://en.wikipedia.org/wiki/Linear_classifier>linear classifier</a> adapted to this specific task, performed best in testing and achieved the best results in the final evaluation of the shared task, even for a previously unseen language.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.cogalex-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--cogalex-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.cogalex-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.cogalex-1.14/>Translating Collocations : The Need for Task-driven Word Associations</a></strong><br><a href=/people/o/olivia-o-y-kwong/>Oi Yee Kwong</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--cogalex-1--14><div class="card-body p-3 small">Existing <a href=https://en.wikipedia.org/wiki/Dictionary>dictionaries</a> may help collocation translation by suggesting associated words in the form of collocations, <a href=https://en.wikipedia.org/wiki/Thesaurus>thesaurus</a>, and example sentences. We propose to enhance them with task-driven word associations, illustrating the need by a few scenarios and outlining a possible approach based on <a href=https://en.wikipedia.org/wiki/Word_embedding>word embedding</a>. An example is given, using pre-trained word embedding, while more extensive investigation with more refined methods and resources is underway.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.cogalex-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--cogalex-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.cogalex-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.cogalex-1.15/>Characterizing Dynamic Word Meaning Representations in the Brain</a></strong><br><a href=/people/n/nora-aguirre-celis/>Nora Aguirre-Celis</a>
|
<a href=/people/r/risto-miikkulainen/>Risto Miikkulainen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--cogalex-1--15><div class="card-body p-3 small">During <a href=https://en.wikipedia.org/wiki/Sentence_comprehension>sentence comprehension</a>, humans adjust <a href=https://en.wikipedia.org/wiki/Meaning_(linguistics)>word meanings</a> according to the combination of the concepts that occur in the sentence. This paper presents a neural network model called CEREBRA (Context-dEpendent meaning REpresentation in the BRAin) that demonstrates this process based on fMRI sentence patterns and the Concept Attribute Rep-resentation (CAR) theory. In several experiments, CEREBRA is used to quantify conceptual combination effect and demonstrate that it matters to humans. Such context-based representations could be used in future <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing systems</a> allowing them to mirror human performance more accurately.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.cogalex-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--cogalex-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.cogalex-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.cogalex-1.16/>Contextualized Word Embeddings Encode Aspects of Human-Like Word Sense Knowledge</a></strong><br><a href=/people/s/sathvik-nair/>Sathvik Nair</a>
|
<a href=/people/m/mahesh-srinivasan/>Mahesh Srinivasan</a>
|
<a href=/people/s/stephan-meylan/>Stephan Meylan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--cogalex-1--16><div class="card-body p-3 small">Understanding context-dependent variation in word meanings is a key aspect of <a href=https://en.wikipedia.org/wiki/Sentence_processing>human language comprehension</a> supported by the lexicon. Lexicographic resources (e.g., WordNet) capture only some of this context-dependent variation ; for example, they often do not encode how closely senses, or <a href=https://en.wikipedia.org/wiki/Semantic_change>discretized word meanings</a>, are related to one another. Our work investigates whether recent advances in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, specifically contextualized word embeddings, capture human-like distinctions between English word senses, such as <a href=https://en.wikipedia.org/wiki/Polysemy>polysemy</a> and <a href=https://en.wikipedia.org/wiki/Homonym>homonymy</a>. We collect data from a behavioral, web-based experiment, in which participants provide judgments of the relatedness of multiple WordNet senses of a word in a two-dimensional spatial arrangement task. We find that participants&#8217; judgments of the relatedness between senses are correlated with distances between senses in the BERT embedding space. Specifically, homonymous senses (e.g., bat as mammal vs. bat as sports equipment) are reliably more distant from one another in the embedding space than polysemous ones (e.g., chicken as animal vs. chicken as meat). Our findings point towards the potential utility of continuous-space representations of sense meanings.</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>