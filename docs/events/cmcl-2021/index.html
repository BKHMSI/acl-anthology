<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Workshop on Cognitive Modeling and Computational Linguistics (2021) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Workshop on Cognitive Modeling and Computational Linguistics (2021)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#2021cmcl-1>Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics</a>
<span class="badge badge-info align-middle ml-1">15&nbsp;papers</span></li></ul></div></div><div id=2021cmcl-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.cmcl-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2021.cmcl-1/>Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.cmcl-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.cmcl-1.0/>Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics</a></strong><br><a href=/people/e/emmanuele-chersoni/>Emmanuele Chersoni</a>
|
<a href=/people/n/nora-hollenstein/>Nora Hollenstein</a>
|
<a href=/people/c/cassandra-l-jacobs/>Cassandra Jacobs</a>
|
<a href=/people/y/yohei-oseki/>Yohei Oseki</a>
|
<a href=/people/l/laurent-prevot/>Laurent Prévot</a>
|
<a href=/people/e/enrico-santus/>Enrico Santus</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.cmcl-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--cmcl-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.cmcl-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.cmcl-1.3/>Modeling Incremental Language Comprehension in the Brain with Combinatory Categorial Grammar<span class=acl-fixed-case>C</span>ombinatory <span class=acl-fixed-case>C</span>ategorial <span class=acl-fixed-case>G</span>rammar</a></strong><br><a href=/people/m/milos-stanojevic/>Miloš Stanojević</a>
|
<a href=/people/s/shohini-bhattasali/>Shohini Bhattasali</a>
|
<a href=/people/d/donald-dunagan/>Donald Dunagan</a>
|
<a href=/people/l/luca-campanelli/>Luca Campanelli</a>
|
<a href=/people/m/mark-steedman/>Mark Steedman</a>
|
<a href=/people/j/jonathan-brennan/>Jonathan Brennan</a>
|
<a href=/people/j/john-hale/>John Hale</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--cmcl-1--3><div class="card-body p-3 small">Hierarchical sentence structure plays a role in word-by-word human sentence comprehension, but it remains unclear how best to characterize this <a href=https://en.wikipedia.org/wiki/Structure>structure</a> and unknown how exactly it would be recognized in a step-by-step process model. With a view towards sharpening this picture, we model the time course of <a href=https://en.wikipedia.org/wiki/Hemodynamics>hemodynamic activity</a> within the brain during an extended episode of <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>naturalistic language comprehension</a> using Combinatory Categorial Grammar (CCG). CCG has well-defined incremental parsing algorithms, surface compositional semantics, and can explain long-range dependencies as well as complicated cases of coordination. We find that CCG-derived predictors improve a regression model of fMRI time course in six language-relevant brain regions, over and above <a href=https://en.wikipedia.org/wiki/Prediction>predictors</a> derived from context-free phrase structure. Adding a special Revealing operator to CCG parsing, one designed to handle right-adjunction, improves the fit in three of these regions. This evidence for CCG from <a href=https://en.wikipedia.org/wiki/Neuroimaging>neuroimaging</a> bolsters the more general case for mildly context-sensitive grammars in the cognitive science of language.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.cmcl-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--cmcl-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.cmcl-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.cmcl-1.5" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.cmcl-1.5/>That Looks Hard : Characterizing Linguistic Complexity in Humans and Language Models</a></strong><br><a href=/people/g/gabriele-sarti/>Gabriele Sarti</a>
|
<a href=/people/d/dominique-brunato/>Dominique Brunato</a>
|
<a href=/people/f/felice-dellorletta/>Felice Dell’Orletta</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--cmcl-1--5><div class="card-body p-3 small">This paper investigates the relationship between two complementary perspectives in the human assessment of sentence complexity and how they are modeled in a neural language model (NLM). The first <a href=https://en.wikipedia.org/wiki/Point_of_view_(philosophy)>perspective</a> takes into account multiple online behavioral metrics obtained from eye-tracking recordings. The second one concerns the offline perception of complexity measured by explicit <a href=https://en.wikipedia.org/wiki/Judgment_(mathematical_logic)>human judgments</a>. Using a broad spectrum of linguistic features modeling lexical, morpho-syntactic, and syntactic properties of sentences, we perform a comprehensive analysis of linguistic phenomena associated with the two complexity viewpoints and report similarities and differences. We then show the effectiveness of <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>linguistic features</a> when explicitly leveraged by a <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression model</a> for predicting sentence complexity and compare its results with the ones obtained by a fine-tuned neural language model. We finally probe the NLM&#8217;s linguistic competence before and after <a href=https://en.wikipedia.org/wiki/Fine-tuning>fine-tuning</a>, highlighting how linguistic information encoded in representations changes when the model learns to predict <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.cmcl-1.8.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--cmcl-1--8 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.cmcl-1.8 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.cmcl-1.8.OptionalSupplementaryData.zip data-toggle=tooltip data-placement=top title="Optional supplementary data"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.cmcl-1.8/>LangResearchLab_NC at CMCL2021 Shared Task : Predicting Gaze Behaviour Using Linguistic Features and Tree Regressors<span class=acl-fixed-case>L</span>ang<span class=acl-fixed-case>R</span>esearch<span class=acl-fixed-case>L</span>ab_<span class=acl-fixed-case>NC</span> at <span class=acl-fixed-case>CMCL</span>2021 Shared Task: Predicting Gaze Behaviour Using Linguistic Features and Tree Regressors</a></strong><br><a href=/people/r/raksha-agarwal/>Raksha Agarwal</a>
|
<a href=/people/n/niladri-chatterjee/>Niladri Chatterjee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--cmcl-1--8><div class="card-body p-3 small">Analysis of gaze data behaviour has gained momentum in recent years for different NLP applications. The present paper aims at modelling gaze data behaviour of tokens in the context of a sentence. We have experimented with various <a href=https://en.wikipedia.org/wiki/Regression_analysis>Machine Learning Regression Algorithms</a> on a <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature space</a> comprising the linguistic features of the target tokens for prediction of five Eye-Tracking features. CatBoost Regressor performed the best and achieved fourth position in terms of MAE based accuracy measurement for the ZuCo Dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.cmcl-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--cmcl-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.cmcl-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.cmcl-1.9" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.cmcl-1.9/>TorontoCL at CMCL 2021 Shared Task : RoBERTa with Multi-Stage Fine-Tuning for Eye-Tracking Prediction<span class=acl-fixed-case>T</span>oronto<span class=acl-fixed-case>CL</span> at <span class=acl-fixed-case>CMCL</span> 2021 Shared Task: <span class=acl-fixed-case>R</span>o<span class=acl-fixed-case>BERT</span>a with Multi-Stage Fine-Tuning for Eye-Tracking Prediction</a></strong><br><a href=/people/b/bai-li/>Bai Li</a>
|
<a href=/people/f/frank-rudzicz/>Frank Rudzicz</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--cmcl-1--9><div class="card-body p-3 small">Eye movement data during reading is a useful source of information for understanding <a href=https://en.wikipedia.org/wiki/Sentence_processing>language comprehension processes</a>. In this paper, we describe our submission to the CMCL 2021 shared task on predicting human reading patterns. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> uses RoBERTa with a <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression layer</a> to predict 5 eye-tracking features. We train the model in two stages : we first fine-tune on the Provo corpus (another eye-tracking dataset), then fine-tune on the task data. We compare different Transformer models and apply ensembling methods to improve the performance. Our final submission achieves a MAE score of 3.929, ranking 3rd place out of 13 teams that participated in this shared task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.cmcl-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--cmcl-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.cmcl-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.cmcl-1.10/>LAST at CMCL 2021 Shared Task : Predicting Gaze Data During Reading with a Gradient Boosting Decision Tree Approach<span class=acl-fixed-case>LAST</span> at <span class=acl-fixed-case>CMCL</span> 2021 Shared Task: Predicting Gaze Data During Reading with a Gradient Boosting Decision Tree Approach</a></strong><br><a href=/people/y/yves-bestgen/>Yves Bestgen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--cmcl-1--10><div class="card-body p-3 small">A LightGBM model fed with target word lexical characteristics and features obtained from word frequency lists, psychometric data and bigram association measures has been optimized for the 2021 CMCL Shared Task on Eye-Tracking Data Prediction. It obtained the best performance of all teams on two of the five eye-tracking measures to predict, allowing <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> to rank first on the official challenge criterion and to outperform all <a href=https://en.wikipedia.org/wiki/Deep_learning>deep-learning based systems</a> participating in the challenge.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.cmcl-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--cmcl-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.cmcl-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.cmcl-1.12/>PIHKers at CMCL 2021 Shared Task : Cosine Similarity and Surprisal to Predict Human Reading Patterns.<span class=acl-fixed-case>PIHK</span>ers at <span class=acl-fixed-case>CMCL</span> 2021 Shared Task: Cosine Similarity and Surprisal to Predict Human Reading Patterns.</a></strong><br><a href=/people/l/lavinia-salicchi/>Lavinia Salicchi</a>
|
<a href=/people/a/alessandro-lenci/>Alessandro Lenci</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--cmcl-1--12><div class="card-body p-3 small">Eye-tracking psycholinguistic studies have revealed that context-word semantic coherence and <a href=https://en.wikipedia.org/wiki/Predictability>predictability</a> influence <a href=https://en.wikipedia.org/wiki/Language_processing_in_the_brain>language processing</a>. In this paper we show our approach to predict eye-tracking features from the ZuCo dataset for the shared task of the Cognitive Modeling and Computational Linguistics (CMCL2021) workshop. Using both cosine similarity and surprisal within a <a href=https://en.wikipedia.org/wiki/Regression_analysis>regression model</a>, we significantly improved the baseline Mean Absolute Error computed among five eye-tracking features.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.cmcl-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--cmcl-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.cmcl-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.cmcl-1.13.OptionalSupplementaryMaterial.zip data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.cmcl-1.13/>TALEP at CMCL 2021 Shared Task : Non Linear Combination of Low and High-Level Features for Predicting Eye-Tracking Data<span class=acl-fixed-case>TALEP</span> at <span class=acl-fixed-case>CMCL</span> 2021 Shared Task: Non Linear Combination of Low and High-Level Features for Predicting Eye-Tracking Data</a></strong><br><a href=/people/f/franck-dary/>Franck Dary</a>
|
<a href=/people/a/alexis-nasr/>Alexis Nasr</a>
|
<a href=/people/a/abdellah-fourtassi/>Abdellah Fourtassi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--cmcl-1--13><div class="card-body p-3 small">In this paper we describe our contribution to the CMCL 2021 Shared Task, which consists in predicting 5 different eye tracking variables from English tokenized text. Our approach is based on a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> that combines both raw textual features we extracted from the text and parser-based features that include linguistic predictions (e.g. part of speech) and complexity metrics (e.g., entropy of parsing). We found that both the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> we considered as well as the architecture of the neural model that combined these <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> played a role in the overall performance. Our system achieved relatively high <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on the test data of the challenge and was ranked 2nd out of 13 competing teams and a total of 30 submissions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.cmcl-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--cmcl-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.cmcl-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.cmcl-1.14.OptionalSupplementaryData.zip data-toggle=tooltip data-placement=top title="Optional supplementary data"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.cmcl-1.14/>MTL782_IITD at CMCL 2021 Shared Task : Prediction of Eye-Tracking Features Using BERT Embeddings and Linguistic Features<span class=acl-fixed-case>MTL</span>782_<span class=acl-fixed-case>IITD</span> at <span class=acl-fixed-case>CMCL</span> 2021 Shared Task: Prediction of Eye-Tracking Features Using <span class=acl-fixed-case>BERT</span> Embeddings and Linguistic Features</a></strong><br><a href=/people/s/shivani-choudhary/>Shivani Choudhary</a>
|
<a href=/people/k/kushagri-tandon/>Kushagri Tandon</a>
|
<a href=/people/r/raksha-agarwal/>Raksha Agarwal</a>
|
<a href=/people/n/niladri-chatterjee/>Niladri Chatterjee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--cmcl-1--14><div class="card-body p-3 small">Reading and comprehension are quintessentially cognitive tasks. Eye movement acts as a surrogate to understand which part of a sentence is critical to the process of comprehension. The aim of the shared task is to predict five eye-tracking features for a given word of the input sentence. We experimented with several models based on LGBM (Light Gradient Boosting Machine) Regression, ANN (Artificial Neural Network), and CNN (Convolutional Neural Network), using BERT embeddings and some combination of linguistic features. Our submission using <a href=https://en.wikipedia.org/wiki/CNN>CNN</a> achieved an average MAE of 4.0639 and ranked 7th in the shared task. The average MAE was further lowered to 3.994 in post-task evaluation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.cmcl-1.18.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--cmcl-1--18 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.cmcl-1.18 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.cmcl-1.18" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.cmcl-1.18/>Enhancing Cognitive Models of Emotions with <a href=https://en.wikipedia.org/wiki/Representation_learning>Representation Learning</a></a></strong><br><a href=/people/y/yuting-guo/>Yuting Guo</a>
|
<a href=/people/j/jinho-d-choi/>Jinho D. Choi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--cmcl-1--18><div class="card-body p-3 small">We present a novel deep learning-based framework to generate embedding representations of fine-grained emotions that can be used to computationally describe psychological models of emotions. Our framework integrates a contextualized embedding encoder with a multi-head probing model that enables to interpret dynamically learned representations optimized for an emotion classification task. Our model is evaluated on the Empathetic Dialogue dataset and shows the state-of-the-art result for classifying 32 emotions. Our layer analysis can derive an emotion graph to depict hierarchical relations among the emotions. Our emotion representations can be used to generate an emotion wheel directly comparable to the one from Plutchik&#8217;s model, and also augment the values of missing emotions in the <a href=https://en.wikipedia.org/wiki/PAD_emotional_state_model>PAD emotional state model</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.cmcl-1.20.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--cmcl-1--20 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.cmcl-1.20 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.cmcl-1.20.OptionalSupplementaryMaterial.pdf data-toggle=tooltip data-placement=top title="Optional supplementary material"><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.cmcl-1.20.OptionalSupplementaryData.pdf data-toggle=tooltip data-placement=top title="Optional supplementary data"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.cmcl-1.20/>Clause Final Verb Prediction in <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a> : Evidence for Noisy Channel Model of Communication<span class=acl-fixed-case>H</span>indi: Evidence for Noisy Channel Model of Communication</a></strong><br><a href=/people/k/kartik-sharma/>Kartik Sharma</a>
|
<a href=/people/n/niyati-bafna/>Niyati Bafna</a>
|
<a href=/people/s/samar-husain/>Samar Husain</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--cmcl-1--20><div class="card-body p-3 small">Verbal prediction has been shown to be critical during online comprehension of Subject-Object-Verb (SOV) languages. In this work we present three <a href=https://en.wikipedia.org/wiki/Computational_model>computational models</a> to predict clause final verbs in <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a> given its prior arguments. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> differ in their use of prior context during the prediction process the context is either noisy or noise-free. Model predictions are compared with the sentence completion data obtained from <a href=https://en.wikipedia.org/wiki/Hindi>Hindi native speakers</a>. Results show that <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that assume noisy context outperform the noise-free model. In particular, a lossy context model that assumes prior context to be affected by <a href=https://en.wikipedia.org/wiki/Predictability>predictability</a> and recency captures the distribution of the predicted verb class and error sources best. The success of the predictability-recency lossy context model is consistent with the noisy channel hypothesis for <a href=https://en.wikipedia.org/wiki/Sentence_processing>sentence comprehension</a> and supports the idea that the reconstruction of the context during prediction is driven by prior linguistic exposure. These results also shed light on the nature of the <a href=https://en.wikipedia.org/wiki/Noise>noise</a> that affects the reconstruction process. Overall the results pose a challenge to the adaptability hypothesis that assumes use of noise-free preverbal context for robust verbal prediction.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.cmcl-1.23.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--cmcl-1--23 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.cmcl-1.23 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.cmcl-1.23.OptionalSupplementaryCode.zip data-toggle=tooltip data-placement=top title="Optional supplementary code"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.cmcl-1.23/>Sentence Complexity in Context</a></strong><br><a href=/people/b/benedetta-iavarone/>Benedetta Iavarone</a>
|
<a href=/people/d/dominique-brunato/>Dominique Brunato</a>
|
<a href=/people/f/felice-dellorletta/>Felice Dell’Orletta</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--cmcl-1--23><div class="card-body p-3 small">We study the influence of <a href=https://en.wikipedia.org/wiki/Context_(language_use)>context</a> on how humans evaluate the <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a> of a sentence in English. We collect a new <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> of sentences, where each sentence is rated for perceived complexity within different contextual windows. We carry out an in-depth analysis to detect which <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>linguistic features</a> correlate more with complexity judgments and with the degree of agreement among annotators. We train several regression models, using either explicit linguistic features or contextualized word embeddings, to predict the mean complexity values assigned to sentences in the different contextual windows, as well as their standard deviation. Results show that models leveraging explicit features capturing morphosyntactic and syntactic phenomena perform always better, especially when they have access to <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>features</a> extracted from all contextual sentences.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.cmcl-1.24.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--cmcl-1--24 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.cmcl-1.24 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.cmcl-1.24" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.cmcl-1.24/>Evaluating the Acquisition of Semantic Knowledge from Cross-situational Learning in Artificial Neural Networks</a></strong><br><a href=/people/m/mitja-nikolaus/>Mitja Nikolaus</a>
|
<a href=/people/a/abdellah-fourtassi/>Abdellah Fourtassi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--cmcl-1--24><div class="card-body p-3 small">When learning their native language, children acquire the meanings of words and sentences from highly ambiguous input without much explicit supervision. One possible learning mechanism is cross-situational learning, which has been successfully tested in laboratory experiments with children. Here we use <a href=https://en.wikipedia.org/wiki/Artificial_neural_network>Artificial Neural Networks</a> to test if this mechanism scales up to more natural language and visual scenes using a large dataset of crowd-sourced images with corresponding descriptions. We evaluate <a href=https://en.wikipedia.org/wiki/Learning>learning</a> using a series of <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a> inspired by <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> commonly used in laboratory studies of <a href=https://en.wikipedia.org/wiki/Language_acquisition>language acquisition</a>. We show that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> acquires rich semantic knowledge both at the word- and sentence-level, mirroring the patterns and trajectory of learning in early childhood. Our work highlights the usefulness of low-level co-occurrence statistics across modalities in facilitating the early acquisition of higher-level semantic knowledge.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.cmcl-1.25.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--cmcl-1--25 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.cmcl-1.25 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.cmcl-1.25/>Representation and Pre-Activation of Lexical-Semantic Knowledge in Neural Language Models</a></strong><br><a href=/people/s/steven-derby/>Steven Derby</a>
|
<a href=/people/p/paul-miller/>Paul Miller</a>
|
<a href=/people/b/barry-devereux/>Barry Devereux</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--cmcl-1--25><div class="card-body p-3 small">In this paper, we perform a systematic analysis of how closely the intermediate layers from LSTM and trans former language models correspond to human semantic knowledge. Furthermore, in order to make more meaningful comparisons with theories of human language comprehension in <a href=https://en.wikipedia.org/wiki/Psycholinguistics>psycholinguistics</a>, we focus on two key stages where the meaning of a particular target word may arise : immediately before the word&#8217;s presentation to the model (comparable to forward inferencing), and immediately after the word token has been input into the network. Our results indicate that the transformer models are better at capturing semantic knowledge relating to lexical concepts, both during <a href=https://en.wikipedia.org/wiki/Word_prediction>word prediction</a> and when retention is required.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.cmcl-1.27.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--cmcl-1--27 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.cmcl-1.27 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.cmcl-1.27/>Graph-theoretic Properties of the Class of Phonological Neighbourhood Networks</a></strong><br><a href=/people/r/rory-turnbull/>Rory Turnbull</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--cmcl-1--27><div class="card-body p-3 small">This paper concerns the structure of phonological neighbourhood networks, which are a graph-theoretic representation of the phonological lexicon. These networks represent each word as a node and links are placed between words which are phonological neighbours, usually defined as a string edit distance of one. Phonological neighbourhood networks have been used to study many aspects of the <a href=https://en.wikipedia.org/wiki/Mental_lexicon>mental lexicon</a> and psycholinguistic theories of speech production and perception. This paper offers preliminary graph-theoretic observations about phonological neighbourhood networks considered as a class. To aid this exploration, this paper introduces the concept of the hyperlexicon, the network consisting of all possible words for a given symbol set and their <a href=https://en.wikipedia.org/wiki/Neighbourhood_(mathematics)>neighbourhood relations</a>. The construction of the hyperlexicon is discussed, and basic properties are derived. This work is among the first to directly address the nature of phonological neighbourhood networks from an analytic perspective.</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>