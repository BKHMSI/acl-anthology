<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>International Natural Language Generation Conference (2021) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>International Natural Language Generation Conference (2021)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#2021inlg-1>Proceedings of the 14th International Conference on Natural Language Generation</a>
<span class="badge badge-info align-middle ml-1">16&nbsp;papers</span></li></ul></div></div><div id=2021inlg-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.inlg-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2021.inlg-1/>Proceedings of the 14th International Conference on Natural Language Generation</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.inlg-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.inlg-1.0/>Proceedings of the 14th International Conference on Natural Language Generation</a></strong><br><a href=/people/a/anja-belz/>Anya Belz</a>
|
<a href=/people/a/angela-fan/>Angela Fan</a>
|
<a href=/people/e/ehud-reiter/>Ehud Reiter</a>
|
<a href=/people/y/yaji-sripada/>Yaji Sripada</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.inlg-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--inlg-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.inlg-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.inlg-1.2" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.inlg-1.2/>Neural Methodius Revisited : Do Discourse Relations Help with Pre-Trained Models Too?</a></strong><br><a href=/people/a/aleksandre-maskharashvili/>Aleksandre Maskharashvili</a>
|
<a href=/people/s/symon-stevens-guille/>Symon Stevens-Guille</a>
|
<a href=/people/x/xintong-li/>Xintong Li</a>
|
<a href=/people/m/michael-white/>Michael White</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--inlg-1--2><div class="card-body p-3 small">Recent developments in natural language generation (NLG) have bolstered arguments in favor of re-introducing explicit coding of discourse relations in the input to neural models. In the Methodius corpus, a meaning representation (MR) is hierarchically structured and includes <a href=https://en.wikipedia.org/wiki/Discourse_analysis>discourse relations</a>. Meanwhile pre-trained language models have been shown to implicitly encode rich linguistic knowledge which provides an excellent resource for NLG. By virtue of synthesizing these lines of research, we conduct extensive experiments on the benefits of using pre-trained models and discourse relation information in MRs, focusing on the improvement of discourse coherence and <a href=https://en.wikipedia.org/wiki/Correctness_(computer_science)>correctness</a>. We redesign the Methodius corpus ; we also construct another Methodius corpus in which MRs are not hierarchically structured but flat. We report experiments on different versions of the corpora, which probe when, where, and how pre-trained models benefit from MRs with discourse relation information in them. We conclude that <a href=https://en.wikipedia.org/wiki/Discourse_analysis>discourse relations</a> significantly improve NLG when data is limited.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.inlg-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--inlg-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.inlg-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.inlg-1.5/>Chefbot : A Novel Framework for the Generation of Commonsense-enhanced Responses for Task-based Dialogue Systems</a></strong><br><a href=/people/c/carl-strathearn/>Carl Strathearn</a>
|
<a href=/people/d/dimitra-gkatzia/>Dimitra Gkatzia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--inlg-1--5><div class="card-body p-3 small">Conversational systems aim to generate responses that are accurate, relevant and engaging, either through utilising neural end-to-end models or through slot filling. Human-to-human conversations are enhanced by not only the latest utterance of the interlocutor, but also by recalling relevant information about concepts / objects covered in the dialogue and integrating them into their responses. Such <a href=https://en.wikipedia.org/wiki/Information>information</a> may contain recent referred concepts, <a href=https://en.wikipedia.org/wiki/Commonsense_knowledge>commonsense knowledge</a> and more. A concrete scenario of such <a href=https://en.wikipedia.org/wiki/Dialogue>dialogues</a> is the cooking scenario, i.e. when an artificial agent (personal assistant, <a href=https://en.wikipedia.org/wiki/Robot>robot</a>, chatbot) and a human converse about a recipe. We will demo a novel system for commonsense enhanced response generation in the scenario of cooking, where the conversational system is able to not only provide directions for cooking step-by-step, but also display commonsense capabilities by offering explanations of how objects can be used and provide recommendations for replacing ingredients.<i>commonsense</i> capabilities by offering explanations of how objects can be used and provide recommendations for replacing ingredients.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.inlg-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--inlg-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.inlg-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.inlg-1.6/>Predicting Antonyms in Context using BERT<span class=acl-fixed-case>BERT</span></a></strong><br><a href=/people/a/ayana-niwa/>Ayana Niwa</a>
|
<a href=/people/k/keisuke-nishiguchi/>Keisuke Nishiguchi</a>
|
<a href=/people/n/naoaki-okazaki/>Naoaki Okazaki</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--inlg-1--6><div class="card-body p-3 small">We address the task of <a href=https://en.wikipedia.org/wiki/Opposite_(semantics)>antonym prediction</a> in a context, which is a fill-in-the-blanks problem. This task setting is unique and practical because it requires <a href=https://en.wikipedia.org/wiki/Contrast_(linguistics)>contrastiveness</a> to the other word and naturalness as a text in filling a blank. We propose methods for fine-tuning pre-trained masked language models (BERT) for context-aware antonym prediction. The experimental results demonstrate that these methods have positive impacts on the prediction of antonyms within a context. Moreover, <a href=https://en.wikipedia.org/wiki/Evaluation>human evaluation</a> reveals that more than 85 % of predictions using the proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a> are acceptable as <a href=https://en.wikipedia.org/wiki/Opposite_(semantics)>antonyms</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.inlg-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--inlg-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.inlg-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.inlg-1.7" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.inlg-1.7/>Examining Covert Gender Bias : A Case Study in Turkish and English Machine Translation Models<span class=acl-fixed-case>T</span>urkish and <span class=acl-fixed-case>E</span>nglish Machine Translation Models</a></strong><br><a href=/people/c/chloe-ciora/>Chloe Ciora</a>
|
<a href=/people/n/nur-iren/>Nur Iren</a>
|
<a href=/people/m/malihe-alikhani/>Malihe Alikhani</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--inlg-1--7><div class="card-body p-3 small">As Machine Translation (MT) has become increasingly more powerful, accessible, and widespread, the potential for the perpetuation of bias has grown alongside its advances. While overt indicators of bias have been studied in <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, we argue that covert biases expose a problem that is further entrenched. Through the use of the <a href=https://en.wikipedia.org/wiki/Turkish_language>gender-neutral language Turkish</a> and the <a href=https://en.wikipedia.org/wiki/English_language>gendered language English</a>, we examine cases of both overt and covert gender bias in MT models. Specifically, we introduce a <a href=https://en.wikipedia.org/wiki/Scientific_method>method</a> to investigate asymmetrical gender markings. We also assess <a href=https://en.wikipedia.org/wiki/Bias>bias</a> in the attribution of personhood and examine occupational and personality stereotypes through overt bias indicators in MT models. Our work explores a deeper layer of bias in MT models and demonstrates the continued need for language-specific, interdisciplinary methodology in MT model development.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.inlg-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--inlg-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.inlg-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.inlg-1.12/>Explaining Decision-Tree Predictions by Addressing Potential Conflicts between Predictions and Plausible Expectations</a></strong><br><a href=/people/s/sameen-maruf/>Sameen Maruf</a>
|
<a href=/people/i/ingrid-zukerman/>Ingrid Zukerman</a>
|
<a href=/people/e/ehud-reiter/>Ehud Reiter</a>
|
<a href=/people/g/gholamreza-haffari/>Gholamreza Haffari</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--inlg-1--12><div class="card-body p-3 small">We offer an approach to explain Decision Tree (DT) predictions by addressing potential conflicts between aspects of these predictions and plausible expectations licensed by background information. We define four types of <a href=https://en.wikipedia.org/wiki/Conflict_(process)>conflicts</a>, operationalize their identification, and specify explanatory schemas that address them. Our human evaluation focused on the effect of explanations on users&#8217; understanding of a DT&#8217;s reasoning and their willingness to act on its predictions. The results show that (1) <a href=https://en.wikipedia.org/wiki/Explanation>explanations</a> that address potential conflicts are considered at least as good as baseline explanations that just follow a DT path ; and (2) the conflict-based explanations are deemed especially valuable when users&#8217; expectations disagree with the DT&#8217;s predictions.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.inlg-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--inlg-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.inlg-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.inlg-1.14.Supplementary_Attachment.zip data-toggle=tooltip data-placement=top title="Supplementary attachment"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.inlg-1.14/>Underreporting of errors in NLG output, and what to do about it<span class=acl-fixed-case>NLG</span> output, and what to do about it</a></strong><br><a href=/people/e/emiel-van-miltenburg/>Emiel van Miltenburg</a>
|
<a href=/people/m/miruna-clinciu/>Miruna Clinciu</a>
|
<a href=/people/o/ondrej-dusek/>Ondřej Dušek</a>
|
<a href=/people/d/dimitra-gkatzia/>Dimitra Gkatzia</a>
|
<a href=/people/s/stephanie-inglis/>Stephanie Inglis</a>
|
<a href=/people/l/leo-leppanen/>Leo Leppänen</a>
|
<a href=/people/s/saad-mahamood/>Saad Mahamood</a>
|
<a href=/people/e/emma-manning/>Emma Manning</a>
|
<a href=/people/s/stephanie-schoch/>Stephanie Schoch</a>
|
<a href=/people/c/craig-thomson/>Craig Thomson</a>
|
<a href=/people/l/luou-wen/>Luou Wen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--inlg-1--14><div class="card-body p-3 small">We observe a severe under-reporting of the different kinds of <a href=https://en.wikipedia.org/wiki/Errors-in-variables_models>errors</a> that Natural Language Generation systems make. This is a problem, because mistakes are an important indicator of where systems should still be improved. If authors only report overall performance metrics, the research community is left in the dark about the specific weaknesses that are exhibited by &#8216;state-of-the-art&#8217; research. Next to quantifying the extent of error under-reporting, this position paper provides recommendations for error identification, analysis and reporting.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.inlg-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--inlg-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.inlg-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2021.inlg-1.15.Supplementary_Attachment.zip data-toggle=tooltip data-placement=top title="Supplementary attachment"><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2021.inlg-1.15/>What can Neural Referential Form Selectors Learn?</a></strong><br><a href=/people/g/guanyi-chen/>Guanyi Chen</a>
|
<a href=/people/f/fahime-same/>Fahime Same</a>
|
<a href=/people/k/kees-van-deemter/>Kees van Deemter</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--inlg-1--15><div class="card-body p-3 small">Despite achieving encouraging results, neural Referring Expression Generation models are often thought to lack transparency. We probed neural Referential Form Selection (RFS) models to find out to what extent the linguistic features influencing the RE form are learned and captured by state-of-the-art RFS models. The results of 8 probing tasks show that all the defined <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> were learned to some extent. The probing tasks pertaining to <a href=https://en.wikipedia.org/wiki/Referent>referential status</a> and syntactic position exhibited the highest performance. The lowest performance was achieved by the probing models designed to predict discourse structure properties beyond the <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence level</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.inlg-1.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--inlg-1--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.inlg-1.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.inlg-1.21" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.inlg-1.21/>SAPPHIRE : Approaches for Enhanced Concept-to-Text Generation<span class=acl-fixed-case>SAPPHIRE</span>: Approaches for Enhanced Concept-to-Text Generation</a></strong><br><a href=/people/s/steven-y-feng/>Steven Y. Feng</a>
|
<a href=/people/j/jessica-huynh/>Jessica Huynh</a>
|
<a href=/people/c/chaitanya-prasad-narisetty/>Chaitanya Prasad Narisetty</a>
|
<a href=/people/e/eduard-hovy/>Eduard Hovy</a>
|
<a href=/people/v/varun-gangal/>Varun Gangal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--inlg-1--21><div class="card-body p-3 small">We motivate and propose a suite of simple but effective improvements for concept-to-text generation called SAPPHIRE : Set Augmentation and Post-hoc PHrase Infilling and REcombination. We demonstrate their effectiveness on generative commonsense reasoning, a.k.a. the CommonGen task, through experiments using both BART and T5 models. Through extensive automatic and human evaluation, we show that SAPPHIRE noticeably improves <a href=https://en.wikipedia.org/wiki/Computer_simulation>model</a> performance. An in-depth qualitative analysis illustrates that SAPPHIRE effectively addresses many issues of the baseline model generations, including lack of commonsense, insufficient specificity, and poor fluency.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.inlg-1.23.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--inlg-1--23 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.inlg-1.23 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2021.inlg-1.23" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2021.inlg-1.23/>Generation Challenges : Results of the Accuracy Evaluation Shared Task</a></strong><br><a href=/people/c/craig-thomson/>Craig Thomson</a>
|
<a href=/people/e/ehud-reiter/>Ehud Reiter</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--inlg-1--23><div class="card-body p-3 small">The Shared Task on Evaluating Accuracy focused on techniques (both manual and automatic) for evaluating the factual accuracy of texts produced by neural NLG systems, in a sports-reporting domain. Four teams submitted evaluation techniques for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, using very different approaches and techniques. The best-performing submissions did encouragingly well at this difficult <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>. However, all automatic submissions struggled to detect factual errors which are semantically or pragmatically complex (for example, based on incorrect computation or inference).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.inlg-1.24.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--inlg-1--24 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.inlg-1.24 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.inlg-1.24/>The ReproGen Shared Task on Reproducibility of Human Evaluations in NLG : Overview and Results<span class=acl-fixed-case>R</span>epro<span class=acl-fixed-case>G</span>en Shared Task on Reproducibility of Human Evaluations in <span class=acl-fixed-case>NLG</span>: Overview and Results</a></strong><br><a href=/people/a/anja-belz/>Anya Belz</a>
|
<a href=/people/a/anastasia-shimorina/>Anastasia Shimorina</a>
|
<a href=/people/s/shubham-agarwal/>Shubham Agarwal</a>
|
<a href=/people/e/ehud-reiter/>Ehud Reiter</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--inlg-1--24><div class="card-body p-3 small">The NLP field has recently seen a substantial increase in work related to reproducibility of results, and more generally in recognition of the importance of having shared definitions and practices relating to <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation</a>. Much of the work on <a href=https://en.wikipedia.org/wiki/Reproducibility>reproducibility</a> has so far focused on metric scores, with reproducibility of human evaluation results receiving far less attention. As part of a research programme designed to develop theory and practice of reproducibility assessment in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, we organised the first shared task on reproducibility of human evaluations, ReproGen 2021. This paper describes the shared task in detail, summarises results from each of the reproduction studies submitted, and provides further comparative analysis of the results. Out of nine initial team registrations, we received submissions from four teams. Meta-analysis of the four reproduction studies revealed varying degrees of <a href=https://en.wikipedia.org/wiki/Reproducibility>reproducibility</a>, and allowed very tentative first conclusions about what types of <a href=https://en.wikipedia.org/wiki/Evaluation>evaluation</a> tend to have better <a href=https://en.wikipedia.org/wiki/Reproducibility>reproducibility</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.inlg-1.27.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--inlg-1--27 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.inlg-1.27 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.inlg-1.27/>Automatic Verification of Data Summaries</a></strong><br><a href=/people/r/rayhane-rezgui/>Rayhane Rezgui</a>
|
<a href=/people/m/mohammed-saeed/>Mohammed Saeed</a>
|
<a href=/people/p/paolo-papotti/>Paolo Papotti</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--inlg-1--27><div class="card-body p-3 small">We present a generic method to compute thefactual accuracy of a generated data summarywith minimal user effort. We look at the prob-lem as a fact-checking task to verify the nu-merical claims in the text. The verification al-gorithm assumes that the data used to generatethe text is available. In this paper, we describehow the proposed solution has been used toidentify incorrect claims about basketball tex-tual summaries in the context of the AccuracyShared Task at INLG 2021.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.inlg-1.31.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--inlg-1--31 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.inlg-1.31 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.inlg-1.31/>A Reproduction Study of an Annotation-based Human Evaluation of MT Outputs<span class=acl-fixed-case>MT</span> Outputs</a></strong><br><a href=/people/m/maja-popovic/>Maja Popović</a>
|
<a href=/people/a/anja-belz/>Anya Belz</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--inlg-1--31><div class="card-body p-3 small">In this paper we report our reproduction study of the Croatian part of an annotation-based human evaluation of machine-translated user reviews (Popovic, 2020). The work was carried out as part of the ReproGen Shared Task on Reproducibility of Human Evaluation in NLG. Our aim was to repeat the original study exactly, except for using a different set of evaluators. We describe the experimental design, characterise differences between original and reproduction study, and present the results from each study, along with analysis of the similarity between them. For the six main evaluation results of Major / Minor / All Comprehension error rates and Major / Minor / All Adequacy error rates, we find that (i) 4/6 system rankings are the same in both studies, (ii) the relative differences between systems are replicated well for Major Comprehension and Adequacy (Pearson&#8217;s 0.9), but not for the corresponding Minor error rates (Pearson&#8217;s 0.36 for Adequacy, 0.67 for Comprehension), and (iii) the individual system scores for both types of Minor error rates had a higher degree of <a href=https://en.wikipedia.org/wiki/Reproducibility>reproducibility</a> than the corresponding Major error rates. We also examine <a href=https://en.wikipedia.org/wiki/Inter-annotator_agreement>inter-annotator agreement</a> and compare the <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a> obtained in the original and reproduction studies.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.inlg-1.33.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--inlg-1--33 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.inlg-1.33 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.inlg-1.33/>DialogSum Challenge : Summarizing Real-Life Scenario Dialogues<span class=acl-fixed-case>D</span>ialog<span class=acl-fixed-case>S</span>um Challenge: Summarizing Real-Life Scenario Dialogues</a></strong><br><a href=/people/y/yulong-chen/>Yulong Chen</a>
|
<a href=/people/y/yang-liu-edinburgh/>Yang Liu</a>
|
<a href=/people/y/yue-zhang/>Yue Zhang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--inlg-1--33><div class="card-body p-3 small">We propose a shared task on summarizing real-life scenario dialogues, DialogSum Challenge, to encourage researchers to address challenges in dialogue summarization, which has been less studied by the summarization community. Real-life scenario dialogue summarization has a wide potential application prospect in <a href=https://en.wikipedia.org/wiki/Chatbot>chat-bot</a> and <a href=https://en.wikipedia.org/wiki/Personal_assistant>personal assistant</a>. It contains unique challenges such as special discourse structure, <a href=https://en.wikipedia.org/wiki/Coreference>coreference</a>, <a href=https://en.wikipedia.org/wiki/Pragmatics>pragmatics</a>, and <a href=https://en.wikipedia.org/wiki/Common_sense>social common sense</a>, which require specific representation learning technologies to deal with. We carefully annotate a large-scale dialogue summarization dataset based on multiple public dialogue corpus, opening the door to all kinds of <a href=https://en.wikipedia.org/wiki/Automatic_summarization>summarization models</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.inlg-1.34.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--inlg-1--34 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.inlg-1.34 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.inlg-1.34/>Quality Evaluation of the Low-Resource Synthetically Generated Code-Mixed Hinglish Text<span class=acl-fixed-case>H</span>inglish Text</a></strong><br><a href=/people/v/vivek-srivastava/>Vivek Srivastava</a>
|
<a href=/people/m/mayank-singh/>Mayank Singh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--inlg-1--34><div class="card-body p-3 small">In this shared task, we seek the participating teams to investigate the factors influencing the quality of the code-mixed text generation systems. We synthetically generate code-mixed Hinglish sentences using two distinct approaches and employ human annotators to rate the generation quality. We propose two subtasks, quality rating prediction and annotators&#8217; disagreement prediction of the synthetic Hinglish dataset. The proposed subtasks will put forward the reasoning and explanation of the factors influencing the <a href=https://en.wikipedia.org/wiki/Quality_(business)>quality</a> and human perception of the code-mixed text.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2021.inlg-1.35.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2021--inlg-1--35 data-toggle=collapse aria-expanded=false aria-controls=abstract-2021.inlg-1.35 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2021.inlg-1.35/>Shared Task on Feedback Comment Generation for Language Learners</a></strong><br><a href=/people/r/ryo-nagata/>Ryo Nagata</a>
|
<a href=/people/m/masato-hagiwara/>Masato Hagiwara</a>
|
<a href=/people/k/kazuaki-hanawa/>Kazuaki Hanawa</a>
|
<a href=/people/m/masato-mita/>Masato Mita</a>
|
<a href=/people/a/artem-chernodub/>Artem Chernodub</a>
|
<a href=/people/o/olena-nahorna/>Olena Nahorna</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2021--inlg-1--35><div class="card-body p-3 small">In this paper, we propose a generation challenge called Feedback comment generation for <a href=https://en.wikipedia.org/wiki/Language_acquisition>language learners</a>. It is a task where given a text and a span, a system generates, for the span, an explanatory note that helps the writer (language learner) improve their writing skills. The motivations for this challenge are : (i) practically, it will be beneficial for both <a href=https://en.wikipedia.org/wiki/Language_acquisition>language learners</a> and teachers if a computer-assisted language learning system can provide feedback comments just as human teachers do ; (ii) theoretically, feedback comment generation for <a href=https://en.wikipedia.org/wiki/Language_acquisition>language learners</a> has a mixed aspect of other generation tasks together with its unique features and it will be interesting to explore what kind of generation technique is effective against what kind of writing rule. To this end, we have created a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> and developed <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline systems</a> to estimate baseline performance. With these preparations, we propose a generation challenge of feedback comment generation.</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>