<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Other Workshops and Events (2020) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Other Workshops and Events (2020)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#2020aespen-1>Proceedings of the Workshop on Automated Extraction of Socio-political Events from News 2020</a>
<span class="badge badge-info align-middle ml-1">6&nbsp;papers</span></li><li><a class=align-middle href=#2020ai4hi-1>Proceedings of the 1st International Workshop on Artificial Intelligence for Historical Image Enrichment and Access</a>
<span class="badge badge-info align-middle ml-1">3&nbsp;papers</span></li><li><a class=align-middle href=#2020alvr-1>Proceedings of the First Workshop on Advances in Language and Vision Research</a>
<span class="badge badge-info align-middle ml-1">4&nbsp;papers</span></li><li><a class=align-middle href=#2020autosimtrans-1>Proceedings of the First Workshop on Automatic Simultaneous Translation</a>
<span class="badge badge-info align-middle ml-1">2&nbsp;papers</span></li><li><a class=align-middle href=#2020bea-1>Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications</a>
<span class="badge badge-info align-middle ml-1">10&nbsp;papers</span></li><li><a class=align-middle href=#2020bionlp-1>Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing</a>
<span class="badge badge-info align-middle ml-1">7&nbsp;papers</span></li><li><a class=align-middle href=#2020bucc-1>Proceedings of the 13th Workshop on Building and Using Comparable Corpora</a>
<span class="badge badge-info align-middle ml-1">7&nbsp;papers</span></li><li><a class=align-middle href=#2020calcs-1>Proceedings of the The 4th Workshop on Computational Approaches to Code Switching</a>
<span class="badge badge-info align-middle ml-1">2&nbsp;papers</span></li><li><a class=align-middle href=#2020challengehml-1>Second Grand-Challenge and Workshop on Multimodal Language (Challenge-HML)</a>
<span class="badge badge-info align-middle ml-1">2&nbsp;papers</span></li><li><a class=align-middle href=#2020cllrd-1>Proceedings of the LREC 2020 Workshop on "Citizen Linguistics in Language Resource Development"</a>
<span class="badge badge-info align-middle ml-1">2&nbsp;papers</span></li><li><a class=align-middle href=#2020clssts-1>Proceedings of the workshop on Cross-Language Search and Summarization of Text and Speech (CLSSTS2020)</a>
<span class="badge badge-info align-middle ml-1">4&nbsp;papers</span></li><li><a class=align-middle href=#2020cmlc-1>Proceedings of the 8th Workshop on Challenges in the Management of Large Corpora</a>
<span class="badge badge-info align-middle ml-1">5&nbsp;papers</span></li><li><a class=align-middle href=#2020computerm-1>Proceedings of the 6th International Workshop on Computational Terminology</a>
<span class="badge badge-info align-middle ml-1">3&nbsp;papers</span></li><li><a class=align-middle href=#2020ecnlp-1>Proceedings of The 3rd Workshop on e-Commerce and NLP</a>
<span class="badge badge-info align-middle ml-1">5&nbsp;papers</span></li><li><a class=align-middle href=#2020fever-1>Proceedings of the Third Workshop on Fact Extraction and VERification (FEVER)</a>
<span class="badge badge-info align-middle ml-1">3&nbsp;papers</span></li><li><a class=align-middle href=#2020figlang-1>Proceedings of the Second Workshop on Figurative Language Processing</a>
<span class="badge badge-info align-middle ml-1">14&nbsp;papers</span></li><li><a class=align-middle href=#2020framenet-1>Proceedings of the International FrameNet Workshop 2020: Towards a Global, Multilingual FrameNet</a>
<span class="badge badge-info align-middle ml-1">4&nbsp;papers</span></li><li><a class=align-middle href=#2020gamnlp-1>Workshop on Games and Natural Language Processing</a>
<span class="badge badge-info align-middle ml-1">7&nbsp;papers</span></li><li><a class=align-middle href=#2020globalex-1>Proceedings of the 2020 Globalex Workshop on Linked Lexicography</a>
<span class="badge badge-info align-middle ml-1">6&nbsp;papers</span></li><li><a class=align-middle href=#2020isa-1>16th Joint ACL - ISO Workshop on Interoperable Semantic Annotation PROCEEDINGS</a>
<span class="badge badge-info align-middle ml-1">2&nbsp;papers</span></li><li><a class=align-middle href=#2020iwltp-1>Proceedings of the 1st International Workshop on Language Technology Platforms</a>
<span class="badge badge-info align-middle ml-1">6&nbsp;papers</span></li><li><a class=align-middle href=#2020iwpt-1>Proceedings of the 16th International Conference on Parsing Technologies and the IWPT 2020 Shared Task on Parsing into Enhanced Universal Dependencies</a>
<span class="badge badge-info align-middle ml-1">9&nbsp;papers</span></li><li><a class=align-middle href=#2020ldl-1>Proceedings of the 7th Workshop on Linked Data in Linguistics (LDL-2020)</a>
<span class="badge badge-info align-middle ml-1">4&nbsp;papers</span></li><li><a class=align-middle href=#2020lincr-1>Proceedings of the Second Workshop on Linguistic and Neurocognitive Resources</a>
<span class="badge badge-info align-middle ml-1">5&nbsp;papers</span></li><li><a class=align-middle href=#2020lr4sshoc-1>Proceedings of the Workshop about Language Resources for the SSH Cloud</a>
<span class="badge badge-info align-middle ml-1">4&nbsp;papers</span></li><li><a class=align-middle href=#2020lt4gov-1>Proceedings of the 1st Workshop on Language Technologies for Government and Public Administration (LT4Gov)</a>
<span class="badge badge-info align-middle ml-1">2&nbsp;papers</span></li><li><a class=align-middle href=#2020lt4hala-1>Proceedings of LT4HALA 2020 - 1st Workshop on Language Technologies for Historical and Ancient Languages</a>
<span class="badge badge-info align-middle ml-1">7&nbsp;papers</span></li><li><a class=align-middle href=#2020mmw-1>Proceedings of the LREC 2020 Workshop on Multimodal Wordnets (MMW2020)</a>
<span class="badge badge-info align-middle ml-1">3&nbsp;papers</span></li><li><a class=align-middle href=#2020multilingualbio-1>Proceedings of the LREC 2020 Workshop on Multilingual Biomedical Text Processing (MultilingualBIO 2020)</a>
<span class="badge badge-info align-middle ml-1">5&nbsp;papers</span></li><li><a class=align-middle href=#2020ngt-1>Proceedings of the Fourth Workshop on Neural Generation and Translation</a>
<span class="badge badge-info align-middle ml-1">8&nbsp;papers</span></li><li><a class=align-middle href=#2020nli-1>Proceedings of the First Workshop on Natural Language Interfaces</a>
<span class="badge badge-info align-middle ml-1">3&nbsp;papers</span></li><li><a class=align-middle href=#2020nlp4convai-1>Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI</a>
<span class="badge badge-info align-middle ml-1">7&nbsp;papers</span></li><li><a class=align-middle href=#2020nlpmc-1>Proceedings of the First Workshop on Natural Language Processing for Medical Conversations</a>
<span class="badge badge-info align-middle ml-1">4&nbsp;papers</span></li><li><a class=align-middle href=#2020nuse-1>Proceedings of the First Joint Workshop on Narrative Understanding, Storylines, and Events</a>
<span class="badge badge-info align-middle ml-1">6&nbsp;papers</span></li><li><a class=align-middle href=#2020onion-1>Proceedings of LREC2020 Workshop "People in language, vision and the mind" (ONION2020)</a>
<span class="badge badge-info align-middle ml-1">3&nbsp;papers</span></li><li><a class=align-middle href=#2020osact-1>Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared Task on Offensive Language Detection</a>
<span class="badge badge-info align-middle ml-1">6&nbsp;papers</span></li><li><a class=align-middle href=#2020parlaclarin-1>Proceedings of the Second ParlaCLARIN Workshop</a>
<span class="badge badge-info align-middle ml-1">4&nbsp;papers</span></li><li><a class=align-middle href=#2020rail-1>Proceedings of the first workshop on Resources for African Indigenous Languages</a>
<span class="badge badge-info align-middle ml-1">6&nbsp;papers</span></li><li><a class=align-middle href=#2020readi-1>Proceedings of the 1st Workshop on Tools and Resources to Empower People with REAding DIfficulties (READI)</a>
<span class="badge badge-info align-middle ml-1">6&nbsp;papers</span></li><li><a class=align-middle href=#2020repl4nlp-1>Proceedings of the 5th Workshop on Representation Learning for NLP</a>
<span class="badge badge-info align-middle ml-1">10&nbsp;papers</span></li><li><a class=align-middle href=#2020restup-1>Proceedings of the Workshop on Resources and Techniques for User and Author Profiling in Abusive Language</a>
<span class="badge badge-info align-middle ml-1">3&nbsp;papers</span></li><li><a class=align-middle href=#2020sigmorphon-1>Proceedings of the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</a>
<span class="badge badge-info align-middle ml-1">7&nbsp;papers</span></li><li><a class=align-middle href=#2020signlang-1>Proceedings of the LREC2020 9th Workshop on the Representation and Processing of Sign Languages: Sign Language Resources in the Service of the Language Community, Technological Challenges and Application Perspectives</a>
<span class="badge badge-info align-middle ml-1">16&nbsp;papers</span></li><li><a class=align-middle href=#2020sltu-1>Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)</a>
<span class="badge badge-info align-middle ml-1">17&nbsp;papers</span></li><li><a class=align-middle href=#2020socialnlp-1>Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media</a>
<span class="badge badge-info align-middle ml-1">3&nbsp;papers</span></li><li><a class=align-middle href=#2020stoc-1>Proceedings for the First International Workshop on Social Threats in Online Conversations: Understanding and Management</a>
<span class="badge badge-info align-middle ml-1">3&nbsp;papers</span></li><li><a class=align-middle href=#2020trac-1>Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying</a>
<span class="badge badge-info align-middle ml-1">11&nbsp;papers</span></li><li><a class=align-middle href=#2020wac-1>Proceedings of the 12th Web as Corpus Workshop</a>
<span class="badge badge-info align-middle ml-1">3&nbsp;papers</span></li><li><a class=align-middle href=#2020wildre-1>Proceedings of the WILDRE5– 5th Workshop on Indian Language Data: Resources and Evaluation</a>
<span class="badge badge-info align-middle ml-1">4&nbsp;papers</span></li></ul></div></div><div id=2020aespen-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.aespen-1/>Proceedings of the Workshop on Automated Extraction of Socio-political Events from News 2020</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.aespen-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.aespen-1.0/>Proceedings of the Workshop on Automated Extraction of Socio-political Events from News 2020</a></strong><br><a href=/people/a/ali-hurriyetoglu/>Ali Hürriyetoğlu</a>
|
<a href=/people/e/erdem-yoruk/>Erdem Yörük</a>
|
<a href=/people/v/vanni-zavarella/>Vanni Zavarella</a>
|
<a href=/people/h/hristo-tanev/>Hristo Tanev</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.aespen-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--aespen-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.aespen-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.aespen-1.1/>Automated Extraction of Socio-political Events from News (AESPEN): Workshop and Shared Task Report<span class=acl-fixed-case>AESPEN</span>): Workshop and Shared Task Report</a></strong><br><a href=/people/a/ali-hurriyetoglu/>Ali Hürriyetoğlu</a>
|
<a href=/people/v/vanni-zavarella/>Vanni Zavarella</a>
|
<a href=/people/h/hristo-tanev/>Hristo Tanev</a>
|
<a href=/people/e/erdem-yoruk/>Erdem Yörük</a>
|
<a href=/people/a/ali-safaya/>Ali Safaya</a>
|
<a href=/people/o/osman-mutlu/>Osman Mutlu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--aespen-1--1><div class="card-body p-3 small">We describe our effort on automated extraction of socio-political events from <a href=https://en.wikipedia.org/wiki/News>news</a> in the scope of a workshop and a shared task we organized at Language Resources and Evaluation Conference (LREC 2020). We believe the event extraction studies in <a href=https://en.wikipedia.org/wiki/Computational_linguistics>computational linguistics</a> and social and political sciences should further support each other in order to enable large scale socio-political event information collection across sources, countries, and languages. The event consists of regular research papers and a shared task, which is about event sentence coreference identification (ESCI), tracks. All submissions were reviewed by five members of the program committee. The workshop attracted research papers related to evaluation of <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning methodologies</a>, language resources, material conflict forecasting, and a shared task participation report in the scope of socio-political event information collection. It has shown us the volume and variety of both the data sources and event information collection approaches related to socio-political events and the need to fill the gap between automated text processing techniques and requirements of social and political sciences.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.aespen-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--aespen-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.aespen-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.aespen-1.5/>Text Categorization for Conflict Event Annotation</a></strong><br><a href=/people/f/fredrik-olsson/>Fredrik Olsson</a>
|
<a href=/people/m/magnus-sahlgren/>Magnus Sahlgren</a>
|
<a href=/people/f/fehmi-ben-abdesslem/>Fehmi ben Abdesslem</a>
|
<a href=/people/a/ariel-ekgren/>Ariel Ekgren</a>
|
<a href=/people/k/kristine-eck/>Kristine Eck</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--aespen-1--5><div class="card-body p-3 small">We cast the problem of event annotation as one of <a href=https://en.wikipedia.org/wiki/Categorization>text categorization</a>, and compare state of the art <a href=https://en.wikipedia.org/wiki/Categorization>text categorization techniques</a> on event data produced within the Uppsala Conflict Data Program (UCDP). Annotating a single text involves assigning the labels pertaining to at least 17 distinct categorization tasks, e.g., who were the attacking organization, who was attacked, and where did the event take place. The text categorization techniques under scrutiny are a classical Bag-of-Words approach ; character-based contextualized embeddings produced by ELMo ; embeddings produced by the BERT base model, and a version of BERT base fine-tuned on UCDP data ; and a pre-trained and fine-tuned classifier based on ULMFiT. The categorization tasks are very diverse in terms of the number of classes to predict as well as the skeweness of the distribution of classes. The <a href=https://en.wikipedia.org/wiki/Categorization>categorization</a> results exhibit a large variability across tasks, ranging from 30.3 % to 99.8 % <a href=https://en.wikipedia.org/wiki/F-score>F-score</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.aespen-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--aespen-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.aespen-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.aespen-1.7/>Seeing the Forest and the Trees : Detection and Cross-Document Coreference Resolution of Militarized Interstate Disputes</a></strong><br><a href=/people/b/benjamin-radford/>Benjamin Radford</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--aespen-1--7><div class="card-body p-3 small">Previous efforts to automate the detection of social and political events in text have primarily focused on identifying events described within single sentences or documents. Within a corpus of documents, these automated systems are unable to link event referencesrecognize singular events across multiple sentences or documents. A separate literature in <a href=https://en.wikipedia.org/wiki/Computational_linguistics>computational linguistics</a> on event coreference resolution attempts to link known events to one another within (and across) documents. I provide a <a href=https://en.wikipedia.org/wiki/Data_set>data set</a> for evaluating methods to identify certain political events in text and to link related texts to one another based on shared events. The <a href=https://en.wikipedia.org/wiki/Data_set>data set</a>, Headlines of War, is built on the Militarized Interstate Disputes data set and offers headlines classified by dispute status and headline pairs labeled with coreference indicators. Additionally, I introduce a <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> capable of accomplishing both <a href=https://en.wikipedia.org/wiki/Task_(project_management)>tasks</a>. The multi-task convolutional neural network is shown to be capable of recognizing <a href=https://en.wikipedia.org/wiki/Event_(computing)>events</a> and event coreferences given the headlines&#8217; texts and publication dates.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.aespen-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--aespen-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.aespen-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.aespen-1.9/>Supervised Event Coding from Text Written in Arabic : Introducing <a href=https://en.wikipedia.org/wiki/Hadath>Hadath</a><span class=acl-fixed-case>A</span>rabic: Introducing Hadath</a></strong><br><a href=/people/j/javier-osorio/>Javier Osorio</a>
|
<a href=/people/a/alejandro-reyes/>Alejandro Reyes</a>
|
<a href=/people/a/alejandro-beltran/>Alejandro Beltrán</a>
|
<a href=/people/a/atal-ahmadzai/>Atal Ahmadzai</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--aespen-1--9><div class="card-body p-3 small">This article introduces <a href=https://en.wikipedia.org/wiki/Hadath>Hadath</a>, a <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised protocol</a> for coding event data from text written in <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a>. Hadath contributes to recent efforts in advancing multi-language event coding using <a href=https://en.wikipedia.org/wiki/Computer-aided_software_engineering>computer-based solutions</a>. In this <a href=https://en.wikipedia.org/wiki/Application_software>application</a>, we focus on extracting <a href=https://en.wikipedia.org/wiki/Event_(computing)>event data</a> about the conflict in Afghanistan from 2008 to 2018 using Arabic information sources. The <a href=https://en.wikipedia.org/wiki/Implementation>implementation</a> relies first on a <a href=https://en.wikipedia.org/wiki/Machine_learning>Machine Learning algorithm</a> to classify <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news stories</a> relevant to the <a href=https://en.wikipedia.org/wiki/War_in_Afghanistan_(2001&#8211;present)>Afghan conflict</a>. Then, using Hadath, we implement the Natural Language Processing component for <a href=https://en.wikipedia.org/wiki/Event-driven_programming>event coding</a> from <a href=https://en.wikipedia.org/wiki/Arabic_script>Arabic script</a>. The output <a href=https://en.wikipedia.org/wiki/Database>database</a> contains daily geo-referenced information at the district level on who did what to whom, when and where in the Afghan conflict. The <a href=https://en.wikipedia.org/wiki/Data>data</a> helps to identify trends in the dynamics of violence, the provision of <a href=https://en.wikipedia.org/wiki/Governance>governance</a>, and traditional <a href=https://en.wikipedia.org/wiki/Conflict_resolution>conflict resolution</a> in <a href=https://en.wikipedia.org/wiki/Afghanistan>Afghanistan</a> for different actors over time and across space.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.aespen-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--aespen-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.aespen-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.aespen-1.10/>Protest Event Analysis : A Longitudinal Analysis for Greece<span class=acl-fixed-case>G</span>reece</a></strong><br><a href=/people/k/konstantina-papanikolaou/>Konstantina Papanikolaou</a>
|
<a href=/people/h/harris-papageorgiou/>Haris Papageorgiou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--aespen-1--10><div class="card-body p-3 small">The advent of <a href=https://en.wikipedia.org/wiki/Big_data>Big Data</a> has shifted <a href=https://en.wikipedia.org/wiki/Social_science>social science research</a> towards <a href=https://en.wikipedia.org/wiki/Computational_science>computational methods</a>. The volume of data that is nowadays available has brought a radical change in traditional approaches due to the cost and effort needed for processing. Knowledge extraction from heterogeneous and ample data is not an easy task to tackle. Thus, <a href=https://en.wikipedia.org/wiki/Interdisciplinarity>interdisciplinary approaches</a> are necessary, combining experts of both social and computer science. This paper aims to present a work in the context of protest analysis, which falls into the scope of <a href=https://en.wikipedia.org/wiki/Computational_social_science>Computational Social Science</a>. More specifically, the contribution of this work is to describe a Computational Social Science methodology for Event Analysis. The presented <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> is generic in the sense that it can be applied in every event typology and moreover, it is innovative and suitable for <a href=https://en.wikipedia.org/wiki/Interdisciplinarity>interdisciplinary tasks</a> as it incorporates the <a href=https://en.wikipedia.org/wiki/Human-in-the-loop>human-in-the-loop</a>. Additionally, a <a href=https://en.wikipedia.org/wiki/Case_study>case study</a> is presented concerning Protest Analysis in Greece over the last two decades. The conceptual foundation lies mainly upon claims analysis, and <a href=https://en.wikipedia.org/wiki/Newspaper>newspaper data</a> were used in order to map, document and discuss protests in Greece in a longitudinal perspective.</div></div></div><hr><div id=2020ai4hi-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.ai4hi-1/>Proceedings of the 1st International Workshop on Artificial Intelligence for Historical Image Enrichment and Access</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ai4hi-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.ai4hi-1.0/>Proceedings of the 1st International Workshop on Artificial Intelligence for Historical Image Enrichment and Access</a></strong><br><a href=/people/y/yalemisew-abgaz/>Yalemisew Abgaz</a>
|
<a href=/people/a/amelie-dorn/>Amelie Dorn</a>
|
<a href=/people/j/jose-luis-preza-diaz/>Jose Luis Preza Diaz</a>
|
<a href=/people/g/gerda-koch/>Gerda Koch</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ai4hi-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ai4hi-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ai4hi-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.ai4hi-1.3/>Toward the Automatic Retrieval and Annotation of Outsider Art images : A Preliminary Statement</a></strong><br><a href=/people/j/john-roberto/>John Roberto</a>
|
<a href=/people/d/diego-ortego/>Diego Ortego</a>
|
<a href=/people/b/brian-davis/>Brian Davis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ai4hi-1--3><div class="card-body p-3 small">The aim of this position paper is to establish an initial approach to the automatic classification of digital images about the <a href=https://en.wikipedia.org/wiki/Outsider_art>Outsider Art style of painting</a>. Specifically, we explore whether is it possible to classify non-traditional artistic styles by using the same features that are used for classifying traditional styles? Our research question is motivated by two facts. First, art historians state that non-traditional styles are influenced by factors outside of the world of art. Second, some studies have shown that several <a href=https://en.wikipedia.org/wiki/Style_(visual_arts)>artistic styles</a> confound certain classification techniques. Following current approaches to style prediction, this paper utilises Deep Learning methods to encode <a href=https://en.wikipedia.org/wiki/Feature_(computer_vision)>image features</a>. Our preliminary experiments have provided motivation to think that, as is the case with traditional styles, <a href=https://en.wikipedia.org/wiki/Outsider_art>Outsider Art</a> can be computationally modelled with objective means by using <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training datasets</a> and CNN models. Nevertheless, our results are not conclusive due to the lack of a large available dataset on <a href=https://en.wikipedia.org/wiki/Outsider_art>Outsider Art</a>. Therefore, at the end of the paper, we have mapped future lines of action, which include the compilation of a large dataset of Outsider Art images and the creation of an ontology of Outsider Art.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ai4hi-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ai4hi-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ai4hi-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.ai4hi-1.5/>Towards a Comprehensive Assessment of the Quality and Richness of the Europeana Metadata of food-related Images</a></strong><br><a href=/people/y/yalemisew-abgaz/>Yalemisew Abgaz</a>
|
<a href=/people/a/amelie-dorn/>Amelie Dorn</a>
|
<a href=/people/j/jose-luis-preza-diaz/>Jose Luis Preza Diaz</a>
|
<a href=/people/g/gerda-koch/>Gerda Koch</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ai4hi-1--5><div class="card-body p-3 small">Semantic enrichment of historical images to build interactive AI systems for the Digital Humanities domain has recently gained significant attention. However, before implementing any semantic enrichment tool for building <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>AI systems</a>, it is also crucial to analyse the quality and richness of the existing datasets and understand the areas where semantic enrichment is most required. Here, we propose an approach to conducting a preliminary analysis of selected historical images from the Europeana platform using existing linked data quality assessment tools. The analysis targets food images by collecting <a href=https://en.wikipedia.org/wiki/Metadata>metadata</a> provided from curators such as Galleries, Libraries, Archives and Museums (GLAMs) and cultural aggregators such as <a href=https://en.wikipedia.org/wiki/Europeana>Europeana</a>. We identified <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> to evaluate the quality of the <a href=https://en.wikipedia.org/wiki/Metadata>metadata</a> associated with food-related images which are harvested from the Europeana platform. In this paper, we present the food-image dataset, the associated <a href=https://en.wikipedia.org/wiki/Metadata>metadata</a> and our proposed method for the assessment. The results of our assessment will be used to guide the current effort to semantically enrich the <a href=https://en.wikipedia.org/wiki/Digital_image>images</a> and build high-quality metadata using <a href=https://en.wikipedia.org/wiki/Computer_vision>Computer Vision</a>.</div></div></div><hr><div id=2020alvr-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.alvr-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.alvr-1/>Proceedings of the First Workshop on Advances in Language and Vision Research</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.alvr-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.alvr-1.0/>Proceedings of the First Workshop on Advances in Language and Vision Research</a></strong><br><a href=/people/x/xin-wang/>Xin Wang</a>
|
<a href=/people/j/jesse-thomason/>Jesse Thomason</a>
|
<a href=/people/r/ronghang-hu/>Ronghang Hu</a>
|
<a href=/people/x/xinlei-chen/>Xinlei Chen</a>
|
<a href=/people/p/peter-anderson/>Peter Anderson</a>
|
<a href=/people/q/qi-wu/>Qi Wu</a>
|
<a href=/people/a/asli-celikyilmaz/>Asli Celikyilmaz</a>
|
<a href=/people/j/jason-baldridge/>Jason Baldridge</a>
|
<a href=/people/w/william-yang-wang/>William Yang Wang</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.alvr-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--alvr-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.alvr-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929760 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.alvr-1.3" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.alvr-1.3/>Visual Question Generation from Radiology Images</a></strong><br><a href=/people/m/mourad-sarrouti/>Mourad Sarrouti</a>
|
<a href=/people/a/asma-ben-abacha/>Asma Ben Abacha</a>
|
<a href=/people/d/dina-demner-fushman/>Dina Demner-Fushman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--alvr-1--3><div class="card-body p-3 small">Visual Question Generation (VQG), the task of generating a question based on image contents, is an increasingly important area that combines <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> and <a href=https://en.wikipedia.org/wiki/Computer_vision>computer vision</a>. Although there are some recent works that have attempted to generate questions from images in the <a href=https://en.wikipedia.org/wiki/Open_domain>open domain</a>, the task of VQG in the <a href=https://en.wikipedia.org/wiki/Medical_imaging>medical domain</a> has not been explored so far. In this paper, we introduce an approach to generation of visual questions about radiology images called VQGR, i.e. an <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> that is able to ask a question when shown an image. VQGR first generates new training data from the existing examples, based on contextual word embeddings and image augmentation techniques. It then uses the variational auto-encoders model to encode images into a latent space and decode natural language questions. Experimental automatic evaluations performed on the VQA-RAD dataset of clinical visual questions show that VQGR achieves good performances compared with the baseline system. The source code is available at https://github.com/sarrouti/vqgr.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.alvr-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--alvr-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.alvr-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.alvr-1.4/>On the role of effective and referring questions in GuessWhat? !<span class=acl-fixed-case>G</span>uess<span class=acl-fixed-case>W</span>hat?!</a></strong><br><a href=/people/m/mauricio-mazuecos/>Mauricio Mazuecos</a>
|
<a href=/people/a/alberto-testoni/>Alberto Testoni</a>
|
<a href=/people/r/raffaella-bernardi/>Raffaella Bernardi</a>
|
<a href=/people/l/luciana-benotti/>Luciana Benotti</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--alvr-1--4><div class="card-body p-3 small">Task success is the standard <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> used to evaluate referential visual dialogue systems. In this paper we propose two new <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> that evaluate how each question contributes to the goal. First, we measure how effective each question is by evaluating whether the question discards objects that are not the referent. Second, we define referring questions as those that univocally identify one object in the image. We report the new <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> for human dialogues and for state of the art publicly available <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on GuessWhat? !. Regarding our first <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a>, we find that successful dialogues do not have a higher percentage of effective questions for most <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. With respect to the second <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a>, humans make questions at the end of the dialogue that are referring, confirming their guess before guessing. Human dialogues that use this <a href=https://en.wikipedia.org/wiki/Strategy>strategy</a> have a higher task success but models do not seem to learn it.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.alvr-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--alvr-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.alvr-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929759 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.alvr-1.5" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.alvr-1.5/>Latent Alignment of Procedural Concepts in Multimodal Recipes</a></strong><br><a href=/people/h/hossein-rajaby-faghihi/>Hossein Rajaby Faghihi</a>
|
<a href=/people/r/roshanak-mirzaee/>Roshanak Mirzaee</a>
|
<a href=/people/s/sudarshan-paliwal/>Sudarshan Paliwal</a>
|
<a href=/people/p/parisa-kordjamshidi/>Parisa Kordjamshidi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--alvr-1--5><div class="card-body p-3 small">We propose a novel alignment mechanism to deal with procedural reasoning on a newly released multimodal QA dataset, named RecipeQA. Our model is solving the textual cloze task which is a <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a> on a <a href=https://en.wikipedia.org/wiki/Recipe>recipe</a> containing images and instructions. We exploit the power of attention networks, cross-modal representations, and a latent alignment space between instructions and candidate answers to solve the problem. We introduce constrained max-pooling which refines the max pooling operation on the alignment matrix to impose disjoint constraints among the outputs of the model. Our evaluation result indicates a 19 % improvement over the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a>.</div></div></div><hr><div id=2020autosimtrans-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.autosimtrans-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.autosimtrans-1/>Proceedings of the First Workshop on Automatic Simultaneous Translation</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.autosimtrans-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.autosimtrans-1.0/>Proceedings of the First Workshop on Automatic Simultaneous Translation</a></strong><br><a href=/people/h/hua-wu/>Hua Wu</a>
|
<a href=/people/c/collin-cherry/>Collin Cherry</a>
|
<a href=/people/l/liang-huang/>Liang Huang</a>
|
<a href=/people/z/zhongjun-he/>Zhongjun He</a>
|
<a href=/people/m/mark-liberman/>Mark Liberman</a>
|
<a href=/people/j/james-cross/>James Cross</a>
|
<a href=/people/y/yang-liu-ict/>Yang Liu</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.autosimtrans-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--autosimtrans-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.autosimtrans-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929921 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.autosimtrans-1.5/>Modeling Discourse Structure for Document-level Neural Machine Translation</a></strong><br><a href=/people/j/junxuan-chen/>Junxuan Chen</a>
|
<a href=/people/x/xiang-li/>Xiang Li</a>
|
<a href=/people/j/jiarui-zhang/>Jiarui Zhang</a>
|
<a href=/people/c/chulun-zhou/>Chulun Zhou</a>
|
<a href=/people/j/jianwei-cui/>Jianwei Cui</a>
|
<a href=/people/b/bin-wang/>Bin Wang</a>
|
<a href=/people/j/jinsong-su/>Jinsong Su</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--autosimtrans-1--5><div class="card-body p-3 small">Recently, document-level neural machine translation (NMT) has become a hot topic in the community of <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>. Despite its success, most of existing studies ignored the discourse structure information of the input document to be translated, which has shown effective in other tasks. In this paper, we propose to improve document-level NMT with the aid of discourse structure information. Our <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> is based on a hierarchical attention network (HAN) (Miculicich et al., 2018). Specifically, we first parse the input document to obtain its discourse structure. Then, we introduce a Transformer-based path encoder to embed the discourse structure information of each word. Finally, we combine the discourse structure information with the <a href=https://en.wikipedia.org/wiki/Word_embedding>word embedding</a> before it is fed into the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a>. Experimental results on the English-to-German dataset show that our model can significantly outperform both Transformer and Transformer+HAN.</div></div></div><hr><div id=2020bea-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.bea-1/>Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bea-1.0/>Proceedings of the Fifteenth Workshop on Innovative Use of NLP for Building Educational Applications</a></strong><br><a href=/people/j/jill-burstein/>Jill Burstein</a>
|
<a href=/people/e/ekaterina-kochmar/>Ekaterina Kochmar</a>
|
<a href=/people/c/claudia-leacock/>Claudia Leacock</a>
|
<a href=/people/n/nitin-madnani/>Nitin Madnani</a>
|
<a href=/people/i/ildiko-pilan/>Ildikó Pilán</a>
|
<a href=/people/h/helen-yannakoudakis/>Helen Yannakoudakis</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bea-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bea-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bea-1.4/>Complementary Systems for Off-Topic Spoken Response Detection</a></strong><br><a href=/people/v/vatsal-raina/>Vatsal Raina</a>
|
<a href=/people/m/mark-gales/>Mark Gales</a>
|
<a href=/people/k/kate-knill/>Kate Knill</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bea-1--4><div class="card-body p-3 small">Increased demand to learn English for business and education has led to growing interest in automatic spoken language assessment and teaching systems. With this shift to automated approaches it is important that systems reliably assess all aspects of a candidate&#8217;s responses. This paper examines one form of spoken language assessment ; whether the response from the candidate is relevant to the prompt provided. This will be referred to as off-topic spoken response detection. Two forms of previously proposed approaches are examined in this work : the hierarchical attention-based topic model (HATM) ; and the similarity grid model (SGM). The work focuses on the scenario when the prompt, and associated responses, have not been seen in the training data, enabling the <a href=https://en.wikipedia.org/wiki/System>system</a> to be applied to new test scripts without the need to collect data or retrain the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>. To improve the performance of the systems for unseen prompts, <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a> based on easy data augmentation (EDA) and translation based approaches are applied. Additionally for the HATM, a form of prompt dropout is described. The <a href=https://en.wikipedia.org/wiki/System>systems</a> were evaluated on both seen and unseen prompts from Linguaskill Business and General English tests. For unseen data the performance of the HATM was improved using <a href=https://en.wikipedia.org/wiki/Data_augmentation>data augmentation</a>, in contrast to the <a href=https://en.wikipedia.org/wiki/SGM>SGM</a> where no gains were obtained. The two <a href=https://en.wikipedia.org/wiki/Computer_simulation>approaches</a> were found to be complementary to one another, yielding a combined <a href=https://en.wikipedia.org/wiki/F-number>F0.5 score</a> of 0.814 for off-topic response detection where the prompts have not been seen in training.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bea-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bea-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bea-1.5/>CIMA : A Large Open Access Dialogue Dataset for Tutoring<span class=acl-fixed-case>CIMA</span>: A Large Open Access Dialogue Dataset for Tutoring</a></strong><br><a href=/people/k/katherine-stasaski/>Katherine Stasaski</a>
|
<a href=/people/k/kimberly-kao/>Kimberly Kao</a>
|
<a href=/people/m/marti-a-hearst/>Marti A. Hearst</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bea-1--5><div class="card-body p-3 small">One-to-one tutoring is often an effective means to help students learn, and recent experiments with neural conversation systems are promising. However, large open datasets of tutoring conversations are lacking. To remedy this, we propose a novel asynchronous method for collecting tutoring dialogue via crowdworkers that is both amenable to the needs of deep learning algorithms and reflective of pedagogical concerns. In this approach, extended conversations are obtained between crowdworkers role-playing as both students and tutors. The CIMA collection, which we make publicly available, is novel in that students are exposed to overlapping grounded concepts between exercises and multiple relevant tutoring responses are collected for the same input. CIMA contains several compelling properties from an educational perspective : student role-players complete exercises in fewer turns during the course of the conversation and tutor players adopt strategies that conform with some educational conversational norms, such as providing hints versus asking questions in appropriate contexts. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> enables a <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> to be trained to generate the next tutoring utterance in a conversation, conditioned on a provided action strategy.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bea-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bea-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.bea-1.6.Dataset.pdf data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.bea-1.6/>Becoming Linguistically Mature : Modeling English and German Children’s Writing Development Across School Grades<span class=acl-fixed-case>E</span>nglish and <span class=acl-fixed-case>G</span>erman Children’s Writing Development Across School Grades</a></strong><br><a href=/people/e/elma-kerz/>Elma Kerz</a>
|
<a href=/people/y/yu-qiao/>Yu Qiao</a>
|
<a href=/people/d/daniel-wiechmann/>Daniel Wiechmann</a>
|
<a href=/people/m/marcus-strobel/>Marcus Ströbel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bea-1--6><div class="card-body p-3 small">In this paper we employ a novel approach to advancing our understanding of the development of writing in English and German children across school grades using classification tasks. The <a href=https://en.wikipedia.org/wiki/Data>data</a> used come from two recently compiled corpora : The English data come from the the GiC corpus (983 school children in second-, sixth-, ninth- and eleventh-grade) and the German data are from the FD-LEX corpus (930 school children in fifth- and ninth-grade). The key to this paper is the combined use of what we refer to as &#8216;complexity contours&#8217;, i.e. series of measurements that capture the progression of linguistic complexity within a text, and Recurrent Neural Network (RNN) classifiers that adequately capture the sequential information in those contours. Our experiments demonstrate that RNN classifiers trained on complexity contours achieve higher classification accuracy than one trained on text-average complexity scores. In a second step, we determine the relative importance of the <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> from four distinct categories through a Sensitivity-Based Pruning approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.8.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bea-1--8 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bea-1.8 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bea-1.8/>Can <a href=https://en.wikipedia.org/wiki/Neural_network>Neural Networks</a> Automatically Score Essay Traits?</a></strong><br><a href=/people/s/sandeep-mathias/>Sandeep Mathias</a>
|
<a href=/people/p/pushpak-bhattacharyya/>Pushpak Bhattacharyya</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bea-1--8><div class="card-body p-3 small">Essay traits are attributes of an essay that can help explain how well written (or badly written) the essay is. Examples of traits include <a href=https://en.wikipedia.org/wiki/Content_(media)>Content</a>, Organization, <a href=https://en.wikipedia.org/wiki/Language>Language</a>, Sentence Fluency, <a href=https://en.wikipedia.org/wiki/Word_choice>Word Choice</a>, etc. A lot of research in the last decade has dealt with automatic holistic essay scoring-where a machine rates an essay and gives a score for the essay. However, writers need feedback, especially if they want to improve their writing-which is why trait-scoring is important. In this paper, we show how a <a href=https://en.wikipedia.org/wiki/Deep_learning>deep-learning based system</a> can outperform feature-based machine learning systems, as well as a string kernel system in scoring <a href=https://en.wikipedia.org/wiki/Essay>essay traits</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bea-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bea-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bea-1.12/>Applications of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a> in Bilingual Language Teaching : An Indonesian-English Case Study<span class=acl-fixed-case>I</span>ndonesian-<span class=acl-fixed-case>E</span>nglish Case Study</a></strong><br><a href=/people/z/zara-maxwelll-smith/>Zara Maxwelll-Smith</a>
|
<a href=/people/s/simon-gonzalez-ochoa/>Simón González Ochoa</a>
|
<a href=/people/b/ben-foley/>Ben Foley</a>
|
<a href=/people/h/hanna-suominen/>Hanna Suominen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bea-1--12><div class="card-body p-3 small">Multilingual corpora are difficult to compile and a classroom setting adds pedagogy to the mix of factors which make this <a href=https://en.wikipedia.org/wiki/Data>data</a> so rich and problematic to classify. In this paper, we set out methodological considerations of using <a href=https://en.wikipedia.org/wiki/Speech_recognition>automated speech recognition</a> to build a <a href=https://en.wikipedia.org/wiki/Speech_corpus>corpus of teacher speech</a> in an Indonesian language classroom. Our preliminary results (64 % word error rate) suggest these tools have the potential to speed <a href=https://en.wikipedia.org/wiki/Data_collection>data collection</a> in this context. We provide practical examples of our data structure, details of our piloted computer-assisted processes, and fine-grained error analysis. Our study is informed and directed by genuine research questions and discussion in both the education and computational linguistics fields. We highlight some of the benefits and risks of using these emerging <a href=https://en.wikipedia.org/wiki/Technology>technologies</a> to analyze the complex work of <a href=https://en.wikipedia.org/wiki/Language_education>language teachers</a> and in <a href=https://en.wikipedia.org/wiki/Education>education</a> more generally.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bea-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bea-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bea-1.13/>An empirical investigation of neural methods for content scoring of science explanations</a></strong><br><a href=/people/b/brian-riordan/>Brian Riordan</a>
|
<a href=/people/s/sarah-bichler/>Sarah Bichler</a>
|
<a href=/people/a/allison-bradford/>Allison Bradford</a>
|
<a href=/people/j/jennifer-king-chen/>Jennifer King Chen</a>
|
<a href=/people/k/korah-wiley/>Korah Wiley</a>
|
<a href=/people/l/libby-gerard/>Libby Gerard</a>
|
<a href=/people/m/marcia-c-linn/>Marcia C. Linn</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bea-1--13><div class="card-body p-3 small">With the widespread adoption of the Next Generation Science Standards (NGSS), science teachers and online learning environments face the challenge of evaluating students&#8217; integration of different dimensions of <a href=https://en.wikipedia.org/wiki/Science_education>science learning</a>. Recent advances in representation learning in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> have proven effective across many <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing tasks</a>, but a rigorous evaluation of the relative merits of these methods for scoring complex constructed response formative assessments has not previously been carried out. We present a detailed empirical investigation of feature-based, recurrent neural network, and pre-trained transformer models on scoring content in real-world formative assessment data. We demonstrate that recent <a href=https://en.wikipedia.org/wiki/Artificial_neural_network>neural methods</a> can rival or exceed the performance of feature-based methods. We also provide evidence that different classes of neural models take advantage of different learning cues, and pre-trained transformer models may be more robust to spurious, dataset-specific learning cues, better reflecting scoring rubrics.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bea-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bea-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.bea-1.16" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.bea-1.16/>GECToR Grammatical Error Correction : Tag, Not Rewrite<span class=acl-fixed-case>GECT</span>o<span class=acl-fixed-case>R</span> – Grammatical Error Correction: Tag, Not Rewrite</a></strong><br><a href=/people/k/kostiantyn-omelianchuk/>Kostiantyn Omelianchuk</a>
|
<a href=/people/v/vitaliy-atrasevych/>Vitaliy Atrasevych</a>
|
<a href=/people/a/artem-chernodub/>Artem Chernodub</a>
|
<a href=/people/o/oleksandr-skurzhanskyi/>Oleksandr Skurzhanskyi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bea-1--16><div class="card-body p-3 small">In this paper, we present a simple and efficient GEC sequence tagger using a Transformer encoder. Our system is pre-trained on synthetic data and then fine-tuned in two stages : first on errorful corpora, and second on a combination of errorful and error-free parallel corpora. We design custom token-level transformations to map input tokens to target corrections. Our best single-model / ensemble GEC tagger achieves an F_0.5 of 65.3/66.5 on CONLL-2014 (test) and F_0.5 of 72.4/73.6 on BEA-2019 (test). Its inference speed is up to 10 times as fast as a Transformer-based seq2seq GEC system.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bea-1--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bea-1.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.bea-1.17.Dataset.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.bea-1.17/>Interpreting Neural CWI Classifiers’ Weights as Vocabulary Size<span class=acl-fixed-case>CWI</span> Classifiers’ Weights as Vocabulary Size</a></strong><br><a href=/people/y/yo-ehara/>Yo Ehara</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bea-1--17><div class="card-body p-3 small">Complex Word Identification (CWI) is a task for the identification of words that are challenging for <a href=https://en.wikipedia.org/wiki/Second-language_acquisition>second-language learners</a> to read. Even though the use of neural classifiers is now common in CWI, the interpretation of their parameters remains difficult. This paper analyzes neural CWI classifiers and shows that some of their parameters can be interpreted as <a href=https://en.wikipedia.org/wiki/Vocabulary_size>vocabulary size</a>. We present a novel formalization of vocabulary size measurement methods that are practiced in the applied linguistics field as a kind of neural classifier. We also contribute to building a novel <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> for validating vocabulary testing and readability via <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bea-1.20.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bea-1--20 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bea-1.20 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bea-1.20/>Predicting the Difficulty and Response Time of Multiple Choice Questions Using Transfer Learning</a></strong><br><a href=/people/k/kang-xue/>Kang Xue</a>
|
<a href=/people/v/victoria-yaneva/>Victoria Yaneva</a>
|
<a href=/people/c/christopher-runyon/>Christopher Runyon</a>
|
<a href=/people/p/peter-baldwin/>Peter Baldwin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bea-1--20><div class="card-body p-3 small">This paper investigates whether <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> can improve the prediction of the difficulty and response time parameters for 18,000 multiple-choice questions from a high-stakes medical exam. The type the signal that best predicts difficulty and <a href=https://en.wikipedia.org/wiki/Response_time_(technology)>response time</a> is also explored, both in terms of <a href=https://en.wikipedia.org/wiki/Abstraction_(computer_science)>representation abstraction</a> and item component used as input (e.g., whole item, answer options only, etc.). The results indicate that, for our sample, <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> can improve the prediction of item difficulty when <a href=https://en.wikipedia.org/wiki/Mental_chronometry>response time</a> is used as an auxiliary task but not the other way around. In addition, difficulty was best predicted using signal from the item stem (the description of the clinical case), while all parts of the item were important for predicting the response time.</div></div></div><hr><div id=2020bionlp-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bionlp-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.bionlp-1/>Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bionlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bionlp-1.0/>Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing</a></strong><br><a href=/people/d/dina-demner-fushman/>Dina Demner-Fushman</a>
|
<a href=/people/k/k-bretonnel-cohen/>Kevin Bretonnel Cohen</a>
|
<a href=/people/s/sophia-ananiadou/>Sophia Ananiadou</a>
|
<a href=/people/j/junichi-tsujii/>Junichi Tsujii</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bionlp-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bionlp-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bionlp-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929643 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.bionlp-1.3/>Interactive Extractive Search over Biomedical Corpora</a></strong><br><a href=/people/h/hillel-taub-tabib/>Hillel Taub Tabib</a>
|
<a href=/people/m/micah-shlain/>Micah Shlain</a>
|
<a href=/people/s/shoval-sadde/>Shoval Sadde</a>
|
<a href=/people/d/dan-lahav/>Dan Lahav</a>
|
<a href=/people/m/matan-eyal/>Matan Eyal</a>
|
<a href=/people/y/yaara-cohen/>Yaara Cohen</a>
|
<a href=/people/y/yoav-goldberg/>Yoav Goldberg</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bionlp-1--3><div class="card-body p-3 small">We present a system that allows life-science researchers to search a linguistically annotated corpus of scientific texts using patterns over dependency graphs, as well as using patterns over token sequences and a powerful variant of boolean keyword queries. In contrast to previous attempts to dependency-based search, we introduce a light-weight query language that does not require the user to know the details of the underlying linguistic representations, and instead to query the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> by providing an example sentence coupled with simple markup. Search is performed at an interactive speed due to efficient linguistic graph-indexing and retrieval engine. This allows for rapid exploration, development and refinement of <a href=https://en.wikipedia.org/wiki/User_(computing)>user queries</a>. We demonstrate the system using example workflows over two <a href=https://en.wikipedia.org/wiki/Corpus_linguistics>corpora</a> : the PubMed corpus including 14,446,243 PubMed abstracts and the CORD-19 dataset, a collection of over 45,000 research papers focused on COVID-19 research. The <a href=https://en.wikipedia.org/wiki/System>system</a> is publicly available at https://allenai.github.io/spike</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bionlp-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bionlp-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bionlp-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bionlp-1.4/>Improving Biomedical Analogical Retrieval with Embedding of Structural Dependencies</a></strong><br><a href=/people/a/amandalynne-paullada/>Amandalynne Paullada</a>
|
<a href=/people/b/bethany-percha/>Bethany Percha</a>
|
<a href=/people/t/trevor-cohen/>Trevor Cohen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bionlp-1--4><div class="card-body p-3 small">Inferring the nature of the relationships between biomedical entities from <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>text</a> is an important problem due to the difficulty of maintaining human-curated knowledge bases in rapidly evolving fields. Neural word embeddings have earned attention for an apparent ability to encode relational information. However, word embedding models that disregard <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a> during training are limited in their ability to encode the structural relationships fundamental to <a href=https://en.wikipedia.org/wiki/Analogy>cognitive theories of analogy</a>. In this paper, we demonstrate the utility of encoding dependency structure in word embeddings in a model we call Embedding of Structural Dependencies (ESD) as a way to represent biomedical relationships in two analogical retrieval tasks : a relationship retrieval (RR) task, and a literature-based discovery (LBD) task meant to hypothesize plausible relationships between pairs of entities unseen in training. We compare our model to skip-gram with negative sampling (SGNS), using 19 databases of biomedical relationships as our evaluation data, with improvements in performance on 17 (LBD) and 18 (RR) of these sets. These results suggest embeddings encoding dependency path information are of value for biomedical analogy retrieval.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bionlp-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bionlp-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bionlp-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bionlp-1.7/>A BERT-based One-Pass Multi-Task Model for Clinical Temporal Relation Extraction<span class=acl-fixed-case>BERT</span>-based One-Pass Multi-Task Model for Clinical Temporal Relation Extraction</a></strong><br><a href=/people/c/chen-lin/>Chen Lin</a>
|
<a href=/people/t/timothy-miller/>Timothy Miller</a>
|
<a href=/people/d/dmitriy-dligach/>Dmitriy Dligach</a>
|
<a href=/people/f/farig-sadeque/>Farig Sadeque</a>
|
<a href=/people/s/steven-bethard/>Steven Bethard</a>
|
<a href=/people/g/guergana-savova/>Guergana Savova</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bionlp-1--7><div class="card-body p-3 small">Recently BERT has achieved a state-of-the-art performance in temporal relation extraction from clinical Electronic Medical Records text. However, the current approach is inefficient as <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> requires multiple passes through each input sequence. We extend a recently-proposed one-pass model for relation classification to a one-pass model for relation extraction. We augment this framework by introducing global embeddings to help with long-distance relation inference, and by <a href=https://en.wikipedia.org/wiki/Multi-task_learning>multi-task learning</a> to increase model performance and generalizability. Our proposed model produces results on par with the state-of-the-art in temporal relation extraction on the THYME corpus and is much greener in <a href=https://en.wikipedia.org/wiki/Computational_cost>computational cost</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bionlp-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bionlp-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bionlp-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bionlp-1.16/>Neural Transduction of Letter Position Dyslexia using an Anagram Matrix Representation</a></strong><br><a href=/people/a/avi-bleiweiss/>Avi Bleiweiss</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bionlp-1--16><div class="card-body p-3 small">Research on analyzing reading patterns of dyslectic children has mainly been driven by classifying dyslexia types offline. We contend that a framework to remedy reading errors inline is more far-reaching and will help to further advance our understanding of this impairment. In this paper, we propose a simple and intuitive neural model to reinstate migrating words that transpire in letter position dyslexia, a visual analysis deficit to the encoding of character order within a word. Introduced by the anagram matrix representation of an input verse, the novelty of our work lies in the expansion from one to a two dimensional context window for training. This warrants words that only differ in the disposition of letters to remain interpreted semantically similar in the <a href=https://en.wikipedia.org/wiki/Embedding>embedding space</a>. Subject to the apparent constraints of the self-attention transformer architecture, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieved a unigram BLEU score of 40.6 on our reconstructed dataset of the <a href=https://en.wikipedia.org/wiki/Shakespeare&#8217;s_sonnets>Shakespeare sonnets</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bionlp-1.19.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bionlp-1--19 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bionlp-1.19 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.bionlp-1.19" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.bionlp-1.19/>Extensive Error Analysis and a Learning-Based Evaluation of Medical Entity Recognition Systems to Approximate User Experience</a></strong><br><a href=/people/i/isar-nejadgholi/>Isar Nejadgholi</a>
|
<a href=/people/k/kathleen-c-fraser/>Kathleen C. Fraser</a>
|
<a href=/people/b/berry-de-bruijn/>Berry de Bruijn</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bionlp-1--19><div class="card-body p-3 small">When comparing entities extracted by a medical entity recognition system with gold standard annotations over a test set, two types of mismatches might occur, label mismatch or span mismatch. Here we focus on span mismatch and show that its severity can vary from a serious error to a fully acceptable entity extraction due to the subjectivity of span annotations. For a domain-specific BERT-based NER system, we showed that 25 % of the errors have the same labels and overlapping span with gold standard entities. We collected expert judgement which shows more than 90 % of these mismatches are accepted or partially accepted by the user. Using the training set of the NER system, we built a fast and lightweight <a href=https://en.wikipedia.org/wiki/Entity&#8211;relationship_model>entity classifier</a> to approximate the <a href=https://en.wikipedia.org/wiki/User_experience>user experience</a> of such mismatches through accepting or rejecting them. The decisions made by this <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> are used to calculate a learning-based F-score which is shown to be a better approximation of a forgiving user&#8217;s experience than the relaxed F-score. We demonstrated the results of applying the proposed evaluation metric for a variety of deep learning medical entity recognition models trained with two datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bionlp-1.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bionlp-1--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bionlp-1.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bionlp-1.21/>Global Locality in Biomedical Relation and Event Extraction</a></strong><br><a href=/people/e/elaheh-shafieibavani/>Elaheh ShafieiBavani</a>
|
<a href=/people/a/antonio-jimeno-yepes/>Antonio Jimeno Yepes</a>
|
<a href=/people/x/xu-zhong/>Xu Zhong</a>
|
<a href=/people/d/david-martinez-iraola/>David Martinez Iraola</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bionlp-1--21><div class="card-body p-3 small">Due to the exponential growth of <a href=https://en.wikipedia.org/wiki/Medical_literature>biomedical literature</a>, event and relation extraction are important tasks in <a href=https://en.wikipedia.org/wiki/Biomedical_text_mining>biomedical text mining</a>. Most work only focus on relation extraction, and detect a single entity pair mention on a short span of text, which is not ideal due to long sentences that appear in biomedical contexts. We propose an approach to both relation and event extraction, for simultaneously predicting relationships between all mention pairs in a text. We also perform an empirical study to discuss different network setups for this purpose. The best performing model includes a set of multi-head attentions and convolutions, an adaptation of the transformer architecture, which offers self-attention the ability to strengthen dependencies among related elements, and models the interaction between features extracted by multiple attention heads. Experiment results demonstrate that our approach outperforms the state of the art on a set of benchmark biomedical corpora including BioNLP 2009, 2011, 2013 and BioCreative 2017 shared tasks.</div></div></div><hr><div id=2020bucc-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.bucc-1/>Proceedings of the 13th Workshop on Building and Using Comparable Corpora</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bucc-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bucc-1.0/>Proceedings of the 13th Workshop on Building and Using Comparable Corpora</a></strong><br><a href=/people/r/reinhard-rapp/>Reinhard Rapp</a>
|
<a href=/people/p/pierre-zweigenbaum/>Pierre Zweigenbaum</a>
|
<a href=/people/s/serge-sharoff/>Serge Sharoff</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bucc-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bucc-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bucc-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bucc-1.3/>Constructing a Bilingual Corpus of Parallel Tweets</a></strong><br><a href=/people/h/hamdy-mubarak/>Hamdy Mubarak</a>
|
<a href=/people/s/sabit-hassan/>Sabit Hassan</a>
|
<a href=/people/a/ahmed-abdelali/>Ahmed Abdelali</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bucc-1--3><div class="card-body p-3 small">In a bid to reach a larger and more diverse audience, Twitter users often post parallel tweetstweets that contain the same content but are written in different languages. Parallel tweets can be an important resource for developing <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation (MT) systems</a> among other <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing (NLP) tasks</a>. In this paper, we introduce a generic <a href=https://en.wikipedia.org/wiki/Methodology>method</a> for collecting parallel tweets. Using this method, we collect a bilingual corpus of English-Arabic parallel tweets and a list of Twitter accounts who post English-Arabictweets regularly. Since our method is generic, it can also be used for collecting parallel tweets that cover less-resourced languages such as <a href=https://en.wikipedia.org/wiki/Serbian_language>Serbian</a> and <a href=https://en.wikipedia.org/wiki/Urdu>Urdu</a>. Additionally, we annotate a subset of Twitter accounts with their countries of origin and topic of interest, which provides insights about the population who post parallel tweets. This latter information can also be useful for author profiling tasks.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bucc-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bucc-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bucc-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bucc-1.4/>Automatic Creation of Correspondence Table of Meaning Tags from Two Dictionaries in One Language Using Bilingual Word Embedding</a></strong><br><a href=/people/t/teruo-hirabayashi/>Teruo Hirabayashi</a>
|
<a href=/people/k/kanako-komiya/>Kanako Komiya</a>
|
<a href=/people/m/masayuki-asahara/>Masayuki Asahara</a>
|
<a href=/people/h/hiroyuki-shinnou/>Hiroyuki Shinnou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bucc-1--4><div class="card-body p-3 small">In this paper, we show how to use bilingual word embeddings (BWE) to automatically create a corresponding table of meaning tags from two dictionaries in one language and examine the effectiveness of the method. To do this, we had a problem : the meaning tags do not always correspond one-to-one because the granularities of the <a href=https://en.wikipedia.org/wiki/Word_sense>word senses</a> and the <a href=https://en.wikipedia.org/wiki/Concept>concepts</a> are different from each other. Therefore, we regarded the concept tag that corresponds to a <a href=https://en.wikipedia.org/wiki/Word_sense>word sense</a> the most as the correct concept tag corresponding the <a href=https://en.wikipedia.org/wiki/Word_sense>word sense</a>. We used two BWE methods, a <a href=https://en.wikipedia.org/wiki/Linear_map>linear transformation matrix</a> and VecMap. We evaluated the most frequent sense (MFS) method and the corpus concatenation method for comparison. The accuracies of the proposed methods were higher than the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of the random baseline but lower than those of the MFS and corpus concatenation methods. However, because our method utilized the embedding vectors of the word senses, the relations of the sense tags corresponding to concept tags could be examined by mapping the sense embeddings to the vector space of the concept tags. Also, our methods could be performed when we have only concept or word sense embeddings whereas the MFS method requires a <a href=https://en.wikipedia.org/wiki/Parallel_corpus>parallel corpus</a> and the corpus concatenation method needs two tagged corpora.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bucc-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bucc-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bucc-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.bucc-1.6" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.bucc-1.6/>Benchmarking Multidomain English-Indonesian Machine Translation<span class=acl-fixed-case>E</span>nglish-<span class=acl-fixed-case>I</span>ndonesian Machine Translation</a></strong><br><a href=/people/t/tri-wahyu-guntara/>Tri Wahyu Guntara</a>
|
<a href=/people/a/alham-fikri-aji/>Alham Fikri Aji</a>
|
<a href=/people/r/radityo-eko-prasojo/>Radityo Eko Prasojo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bucc-1--6><div class="card-body p-3 small">In the context of Machine Translation (MT) from-and-to English, <a href=https://en.wikipedia.org/wiki/Indonesian_language>Bahasa Indonesia</a> has been considered a low-resource language, and therefore applying Neural Machine Translation (NMT) which typically requires large training dataset proves to be problematic. In this paper, we show otherwise by collecting large, publicly-available datasets from the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>Web</a>, which we split into several domains : <a href=https://en.wikipedia.org/wiki/News>news</a>, <a href=https://en.wikipedia.org/wiki/Religion>religion</a>, general, and <a href=https://en.wikipedia.org/wiki/Conversation>conversation</a>, to train and benchmark some variants of transformer-based NMT models across the domains. We show using BLEU that our models perform well across them, outperform the baseline Statistical Machine Translation (SMT) models, and perform comparably with <a href=https://en.wikipedia.org/wiki/Google_Translate>Google Translate</a>. Our datasets (with the standard split for training, validation, and testing), code, and models are available on<url>https://github.com/gunnxx/indonesian-mt-data</url>\n</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bucc-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bucc-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bucc-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bucc-1.7/>Reducing the Search Space for Parallel Sentences in Comparable Corpora</a></strong><br><a href=/people/r/remi-cardon/>Rémi Cardon</a>
|
<a href=/people/n/natalia-grabar/>Natalia Grabar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bucc-1--7><div class="card-body p-3 small">This paper describes and evaluates simple techniques for reducing the research space for parallel sentences in monolingual comparable corpora. Initially, when searching for parallel sentences between two comparable documents, all the possible sentence pairs between the documents have to be considered, which introduces a great degree of imbalance between parallel pairs and non-parallel pairs. This is a problem because even with a high performing <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a>, a lot of <a href=https://en.wikipedia.org/wiki/Noise>noise</a> will be present in the extracted results, thus introducing a need for an extensive and costly manual check phase. We work on a manually annotated subset obtained from a French comparable corpus and show how we can drastically reduce the number of sentence pairs that have to be fed to a <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifier</a> so that the results can be manually handled.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bucc-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bucc-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bucc-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bucc-1.9/>TALN / LS2N Participation at the BUCC Shared Task : Bilingual Dictionary Induction from Comparable Corpora<span class=acl-fixed-case>TALN</span>/<span class=acl-fixed-case>LS</span>2<span class=acl-fixed-case>N</span> Participation at the <span class=acl-fixed-case>BUCC</span> Shared Task: Bilingual Dictionary Induction from Comparable Corpora</a></strong><br><a href=/people/m/martin-laville/>Martin Laville</a>
|
<a href=/people/a/amir-hazem/>Amir Hazem</a>
|
<a href=/people/e/emmanuel-morin/>Emmanuel Morin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bucc-1--9><div class="card-body p-3 small">This paper describes the TALN / LS2N system participation at the Building and Using Comparable Corpora (BUCC) shared task. We first introduce three strategies : (i) a word embedding approach based on fastText embeddings ; (ii) a concatenation approach using both character Skip-Gram and character CBOW models, and finally (iii) a cognates matching approach based on an exact match string similarity. Then, we present the applied <a href=https://en.wikipedia.org/wiki/Strategy_(game_theory)>strategy</a> for the shared task which consists in the combination of the embeddings concatenation and the cognates matching approaches. The covered languages are <a href=https://en.wikipedia.org/wiki/French_language>French</a>, <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/German_language>German</a>, <a href=https://en.wikipedia.org/wiki/Russian_language>Russian</a> and <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>. Overall, our system mixing embeddings concatenation and perfect cognates matching obtained the best results while compared to individual strategies, except for English-Russian and Russian-English language pairs for which the concatenation approach was preferred.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.bucc-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--bucc-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.bucc-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.bucc-1.11/>BUCC2020 : Bilingual Dictionary Induction using Cross-lingual Embedding<span class=acl-fixed-case>BUCC</span>2020: Bilingual Dictionary Induction using Cross-lingual Embedding</a></strong><br><a href=/people/s/sanjanasri-jp/>Sanjanasri JP</a>
|
<a href=/people/v/vijay-krishna-menon/>Vijay Krishna Menon</a>
|
<a href=/people/s/soman-kp/>Soman KP</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--bucc-1--11><div class="card-body p-3 small">This paper presents a <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning system</a> for the BUCC 2020 shared task : Bilingual dictionary induction from comparable corpora. We have submitted two runs for this shared Task, German (de) and English (en) language pair for closed track and Tamil (ta) and English (en) for the open track. Our core approach focuses on quantifying the <a href=https://en.wikipedia.org/wiki/Semantics>semantics of the language pairs</a>, so that <a href=https://en.wikipedia.org/wiki/Semantics>semantics</a> of two different language pairs can be compared or transfer learned. With the advent of <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a>, it is possible to quantify this. In this paper, we propose a deep learning approach which makes use of the supplied training data, to generate cross-lingual embedding. This is later used for inducting <a href=https://en.wikipedia.org/wiki/Bilingual_dictionary>bilingual dictionary</a> from comparable corpora.</div></div></div><hr><div id=2020calcs-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.calcs-1/>Proceedings of the The 4th Workshop on Computational Approaches to Code Switching</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.calcs-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.calcs-1.0/>Proceedings of the The 4th Workshop on Computational Approaches to Code Switching</a></strong><br><a href=/people/t/thamar-solorio/>Thamar Solorio</a>
|
<a href=/people/m/monojit-choudhury/>Monojit Choudhury</a>
|
<a href=/people/k/kalika-bali/>Kalika Bali</a>
|
<a href=/people/s/sunayana-sitaram/>Sunayana Sitaram</a>
|
<a href=/people/a/amitava-das/>Amitava Das</a>
|
<a href=/people/m/mona-diab/>Mona Diab</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.calcs-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--calcs-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.calcs-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.calcs-1.1/>An Annotated Corpus of Emerging Anglicisms in Spanish Newspaper Headlines<span class=acl-fixed-case>S</span>panish Newspaper Headlines</a></strong><br><a href=/people/e/elena-alvarez-mellado/>Elena Alvarez-Mellado</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--calcs-1--1><div class="card-body p-3 small">The extraction of anglicisms (lexical borrowings from English) is relevant both for <a href=https://en.wikipedia.org/wiki/Lexicography>lexicographic purposes</a> and for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP downstream tasks</a>. We introduce a corpus of European Spanish newspaper headlines annotated with <a href=https://en.wikipedia.org/wiki/Anglicism>anglicisms</a> and a baseline model for anglicism extraction. In this paper we present : (1) a corpus of 21,570 newspaper headlines written in <a href=https://en.wikipedia.org/wiki/European_Spanish>European Spanish</a> annotated with emergent anglicisms and (2) a conditional random field baseline model with handcrafted features for anglicism extraction. We present the newspaper headlines corpus, describe the annotation tagset and guidelines and introduce a CRF model that can serve as baseline for the task of detecting anglicisms. The presented work is a first step towards the creation of an anglicism extractor for <a href=https://en.wikipedia.org/wiki/List_of_newspapers_in_Spain>Spanish newswire</a>.</div></div></div><hr><div id=2020challengehml-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.challengehml-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.challengehml-1/>Second Grand-Challenge and Workshop on Multimodal Language (Challenge-HML)</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.challengehml-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.challengehml-1.0/>Second Grand-Challenge and Workshop on Multimodal Language (Challenge-HML)</a></strong><br><a href=/people/a/amir-zadeh/>Amir Zadeh</a>
|
<a href=/people/l/louis-philippe-morency/>Louis-Philippe Morency</a>
|
<a href=/people/p/paul-pu-liang/>Paul Pu Liang</a>
|
<a href=/people/s/soujanya-poria/>Soujanya Poria</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.challengehml-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--challengehml-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.challengehml-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38931259 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.challengehml-1.2/>A Multi-modal Approach to Fine-grained Opinion Mining on Video Reviews</a></strong><br><a href=/people/e/edison-marrese-taylor/>Edison Marrese-Taylor</a>
|
<a href=/people/c/cristian-rodriguez/>Cristian Rodriguez</a>
|
<a href=/people/j/jorge-balazs/>Jorge Balazs</a>
|
<a href=/people/s/stephen-gould/>Stephen Gould</a>
|
<a href=/people/y/yutaka-matsuo/>Yutaka Matsuo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--challengehml-1--2><div class="card-body p-3 small">Despite the recent advances in <a href=https://en.wikipedia.org/wiki/Opinion_mining>opinion mining</a> for written reviews, few works have tackled the <a href=https://en.wikipedia.org/wiki/Problem_solving>problem</a> on other sources of reviews. In light of this issue, we propose a multi-modal approach for mining fine-grained opinions from video reviews that is able to determine the aspects of the item under review that are being discussed and the sentiment orientation towards them. Our approach works at the sentence level without the need for time annotations and uses features derived from the audio, video and language transcriptions of its contents. We evaluate our approach on two datasets and show that leveraging the video and audio modalities consistently provides increased performance over text-only baselines, providing evidence these extra modalities are key in better understanding video reviews.</div></div></div><hr><div id=2020cllrd-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.cllrd-1/>Proceedings of the LREC 2020 Workshop on "Citizen Linguistics in Language Resource Development"</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.cllrd-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.cllrd-1.0/>Proceedings of the LREC 2020 Workshop on "Citizen Linguistics in Language Resource Development"</a></strong><br><a href=/people/j/james-fiumara/>James Fiumara</a>
|
<a href=/people/c/christopher-cieri/>Christopher Cieri</a>
|
<a href=/people/m/mark-liberman/>Mark Liberman</a>
|
<a href=/people/c/chris-callison-burch/>Chris Callison-Burch</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.cllrd-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--cllrd-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.cllrd-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.cllrd-1.4/>Speaking Outside the Box : Exploring the Benefits of Unconstrained Input in <a href=https://en.wikipedia.org/wiki/Crowdsourcing>Crowdsourcing</a> and Citizen Science Platforms</a></strong><br><a href=/people/j/jon-chamberlain/>Jon Chamberlain</a>
|
<a href=/people/u/udo-kruschwitz/>Udo Kruschwitz</a>
|
<a href=/people/m/massimo-poesio/>Massimo Poesio</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--cllrd-1--4><div class="card-body p-3 small">Crowdsourcing approaches provide a difficult design challenge for developers. There is a trade-off between the efficiency of the task to be done and the reward given to the user for participating, whether it be <a href=https://en.wikipedia.org/wiki/Altruism>altruism</a>, social enhancement, <a href=https://en.wikipedia.org/wiki/Entertainment>entertainment</a> or money. This paper explores how <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing</a> and <a href=https://en.wikipedia.org/wiki/Citizen_science>citizen science systems</a> collect data and complete tasks, illustrated by a case study from the online language game-with-a-purpose Phrase Detectives. The <a href=https://en.wikipedia.org/wiki/Game_(retailer)>game</a> was originally developed to be a constrained interface to prevent player collusion, but subsequently benefited from posthoc analysis of over 76k unconstrained inputs from users. Understanding the interface design and task deconstruction are critical for enabling users to participate in such systems and the paper concludes with a discussion of the idea that <a href=https://en.wikipedia.org/wiki/List_of_social_networking_websites>social networks</a> can be viewed as form of <a href=https://en.wikipedia.org/wiki/Citizen_science>citizen science platform</a> with both constrained and unconstrained inputs making for a highly complex dataset.</div></div></div><hr><div id=2020clssts-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.clssts-1/>Proceedings of the workshop on Cross-Language Search and Summarization of Text and Speech (CLSSTS2020)</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.clssts-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.clssts-1.0/>Proceedings of the workshop on Cross-Language Search and Summarization of Text and Speech (CLSSTS2020)</a></strong><br><a href=/people/k/kathleen-mckeown/>Kathy McKeown</a>
|
<a href=/people/d/douglas-w-oard/>Douglas W. Oard</a>
|
<a href=/people/e/elizabeth/>Elizabeth</a>
|
<a href=/people/r/richard-schwartz/>Richard Schwartz</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.clssts-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--clssts-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.clssts-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.clssts-1.4/>SEARCHER : Shared Embedding Architecture for Effective Retrieval<span class=acl-fixed-case>SEARCHER</span>: Shared Embedding Architecture for Effective Retrieval</a></strong><br><a href=/people/j/joel-barry/>Joel Barry</a>
|
<a href=/people/e/elizabeth-boschee/>Elizabeth Boschee</a>
|
<a href=/people/m/marjorie-freedman/>Marjorie Freedman</a>
|
<a href=/people/s/scott-miller/>Scott Miller</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--clssts-1--4><div class="card-body p-3 small">We describe an approach to <a href=https://en.wikipedia.org/wiki/Cross-lingual_information_retrieval>cross lingual information retrieval</a> that does not rely on explicit translation of either document or query terms. Instead, both queries and documents are mapped into a shared embedding space where <a href=https://en.wikipedia.org/wiki/Information_retrieval>retrieval</a> is performed. We discuss potential advantages of the approach in handling <a href=https://en.wikipedia.org/wiki/Polysemy>polysemy</a> and <a href=https://en.wikipedia.org/wiki/Synonym_(taxonomy)>synonymy</a>. We present a method for training the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>, and give details of the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> implementation. We present experimental results for two cases : Somali-English and Bulgarian-English CLIR.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.clssts-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--clssts-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.clssts-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.clssts-1.5/>Cross-lingual Information Retrieval with BERT<span class=acl-fixed-case>BERT</span></a></strong><br><a href=/people/z/zhuolin-jiang/>Zhuolin Jiang</a>
|
<a href=/people/a/amro-el-jaroudi/>Amro El-Jaroudi</a>
|
<a href=/people/w/william-hartmann/>William Hartmann</a>
|
<a href=/people/d/damianos-karakos/>Damianos Karakos</a>
|
<a href=/people/l/lingjun-zhao/>Lingjun Zhao</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--clssts-1--5><div class="card-body p-3 small">Multiple neural language models have been developed recently, e.g., BERT and XLNet, and achieved impressive results in various NLP tasks including sentence classification, <a href=https://en.wikipedia.org/wiki/Question_answering>question answering</a> and <a href=https://en.wikipedia.org/wiki/Document_ranking>document ranking</a>. In this paper, we explore the use of the popular bidirectional language model, BERT, to model and learn the <a href=https://en.wikipedia.org/wiki/Relevance_(information_retrieval)>relevance</a> between English queries and foreign-language documents in the task of <a href=https://en.wikipedia.org/wiki/Cross-lingual_information_retrieval>cross-lingual information retrieval</a>. A deep relevance matching model based on BERT is introduced and trained by finetuning a pretrained multilingual BERT model with weak supervision, using home-made CLIR training data derived from parallel corpora. Experimental results of the retrieval of Lithuanian documents against short English queries show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is effective and outperforms the competitive baseline approaches.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.clssts-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--clssts-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.clssts-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.clssts-1.6/>A Comparison of <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>Unsupervised Methods</a> for Ad hoc Cross-Lingual Document Retrieval</a></strong><br><a href=/people/e/elaine-zosa/>Elaine Zosa</a>
|
<a href=/people/m/mark-granroth-wilding/>Mark Granroth-Wilding</a>
|
<a href=/people/l/lidia-pivovarova/>Lidia Pivovarova</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--clssts-1--6><div class="card-body p-3 small">We address the problem of linking related documents across languages in a <a href=https://en.wikipedia.org/wiki/Collection_(abstract_data_type)>multilingual collection</a>. We evaluate three diverse unsupervised methods to represent and compare documents : (1) multilingual topic model ; (2) cross-lingual document embeddings ; and (3) <a href=https://en.wikipedia.org/wiki/Wasserstein_distance>Wasserstein distance</a>. We test the performance of these methods in retrieving news articles in Swedish that are known to be related to a given Finnish article. The results show that ensembles of the methods outperform the stand-alone methods, suggesting that they capture complementary characteristics of the documents</div></div></div><hr><div id=2020cmlc-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.cmlc-1/>Proceedings of the 8th Workshop on Challenges in the Management of Large Corpora</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.cmlc-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.cmlc-1.0/>Proceedings of the 8th Workshop on Challenges in the Management of Large Corpora</a></strong><br><a href=/people/p/piotr-banski/>Piotr Bański</a>
|
<a href=/people/a/adrien-barbaresi/>Adrien Barbaresi</a>
|
<a href=/people/s/simon-clematide/>Simon Clematide</a>
|
<a href=/people/m/marc-kupietz/>Marc Kupietz</a>
|
<a href=/people/h/harald-lungen/>Harald Lüngen</a>
|
<a href=/people/i/ines-pisetta/>Ines Pisetta</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.cmlc-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--cmlc-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.cmlc-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.cmlc-1.4/>Geoparsing the historical Gazetteers of Scotland : accurately computing location in mass digitised texts<span class=acl-fixed-case>S</span>cotland: accurately computing location in mass digitised texts</a></strong><br><a href=/people/r/rosa-filgueira/>Rosa Filgueira</a>
|
<a href=/people/c/claire-grover/>Claire Grover</a>
|
<a href=/people/m/melissa-terras/>Melissa Terras</a>
|
<a href=/people/b/beatrice-alex/>Beatrice Alex</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--cmlc-1--4><div class="card-body p-3 small">This paper describes work in progress on devising automatic and parallel methods for geoparsing large digital historical textual data by combining the strengths of three natural language processing (NLP) tools, the Edinburgh Geoparser, spaCy and defoe, and employing different tokenisation and named entity recognition (NER) techniques. We apply these tools to a large collection of nineteenth century Scottish geographical dictionaries, and describe preliminary results obtained when processing this <a href=https://en.wikipedia.org/wiki/Data>data</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.cmlc-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--cmlc-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.cmlc-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.cmlc-1.5/>The Corpus Query Middleware of Tomorrow A Proposal for a Hybrid Corpus Query Architecture</a></strong><br><a href=/people/m/markus-gartner/>Markus Gärtner</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--cmlc-1--5><div class="card-body p-3 small">Development of dozens of specialized corpus query systems and languages over the past decades has let to a diverse but also fragmented landscape. Today we are faced with a plethora of query tools that each provide unique features, but which are also not interoperable and often rely on very specific database back-ends or formats for storage. This severely hampers usability both for end users that want to query different corpora and also for corpus designers that wish to provide users with an interface for querying and exploration. We propose a hybrid corpus query architecture as a first step to overcoming this issue. It takes the form of a <a href=https://en.wikipedia.org/wiki/Middleware>middleware system</a> between user front-ends and optional database or text indexing solutions as <a href=https://en.wikipedia.org/wiki/Front_and_back_ends>back-ends</a>. At its core is a custom query evaluation engine for index-less processing of corpus queries. With a flexible JSON-LD query protocol the approach allows communication with <a href=https://en.wikipedia.org/wiki/Front_and_back_ends>back-end systems</a> to partially solve queries and offset some of the performance penalties imposed by the custom evaluation engine. This paper outlines the details of our first draft of aforementioned <a href=https://en.wikipedia.org/wiki/Architecture>architecture</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.cmlc-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--cmlc-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.cmlc-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.cmlc-1.6/>Using <a href=https://en.wikipedia.org/wiki/Full-text_search>full text indices</a> for querying spoken language data</a></strong><br><a href=/people/e/elena-frick/>Elena Frick</a>
|
<a href=/people/t/thomas-schmidt/>Thomas Schmidt</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--cmlc-1--6><div class="card-body p-3 small">As a part of the ZuMult-project, we are currently modelling a backend architecture that should provide query access to corpora from the Archive of Spoken German (AGD) at the Leibniz-Institute for the German Language (IDS). We are exploring how to reuse existing search engine frameworks providing full text indices and allowing to query corpora by one of the corpus query languages (QLs) established and actively used in the corpus research community. For this purpose, we tested MTAS-an open source Lucene-based search engine for querying on text with multilevel annotations. We applied MTAS on three oral corpora stored in the TEI-based ISO standard for transcriptions of spoken language (ISO 24624:2016). These corpora differ from the corpus data that MTAS was developed for, because they include interactions with two and more speakers and are enriched, inter alia, with timeline-based annotations. In this contribution, we report our test results and address issues that arise when search frameworks originally developed for querying <a href=https://en.wikipedia.org/wiki/Text_corpus>written corpora</a> are being transferred into the field of <a href=https://en.wikipedia.org/wiki/Spoken_language>spoken language</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.cmlc-1.8.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--cmlc-1--8 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.cmlc-1.8 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.cmlc-1.8/>Czech National Corpus in 2020 : Recent Developments and Future Outlook<span class=acl-fixed-case>C</span>zech National Corpus in 2020: Recent Developments and Future Outlook</a></strong><br><a href=/people/m/michal-kren/>Michal Kren</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--cmlc-1--8><div class="card-body p-3 small">The paper overviews the state of implementation of the Czech National Corpus (CNC) in all the main areas of its operation : <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus compilation</a>, <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a>, <a href=https://en.wikipedia.org/wiki/Application_software>application development</a> and user services. As the focus is on the recent development, some of the areas are described in more detail than the others. Close attention is paid to the <a href=https://en.wikipedia.org/wiki/Data_collection>data collection</a> and, in particular, to the description of <a href=https://en.wikipedia.org/wiki/Web_application_development>web application development</a>. This is not only because <a href=https://en.wikipedia.org/wiki/Numerical_control>CNC</a> has recently seen a significant progress in this area, but also because we believe that end-user web applications shape the way linguists and other scholars think about the language data and about the range of possibilities they offer. This consideration is even more important given the variability of the <a href=https://en.wikipedia.org/wiki/Numerical_analysis>CNC corpora</a>.</div></div></div><hr><div id=2020computerm-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.computerm-1/>Proceedings of the 6th International Workshop on Computational Terminology</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.computerm-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.computerm-1.0/>Proceedings of the 6th International Workshop on Computational Terminology</a></strong><br><a href=/people/b/beatrice-daille/>Béatrice Daille</a>
|
<a href=/people/k/kyo-kageura/>Kyo Kageura</a>
|
<a href=/people/a/ayla-rigouts-terryn/>Ayla Rigouts Terryn</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.computerm-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--computerm-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.computerm-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.computerm-1.7/>A study of semantic projection from single word terms to multi-word terms in the environment domain</a></strong><br><a href=/people/y/yizhe-wang/>Yizhe Wang</a>
|
<a href=/people/b/beatrice-daille/>Beatrice Daille</a>
|
<a href=/people/n/nabil-hathout/>Nabil Hathout</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--computerm-1--7><div class="card-body p-3 small">The semantic projection method is often used in <a href=https://en.wikipedia.org/wiki/Terminology>terminology structuring</a> to infer semantic relations between terms. Semantic projection relies upon the assumption of semantic compositionality : the relation that links simple term pairs remains valid in pairs of complex terms built from these simple terms. This paper proposes to investigate whether this assumption commonly adopted in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a> is actually valid. First, we describe the process of constructing a list of semantically linked multi-word terms (MWTs) related to the environmental field through the extraction of semantic variants. Second, we present our analysis of the results from the semantic projection. We find that contexts play an essential role in defining the relations between MWTs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.computerm-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--computerm-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.computerm-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.computerm-1.14/>TermEval 2020 : RACAI’s automatic term extraction system<span class=acl-fixed-case>T</span>erm<span class=acl-fixed-case>E</span>val 2020: <span class=acl-fixed-case>RACAI</span>’s automatic term extraction system</a></strong><br><a href=/people/v/vasile-pais/>Vasile Pais</a>
|
<a href=/people/r/radu-ion/>Radu Ion</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--computerm-1--14><div class="card-body p-3 small">This paper describes RACAI&#8217;s automatic term extraction system, which participated in the TermEval 2020 shared task on English monolingual term extraction. We discuss the <a href=https://en.wikipedia.org/wiki/Systems_architecture>system architecture</a>, some of the challenges that we faced as well as present our results in the English competition.</div></div></div><hr><div id=2020ecnlp-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ecnlp-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.ecnlp-1/>Proceedings of The 3rd Workshop on e-Commerce and NLP</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ecnlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.ecnlp-1.0/>Proceedings of The 3rd Workshop on e-Commerce and NLP</a></strong><br><a href=/people/s/shervin-malmasi/>Shervin Malmasi</a>
|
<a href=/people/s/surya-kallumadi/>Surya Kallumadi</a>
|
<a href=/people/n/nicola-ueffing/>Nicola Ueffing</a>
|
<a href=/people/o/oleg-rokhlenko/>Oleg Rokhlenko</a>
|
<a href=/people/e/eugene-agichtein/>Eugene Agichtein</a>
|
<a href=/people/i/ido-guy/>Ido Guy</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ecnlp-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ecnlp-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ecnlp-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38931239 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.ecnlp-1.1/>Bootstrapping Named Entity Recognition in E-Commerce with Positive Unlabeled Learning<span class=acl-fixed-case>E</span>-Commerce with Positive Unlabeled Learning</a></strong><br><a href=/people/h/hanchu-zhang/>Hanchu Zhang</a>
|
<a href=/people/l/leonhard-hennig/>Leonhard Hennig</a>
|
<a href=/people/c/christoph-alt/>Christoph Alt</a>
|
<a href=/people/c/changjian-hu/>Changjian Hu</a>
|
<a href=/people/y/yao-meng/>Yao Meng</a>
|
<a href=/people/c/chao-wang/>Chao Wang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ecnlp-1--1><div class="card-body p-3 small">In this work, we introduce a bootstrapped, iterative NER model that integrates a PU learning algorithm for recognizing <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entities</a> in a low-resource setting. Our approach combines dictionary-based labeling with syntactically-informed label expansion to efficiently enrich the seed dictionaries. Experimental results on a dataset of manually annotated e-commerce product descriptions demonstrate the effectiveness of the proposed <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ecnlp-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ecnlp-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ecnlp-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38931243 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.ecnlp-1.4/>A <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Learning System</a> for Sentiment Analysis of Service Calls</a></strong><br><a href=/people/y/yanan-jia/>Yanan Jia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ecnlp-1--4><div class="card-body p-3 small">Sentiment analysis is crucial for the advancement of <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>artificial intelligence (AI)</a>. Sentiment understanding can help <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>AI</a> to replicate <a href=https://en.wikipedia.org/wiki/Human&#8211;computer_interaction>human language and discourse</a>. Studying the formation and response of sentiment state from well-trained Customer Service Representatives (CSRs) can help make the interaction between humans and AI more intelligent. In this paper, a sentiment analysis pipeline is first carried out with respect to real-world multi-party conversations-that is, <a href=https://en.wikipedia.org/wiki/Service_(systems_architecture)>service calls</a>. Based on the acoustic and linguistic features extracted from the source information, a novel aggregated method for voice sentiment recognition framework is built. Each party&#8217;s sentiment pattern during the communication is investigated along with the interaction sentiment pattern between all parties.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ecnlp-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ecnlp-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ecnlp-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.ecnlp-1.11/>SimsterQ : A Similarity based Clustering Approach to Opinion Question Answering<span class=acl-fixed-case>S</span>imster<span class=acl-fixed-case>Q</span>: <span class=acl-fixed-case>A</span> Similarity based Clustering Approach to Opinion Question Answering</a></strong><br><a href=/people/a/aishwarya-ashok/>Aishwarya Ashok</a>
|
<a href=/people/g/ganapathy-natarajan/>Ganapathy Natarajan</a>
|
<a href=/people/r/ramez-elmasri/>Ramez Elmasri</a>
|
<a href=/people/l/laurel-smith-stvan/>Laurel Smith-Stvan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ecnlp-1--11><div class="card-body p-3 small">In recent years, there has been an increase in <a href=https://en.wikipedia.org/wiki/Online_shopping>online shopping</a> resulting in an increased number of <a href=https://en.wikipedia.org/wiki/Review_site>online reviews</a>. Customers can not delve into the huge amount of data when they are looking for specific aspects of a product. Some of these aspects can be extracted from the <a href=https://en.wikipedia.org/wiki/Product_review>product reviews</a>. In this paper we introduced SimsterQ-a clustering based system for answering questions that makes use of word vectors. Clustering was performed using cosine similarity scores between sentence vectors of reviews and questions. Two variants (Sim and Median) with and without <a href=https://en.wikipedia.org/wiki/Stopword>stopwords</a> were evaluated against traditional methods that use <a href=https://en.wikipedia.org/wiki/Term_frequency>term frequency</a>. We also used an n-gram approach to study the effect of <a href=https://en.wikipedia.org/wiki/Noise>noise</a>. We used the reviews in the Amazon Reviews dataset to pick the answers. Evaluation was performed both at the individual sentence level using the top sentence from <a href=https://en.wikipedia.org/wiki/Okapi_BM25>Okapi BM25</a> as the gold standard and at the whole answer level using review snippets as the gold standard. At the <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence level</a> our <a href=https://en.wikipedia.org/wiki/System>system</a> performed slightly better than a more complicated <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning method</a>. Our system returned answers similar to the review snippets from the Amazon QA Dataset as measured by the <a href=https://en.wikipedia.org/wiki/Cosine_similarity>cosine similarity</a>. Analysis was also performed on the quality of the <a href=https://en.wikipedia.org/wiki/Cluster_analysis>clusters</a> generated by our <a href=https://en.wikipedia.org/wiki/System>system</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ecnlp-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ecnlp-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ecnlp-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38931245 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.ecnlp-1.13/>On Application of Bayesian Parametric and Non-parametric Methods for User Cohorting in Product Search<span class=acl-fixed-case>B</span>ayesian Parametric and Non-parametric Methods for User Cohorting in Product Search</a></strong><br><a href=/people/s/shashank-gupta/>Shashank Gupta</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ecnlp-1--13><div class="card-body p-3 small">In this paper, we study the applicability of Bayesian Parametric and Non-parametric methods for user clustering in an E-commerce search setting. To the best of our knowledge, this is the first work that presents a comparative study of various Bayesian clustering methods in the context of product search. Specifically, we cluster users based on their topical patterns from their respective product search queries. To evaluate the quality of the <a href=https://en.wikipedia.org/wiki/Cluster_analysis>clusters</a> formed, we perform a collaborative query recommendation task. Our findings indicate that simple parametric model like Latent Dirichlet Allocation (LDA) outperforms more sophisticated non-parametric methods like Distance Dependent Chinese Restaurant Process and Dirichlet Process-based clustering in both tasks.</div></div></div><hr><div id=2020fever-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.fever-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.fever-1/>Proceedings of the Third Workshop on Fact Extraction and VERification (FEVER)</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.fever-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.fever-1.0/>Proceedings of the Third Workshop on Fact Extraction and VERification (FEVER)</a></strong><br><a href=/people/c/christos-christodoulopoulos/>Christos Christodoulopoulos</a>
|
<a href=/people/j/james-thorne/>James Thorne</a>
|
<a href=/people/a/andreas-vlachos/>Andreas Vlachos</a>
|
<a href=/people/o/oana-cocarascu/>Oana Cocarascu</a>
|
<a href=/people/a/arpit-mittal/>Arpit Mittal</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.fever-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--fever-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.fever-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929663 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.fever-1.1/>Simple Compounded-Label Training for Fact Extraction and Verification</a></strong><br><a href=/people/y/yixin-nie/>Yixin Nie</a>
|
<a href=/people/l/lisa-bauer/>Lisa Bauer</a>
|
<a href=/people/m/mohit-bansal/>Mohit Bansal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--fever-1--1><div class="card-body p-3 small">Automatic fact checking is an important task motivated by the need for detecting and preventing the spread of misinformation across the web. The recently released FEVER challenge provides a benchmark task that assesses systems&#8217; capability for both the retrieval of required evidence and the identification of authentic claims. Previous approaches share a similar pipeline training paradigm that decomposes the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> into three subtasks, with each component built and trained separately. Although achieving acceptable scores, these <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>methods</a> induce difficulty for practical application development due to <a href=https://en.wikipedia.org/wiki/Complexity>unnecessary complexity</a> and expensive computation. In this paper, we explore the potential of simplifying the system design and reducing training computation by proposing a joint training setup in which a single sequence matching model is trained with compounded labels that give supervision for both sentence selection and claim verification subtasks, eliminating the duplicate computation that occurs when models are designed and trained separately. Empirical results on FEVER indicate that our method : (1) outperforms the typical multi-task learning approach, and (2) gets comparable results to top performing systems with a much simpler training setup and less training computation (in terms of the amount of data consumed and the number of model parameters), facilitating future works on the automatic fact checking task and its practical usage.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.fever-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--fever-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.fever-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929662 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.fever-1.5/>Language Models as Fact Checkers?</a></strong><br><a href=/people/n/nayeon-lee/>Nayeon Lee</a>
|
<a href=/people/b/belinda-z-li/>Belinda Z. Li</a>
|
<a href=/people/s/sinong-wang/>Sinong Wang</a>
|
<a href=/people/w/wen-tau-yih/>Wen-tau Yih</a>
|
<a href=/people/h/hao-ma/>Hao Ma</a>
|
<a href=/people/m/madian-khabsa/>Madian Khabsa</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--fever-1--5><div class="card-body p-3 small">Recent work has suggested that language models (LMs) store both common-sense and factual knowledge learned from pre-training data. In this paper, we leverage this implicit knowledge to create an effective end-to-end fact checker using a solely a <a href=https://en.wikipedia.org/wiki/Language_model>language model</a>, without any external knowledge or explicit retrieval components. While previous work on extracting knowledge from LMs have focused on the task of open-domain question answering, to the best of our knowledge, this is the first work to examine the use of language models as <a href=https://en.wikipedia.org/wiki/Fact-checking>fact checkers</a>. In a closed-book setting, we show that our zero-shot LM approach outperforms a random baseline on the standard FEVER task, and that our finetuned LM compares favorably with standard baselines. Though we do not ultimately outperform methods which use explicit knowledge bases, we believe our exploration shows that this method is viable and has much room for exploration.</div></div></div><hr><div id=2020figlang-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.figlang-1/>Proceedings of the Second Workshop on Figurative Language Processing</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.figlang-1.0/>Proceedings of the Second Workshop on Figurative Language Processing</a></strong><br><a href=/people/b/beata-beigman-klebanov/>Beata Beigman Klebanov</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a>
|
<a href=/people/p/patricia-lichtenstein/>Patricia Lichtenstein</a>
|
<a href=/people/s/smaranda-muresan/>Smaranda Muresan</a>
|
<a href=/people/c/chee-wee/>Chee Wee</a>
|
<a href=/people/a/anna-feldman/>Anna Feldman</a>
|
<a href=/people/d/debanjan-ghosh/>Debanjan Ghosh</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929697 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.7/>Sarcasm Detection in Tweets with BERT and GloVe Embeddings<span class=acl-fixed-case>BERT</span> and <span class=acl-fixed-case>G</span>lo<span class=acl-fixed-case>V</span>e Embeddings</a></strong><br><a href=/people/a/akshay-khatri/>Akshay Khatri</a>
|
<a href=/people/p/pranav-p/>Pranav P</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--7><div class="card-body p-3 small">Sarcasm is a form of communication in which the person states opposite of what he actually means. In this paper, we propose using machine learning techniques with BERT and GloVe embeddings to detect <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> in <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a>. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> is preprocessed before extracting the <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a>. The proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> also uses all of the context provided in the dataset to which the user is reacting along with his actual response.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.8.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--8 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.8 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929698 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.8/>C-Net : Contextual Network for Sarcasm Detection<span class=acl-fixed-case>C</span>-Net: Contextual Network for Sarcasm Detection</a></strong><br><a href=/people/a/amit-kumar-jena/>Amit Kumar Jena</a>
|
<a href=/people/a/aman-sinha/>Aman Sinha</a>
|
<a href=/people/r/rohit-agarwal/>Rohit Agarwal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--8><div class="card-body p-3 small">Automatic Sarcasm Detection in <a href=https://en.wikipedia.org/wiki/Conversation>conversations</a> is a difficult and tricky task. Classifying an utterance as sarcastic or not in isolation can be futile since most of the time the sarcastic nature of a sentence heavily relies on its context. This paper presents our proposed model, <a href=https://en.wikipedia.org/wiki/C-Net>C-Net</a>, which takes contextual information of a sentence in a sequential manner to classify it as sarcastic or non-sarcastic. Our <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> showcases competitive performance in the Sarcasm Detection shared task organised on CodaLab and achieved 75.0 % <a href=https://en.wikipedia.org/wiki/F-number>F1-score</a> on the Twitter dataset and 66.3 % <a href=https://en.wikipedia.org/wiki/F-number>F1-score</a> on Reddit dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929700 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.10/>Sarcasm Identification and Detection in Conversion Context using BERT<span class=acl-fixed-case>BERT</span></a></strong><br><a href=/people/k/kalaivani-a/>Kalaivani A.</a>
|
<a href=/people/t/thenmozhi-d/>Thenmozhi D.</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--10><div class="card-body p-3 small">Sarcasm analysis in user conversion text is automatic detection of any irony, insult, hurting, painful, caustic, <a href=https://en.wikipedia.org/wiki/Humour>humour</a>, vulgarity that degrades an individual. It is helpful in the field of sentimental analysis and <a href=https://en.wikipedia.org/wiki/Cyberbullying>cyberbullying</a>. As an immense growth of <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>, sarcasm analysis helps to avoid insult, hurts and <a href=https://en.wikipedia.org/wiki/Humour>humour</a> to affect someone. In this paper, we present traditional machine learning approaches, deep learning approach (LSTM -RNN) and BERT (Bidirectional Encoder Representations from Transformers) for identifying <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a>. We have used the approaches to build the model, to identify and categorize how much conversion context or response is needed for sarcasm detection and evaluated on the two social media forums that is twitter conversation dataset and reddit conversion dataset. We compare the performance based on the approaches and obtained the best F1 scores as 0.722, 0.679 for the <a href=https://en.wikipedia.org/wiki/Twitter>twitter forums</a> and <a href=https://en.wikipedia.org/wiki/Reddit>reddit forums</a> respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929701 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.11/>Neural Sarcasm Detection using Conversation Context</a></strong><br><a href=/people/n/nikhil-jaiswal/>Nikhil Jaiswal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--11><div class="card-body p-3 small">Social media platforms and <a href=https://en.wikipedia.org/wiki/Internet_forum>discussion forums</a> such as <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a>, <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>, etc. are filled with <a href=https://en.wikipedia.org/wiki/Literal_and_figurative_language>figurative languages</a>. Sarcasm is one such category of <a href=https://en.wikipedia.org/wiki/Literal_and_figurative_language>figurative language</a> whose presence in a conversation makes <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>language understanding</a> a challenging task. In this paper, we present a <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural architecture</a> for sarcasm detection. We investigate various pre-trained language representation models (PLRMs) like BERT, RoBERTa, etc. and fine-tune it on the Twitter dataset. We experiment with a variety of PLRMs either on the twitter utterance in isolation or utilizing the <a href=https://en.wikipedia.org/wiki/Context_(language_use)>contextual information</a> along with the utterance. Our findings indicate that by taking into consideration the previous three most recent utterances, the model is more accurately able to classify a conversation as being sarcastic or not. Our best performing <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensemble model</a> achieves an overall <a href=https://en.wikipedia.org/wiki/F-number>F1 score</a> of 0.790, which ranks us second on the leaderboard of the Sarcasm Shared Task 2020.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929704 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.14/>A Novel Hierarchical BERT Architecture for Sarcasm Detection<span class=acl-fixed-case>BERT</span> Architecture for Sarcasm Detection</a></strong><br><a href=/people/h/himani-srivastava/>Himani Srivastava</a>
|
<a href=/people/v/vaibhav-varshney/>Vaibhav Varshney</a>
|
<a href=/people/s/surabhi-kumari/>Surabhi Kumari</a>
|
<a href=/people/s/saurabh-srivastava/>Saurabh Srivastava</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--14><div class="card-body p-3 small">Online discussion platforms are often flooded with opinions from users across the world on a variety of topics. Many such posts, comments, or utterances are often sarcastic in nature, i.e., the actual intent is hidden in the sentence and is different from its literal meaning, making the detection of such utterances challenging without additional context. In this paper, we propose a novel deep learning-based approach to detect whether an utterance is sarcastic or non-sarcastic by utilizing the given contexts ina hierarchical manner. We have used <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> from two online discussion platforms-Twitter and Reddit1for our experiments. Experimental and error analysis shows that the hierarchical models can make full use of history to obtain a better representation of contexts and thus, in turn, can outperform their sequential counterparts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.figlang-1.15/>Detecting Sarcasm in Conversation Context Using Transformer-Based Models<span class=acl-fixed-case>D</span>etecting <span class=acl-fixed-case>S</span>arcasm in <span class=acl-fixed-case>C</span>onversation <span class=acl-fixed-case>C</span>ontext <span class=acl-fixed-case>U</span>sing <span class=acl-fixed-case>T</span>ransformer-<span class=acl-fixed-case>B</span>ased <span class=acl-fixed-case>M</span>odels</a></strong><br><a href=/people/a/adithya-avvaru/>Adithya Avvaru</a>
|
<a href=/people/s/sanath-vobilisetty/>Sanath Vobilisetty</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--15><div class="card-body p-3 small">Sarcasm detection, regarded as one of the sub-problems of <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>, is a very typical task because the introduction of sarcastic words can flip the sentiment of the sentence itself. To date, many research works revolve around detecting <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> in one single sentence and there is very limited research to detect <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> resulting from multiple sentences. Current models used Long Short Term Memory (LSTM) variants with or without <a href=https://en.wikipedia.org/wiki/Attention>attention</a> to detect <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> in conversations. We showed that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> using state-of-the-art Bidirectional Encoder Representations from Transformers (BERT), to capture syntactic and semantic information across conversation sentences, performed better than the current <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. Based on the data analysis, we estimated that the number of sentences in the conversation that can contribute to the <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> and the results agrees to this estimation. We also perform a comparative study of our different versions of BERT-based model with other variants of LSTM model and XLNet (both using the estimated number of conversation sentences) and find out that BERT-based models outperformed them.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929723 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.16/>Using Conceptual Norms for Metaphor Detection</a></strong><br><a href=/people/m/mingyu-wan/>Mingyu Wan</a>
|
<a href=/people/k/kathleen-ahrens/>Kathleen Ahrens</a>
|
<a href=/people/e/emmanuele-chersoni/>Emmanuele Chersoni</a>
|
<a href=/people/m/menghan-jiang/>Menghan Jiang</a>
|
<a href=/people/q/qi-su/>Qi Su</a>
|
<a href=/people/r/rong-xiang/>Rong Xiang</a>
|
<a href=/people/c/chu-ren-huang/>Chu-Ren Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--16><div class="card-body p-3 small">This paper reports a linguistically-enriched method of detecting token-level metaphors for the second shared task on Metaphor Detection. We participate in all four phases of competition with both <a href=https://en.wikipedia.org/wiki/Digital_data>datasets</a>, i.e. Verbs and AllPOS on the VUA and the TOFEL datasets. We use the modality exclusivity and embodiment norms for constructing a conceptual representation of the nodes and the context. Our <a href=https://en.wikipedia.org/wiki/System>system</a> obtains an <a href=https://en.wikipedia.org/wiki/International_Federation_of_the_Phonographic_Industry>F-score</a> of 0.652 for the VUA Verbs track, which is 5 % higher than the strong baselines. The experimental results across models and datasets indicate the salient contribution of using modality exclusivity and modality shift information for predicting <a href=https://en.wikipedia.org/wiki/Metaphor>metaphoricity</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.18.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--18 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.18 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929724 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.18/>Character aware models with <a href=https://en.wikipedia.org/wiki/Similarity_learning>similarity learning</a> for metaphor detection</a></strong><br><a href=/people/t/tarun-kumar/>Tarun Kumar</a>
|
<a href=/people/y/yashvardhan-sharma/>Yashvardhan Sharma</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--18><div class="card-body p-3 small">Recent work on automatic sequential metaphor detection has involved <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural networks</a> initialized with different pre-trained word embeddings and which are sometimes combined with hand engineered features. To capture lexical and orthographic information automatically, in this paper we propose to add character based word representation. Also, to contrast the difference between <a href=https://en.wikipedia.org/wiki/Literal_and_figurative_language>literal and contextual meaning</a>, we utilize a similarity network. We explore these components via two different architectures-a BiLSTM model and a Transformer Encoder model similar to BERT to perform metaphor identification. We participate in the Second Shared Task on Metaphor Detection on both the VUA and TOFEL datasets with the above models. The experimental results demonstrate the effectiveness of our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> as it outperforms all the <a href=https://en.wikipedia.org/wiki/System>systems</a> which participated in the previous shared task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.20.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--20 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.20 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929717 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.20/>Recognizing Euphemisms and Dysphemisms Using <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a></a></strong><br><a href=/people/c/christian-felt/>Christian Felt</a>
|
<a href=/people/e/ellen-riloff/>Ellen Riloff</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--20><div class="card-body p-3 small">This paper presents the first research aimed at recognizing euphemistic and dysphemistic phrases with <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. Euphemisms soften references to topics that are sensitive, disagreeable, or taboo. Conversely, <a href=https://en.wikipedia.org/wiki/Dysphemism>dysphemisms</a> refer to sensitive topics in a harsh or rude way. For example, passed away and departed are <a href=https://en.wikipedia.org/wiki/Euphemism>euphemisms</a> for death, while croaked and six feet under are <a href=https://en.wikipedia.org/wiki/Dysphemism>dysphemisms</a> for death. Our work explores the use of <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> to recognize euphemistic and dysphemistic language. First, we identify near-synonym phrases for three topics (firing, lying, and stealing) using a bootstrapping algorithm for semantic lexicon induction. Next, we classify phrases as <a href=https://en.wikipedia.org/wiki/Euphemism>euphemistic</a>, dysphemistic, or neutral using <a href=https://en.wikipedia.org/wiki/Lexical_analysis>lexical sentiment cues</a> and contextual sentiment analysis. We introduce a new gold standard data set and present our experimental results for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.23.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--23 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.23 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.figlang-1.23.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.figlang-1.23.Dataset.pdf data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929711 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.23/>Generating Ethnographic Models from Communities’ Online Data</a></strong><br><a href=/people/t/tomek-strzalkowski/>Tomek Strzalkowski</a>
|
<a href=/people/a/anna-newheiser/>Anna Newheiser</a>
|
<a href=/people/n/nathan-kemper/>Nathan Kemper</a>
|
<a href=/people/n/ning-sa/>Ning Sa</a>
|
<a href=/people/b/bharvee-acharya/>Bharvee Acharya</a>
|
<a href=/people/g/gregorios-katsios/>Gregorios Katsios</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--23><div class="card-body p-3 small">In this paper we describe computational ethnography study to demonstrate how machine learning techniques can be utilized to exploit bias resident in language data produced by communities with online presence. Specifically, we leverage the use of <a href=https://en.wikipedia.org/wiki/Figurative_language>figurative language</a> (i.e., the choice of metaphors) in <a href=https://en.wikipedia.org/wiki/Online_and_offline>online text</a> (e.g., <a href=https://en.wikipedia.org/wiki/News_media>news media</a>, blogs) produced by distinct communities to obtain models of community worldviews that can be shown to be distinctly biased and thus different from other communities&#8217; models. We automatically construct metaphor-based community models for two distinct scenarios : <a href=https://en.wikipedia.org/wiki/Gun_politics_in_the_United_States>gun rights</a> and <a href=https://en.wikipedia.org/wiki/Same-sex_marriage_in_the_United_States>marriage equality</a>. We then conduct a series of experiments to validate the hypothesis that the <a href=https://en.wikipedia.org/wiki/Metaphor>metaphors</a> found in each community&#8217;s online language convey the bias in the community&#8217;s worldview.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.28.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--28 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.28 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.figlang-1.28/>Augmenting Neural Metaphor Detection with Concreteness</a></strong><br><a href=/people/g/ghadi-alnafesah/>Ghadi Alnafesah</a>
|
<a href=/people/h/harish-tayyar-madabushi/>Harish Tayyar Madabushi</a>
|
<a href=/people/m/mark-lee/>Mark Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--28><div class="card-body p-3 small">The idea that a shift in <a href=https://en.wikipedia.org/wiki/Concreteness>concreteness</a> within a sentence indicates the presence of a <a href=https://en.wikipedia.org/wiki/Metaphor>metaphor</a> has been around for a while. However, recent methods of detecting metaphor that have relied on <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural models</a> have ignored <a href=https://en.wikipedia.org/wiki/Concreteness>concreteness</a> and related psycholinguistic information. We hypothesis that this <a href=https://en.wikipedia.org/wiki/Information>information</a> is not available to these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> and that their addition will boost the performance of these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> in detecting <a href=https://en.wikipedia.org/wiki/Metaphor>metaphor</a>. We test this hypothesis on the Metaphor Detection Shared Task 2020 and find that the addition of concreteness information does in fact boost <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural models</a>. We also run tests on data from a previous <a href=https://en.wikipedia.org/wiki/Task_(computing)>shared task</a> and show similar results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.33.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--33 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.33 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929728 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.33/>Metaphor Detection using Ensembles of Bidirectional Recurrent Neural Networks</a></strong><br><a href=/people/j/jennifer-brooks/>Jennifer Brooks</a>
|
<a href=/people/a/abdou-youssef/>Abdou Youssef</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--33><div class="card-body p-3 small">In this paper we present our results from the Second Shared Task on Metaphor Detection, hosted by the Second Workshop on Figurative Language Processing. We use an ensemble of RNN models with bidirectional LSTMs and bidirectional attention mechanisms. Some of the <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> were trained on all parts of speech. Each of the other models was trained on one of four categories for <a href=https://en.wikipedia.org/wiki/Part_of_speech>parts of speech</a> : <a href=https://en.wikipedia.org/wiki/Noun>nouns</a>, <a href=https://en.wikipedia.org/wiki/Verb>verbs</a>, <a href=https://en.wikipedia.org/wiki/Adjective>adverbs / adjectives</a>, or other. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> were combined into voting pools and the voting pools were combined using the logical OR operator.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.35.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--35 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.35 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929730 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.35/>Testing the role of <a href=https://en.wikipedia.org/wiki/Metadata>metadata</a> in metaphor identification</a></strong><br><a href=/people/e/egon-stemle/>Egon Stemle</a>
|
<a href=/people/a/alexander-onysko/>Alexander Onysko</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--35><div class="card-body p-3 small">This paper describes the adaptation and application of a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network system</a> for the automatic detection of metaphors. The LSTM BiRNN system participated in the shared task of metaphor identification that was part of the Second Workshop of Figurative Language Processing (FigLang2020) held at the Annual Conference of the Association for Computational Linguistics (ACL2020). The particular focus of our approach is on the potential influence that the <a href=https://en.wikipedia.org/wiki/Metadata>metadata</a> given in the ETS Corpus of Non-Native Written English might have on the automatic detection of metaphors in this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. The article first discusses the annotated ETS learner data, highlighting some of its peculiarities and inherent biases of metaphor use. A series of evaluations follow in order to test whether specific <a href=https://en.wikipedia.org/wiki/Metadata>metadata</a> influence the <a href=https://en.wikipedia.org/wiki/System>system</a> performance in the task of automatic metaphor identification. The <a href=https://en.wikipedia.org/wiki/System>system</a> is available under the APLv2 open-source license.</div></div></div><hr><div id=2020framenet-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.framenet-1/>Proceedings of the International FrameNet Workshop 2020: Towards a Global, Multilingual FrameNet</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.framenet-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.framenet-1.0/>Proceedings of the International FrameNet Workshop 2020: Towards a Global, Multilingual FrameNet</a></strong><br><a href=/people/t/tiago-timponi-torrent/>Tiago T. Torrent</a>
|
<a href=/people/c/collin-f-baker/>Collin F. Baker</a>
|
<a href=/people/o/oliver-czulo/>Oliver Czulo</a>
|
<a href=/people/k/kyoko-ohara/>Kyoko Ohara</a>
|
<a href=/people/m/miriam-r-l-petruck/>Miriam R. L. Petruck</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.framenet-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--framenet-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.framenet-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.framenet-1.2/>Finding Corresponding Constructions in <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a> in a TED Talk Parallel Corpus using Frames-and-Constructions Analysis<span class=acl-fixed-case>E</span>nglish and <span class=acl-fixed-case>J</span>apanese in a <span class=acl-fixed-case>TED</span> Talk Parallel Corpus using Frames-and-Constructions Analysis</a></strong><br><a href=/people/k/kyoko-ohara/>Kyoko Ohara</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--framenet-1--2><div class="card-body p-3 small">This paper reports on an effort to search for corresponding constructions in <a href=https://en.wikipedia.org/wiki/English_language>English</a> and <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a> in a TED Talk parallel corpus, using frames-and-constructions analysis (Ohara, 2019 ; Ohara and Okubo, 2020 ; cf. Czulo, 2013, 2017). The purpose of the paper is two-fold : (1) to demonstrate the validity of frames-and-constructions analysis to search for corresponding constructions in typologically unrelated languages ; and (2) to assess whether the Do schools kill creativity? TED Talk parallel corpus, annotated in various languages for Multilingual FrameNet, is a good starting place for building a multilingual constructicon. The analysis showed that similar to our previous findings involving texts in a Japanese to English bilingual children&#8217;s book, the TED Talk bilingual transcripts include pairs of constructions that share similar pragmatic functions. While the TED Talk parallel corpus constitutes a good resource for frame semantic annotation in multiple languages, it may not be the ideal place to start aligning constructions among typologically unrelated languages. Finally, this work shows that the proposed method, which focuses on heads of sentences, seems valid for searching for corresponding constructions in transcripts of spoken data, as well as in written data of typologically-unrelated languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.framenet-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--framenet-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.framenet-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.framenet-1.7/>Greek within the Global FrameNet Initiative : Challenges and Conclusions so far<span class=acl-fixed-case>G</span>reek within the Global <span class=acl-fixed-case>F</span>rame<span class=acl-fixed-case>N</span>et Initiative: Challenges and Conclusions so far</a></strong><br><a href=/people/v/voula-giouli/>Voula Giouli</a>
|
<a href=/people/v/vera-pilitsidou/>Vera Pilitsidou</a>
|
<a href=/people/h/hephaestion-christopoulos/>Hephaestion Christopoulos</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--framenet-1--7><div class="card-body p-3 small">Large coverage lexical resources that bear deep linguistic information have always been considered useful for many natural language processing (NLP) applications including Machine Translation (MT). In this respect, Frame-based resources have been developed for many languages following Frame Semantics and the Berkeley FrameNet project. However, to a great extent, all those efforts have been kept fragmented. Consequentially, the Global FrameNet initiative has been conceived of as a joint effort to bring together <a href=https://en.wikipedia.org/wiki/FrameNet>FrameNets</a> in different languages. The proposed paper is aimed at describing ongoing work towards developing the Greek (EL) counterpart of the Global FrameNet and our efforts to contribute to the Shared Annotation Task. In the paper, we will elaborate on the <a href=https://en.wikipedia.org/wiki/Annotation>annotation methodology</a> employed, the current status and progress made so far, as well as the problems raised during <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.framenet-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--framenet-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.framenet-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.framenet-1.11/>Exploring Crosslinguistic Frame Alignment</a></strong><br><a href=/people/c/collin-f-baker/>Collin F. Baker</a>
|
<a href=/people/a/arthur-lorenzi/>Arthur Lorenzi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--framenet-1--11><div class="card-body p-3 small">The FrameNet (FN) project at the International Computer Science Institute in Berkeley (ICSI), which documents the core vocabulary of contemporary English, was the first lexical resource based on Fillmore&#8217;s theory of <a href=https://en.wikipedia.org/wiki/Frame_semantics_(linguistics)>Frame Semantics</a>. Berkeley FrameNet has inspired related projects in roughly a dozen other languages, which have evolved somewhat independently ; the current Multilingual FrameNet project (MLFN) is an attempt to find alignments between all of them. The alignment problem is complicated by the fact that these projects have adhered to the Berkeley FrameNet model to varying degrees, and they were also founded at different times, when different versions of the Berkeley FrameNet data were available. We describe several new <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> for finding relations of similarity between semantic frames across languages. We will demonstrate ViToXF, a new tool which provides interactive visualizations of these cross-lingual relations, between frames, lexical units, and frame elements, based on resources such as multilingual dictionaries and on shared distributional vector spaces, making clear the strengths and weaknesses of different alignment methods.</div></div></div><hr><div id=2020gamnlp-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.gamnlp-1/>Workshop on Games and Natural Language Processing</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.gamnlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.gamnlp-1.0/>Workshop on Games and Natural Language Processing</a></strong><br><a href=/people/s/stephanie-lukin/>Stephanie M. Lukin</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.gamnlp-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--gamnlp-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.gamnlp-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.gamnlp-1.1/>Creating a Sentiment Lexicon with Game-Specific Words for Analyzing NPC Dialogue in The Elder Scrolls V : Skyrim<span class=acl-fixed-case>NPC</span> Dialogue in The Elder Scrolls <span class=acl-fixed-case>V</span>: Skyrim</a></strong><br><a href=/people/t/therese-bergsma/>Thérèse Bergsma</a>
|
<a href=/people/j/judith-van-stegeren/>Judith van Stegeren</a>
|
<a href=/people/m/mariet-theune/>Mariët Theune</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--gamnlp-1--1><div class="card-body p-3 small">A weak point of rule-based sentiment analysis systems is that the underlying sentiment lexicons are often not adapted to the domain of the text we want to analyze. We created a game-specific sentiment lexicon for video game Skyrim based on the E-ANEW word list and a dataset of Skyrim&#8217;s in-game documents. We calculated sentiment ratings for NPC dialogue using both our <a href=https://en.wikipedia.org/wiki/Lexicon>lexicon</a> and E-ANEW and compared the resulting sentiment ratings to those of human raters. Both lexicons perform comparably well on our evaluation dialogues, but the game-specific extension performs slightly better on the dominance dimension for dialogue segments and the arousal dimension for full dialogues. To our knowledge, this is the first time that a <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis lexicon</a> has been adapted to the <a href=https://en.wikipedia.org/wiki/Video_game>video game domain</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.gamnlp-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--gamnlp-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.gamnlp-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.gamnlp-1.2/>ClueMeIn : Obtaining More Specific Image Labels Through a Game<span class=acl-fixed-case>C</span>lue<span class=acl-fixed-case>M</span>e<span class=acl-fixed-case>I</span>n: Obtaining More Specific Image Labels Through a Game</a></strong><br><a href=/people/c/christopher-harris/>Christopher Harris</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--gamnlp-1--2><div class="card-body p-3 small">The <a href=https://en.wikipedia.org/wiki/ESP_Game>ESP Game</a> (also known as the Google Image Labeler) demonstrated how the crowd could perform a task that is straightforward for humans but challenging for computers providing labels for images. The game facilitated the task of basic image labeling ; however, the labels generated were non-specific and limited the ability to distinguish similar images from one another, limiting its ability in search tasks, annotating images for the visually impaired, and training computer vision machine algorithms. In this paper, we describe ClueMeIn, an entertaining web-based game with a purpose that generates more detailed image labels than the <a href=https://en.wikipedia.org/wiki/ESP_Game>ESP Game</a>. We conduct experiments to generate specific image labels, show how the results can lead to improvements in the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of image searches over image labels generated by the <a href=https://en.wikipedia.org/wiki/ESP_Game>ESP Game</a> when using the same public dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.gamnlp-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--gamnlp-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.gamnlp-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.gamnlp-1.3/>Cipher : A Prototype Game-with-a-Purpose for Detecting Errors in Text<span class=acl-fixed-case>C</span>ipher: A Prototype Game-with-a-Purpose for Detecting Errors in Text</a></strong><br><a href=/people/l/liang-xu/>Liang Xu</a>
|
<a href=/people/j/jon-chamberlain/>Jon Chamberlain</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--gamnlp-1--3><div class="card-body p-3 small">Errors commonly exist in machine-generated documents and publication materials ; however, some correction algorithms do not perform well for complex errors and it is costly to employ humans to do the task. To solve the problem, a prototype <a href=https://en.wikipedia.org/wiki/PC_game>computer game</a> called Cipher was developed that encourages people to identify errors in text. Gamification is achieved by introducing the idea of <a href=https://en.wikipedia.org/wiki/Steganography>steganography</a> as the entertaining game element. People play the <a href=https://en.wikipedia.org/wiki/Game>game</a> for entertainment while they make valuable annotations to locate <a href=https://en.wikipedia.org/wiki/Typographical_error>text errors</a>. The <a href=https://en.wikipedia.org/wiki/Prototype>prototype</a> was tested by 35 players in a evaluation experiment, creating 4,764 annotations. After filtering the data, the <a href=https://en.wikipedia.org/wiki/System>system</a> detected manually introduced text errors and also genuine errors in the texts that were not noticed when they were introduced into the <a href=https://en.wikipedia.org/wiki/Game>game</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.gamnlp-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--gamnlp-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.gamnlp-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.gamnlp-1.4/>Game Design Evaluation of GWAPs for Collecting Word Associations<span class=acl-fixed-case>GWAP</span>s for Collecting Word Associations</a></strong><br><a href=/people/m/mathieu-lafourcade/>Mathieu Lafourcade</a>
|
<a href=/people/l/le-brun-nathalie/>Le Brun Nathalie</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--gamnlp-1--4><div class="card-body p-3 small">GWAP design might have a tremendous effect on its popularity of course but also on the quality of the data collected. In this paper, a comparison is undertaken between two GWAPs for building term association lists, namely JeuxDeMots and Quicky Goose. After comparing both game designs, the <a href=https://en.wikipedia.org/wiki/Cohen_kappa>Cohen kappa</a> of associative lists in various configurations is computed in order to assess likeness and differences of the data they provide.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.gamnlp-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--gamnlp-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.gamnlp-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.gamnlp-1.5/>The Challenge of the <a href=https://en.wikipedia.org/wiki/Game_show>TV game</a> La Ghigliottina to NLP<span class=acl-fixed-case>TV</span> game La Ghigliottina to <span class=acl-fixed-case>NLP</span></a></strong><br><a href=/people/f/federico-sangati/>Federico Sangati</a>
|
<a href=/people/a/antonio-pascucci/>Antonio Pascucci</a>
|
<a href=/people/j/johanna-monti/>Johanna Monti</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--gamnlp-1--5><div class="card-body p-3 small">In this paper, we describe a Telegram bot, Mago della Ghigliottina (Ghigliottina Wizard), able to solve La Ghigliottina game (The Guillotine), the final game of the Italian TV quiz show L&#8217;Eredit. Our system relies on <a href=https://en.wikipedia.org/wiki/Natural_language_processing>linguistic resources</a> and <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>artificial intelligence</a> and achieves better results than human players (and competitors of L&#8217;Eredit too). In addition to solving a <a href=https://en.wikipedia.org/wiki/Game>game</a>, Mago della Ghigliottina can also generate new <a href=https://en.wikipedia.org/wiki/Game>game instances</a> and challenge the users to match the solution.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.gamnlp-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--gamnlp-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.gamnlp-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.gamnlp-1.6/>A 3D Role-Playing Game for Abusive Language Annotation<span class=acl-fixed-case>D</span> Role-Playing Game for Abusive Language Annotation</a></strong><br><a href=/people/f/federico-bonetti/>Federico Bonetti</a>
|
<a href=/people/s/sara-tonelli/>Sara Tonelli</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--gamnlp-1--6><div class="card-body p-3 small">Gamification has been applied to many linguistic annotation tasks, as an alternative to <a href=https://en.wikipedia.org/wiki/Crowdsourcing>crowdsourcing platforms</a> to collect annotated data in an inexpensive way. However, we think that still much has to be explored. Games with a Purpose (GWAPs) tend to lack important elements that we commonly see in commercial games, such as 2D and 3D worlds or a <a href=https://en.wikipedia.org/wiki/Plot_(narrative)>story</a>. Making GWAPs more similar to full-fledged video games in order to involve users more easily and increase dissemination is a demanding yet interesting ground to explore. In this paper we present a <a href=https://en.wikipedia.org/wiki/Role-playing_video_game>3D role-playing game</a> for abusive language annotation that is currently under development.</div></div></div><hr><div id=2020globalex-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.globalex-1/>Proceedings of the 2020 Globalex Workshop on Linked Lexicography</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.globalex-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.globalex-1.0/>Proceedings of the 2020 Globalex Workshop on Linked Lexicography</a></strong><br><a href=/people/i/ilan-kernerman/>Ilan Kernerman</a>
|
<a href=/people/s/simon-krek/>Simon Krek</a>
|
<a href=/people/j/john-philip-mccrae/>John P. McCrae</a>
|
<a href=/people/j/jorge-gracia/>Jorge Gracia</a>
|
<a href=/people/s/sina-ahmadi/>Sina Ahmadi</a>
|
<a href=/people/b/besim-kabashi/>Besim Kabashi</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.globalex-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--globalex-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.globalex-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.globalex-1.1/>Modelling Frequency and Attestations for OntoLex-Lemon<span class=acl-fixed-case>O</span>nto<span class=acl-fixed-case>L</span>ex-Lemon</a></strong><br><a href=/people/c/christian-chiarcos/>Christian Chiarcos</a>
|
<a href=/people/m/maxim-ionov/>Maxim Ionov</a>
|
<a href=/people/j/jesse-de-does/>Jesse de Does</a>
|
<a href=/people/k/katrien-depuydt/>Katrien Depuydt</a>
|
<a href=/people/f/fahad-khan/>Anas Fahad Khan</a>
|
<a href=/people/s/sander-stolk/>Sander Stolk</a>
|
<a href=/people/t/thierry-declerck/>Thierry Declerck</a>
|
<a href=/people/j/john-philip-mccrae/>John Philip McCrae</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--globalex-1--1><div class="card-body p-3 small">The OntoLex vocabulary enjoys increasing popularity as a means of publishing lexical resources with <a href=https://en.wikipedia.org/wiki/Resource_Description_Framework>RDF</a> and as <a href=https://en.wikipedia.org/wiki/Linked_data>Linked Data</a>. The recent publication of a new OntoLex module for <a href=https://en.wikipedia.org/wiki/Lexicography>lexicography</a>, lexicog, reflects its increasing importance for digital lexicography. However, not all aspects of digital lexicography have been covered to the same extent. In particular, supplementary information drawn from <a href=https://en.wikipedia.org/wiki/Text_corpus>corpora</a> such as frequency information, links to attestations, and collocation data were considered to be beyond the scope of lexicog. Therefore, the OntoLex community has put forward the proposal for a novel module for frequency, attestation and corpus information (FrAC), that not only covers the requirements of digital lexicography, but also accommodates essential data structures for lexical information in <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. This paper introduces the current state of the OntoLex-FrAC vocabulary, describes its structure, some selected use cases, elementary concepts and fundamental definitions, with a focus on frequency and attestations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.globalex-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--globalex-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.globalex-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.globalex-1.5/>Towards an Extension of the Linking of the Open Dutch WordNet with Dutch Lexicographic Resources<span class=acl-fixed-case>D</span>utch <span class=acl-fixed-case>W</span>ord<span class=acl-fixed-case>N</span>et with <span class=acl-fixed-case>D</span>utch Lexicographic Resources</a></strong><br><a href=/people/t/thierry-declerck/>Thierry Declerck</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--globalex-1--5><div class="card-body p-3 small">This extended abstract presents on-going work consisting in interlinking and merging the Open Dutch WordNet and generic lexicographic resources for <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch</a>, focusing for now on the Dutch and English versions of <a href=https://en.wikipedia.org/wiki/Wiktionary>Wiktionary</a> and using the Algemeen Nederlands Woordenboek as a quality checking instance. As the Open Dutch WordNet is already equipped with a relevant number of complex lexical units, we are aiming at expanding it and proposing a new representational framework for the encoding of the interlinked and integrated data. The longer term goal of the work is to investigate if and on how senses can be restricted to particular morphological variations of Dutch lexical entries, and how to represent this information in a Linguistic Linked Open Data compliant format.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.globalex-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--globalex-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.globalex-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.globalex-1.6/>Widening the Discussion on False Friends in Multilingual Wordnets<span class=acl-fixed-case>F</span>riends” in Multilingual Wordnets</a></strong><br><a href=/people/h/hugo-goncalo-oliveira/>Hugo Gonçalo Oliveira</a>
|
<a href=/people/a/ana-luis/>Ana Luís</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--globalex-1--6><div class="card-body p-3 small">There are wordnets in many languages, many aligned with Princeton WordNet, some of which in a (semi-)automatic process, but we rarely see actual discussions on the role of false friends in this process. Having in mind known issues related to such words in <a href=https://en.wikipedia.org/wiki/Translation>language translation</a>, and further motivated by false friend-related issues on the alignment of a Portuguese wordnet with Princeton Wordnet, we aim to widen this discussion, while suggesting preliminary ideas of how wordnets could benefit from this kind of research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.globalex-1.8.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--globalex-1--8 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.globalex-1.8 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.globalex-1.8/>Building Sense Representations in <a href=https://en.wikipedia.org/wiki/Danish_language>Danish</a> by Combining Word Embeddings with Lexical Resources<span class=acl-fixed-case>D</span>anish by Combining Word Embeddings with Lexical Resources</a></strong><br><a href=/people/i/ida-rormann-olsen/>Ida Rørmann Olsen</a>
|
<a href=/people/b/bolette-sandford-pedersen/>Bolette Pedersen</a>
|
<a href=/people/a/asad-sayeed/>Asad Sayeed</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--globalex-1--8><div class="card-body p-3 small">Our aim is to identify suitable sense representations for <a href=https://en.wikipedia.org/wiki/Neuro-linguistic_programming>NLP</a> in <a href=https://en.wikipedia.org/wiki/Danish_language>Danish</a>. We investigate sense inventories that correlate with human interpretations of word meaning and <a href=https://en.wikipedia.org/wiki/Ambiguity>ambiguity</a> as typically described in dictionaries and wordnets and that are well reflected distributionally as expressed in <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a>. To this end, we study a number of highly ambiguous Danish nouns and examine the effectiveness of sense representations constructed by combining <a href=https://en.wikipedia.org/wiki/Vector_space>vectors</a> from a <a href=https://en.wikipedia.org/wiki/Distribution_(mathematics)>distributional model</a> with the information from a <a href=https://en.wikipedia.org/wiki/Wordnet>wordnet</a>. We establish <a href=https://en.wikipedia.org/wiki/Representation_(arts)>representations</a> based on centroids obtained from wordnet synests and example sentences as well as <a href=https://en.wikipedia.org/wiki/Representation_(arts)>representations</a> established via are tested in a word sense disambiguation task. We conclude that the more information extracted from the wordnet entries (example sentence, definition, semantic relations) the more successful the sense representation vector.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.globalex-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--globalex-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.globalex-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.globalex-1.16/>Translation Inference by Concept Propagation</a></strong><br><a href=/people/c/christian-chiarcos/>Christian Chiarcos</a>
|
<a href=/people/n/niko-schenk/>Niko Schenk</a>
|
<a href=/people/c/christian-fath/>Christian Fäth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--globalex-1--16><div class="card-body p-3 small">This paper describes our contribution to the Third Shared Task on Translation Inference across Dictionaries (TIAD-2020). We describe an approach on translation inference based on <a href=https://en.wikipedia.org/wiki/Computer_algebra>symbolic methods</a>, the propagation of concepts over a graph of interconnected dictionaries : Given a mapping from source language words to <a href=https://en.wikipedia.org/wiki/Lexical_item>lexical concepts</a> (e.g., synsets) as a seed, we use <a href=https://en.wikipedia.org/wiki/Bilingual_dictionary>bilingual dictionaries</a> to extrapolate a mapping of pivot and target language words to these <a href=https://en.wikipedia.org/wiki/Lexical_item>lexical concepts</a>. Translation inference is then performed by looking up the lexical concept(s) of a source language word and returning the target language word(s) for which these lexical concepts have the respective highest score. We present two instantiations of this system : One using WordNet synsets as <a href=https://en.wikipedia.org/wiki/Concept>concepts</a>, and one using lexical entries (translations) as <a href=https://en.wikipedia.org/wiki/Concept>concepts</a>. With a threshold of 0, the latter <a href=https://en.wikipedia.org/wiki/Computer_configuration>configuration</a> is the second among participant systems in terms of <a href=https://en.wikipedia.org/wiki/F1_score>F1 score</a>. We also describe additional evaluation experiments on Apertium data, a comparison with an earlier approach based on embedding projection, and an approach for constrained projection that outperforms the TIAD-2020 vanilla system by a large margin.</div></div></div><hr><div id=2020isa-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.isa-1/>16th Joint ACL - ISO Workshop on Interoperable Semantic Annotation PROCEEDINGS</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.isa-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.isa-1.0/>16th Joint ACL - ISO Workshop on Interoperable Semantic Annotation PROCEEDINGS</a></strong><br><a href=/people/h/harry-bunt/>Harry Bunt</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.isa-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--isa-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.isa-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.isa-1.5/>Annotation-based Semantics</a></strong><br><a href=/people/k/kiyong-lee/>Kiyong Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--isa-1--5><div class="card-body p-3 small">This paper proposes a semantics ABS for the model-theoretic interpretation of annotation structures. It provides a language ABSr, that represents semantic forms in a (possibly -free) type-theoretic first-order logic. For semantic compositionality, the representation language introduces two operators and with subtypes for the conjunctive or distributive composition of semantic forms. ABS also introduces a small set of <a href=https://en.wikipedia.org/wiki/Predicate_(mathematical_logic)>logical predicates</a> to represent semantic forms in a simplified format. The use of ABSr is illustrated with some annotation structures that conform to ISO 24617 standards on semantic annotation such as <a href=https://en.wikipedia.org/wiki/ISO-TimeML>ISO-TimeML</a> and ISO-Space.<i>semantic forms</i> in a (possibly <tex-math>\\lambda</tex-math>-free) type-theoretic first-order logic. For semantic compositionality, the representation language introduces two operators <tex-math>\\oplus</tex-math> and <tex-math>\\oslash</tex-math> with subtypes for the conjunctive or distributive composition of semantic forms. ABS also introduces a small set of logical predicates to represent semantic forms in a simplified format. The use of ABSr is illustrated with some annotation structures that conform to ISO 24617 standards on semantic annotation such as ISO-TimeML and ISO-Space.</div></div></div><hr><div id=2020iwltp-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.iwltp-1/>Proceedings of the 1st International Workshop on Language Technology Platforms</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwltp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.iwltp-1.0/>Proceedings of the 1st International Workshop on Language Technology Platforms</a></strong><br><a href=/people/g/georg-rehm/>Georg Rehm</a>
|
<a href=/people/k/kalina-bontcheva/>Kalina Bontcheva</a>
|
<a href=/people/k/khalid-choukri/>Khalid Choukri</a>
|
<a href=/people/j/jan-hajic/>Jan Hajič</a>
|
<a href=/people/s/stelios-piperidis/>Stelios Piperidis</a>
|
<a href=/people/a/andrejs-vasiljevs/>Andrejs Vasiļjevs</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwltp-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwltp-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwltp-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.iwltp-1.5/>CLARIN : Distributed Language Resources and Technology in a European Infrastructure<span class=acl-fixed-case>CLARIN</span>: Distributed Language Resources and Technology in a <span class=acl-fixed-case>E</span>uropean Infrastructure</a></strong><br><a href=/people/m/maria-eskevich/>Maria Eskevich</a>
|
<a href=/people/f/franciska-de-jong/>Franciska de Jong</a>
|
<a href=/people/a/alexander-konig/>Alexander König</a>
|
<a href=/people/d/darja-fiser/>Darja Fišer</a>
|
<a href=/people/d/dieter-van-uytvanck/>Dieter Van Uytvanck</a>
|
<a href=/people/t/tero-aalto/>Tero Aalto</a>
|
<a href=/people/l/lars-borin/>Lars Borin</a>
|
<a href=/people/o/olga-gerassimenko/>Olga Gerassimenko</a>
|
<a href=/people/j/jan-hajic/>Jan Hajic</a>
|
<a href=/people/h/henk-van-den-heuvel/>Henk van den Heuvel</a>
|
<a href=/people/n/neeme-kahusk/>Neeme Kahusk</a>
|
<a href=/people/k/krista-liin/>Krista Liin</a>
|
<a href=/people/m/martin-matthiesen/>Martin Matthiesen</a>
|
<a href=/people/s/stelios-piperidis/>Stelios Piperidis</a>
|
<a href=/people/k/kadri-vider/>Kadri Vider</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwltp-1--5><div class="card-body p-3 small">CLARIN is a European Research Infrastructure providing access to digital language resources and tools from across Europe and beyond to researchers in the humanities and social sciences. This paper focuses on <a href=https://en.wikipedia.org/wiki/CLARIN>CLARIN</a> as a platform for the sharing of language resources. It zooms in on the service offer for the aggregation of language repositories and the value proposition for a number of communities that benefit from the enhanced visibility of their data and services as a result of integration in <a href=https://en.wikipedia.org/wiki/CLARIN>CLARIN</a>. The enhanced findability of language resources is serving the social sciences and humanities (SSH) community at large and supports research communities that aim to collaborate based on virtual collections for a specific domain. The paper also addresses the wider landscape of service platforms based on language technologies which has the potential of becoming a powerful set of interoperable facilities to a variety of communities of use.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwltp-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwltp-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwltp-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.iwltp-1.7/>Removing European Language Barriers with Innovative Machine Translation Technology<span class=acl-fixed-case>E</span>uropean Language Barriers with Innovative Machine Translation Technology</a></strong><br><a href=/people/d/dario-franceschini/>Dario Franceschini</a>
|
<a href=/people/c/chiara-canton/>Chiara Canton</a>
|
<a href=/people/i/ivan-simonini/>Ivan Simonini</a>
|
<a href=/people/a/armin-schweinfurth/>Armin Schweinfurth</a>
|
<a href=/people/a/adelheid-glott/>Adelheid Glott</a>
|
<a href=/people/s/sebastian-stuker/>Sebastian Stüker</a>
|
<a href=/people/t/thai-son-nguyen/>Thai-Son Nguyen</a>
|
<a href=/people/f/felix-schneider/>Felix Schneider</a>
|
<a href=/people/t/thanh-le-ha/>Thanh-Le Ha</a>
|
<a href=/people/a/alex-waibel/>Alex Waibel</a>
|
<a href=/people/b/barry-haddow/>Barry Haddow</a>
|
<a href=/people/p/philip-williams/>Philip Williams</a>
|
<a href=/people/r/rico-sennrich/>Rico Sennrich</a>
|
<a href=/people/o/ondrej-bojar/>Ondřej Bojar</a>
|
<a href=/people/s/sangeet-sagar/>Sangeet Sagar</a>
|
<a href=/people/d/dominik-machacek/>Dominik Macháček</a>
|
<a href=/people/o/otakar-smrz/>Otakar Smrž</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwltp-1--7><div class="card-body p-3 small">This paper presents our progress towards deploying a versatile communication platform in the task of highly multilingual live speech translation for <a href=https://en.wikipedia.org/wiki/Convention_(meeting)>conferences</a> and remote meetings live subtitling. The <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a> has been designed with a focus on very low latency and high flexibility while allowing research prototypes of speech and text processing tools to be easily connected, regardless of where they physically run. We outline our architecture solution and also briefly compare it with the ELG platform. Technical details are provided on the most important components and we summarize the test deployment events we ran so far.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwltp-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwltp-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwltp-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.iwltp-1.9/>The Kairntech Sherpa An ML Platform and <a href=https://en.wikipedia.org/wiki/Application_programming_interface>API</a> for the Enrichment of (not only) Scientific Content<span class=acl-fixed-case>K</span>airntech <span class=acl-fixed-case>S</span>herpa – An <span class=acl-fixed-case>ML</span> Platform and <span class=acl-fixed-case>API</span> for the Enrichment of (not only) Scientific Content</a></strong><br><a href=/people/s/stefan-geissler/>Stefan Geißler</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwltp-1--9><div class="card-body p-3 small">We present an <a href=https://en.wikipedia.org/wiki/Computing_platform>software platform</a> and <a href=https://en.wikipedia.org/wiki/Application_programming_interface>API</a> that combines various ML and NLP approaches for the analysis and enrichment of textual content. The <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a>&#8217;s design and implementation is guided by the goal to allow non-technical users to conduct their own experiments and training runs on their respective data, allowing to test, tune and deploy analysis models for production. Dedicated specific packages for subtasks such as document structure processing, document categorization, annotation with existing thesauri, disambiguation and linking, annotation with newly created entity recognizers and summarization available as open source components in isolation are combined into an end-user-facing, collaborative, scalable platform to support large-scale industrial document analysis document analysis. We see the Sherpa&#8217;s setup as an answer to the observation that ML has reached a level of maturity that allows to attain useful results in many analysis scenarios today, but that in-depth technical competencies in the required fields of <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> and <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>AI</a> is often scarce ; a setup that focusses on non-technical domain-expert end-users can help to bring required analysis functionalities closer to the day-to-day reality in business contexts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwltp-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwltp-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwltp-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.iwltp-1.11/>NTeALan Dictionaries Platforms : An Example Of Collaboration-Based Model<span class=acl-fixed-case>NT</span>e<span class=acl-fixed-case>AL</span>an Dictionaries Platforms: An Example Of Collaboration-Based Model</a></strong><br><a href=/people/e/elvis-mboning/>Elvis Mboning</a>
|
<a href=/people/d/daniel-baleba/>Daniel Baleba</a>
|
<a href=/people/j/jean-marc-bassahak/>Jean Marc Bassahak</a>
|
<a href=/people/o/ornella-wandji/>Ornella Wandji</a>
|
<a href=/people/j/jules-assoumou/>Jules Assoumou</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwltp-1--11><div class="card-body p-3 small">Nowadays the scarcity and dispersion of open-source NLP resources and tools in and for <a href=https://en.wikipedia.org/wiki/Languages_of_Africa>African languages</a> make it difficult for researchers to truly fit these <a href=https://en.wikipedia.org/wiki/Language>languages</a> into current algorithms of <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>artificial intelligence</a>, resulting in the stagnation of these numerous <a href=https://en.wikipedia.org/wiki/Language>languages</a>, as far as technological progress is concerned. Created in 2017, with the aim of building communities of voluntary contributors around African native and/or national languages, cultures, <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP technologies</a> and <a href=https://en.wikipedia.org/wiki/Artificial_intelligence>artificial intelligence</a>, the NTeALan association has set up a series of web collaborative platforms intended to allow the aforementioned communities to create and manage their own lexicographic and linguistic resources. This paper aims at presenting the first versions of three lexicographic platforms that we developed in and for African languages : the REST / GraphQL API for saving lexicographic resources, the dictionary management platform and the collaborative dictionary platform. We also describe the <a href=https://en.wikipedia.org/wiki/Data_format>data representation format</a> used for these <a href=https://en.wikipedia.org/wiki/Resource_(computer_science)>resources</a>. After experimenting with a few dictionaries and looking at users feedback, we are convinced that only collaboration-based approaches and platforms can effectively respond to challenges of producing quality resources in and for African native and/or national languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwltp-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwltp-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwltp-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.iwltp-1.12/>A Workflow Manager for Complex NLP and Content Curation Workflows<span class=acl-fixed-case>NLP</span> and Content Curation Workflows</a></strong><br><a href=/people/j/julian-moreno-schneider/>Julian Moreno-Schneider</a>
|
<a href=/people/p/peter-bourgonje/>Peter Bourgonje</a>
|
<a href=/people/f/florian-kintzel/>Florian Kintzel</a>
|
<a href=/people/g/georg-rehm/>Georg Rehm</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwltp-1--12><div class="card-body p-3 small">We present a <a href=https://en.wikipedia.org/wiki/Workflow_management_system>workflow manager</a> for the flexible creation and customisation of NLP processing pipelines. The workflow manager addresses challenges in <a href=https://en.wikipedia.org/wiki/Interoperability>interoperability</a> across various different NLP tasks and hardware-based resource usage. Based on the four key principles of <a href=https://en.wikipedia.org/wiki/Generality>generality</a>, <a href=https://en.wikipedia.org/wiki/Flexibility_(engineering)>flexibility</a>, <a href=https://en.wikipedia.org/wiki/Scalability>scalability</a> and <a href=https://en.wikipedia.org/wiki/Efficiency>efficiency</a>, we present the first version of the workflow manager by providing details on its custom definition language, explaining the communication components and the general system architecture and setup. We currently implement the <a href=https://en.wikipedia.org/wiki/System>system</a>, which is grounded and motivated by real-world industry use cases in several innovation and transfer projects.</div></div></div><hr><div id=2020iwpt-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwpt-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.iwpt-1/>Proceedings of the 16th International Conference on Parsing Technologies and the IWPT 2020 Shared Task on Parsing into Enhanced Universal Dependencies</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwpt-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.iwpt-1.0/>Proceedings of the 16th International Conference on Parsing Technologies and the IWPT 2020 Shared Task on Parsing into Enhanced Universal Dependencies</a></strong><br><a href=/people/g/gosse-bouma/>Gosse Bouma</a>
|
<a href=/people/y/yuji-matsumoto/>Yuji Matsumoto</a>
|
<a href=/people/s/stephan-oepen/>Stephan Oepen</a>
|
<a href=/people/k/kenji-sagae/>Kenji Sagae</a>
|
<a href=/people/d/djame-seddah/>Djamé Seddah</a>
|
<a href=/people/w/weiwei-sun/>Weiwei Sun</a>
|
<a href=/people/a/anders-sogaard/>Anders Søgaard</a>
|
<a href=/people/r/reut-tsarfaty/>Reut Tsarfaty</a>
|
<a href=/people/d/daniel-zeman/>Dan Zeman</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwpt-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwpt-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwpt-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929668 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwpt-1.1/>Syntactic Parsing in Humans and Machines</a></strong><br><a href=/people/p/paola-merlo/>Paola Merlo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwpt-1--1><div class="card-body p-3 small">To process the syntactic structures of a language in ways that are compatible with human expectations, we need computational representations of lexical and syntactic properties that form the basis of human knowledge of words and sentences. Recent neural-network-based and distributed semantics techniques have developed systems of considerable practical success and impressive performance. As has been advocated by many, however, such <a href=https://en.wikipedia.org/wiki/System>systems</a> still lack human-like properties. In particular, linguistic, psycholinguistic and neuroscientific investigations have shown that human processing of sentences is sensitive to structure and unbounded relations. In the spirit of better understanding the structure building and long-distance properties of <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a>, I will present an overview of recent results on agreement and island effects in <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a> in several languages. While certain sets of results in the literature indicate that neural language models exhibit long-distance agreement abilities, other finer-grained investigation of how these effects are calculated indicates that that the similarity spaces they define do not correlate with human experimental results on intervention similarity in long-distance dependencies. This opens the way to reflections on how to better match the <a href=https://en.wikipedia.org/wiki/Syntax>syntactic properties</a> of <a href=https://en.wikipedia.org/wiki/Natural_language>natural languages</a> in the representations of neural models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwpt-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwpt-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwpt-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929672 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwpt-1.5/>Semi-supervised Parsing with a Variational Autoencoding Parser</a></strong><br><a href=/people/x/xiao-zhang/>Xiao Zhang</a>
|
<a href=/people/d/dan-goldwasser/>Dan Goldwasser</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwpt-1--5><div class="card-body p-3 small">We propose an end-to-end variational autoencoding parsing (VAP) model for semi-supervised graph-based projective dependency parsing. It encodes the input using <a href=https://en.wikipedia.org/wiki/Latent_variable_model>continuous latent variables</a> in a sequential manner by <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural networks (DNN)</a> that can utilize the contextual information, and reconstruct the input using a <a href=https://en.wikipedia.org/wiki/Generative_model>generative model</a>. The VAP model admits a unified structure with different <a href=https://en.wikipedia.org/wiki/Loss_function>loss functions</a> for labeled and unlabeled data with shared parameters. We conducted experiments on the WSJ data sets, showing the proposed model can use the unlabeled data to increase the performance on a limited amount of labeled data, on a par with a recently proposed semi-supervised parser with faster inference.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwpt-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwpt-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwpt-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929674 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.iwpt-1.7" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwpt-1.7/>Obfuscation for Privacy-preserving Syntactic Parsing</a></strong><br><a href=/people/z/zhifeng-hu/>Zhifeng Hu</a>
|
<a href=/people/s/serhii-havrylov/>Serhii Havrylov</a>
|
<a href=/people/i/ivan-titov/>Ivan Titov</a>
|
<a href=/people/s/shay-b-cohen/>Shay B. Cohen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwpt-1--7><div class="card-body p-3 small">The goal of <a href=https://en.wikipedia.org/wiki/Homomorphic_encryption>homomorphic encryption</a> is to encrypt data such that another party can operate on it without being explicitly exposed to the content of the original data. We introduce an idea for a privacy-preserving transformation on <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>natural language data</a>, inspired by <a href=https://en.wikipedia.org/wiki/Homomorphic_encryption>homomorphic encryption</a>. Our primary tool is <a href=https://en.wikipedia.org/wiki/Obfuscation>obfuscation</a>, relying on the properties of <a href=https://en.wikipedia.org/wiki/Natural_language>natural language</a>. Specifically, a given English text is obfuscated using a neural model that aims to preserve the syntactic relationships of the original sentence so that the obfuscated sentence can be parsed instead of the original one. The <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> works at the word level, and learns to obfuscate each word separately by changing it into a new word that has a similar syntactic role. The text obfuscated by our model leads to better performance on three syntactic parsers (two dependency and one constituency parsers) in comparison to an upper-bound random substitution baseline. More specifically, the results demonstrate that as more terms are obfuscated (by their part of speech), the substitution upper bound significantly degrades, while the neural model maintains a relatively high performing <a href=https://en.wikipedia.org/wiki/Parsing>parser</a>. All of this is done without much sacrifice of <a href=https://en.wikipedia.org/wiki/Privacy>privacy</a> compared to the random substitution upper bound. We also further analyze the results, and discover that the substituted words have similar <a href=https://en.wikipedia.org/wiki/Syntax>syntactic properties</a>, but different <a href=https://en.wikipedia.org/wiki/Semantics>semantic content</a>, compared to the original words.<i>obfuscation</i>, relying on the properties of natural language. Specifically, a given English text is obfuscated using a neural model that aims to preserve the syntactic relationships of the original sentence so that the obfuscated sentence can be parsed instead of the original one. The model works at the word level, and learns to obfuscate each word separately by changing it into a new word that has a similar syntactic role. The text obfuscated by our model leads to better performance on three syntactic parsers (two dependency and one constituency parsers) in comparison to an upper-bound random substitution baseline. More specifically, the results demonstrate that as more terms are obfuscated (by their part of speech), the substitution upper bound significantly degrades, while the neural model maintains a relatively high performing parser. All of this is done without much sacrifice of privacy compared to the random substitution upper bound. We also further analyze the results, and discover that the substituted words have similar syntactic properties, but different semantic content, compared to the original words.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwpt-1.8.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwpt-1--8 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwpt-1.8 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.iwpt-1.8.Dataset.pdf data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929675 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwpt-1.8/>Tensors over Semirings for Latent-Variable Weighted Logic Programs</a></strong><br><a href=/people/e/esma-balkir/>Esma Balkir</a>
|
<a href=/people/d/daniel-gildea/>Daniel Gildea</a>
|
<a href=/people/s/shay-b-cohen/>Shay B. Cohen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwpt-1--8><div class="card-body p-3 small">Semiring parsing is an elegant <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> for describing <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a> by using semiring weighted logic programs. In this paper we present a generalization of this <a href=https://en.wikipedia.org/wiki/Concept>concept</a> : latent-variable semiring parsing. With our framework, any <a href=https://en.wikipedia.org/wiki/Semiring>semiring weighted logic program</a> can be latentified by transforming weights from scalar values of a <a href=https://en.wikipedia.org/wiki/Semiring>semiring</a> to rank-n arrays, or tensors, of <a href=https://en.wikipedia.org/wiki/Semiring>semiring values</a>, allowing the modelling of latent-variable models within the <a href=https://en.wikipedia.org/wiki/Semiring>semiring parsing framework</a>. Semiring is too strong a notion when dealing with <a href=https://en.wikipedia.org/wiki/Tensor>tensors</a>, and we have to resort to a weaker structure : a partial semiring. We prove that this <a href=https://en.wikipedia.org/wiki/Generalization>generalization</a> preserves all the desired properties of the original semiring framework while strictly increasing its expressiveness.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwpt-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwpt-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwpt-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929678 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwpt-1.11/>Self-Training for Unsupervised Parsing with PRPN<span class=acl-fixed-case>PRPN</span></a></strong><br><a href=/people/a/anhad-mohananey/>Anhad Mohananey</a>
|
<a href=/people/k/katharina-kann/>Katharina Kann</a>
|
<a href=/people/s/samuel-bowman/>Samuel R. Bowman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwpt-1--11><div class="card-body p-3 small">Neural unsupervised parsing (UP) models learn to parse without access to syntactic annotations, while being optimized for another task like <a href=https://en.wikipedia.org/wiki/Language_model>language modeling</a>. In this work, we propose self-training for neural UP models : we leverage aggregated annotations predicted by copies of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> as supervision for future copies. To be able to use our model&#8217;s predictions during training, we extend a recent neural UP architecture, the PRPN (Shen et al., 2018a), such that it can be trained in a semi-supervised fashion. We then add examples with <a href=https://en.wikipedia.org/wiki/Parsing>parses</a> predicted by our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to our unlabeled UP training data. Our self-trained model outperforms the PRPN by 8.1 % <a href=https://en.wikipedia.org/wiki/F-number>F1</a> and the previous state of the art by 1.6 % <a href=https://en.wikipedia.org/wiki/F-number>F1</a>. In addition, we show that our <a href=https://en.wikipedia.org/wiki/Software_architecture>architecture</a> can also be helpful for semi-supervised parsing in ultra-low-resource settings.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwpt-1.19.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwpt-1--19 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwpt-1.19 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929686 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwpt-1.19/>Adaptation of Multilingual Transformer Encoder for Robust Enhanced Universal Dependency Parsing<span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependency Parsing</a></strong><br><a href=/people/h/han-he/>Han He</a>
|
<a href=/people/j/jinho-d-choi/>Jinho D. Choi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwpt-1--19><div class="card-body p-3 small">This paper presents our enhanced dependency parsing approach using transformer encoders, coupled with a simple yet powerful ensemble algorithm that takes advantage of both tree and graph dependency parsing. Two types of transformer encoders are compared, a multilingual encoder and language-specific encoders. Our dependency tree parsing (DTP) approach generates only primary dependencies to form trees whereas our dependency graph parsing (DGP) approach handles both primary and secondary dependencies to form graphs. Since DGP does not guarantee the generated graphs are acyclic, the ensemble algorithm is designed to add secondary arcs predicted by DGP to primary arcs predicted by DTP. Our results show that <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> using the multilingual encoder outperform ones using the language specific encoders for most languages. The ensemble models generally show higher labeled attachment score on enhanced dependencies (ELAS) than the DTP and DGP models. As the result, our best <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> rank the third place on the macro-average ELAS over 17 languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwpt-1.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwpt-1--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwpt-1.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929688 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwpt-1.21/>Linear Neural Parsing and Hybrid Enhancement for Enhanced Universal Dependencies<span class=acl-fixed-case>U</span>niversal <span class=acl-fixed-case>D</span>ependencies</a></strong><br><a href=/people/g/giuseppe-attardi/>Giuseppe Attardi</a>
|
<a href=/people/d/daniele-sartiano/>Daniele Sartiano</a>
|
<a href=/people/m/maria-simi/>Maria Simi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwpt-1--21><div class="card-body p-3 small">To accomplish the shared task on <a href=https://en.wikipedia.org/wiki/Dependency_grammar>dependency parsing</a> we explore the use of a linear transition-based neural dependency parser as well as a combination of three of them by means of a linear tree combination algorithm. We train separate <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> for each language on the shared task data. We compare our base <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> with two biaffine parsers and also present an ensemble combination of all five <a href=https://en.wikipedia.org/wiki/Parsing>parsers</a>, which achieves an average UAS 1.88 point lower than the top official submission. For producing the enhanced dependencies, we exploit a hybrid approach, coupling an algorithmic graph transformation of the dependency tree with predictions made by a multitask machine learning model.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.iwpt-1.23.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--iwpt-1--23 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.iwpt-1.23 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929690 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.iwpt-1.23/>How Much of Enhanced UD Is Contained in UD?<span class=acl-fixed-case>UD</span> Is Contained in <span class=acl-fixed-case>UD</span>?</a></strong><br><a href=/people/a/adam-ek/>Adam Ek</a>
|
<a href=/people/j/jean-philippe-bernardy/>Jean-Philippe Bernardy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--iwpt-1--23><div class="card-body p-3 small">In this paper, we present the submission of team CLASP to the IWPT 2020 Shared Task on parsing enhanced universal dependencies. We develop a tree-to-graph transformation algorithm based on dependency patterns. This <a href=https://en.wikipedia.org/wiki/Algorithm>algorithm</a> can transform gold UD trees to EUD graphs with an ELAS score of 81.55 and a EULAS score of 96.70. These results show that much of the information needed to construct EUD graphs from UD trees are present in the UD trees. Coupled with a standard UD parser, the method applies to the official test data and yields and ELAS score of 67.85 and a EULAS score is 80.18.</div></div></div><hr><div id=2020ldl-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.ldl-1/>Proceedings of the 7th Workshop on Linked Data in Linguistics (LDL-2020)</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ldl-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.ldl-1.0/>Proceedings of the 7th Workshop on Linked Data in Linguistics (LDL-2020)</a></strong><br><a href=/people/m/maxim-ionov/>Maxim Ionov</a>
|
<a href=/people/j/john-philip-mccrae/>John P. McCrae</a>
|
<a href=/people/c/christian-chiarcos/>Christian Chiarcos</a>
|
<a href=/people/t/thierry-declerck/>Thierry Declerck</a>
|
<a href=/people/j/julia-bosque-gil/>Julia Bosque-Gil</a>
|
<a href=/people/j/jorge-gracia/>Jorge Gracia</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ldl-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ldl-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ldl-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.ldl-1.2/>Transforming the Cologne Digital Sanskrit Dictionaries into OntoLex-Lemon<span class=acl-fixed-case>S</span>anskrit Dictionaries into <span class=acl-fixed-case>O</span>nto<span class=acl-fixed-case>L</span>ex-Lemon</a></strong><br><a href=/people/f/francisco-mondaca/>Francisco Mondaca</a>
|
<a href=/people/f/felix-rau/>Felix Rau</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ldl-1--2><div class="card-body p-3 small">The Cologne Digital Sanskrit Dictionaries (CDSD) is a large collection of complex digitized Sanskrit dictionaries, consisting of over thirty-five works, and is the most prominent collection of Sanskrit dictionaries worldwide. In this paper we evaluate two methods for transforming the <a href=https://en.wikipedia.org/wiki/Conformational_isomerism>CDSD</a> into Ontolex-Lemon based on a modelling exercise. The first method that we evaluate consists of applying <a href=https://en.wikipedia.org/wiki/RDFa>RDFa</a> to the existent TEI-P5 files. The second method consists of transforming the TEI-encoded dictionaries into new files containing RDF triples modelled in OntoLex-Lemon. As a result of the modelling exercise we choose the second method : to transform TEI-encoded lexical data into Ontolex-Lemon by creating new files containing exclusively RDF triples.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ldl-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ldl-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ldl-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.ldl-1.7/>Challenges of Word Sense Alignment : Portuguese Language Resources<span class=acl-fixed-case>P</span>ortuguese Language Resources</a></strong><br><a href=/people/a/ana-salgado/>Ana Salgado</a>
|
<a href=/people/s/sina-ahmadi/>Sina Ahmadi</a>
|
<a href=/people/a/alberto-simoes/>Alberto Simões</a>
|
<a href=/people/j/john-philip-mccrae/>John Philip McCrae</a>
|
<a href=/people/r/rute-costa/>Rute Costa</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ldl-1--7><div class="card-body p-3 small">This paper reports on an ongoing task of monolingual word sense alignment in which a comparative study between the Portuguese Academy of Sciences Dictionary and the Dicionrio Aberto is carried out in the context of the ELEXIS (European Lexicographic Infrastructure) project. Word sense alignment involves searching for matching senses within dictionary entries of different lexical resources and linking them, which poses significant challenges. The lexicographic criteria are not always entirely consistent within individual dictionaries and even less so across different projects where different options may have been assumed in terms of structure and especially wording techniques of <a href=https://en.wikipedia.org/wiki/Gloss_(annotation)>lexicographic glosses</a>. This hinders the task of <a href=https://en.wikipedia.org/wiki/Sensory_nervous_system>matching senses</a>. We aim to present our annotation workflow in <a href=https://en.wikipedia.org/wiki/Portuguese_language>Portuguese</a> using the <a href=https://en.wikipedia.org/wiki/Semantic_Web>Semantic Web technologies</a>. The results obtained are useful for the discussion within the community.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ldl-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ldl-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ldl-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.ldl-1.12/>Lexemes in <a href=https://en.wikipedia.org/wiki/Wikidata>Wikidata</a> : 2020 status<span class=acl-fixed-case>W</span>ikidata: 2020 status</a></strong><br><a href=/people/f/finn-nielsen/>Finn Nielsen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ldl-1--12><div class="card-body p-3 small">Wikidata now records data about <a href=https://en.wikipedia.org/wiki/Lexeme>lexemes</a>, senses and lexical forms and exposes them as <a href=https://en.wikipedia.org/wiki/Linguistic_Linked_Open_Data>Linguistic Linked Open Data</a>. Since <a href=https://en.wikipedia.org/wiki/Lexeme>lexemes</a> in <a href=https://en.wikipedia.org/wiki/Wikidata>Wikidata</a> was first established in 2018, this <a href=https://en.wikipedia.org/wiki/Data>data</a> has grown considerable in size. Links between <a href=https://en.wikipedia.org/wiki/Lexeme>lexemes</a> in different languages can be made, e.g., through a <a href=https://en.wikipedia.org/wiki/Morphological_derivation>derivation property</a> or <a href=https://en.wikipedia.org/wiki/Word_sense>senses</a>. We present some descriptive statistics about the lexemes of <a href=https://en.wikipedia.org/wiki/Wikidata>Wikidata</a>, focusing on the multilingual aspects and show that there are still relatively few multilingual links.</div></div></div><hr><div id=2020lincr-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.lincr-1/>Proceedings of the Second Workshop on Linguistic and Neurocognitive Resources</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lincr-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lincr-1.0/>Proceedings of the Second Workshop on Linguistic and Neurocognitive Resources</a></strong><br><a href=/people/e/emmanuele-chersoni/>Emmanuele Chersoni</a>
|
<a href=/people/b/barry-devereux/>Barry Devereux</a>
|
<a href=/people/c/chu-ren-huang/>Chu-Ren Huang</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lincr-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lincr-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lincr-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lincr-1.1/>Extrapolating Binder Style Word Embeddings to New Words</a></strong><br><a href=/people/j/jacob-turton/>Jacob Turton</a>
|
<a href=/people/d/david-vinson/>David Vinson</a>
|
<a href=/people/r/robert-smith/>Robert Smith</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lincr-1--1><div class="card-body p-3 small">Word embeddings such as Word2Vec not only uniquely identify words but also encode important semantic information about them. However, as single entities they are difficult to interpret and their individual dimensions do not have obvious meanings. A more intuitive and interpretable <a href=https://en.wikipedia.org/wiki/Feature_space>feature space</a> based on neural representations of words was presented by Binder and colleagues (2016) but is only available for a very limited vocabulary. Previous research (Utsumi, 2018) indicates that Binder features can be predicted for words from their embedding vectors (such as Word2Vec), but only looked at the original Binder vocabulary. This paper aimed to demonstrate that Binder features can effectively be predicted for a large number of new words and that the predicted values are sensible. The results supported this, showing that correlations between predicted feature values were consistent with those in the original Binder dataset. Additionally, vectors of predicted values performed comparatively to established embedding models in tests of word-pair semantic similarity. Being able to predict Binder feature space vectors for any number of new words opens up many uses not possible with the original vocabulary size.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lincr-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lincr-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lincr-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lincr-1.2/>Towards the First Dyslexic Font in Russian<span class=acl-fixed-case>R</span>ussian</a></strong><br><a href=/people/s/svetlana-alexeeva/>Svetlana Alexeeva</a>
|
<a href=/people/a/aleksandra-dobrego/>Aleksandra Dobrego</a>
|
<a href=/people/v/vladislav-zubov/>Vladislav Zubov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lincr-1--2><div class="card-body p-3 small">Texts comprise a large part of visual information that we process every day, so one of the tasks of <a href=https://en.wikipedia.org/wiki/Language_science>language science</a> is to make them more accessible. However, often the text design process is focused on the font size, but not on its type ; which might be crucial especially for the people with reading disabilities. The current paper represents a study on <a href=https://en.wikipedia.org/wiki/Accessibility>text accessibility</a> and the first attempt to create a research-based accessible font for <a href=https://en.wikipedia.org/wiki/Cyrillic_script>Cyrillic letters</a>. This resulted in the dyslexic-specific font, LexiaD. Its design rests on the reduction of inter-letter similarity of the <a href=https://en.wikipedia.org/wiki/Russian_alphabet>Russian alphabet</a>. In evaluation stage, dyslexic and non-dyslexic children were asked to read sentences from the Children version of the Russian Sentence Corpus. We tested the readability of LexiaD compared to PT Sans and PT Serif fonts. The results showed that all children had some advantage in letter feature extraction and information integration while reading in LexiaD, but <a href=https://en.wikipedia.org/wiki/Lexical_access>lexical access</a> was improved when sentences were rendered in <a href=https://en.wikipedia.org/wiki/PT_Sans>PT Sans</a> or <a href=https://en.wikipedia.org/wiki/PT_Serif>PT Serif</a>. Therefore, in several aspects, LexiaD proved to be faster to read and could be recommended to use by <a href=https://en.wikipedia.org/wiki/Dyslexia>dyslexics</a> who have visual deficiency or those who struggle with text understanding resulting in re-reading.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lincr-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lincr-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lincr-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lincr-1.6/>The Little Prince in 26 Languages : Towards a Multilingual Neuro-Cognitive Corpus</a></strong><br><a href=/people/s/sabrina-stehwien/>Sabrina Stehwien</a>
|
<a href=/people/l/lena-henke/>Lena Henke</a>
|
<a href=/people/j/john-hale/>John Hale</a>
|
<a href=/people/j/jonathan-brennan/>Jonathan Brennan</a>
|
<a href=/people/l/lars-meyer/>Lars Meyer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lincr-1--6><div class="card-body p-3 small">We present the Le Petit Prince Corpus (LPPC), a multi-lingual resource for research in (computational) psycho- and neurolinguistics. The <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> consists of the children&#8217;s story The Little Prince in 26 languages. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> is in the process of being built using state-of-the-art methods for <a href=https://en.wikipedia.org/wiki/Speech_processing>speech and language processing</a> and <a href=https://en.wikipedia.org/wiki/Electroencephalography>electroencephalography (EEG)</a>. The planned release of LPPC dataset will include raw text annotated with dependency graphs in the Universal Dependencies standard, a near-natural-sounding synthetic spoken subset as well as <a href=https://en.wikipedia.org/wiki/Electroencephalography>EEG recordings</a>. We will use this <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> for conducting <a href=https://en.wikipedia.org/wiki/Neurolinguistics>neurolinguistic studies</a> that generalize across a wide range of languages, overcoming <a href=https://en.wikipedia.org/wiki/Linguistic_typology>typological constraints</a> to traditional approaches. The planned release of the LPPC combines linguistic and EEG data for many languages using fully automatic methods, and thus constitutes a readily extendable resource that supports cross-linguistic and cross-disciplinary research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lincr-1.8.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lincr-1--8 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lincr-1.8 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lincr-1.8/>Sensorimotor Norms for 506 Russian Nouns<span class=acl-fixed-case>R</span>ussian Nouns</a></strong><br><a href=/people/a/alex-miklashevsky/>Alex Miklashevsky</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lincr-1--8><div class="card-body p-3 small">Embodied cognitive science suggested a number of <a href=https://en.wikipedia.org/wiki/Variable_(mathematics)>variables</a> describing our sensorimotor experience associated with different concepts : modality experience rating (i.e., relationship between words and images of a particular perceptive modalityvisual, auditory, haptic etc.), manipulability (the necessity for an object to interact with human hands in order to perform its function), vertical spatial localization. According to the embodied cognition theory, these semantic variables capture our <a href=https://en.wikipedia.org/wiki/Mental_representation>mental representations</a> and thus should influence <a href=https://en.wikipedia.org/wiki/Word_formation>word learning</a>, processing and <a href=https://en.wikipedia.org/wiki/Word_formation>production</a>. However, it is not clear how these new <a href=https://en.wikipedia.org/wiki/Variable_and_attribute_(research)>variables</a> are related to such traditional <a href=https://en.wikipedia.org/wiki/Variable_and_attribute_(research)>variables</a> as imageability, age of acquisition (AoA) and <a href=https://en.wikipedia.org/wiki/Word_frequency>word frequency</a>. In the presented database, normative data on the modality (visual, auditory, haptic, olfactory, and gustatory) ratings, vertical spatial localization of the object, manipulability, imageability, age of acquisition, and subjective frequency for 506 Russian nouns are collected. Factor analysis revealed four factors : (1) visual and haptic modality ratings were combined with imageability, manipulability and AoA ; (2) word length, frequency and AoA ; (3) olfactory modality was united with gustatory ; (4) spatial localization only was included in the fourth factor. The database is available online together with a publication describing the method of data collection and data parameters (Miklashevsky, 2018).</div></div></div><hr><div id=2020lr4sshoc-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.lr4sshoc-1/>Proceedings of the Workshop about Language Resources for the SSH Cloud</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lr4sshoc-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lr4sshoc-1.0/>Proceedings of the Workshop about Language Resources for the SSH Cloud</a></strong><br><a href=/people/d/daan-broeder/>Daan Broeder</a>
|
<a href=/people/m/maria-eskevich/>Maria Eskevich</a>
|
<a href=/people/m/monica-monachini/>Monica Monachini</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lr4sshoc-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lr4sshoc-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lr4sshoc-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lr4sshoc-1.5/>Mining Wages in Nineteenth-Century Job Advertisements. The Application of Language Resources and Language Technology to study Economic and Social Inequality</a></strong><br><a href=/people/r/ruben-ros/>Ruben Ros</a>
|
<a href=/people/m/marieke-van-erp/>Marieke van Erp</a>
|
<a href=/people/a/auke-rijpma/>Auke Rijpma</a>
|
<a href=/people/r/richard-zijdeman/>Richard Zijdeman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lr4sshoc-1--5><div class="card-body p-3 small">For the analysis of historical wage development, no <a href=https://en.wikipedia.org/wiki/Structured_data>structured data</a> is available. Job advertisements, as found in <a href=https://en.wikipedia.org/wiki/Newspaper>newspapers</a> can provide insights into what different types of jobs paid, but require <a href=https://en.wikipedia.org/wiki/Language_technology>language technology</a> to structure in a format conducive to <a href=https://en.wikipedia.org/wiki/Quantitative_analysis_(finance)>quantitative analysis</a>. In this paper, we report on our experiments to mine <a href=https://en.wikipedia.org/wiki/Wage>wages</a> from 19th century newspaper advertisements and detail the challenges that need to be overcome to perform a socio-economic analysis of textual data sources.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lr4sshoc-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lr4sshoc-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lr4sshoc-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lr4sshoc-1.7/>EOSC as a game-changer in the Social Sciences and Humanities research activities<span class=acl-fixed-case>EOSC</span> as a game-changer in the Social Sciences and Humanities research activities</a></strong><br><a href=/people/d/donatella-castelli/>Donatella Castelli</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lr4sshoc-1--7><div class="card-body p-3 small">This paper aims to give some insights on how the European Open Science Cloud (EOSC) will be able to influence the Social Sciences and Humanities (SSH) sector, thus paving the way towards innovation. Points of discussion on how the LRs and RIs community can contribute to the revolution in the practice of research areas are provided.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lr4sshoc-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lr4sshoc-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lr4sshoc-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lr4sshoc-1.9/>Crossing the SSH Bridge with Interview Data<span class=acl-fixed-case>SSH</span> Bridge with Interview Data</a></strong><br><a href=/people/h/henk-van-den-heuvel/>Henk van den Heuvel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lr4sshoc-1--9><div class="card-body p-3 small">Spoken audio data, such as interview data, is a scientific instrument used by researchers in various disciplines crossing the boundaries of <a href=https://en.wikipedia.org/wiki/Social_science>social sciences</a> and humanities. In this paper, we will have a closer look at a portal designed to perform speech-to-text conversion on audio recordings through Automatic Speech Recognition (ASR) in the CLARIN infrastructure. Within the cluster cross-domain EU project SSHOC the potential value of such a linguistic tool kit for processing spoken language recording has found uptake in a <a href=https://en.wikipedia.org/wiki/Web_conferencing>webinar</a> about the topic, and in a task addressing audio analysis of panel survey data. The objective of this contribution is to show that the processing of <a href=https://en.wikipedia.org/wiki/Interview_(research)>interviews</a> as a research instrument has opened up a fascinating and fruitful area of collaboration between Social Sciences and Humanities (SSH).</div></div></div><hr><div id=2020lt4gov-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.lt4gov-1/>Proceedings of the 1st Workshop on Language Technologies for Government and Public Administration (LT4Gov)</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lt4gov-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lt4gov-1.0/>Proceedings of the 1st Workshop on Language Technologies for Government and Public Administration (LT4Gov)</a></strong><br><a href=/people/d/doaa-samy/>Doaa Samy</a>
|
<a href=/people/d/david-perez-fernandez/>David Pérez-Fernández</a>
|
<a href=/people/j/jeronimo-arenas-garcia/>Jerónimo Arenas-García</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lt4gov-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lt4gov-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lt4gov-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lt4gov-1.1/>Development of Natural Language Processing Tools to Support Determination of Federal Disability Benefits in the U.S.<span class=acl-fixed-case>U</span>.<span class=acl-fixed-case>S</span>.</a></strong><br><a href=/people/b/bart-desmet/>Bart Desmet</a>
|
<a href=/people/j/julia-porcino/>Julia Porcino</a>
|
<a href=/people/a/ayah-zirikly/>Ayah Zirikly</a>
|
<a href=/people/d/denis-newman-griffis/>Denis Newman-Griffis</a>
|
<a href=/people/g/guy-divita/>Guy Divita</a>
|
<a href=/people/e/elizabeth-rasch/>Elizabeth Rasch</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lt4gov-1--1><div class="card-body p-3 small">The disability benefits programs administered by the US Social Security Administration (SSA) receive between 2 and 3 million new applications each year. Adjudicators manually review hundreds of evidence pages per case to determine eligibility based on financial, medical, and functional criteria. Natural Language Processing (NLP) technology is uniquely suited to support this adjudication work and is a critical component of an ongoing inter-agency collaboration between <a href=https://en.wikipedia.org/wiki/Social_Security_Administration>SSA</a> and the National Institutes of Health. This NLP work provides resources and models for <a href=https://en.wikipedia.org/wiki/Document_ranking>document ranking</a>, <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>named entity recognition</a>, and <a href=https://en.wikipedia.org/wiki/Terminology_extraction>terminology extraction</a> in order to automatically identify documents and reports pertinent to a case, and to allow adjudicators to search for and locate desired information quickly. In this paper, we describe our vision for how <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> can impact <a href=https://en.wikipedia.org/wiki/Social_Security_Administration>SSA</a>&#8217;s adjudication process, present the resources and models that have been developed, and discuss some of the benefits and challenges in working with large-scale government data, and its specific properties in the functional domain.</div></div></div><hr><div id=2020lt4hala-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.lt4hala-1/>Proceedings of LT4HALA 2020 - 1st Workshop on Language Technologies for Historical and Ancient Languages</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lt4hala-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lt4hala-1.0/>Proceedings of LT4HALA 2020 - 1st Workshop on Language Technologies for Historical and Ancient Languages</a></strong><br><a href=/people/r/rachele-sprugnoli/>Rachele Sprugnoli</a>
|
<a href=/people/m/marco-passarotti/>Marco Passarotti</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lt4hala-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lt4hala-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lt4hala-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lt4hala-1.6/>Using LatInfLexi for an Entropy-Based Assessment of Predictability in Latin Inflection<span class=acl-fixed-case>L</span>at<span class=acl-fixed-case>I</span>nf<span class=acl-fixed-case>L</span>exi for an Entropy-Based Assessment of Predictability in <span class=acl-fixed-case>L</span>atin Inflection</a></strong><br><a href=/people/m/matteo-pellegrini/>Matteo Pellegrini</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lt4hala-1--6><div class="card-body p-3 small">This paper presents LatInfLexi, a large inflected lexicon of Latin providing information on all the <a href=https://en.wikipedia.org/wiki/List_of_Latin-script_digraphs>inflected wordforms</a> of 3,348 verbs and 1,038 nouns. After a description of the structure of the resource and some data on its size, the procedure followed to obtain the lexicon from the database of the Lemlat 3.0 morphological analyzer is detailed, as well as the choices made regarding overabundant and defective cells. The way in which the data of LatInfLexi can be exploited in order to perform a quantitative assessment of predictability in Latin verb inflection is then illustrated : results obtained by computing the conditional entropy of guessing the content of a paradigm cell assuming knowledge of one wordform or multiple wordforms are presented in turn, highlighting the descriptive and theoretical relevance of the analysis. Lastly, the paper envisages the advantages of an inclusion of LatInfLexi into the LiLa knowledge base, both for the presented resource and for the knowledge base itself.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lt4hala-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lt4hala-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lt4hala-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.lt4hala-1.7" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.lt4hala-1.7/>A Tool for Facilitating OCR Postediting in Historical Documents<span class=acl-fixed-case>OCR</span> Postediting in Historical Documents</a></strong><br><a href=/people/a/alberto-poncelas/>Alberto Poncelas</a>
|
<a href=/people/m/mohammad-aboomar/>Mohammad Aboomar</a>
|
<a href=/people/j/jan-buts/>Jan Buts</a>
|
<a href=/people/j/james-hadley/>James Hadley</a>
|
<a href=/people/a/andy-way/>Andy Way</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lt4hala-1--7><div class="card-body p-3 small">Optical character recognition (OCR) for <a href=https://en.wikipedia.org/wiki/Historical_document>historical documents</a> is a complex procedure subject to a unique set of material issues, including inconsistencies in <a href=https://en.wikipedia.org/wiki/Typeface>typefaces</a> and low quality scanning. Consequently, even the most sophisticated <a href=https://en.wikipedia.org/wiki/Optical_character_recognition>OCR engines</a> produce errors. This paper reports on a tool built for postediting the output of Tesseract, more specifically for correcting common errors in digitized historical documents. The proposed <a href=https://en.wikipedia.org/wiki/Tool>tool</a> suggests alternatives for <a href=https://en.wikipedia.org/wiki/Linguistic_description>word forms</a> not found in a specified vocabulary. The assumed error is replaced by a presumably correct alternative in the post-edition based on the scores of a Language Model (LM). The <a href=https://en.wikipedia.org/wiki/Tool>tool</a> is tested on a chapter of the book An Essay Towards Regulating the Trade and Employing the Poor of this Kingdom (Cary, 1719). As demonstrated below, the <a href=https://en.wikipedia.org/wiki/Tool>tool</a> is successful in correcting a number of common errors. If sometimes unreliable, <a href=https://en.wikipedia.org/wiki/It_(2017_film)>it</a> is also transparent and subject to human intervention.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lt4hala-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lt4hala-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lt4hala-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lt4hala-1.10/>A Thesaurus for Biblical Hebrew<span class=acl-fixed-case>H</span>ebrew</a></strong><br><a href=/people/m/miriam-azar/>Miriam Azar</a>
|
<a href=/people/a/aliza-pahmer/>Aliza Pahmer</a>
|
<a href=/people/j/joshua-waxman/>Joshua Waxman</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lt4hala-1--10><div class="card-body p-3 small">We built a thesaurus for <a href=https://en.wikipedia.org/wiki/Biblical_Hebrew>Biblical Hebrew</a>, with connections between roots based on phonetic, semantic, and distributional similarity. To this end, we apply established <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a> to find connections between <a href=https://en.wikipedia.org/wiki/Headword>headwords</a> based on existing lexicons and other digital resources. For semantic similarity, we utilize the cosine-similarity of tf-idf vectors of English gloss text of Hebrew headwords from Ernest Klein&#8217;s A Comprehensive Etymological Dictionary of the Hebrew Language for Readers of English as well as to Brown-Driver-Brigg&#8217;s Hebrew Lexicon. For phonetic similarity, we digitize part of Matityahu Clark&#8217;s Etymological Dictionary of Biblical Hebrew, grouping Hebrew roots into phonemic classes, and establish phonetic relationships between headwords in Klein&#8217;s Dictionary. For distributional similarity, we consider the cosine similarity of PPMI vectors of Hebrew roots and also, in a somewhat novel approach, apply Word2Vec to a Biblical corpus reduced to its lexemes. The resulting resource is helpful to those trying to understand <a href=https://en.wikipedia.org/wiki/Biblical_Hebrew>Biblical Hebrew</a>, and also stands as a good basis for programs trying to process the Biblical text.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lt4hala-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lt4hala-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lt4hala-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.lt4hala-1.12" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.lt4hala-1.12/>Comparing Statistical and Neural Models for Learning Sound Correspondences</a></strong><br><a href=/people/c/clementine-fourrier/>Clémentine Fourrier</a>
|
<a href=/people/b/benoit-sagot/>Benoît Sagot</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lt4hala-1--12><div class="card-body p-3 small">Cognate prediction and proto-form reconstruction are key tasks in computational historical linguistics that rely on the study of sound change regularity. Solving these tasks appears to be very similar to <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a>, though methods from that field have barely been applied to <a href=https://en.wikipedia.org/wiki/Historical_linguistics>historical linguistics</a>. Therefore, in this paper, we investigate the learnability of sound correspondences between a proto-language and daughter languages for two machine-translation-inspired models, one statistical, the other neural. We first carry out our experiments on plausible artificial languages, without <a href=https://en.wikipedia.org/wiki/Noise_(signal_processing)>noise</a>, in order to study the role of each parameter on the algorithms respective performance under almost perfect conditions. We then study real languages, namely <a href=https://en.wikipedia.org/wiki/Latin>Latin</a>, <a href=https://en.wikipedia.org/wiki/Italian_language>Italian</a> and <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>, to see if those performances generalise well. We show that both model types manage to learn sound changes despite data scarcity, although the best performing model type depends on several parameters such as the size of the training data, the ambiguity, and the prediction direction.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lt4hala-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lt4hala-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lt4hala-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lt4hala-1.14/>Latin-Spanish Neural Machine Translation : from the Bible to Saint Augustine<span class=acl-fixed-case>L</span>atin-<span class=acl-fixed-case>S</span>panish Neural Machine Translation: from the <span class=acl-fixed-case>B</span>ible to Saint Augustine</a></strong><br><a href=/people/e/eva-martinez-garcia/>Eva Martínez Garcia</a>
|
<a href=/people/a/alvaro-garcia-tejedor/>Álvaro García Tejedor</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lt4hala-1--14><div class="card-body p-3 small">Although there are several sources where to find historical texts, they usually are available in the original language that makes them generally inaccessible. This paper presents the development of state-of-the-art Neural Machine Systems for the low-resourced Latin-Spanish language pair. First, we build a Transformer-based Machine Translation system on the Bible parallel corpus. Then, we build a comparable corpus from <a href=https://en.wikipedia.org/wiki/Augustine_of_Hippo>Saint Augustine texts</a> and their translations. We use this <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> to study the domain adaptation case from the <a href=https://en.wikipedia.org/wiki/Bible>Bible texts</a> to Saint Augustine&#8217;s works. Results show the difficulties of handling a low-resourced language as Latin. First, we noticed the importance of having enough data, since the <a href=https://en.wikipedia.org/wiki/System>systems</a> do not achieve high BLEU scores. Regarding <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a>, results show how using in-domain data helps <a href=https://en.wikipedia.org/wiki/System>systems</a> to achieve a better quality translation. Also, we observed that it is needed a higher amount of data to perform an effective vocabulary extension that includes in-domain vocabulary.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.lt4hala-1.19.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--lt4hala-1--19 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.lt4hala-1.19 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.lt4hala-1.19/>A Gradient Boosting-Seq2Seq System for Latin POS Tagging and <a href=https://en.wikipedia.org/wiki/Lemmatization>Lemmatization</a><span class=acl-fixed-case>S</span>eq2<span class=acl-fixed-case>S</span>eq System for <span class=acl-fixed-case>L</span>atin <span class=acl-fixed-case>POS</span> Tagging and Lemmatization</a></strong><br><a href=/people/g/giuseppe-g-a-celano/>Giuseppe G. A. Celano</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--lt4hala-1--19><div class="card-body p-3 small">The paper presents the system used in the EvaLatin shared task to POS tag and lemmatize Latin. It consists of two components. A gradient boosting machine (LightGBM) is used for POS tagging, mainly fed with pre-computed word embeddings of a window of seven contiguous tokensthe token at hand plus the three preceding and following onesper target feature value. Word embeddings are trained on the texts of the <a href=https://en.wikipedia.org/wiki/Perseus_Digital_Library>Perseus Digital Library</a>, <a href=https://en.wikipedia.org/wiki/Patrologia_Latina>Patrologia Latina</a>, and Biblioteca Digitale di Testi Tardo Antichi, which together comprise a high number of texts of different genres from the Classical Age to Late Antiquity. Word forms plus the outputted POS labels are used to feed a seq2seq algorithm implemented in <a href=https://en.wikipedia.org/wiki/Keras>Keras</a> to predict lemmas. The final shared-task accuracies measured for Classical Latin texts are in line with state-of-the-art POS taggers (0.96) and lemmatizers (0.95).</div></div></div><hr><div id=2020mmw-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.mmw-1/>Proceedings of the LREC 2020 Workshop on Multimodal Wordnets (MMW2020)</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.mmw-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.mmw-1.0/>Proceedings of the LREC 2020 Workshop on Multimodal Wordnets (MMW2020)</a></strong><br><a href=/people/t/thierry-declerk/>Thierry Declerk</a>
|
<a href=/people/i/itziar-gonzalez-dios/>Itziar Gonzalez-Dios</a>
|
<a href=/people/g/german-rigau/>German Rigau</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.mmw-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--mmw-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.mmw-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.mmw-1.3/>English WordNet 2020 : Improving and Extending a <a href=https://en.wikipedia.org/wiki/WordNet>WordNet</a> for English using an Open-Source Methodology<span class=acl-fixed-case>E</span>nglish <span class=acl-fixed-case>W</span>ord<span class=acl-fixed-case>N</span>et 2020: Improving and Extending a <span class=acl-fixed-case>W</span>ord<span class=acl-fixed-case>N</span>et for <span class=acl-fixed-case>E</span>nglish using an Open-Source Methodology</a></strong><br><a href=/people/j/john-philip-mccrae/>John Philip McCrae</a>
|
<a href=/people/a/alexandre-rademaker/>Alexandre Rademaker</a>
|
<a href=/people/e/ewa-rudnicka/>Ewa Rudnicka</a>
|
<a href=/people/f/francis-bond/>Francis Bond</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--mmw-1--3><div class="card-body p-3 small">WordNet, while one of the most widely used resources for <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, has not been updated for a long time, and as such a new project English WordNet has arisen to continue the development of the model under an open-source paradigm. In this paper, we detail the second release of this <a href=https://en.wikipedia.org/wiki/Resource>resource</a> entitled English WordNet 2020. The work has focused firstly, on the introduction of new synsets and senses and developing guidelines for this and secondly, on the integration of contributions from other projects. We present the changes in this edition, which total over 15,000 changes over the previous release.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.mmw-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--mmw-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.mmw-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.mmw-1.7/>Adding <a href=https://en.wikipedia.org/wiki/Pronunciation>Pronunciation Information</a> to Wordnets</a></strong><br><a href=/people/t/thierry-declerck/>Thierry Declerck</a>
|
<a href=/people/l/lenka-bajcetic/>Lenka Bajcetic</a>
|
<a href=/people/m/melanie-siegel/>Melanie Siegel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--mmw-1--7><div class="card-body p-3 small">We describe on-going work consisting in adding pronunciation information to wordnets, as such <a href=https://en.wikipedia.org/wiki/Information>information</a> can indicate specific senses of a word. Many wordnets associate with their senses only a <a href=https://en.wikipedia.org/wiki/Lemma_(morphology)>lemma form</a> and a <a href=https://en.wikipedia.org/wiki/Part-of-speech_tag>part-of-speech tag</a>. At the same time, we are aware that additional linguistic information can be useful for identifying a specific sense of a wordnet lemma when encountered in a corpus. While work already deals with the addition of grammatical number or grammatical gender information to wordnet lemmas, we are investigating the linking of wordnet lemmas to pronunciation information, adding thus a speech-related modality to wordnets</div></div></div><hr><div id=2020multilingualbio-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.multilingualbio-1/>Proceedings of the LREC 2020 Workshop on Multilingual Biomedical Text Processing (MultilingualBIO 2020)</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.multilingualbio-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.multilingualbio-1.0/>Proceedings of the LREC 2020 Workshop on Multilingual Biomedical Text Processing (MultilingualBIO 2020)</a></strong><br><a href=/people/m/maite-melero/>Maite Melero</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.multilingualbio-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--multilingualbio-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.multilingualbio-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.multilingualbio-1.1/>Detecting Adverse Drug Events from Swedish Electronic Health Records using <a href=https://en.wikipedia.org/wiki/Text_mining>Text Mining</a><span class=acl-fixed-case>S</span>wedish Electronic Health Records using Text Mining</a></strong><br><a href=/people/m/maria-bampa/>Maria Bampa</a>
|
<a href=/people/h/hercules-dalianis/>Hercules Dalianis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--multilingualbio-1--1><div class="card-body p-3 small">Electronic Health Records are a valuable source of patient information which can be leveraged to detect Adverse Drug Events (ADEs) and aid post-mark drug-surveillance. The overall aim of this study is to scrutinize text written by clinicians in the <a href=https://en.wikipedia.org/wiki/Electronic_health_record>EHRs</a> and build a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> for ADE detection that produces medically relevant predictions. Natural Language Processing techniques will be exploited to create important <a href=https://en.wikipedia.org/wiki/Dependent_and_independent_variables>predictors</a> and incorporate them into the <a href=https://en.wikipedia.org/wiki/Learning>learning process</a>. The study focuses on the 5 most frequent ADE cases found ina Swedish electronic patient record corpus. The results indicate that considering textual features, rather than the structured, can improve the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> performance by 15 % in some ADE cases. Additionally, variable patient history lengths are incorporated in the models, demonstrating the importance of the above decision rather than using an arbitrary number for a history length. The experimental findings suggest that the clinical text in <a href=https://en.wikipedia.org/wiki/Electronic_health_record>EHRs</a> includes information that can capture data beyond the ones that are found in a structured format.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.multilingualbio-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--multilingualbio-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.multilingualbio-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.multilingualbio-1.3/>Localising the Clinical Terminology SNOMED CT by Semi-automated Creation of a German Interface Vocabulary<span class=acl-fixed-case>SNOMED</span> <span class=acl-fixed-case>CT</span> by Semi-automated Creation of a <span class=acl-fixed-case>G</span>erman Interface Vocabulary</a></strong><br><a href=/people/s/stefan-schulz/>Stefan Schulz</a>
|
<a href=/people/l/larissa-hammer/>Larissa Hammer</a>
|
<a href=/people/d/david-hashemian-nik/>David Hashemian-Nik</a>
|
<a href=/people/m/markus-kreuzthaler/>Markus Kreuzthaler</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--multilingualbio-1--3><div class="card-body p-3 small">Medical language exhibits great variations regarding users, institutions and language registers. With large parts of clinical documents in free text, <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a> is playing a more and more important role in unlocking re-usable and interoperable meaning from <a href=https://en.wikipedia.org/wiki/Medical_record>medical records</a>. This study describes the architectural principles and the evolution of a German interface vocabulary, combining <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> with human annotation and rule-based term generation, yielding a resource with 7.7 million raw entries, each of which linked to the reference terminology <a href=https://en.wikipedia.org/wiki/SNOMED_CT>SNOMED CT</a>, an international standard with about 350 thousand concepts. The purpose is to offer a high coverage of medical jargon in order to optimise terminology grounding of <a href=https://en.wikipedia.org/wiki/Medicine>clinical texts</a> by <a href=https://en.wikipedia.org/wiki/Text_mining>text mining systems</a>. The core resource is a manually curated table of English-to-German word and chunk translations, supported by a set of language generation rules. The work describes a <a href=https://en.wikipedia.org/wiki/Workflow>workflow</a> consisting the enrichment and modification of this table with human and machine efforts, manually enriched by grammarspecific tags. Top-down and bottom-up methods for terminology population used in parallel. The final interface terms are produced by a term generator, which creates one-to-many German variants per SNOMED CT English description. Filtering against a large collection of domain terminologies and corpora drastically reduces the size of the vocabulary in favour of more realistic terms or terms that can reasonably be expected to match clinical text passages within a text-mining pipeline. An evaluation was performed by a comparison between the current version of the German interface vocabulary and the English description table of the SNOMED CT International release. An exact term matching was performed with a small <a href=https://en.wikipedia.org/wiki/Parallel_corpus>parallel corpus</a> constituted by text snippets from different clinical documents. With overall low retrieval parameters (with F-values around 30 %), the performance of the German language scenario reaches 80 90 % of the English one. Interestingly, annotations are slightly better with machine-translated (German English) texts, using the International SNOMED CT resource only.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.multilingualbio-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--multilingualbio-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.multilingualbio-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.multilingualbio-1.4" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.multilingualbio-1.4/>Multilingual enrichment of disease biomedical ontologies</a></strong><br><a href=/people/l/leo-bouscarrat/>Léo Bouscarrat</a>
|
<a href=/people/a/antoine-bonnefoy/>Antoine Bonnefoy</a>
|
<a href=/people/c/cecile-capponi/>Cécile Capponi</a>
|
<a href=/people/c/carlos-ramisch/>Carlos Ramisch</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--multilingualbio-1--4><div class="card-body p-3 small">Translating biomedical ontologies is an important challenge, but doing it manually requires much time and money. We study the possibility to use open-source knowledge bases to translate biomedical ontologies. We focus on two aspects : <a href=https://en.wikipedia.org/wiki/Coverage_(telecommunication)>coverage</a> and <a href=https://en.wikipedia.org/wiki/Quality_(business)>quality</a>. We look at the coverage of two biomedical ontologies focusing on diseases with respect to <a href=https://en.wikipedia.org/wiki/Wikidata>Wikidata</a> for 9 European languages (Czech, Dutch, English, French, German, Italian, Polish, Portuguese and Spanish) for both, plus <a href=https://en.wikipedia.org/wiki/Arabic>Arabic</a>, <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a> and <a href=https://en.wikipedia.org/wiki/Russian_language>Russian</a> for the second. We first use direct links between <a href=https://en.wikipedia.org/wiki/Wikidata>Wikidata</a> and the studied <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontologies</a> and then use second-order links by going through other intermediate ontologies. We then compare the quality of the translations obtained thanks to <a href=https://en.wikipedia.org/wiki/Wikidata>Wikidata</a> with a commercial machine translation tool, here Google Cloud Translation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.multilingualbio-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--multilingualbio-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.multilingualbio-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.multilingualbio-1.6/>Automated Processing of Multilingual Online News for the Monitoring of Animal Infectious Diseases</a></strong><br><a href=/people/s/sarah-valentin/>Sarah Valentin</a>
|
<a href=/people/r/renaud-lancelot/>Renaud Lancelot</a>
|
<a href=/people/m/mathieu-roche/>Mathieu Roche</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--multilingualbio-1--6><div class="card-body p-3 small">The Platform for Automated extraction of animal Disease Information from the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>web</a> (PADI-web) is an automated system which monitors the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>web</a> for monitoring and detecting emerging animal infectious diseases. The <a href=https://en.wikipedia.org/wiki/Tool>tool</a> automatically collects news via customised multilingual queries, classifies them and extracts <a href=https://en.wikipedia.org/wiki/Epidemiology>epidemiological information</a>. We detail the processing of multilingual online sources by PADI-web and analyse the translated outputs in a case study</div></div></div><hr><div id=2020ngt-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ngt-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.ngt-1/>Proceedings of the Fourth Workshop on Neural Generation and Translation</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ngt-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.ngt-1.0/>Proceedings of the Fourth Workshop on Neural Generation and Translation</a></strong><br><a href=/people/a/alexandra-birch/>Alexandra Birch</a>
|
<a href=/people/a/andrew-finch/>Andrew Finch</a>
|
<a href=/people/h/hiroaki-hayashi/>Hiroaki Hayashi</a>
|
<a href=/people/k/kenneth-heafield/>Kenneth Heafield</a>
|
<a href=/people/m/marcin-junczys-dowmunt/>Marcin Junczys-Dowmunt</a>
|
<a href=/people/i/ioannis-konstas/>Ioannis Konstas</a>
|
<a href=/people/x/xian-li/>Xian Li</a>
|
<a href=/people/g/graham-neubig/>Graham Neubig</a>
|
<a href=/people/y/yusuke-oda/>Yusuke Oda</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ngt-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ngt-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ngt-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929815 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.ngt-1.2/>Learning to Generate Multiple Style Transfer Outputs for an Input Sentence</a></strong><br><a href=/people/k/kevin-lin/>Kevin Lin</a>
|
<a href=/people/m/ming-yu-liu/>Ming-Yu Liu</a>
|
<a href=/people/m/ming-ting-sun/>Ming-Ting Sun</a>
|
<a href=/people/j/jan-kautz/>Jan Kautz</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ngt-1--2><div class="card-body p-3 small">Text style transfer refers to the task of rephrasing a given text in a different style. While various methods have been proposed to advance the state of the art, they often assume the transfer output follows a <a href=https://en.wikipedia.org/wiki/Delta_distribution>delta distribution</a>, and thus their <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> can not generate different style transfer results for a given input text. To address the limitation, we propose a one-to-many text style transfer framework. In contrast to prior works that learn a <a href=https://en.wikipedia.org/wiki/One-to-one_mapping>one-to-one mapping</a> that converts an input sentence to one output sentence, our approach learns a one-to-many mapping that can convert an input sentence to multiple different output sentences, while preserving the input content. This is achieved by applying <a href=https://en.wikipedia.org/wiki/Adversarial_system>adversarial training</a> with a latent decomposition scheme. Specifically, we decompose the latent representation of the input sentence to a style code that captures the language style variation and a content code that encodes the language style-independent content. We then combine the <a href=https://en.wikipedia.org/wiki/Content_(media)>content code</a> with the <a href=https://en.wikipedia.org/wiki/Style_sheet_(web_development)>style code</a> for generating a style transfer output. By combining the same <a href=https://en.wikipedia.org/wiki/Content_(media)>content code</a> with a different <a href=https://en.wikipedia.org/wiki/Style_sheet_(web_development)>style code</a>, we generate a different style transfer output. Extensive experimental results with comparisons to several text style transfer approaches on multiple public datasets using a diverse set of performance metrics validate effectiveness of the proposed approach.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ngt-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ngt-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ngt-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929819 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.ngt-1.6/>Automatically Ranked Russian Paraphrase Corpus for Text Generation<span class=acl-fixed-case>R</span>ussian Paraphrase Corpus for Text Generation</a></strong><br><a href=/people/v/vadim-gudkov/>Vadim Gudkov</a>
|
<a href=/people/o/olga-mitrofanova/>Olga Mitrofanova</a>
|
<a href=/people/e/elizaveta-filippskikh/>Elizaveta Filippskikh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ngt-1--6><div class="card-body p-3 small">The article is focused on automatic development and ranking of a large corpus for Russian paraphrase generation which proves to be the first <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> of such type in Russian computational linguistics. Existing manually annotated paraphrase datasets for Russian are limited to small-sized ParaPhraser corpus and ParaPlag which are suitable for a set of NLP tasks, such as paraphrase and plagiarism detection, sentence similarity and relatedness estimation, etc. Due to size restrictions, these <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> can hardly be applied in end-to-end text generation solutions. Meanwhile, <a href=https://en.wikipedia.org/wiki/Paraphrase_generation>paraphrase generation</a> requires a large amount of training data. In our study we propose a solution to the problem : we collect, rank and evaluate a new publicly available headline paraphrase corpus (ParaPhraser Plus), and then perform text generation experiments with manual evaluation on automatically ranked corpora using the Universal Transformer architecture.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ngt-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ngt-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ngt-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929825 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.ngt-1.12/>Distill, Adapt, Distill : Training Small, In-Domain Models for Neural Machine Translation</a></strong><br><a href=/people/m/mitchell-gordon/>Mitchell Gordon</a>
|
<a href=/people/k/kevin-duh/>Kevin Duh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ngt-1--12><div class="card-body p-3 small">We explore best practices for training small, memory efficient <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation models</a> with sequence-level knowledge distillation in the domain adaptation setting. While both <a href=https://en.wikipedia.org/wiki/Domain_adaptation>domain adaptation</a> and knowledge distillation are widely-used, their interaction remains little understood. Our large-scale empirical results in <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> (on three language pairs with three domains each) suggest distilling twice for best performance : once using general-domain data and again using in-domain data with an adapted teacher.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ngt-1.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ngt-1--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ngt-1.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929831 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.ngt-1.17/>The ADAPT System Description for the STAPLE 2020 English-to-Portuguese Translation Task<span class=acl-fixed-case>ADAPT</span> System Description for the <span class=acl-fixed-case>STAPLE</span> 2020 <span class=acl-fixed-case>E</span>nglish-to-<span class=acl-fixed-case>P</span>ortuguese Translation Task</a></strong><br><a href=/people/r/rejwanul-haque/>Rejwanul Haque</a>
|
<a href=/people/y/yasmin-moslem/>Yasmin Moslem</a>
|
<a href=/people/a/andy-way/>Andy Way</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ngt-1--17><div class="card-body p-3 small">This paper describes the ADAPT Centre&#8217;s submission to STAPLE (Simultaneous Translation and Paraphrase for Language Education) 2020, a shared task of the 4th Workshop on Neural Generation and Translation (WNGT), for the English-to-Portuguese translation task. In this shared task, the participants were asked to produce high-coverage sets of plausible translations given English prompts (input source sentences). We present our English-to-Portuguese machine translation (MT) models that were built applying various strategies, e.g. data and sentence selection, monolingual MT for generating alternative translations, and combining multiple n-best translations. Our experiments show that adding the aforementioned techniques to the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> yields an excellent performance in the English-to-Portuguese translation task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ngt-1.25.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ngt-1--25 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ngt-1.25 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929839 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.ngt-1.25/>Efficient and High-Quality <a href=https://en.wikipedia.org/wiki/Neural_machine_translation>Neural Machine Translation</a> with OpenNMT<span class=acl-fixed-case>O</span>pen<span class=acl-fixed-case>NMT</span></a></strong><br><a href=/people/g/guillaume-klein/>Guillaume Klein</a>
|
<a href=/people/d/dakun-zhang/>Dakun Zhang</a>
|
<a href=/people/c/clement-chouteau/>Clément Chouteau</a>
|
<a href=/people/j/josep-m-crego/>Josep Crego</a>
|
<a href=/people/j/jean-senellart/>Jean Senellart</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ngt-1--25><div class="card-body p-3 small">This paper describes the OpenNMT submissions to the WNGT 2020 efficiency shared task. We explore training and acceleration of Transformer models with various sizes that are trained in a teacher-student setup. We also present a custom and optimized C++ inference engine that enables fast CPU and GPU decoding with few dependencies. By combining additional <a href=https://en.wikipedia.org/wiki/Optimizing_compiler>optimizations</a> and <a href=https://en.wikipedia.org/wiki/Parallel_computing>parallelization techniques</a>, we create small, efficient, and high-quality neural machine translation models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ngt-1.26.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ngt-1--26 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ngt-1.26 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.ngt-1.26.Dataset.txt data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929840 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.ngt-1.26/>Edinburgh’s Submissions to the 2020 Machine Translation Efficiency Task<span class=acl-fixed-case>E</span>dinburgh’s Submissions to the 2020 Machine Translation Efficiency Task</a></strong><br><a href=/people/n/nikolay-bogoychev/>Nikolay Bogoychev</a>
|
<a href=/people/r/roman-grundkiewicz/>Roman Grundkiewicz</a>
|
<a href=/people/a/alham-fikri-aji/>Alham Fikri Aji</a>
|
<a href=/people/m/maximiliana-behnke/>Maximiliana Behnke</a>
|
<a href=/people/k/kenneth-heafield/>Kenneth Heafield</a>
|
<a href=/people/s/sidharth-kashyap/>Sidharth Kashyap</a>
|
<a href=/people/e/emmanouil-ioannis-farsarakis/>Emmanouil-Ioannis Farsarakis</a>
|
<a href=/people/m/mateusz-chudyk/>Mateusz Chudyk</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ngt-1--26><div class="card-body p-3 small">We participated in all tracks of the Workshop on Neural Generation and Translation 2020 Efficiency Shared Task : <a href=https://en.wikipedia.org/wiki/Single-core>single-core CPU</a>, <a href=https://en.wikipedia.org/wiki/Multi-core_processor>multi-core CPU</a>, and <a href=https://en.wikipedia.org/wiki/Graphics_processing_unit>GPU</a>. At the model level, we use teacher-student training with a variety of student sizes, tie embeddings and sometimes layers, use the Simpler Simple Recurrent Unit, and introduce head pruning. On <a href=https://en.wikipedia.org/wiki/Graphics_processing_unit>GPUs</a>, we used 16-bit floating-point tensor cores. On <a href=https://en.wikipedia.org/wiki/Central_processing_unit>CPUs</a>, we customized 8-bit quantization and <a href=https://en.wikipedia.org/wiki/Multiprocessing>multiple processes</a> with affinity for the <a href=https://en.wikipedia.org/wiki/Multi-core_processor>multi-core setting</a>. To reduce model size, we experimented with 4-bit log quantization but use floats at runtime. In the shared task, most of our submissions were Pareto optimal with respect the trade-off between time and quality.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.ngt-1.27.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--ngt-1--27 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.ngt-1.27 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.ngt-1.27/>Improving Document-Level Neural Machine Translation with Domain Adaptation</a></strong><br><a href=/people/s/sami-ul-haq/>Sami Ul Haq</a>
|
<a href=/people/s/sadaf-abdul-rauf/>Sadaf Abdul Rauf</a>
|
<a href=/people/a/arslan-shoukat/>Arslan Shoukat</a>
|
<a href=/people/n/noor-e-hira/>Noor-e- Hira</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--ngt-1--27><div class="card-body p-3 small">Recent studies have shown that translation quality of NMT systems can be improved by providing document-level contextual information. In general sentence-based NMT models are extended to capture <a href=https://en.wikipedia.org/wiki/Context_(language_use)>contextual information</a> from large-scale document-level corpora which are difficult to acquire. Domain adaptation on the other hand promises adapting components of already developed <a href=https://en.wikipedia.org/wiki/System>systems</a> by exploiting limited in-domain data. This paper presents FJWU&#8217;s system submission at WNGT, we specifically participated in Document level MT task for German-English translation. Our system is based on context-aware Transformer model developed on top of original NMT architecture by integrating contextual information using attention networks. Our experimental results show providing previous sentences as context significantly improves the BLEU score as compared to a strong NMT baseline. We also studied the impact of domain adaptation on document level translationand were able to improve results by adaptingthe <a href=https://en.wikipedia.org/wiki/System>systems</a> according to the testing domain.</div></div></div><hr><div id=2020nli-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nli-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.nli-1/>Proceedings of the First Workshop on Natural Language Interfaces</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nli-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nli-1.0/>Proceedings of the First Workshop on Natural Language Interfaces</a></strong><br><a href=/people/a/ahmed-hassan/>Ahmed Hassan Awadallah</a>
|
<a href=/people/y/yu-su/>Yu Su</a>
|
<a href=/people/h/huan-sun/>Huan Sun</a>
|
<a href=/people/w/wen-tau-yih/>Scott Wen-tau Yih</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nli-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nli-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nli-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929797 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nli-1.1/>Answering Complex Questions by Combining Information from Curated and Extracted Knowledge Bases</a></strong><br><a href=/people/n/nikita-bhutani/>Nikita Bhutani</a>
|
<a href=/people/x/xinyi-zheng/>Xinyi Zheng</a>
|
<a href=/people/k/kun-qian/>Kun Qian</a>
|
<a href=/people/y/yunyao-li/>Yunyao Li</a>
|
<a href=/people/h/h-jagadish/>H. Jagadish</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nli-1--1><div class="card-body p-3 small">Knowledge-based question answering (KB_QA) has long focused on simple questions that can be answered from a single knowledge source, a manually curated or an automatically extracted KB. In this work, we look at answering complex questions which often require combining information from multiple sources. We present a novel KB-QA system, Multique, which can map a complex question to a complex query pattern using a sequence of simple queries each targeted at a specific KB. It finds simple queries using a neural-network based model capable of collective inference over textual relations in extracted KB and <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontological relations</a> in curated KB. Experiments show that our proposed system outperforms previous KB-QA systems on benchmark datasets, ComplexWebQuestions and WebQuestionsSP.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nli-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nli-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nli-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929795 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nli-1.2/>Towards Reversal-Based Textual Data Augmentation for NLI Problems with Opposable Classes<span class=acl-fixed-case>NLI</span> Problems with Opposable Classes</a></strong><br><a href=/people/a/alexey-tarasov/>Alexey Tarasov</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nli-1--2><div class="card-body p-3 small">Data augmentation methods are commonly used in <a href=https://en.wikipedia.org/wiki/Computer_vision>computer vision</a> and <a href=https://en.wikipedia.org/wiki/Speech>speech</a>. However, in domains dealing with <a href=https://en.wikipedia.org/wiki/Text_(literary_theory)>textual data</a>, such techniques are not that common. Most of the existing methods rely on <a href=https://en.wikipedia.org/wiki/Rephrasing>rephrasing</a>, i.e. new sentences are generated by changing a source sentence, preserving its meaning. We argue that in tasks with opposable classes (such as Positive and Negative in sentiment analysis), it might be beneficial to also invert the source sentence, reversing its meaning, to generate examples of the opposing class. Methods that use somewhat similar intuition exist in the space of <a href=https://en.wikipedia.org/wiki/Adversarial_learning>adversarial learning</a>, but are not always applicable to text classification (in our experiments, some of them were even detrimental to the resulting classifier accuracy). We propose and evaluate two reversal-based methods on an NLI task of recognising a type of a simple logical expression from its description in plain-text form. After gathering a dataset on <a href=https://en.wikipedia.org/wiki/MTurk>MTurk</a>, we show that a simple <a href=https://en.wikipedia.org/wiki/Heuristic>heuristic</a> using a notion of negating the main verb has a potential not only on its own, but that it can also boost existing state-of-the-art rephrasing-based approaches.</div></div></div><hr><div id=2020nlp4convai-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlp4convai-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.nlp4convai-1/>Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlp4convai-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nlp4convai-1.0/>Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI</a></strong><br><a href=/people/t/tsung-hsien-wen/>Tsung-Hsien Wen</a>
|
<a href=/people/a/asli-celikyilmaz/>Asli Celikyilmaz</a>
|
<a href=/people/z/zhou-yu/>Zhou Yu</a>
|
<a href=/people/a/alexandros-papangelis/>Alexandros Papangelis</a>
|
<a href=/people/m/mihail-eric/>Mihail Eric</a>
|
<a href=/people/a/anuj-kumar/>Anuj Kumar</a>
|
<a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/r/rushin-shah/>Rushin Shah</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlp4convai-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlp4convai-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlp4convai-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929634 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nlp4convai-1.4/>How to Tame Your Data : <a href=https://en.wikipedia.org/wiki/Data_augmentation>Data Augmentation</a> for Dialog State Tracking</a></strong><br><a href=/people/a/adam-summerville/>Adam Summerville</a>
|
<a href=/people/j/jordan-hashemi/>Jordan Hashemi</a>
|
<a href=/people/j/james-ryan/>James Ryan</a>
|
<a href=/people/w/william-ferguson/>William Ferguson</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlp4convai-1--4><div class="card-body p-3 small">Dialog State Tracking (DST) is a problem space in which the effective vocabulary is practically limitless. For example, the domain of possible <a href=https://en.wikipedia.org/wiki/Film_title_design>movie titles</a> or restaurant names is bound only by the limits of language. As such, DST systems often encounter out-of-vocabulary words at inference time that were never encountered during training. To combat this issue, we present a targeted data augmentation process, by which a practitioner observes the types of errors made on held-out evaluation data, and then modifies the training data with additional corpora to increase the vocabulary size at training time. Using this with a RoBERTa-based Transformer architecture, we achieve state-of-the-art results in comparison to systems that only mask trouble slots with special tokens. Additionally, we present a data-representation scheme for seamlessly retargeting DST architectures to new domains.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlp4convai-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlp4convai-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlp4convai-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.nlp4convai-1.5.Dataset.zip data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929632 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.nlp4convai-1.5" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nlp4convai-1.5/>Efficient Intent Detection with Dual Sentence Encoders</a></strong><br><a href=/people/i/inigo-casanueva/>Iñigo Casanueva</a>
|
<a href=/people/t/tadas-temcinas/>Tadas Temčinas</a>
|
<a href=/people/d/daniela-gerz/>Daniela Gerz</a>
|
<a href=/people/m/matthew-henderson/>Matthew Henderson</a>
|
<a href=/people/i/ivan-vulic/>Ivan Vulić</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlp4convai-1--5><div class="card-body p-3 small">Building conversational systems in new domains and with added functionality requires resource-efficient models that work under low-data regimes (i.e., in few-shot setups). Motivated by these requirements, we introduce intent detection methods backed by pretrained dual sentence encoders such as USE and ConveRT. We demonstrate the usefulness and wide applicability of the proposed intent detectors, showing that : 1) they outperform intent detectors based on fine-tuning the full BERT-Large model or using BERT as a fixed black-box encoder on three diverse intent detection data sets ; 2) the gains are especially pronounced in few-shot setups (i.e., with only 10 or 30 annotated examples per intent) ; 3) our intent detectors can be trained in a matter of minutes on a single CPU ; and 4) they are stable across different hyperparameter settings. In hope of facilitating and democratizing research focused on intention detection, we release our code, as well as a new challenging single-domain intent detection dataset comprising 13,083 annotated examples over 77 intents.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlp4convai-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlp4convai-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlp4convai-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.nlp4convai-1.6" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.nlp4convai-1.6/>Accelerating <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>Natural Language Understanding</a> in Task-Oriented Dialog</a></strong><br><a href=/people/o/ojas-ahuja/>Ojas Ahuja</a>
|
<a href=/people/s/shrey-desai/>Shrey Desai</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlp4convai-1--6><div class="card-body p-3 small">Task-oriented dialog models typically leverage complex neural architectures and large-scale, pre-trained Transformers to achieve state-of-the-art performance on popular natural language understanding benchmarks. However, these models frequently have in excess of tens of millions of parameters, making them impossible to deploy on-device where <a href=https://en.wikipedia.org/wiki/Resource_efficiency>resource-efficiency</a> is a major concern. In this work, we show that a simple convolutional model compressed with structured pruning achieves largely comparable results to BERT on <a href=https://en.wikipedia.org/wiki/Automatic_terminal_information_service>ATIS</a> and Snips, with under 100 K parameters. Moreover, we perform acceleration experiments on <a href=https://en.wikipedia.org/wiki/Central_processing_unit>CPUs</a>, where we observe our multi-task model predicts intents and slots nearly 63x faster than even DistilBERT.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlp4convai-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlp4convai-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlp4convai-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.nlp4convai-1.9.Software.txt data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.nlp4convai-1.9.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929630 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nlp4convai-1.9/>Automating Template Creation for Ranking-Based Dialogue Models</a></strong><br><a href=/people/j/jingxiang-chen/>Jingxiang Chen</a>
|
<a href=/people/h/heba-elfardy/>Heba Elfardy</a>
|
<a href=/people/s/simi-wang/>Simi Wang</a>
|
<a href=/people/a/andrea-kahn/>Andrea Kahn</a>
|
<a href=/people/j/jared-kramer/>Jared Kramer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlp4convai-1--9><div class="card-body p-3 small">Dialogue response generation models that use template ranking rather than direct sequence generation allow model developers to limit generated responses to pre-approved messages. However, manually creating templates is time-consuming and requires domain expertise. To alleviate this problem, we explore automating the process of creating dialogue templates by using <a href=https://en.wikipedia.org/wiki/Unsupervised_learning>unsupervised methods</a> to cluster historical utterances and selecting representative utterances from each <a href=https://en.wikipedia.org/wiki/Cluster_analysis>cluster</a>. Specifically, we propose an end-to-end model called Deep Sentence Encoder Clustering (DSEC) that uses an auto-encoder structure to jointly learn the utterance representation and construct template clusters. We compare this method to a random baseline that randomly assigns templates to clusters as well as a strong baseline that performs the sentence encoding and the utterance clustering sequentially. To evaluate the performance of the proposed method, we perform an automatic evaluation with two annotated customer service datasets to assess clustering effectiveness, and a human-in-the-loop experiment using a live customer service application to measure the acceptance rate of the generated templates. DSEC performs best in the automatic evaluation, beats both the sequential and random baselines on most metrics in the human-in-the-loop experiment, and shows promising results when compared to gold / manually created templates.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlp4convai-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlp4convai-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlp4convai-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929641 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.nlp4convai-1.13" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nlp4convai-1.13/>MultiWOZ 2.2 : A Dialogue Dataset with Additional Annotation Corrections and State Tracking Baselines<span class=acl-fixed-case>M</span>ulti<span class=acl-fixed-case>WOZ</span> 2.2 : A Dialogue Dataset with Additional Annotation Corrections and State Tracking Baselines</a></strong><br><a href=/people/x/xiaoxue-zang/>Xiaoxue Zang</a>
|
<a href=/people/a/abhinav-rastogi/>Abhinav Rastogi</a>
|
<a href=/people/s/srinivas-sunkara/>Srinivas Sunkara</a>
|
<a href=/people/r/raghav-gupta/>Raghav Gupta</a>
|
<a href=/people/j/jianguo-zhang/>Jianguo Zhang</a>
|
<a href=/people/j/jindong-chen/>Jindong Chen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlp4convai-1--13><div class="card-body p-3 small">MultiWOZ is a well-known task-oriented dialogue dataset containing over 10,000 annotated dialogues spanning 8 domains. It is extensively used as a benchmark for dialogue state tracking. However, recent works have reported presence of substantial noise in the dialogue state annotations. MultiWOZ 2.1 identified and fixed many of these erroneous <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a> and user utterances, resulting in an improved version of this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. This work introduces MultiWOZ 2.2, which is a yet another improved version of this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. Firstly, we identify and fix dialogue state annotation errors across 17.3 % of the utterances on top of MultiWOZ 2.1. Secondly, we redefine the <a href=https://en.wikipedia.org/wiki/Ontology_(information_science)>ontology</a> by disallowing vocabularies of slots with a large number of possible values (e.g., restaurant name, time of booking). In addition, we introduce slot span annotations for these slots to standardize them across recent models, which previously used custom string matching heuristics to generate them. We also benchmark a few state of the art dialogue state tracking models on the corrected dataset to facilitate comparison for future work. In the end, we discuss best practices for dialogue data collection that can help avoid annotation errors.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlp4convai-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlp4convai-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlp4convai-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929635 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.nlp4convai-1.15" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nlp4convai-1.15/>Probing Neural Dialog Models for Conversational Understanding</a></strong><br><a href=/people/a/abdelrhman-saleh/>Abdelrhman Saleh</a>
|
<a href=/people/t/tovly-deutsch/>Tovly Deutsch</a>
|
<a href=/people/s/stephen-casper/>Stephen Casper</a>
|
<a href=/people/y/yonatan-belinkov/>Yonatan Belinkov</a>
|
<a href=/people/s/stuart-m-shieber/>Stuart Shieber</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlp4convai-1--15><div class="card-body p-3 small">The predominant approach to open-domain dialog generation relies on end-to-end training of neural models on chat datasets. However, this approach provides little insight as to what these <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> learn (or do not learn) about engaging in <a href=https://en.wikipedia.org/wiki/Dialogue>dialog</a>. In this study, we analyze the internal representations learned by neural open-domain dialog systems and evaluate the quality of these <a href=https://en.wikipedia.org/wiki/Knowledge_representation_and_reasoning>representations</a> for learning basic conversational skills. Our results suggest that standard open-domain dialog systems struggle with answering questions, inferring <a href=https://en.wikipedia.org/wiki/Contradiction>contradiction</a>, and determining the topic of conversation, among other tasks. We also find that the dyadic, turn-taking nature of <a href=https://en.wikipedia.org/wiki/Dialogue>dialog</a> is not fully leveraged by these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. By exploring these limitations, we highlight the need for additional research into <a href=https://en.wikipedia.org/wiki/Computer_architecture>architectures</a> and <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training methods</a> that can better capture high-level information about dialog.</div></div></div><hr><div id=2020nlpmc-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpmc-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.nlpmc-1/>Proceedings of the First Workshop on Natural Language Processing for Medical Conversations</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpmc-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nlpmc-1.0/>Proceedings of the First Workshop on Natural Language Processing for Medical Conversations</a></strong><br><a href=/people/p/parminder-bhatia/>Parminder Bhatia</a>
|
<a href=/people/s/steven-lin/>Steven Lin</a>
|
<a href=/people/r/rashmi-gangadharaiah/>Rashmi Gangadharaiah</a>
|
<a href=/people/b/byron-c-wallace/>Byron Wallace</a>
|
<a href=/people/i/izhak-shafran/>Izhak Shafran</a>
|
<a href=/people/c/chaitanya-shivade/>Chaitanya Shivade</a>
|
<a href=/people/n/nan-du/>Nan Du</a>
|
<a href=/people/m/mona-diab/>Mona Diab</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpmc-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlpmc-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlpmc-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929890 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nlpmc-1.1/>Methods for Extracting Information from Messages from Primary Care Providers to Specialists</a></strong><br><a href=/people/x/xiyu-ding/>Xiyu Ding</a>
|
<a href=/people/m/michael-barnett/>Michael Barnett</a>
|
<a href=/people/a/ateev-mehrotra/>Ateev Mehrotra</a>
|
<a href=/people/t/timothy-miller/>Timothy Miller</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlpmc-1--1><div class="card-body p-3 small">Electronic consult (eConsult) systems allow specialists more flexibility to respond to referrals more efficiently, thereby increasing access in under-resourced healthcare settings like safety net systems. Understanding the usage patterns of eConsult system is an important part of improving specialist efficiency. In this work, we develop and apply classifiers to a dataset of eConsult questions from primary care providers to specialists, classifying the messages for how they were triaged by the specialist office, and the underlying type of clinical question posed by the primary care provider. We show that pre-trained transformer models are strong baselines, with improving performance from domain-specific training and shared representations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpmc-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlpmc-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlpmc-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929893 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nlpmc-1.2/>Towards Understanding ASR Error Correction for Medical Conversations<span class=acl-fixed-case>ASR</span> Error Correction for Medical Conversations</a></strong><br><a href=/people/a/anirudh-mani/>Anirudh Mani</a>
|
<a href=/people/s/shruti-palaskar/>Shruti Palaskar</a>
|
<a href=/people/s/sandeep-konam/>Sandeep Konam</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlpmc-1--2><div class="card-body p-3 small">Domain Adaptation for Automatic Speech Recognition (ASR) error correction via <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation</a> is a useful technique for improving out-of-domain outputs of pre-trained ASR systems to obtain optimal results for specific in-domain tasks. We use this technique on our dataset of Doctor-Patient conversations using two off-the-shelf ASR systems : Google ASR (commercial) and the ASPIRE model (open-source). We train a Sequence-to-Sequence Machine Translation model and evaluate it on seven specific UMLS Semantic types, including Pharmacological Substance, Sign or Symptom, and Diagnostic Procedure to name a few. Lastly, we breakdown, analyze and discuss the 7 % overall improvement in <a href=https://en.wikipedia.org/wiki/Word_error_rate>word error rate</a> in view of each Semantic type.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nlpmc-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nlpmc-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nlpmc-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929892 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nlpmc-1.7/>On the Utility of Audiovisual Dialog Technologies and Signal Analytics for Real-time Remote Monitoring of Depression Biomarkers</a></strong><br><a href=/people/m/michael-neumann/>Michael Neumann</a>
|
<a href=/people/o/oliver-roessler/>Oliver Roessler</a>
|
<a href=/people/d/david-suendermann-oeft/>David Suendermann-Oeft</a>
|
<a href=/people/v/vikram-ramanarayanan/>Vikram Ramanarayanan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nlpmc-1--7><div class="card-body p-3 small">We investigate the utility of audiovisual dialog systems combined with speech and video analytics for real-time remote monitoring of depression at scale in uncontrolled environment settings. We collected audiovisual conversational data from participants who interacted with a cloud-based multimodal dialog system, and automatically extracted a large set of speech and vision metrics based on the rich existing literature of laboratory studies. We report on the efficacy of various audio and video metrics in differentiating people with mild, moderate and severe depression, and discuss the implications of these results for the deployment of such technologies in real-world neurological diagnosis and monitoring applications.</div></div></div><hr><div id=2020nuse-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nuse-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.nuse-1/>Proceedings of the First Joint Workshop on Narrative Understanding, Storylines, and Events</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nuse-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.nuse-1.0/>Proceedings of the First Joint Workshop on Narrative Understanding, Storylines, and Events</a></strong><br><a href=/people/c/claire-bonial/>Claire Bonial</a>
|
<a href=/people/t/tommaso-caselli/>Tommaso Caselli</a>
|
<a href=/people/s/snigdha-chaturvedi/>Snigdha Chaturvedi</a>
|
<a href=/people/e/elizabeth-clark/>Elizabeth Clark</a>
|
<a href=/people/r/ruihong-huang/>Ruihong Huang</a>
|
<a href=/people/m/mohit-iyyer/>Mohit Iyyer</a>
|
<a href=/people/a/alejandro-jaimes/>Alejandro Jaimes</a>
|
<a href=/people/h/heng-ji/>Heng Ji</a>
|
<a href=/people/l/lara-j-martin/>Lara J. Martin</a>
|
<a href=/people/b/ben-miller/>Ben Miller</a>
|
<a href=/people/t/teruko-mitamura/>Teruko Mitamura</a>
|
<a href=/people/n/nanyun-peng/>Nanyun Peng</a>
|
<a href=/people/j/joel-tetreault/>Joel Tetreault</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nuse-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nuse-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nuse-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929742 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nuse-1.3/>Improving the Identification of the Discourse Function of News Article Paragraphs</a></strong><br><a href=/people/d/deya-banisakher/>Deya Banisakher</a>
|
<a href=/people/w/w-victor-yarlott/>W. Victor Yarlott</a>
|
<a href=/people/m/mohammed-aldawsari/>Mohammed Aldawsari</a>
|
<a href=/people/n/naphtali-rishe/>Naphtali Rishe</a>
|
<a href=/people/m/mark-finlayson/>Mark Finlayson</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nuse-1--3><div class="card-body p-3 small">Identifying the discourse structure of documents is an important task in understanding <a href=https://en.wikipedia.org/wiki/Writing>written text</a>. Building on prior work, we demonstrate an improved approach to automatically identifying the discourse function of paragraphs in <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a>. We start with the hierarchical theory of news discourse developed by van Dijk (1988) which proposes how paragraphs function within <a href=https://en.wikipedia.org/wiki/Article_(publishing)>news articles</a>. This discourse information is a level intermediate between phrase- or sentence-sized discourse segments and document genre, characterizing how individual paragraphs convey information about the events in the storyline of the article. Specifically, the theory categorizes the relationships between narrated events and (1) the overall storyline (such as Main Events, Background, or Consequences) as well as (2) commentary (such as Verbal Reactions and Evaluations). We trained and tested a linear chain conditional random field (CRF) with new features to model van Dijk&#8217;s labels and compared it against several machine learning models presented in previous work. Our model significantly outperformed all <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baselines</a> and prior approaches, achieving an average of 0.71 <a href=https://en.wikipedia.org/wiki/F-number>F1 score</a> which represents a 31.5 % improvement over the previously best-performing <a href=https://en.wikipedia.org/wiki/Support_vector_machine>support vector machine model</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nuse-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nuse-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nuse-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929744 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nuse-1.5/>Extensively Matching for Few-shot Learning Event Detection</a></strong><br><a href=/people/v/viet-dac-lai/>Viet Dac Lai</a>
|
<a href=/people/t/thien-huu-nguyen/>Thien Huu Nguyen</a>
|
<a href=/people/f/franck-dernoncourt/>Franck Dernoncourt</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nuse-1--5><div class="card-body p-3 small">Current event detection models under supervised learning settings fail to transfer to new event types. Few-shot learning has not been explored in event detection even though it allows a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> to perform well with high <a href=https://en.wikipedia.org/wiki/Generalization>generalization</a> on new event types. In this work, we formulate event detection as a few-shot learning problem to enable to extend event detection to new event types. We propose two novel <a href=https://en.wikipedia.org/wiki/Loss_factor>loss factors</a> that matching examples in the support set to provide more <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training signals</a> to the <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>. Moreover, these <a href=https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets>training signals</a> can be applied in many metric-based few-shot learning models. Our extensive experiments on the ACE-2005 dataset (under a few-shot learning setting) show that the proposed method can improve the performance of few-shot learning.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nuse-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nuse-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nuse-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929748 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nuse-1.9/>Annotating and quantifying narrative time disruptions in modernist and hypertext fiction</a></strong><br><a href=/people/e/edward-kearns/>Edward Kearns</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nuse-1--9><div class="card-body p-3 small">This paper outlines work in progress on a new method of annotating and quantitatively discussing <a href=https://en.wikipedia.org/wiki/Narrative>narrative techniques</a> related to time in fiction. Specifically those techniques are <a href=https://en.wikipedia.org/wiki/Analepsis>analepsis</a>, <a href=https://en.wikipedia.org/wiki/Prolepsis>prolepsis</a>, narrative level changes, and <a href=https://en.wikipedia.org/wiki/Stream_of_consciousness>stream-of-consciousness</a> and free-indirect-discourse narration. By counting the frequency and extent of the usage of these <a href=https://en.wikipedia.org/wiki/List_of_narrative_techniques>techniques</a>, the <a href=https://en.wikipedia.org/wiki/Narrative>narrative characteristics</a> of different works from different time periods and genres can be compared. This project uses <a href=https://en.wikipedia.org/wiki/Literary_modernism>modernist fiction</a> and <a href=https://en.wikipedia.org/wiki/Hypertext_fiction>hypertext fiction</a> as its case studies.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nuse-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nuse-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nuse-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://slideslive.com/38939705 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.nuse-1.10" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nuse-1.10/>Exploring aspects of similarity between spoken personal narratives by disentangling them into narrative clause types</a></strong><br><a href=/people/b/belen-saldias/>Belen Saldias</a>
|
<a href=/people/d/deb-roy/>Deb Roy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nuse-1--10><div class="card-body p-3 small">Sharing personal narratives is a fundamental aspect of <a href=https://en.wikipedia.org/wiki/Social_behavior>human social behavior</a> as it helps share our life experiences. We can tell stories and rely on our background to understand their context, similarities, and differences. A substantial effort has been made towards developing storytelling machines or inferring characters&#8217; features. However, we do n&#8217;t usually find <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> that compare narratives. This task is remarkably challenging for machines since they, as sometimes we do, lack an understanding of what similarity means. To address this challenge, we first introduce a corpus of real-world spoken personal narratives comprising 10,296 narrative clauses from 594 <a href=https://en.wikipedia.org/wiki/Videotape>video transcripts</a>. Second, we ask non-narrative experts to annotate those clauses under Labov&#8217;s sociolinguistic model of personal narratives (i.e., action, orientation, and evaluation clause types) and train a classifier that reaches 84.7 % F-score for the highest-agreed clauses. Finally, we match stories and explore whether people implicitly rely on Labov&#8217;s framework to compare narratives. We show that actions followed by the narrator&#8217;s evaluation of these are the aspects non-experts consider the most. Our approach is intended to help inform <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning methods</a> aimed at studying or representing <a href=https://en.wikipedia.org/wiki/Personal_narrative>personal narratives</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.nuse-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--nuse-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.nuse-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929754 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.nuse-1.14/>On-The-Fly Information Retrieval Augmentation for <a href=https://en.wikipedia.org/wiki/Language_model>Language Models</a></a></strong><br><a href=/people/h/hai-wang/>Hai Wang</a>
|
<a href=/people/d/david-mcallester/>David McAllester</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--nuse-1--14><div class="card-body p-3 small">Here we experiment with the use of <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval</a> as an augmentation for pre-trained language models. The <a href=https://en.wikipedia.org/wiki/Text_corpus>text corpus</a> used in <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval</a> can be viewed as form of <a href=https://en.wikipedia.org/wiki/Episodic_memory>episodic memory</a> which grows over time. By augmenting GPT 2.0 with <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval</a> we achieve a zero shot 15 % relative reduction in perplexity on Gigaword corpus without any re-training. We also validate our IR augmentation on an event co-reference task.</div></div></div><hr><div id=2020onion-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.onion-1/>Proceedings of LREC2020 Workshop "People in language, vision and the mind" (ONION2020)</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.onion-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.onion-1.0/>Proceedings of LREC2020 Workshop "People in language, vision and the mind" (ONION2020)</a></strong><br><a href=/people/p/patrizia-paggio/>Patrizia Paggio</a>
|
<a href=/people/a/albert-gatt/>Albert Gatt</a>
|
<a href=/people/r/roman-klinger/>Roman Klinger</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.onion-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--onion-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.onion-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.onion-1.2/>Analysis of Body Behaviours in Human-Human and Human-Robot Interactions</a></strong><br><a href=/people/t/taiga-mori/>Taiga Mori</a>
|
<a href=/people/k/kristiina-jokinen/>Kristiina Jokinen</a>
|
<a href=/people/y/yasuharu-den/>Yasuharu Den</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--onion-1--2><div class="card-body p-3 small">We conducted preliminary comparison of human-robot (HR) interaction with human-human (HH) interaction conducted in <a href=https://en.wikipedia.org/wiki/English_language>English</a> and in <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese</a>. As the result, body gestures increased in <a href=https://en.wikipedia.org/wiki/Human_factors_and_ergonomics>HR</a>, while hand and head gestures decreased in <a href=https://en.wikipedia.org/wiki/Human_factors_and_ergonomics>HR</a>. Concerning <a href=https://en.wikipedia.org/wiki/List_of_gestures>hand gesture</a>, they were composed of more diverse and complex forms, trajectories and functions in HH than in HR. Moreover, <a href=https://en.wikipedia.org/wiki/English_language>English speakers</a> produced 6 times more <a href=https://en.wikipedia.org/wiki/List_of_gestures>hand gestures</a> than <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese speakers</a> in HH. Regarding head gesture, even though there was no difference in the frequency of head gestures between <a href=https://en.wikipedia.org/wiki/English_language>English speakers</a> and <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese speakers</a> in HH, <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese speakers</a> produced slightly more nodding during the robot&#8217;s speaking than <a href=https://en.wikipedia.org/wiki/English_language>English speakers</a> in HR. Furthermore, positions of nod were different depending on the language. Concerning <a href=https://en.wikipedia.org/wiki/Gesture>body gesture</a>, participants produced <a href=https://en.wikipedia.org/wiki/Gesture>body gestures</a> mostly to regulate appropriate distance with the robot in <a href=https://en.wikipedia.org/wiki/Human_resources>HR</a>. Additionally, <a href=https://en.wikipedia.org/wiki/English_language>English speakers</a> produced slightly more <a href=https://en.wikipedia.org/wiki/List_of_gestures>body gestures</a> than <a href=https://en.wikipedia.org/wiki/Japanese_language>Japanese speakers</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.onion-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--onion-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.onion-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.onion-1.5/>Improving <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a> with Biofeedback Data</a></strong><br><a href=/people/d/daniel-schlor/>Daniel Schlör</a>
|
<a href=/people/a/albin-zehe/>Albin Zehe</a>
|
<a href=/people/k/konstantin-kobs/>Konstantin Kobs</a>
|
<a href=/people/b/blerta-veseli/>Blerta Veseli</a>
|
<a href=/people/f/franziska-westermeier/>Franziska Westermeier</a>
|
<a href=/people/l/larissa-brubach/>Larissa Brübach</a>
|
<a href=/people/d/daniel-roth/>Daniel Roth</a>
|
<a href=/people/m/marc-erich-latoschik/>Marc Erich Latoschik</a>
|
<a href=/people/a/andreas-hotho/>Andreas Hotho</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--onion-1--5><div class="card-body p-3 small">Humans frequently are able to read and interpret emotions of others by directly taking verbal and non-verbal signals in human-to-human communication into account or to infer or even experience <a href=https://en.wikipedia.org/wiki/Emotion>emotions</a> from mediated stories. For <a href=https://en.wikipedia.org/wiki/Computer>computers</a>, however, <a href=https://en.wikipedia.org/wiki/Emotion_recognition>emotion recognition</a> is a complex problem : Thoughts and feelings are the roots of many <a href=https://en.wikipedia.org/wiki/Behavior>behavioural responses</a> and they are deeply entangled with <a href=https://en.wikipedia.org/wiki/Neurophysiology>neurophysiological changes</a> within humans. As such, <a href=https://en.wikipedia.org/wiki/Emotion>emotions</a> are very subjective, often are expressed in a subtle manner, and are highly depending on context. For example, machine learning approaches for text-based sentiment analysis often rely on incorporating sentiment lexicons or <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> to capture the contextual meaning. This paper explores if and how we further can enhance <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> using <a href=https://en.wikipedia.org/wiki/Biofeedback>biofeedback</a> of humans which are experiencing <a href=https://en.wikipedia.org/wiki/Emotion>emotions</a> while reading texts. Specifically, we record the <a href=https://en.wikipedia.org/wiki/Heart_rate>heart rate</a> and <a href=https://en.wikipedia.org/wiki/Neural_oscillation>brain waves</a> of readers that are presented with short texts which have been annotated with the emotions they induce. We use these <a href=https://en.wikipedia.org/wiki/Physiology>physiological signals</a> to improve the performance of a lexicon-based sentiment classifier. We find that the combination of several <a href=https://en.wikipedia.org/wiki/Biosignal>biosignals</a> can improve the ability of a text-based classifier to detect the presence of a sentiment in a text on a per-sentence level.</div></div></div><hr><div id=2020osact-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.osact-1/>Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared Task on Offensive Language Detection</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.osact-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.osact-1.0/>Proceedings of the 4th Workshop on Open-Source Arabic Corpora and Processing Tools, with a Shared Task on Offensive Language Detection</a></strong><br><a href=/people/h/hend-al-khalifa/>Hend Al-Khalifa</a>
|
<a href=/people/w/walid-magdy/>Walid Magdy</a>
|
<a href=/people/k/kareem-darwish/>Kareem Darwish</a>
|
<a href=/people/t/tamer-elsayed/>Tamer Elsayed</a>
|
<a href=/people/h/hamdy-mubarak/>Hamdy Mubarak</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.osact-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--osact-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.osact-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.osact-1.2" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.osact-1.2/>AraBERT : Transformer-based Model for Arabic Language Understanding<span class=acl-fixed-case>A</span>ra<span class=acl-fixed-case>BERT</span>: Transformer-based Model for <span class=acl-fixed-case>A</span>rabic Language Understanding</a></strong><br><a href=/people/w/wissam-antoun/>Wissam Antoun</a>
|
<a href=/people/f/fady-baly/>Fady Baly</a>
|
<a href=/people/h/hazem-hajj/>Hazem Hajj</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--osact-1--2><div class="card-body p-3 small">The <a href=https://en.wikipedia.org/wiki/Arabic>Arabic language</a> is a morphologically rich language with relatively few resources and a less explored syntax compared to <a href=https://en.wikipedia.org/wiki/English_language>English</a>. Given these limitations, Arabic Natural Language Processing (NLP) tasks like Sentiment Analysis (SA), Named Entity Recognition (NER), and Question Answering (QA), have proven to be very challenging to tackle. Recently, with the surge of transformers based models, language-specific BERT based models have proven to be very efficient at <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>language understanding</a>, provided they are pre-trained on a very large corpus. Such <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> were able to set new standards and achieve state-of-the-art results for most NLP tasks. In this paper, we pre-trained BERT specifically for the <a href=https://en.wikipedia.org/wiki/Arabic>Arabic language</a> in the pursuit of achieving the same success that BERT did for the <a href=https://en.wikipedia.org/wiki/English_language>English language</a>. The performance of AraBERT is compared to multilingual BERT from <a href=https://en.wikipedia.org/wiki/Google>Google</a> and other state-of-the-art approaches. The results showed that the newly developed AraBERT achieved state-of-the-art performance on most tested Arabic NLP tasks. The pretrained araBERT models are publicly available on https://github.com/aub-mind/araBERT hoping to encourage research and applications for Arabic NLP.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.osact-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--osact-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.osact-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.osact-1.5/>From Arabic Sentiment Analysis to Sarcasm Detection : The ArSarcasm Dataset<span class=acl-fixed-case>A</span>rabic Sentiment Analysis to Sarcasm Detection: The <span class=acl-fixed-case>A</span>r<span class=acl-fixed-case>S</span>arcasm Dataset</a></strong><br><a href=/people/i/ibrahim-abu-farha/>Ibrahim Abu Farha</a>
|
<a href=/people/w/walid-magdy/>Walid Magdy</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--osact-1--5><div class="card-body p-3 small">Sarcasm is one of the main challenges for sentiment analysis systems. Its <a href=https://en.wikipedia.org/wiki/Complexity>complexity</a> comes from the <a href=https://en.wikipedia.org/wiki/Opinion>expression of opinion</a> using implicit indirect phrasing. In this paper, we present ArSarcasm, an Arabic sarcasm detection dataset, which was created through the reannotation of available Arabic sentiment analysis datasets. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> contains 10,547 tweets, 16 % of which are <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcastic</a>. In addition to <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> the <a href=https://en.wikipedia.org/wiki/Data>data</a> was annotated for sentiment and dialects. Our analysis shows the highly subjective nature of these tasks, which is demonstrated by the shift in sentiment labels based on annotators&#8217; biases. Experiments show the degradation of state-of-the-art <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysers</a> when faced with sarcastic content. Finally, we train a <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning model</a> for sarcasm detection using BiLSTM. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieves an <a href=https://en.wikipedia.org/wiki/F-number>F1 score</a> of 0.46, which shows the challenging nature of the <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>, and should act as a basic baseline for future research on our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.osact-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--osact-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.osact-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.osact-1.9/>ALT Submission for OSACT Shared Task on Offensive Language Detection<span class=acl-fixed-case>ALT</span> Submission for <span class=acl-fixed-case>OSACT</span> Shared Task on Offensive Language Detection</a></strong><br><a href=/people/s/sabit-hassan/>Sabit Hassan</a>
|
<a href=/people/y/younes-samih/>Younes Samih</a>
|
<a href=/people/h/hamdy-mubarak/>Hamdy Mubarak</a>
|
<a href=/people/a/ahmed-abdelali/>Ahmed Abdelali</a>
|
<a href=/people/a/ammar-rashed/>Ammar Rashed</a>
|
<a href=/people/s/shammur-absar-chowdhury/>Shammur Absar Chowdhury</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--osact-1--9><div class="card-body p-3 small">In this paper, we describe our efforts at OSACT Shared Task on Offensive Language Detection. The shared <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a> consists of two subtasks : offensive language detection (Subtask A) and hate speech detection (Subtask B). For offensive language detection, a system combination of Support Vector Machines (SVMs) and <a href=https://en.wikipedia.org/wiki/Deep_learning>Deep Neural Networks (DNNs)</a> achieved the best results on development set, which ranked 1st in the official results for Subtask A with F1-score of 90.51 % on the test set. For hate speech detection, DNNs were less effective and a system combination of multiple SVMs with different parameters achieved the best results on development set, which ranked 4th in official results for Subtask B with F1-macro score of 80.63 % on the test set.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.osact-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--osact-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.osact-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.osact-1.10/>ASU_OPTO at OSACT4-Offensive Language Detection for Arabic text<span class=acl-fixed-case>ASU</span>_<span class=acl-fixed-case>OPTO</span> at <span class=acl-fixed-case>OSACT</span>4 - Offensive Language Detection for <span class=acl-fixed-case>A</span>rabic text</a></strong><br><a href=/people/a/amr-keleg/>Amr Keleg</a>
|
<a href=/people/s/samhaa-r-el-beltagy/>Samhaa R. El-Beltagy</a>
|
<a href=/people/m/mahmoud-khalil/>Mahmoud Khalil</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--osact-1--10><div class="card-body p-3 small">In the past years, toxic comments and offensive speech are polluting the internet and manual inspection of these comments is becoming a tiresome task to manage. Having a <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning based model</a> that is able to filter offensive Arabic content is of high need nowadays. In this paper, we describe the model that was submitted to the Shared Task on Offensive Language Detection that is organized by (The 4th Workshop on Open-Source Arabic Corpora and Processing Tools). Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> makes use transformer based model (BERT) to detect offensive content. We came in the fourth place in subtask A (detecting Offensive Speech) and in the third place in subtask B (detecting Hate Speech).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.osact-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--osact-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.osact-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.osact-1.16/>Multi-Task Learning using AraBert for Offensive Language Detection<span class=acl-fixed-case>A</span>ra<span class=acl-fixed-case>B</span>ert for Offensive Language Detection</a></strong><br><a href=/people/m/marc-djandji/>Marc Djandji</a>
|
<a href=/people/f/fady-baly/>Fady Baly</a>
|
<a href=/people/w/wissam-antoun/>Wissam Antoun</a>
|
<a href=/people/h/hazem-hajj/>Hazem Hajj</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--osact-1--16><div class="card-body p-3 small">The use of <a href=https://en.wikipedia.org/wiki/Social_media>social media platforms</a> has become more prevalent, which has provided tremendous opportunities for people to connect but has also opened the door for misuse with the spread of <a href=https://en.wikipedia.org/wiki/Hate_speech>hate speech</a> and <a href=https://en.wikipedia.org/wiki/Profanity>offensive language</a>. This phenomenon has been driving more and more people to more extreme reactions and online aggression, sometimes causing physical harm to individuals or groups of people. There is a need to control and prevent such misuse of <a href=https://en.wikipedia.org/wiki/Social_media>online social media</a> through automatic detection of profane language. The shared task on Offensive Language Detection at the OSACT4 has aimed at achieving state of art profane language detection methods for Arabic social media. Our team BERTologists tackled this problem by leveraging state of the art pretrained Arabic language model, AraBERT, that we augment with the addition of <a href=https://en.wikipedia.org/wiki/Multi-task_learning>Multi-task learning</a> to enable our model to learn efficiently from little data. Our Multitask AraBERT approach achieved the second place in both subtasks A & B, which shows that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> performs consistently across different tasks.</div></div></div><hr><div id=2020parlaclarin-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.parlaclarin-1/>Proceedings of the Second ParlaCLARIN Workshop</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.parlaclarin-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.parlaclarin-1.0/>Proceedings of the Second ParlaCLARIN Workshop</a></strong><br><a href=/people/d/darja-fiser/>Darja Fišer</a>
|
<a href=/people/m/maria-eskevich/>Maria Eskevich</a>
|
<a href=/people/f/franciska-de-jong/>Franciska de Jong</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.parlaclarin-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--parlaclarin-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.parlaclarin-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.parlaclarin-1.4/>Compiling Czech Parliamentary Stenographic Protocols into a Corpus<span class=acl-fixed-case>C</span>zech Parliamentary Stenographic Protocols into a Corpus</a></strong><br><a href=/people/b/barbora-hladka/>Barbora Hladka</a>
|
<a href=/people/m/matyas-kopp/>Matyáš Kopp</a>
|
<a href=/people/p/pavel-stranak/>Pavel Straňák</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--parlaclarin-1--4><div class="card-body p-3 small">The Parliament of the Czech Republic consists of two chambers : the Chamber of Deputies (Lower House) and the Senate (Upper House). In our work, we focus on agenda and documents that relate to the Chamber of Deputies exclusively. We pay particular attention to <a href=https://en.wikipedia.org/wiki/Shorthand>stenographic protocols</a> that record the Chamber of Deputies&#8217; meetings. Our overall goal is to (1) compile the protocols into a ParlaCLARIN TEI encoded corpus, (2) make this <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> accessible and searchable in the TEITOK web-based platform, (3) annotate the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> using the modules available in TEITOK, e.g. detect and recognize <a href=https://en.wikipedia.org/wiki/Named_entity>named entities</a>, and (4) highlight the <a href=https://en.wikipedia.org/wiki/Annotation>annotations</a> in TEITOK. In addition, we add two more goals that we consider innovative : (5) update the corpus every time a new stenographic protocol is published online by the Chambers of Deputies and (6) expose the annotations as the <a href=https://en.wikipedia.org/wiki/Linked_open_data>linked open data</a> in order to improve the protocols&#8217; interoperability with other existing <a href=https://en.wikipedia.org/wiki/Linked_open_data>linked open data</a>. This paper is devoted to the goals (1) and (5).</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.parlaclarin-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--parlaclarin-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.parlaclarin-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.parlaclarin-1.7/>Who mentions whom? Recognizing political actors in proceedings</a></strong><br><a href=/people/l/lennart-kerkvliet/>Lennart Kerkvliet</a>
|
<a href=/people/j/jaap-kamps/>Jaap Kamps</a>
|
<a href=/people/m/maarten-marx/>Maarten Marx</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--parlaclarin-1--7><div class="card-body p-3 small">We show that it is straightforward to train a state of the art named entity tagger (spaCy) to recognize political actors in Dutch parliamentary proceedings with high accuracy. The <a href=https://en.wikipedia.org/wiki/Tag_(metadata)>tagger</a> was trained on 3.4 K manually labeled examples, which were created in a modest 2.5 days work. This resource is made available on github. Besides proper nouns of persons and <a href=https://en.wikipedia.org/wiki/Political_party>political parties</a>, the tagger can recognize quite complex definite descriptions referring to cabinet ministers, ministries, and parliamentary committees. We also provide a demo search engine which employs the tagged entities in its <a href=https://en.wikipedia.org/wiki/Search_engine_results_page>SERP</a> and result summaries.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.parlaclarin-1.13.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--parlaclarin-1--13 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.parlaclarin-1.13 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.parlaclarin-1.13/>Querying a large annotated corpus of parliamentary debates</a></strong><br><a href=/people/s/sascha-diwersy/>Sascha Diwersy</a>
|
<a href=/people/g/giancarlo-luxardo/>Giancarlo Luxardo</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--parlaclarin-1--13><div class="card-body p-3 small">The TAPS corpus makes it possible to share a large volume of French parliamentary data. The TEI-compliant approach behind its design choices facilitates the publishing and the interoperability of data, but also the implementation of exploratory data analysis techniques in order to process institutional or political discourse. We demonstrate its application to the debates occurred in the context of a specific legislative process, which generated a strong opposition.</div></div></div><hr><div id=2020rail-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.rail-1/>Proceedings of the first workshop on Resources for African Indigenous Languages</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.rail-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.rail-1.0/>Proceedings of the first workshop on Resources for African Indigenous Languages</a></strong><br><a href=/people/r/rooweither-mabuya/>Rooweither Mabuya</a>
|
<a href=/people/p/phathutshedzo-ramukhadi/>Phathutshedzo Ramukhadi</a>
|
<a href=/people/m/mmasibidi-setaka/>Mmasibidi Setaka</a>
|
<a href=/people/v/valencia-wagner/>Valencia Wagner</a>
|
<a href=/people/m/menno-van-zaanen/>Menno van Zaanen</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.rail-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--rail-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.rail-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.rail-1.1/>Endangered African Languages Featured in a Digital Collection : The Case of the Khomani San, Hugh Brody Collection<span class=acl-fixed-case>A</span>frican Languages Featured in a Digital Collection: The Case of the ǂ<span class=acl-fixed-case>K</span>homani <span class=acl-fixed-case>S</span>an, <span class=acl-fixed-case>H</span>ugh <span class=acl-fixed-case>B</span>rody <span class=acl-fixed-case>C</span>ollection</a></strong><br><a href=/people/k/kerry-jones/>Kerry Jones</a>
|
<a href=/people/s/sanjin-muftic/>Sanjin Muftic</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--rail-1--1><div class="card-body p-3 small">The Khomani San, Hugh Brody Collection features the voices and history of indigenous hunter gatherer descendants in three endangered languages namely, N|uu, Kora and <a href=https://en.wikipedia.org/wiki/Khoekhoe_language>Khoekhoe</a> as well as a regional dialect of Afrikaans. A large component of this collection is audio-visual (legacy media) recordings of interviews conducted with members of the community by Hugh Brody and his colleagues between 1997 and 2012, referring as far back as the 1800s. The Digital Library Services team at the University of Cape Town aim to showcase the collection digitally on the UCT-wide Digital Collections platform, Ibali which runs on Omeka-S. In this paper we highlight the importance of such a collection in the context of <a href=https://en.wikipedia.org/wiki/South_Africa>South Africa</a>, and the ethical steps that were taken to ensure the respect of the Khomani San as their stories get uploaded onto a repository and become accessible to all. We will also feature some of the completed <a href=https://en.wikipedia.org/wiki/Collection_(publishing)>collection</a> on Ibali and guide the reader through the organisation of the <a href=https://en.wikipedia.org/wiki/Collection_(publishing)>collection</a> on the Omeka-S backend. Finally, we will outline our development process, from <a href=https://en.wikipedia.org/wiki/Digitization>digitisation</a> to repository publishing as well as present some of the challenges in data clean-up, the curation of legacy media, multi-lingual support, and site organisation.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.rail-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--rail-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.rail-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.rail-1.4/>Complex Setswana Parts of Speech Tagging</a></strong><br><a href=/people/g/gabofetswe-malema/>Gabofetswe Malema</a>
|
<a href=/people/b/boago-okgetheng/>Boago Okgetheng</a>
|
<a href=/people/b/bopaki-tebalo/>Bopaki Tebalo</a>
|
<a href=/people/m/moffat-motlhanka/>Moffat Motlhanka</a>
|
<a href=/people/g/goaletsa-rammidi/>Goaletsa Rammidi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--rail-1--4><div class="card-body p-3 small">Setswana language is one of the <a href=https://en.wikipedia.org/wiki/Bantu_languages>Bantu languages</a> written disjunctively. Some of its <a href=https://en.wikipedia.org/wiki/Part_of_speech>parts of speech</a> such as qualificatives and some <a href=https://en.wikipedia.org/wiki/Adverb>adverbs</a> are made up of multiple words. That is, the <a href=https://en.wikipedia.org/wiki/Part_of_speech>part of speech</a> is made up of a group of words. The disjunctive style of writing poses a challenge when a sentence is tokenized or when <a href=https://en.wikipedia.org/wiki/Tag_(metadata)>tagging</a>. A few studies have been done on identification of multi-word parts of speech. In this study we go further to tokenize complex parts of speech which are formed by extending basic forms of multi-word parts of speech. The parts of speech are extended by recursively concatenating more parts of speech to a basic form of parts of speech. We developed <a href=https://en.wikipedia.org/wiki/Linguistic_prescription>rules</a> for building complex relative parts of speech. A morphological analyzer and Python NLTK are used to tag individual words and basic forms of multi-word parts of speech. Developed <a href=https://en.wikipedia.org/wiki/Rule_of_inference>rules</a> are then used to identify complex parts of speech. Results from a 300 sentence text files give a performance of 74 %. The <a href=https://en.wikipedia.org/wiki/Tagger>tagger</a> fails when it encounters expansion rules not implemented and when <a href=https://en.wikipedia.org/wiki/Tag_(metadata)>tagging</a> by the morphological analyzer is incorrect.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.rail-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--rail-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.rail-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.rail-1.5/>Comparing Neural Network Parsers for a Less-resourced and Morphologically-rich Language : Amharic Dependency Parser<span class=acl-fixed-case>A</span>mharic Dependency Parser</a></strong><br><a href=/people/b/binyam-ephrem-seyoum/>Binyam Ephrem Seyoum</a>
|
<a href=/people/y/yusuke-miyao/>Yusuke Miyao</a>
|
<a href=/people/b/baye-yimam-mekonnen/>Baye Yimam Mekonnen</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--rail-1--5><div class="card-body p-3 small">In this paper, we compare four state-of-the-art neural network dependency parsers for the Semitic language Amharic. As <a href=https://en.wikipedia.org/wiki/Amharic>Amharic</a> is a morphologically-rich and less-resourced language, the out-of-vocabulary (OOV) problem will be higher when we develop data-driven models. This fact limits researchers to develop <a href=https://en.wikipedia.org/wiki/Neural_network>neural network parsers</a> because the <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> requires large quantities of data to train a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a>. We empirically evaluate neural network parsers when a small Amharic treebank is used for training. Based on our experiment, we obtain an 83.79 LAS score using the UDPipe system. Better <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> is achieved when the neural parsing system uses external resources like <a href=https://en.wikipedia.org/wiki/Word_embedding>word embedding</a>. Using such <a href=https://en.wikipedia.org/wiki/Resource_(computer_science)>resources</a>, the LAS score for UDPipe improves to 85.26. Our experiment shows that the <a href=https://en.wikipedia.org/wiki/Neural_network>neural networks</a> can learn dependency relations better from limited data while segmentation and POS tagging require much data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.rail-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--rail-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.rail-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.rail-1.6/>Mobilizing Metadata : Open Data Kit (ODK) for Language Resource Development in East Africa<span class=acl-fixed-case>ODK</span>) for Language Resource Development in <span class=acl-fixed-case>E</span>ast <span class=acl-fixed-case>A</span>frica</a></strong><br><a href=/people/r/richard-griscom/>Richard Griscom</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--rail-1--6><div class="card-body p-3 small">Linguistic fieldworkers collect and archive metadata as part of the language resources (LRs) that they create, but they often work in resource-constrained environments that prevent them from using <a href=https://en.wikipedia.org/wiki/Computer>computers</a> for <a href=https://en.wikipedia.org/wiki/Data_entry_clerk>data entry</a>. In such situations, linguists must complete time-consuming and error-prone digitization tasks that limit the quantity and quality of the resources and metadata that they produce (Thieberger & Berez 2012 ; Margetts & Margetts 2012). This paper describes a method for entering <a href=https://en.wikipedia.org/wiki/Metadata>linguistic metadata</a> into <a href=https://en.wikipedia.org/wiki/Mobile_device>mobile devices</a> using the Open Data Kit (ODK) platform, a suite of open source tools designed for mobile data collection.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.rail-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--rail-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.rail-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.rail-1.7/>A Computational Grammar of Ga<span class=acl-fixed-case>G</span>a</a></strong><br><a href=/people/l/lars-hellan/>Lars Hellan</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--rail-1--7><div class="card-body p-3 small">The paper describes aspects of an HPSG style computational grammar of the West African language Ga (a <a href=https://en.wikipedia.org/wiki/Kwa_languages>Kwa language</a> spoken in the Accra area of Ghana). As a Volta Basin Kwa language, Ga features many types of multiverb expressions and other particular constructional patterns in the verbal and nominal domain. The paper highlights theoretical and formal features of the <a href=https://en.wikipedia.org/wiki/Grammar>grammar</a> motivated by these phenomena, some of them possibly innovative to the <a href=https://en.wikipedia.org/wiki/Formal_grammar>formal framework</a>. As a so-called deep grammar of the language, it hosts a rich lexical structure, and we describe ways in which the <a href=https://en.wikipedia.org/wiki/Grammar>grammar</a> builds on previously available lexical resources. We outline an environment of current resources in which the <a href=https://en.wikipedia.org/wiki/Grammar>grammar</a> is part, and lines of research and development in which it and its environment can be used.</div></div></div><hr><div id=2020readi-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.readi-1/>Proceedings of the 1st Workshop on Tools and Resources to Empower People with REAding DIfficulties (READI)</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.readi-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.readi-1.0/>Proceedings of the 1st Workshop on Tools and Resources to Empower People with REAding DIfficulties (READI)</a></strong><br><a href=/people/n/nuria-gala/>Núria Gala</a>
|
<a href=/people/r/rodrigo-wilkens/>Rodrigo Wilkens</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.readi-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--readi-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.readi-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.readi-1.4/>Automatically Assess Children’s Reading Skills</a></strong><br><a href=/people/o/ornella-mich/>Ornella Mich</a>
|
<a href=/people/n/nadia-mana/>Nadia Mana</a>
|
<a href=/people/r/roberto-gretter/>Roberto Gretter</a>
|
<a href=/people/m/marco-matassoni/>Marco Matassoni</a>
|
<a href=/people/d/daniele-falavigna/>Daniele Falavigna</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--readi-1--4><div class="card-body p-3 small">Assessing reading skills is an important task teachers have to perform at the beginning of a new scholastic year to evaluate the starting level of the class and properly plan next learning activities. Digital tools based on automatic speech recognition (ASR) may be really useful to support teachers in this task, currently very time consuming and prone to human errors. This paper presents a <a href=https://en.wikipedia.org/wiki/Web_application>web application</a> for automatically assessing fluency and accuracy of oral reading in children attending Italian primary and lower secondary schools. Our system, based on ASR technology, implements the Cornoldi&#8217;s MT battery, which is a well-known Italian test to assess reading skills. The front-end of the <a href=https://en.wikipedia.org/wiki/System>system</a> has been designed following the participatory design approach by involving end users from the beginning of the creation process. Teachers may use our system to both test student&#8217;s reading skills and monitor their performance over time. In fact, the system offers an effective graphical visualization of the assessment results for both individual students and entire class. The paper also presents the results of a pilot study to evaluate the <a href=https://en.wikipedia.org/wiki/System>system</a> usability with teachers.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.readi-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--readi-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.readi-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.readi-1.5/>Text Simplification to Help Individuals with Low Vision Read More Fluently</a></strong><br><a href=/people/l/lauren-sauvan/>Lauren Sauvan</a>
|
<a href=/people/n/natacha-stolowy/>Natacha Stolowy</a>
|
<a href=/people/c/carlos-aguilar/>Carlos Aguilar</a>
|
<a href=/people/t/thomas-francois/>Thomas François</a>
|
<a href=/people/n/nuria-gala/>Núria Gala</a>
|
<a href=/people/f/frederic-matonti/>Frédéric Matonti</a>
|
<a href=/people/e/eric-castet/>Eric Castet</a>
|
<a href=/people/a/aurelie-calabrese/>Aurélie Calabrèse</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--readi-1--5><div class="card-body p-3 small">The objective of this work is to introduce text simplification as a potential reading aid to help improve the poor reading performance experienced by visually impaired individuals. As a first step, we explore what makes a text especially complex when read with <a href=https://en.wikipedia.org/wiki/Visual_impairment>low vision</a>, by assessing the individual effect of three word properties (frequency, orthographic similarity and length) on reading speed in the presence of Central visual Field Loss (CFL). Individuals with bilateral CFL induced by <a href=https://en.wikipedia.org/wiki/Macular_degeneration>macular diseases</a> read pairs of French sentences displayed with the self-paced reading method. For each sentence pair, sentence n contained a target word matched with a synonym word of the same length included in sentence n+1. Reading time was recorded for each target word. Given the corpus we used, our results show that (1) word frequency has a significant effect on reading time (the more frequent the faster the reading speed) with larger amplitude (in the range of seconds) compared to normal vision ; (2) word neighborhood size has a significant effect on reading time (the more neighbors the slower the reading speed), this effect being rather small in amplitude, but interestingly reversed compared to normal vision ; (3) word length has no significant effect on reading time. Supporting the development of new and more effective <a href=https://en.wikipedia.org/wiki/Assistive_technology>assistive technology</a> to help <a href=https://en.wikipedia.org/wiki/Visual_impairment>low vision</a> is an important and timely issue, with massive potential implications for social and rehabilitation practices. The end goal of this project will be to use our findings to custom text simplification to this specific population and use it as an optimal and efficient reading aid.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.readi-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--readi-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.readi-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.readi-1.10/>LagunTest : A NLP Based Application to Enhance Reading Comprehension<span class=acl-fixed-case>L</span>agun<span class=acl-fixed-case>T</span>est: A <span class=acl-fixed-case>NLP</span> Based Application to Enhance Reading Comprehension</a></strong><br><a href=/people/k/kepa-bengoetxea/>Kepa Bengoetxea</a>
|
<a href=/people/i/itziar-gonzalez-dios/>Itziar Gonzalez-Dios</a>
|
<a href=/people/a/amaia-aguirregoitia/>Amaia Aguirregoitia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--readi-1--10><div class="card-body p-3 small">The ability to read and understand written texts plays an important role in <a href=https://en.wikipedia.org/wiki/Education>education</a>, above all in the last years of primary education. This is especially pertinent in <a href=https://en.wikipedia.org/wiki/Language_immersion>language immersion educational programmes</a>, where some students have low linguistic competence in the languages of instruction. In this context, adapting the texts to the individual needs of each student requires a considerable effort by education professionals. However, <a href=https://en.wikipedia.org/wiki/Language_technology>language technologies</a> can facilitate the laborious adaptation of materials in order to enhance <a href=https://en.wikipedia.org/wiki/Reading_comprehension>reading comprehension</a>. In this paper, we present LagunTest, a NLP based application that takes as input a text in Basque or <a href=https://en.wikipedia.org/wiki/English_language>English</a>, and offers synonyms, definitions, examples of the words in different contexts and presents some linguistic characteristics as well as visualizations. LagunTest is based on reusable and open multilingual and multimodal tools, and it is also distributed with an open license. LagunTest is intended to ease the burden of education professionals in the task of adapting materials, and the output should always be supervised by them.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.readi-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--readi-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.readi-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.readi-1.11/>A Lexical Simplification Tool for Promoting Health Literacy</a></strong><br><a href=/people/l/leonardo-zilio/>Leonardo Zilio</a>
|
<a href=/people/l/liana-braga-paraguassu/>Liana Braga Paraguassu</a>
|
<a href=/people/l/luis-antonio-leiva-hercules/>Luis Antonio Leiva Hercules</a>
|
<a href=/people/g/gabriel-ponomarenko/>Gabriel Ponomarenko</a>
|
<a href=/people/l/laura-berwanger/>Laura Berwanger</a>
|
<a href=/people/m/maria-jose-bocorny-finatto/>Maria José Bocorny Finatto</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--readi-1--11><div class="card-body p-3 small">This paper presents MedSimples, an authoring tool that combines <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a>, <a href=https://en.wikipedia.org/wiki/Corpus_linguistics>Corpus Linguistics</a> and <a href=https://en.wikipedia.org/wiki/Terminology>Terminology</a> to help writers to convert health-related information into a more accessible version for people with low literacy skills. MedSimples applies parsing methods associated with lexical resources to automatically evaluate a text and present simplification suggestions that are more suitable for the target audience. Using the suggestions provided by the <a href=https://en.wikipedia.org/wiki/Tool>tool</a>, the author can adapt the original text and make it more accessible. The focus of MedSimples lies on texts for special purposes, so that it not only deals with <a href=https://en.wikipedia.org/wiki/Vocabulary>general vocabulary</a>, but also with <a href=https://en.wikipedia.org/wiki/Specialization_(functional)>specialized terms</a>. The <a href=https://en.wikipedia.org/wiki/Tool>tool</a> is currently under development, but an online working prototype exists and can be tested freely. An assessment of MedSimples was carried out aiming at evaluating its current performance with some promising results, especially for informing the future developments that are planned for the tool.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.readi-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--readi-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.readi-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.readi-1.12/>A multi-lingual and cross-domain analysis of features for <a href=https://en.wikipedia.org/wiki/Text_simplification>text simplification</a></a></strong><br><a href=/people/r/regina-stodden/>Regina Stodden</a>
|
<a href=/people/l/laura-kallmeyer/>Laura Kallmeyer</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--readi-1--12><div class="card-body p-3 small">In <a href=https://en.wikipedia.org/wiki/Text_simplification>text simplification</a> and readability research, several features have been proposed to estimate or simplify a complex text, e.g., readability scores, <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence length</a>, or proportion of POS tags. These <a href=https://en.wikipedia.org/wiki/Software_feature>features</a> are however mainly developed for <a href=https://en.wikipedia.org/wiki/English_language>English</a>. In this paper, we investigate their relevance for <a href=https://en.wikipedia.org/wiki/Czech_language>Czech</a>, <a href=https://en.wikipedia.org/wiki/German_language>German</a>, English, Spanish, and Italian text simplification corpora. Our multi-lingual and multi-domain corpus analysis shows that the relevance of different <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> for text simplification is different per corpora, language, and domain. For example, the relevance of the lexical complexity is different across all languages, the BLEU score across all domains, and 14 <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a> within the web domain corpora. Overall, the negative statistical tests regarding the other <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>features</a> across and within domains and languages lead to the assumption that text simplification models may be transferable between different domains or different languages.</div></div></div><hr><div id=2020repl4nlp-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.repl4nlp-1/>Proceedings of the 5th Workshop on Representation Learning for NLP</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.0/>Proceedings of the 5th Workshop on Representation Learning for NLP</a></strong><br><a href=/people/s/spandana-gella/>Spandana Gella</a>
|
<a href=/people/j/johannes-welbl/>Johannes Welbl</a>
|
<a href=/people/m/marek-rei/>Marek Rei</a>
|
<a href=/people/f/fabio-petroni/>Fabio Petroni</a>
|
<a href=/people/p/patrick-lewis/>Patrick Lewis</a>
|
<a href=/people/e/emma-strubell/>Emma Strubell</a>
|
<a href=/people/m/minjoon-seo/>Minjoon Seo</a>
|
<a href=/people/h/hannaneh-hajishirzi/>Hannaneh Hajishirzi</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--repl4nlp-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.repl4nlp-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929767 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.1/>Zero-Resource Cross-Domain Named Entity Recognition</a></strong><br><a href=/people/z/zihan-liu/>Zihan Liu</a>
|
<a href=/people/g/genta-indra-winata/>Genta Indra Winata</a>
|
<a href=/people/p/pascale-fung/>Pascale Fung</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--repl4nlp-1--1><div class="card-body p-3 small">Existing models for cross-domain named entity recognition (NER) rely on numerous unlabeled corpus or labeled NER training data in target domains. However, collecting data for low-resource target domains is not only expensive but also time-consuming. Hence, we propose a cross-domain NER model that does not use any <a href=https://en.wikipedia.org/wiki/Resource_(computing)>external resources</a>. We first introduce a Multi-Task Learning (MTL) by adding a new <a href=https://en.wikipedia.org/wiki/Loss_function>objective function</a> to detect whether tokens are named entities or not. We then introduce a <a href=https://en.wikipedia.org/wiki/Software_framework>framework</a> called Mixture of Entity Experts (MoEE) to improve the <a href=https://en.wikipedia.org/wiki/Robustness_(computer_science)>robustness</a> for zero-resource domain adaptation. Finally, experimental results show that our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> outperforms strong unsupervised cross-domain sequence labeling models, and the performance of our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is close to that of the state-of-the-art model which leverages extensive resources.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--repl4nlp-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.repl4nlp-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929768 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.2/>Encodings of Source Syntax : Similarities in NMT Representations Across Target Languages<span class=acl-fixed-case>NMT</span> Representations Across Target Languages</a></strong><br><a href=/people/t/tyler-a-chang/>Tyler A. Chang</a>
|
<a href=/people/a/anna-n-rafferty/>Anna Rafferty</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--repl4nlp-1--2><div class="card-body p-3 small">We train neural machine translation (NMT) models from <a href=https://en.wikipedia.org/wiki/English_language>English</a> to six target languages, using NMT encoder representations to predict ancestor constituent labels of source language words. We find that NMT encoders learn similar source syntax regardless of NMT target language, relying on explicit morphosyntactic cues to extract syntactic features from source sentences. Furthermore, the NMT encoders outperform RNNs trained directly on several of the constituent label prediction tasks, suggesting that NMT encoder representations can be used effectively for natural language tasks involving <a href=https://en.wikipedia.org/wiki/Syntax>syntax</a>. However, both the NMT encoders and the directly-trained RNNs learn substantially different syntactic information from a probabilistic context-free grammar (PCFG) parser. Despite lower overall accuracy scores, the PCFG often performs well on sentences for which the RNN-based models perform poorly, suggesting that RNN architectures are constrained in the types of syntax they can learn.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--repl4nlp-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.repl4nlp-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929769 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.3/>Learning Probabilistic Sentence Representations from Paraphrases</a></strong><br><a href=/people/m/mingda-chen/>Mingda Chen</a>
|
<a href=/people/k/kevin-gimpel/>Kevin Gimpel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--repl4nlp-1--3><div class="card-body p-3 small">Probabilistic word embeddings have shown effectiveness in capturing notions of generality and <a href=https://en.wikipedia.org/wiki/Logical_consequence>entailment</a>, but there is very little work on doing the analogous type of investigation for sentences. In this paper we define <a href=https://en.wikipedia.org/wiki/Statistical_model>probabilistic models</a> that produce <a href=https://en.wikipedia.org/wiki/Probability_distribution>distributions</a> for sentences. Our best-performing <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> treats each word as a <a href=https://en.wikipedia.org/wiki/Linear_map>linear transformation operator</a> applied to a <a href=https://en.wikipedia.org/wiki/Normal_distribution>multivariate Gaussian distribution</a>. We train our <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> on <a href=https://en.wikipedia.org/wiki/Paraphrase>paraphrases</a> and demonstrate that they naturally capture sentence specificity. While our proposed model achieves the best performance overall, we also show that <a href=https://en.wikipedia.org/wiki/Sensitivity_and_specificity>specificity</a> is represented by simpler <a href=https://en.wikipedia.org/wiki/Computer_architecture>architectures</a> via the norm of the sentence vectors. Qualitative analysis shows that our probabilistic model captures sentential entailment and provides ways to analyze the specificity and preciseness of individual words.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--repl4nlp-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.repl4nlp-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929770 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.4/>Word Embeddings as Tuples of Feature Probabilities</a></strong><br><a href=/people/s/siddharth-bhat/>Siddharth Bhat</a>
|
<a href=/people/a/alok-debnath/>Alok Debnath</a>
|
<a href=/people/s/souvik-banerjee/>Souvik Banerjee</a>
|
<a href=/people/m/manish-shrivastava/>Manish Shrivastava</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--repl4nlp-1--4><div class="card-body p-3 small">In this paper, we provide an alternate perspective on <a href=https://en.wikipedia.org/wiki/Word_(group_theory)>word representations</a>, by reinterpreting the dimensions of the vector space of a <a href=https://en.wikipedia.org/wiki/Word_embedding>word embedding</a> as a collection of <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>features</a>. In this reinterpretation, every component of the word vector is normalized against all the word vectors in the vocabulary. This idea now allows us to view each vector as an n-tuple (akin to a fuzzy set), where n is the dimensionality of the word representation and each element represents the probability of the word possessing a <a href=https://en.wikipedia.org/wiki/Feature_(machine_learning)>feature</a>. Indeed, this representation enables the use fuzzy set theoretic operations, such as <a href=https://en.wikipedia.org/wiki/Union_(set_theory)>union</a>, <a href=https://en.wikipedia.org/wiki/Intersection_(set_theory)>intersection</a> and <a href=https://en.wikipedia.org/wiki/Subtraction>difference</a>. Unlike previous attempts, we show that this representation of words provides a notion of similarity which is inherently asymmetric and hence closer to human similarity judgements. We compare the performance of this representation with various <a href=https://en.wikipedia.org/wiki/Benchmark_(computing)>benchmarks</a>, and explore some of the unique properties including function word detection, detection of polysemous words, and some insight into the interpretability provided by set theoretic operations.<tex-math>n</tex-math>-tuple (akin to a fuzzy set), where <tex-math>n</tex-math> is the dimensionality of the word representation and each element represents the probability of the word possessing a feature. Indeed, this representation enables the use fuzzy set theoretic operations, such as union, intersection and difference. Unlike previous attempts, we show that this representation of words provides a notion of similarity which is inherently asymmetric and hence closer to human similarity judgements. We compare the performance of this representation with various benchmarks, and explore some of the unique properties including function word detection, detection of polysemous words, and some insight into the interpretability provided by set theoretic operations.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--repl4nlp-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.repl4nlp-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929771 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.5/>Compositionality and Capacity in Emergent Languages</a></strong><br><a href=/people/a/abhinav-gupta/>Abhinav Gupta</a>
|
<a href=/people/c/cinjon-resnick/>Cinjon Resnick</a>
|
<a href=/people/j/jakob-foerster/>Jakob Foerster</a>
|
<a href=/people/a/andrew-dai/>Andrew Dai</a>
|
<a href=/people/k/kyunghyun-cho/>Kyunghyun Cho</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--repl4nlp-1--5><div class="card-body p-3 small">Recent works have discussed the extent to which <a href=https://en.wikipedia.org/wiki/Emergence>emergent languages</a> can exhibit properties of <a href=https://en.wikipedia.org/wiki/Natural_language>natural languages</a> particularly learning compositionality. In this paper, we investigate the <a href=https://en.wikipedia.org/wiki/Learning_bias>learning biases</a> that affect the efficacy and <a href=https://en.wikipedia.org/wiki/Compositionality>compositionality</a> in multi-agent communication in addition to the communicative bandwidth. Our foremost contribution is to explore how the capacity of a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network</a> impacts its ability to learn a compositional language. We additionally introduce a set of evaluation metrics with which we analyze the learned languages. Our hypothesis is that there should be a specific range of model capacity and <a href=https://en.wikipedia.org/wiki/Bandwidth_(signal_processing)>channel bandwidth</a> that induces compositional structure in the resulting language and consequently encourages systematic generalization. While we empirically see evidence for the bottom of this range, we curiously do not find evidence for the top part of the range and believe that this is an open question for the community.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--repl4nlp-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.repl4nlp-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.repl4nlp-1.6.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929772 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.6/>Learning Geometric Word Meta-Embeddings</a></strong><br><a href=/people/p/pratik-jawanpuria/>Pratik Jawanpuria</a>
|
<a href=/people/s/satya-dev-n-t-v/>Satya Dev N T V</a>
|
<a href=/people/a/anoop-kunchukuttan/>Anoop Kunchukuttan</a>
|
<a href=/people/b/bamdev-mishra/>Bamdev Mishra</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--repl4nlp-1--6><div class="card-body p-3 small">We propose a geometric framework for learning meta-embeddings of words from different embedding sources. Our framework transforms the <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a> into a common latent space, where, for example, simple averaging or concatenation of different embeddings (of a given word) is more amenable. The proposed latent space arises from two particular geometric transformations-source embedding specific orthogonal rotations and a common Mahalanobis metric scaling. Empirical results on several word similarity and word analogy benchmarks illustrate the efficacy of the proposed framework.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--repl4nlp-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.repl4nlp-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929776 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.10/>Exploring the Limits of Simple Learners in Knowledge Distillation for <a href=https://en.wikipedia.org/wiki/Document_classification>Document Classification</a> with DocBERT<span class=acl-fixed-case>D</span>oc<span class=acl-fixed-case>BERT</span></a></strong><br><a href=/people/a/ashutosh-adhikari/>Ashutosh Adhikari</a>
|
<a href=/people/a/achyudh-ram/>Achyudh Ram</a>
|
<a href=/people/r/raphael-tang/>Raphael Tang</a>
|
<a href=/people/w/william-l-hamilton/>William L. Hamilton</a>
|
<a href=/people/j/jimmy-lin/>Jimmy Lin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--repl4nlp-1--10><div class="card-body p-3 small">Fine-tuned variants of BERT are able to achieve state-of-the-art <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> on many natural language processing tasks, although at significant computational costs. In this paper, we verify BERT&#8217;s effectiveness for document classification and investigate the extent to which BERT-level effectiveness can be obtained by different baselines, combined with knowledge distillationa popular model compression method. The results show that BERT-level effectiveness can be achieved by a single-layer LSTM with at least 40 fewer FLOPS and only 3 % parameters. More importantly, this study analyzes the limits of knowledge distillation as we distill BERT&#8217;s knowledge all the way down to linear modelsa relevant baseline for the task. We report substantial improvement in <a href=https://en.wikipedia.org/wiki/Effectiveness>effectiveness</a> for even the simplest <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>, as they capture the knowledge learnt by BERT.<tex-math>40\\times</tex-math> fewer FLOPS and only <tex-math>{\\sim}3\\%</tex-math> parameters. More importantly, this study analyzes the limits of knowledge distillation as we distill BERT&#8217;s knowledge all the way down to linear models&#8212;a relevant baseline for the task. We report substantial improvement in effectiveness for even the simplest models, as they capture the knowledge learnt by BERT.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--repl4nlp-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.repl4nlp-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929782 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.repl4nlp-1.16" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.16/>Are All Languages Created Equal in Multilingual BERT?<span class=acl-fixed-case>BERT</span>?</a></strong><br><a href=/people/s/shijie-wu/>Shijie Wu</a>
|
<a href=/people/m/mark-dredze/>Mark Dredze</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--repl4nlp-1--16><div class="card-body p-3 small">Multilingual BERT (mBERT) trained on 104 languages has shown surprisingly good cross-lingual performance on several NLP tasks, even without explicit cross-lingual signals. However, these evaluations have focused on cross-lingual transfer with high-resource languages, covering only a third of the languages covered by mBERT. We explore how mBERT performs on a much wider set of languages, focusing on the quality of representation for low-resource languages, measured by within-language performance. We consider three tasks : <a href=https://en.wikipedia.org/wiki/Named-entity_recognition>Named Entity Recognition</a> (99 languages), <a href=https://en.wikipedia.org/wiki/Part-of-speech_tagging>Part-of-speech Tagging</a> and Dependency Parsing (54 languages each). mBERT does better than or comparable to baselines on high resource languages but does much worse for low resource languages. Furthermore, monolingual BERT models for these <a href=https://en.wikipedia.org/wiki/Language>languages</a> do even worse. Paired with similar languages, the performance gap between monolingual BERT and mBERT can be narrowed. We find that better <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> for low resource languages require more efficient pretraining techniques or more data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.repl4nlp-1.22.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--repl4nlp-1--22 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.repl4nlp-1.22 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.repl4nlp-1.22.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929788 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.repl4nlp-1.22/>Evaluating Compositionality of Sentence Representation Models</a></strong><br><a href=/people/h/hanoz-bhathena/>Hanoz Bhathena</a>
|
<a href=/people/a/angelica-willis/>Angelica Willis</a>
|
<a href=/people/n/nathan-dass/>Nathan Dass</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--repl4nlp-1--22><div class="card-body p-3 small">We evaluate the compositionality of general-purpose sentence encoders by proposing two different <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metrics</a> to quantify compositional understanding capability of sentence encoders. We introduce a novel <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a>, Polarity Sensitivity Scoring (PSS), which utilizes sentiment perturbations as a proxy for measuring <a href=https://en.wikipedia.org/wiki/Compositionality>compositionality</a>. We then compare results from PSS with those obtained via our proposed extension of a <a href=https://en.wikipedia.org/wiki/Metric_(mathematics)>metric</a> called Tree Reconstruction Error (TRE) (CITATION) where compositionality is evaluated by measuring how well a true representation producing model can be approximated by a <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> that explicitly combines representations of its primitives.</div></div></div><hr><div id=2020restup-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.restup-1/>Proceedings of the Workshop on Resources and Techniques for User and Author Profiling in Abusive Language</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.restup-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.restup-1.0/>Proceedings of the Workshop on Resources and Techniques for User and Author Profiling in Abusive Language</a></strong><br><a href=/people/j/johanna-monti/>Johanna Monti</a>
|
<a href=/people/v/valerio-basile/>Valerio Basile</a>
|
<a href=/people/m/maria-pia-di-buono/>Maria Pia Di Buono</a>
|
<a href=/people/r/raffaele-manna/>Raffaele Manna</a>
|
<a href=/people/a/antonio-pascucci/>Antonio Pascucci</a>
|
<a href=/people/s/sara-tonelli/>Sara Tonelli</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.restup-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--restup-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.restup-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.restup-1.1/>Profiling Bots, Fake News Spreaders and Haters</a></strong><br><a href=/people/p/paolo-rosso/>Paolo Rosso</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--restup-1--1><div class="card-body p-3 small">Author profiling studies how language is shared by people. Stylometry techniques help in identifying aspects such as gender, age, <a href=https://en.wikipedia.org/wiki/First_language>native language</a>, or even <a href=https://en.wikipedia.org/wiki/Personality>personality</a>. Author profiling is a problem of growing importance, not only in marketing and forensics, but also in <a href=https://en.wikipedia.org/wiki/Computer_security>cybersecurity</a>. The aim is not only to identify users whose messages are potential threats from a terrorism viewpoint but also those whose messages are a threat from a social exclusion perspective because containing <a href=https://en.wikipedia.org/wiki/Hate_speech>hate speech</a>, <a href=https://en.wikipedia.org/wiki/Cyberbullying>cyberbullying</a> etc. Bots often play a key role in spreading <a href=https://en.wikipedia.org/wiki/Hate_speech>hate speech</a>, as well as <a href=https://en.wikipedia.org/wiki/Fake_news>fake news</a>, with the purpose of polarizing the public opinion with respect to controversial issues like <a href=https://en.wikipedia.org/wiki/Brexit>Brexit</a> or the <a href=https://en.wikipedia.org/wiki/2017_Catalan_independence_referendum>Catalan referendum</a>. For instance, the authors of a recent study about the 1 Oct 2017 Catalan referendum, showed that in a <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> with 3.6 million tweets, about 23.6 % of tweets were produced by <a href=https://en.wikipedia.org/wiki/Internet_bot>bots</a>. The target of these <a href=https://en.wikipedia.org/wiki/Internet_bot>bots</a> were pro-independence influencers that were sent negative, emotional and aggressive hateful tweets with hashtags such as # sonunesbesties (i.e. # theyareanimals). Since 2013 at the PAN Lab at CLEF (https://pan.webis.de/) we have addressed several aspects of <a href=https://en.wikipedia.org/wiki/Author_profiling>author profiling</a> in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. In 2019 we investigated the feasibility of distinguishing whether the author of a <a href=https://en.wikipedia.org/wiki/Twitter>Twitter feed</a> is a bot, while this year we are addressing the problem of profiling those authors that are more likely to spread <a href=https://en.wikipedia.org/wiki/Fake_news>fake news</a> in <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> because they did in the past. We aim at identifying possible <a href=https://en.wikipedia.org/wiki/Fake_news>fake news spreaders</a> as a first step towards preventing <a href=https://en.wikipedia.org/wiki/Fake_news>fake news</a> from being propagated among online users (fake news aim to polarize the public opinion and may contain hate speech). In 2021 we specifically aim at addressing the challenging problem of profiling haters in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> in order to monitor abusive language and prevent cases of <a href=https://en.wikipedia.org/wiki/Social_exclusion>social exclusion</a> in order to combat, for instance, <a href=https://en.wikipedia.org/wiki/Racism>racism</a>, <a href=https://en.wikipedia.org/wiki/Xenophobia>xenophobia</a> and <a href=https://en.wikipedia.org/wiki/Misogyny>misogyny</a>. Although we already started addressing the problem of detecting hate speech when targets are immigrants or women at the HatEval shared task in SemEval-2019, and when targets are women also in the Automatic Misogyny Identification tasks at IberEval-2018, Evalita-2018 and Evalita-2020, it was not done from an author profiling perspective. At the end of the keynote, I will present some insights in order to stress the importance of monitoring abusive language in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>, for instance, in foreseeing sexual crimes. In fact, previous studies confirmed that a correlation might lay between the yearly per capita rate of rape and the misogynistic language used in <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.restup-1.2.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--restup-1--2 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.restup-1.2 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.restup-1.2/>An Indian Language Social Media Collection for Hate and Offensive Speech<span class=acl-fixed-case>I</span>ndian Language Social Media Collection for Hate and Offensive Speech</a></strong><br><a href=/people/a/anita-saroj/>Anita Saroj</a>
|
<a href=/people/s/sukomal-pal/>Sukomal Pal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--restup-1--2><div class="card-body p-3 small">In <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>, people express themselves every day on issues that affect their lives. During the <a href=https://en.wikipedia.org/wiki/Elections_in_Pakistan>parliamentary elections</a>, people&#8217;s interaction with the candidates in social media posts reflects a lot of social trends in a charged atmosphere. People&#8217;s likes and dislikes on leaders, <a href=https://en.wikipedia.org/wiki/Political_party>political parties</a> and their stands often become subject of hate and offensive posts. We collected social media posts in <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a> and <a href=https://en.wikipedia.org/wiki/English_language>English</a> from <a href=https://en.wikipedia.org/wiki/Facebook>Facebook</a> and <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a> during the run-up to the parliamentary election 2019 of India (PEI data-2019). We created a dataset for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> into three categories : <a href=https://en.wikipedia.org/wiki/Hate_speech>hate speech</a>, offensive and not hate, or not offensive. We report here the initial results of sentiment classification for the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> using different <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a>.</div></div></div><hr><div id=2020sigmorphon-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sigmorphon-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.sigmorphon-1/>Proceedings of the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sigmorphon-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sigmorphon-1.0/>Proceedings of the 17th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology</a></strong><br><a href=/people/g/garrett-nicolai/>Garrett Nicolai</a>
|
<a href=/people/k/kyle-gorman/>Kyle Gorman</a>
|
<a href=/people/r/ryan-cotterell/>Ryan Cotterell</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sigmorphon-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sigmorphon-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sigmorphon-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sigmorphon-1.6/>The CMU-LTI submission to the SIGMORPHON 2020 Shared Task 0 : Language-Specific Cross-Lingual Transfer<span class=acl-fixed-case>CMU</span>-<span class=acl-fixed-case>LTI</span> submission to the <span class=acl-fixed-case>SIGMORPHON</span> 2020 Shared Task 0: Language-Specific Cross-Lingual Transfer</a></strong><br><a href=/people/n/nikitha-murikinati/>Nikitha Murikinati</a>
|
<a href=/people/a/antonios-anastasopoulos/>Antonios Anastasopoulos</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sigmorphon-1--6><div class="card-body p-3 small">This paper describes the CMU-LTI submission to the SIGMORPHON 2020 Shared Task 0 on typologically diverse morphological inflection. The (unrestricted) submission uses the cross-lingual approach of our last year&#8217;s winning submission (Anastasopoulos and Neubig, 2019), but adapted to use specific transfer languages for each test language. Our <a href=https://en.wikipedia.org/wiki/System>system</a>, with fixed non-tuned hyperparameters, achieved a macro-averaged accuracy of 80.65 ranking 20th among 31 systems, but it was still tied for best <a href=https://en.wikipedia.org/wiki/System>system</a> in 25 of the 90 total languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sigmorphon-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sigmorphon-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sigmorphon-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sigmorphon-1.7/>Grapheme-to-Phoneme Conversion with a Multilingual Transformer Model</a></strong><br><a href=/people/o/omnia-elsaadany/>Omnia ElSaadany</a>
|
<a href=/people/b/benjamin-suter/>Benjamin Suter</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sigmorphon-1--7><div class="card-body p-3 small">In this paper, we describe our three submissions to the SIGMORPHON 2020 shared task 1 on grapheme-to-phoneme conversion for 15 languages. We experimented with a single multilingual transformer model. We observed that the multilingual model achieves results on par with our separately trained <a href=https://en.wikipedia.org/wiki/Monolingualism>monolingual models</a> and is even able to avoid a few of the errors made by the <a href=https://en.wikipedia.org/wiki/Monolingualism>monolingual models</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sigmorphon-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sigmorphon-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sigmorphon-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sigmorphon-1.9/>The IMSCUBoulder System for the SIGMORPHON 2020 Shared Task on Unsupervised Morphological Paradigm Completion<span class=acl-fixed-case>IMS</span>–<span class=acl-fixed-case>CUB</span>oulder System for the <span class=acl-fixed-case>SIGMORPHON</span> 2020 Shared Task on Unsupervised Morphological Paradigm Completion</a></strong><br><a href=/people/m/manuel-mager/>Manuel Mager</a>
|
<a href=/people/k/katharina-kann/>Katharina Kann</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sigmorphon-1--9><div class="card-body p-3 small">In this paper, we present the systems of the University of Stuttgart IMS and the University of Colorado Boulder (IMSCUBoulder) for SIGMORPHON 2020 Task 2 on unsupervised morphological paradigm completion (Kann et al., 2020). The task consists of generating the <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphological paradigms</a> of a set of lemmas, given only the lemmas themselves and unlabeled text. Our proposed <a href=https://en.wikipedia.org/wiki/System>system</a> is a modified version of the <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline</a> introduced together with the <a href=https://en.wikipedia.org/wiki/Task_(computing)>task</a>. In particular, we experiment with substituting the inflection generation component with an LSTM sequence-to-sequence model and an LSTM pointer-generator network. Our pointer-generator system obtains the best score of all seven submitted systems on average over all languages, and outperforms the official baseline, which was best overall, on <a href=https://en.wikipedia.org/wiki/Bulgarian_language>Bulgarian</a> and <a href=https://en.wikipedia.org/wiki/Kannada>Kannada</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sigmorphon-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sigmorphon-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sigmorphon-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sigmorphon-1.14/>Exploring Neural Architectures And Techniques For Typologically Diverse Morphological Inflection</a></strong><br><a href=/people/p/pratik-jayarao/>Pratik Jayarao</a>
|
<a href=/people/s/siddhanth-pillay/>Siddhanth Pillay</a>
|
<a href=/people/p/pranav-thombre/>Pranav Thombre</a>
|
<a href=/people/a/aditi-chaudhary/>Aditi Chaudhary</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sigmorphon-1--14><div class="card-body p-3 small">Morphological inflection in low resource languages is critical to augment existing corpora in Low Resource Languages, which can help develop several applications in these languages with very good social impact. We describe our attention-based encoder-decoder approach that we implement using <a href=https://en.wikipedia.org/wiki/Light-emitting_diode>LSTMs</a> and <a href=https://en.wikipedia.org/wiki/Transformers_(video_game)>Transformers</a> as the base units. We also describe the ancillary techniques that we experimented with, such as <a href=https://en.wikipedia.org/wiki/Hallucination>hallucination</a>, language vector injection, sparsemax loss and adversarial language network alongside our approach to select the related language(s) for training. We present the results we generated on the constrained as well as unconstrained SIGMORPHON 2020 dataset (CITATION). One of the primary goals of our paper was to study the contribution varied components described above towards the performance of our <a href=https://en.wikipedia.org/wiki/System>system</a> and perform an analysis on the same.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sigmorphon-1.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sigmorphon-1--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sigmorphon-1.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sigmorphon-1.17/>Leveraging Principal Parts for Morphological Inflection</a></strong><br><a href=/people/l/ling-liu/>Ling Liu</a>
|
<a href=/people/m/mans-hulden/>Mans Hulden</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sigmorphon-1--17><div class="card-body p-3 small">This paper presents the submission by the CU Ling team from the University of Colorado to SIGMORPHON 2020 shared task 0 on morphological inflection. The task is to generate the target <a href=https://en.wikipedia.org/wiki/Inflection>inflected word form</a> given a <a href=https://en.wikipedia.org/wiki/Lemma_(morphology)>lemma form</a> and a target <a href=https://en.wikipedia.org/wiki/Morphology_(linguistics)>morphosyntactic description</a>. Our <a href=https://en.wikipedia.org/wiki/System>system</a> uses the Transformer architecture. Our overall approach is to treat the morphological inflection task as a paradigm cell filling problem and to design the system to leverage principal parts information for better morphological inflection when the training data is limited. We train one <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> for each language separately without <a href=https://en.wikipedia.org/wiki/Data>external data</a>. The overall average performance of our submission ranks the first in both <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>average accuracy</a> and <a href=https://en.wikipedia.org/wiki/Levenshtein_distance>Levenshtein distance</a> from the gold inflection among all submissions including those using external resources.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sigmorphon-1.29.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sigmorphon-1--29 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sigmorphon-1.29 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929874 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.sigmorphon-1.29/>Multi-Tiered Strictly Local Functions</a></strong><br><a href=/people/p/phillip-burness/>Phillip Burness</a>
|
<a href=/people/k/kevin-mcmullin/>Kevin McMullin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sigmorphon-1--29><div class="card-body p-3 small">Tier-based Strictly Local functions, as they have so far been defined, are equipped with just a single tier. In light of this fact, they are currently incapable of modelling simultaneous phonological processes that would require different tiers. In this paper we consider whether and how we can allow a single function to operate over more than one tier. We conclude that multiple tiers can and should be permitted, but that the relationships between them must be restricted in some way to avoid overgeneration. The particular restriction that we propose comes in two parts. First, each input element is associated with a set of tiers that on their own can fully determine what the element is mapped to. Second, the set of tiers associated to a given input element must form a strict superset-subset hierarchy. In this way, we can track multiple, related sources of information when deciding how to process a particular input element. We demonstrate that doing so enables simple and intuitive analyses to otherwise challenging <a href=https://en.wikipedia.org/wiki/Phonology>phonological phenomena</a>.</div></div></div><hr><div id=2020signlang-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.signlang-1/>Proceedings of the LREC2020 9th Workshop on the Representation and Processing of Sign Languages: Sign Language Resources in the Service of the Language Community, Technological Challenges and Application Perspectives</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.signlang-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.signlang-1.0/>Proceedings of the LREC2020 9th Workshop on the Representation and Processing of Sign Languages: Sign Language Resources in the Service of the Language Community, Technological Challenges and Application Perspectives</a></strong><br><a href=/people/e/eleni-efthimiou/>Eleni Efthimiou</a>
|
<a href=/people/s/stavroula-evita-fotinea/>Stavroula-Evita Fotinea</a>
|
<a href=/people/t/thomas-hanke/>Thomas Hanke</a>
|
<a href=/people/j/julie-a-hochgesang/>Julie A. Hochgesang</a>
|
<a href=/people/j/jette-kristoffersen/>Jette Kristoffersen</a>
|
<a href=/people/j/johanna-mesch/>Johanna Mesch</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.signlang-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--signlang-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.signlang-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.signlang-1.1/>Back and Forth between Theory and Application : Shared Phonological Coding Between ASL Signbank and ASL-LEX<span class=acl-fixed-case>ASL</span> <span class=acl-fixed-case>S</span>ignbank and <span class=acl-fixed-case>ASL</span>-<span class=acl-fixed-case>LEX</span></a></strong><br><a href=/people/a/amelia-becker/>Amelia Becker</a>
|
<a href=/people/d/donovan-catt/>Donovan Catt</a>
|
<a href=/people/j/julie-a-hochgesang/>Julie A. Hochgesang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--signlang-1--1><div class="card-body p-3 small">The development of signed language lexical databases, digital organizations that describe different phonological features of and attempt to establish relationships between signs has resulted in a renewed interest in the phonological descriptions used to uniquely identify and organize the lexicons of respective sign languages (van der Kooij, 2002 ; Fenlon et al., 2016 ; Brentari et al., 2018). Throughout the mutually shared coding process involved in organizing two lexical databases, ASL Signbank (Hochgesang, Crasborn and Lillo-Martin, 2020) and ASL-LEX (Caselli et al., 2016), issues have arisen that require revisiting how phonological features and categories are to be applied and even decided upon, and which would adequately distinguish lexical contrast for respective sign languages. The paper concludes by exploring the inverse of the theory-to-database relationship. Examples are given of theoretical implications and research questions that arise from consequences of language resource building. These are presented as evidence that not only does <a href=https://en.wikipedia.org/wiki/Theory>theory</a> impact organization of databases but that the process of database creation can also inform our theories.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.signlang-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--signlang-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.signlang-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.signlang-1.4/>Measuring <a href=https://en.wikipedia.org/wiki/Lexical_similarity>Lexical Similarity</a> across <a href=https://en.wikipedia.org/wiki/Sign_language>Sign Languages</a> in Global Signbank<span class=acl-fixed-case>G</span>lobal <span class=acl-fixed-case>S</span>ignbank</a></strong><br><a href=/people/c/carl-borstell/>Carl Börstell</a>
|
<a href=/people/o/onno-crasborn/>Onno Crasborn</a>
|
<a href=/people/l/lori-whynot/>Lori Whynot</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--signlang-1--4><div class="card-body p-3 small">Lexicostatistics is the main method used in previous work measuring linguistic distances between sign languages. As a method, <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> disregards any possible structural / grammatical similarity, instead focusing exclusively on lexical items, but <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> is time consuming as <a href=https://en.wikipedia.org/wiki/Information_technology>it</a> requires some comparable phonological coding (i.e. form description) as well as concept matching (i.e. meaning description) of signs across the <a href=https://en.wikipedia.org/wiki/Sign_language>sign languages</a> to be compared. In this paper, we present a novel approach for measuring <a href=https://en.wikipedia.org/wiki/Lexical_similarity>lexical similarity</a> across any two sign languages using the Global Signbank platform, a <a href=https://en.wikipedia.org/wiki/Lexical_database>lexical database</a> of uniformly coded signs. The method involves a feature-by-feature comparison of all matched <a href=https://en.wikipedia.org/wiki/Phonological_feature>phonological features</a>. This method can be used in two distinct ways : 1) automatically comparing the amount of lexical overlap between two <a href=https://en.wikipedia.org/wiki/Sign_language>sign languages</a> (with a more detailed feature-description than previous lexicostatistical methods) ; 2) finding exact form-matches across languages that are either matched or mismatched in meaning (i.e. true or false friends). We show the feasability of this method by comparing three languages (datasets) in Global Signbank, and are currently expanding both the size of these three as well as the total number of datasets.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.signlang-1.6.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--signlang-1--6 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.signlang-1.6 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.signlang-1.6/>PE2LGP Animator : A Tool To Animate A Portuguese Sign Language Avatar<span class=acl-fixed-case>PE</span>2<span class=acl-fixed-case>LGP</span> Animator: A Tool To Animate A <span class=acl-fixed-case>P</span>ortuguese <span class=acl-fixed-case>S</span>ign <span class=acl-fixed-case>L</span>anguage Avatar</a></strong><br><a href=/people/p/pedro-cabral/>Pedro Cabral</a>
|
<a href=/people/m/matilde-goncalves/>Matilde Gonçalves</a>
|
<a href=/people/h/hugo-nicolau/>Hugo Nicolau</a>
|
<a href=/people/l/luisa-coheur/>Luísa Coheur</a>
|
<a href=/people/r/ruben-santos/>Ruben Santos</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--signlang-1--6><div class="card-body p-3 small">Software for the production of sign languages is much less common than for <a href=https://en.wikipedia.org/wiki/Spoken_language>spoken languages</a>. Such <a href=https://en.wikipedia.org/wiki/Software>software</a> usually relies on 3D humanoid avatars to produce signs which, inevitably, necessitates the use of <a href=https://en.wikipedia.org/wiki/Animation>animation</a>. One barrier to the use of popular animation tools is their complexity and steep learning curve, which can be hard to master for inexperienced users. Here, we present PE2LGP, an <a href=https://en.wikipedia.org/wiki/Authoring_system>authoring system</a> that features a <a href=https://en.wikipedia.org/wiki/Avatar_(computing)>3D avatar</a> that signs <a href=https://en.wikipedia.org/wiki/Portuguese_Sign_Language>Portuguese Sign Language</a>. Our <a href=https://en.wikipedia.org/wiki/Animator>Animator</a> is designed specifically to craft sign language animations using a key frame method, and is meant to be easy to use and learn to users without animation skills. We conducted a preliminary evaluation of the <a href=https://en.wikipedia.org/wiki/Animator>Animator</a>, where we animated seven Portuguese Sign Language sentences and asked four sign language users to evaluate their quality. This evaluation revealed that the <a href=https://en.wikipedia.org/wiki/System>system</a>, in spite of its simplicity, is indeed capable of producing comprehensible messages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.signlang-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--signlang-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.signlang-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.signlang-1.7/>Translating an <a href=https://en.wikipedia.org/wiki/Aesop&#8217;s_Fables>Aesop’s Fable</a> to <a href=https://en.wikipedia.org/wiki/Filipino_Sign_Language>Filipino Sign Language</a> through <a href=https://en.wikipedia.org/wiki/Animation>3D Animation</a><span class=acl-fixed-case>A</span>esop’s Fable to <span class=acl-fixed-case>F</span>ilipino <span class=acl-fixed-case>S</span>ign <span class=acl-fixed-case>L</span>anguage through 3<span class=acl-fixed-case>D</span> Animation</a></strong><br><a href=/people/m/mark-cueto/>Mark Cueto</a>
|
<a href=/people/w/winnie-he/>Winnie He</a>
|
<a href=/people/r/rei-untiveros/>Rei Untiveros</a>
|
<a href=/people/j/josh-zuniga/>Josh Zuñiga</a>
|
<a href=/people/j/joanna-pauline-rivera/>Joanna Pauline Rivera</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--signlang-1--7><div class="card-body p-3 small">According to the National Statistics Office (2003) in the 2000 Population Census, the deaf community in the Philippines numbered to about 121,000 deaf and hard of hearing Filipinos. Deaf and hard of hearing Filipinos in these communities use the Filipino Sign Language (FSL) as the main method of manual communication. Deaf and hard of hearing children experience difficulty in developing reading and writing skills through traditional methods of teaching used primarily for hearing children. This study aims to translate an <a href=https://en.wikipedia.org/wiki/Aesop&#8217;s_Fables>Aesop&#8217;s fable</a> to <a href=https://en.wikipedia.org/wiki/Filipino_Sign_Language>Filipino Sign Language</a> with the use of <a href=https://en.wikipedia.org/wiki/Animation>3D animation</a> resulting to a video output. The video created contains a 3D animated avatar performing the sign translations to FSL (mainly focusing on hand gestures which includes hand shape, palm orientation, location, and movement) on screen beside their English text equivalent and related images. The final output was then evaluated by FSL deaf signers. Evaluation results showed that the final output can potentially be used as a learning material. In order to make it more effective as a learning material, it is very important to consider the animation&#8217;s appearance, <a href=https://en.wikipedia.org/wiki/Speed>speed</a>, naturalness, and <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a>. In this paper, the common action units were also listed for easier construction of animations of the signs.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.signlang-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--signlang-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.signlang-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.signlang-1.9/>Elicitation and Corpus of Spontaneous Sign Language Discourse Representation Diagrams</a></strong><br><a href=/people/m/michael-filhol/>Michael Filhol</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--signlang-1--9><div class="card-body p-3 small">While <a href=https://en.wikipedia.org/wiki/Sign_language>Sign Languages</a> have no standard written form, many signers do capture their language in some form of spontaneous graphical form. We list a few <a href=https://en.wikipedia.org/wiki/Use_case>use cases</a> (discourse preparation, deverbalising for <a href=https://en.wikipedia.org/wiki/Translation>translation</a>, etc.) and give examples of <a href=https://en.wikipedia.org/wiki/Diagram>diagrams</a>. After hypothesising that they contain regular patterns of significant value, we propose to build a <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> of such <a href=https://en.wikipedia.org/wiki/Production_(economics)>productions</a>. The main contribution of this paper is the specification of the elicitation protocol, explaining the variables that are likely to affect the diagrams collected. We conclude with a report on the current state of a collection following this <a href=https://en.wikipedia.org/wiki/Protocol_(science)>protocol</a>, and a few observations on the collected contents. A first prospect is the standardisation of a scheme to represent SL discourse in a way that would make them sharable. A subsequent longer-term prospect is for this scheme to be owned by users and with time be shaped into a script for their language.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.signlang-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--signlang-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.signlang-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.signlang-1.11/>Signing as Input for a Dictionary Query : Matching Signs Based on Joint Positions of the Dominant Hand</a></strong><br><a href=/people/m/manolis-fragkiadakis/>Manolis Fragkiadakis</a>
|
<a href=/people/v/victoria-nyst/>Victoria Nyst</a>
|
<a href=/people/p/peter-van-der-putten/>Peter van der Putten</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--signlang-1--11><div class="card-body p-3 small">This study presents a new <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> to search sign language lexica, using a full sign as input for a query. Thus, a dictionary user can look up information about a sign by signing the sign to a webcam. The recorded sign is then compared to potential matching signs in the lexicon. As such, it provides a new way of searching sign language dictionaries to complement existing methods based on (spoken language) glosses or phonological features, like <a href=https://en.wikipedia.org/wiki/Handshape>handshape</a> or <a href=https://en.wikipedia.org/wiki/Location>location</a>. The method utilizes OpenPose to extract the body and finger joint positions. Dynamic Time Warping (DTW) is used to quantify the variation of the trajectory of the dominant hand and the average trajectories of the fingers. Ten people with various degrees of sign language proficiency have participated in this study. Each subject viewed a set of 20 signs from the newly compiled Ghanaian sign language lexicon and was asked to replicate the signs. The results show that DTW can predict the matching sign with 87 % and 74 % accuracy at the Top-10 and Top-5 ranking level respectively by using only the trajectory of the dominant hand. Additionally, more proficient signers obtain 90 % <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> at the Top-10 ranking. The <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> has the potential to be used also as a variation measurement tool to quantify the difference in signing between different signers or sign languages in general.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.signlang-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--signlang-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.signlang-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.signlang-1.14/>An Isolated-Signing RGBD Dataset of 100 American Sign Language Signs Produced by Fluent ASL Signers<span class=acl-fixed-case>RGBD</span> Dataset of 100 <span class=acl-fixed-case>A</span>merican <span class=acl-fixed-case>S</span>ign <span class=acl-fixed-case>L</span>anguage Signs Produced by Fluent <span class=acl-fixed-case>ASL</span> Signers</a></strong><br><a href=/people/s/saad-hassan/>Saad Hassan</a>
|
<a href=/people/l/larwan-berke/>Larwan Berke</a>
|
<a href=/people/e/elahe-vahdani/>Elahe Vahdani</a>
|
<a href=/people/l/longlong-jing/>Longlong Jing</a>
|
<a href=/people/y/yingli-tian/>Yingli Tian</a>
|
<a href=/people/m/matt-huenerfauth/>Matt Huenerfauth</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--signlang-1--14><div class="card-body p-3 small">We have collected a new dataset consisting of color and depth videos of fluent American Sign Language (ASL) signers performing sequences of 100 ASL signs from a Kinect v2 sensor. This directed dataset had originally been collected as part of an ongoing collaborative project, to aid in the development of a sign-recognition system for identifying occurrences of these 100 signs in video. The set of words consist of vocabulary items that would commonly be learned in a first-year ASL course offered at a university, although the specific set of signs selected for inclusion in the dataset had been motivated by project-related factors. Given increasing interest among sign-recognition and other computer-vision researchers in red-green-blue-depth (RBGD) video, we release this dataset for use by the research community. In addition to the RGB video files, we share depth and HD face data as well as additional features of <a href=https://en.wikipedia.org/wiki/Face>face</a>, <a href=https://en.wikipedia.org/wiki/Hand>hands</a>, and <a href=https://en.wikipedia.org/wiki/Human_body>body</a> produced through post-processing of this data.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.signlang-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--signlang-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.signlang-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.signlang-1.16/>Sign Language Motion Capture Dataset for Data-driven Synthesis</a></strong><br><a href=/people/p/pavel-jedlicka/>Pavel Jedlička</a>
|
<a href=/people/z/zdenek-krnoul/>Zdeněk Krňoul</a>
|
<a href=/people/j/jakub-kanis/>Jakub Kanis</a>
|
<a href=/people/m/milos-zelezny/>Miloš Železný</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--signlang-1--16><div class="card-body p-3 small">This paper presents a new 3D motion capture dataset of <a href=https://en.wikipedia.org/wiki/Czech_Sign_Language>Czech Sign Language (CSE)</a>. Its main purpose is to provide the data for further analysis and data-based automatic synthesis of CSE utterances. The content of the <a href=https://en.wikipedia.org/wiki/Data>data</a> in the given limited domain of weather forecasts was carefully selected by the CSE linguists to provide the necessary utterances needed to produce any new <a href=https://en.wikipedia.org/wiki/Weather_forecasting>weather forecast</a>. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> was recorded using the state-of-the-art motion capture (MoCap) technology to provide the most precise trajectories of the motion. In general, MoCap is a device capable of accurate recording of motion directly in <a href=https://en.wikipedia.org/wiki/Three-dimensional_space>3D space</a>. The <a href=https://en.wikipedia.org/wiki/Data>data</a> contains trajectories of body, arms, hands and face markers recorded at once to provide consistent data without the need for the time alignment.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.signlang-1.20.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--signlang-1--20 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.signlang-1.20 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.signlang-1.20/>Recognition of Static Features in <a href=https://en.wikipedia.org/wiki/Sign_language>Sign Language</a> Using Key-Points</a></strong><br><a href=/people/i/ioannis-koulierakis/>Ioannis Koulierakis</a>
|
<a href=/people/g/georgios-siolas/>Georgios Siolas</a>
|
<a href=/people/e/eleni-efthimiou/>Eleni Efthimiou</a>
|
<a href=/people/e/evita-fotinea/>Evita Fotinea</a>
|
<a href=/people/a/andreas-georgios-stafylopatis/>Andreas-Georgios Stafylopatis</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--signlang-1--20><div class="card-body p-3 small">In this paper we report on a research effort focusing on recognition of static features of sign formation in single sign videos. Three sequential models have been developed for <a href=https://en.wikipedia.org/wiki/Handshape>handshape</a>, palm orientation and location of sign formation respectively, which make use of key-points extracted via OpenPose software. The <a href=https://en.wikipedia.org/wiki/Statistical_model>models</a> have been applied to a Danish and a Greek Sign Language dataset, providing results around 96 %. Moreover, during the reported research, a method has been developed for identifying the time-frame of real signing in the video, which allows to ignore transition frames during sign recognition processing.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.signlang-1.22.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--signlang-1--22 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.signlang-1.22 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.signlang-1.22/>Machine Learning for Enhancing Dementia Screening in Ageing Deaf Signers of British Sign Language<span class=acl-fixed-case>B</span>ritish <span class=acl-fixed-case>S</span>ign <span class=acl-fixed-case>L</span>anguage</a></strong><br><a href=/people/x/xing-liang/>Xing Liang</a>
|
<a href=/people/b/bencie-woll/>Bencie Woll</a>
|
<a href=/people/k/kapetanios-epaminondas/>Kapetanios Epaminondas</a>
|
<a href=/people/a/anastasia-angelopoulou/>Anastasia Angelopoulou</a>
|
<a href=/people/r/reda-al-batat/>Reda Al-Batat</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--signlang-1--22><div class="card-body p-3 small">Ageing trend in populations is correlated with increased prevalence of <a href=https://en.wikipedia.org/wiki/Cognitive_deficit>acquired cognitive impairments</a> such as <a href=https://en.wikipedia.org/wiki/Dementia>dementia</a>. Although there is no cure for <a href=https://en.wikipedia.org/wiki/Dementia>dementia</a>, a timely diagnosis helps in obtaining necessary support and appropriate medication. With this in mind, researchers are working urgently to develop effective technological tools that can help doctors undertake early identification of cognitive disorder. In this paper, we introduce an automatic dementia screening system for ageing Deaf signers of British Sign Language (BSL), using Convolutional Neural Networks (CNN), by analysing the sign space envelope and facial expression of BSL signers using normal 2D videos from BSL corpus. Our approach firstly establishes an accurate real-time hand trajectory tracking model together with a real-time landmark facial motion analysis model to identify differences in sign space envelope and facial movement as the keys to identifying language changes associated with <a href=https://en.wikipedia.org/wiki/Dementia>dementia</a>. Based on the differences in patterns obtained from facial and trajectory motion data, CNN models (ResNet50 / VGG16) are fine-tuned using Keras deep learning models to incrementally identify and improve dementia recognition rates. We report the results for two methods using different modalities (sign trajectory and facial motion), together with the performance comparisons between different deep learning CNN models in ResNet50 and VGG16. The experiments show the effectiveness of our deep learning based approach in terms of sign space tracking, facial motion tracking and early stage dementia performance assessment tasks. The results are validated against cognitive assessment scores as of our ground truth data with a test set performance of 87.88 %.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.signlang-1.23.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--signlang-1--23 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.signlang-1.23 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.signlang-1.23/>Machine Translation from <a href=https://en.wikipedia.org/wiki/Spoken_language>Spoken Language</a> to <a href=https://en.wikipedia.org/wiki/Sign_language>Sign Language</a> using Pre-trained Language Model as Encoder</a></strong><br><a href=/people/t/taro-miyazaki/>Taro Miyazaki</a>
|
<a href=/people/y/yusuke-morita/>Yusuke Morita</a>
|
<a href=/people/m/masanori-sano/>Masanori Sano</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--signlang-1--23><div class="card-body p-3 small">Sign language is the first language for those who were born deaf or lost their hearing in early childhood, so such individuals require services provided with <a href=https://en.wikipedia.org/wiki/Sign_language>sign language</a>. To achieve flexible open-domain services with <a href=https://en.wikipedia.org/wiki/Sign_language>sign language</a>, <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translations</a> into <a href=https://en.wikipedia.org/wiki/Sign_language>sign language</a> are needed. Machine translations generally require large-scale training corpora, but there are only small corpora for <a href=https://en.wikipedia.org/wiki/Sign_language>sign language</a>. To overcome this data-shortage scenario, we developed a method that involves using a pre-trained language model of spoken language as the initial model of the <a href=https://en.wikipedia.org/wiki/Encoder>encoder</a> of the <a href=https://en.wikipedia.org/wiki/Machine_translation>machine translation model</a>. We evaluated our method by comparing it to baseline methods, including phrase-based machine translation, using only 130,000 phrase pairs of training data. Our method outperformed the baseline method, and we found that one of the reasons of translation error is from <a href=https://en.wikipedia.org/wiki/Pointing>pointing</a>, which is a special feature used in <a href=https://en.wikipedia.org/wiki/Sign_language>sign language</a>. We also conducted trials to improve the translation quality for <a href=https://en.wikipedia.org/wiki/Pointing>pointing</a>. The results are somewhat disappointing, so we believe that there is still room for improving translation quality, especially for <a href=https://en.wikipedia.org/wiki/Pointing>pointing</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.signlang-1.27.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--signlang-1--27 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.signlang-1.27 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.signlang-1.27/>Automatic Classification of Handshapes in <a href=https://en.wikipedia.org/wiki/Russian_Sign_Language>Russian Sign Language</a><span class=acl-fixed-case>R</span>ussian <span class=acl-fixed-case>S</span>ign <span class=acl-fixed-case>L</span>anguage</a></strong><br><a href=/people/m/medet-mukushev/>Medet Mukushev</a>
|
<a href=/people/a/alfarabi-imashev/>Alfarabi Imashev</a>
|
<a href=/people/v/vadim-kimmelman/>Vadim Kimmelman</a>
|
<a href=/people/a/anara-sandygulova/>Anara Sandygulova</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--signlang-1--27><div class="card-body p-3 small">Handshapes are one of the basic parameters of signs, and any <a href=https://en.wikipedia.org/wiki/Phonology>phonological or phonetic analysis</a> of a <a href=https://en.wikipedia.org/wiki/Sign_language>sign language</a> must account for <a href=https://en.wikipedia.org/wiki/Handshapes>handshapes</a>. Many <a href=https://en.wikipedia.org/wiki/Sign_language>sign languages</a> have been carefully analysed by sign language linguists to create handshape inventories. This has theoretical implications, but also applied use, as it is important due to the need of generating corpora for sign languages that can be searched, filtered, sorted by different sign components (such as handshapes, orientation, location, movement, etc.). However, it is a very time-consuming process, thus only a handful of <a href=https://en.wikipedia.org/wiki/Sign_language>sign languages</a> have such inventories. This work proposes a process of automatically generating such inventories for sign languages by applying automatic hand detection, cropping, and clustering techniques. We applied our proposed method to a commonly used resource : the Spreadthesign online dictionary (www.spreadthesign.com), in particular to Russian Sign Language (RSL). We then manually verified the data to be able to perform <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a>. Thus, the proposed <a href=https://en.wikipedia.org/wiki/Pipeline_transport>pipeline</a> can serve as an alternative approach to manual annotation, and can help linguists in answering numerous research questions in relation to handshape frequencies in sign languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.signlang-1.30.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--signlang-1--30 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.signlang-1.30 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.signlang-1.30/>BosphorusSign22k Sign Language Recognition Dataset<span class=acl-fixed-case>B</span>osphorus<span class=acl-fixed-case>S</span>ign22k Sign Language Recognition Dataset</a></strong><br><a href=/people/o/ogulcan-ozdemir/>Oğulcan Özdemir</a>
|
<a href=/people/a/ahmet-alp-kindiroglu/>Ahmet Alp Kındıroğlu</a>
|
<a href=/people/n/necati-cihan-camgoz/>Necati Cihan Camgöz</a>
|
<a href=/people/l/lale-akarun/>Lale Akarun</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--signlang-1--30><div class="card-body p-3 small">Sign Language Recognition is a challenging research domain. It has recently seen several advancements with the increased availability of data. In this paper, we introduce the BosphorusSign22k, a publicly available large scale sign language dataset aimed at <a href=https://en.wikipedia.org/wiki/Computer_vision>computer vision</a>, <a href=https://en.wikipedia.org/wiki/Computer_vision>video recognition</a> and <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning research communities</a>. The primary objective of this dataset is to serve as a new benchmark in Turkish Sign Language Recognition for its vast lexicon, the high number of repetitions by native signers, high recording quality, and the unique syntactic properties of the signs it encompasses. We also provide state-of-the-art human pose estimates to encourage other tasks such as Sign Language Production. We survey other publicly available datasets and expand on how BosphorusSign22k can contribute to future research that is being made possible through the widespread availability of similar Sign Language resources. We have conducted extensive experiments and present baseline results to underpin future research on our <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.signlang-1.34.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--signlang-1--34 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.signlang-1.34 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.signlang-1.34/>Video-to-HamNoSys Automated Annotation System<span class=acl-fixed-case>H</span>am<span class=acl-fixed-case>N</span>o<span class=acl-fixed-case>S</span>ys Automated Annotation System</a></strong><br><a href=/people/v/victor-skobov/>Victor Skobov</a>
|
<a href=/people/y/yves-lepage/>Yves Lepage</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--signlang-1--34><div class="card-body p-3 small">The Hamburg Notation System (HamNoSys) was developed for movement annotation of any sign language (SL) and can be used to produce signing animations for a virtual avatar with the JASigning platform. This provides the potential to use <a href=https://en.wikipedia.org/wiki/HamNoSys>HamNoSys</a>, i.e., <a href=https://en.wikipedia.org/wiki/String_(computer_science)>strings of characters</a>, as a representation of an SL corpus instead of <a href=https://en.wikipedia.org/wiki/Video>video material</a>. Processing <a href=https://en.wikipedia.org/wiki/String_(computer_science)>strings of characters</a> instead of images can significantly contribute to <a href=https://en.wikipedia.org/wiki/Sign_language>sign language research</a>. However, the complexity of <a href=https://en.wikipedia.org/wiki/HamNoSys>HamNoSys</a> makes it difficult to annotate without a lot of time and effort. Therefore <a href=https://en.wikipedia.org/wiki/Annotation>annotation</a> has to be automatized. This work proposes a conceptually new <a href=https://en.wikipedia.org/wiki/Method_(computer_programming)>approach</a> to this problem. It includes a new tree representation of the HamNoSys grammar that serves as a basis for the generation of grammatical training data and classification of complex movements using <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning</a>. Our automatic annotation system relies on HamNoSys grammar structure and can potentially be used on already existing SL corpora. It is retrainable for specific settings such as <a href=https://en.wikipedia.org/wiki/Camera_angle>camera angles</a>, <a href=https://en.wikipedia.org/wiki/Film_speed>speed</a>, and <a href=https://en.wikipedia.org/wiki/Gesture_recognition>gestures</a>. Our approach is conceptually different from other SL recognition solutions and offers a developed <a href=https://en.wikipedia.org/wiki/Methodology>methodology</a> for future research.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.signlang-1.35.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--signlang-1--35 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.signlang-1.35 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.signlang-1.35/>Cross-Lingual Keyword Search for Sign Language</a></strong><br><a href=/people/n/nazif-can-tamer/>Nazif Can Tamer</a>
|
<a href=/people/m/murat-saraclar/>Murat Saraçlar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--signlang-1--35><div class="card-body p-3 small">Sign language research most often relies on exhaustively annotated and segmented data, which is scarce even for the most studied <a href=https://en.wikipedia.org/wiki/Sign_language>sign languages</a>. However, parallel corpora consisting of sign language interpreting are rarely explored. By utilizing such data for the task of <a href=https://en.wikipedia.org/wiki/Keyword_search>keyword search</a>, this work aims to enable <a href=https://en.wikipedia.org/wiki/Information_retrieval>information retrieval</a> from <a href=https://en.wikipedia.org/wiki/Sign_language>sign language</a> with the queries from the translated written language. With the written language translations as labels, we train a weakly supervised keyword search model for <a href=https://en.wikipedia.org/wiki/Sign_language>sign language</a> and further improve the retrieval performance with two context modeling strategies. In our experiments, we compare the gloss retrieval and cross language retrieval performance on RWTH-PHOENIX-Weather 2014 T dataset.</div></div></div><hr><div id=2020sltu-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.sltu-1/>Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.0/>Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)</a></strong><br><a href=/people/d/dorothee-beermann/>Dorothee Beermann</a>
|
<a href=/people/l/laurent-besacier/>Laurent Besacier</a>
|
<a href=/people/s/sakriani-sakti/>Sakriani Sakti</a>
|
<a href=/people/c/claudia-soria/>Claudia Soria</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.3/>Open-Source High Quality Speech Datasets for Basque, Catalan and Galician<span class=acl-fixed-case>B</span>asque, <span class=acl-fixed-case>C</span>atalan and <span class=acl-fixed-case>G</span>alician</a></strong><br><a href=/people/o/oddur-kjartansson/>Oddur Kjartansson</a>
|
<a href=/people/a/alexander-gutkin/>Alexander Gutkin</a>
|
<a href=/people/a/alena-butryna/>Alena Butryna</a>
|
<a href=/people/i/isin-demirsahin/>Isin Demirsahin</a>
|
<a href=/people/c/clara-rivera/>Clara Rivera</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--3><div class="card-body p-3 small">This paper introduces new open speech datasets for three of the languages of Spain : <a href=https://en.wikipedia.org/wiki/Basque_language>Basque</a>, <a href=https://en.wikipedia.org/wiki/Catalan_language>Catalan</a> and <a href=https://en.wikipedia.org/wiki/Galician_language>Galician</a>. Catalan is furthermore the official language of the Principality of Andorra. The <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> consist of high-quality multi-speaker recordings of the three languages along with the associated transcriptions. The resulting <a href=https://en.wikipedia.org/wiki/Text_corpus>corpora</a> include over 33 hours of crowd-sourced recordings of 132 male and female native speakers. The recording scripts also include material for elicitation of global and local place names, personal and business names. The <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> are released under a permissive license and are available for free download for commercial, academic and personal use. The high-quality annotated speech datasets described in this paper can be used to, among other things, build <a href=https://en.wikipedia.org/wiki/Speech_synthesis>text-to-speech systems</a>, serve as adaptation data in <a href=https://en.wikipedia.org/wiki/Speech_recognition>automatic speech recognition</a> and provide useful phonetic and phonological insights in <a href=https://en.wikipedia.org/wiki/Corpus_linguistics>corpus linguistics</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.5/>Morphological Disambiguation of South Smi with FSTs and <a href=https://en.wikipedia.org/wiki/Neural_network>Neural Networks</a><span class=acl-fixed-case>S</span>outh <span class=acl-fixed-case>S</span>ámi with <span class=acl-fixed-case>FST</span>s and Neural Networks</a></strong><br><a href=/people/m/mika-hamalainen/>Mika Hämäläinen</a>
|
<a href=/people/l/linda-wiechetek/>Linda Wiechetek</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--5><div class="card-body p-3 small">We present a method for conducting morphological disambiguation for South Smi, which is an <a href=https://en.wikipedia.org/wiki/Endangered_language>endangered language</a>. Our method uses an FST-based morphological analyzer to produce an ambiguous set of morphological readings for each word in a sentence. These readings are disambiguated with a Bi-RNN model trained on the related North Smi UD Treebank and some synthetically generated South Smi data. The disambiguation is done on the level of morphological tags ignoring word forms and <a href=https://en.wikipedia.org/wiki/Lemma_(morphology)>lemmas</a> ; this makes it possible to use North Smi training data for South Smi without the need for a <a href=https://en.wikipedia.org/wiki/Bilingual_dictionary>bilingual dictionary</a> or aligned word embeddings. Our approach requires only minimal resources for South Smi, which makes it usable and applicable in the contexts of any other <a href=https://en.wikipedia.org/wiki/Endangered_language>endangered language</a> as well.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.8.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--8 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.8 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.8/>Neural Text-to-Speech Synthesis for an Under-Resourced Language in a Diglossic Environment : the Case of Gascon Occitan<span class=acl-fixed-case>G</span>ascon <span class=acl-fixed-case>O</span>ccitan</a></strong><br><a href=/people/a/ander-corral/>Ander Corral</a>
|
<a href=/people/i/igor-leturia/>Igor Leturia</a>
|
<a href=/people/a/aure-seguier/>Aure Séguier</a>
|
<a href=/people/m/michael-barret/>Michäel Barret</a>
|
<a href=/people/b/benaset-dazeas/>Benaset Dazéas</a>
|
<a href=/people/p/philippe-boula-de-mareuil/>Philippe Boula de Mareüil</a>
|
<a href=/people/n/nicolas-quint/>Nicolas Quint</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--8><div class="card-body p-3 small">Occitan is a <a href=https://en.wikipedia.org/wiki/Minority_language>minority language</a> spoken in Southern France, some Alpine Valleys of Italy, and the Val d&#8217;Aran in Spain, which only very recently started developing language and speech technologies. This paper describes the first project for designing a Text-to-Speech synthesis system for one of its main <a href=https://en.wikipedia.org/wiki/Gascon_language>regional varieties</a>, namely <a href=https://en.wikipedia.org/wiki/Gascon_language>Gascon</a>. We used a state-of-the-art deep neural network approach, the Tacotron2-WaveGlow system. However, we faced two additional difficulties or challenges : on the one hand, we wanted to test if it was possible to obtain good quality results with fewer recording hours than is usually reported for such systems ; on the other hand, we needed to achieve a standard, non-Occitan pronunciation of French proper names, therefore we needed to record French words and test phoneme-based approaches. The evaluation carried out over the various developed <a href=https://en.wikipedia.org/wiki/System>systems</a> and <a href=https://en.wikipedia.org/wiki/Software_development_process>approaches</a> shows promising results with near production-ready quality. It has also allowed us to detect the phenomena for which some flaws or fall of quality occur, pointing at the direction of future work to improve the quality of the actual system and for new systems for other <a href=https://en.wikipedia.org/wiki/Variety_(linguistics)>language varieties</a> and voices.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.14/>Poio Text Prediction : Lessons on the Development and Sustainability of LTs for Endangered Languages<span class=acl-fixed-case>LT</span>s for Endangered Languages</a></strong><br><a href=/people/g/gema-zamora-fernandez/>Gema Zamora Fernández</a>
|
<a href=/people/v/vera-ferreira/>Vera Ferreira</a>
|
<a href=/people/p/pedro-manha/>Pedro Manha</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--14><div class="card-body p-3 small">2019, the International Year of Indigenous Languages (IYIL), marked a crucial milestone for a diverse community united by a strong sense of urgency. In this presentation, we evaluate the impact of IYIL&#8217;s outcomes in the development of LTs for <a href=https://en.wikipedia.org/wiki/Endangered_language>endangered languages</a>. We give a brief description of the field of <a href=https://en.wikipedia.org/wiki/Language_documentation>Language Documentation</a>, whose experts have led the research and data collection efforts surrounding <a href=https://en.wikipedia.org/wiki/Endangered_language>endangered languages</a> for the past 30 years. We introduce the work of the Interdisciplinary Centre for Social and Language Documentation and we look at Poio as an example of an LT developed specifically with speakers of endangered languages in mind. This example illustrates how the deeper systemic causes of <a href=https://en.wikipedia.org/wiki/Endangered_language>language endangerment</a> are reflected in the development of <a href=https://en.wikipedia.org/wiki/Language_proficiency>LTs</a>. Additionally, we share some of the strategic decisions that have led the development of this project. Finally, we advocate the importance of bridging the divide between research and activism, pushing for the inclusion of threatened languages in the world of LTs, and doing so in close collaboration with the speaker community.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.16/>Scaling Language Data Import / Export with a Data Transformer Interface</a></strong><br><a href=/people/n/nicholas-buckeridge/>Nicholas Buckeridge</a>
|
<a href=/people/b/ben-foley/>Ben Foley</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--16><div class="card-body p-3 small">This paper focuses on the technical improvement of <a href=https://en.wikipedia.org/wiki/Elpis>Elpis</a>, a <a href=https://en.wikipedia.org/wiki/Language_technology>language technology</a> which assists people in the process of transcription, particularly for low-resource language documentation situations. To provide better support for the diversity of file formats encountered by people working to document the world&#8217;s languages, a Data Transformer interface has been developed to abstract the complexities of designing individual data import scripts. This work took place as part of a larger project of <a href=https://en.wikipedia.org/wiki/Code_quality>code quality improvement</a> and the publication of <a href=https://en.wikipedia.org/wiki/Template_processor>template code</a> that can be used for development of other <a href=https://en.wikipedia.org/wiki/Programming_language>language technologies</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.21.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--21 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.21 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.21/>Natural Language Processing Chains Inside a Cross-lingual Event-Centric Knowledge Pipeline for European Union Under-resourced Languages<span class=acl-fixed-case>E</span>uropean <span class=acl-fixed-case>U</span>nion Under-resourced Languages</a></strong><br><a href=/people/d/diego-alves/>Diego Alves</a>
|
<a href=/people/g/gaurish-thakkar/>Gaurish Thakkar</a>
|
<a href=/people/m/marko-tadic/>Marko Tadić</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--21><div class="card-body p-3 small">This article presents the strategy for developing a platform containing Language Processing Chains for European Union languages, consisting of Tokenization to <a href=https://en.wikipedia.org/wiki/Parsing>Parsing</a>, also including Named Entity recognition and with addition of <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a>. These chains are part of the first step of an event-centric knowledge processing pipeline whose aim is to process multilingual media information about major events that can cause an impact in Europe and the rest of the world. Due to the differences in terms of availability of language resources for each language, we have built this strategy in three steps, starting with processing chains for the well-resourced languages and finishing with the development of new modules for the under-resourced ones. In order to classify all <a href=https://en.wikipedia.org/wiki/Languages_of_the_European_Union>European Union official languages</a> in terms of resources, we have analysed the size of annotated corpora as well as the existence of pre-trained models in mainstream Language Processing tools, and we have combined this information with the proposed classification published at META-NET whitepaper series.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.23.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--23 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.23 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.23/>Acoustic-Phonetic Approach for ASR of Less Resourced Languages Using Monolingual and Cross-Lingual Information<span class=acl-fixed-case>ASR</span> of Less Resourced Languages Using Monolingual and Cross-Lingual Information</a></strong><br><a href=/people/s/shweta-bansal/>Shweta Bansal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--23><div class="card-body p-3 small">The exploration of <a href=https://en.wikipedia.org/wiki/Speech_processing>speech processing</a> for <a href=https://en.wikipedia.org/wiki/Endangered_language>endangered languages</a> has substantially increased in the past epoch of time. In this paper, we present the acoustic-phonetic approach for automatic speech recognition (ASR) using monolingual and cross-lingual information with application to under-resourced Indian languages, <a href=https://en.wikipedia.org/wiki/Punjabi_language>Punjabi</a>, <a href=https://en.wikipedia.org/wiki/Nepali_language>Nepali</a> and <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a>. The challenging task while developing the ASR was the collection of the acoustic corpus for under-resourced languages. We have described here, in brief, the strategies used for designing the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> and also highlighted the issues pertaining while collecting data for these <a href=https://en.wikipedia.org/wiki/Language>languages</a>. The bootstrap GMM-UBM based approach is used, which integrates pronunciation lexicon, <a href=https://en.wikipedia.org/wiki/Language_model>language model</a> and <a href=https://en.wikipedia.org/wiki/Acoustic_phonetics>acoustic-phonetic model</a>. Mel Frequency Cepstral Coefficients were used for extracting the acoustic signal features for training in monolingual and cross-lingual settings. The experimental result shows the overall performance of ASR for cross-lingual and monolingual. The phone substitution plays a key role in the cross-lingual as well as monolingual recognition. The result obtained by cross-lingual recognition compared with other <a href=https://en.wikipedia.org/wiki/Baseline_(configuration_management)>baseline system</a> and it has been found that the performance of the <a href=https://en.wikipedia.org/wiki/Speech_recognition>recognition system</a> is based on <a href=https://en.wikipedia.org/wiki/Phoneme>phonemic units</a>. The recognition rate of cross-lingual generally declines as compared with the monolingual.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.25.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--25 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.25 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.sltu-1.25" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.25/>A Sentiment Analysis Dataset for Code-Mixed Malayalam-English<span class=acl-fixed-case>M</span>alayalam-<span class=acl-fixed-case>E</span>nglish</a></strong><br><a href=/people/b/bharathi-raja-chakravarthi/>Bharathi Raja Chakravarthi</a>
|
<a href=/people/n/navya-jose/>Navya Jose</a>
|
<a href=/people/s/shardul-suryawanshi/>Shardul Suryawanshi</a>
|
<a href=/people/e/elizabeth-sherly/>Elizabeth Sherly</a>
|
<a href=/people/j/john-philip-mccrae/>John Philip McCrae</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--25><div class="card-body p-3 small">There is an increasing demand for <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> of text from <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> which are mostly code-mixed. Systems trained on monolingual data fail for code-mixed data due to the complexity of mixing at different levels of the text. However, very few resources are available for code-mixed data to create <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> specific for this <a href=https://en.wikipedia.org/wiki/Data>data</a>. Although much research in multilingual and cross-lingual sentiment analysis has used <a href=https://en.wikipedia.org/wiki/Semi-supervised_learning>semi-supervised or unsupervised methods</a>, <a href=https://en.wikipedia.org/wiki/Supervised_learning>supervised methods</a> still performs better. Only a few datasets for popular languages such as English-Spanish, <a href=https://en.wikipedia.org/wiki/English_language_in_India>English-Hindi</a>, and <a href=https://en.wikipedia.org/wiki/Standard_Chinese>English-Chinese</a> are available. There are no resources available for Malayalam-English code-mixed data. This paper presents a new gold standard corpus for sentiment analysis of code-mixed text in <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam-English</a> annotated by voluntary annotators. This gold standard <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> obtained a <a href=https://en.wikipedia.org/wiki/Krippendorff&#8217;s_alpha>Krippendorff&#8217;s alpha</a> above 0.8 for the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. We use this new <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> to provide the benchmark for sentiment analysis in Malayalam-English code-mixed texts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.27.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--27 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.27 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.sltu-1.27" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.27/>Macsen : A Voice Assistant for Speakers of a Lesser Resourced Language<span class=acl-fixed-case>M</span>acsen: A Voice Assistant for Speakers of a Lesser Resourced Language</a></strong><br><a href=/people/d/dewi-jones/>Dewi Jones</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--27><div class="card-body p-3 small">This paper reports on the development of a voice assistant mobile app for speakers of a lesser resourced language Welsh. An assistant with a smaller set of effective but useful skills is both desirable and urgent for the wider Welsh speaking community. Descriptions of the <a href=https://en.wikipedia.org/wiki/Mobile_app>app</a>&#8217;s skills, architecture, design decisions and <a href=https://en.wikipedia.org/wiki/User_interface>user interface</a> is provided before elaborating on the most recent research and activities in open source speech technology for <a href=https://en.wikipedia.org/wiki/Welsh_language>Welsh</a>. The paper reports on the progress to date on crowdsourcing Welsh speech data in Mozilla Common Voice and of its suitability for training Mozilla&#8217;s DeepSpeech speech recognition for a voice assistant application according to conventional and transfer learning methods. We demonstrate that with smaller datasets of speech data, <a href=https://en.wikipedia.org/wiki/Transfer_learning>transfer learning</a> and a domain specific language model, acceptable <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech recognition</a> is achievable that facilitates, as confirmed by beta users, a practical and useful voice assistant for Welsh speakers. We hope that this work informs and serves as a model to researchers and developers in other lesser-resourced linguistic communities and helps bring into being voice assistant apps for their languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.29.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--29 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.29 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.29/>Gender Detection from <a href=https://en.wikipedia.org/wiki/Human_voice>Human Voice</a> Using Tensor Analysis</a></strong><br><a href=/people/p/prasanta-roy/>Prasanta Roy</a>
|
<a href=/people/p/parabattina-bhagath/>Parabattina Bhagath</a>
|
<a href=/people/p/pradip-das/>Pradip Das</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--29><div class="card-body p-3 small">Speech-based communication is one of the most preferred modes of communication for humans. The <a href=https://en.wikipedia.org/wiki/Human_voice>human voice</a> contains several important information and clues that help in interpreting the voice message. The gender of the speaker can be accurately guessed by a person based on the received voice of a speaker. The knowledge of the speaker&#8217;s gender can be a great aid to design accurate <a href=https://en.wikipedia.org/wiki/Speech_recognition>speech recognition systems</a>. GMM based classifier is a popular choice used for gender detection. In this paper, we propose a Tensor-based approach for detecting the gender of a speaker and discuss its implementation details for low resourceful languages. Experiments were conducted using the TIMIT and SHRUTI dataset. An average gender detection accuracy of 91 % is recorded. Analysis of the results with the proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a> is presented in this paper.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.30.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--30 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.30 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.30/>Data-Driven Parametric Text Normalization : Rapidly Scaling Finite-State Transduction Verbalizers to New Languages</a></strong><br><a href=/people/s/sandy-ritchie/>Sandy Ritchie</a>
|
<a href=/people/e/eoin-mahon/>Eoin Mahon</a>
|
<a href=/people/k/kim-heiligenstein/>Kim Heiligenstein</a>
|
<a href=/people/n/nikos-bampounis/>Nikos Bampounis</a>
|
<a href=/people/d/daan-van-esch/>Daan van Esch</a>
|
<a href=/people/c/christian-schallhart/>Christian Schallhart</a>
|
<a href=/people/j/jonas-mortensen/>Jonas Mortensen</a>
|
<a href=/people/b/benoit-brard/>Benoit Brard</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--30><div class="card-body p-3 small">This paper presents a methodology for rapidly generating FST-based verbalizers for ASR and TTS systems by efficiently sourcing language-specific data. We describe a questionnaire which collects the necessary data to bootstrap the number grammar induction system and parameterize the verbalizer templates described in Ritchie et al. (2019), and a machine-readable data store which allows the data collected through the questionnaire to be supplemented by additional data from other sources. This system allows us to rapidly scale technologies such as <a href=https://en.wikipedia.org/wiki/Autonomous_system_(Internet)>ASR</a> and <a href=https://en.wikipedia.org/wiki/Text-based_user_interface>TTS</a> to more languages, including low-resource languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.32.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--32 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.32 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.32/>Adapting a Welsh Terminology Tool to Develop a Cornish Dictionary<span class=acl-fixed-case>W</span>elsh Terminology Tool to Develop a <span class=acl-fixed-case>C</span>ornish Dictionary</a></strong><br><a href=/people/d/delyth-prys/>Delyth Prys</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--32><div class="card-body p-3 small">Cornish and <a href=https://en.wikipedia.org/wiki/Welsh_language>Welsh</a> are closely related <a href=https://en.wikipedia.org/wiki/Celtic_languages>Celtic languages</a> and this paper provides a brief description of a recent project to publish an online bilingual English / Cornish dictionary, the Gerlyver Kernewek, based on similar work previously undertaken for <a href=https://en.wikipedia.org/wiki/Welsh_language>Welsh</a>. Both languages are endangered, Cornish critically so, but both can benefit from the use of <a href=https://en.wikipedia.org/wiki/Language_technology>language technology</a>. Welsh has previous experience of using language technologies for <a href=https://en.wikipedia.org/wiki/Language_revitalization>language revitalization</a>, and this is now being used to help the <a href=https://en.wikipedia.org/wiki/Cornish_language>Cornish language</a> create new tools and resources, including lexicographical ones, helping a dispersed team of language specialists and editors, many of them in a voluntary capacity, to work collaboratively online. Details are given of the Maes T dictionary writing and publication platform, originally developed for <a href=https://en.wikipedia.org/wiki/Welsh_language>Welsh</a>, and of some of the adaptations that had to be made to accommodate the specific needs of Cornish, including their use of Middle and Late varieties due to its development as a revived language.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.40.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--40 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.40 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.40/>On the Exploration of English to Urdu Machine Translation<span class=acl-fixed-case>E</span>nglish to <span class=acl-fixed-case>U</span>rdu Machine Translation</a></strong><br><a href=/people/s/sadaf-abdul-rauf/>Sadaf Abdul Rauf</a>
|
<a href=/people/s/syeda-abida/>Syeda Abida</a>
|
<a href=/people/n/noor-e-hira/>Noor-e- Hira</a>
|
<a href=/people/s/syeda-zahra/>Syeda Zahra</a>
|
<a href=/people/d/dania-parvez/>Dania Parvez</a>
|
<a href=/people/j/javeria-bashir/>Javeria Bashir</a>
|
<a href=/people/q/qurat-ul-ain-majid/>Qurat-ul-ain Majid</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--40><div class="card-body p-3 small">Machine Translation is the inevitable technology to reduce communication barriers in today&#8217;s world. It has made substantial progress in recent years and is being widely used in commercial as well as non-profit sectors. Such is only the case for European and other high resource languages. For English-Urdu language pair, the <a href=https://en.wikipedia.org/wiki/Technology>technology</a> is in its infancy stage due to scarcity of resources. Present research is an important milestone in English-Urdu machine translation, as we present results for four major domains including Biomedical, Religious, Technological and General using Statistical and Neural Machine Translation. We performed series of experiments in attempts to optimize the performance of each <a href=https://en.wikipedia.org/wiki/System>system</a> and also to study the impact of data sources on the <a href=https://en.wikipedia.org/wiki/System>systems</a>. Finally, we established a comparison of the data sources and the effect of language model size on <a href=https://en.wikipedia.org/wiki/Statistical_machine_translation>statistical machine translation</a> performance.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.42.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--42 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.42 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.42/>Adapting Language Specific Components of Cross-Media Analysis Frameworks to Less-Resourced Languages : the Case of Amharic<span class=acl-fixed-case>A</span>mharic</a></strong><br><a href=/people/y/yonas-woldemariam/>Yonas Woldemariam</a>
|
<a href=/people/a/adam-dahlgren/>Adam Dahlgren</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--42><div class="card-body p-3 small">We present an ASR based pipeline for <a href=https://en.wikipedia.org/wiki/Amharic>Amharic</a> that orchestrates NLP components within a cross media analysis framework (CMAF). One of the major challenges that are inherently associated with CMAFs is effectively addressing multi-lingual issues. As a result, many languages remain under-resourced and fail to leverage out of available media analysis solutions. Although spoken natively by over 22 million people and there is an ever-increasing amount of Amharic multimedia content on the <a href=https://en.wikipedia.org/wiki/World_Wide_Web>Web</a>, querying them with simple text search is difficult. Searching for, especially audio / video content with simple key words, is even hard as they exist in their raw form. In this study, we introduce a spoken and textual content processing workflow into a CMAF for <a href=https://en.wikipedia.org/wiki/Amharic>Amharic</a>. We design an ASR-named entity recognition (NER) pipeline that includes three main components : ASR, a transliterator and NER. We explore various acoustic modeling techniques and develop an OpenNLP-based NER extractor along with a transliterator that interfaces between ASR and <a href=https://en.wikipedia.org/wiki/Near-infrared_spectroscopy>NER</a>. The designed ASR-NER pipeline for <a href=https://en.wikipedia.org/wiki/Amharic>Amharic</a> promotes the multi-lingual support of CMAFs. Also, the state-of-the art design principles and techniques employed in this study shed light for other less-resourced languages, particularly the <a href=https://en.wikipedia.org/wiki/Semitic_languages>Semitic ones</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.45.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--45 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.45 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.45/>Owksape-An Online Language Learning Platform for Lakota<span class=acl-fixed-case>L</span>akota</a></strong><br><a href=/people/j/jan-ullrich/>Jan Ullrich</a>
|
<a href=/people/e/elliot-thornton/>Elliot Thornton</a>
|
<a href=/people/p/peter-vieira/>Peter Vieira</a>
|
<a href=/people/l/logan-swango/>Logan Swango</a>
|
<a href=/people/m/marek-kupiec/>Marek Kupiec</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--45><div class="card-body p-3 small">This paper presents Owksape, an online language learning platform for the under-resourced language Lakota. The Lakota language (Laktiyapi) is a Siouan language native to the United States with fewer than 2000 fluent speakers. Owksape was developed by The Language Conservancy to support revitalization efforts, including reaching younger generations and providing a tool to complement traditional teaching methods. This project grew out of various multimedia resources in order to combine their most effective aspects into a single, self-paced learning tool. The first section of this paper discusses the motivation for and background of Owksape. Section two details the <a href=https://en.wikipedia.org/wiki/Linguistic_description>linguistic features</a> and language documentation principles that form the backbone of the <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a>. Section three lays out the unique integration of cultural aspects of the Lakota people into the <a href=https://en.wikipedia.org/wiki/Graphic_design>visual design</a> of the <a href=https://en.wikipedia.org/wiki/Application_software>application</a>. Section four explains the pedagogical principles of Owksape. Application features and exercise types are then discussed in detail with visual examples, followed by an overview of the <a href=https://en.wikipedia.org/wiki/Software_design>software design</a>, as well as the effort required to develop the <a href=https://en.wikipedia.org/wiki/Computing_platform>platform</a>. Finally, a description of future features and considerations is presented.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.sltu-1.51.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--sltu-1--51 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.sltu-1.51 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.sltu-1.51/>Speech Transcription Challenges for Resource Constrained Indigenous Language Cree<span class=acl-fixed-case>C</span>ree</a></strong><br><a href=/people/v/vishwa-gupta/>Vishwa Gupta</a>
|
<a href=/people/g/gilles-boulianne/>Gilles Boulianne</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--sltu-1--51><div class="card-body p-3 small">Cree is one of the most spoken Indigenous languages in Canada. From a speech recognition perspective, it is a low-resource language, since very little data is available for either acoustic or language modeling. This has prevented development of <a href=https://en.wikipedia.org/wiki/Speech_technology>speech technology</a> that could help revitalize the <a href=https://en.wikipedia.org/wiki/Language>language</a>. We describe our experiments with available Cree data to improve <a href=https://en.wikipedia.org/wiki/Transcription_(biology)>automatic transcription</a> both in speaker- independent and dependent scenarios. While it was difficult to get low speaker-independent word error rates with only six speakers, we were able to get low word and phoneme error rates in the speaker-dependent scenario. We compare our phoneme recognition with two state-of-the-art open-source phoneme recognition toolkits, which use end-to-end training and sequence-to-sequence modeling. Our phoneme error rate (8.7 %) is significantly lower than that achieved by the best of these systems (15.1 %). With these systems and varying amounts of transcribed and text data, we show that pre-training on other languages is important for speaker-independent recognition, and even small amounts of additional text-only documents are useful. These results can guide practical language documentation work, when deciding how much transcribed and text data is needed to achieve useful phoneme accuracies.</div></div></div><hr><div id=2020socialnlp-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.socialnlp-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.socialnlp-1/>Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.socialnlp-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.socialnlp-1.0/>Proceedings of the Eighth International Workshop on Natural Language Processing for Social Media</a></strong><br><a href=/people/l/lun-wei-ku/>Lun-Wei Ku</a>
|
<a href=/people/c/cheng-te-li/>Cheng-Te Li</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.socialnlp-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--socialnlp-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.socialnlp-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929901 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.socialnlp-1.1/>Enhancing Bias Detection in <a href=https://en.wikipedia.org/wiki/Political_journalism>Political News</a> Using Pragmatic Presupposition</a></strong><br><a href=/people/l/lalitha-kameswari/>Lalitha Kameswari</a>
|
<a href=/people/d/dama-sravani/>Dama Sravani</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--socialnlp-1--1><div class="card-body p-3 small">Usage of presuppositions in <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> and news discourse can be a powerful way to influence the readers as they usually tend to not examine the truth value of the hidden or indirectly expressed information. Fairclough and Wodak (1997) discuss <a href=https://en.wikipedia.org/wiki/Presupposition>presupposition</a> at a discourse level where some implicit claims are taken for granted in the explicit meaning of a text or utterance. From the Gricean perspective, the presuppositions of a sentence determine the class of contexts in which the sentence could be felicitously uttered. This paper aims to correlate the type of knowledge presupposed in a news article to the bias present in it. We propose a set of guidelines to identify various kinds of presuppositions in news articles and present a dataset consisting of 1050 articles which are annotated for <a href=https://en.wikipedia.org/wiki/Bias>bias</a> (positive, negative or neutral) and the magnitude of <a href=https://en.wikipedia.org/wiki/Presupposition>presupposition</a>. We introduce a supervised classification approach for detecting bias in <a href=https://en.wikipedia.org/wiki/Political_journalism>political news</a> which significantly outperforms the existing systems.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.socialnlp-1.3.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--socialnlp-1--3 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.socialnlp-1.3 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929903 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.socialnlp-1.3" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.socialnlp-1.3/>NARMADA : Need and Available Resource Managing Assistant for Disasters and Adversities<span class=acl-fixed-case>NARMADA</span>: Need and Available Resource Managing Assistant for Disasters and Adversities</a></strong><br><a href=/people/k/kaustubh-hiware/>Kaustubh Hiware</a>
|
<a href=/people/r/ritam-dutt/>Ritam Dutt</a>
|
<a href=/people/s/sayan-sinha/>Sayan Sinha</a>
|
<a href=/people/s/sohan-patro/>Sohan Patro</a>
|
<a href=/people/k/kripa-ghosh/>Kripa Ghosh</a>
|
<a href=/people/s/saptarshi-ghosh/>Saptarshi Ghosh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--socialnlp-1--3><div class="card-body p-3 small">Although a lot of research has been done on utilising <a href=https://en.wikipedia.org/wiki/Social_media>Online Social Media</a> during disasters, there exists no system for a specific task that is critical in a post-disaster scenario identifying resource-needs and resource-availabilities in the disaster-affected region, coupled with their subsequent matching. To this end, we present NARMADA, a semi-automated platform which leverages the crowd-sourced information from social media posts for assisting post-disaster relief coordination efforts. The system employs <a href=https://en.wikipedia.org/wiki/Natural_language_processing>Natural Language Processing</a> and Information Retrieval techniques for identifying resource-needs and resource-availabilities from <a href=https://en.wikipedia.org/wiki/Microblogging>microblogs</a>, extracting resources from the posts, and also matching the needs to suitable availabilities. The <a href=https://en.wikipedia.org/wiki/System>system</a> is thus capable of facilitating the judicious management of resources during <a href=https://en.wikipedia.org/wiki/Emergency_management>post-disaster relief operations</a>.</div></div></div><hr><div id=2020stoc-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.stoc-1/>Proceedings for the First International Workshop on Social Threats in Online Conversations: Understanding and Management</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.stoc-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.stoc-1.0/>Proceedings for the First International Workshop on Social Threats in Online Conversations: Understanding and Management</a></strong><br><a href=/people/a/archna-bhatia/>Archna Bhatia</a>
|
<a href=/people/s/samira-shaikh/>Samira Shaikh</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.stoc-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--stoc-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.stoc-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.stoc-1.4/>A Privacy Preserving Data Publishing Middleware for Unstructured, Textual Social Media Data</a></strong><br><a href=/people/p/prasadi-abeywardana/>Prasadi Abeywardana</a>
|
<a href=/people/u/uthayasanker-thayasivam/>Uthayasanker Thayasivam</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--stoc-1--4><div class="card-body p-3 small">Privacy is going to be an integral part of <a href=https://en.wikipedia.org/wiki/Data_science>data science and analytics</a> in the coming years. The next hype of data experimentation is going to be heavily dependent on privacy preserving techniques mainly as it&#8217;s going to be a legal responsibility rather than a mere social responsibility. Privacy preservation becomes more challenging specially in the context of <a href=https://en.wikipedia.org/wiki/Unstructured_data>unstructured data</a>. Social networks have become predominantly popular over the past couple of decades and they are creating a huge data lake at a high velocity. Social media profiles contain a wealth of personal and sensitive information, creating enormous opportunities for third parties to analyze them with different <a href=https://en.wikipedia.org/wiki/Algorithm>algorithms</a>, draw conclusions and use in <a href=https://en.wikipedia.org/wiki/Disinformation>disinformation campaigns</a> and micro targeting based dark advertising. This study provides a mitigation mechanism for <a href=https://en.wikipedia.org/wiki/Disinformation>disinformation campaigns</a> that are done based on the insights extracted from personal / sensitive data analysis. Specifically, this research is aimed at building a privacy preserving data publishing middleware for unstructured social media data without compromising the true analytical value of those <a href=https://en.wikipedia.org/wiki/Data>data</a>. A novel way is proposed to apply traditional structured privacy preserving techniques on <a href=https://en.wikipedia.org/wiki/Unstructured_data>unstructured data</a>. Creating a comprehensive twitter corpus annotated with privacy attributes is another objective of this research, especially because the research community is lacking one.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.stoc-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--stoc-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.stoc-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.stoc-1.5/>Information Space Dashboard</a></strong><br><a href=/people/t/theresa-krumbiegel/>Theresa Krumbiegel</a>
|
<a href=/people/a/albert-pritzkau/>Albert Pritzkau</a>
|
<a href=/people/h/hans-christian-schmitz/>Hans-Christian Schmitz</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--stoc-1--5><div class="card-body p-3 small">The <a href=https://en.wikipedia.org/wiki/Information_space>information space</a>, where information is generated, stored, exchanged and discussed, is not idyllic but a space where <a href=https://en.wikipedia.org/wiki/Disinformation>campaigns of disinformation</a> and <a href=https://en.wikipedia.org/wiki/Destabilization>destabilization</a> are conducted. Such campaigns are subsumed under the terms <a href=https://en.wikipedia.org/wiki/Hybrid_warfare>hybrid warfare</a> and <a href=https://en.wikipedia.org/wiki/Information_warfare>information warfare</a> (Woolley and Howard, 2017). In order to enable awareness of them, we propose an information state dashboard comprising various components / apps for <a href=https://en.wikipedia.org/wiki/Data_collection>data collection</a>, analysis and <a href=https://en.wikipedia.org/wiki/Data_visualization>visualization</a>. The aim of the dashboard is to support an analyst in generating a common operational picture of the information space, link it with an operational picture of the physical space and, thus, contribute to overarching situational awareness. The <a href=https://en.wikipedia.org/wiki/Dashboard>dashboard</a> is work in progress. However, a first prototype with components for exploiting elementary language statistics, keyword and metadata analysis, <a href=https://en.wikipedia.org/wiki/Text_classification>text classification</a> and <a href=https://en.wikipedia.org/wiki/Network_theory>network analysis</a> has been implemented. Further components, in particular, for <a href=https://en.wikipedia.org/wiki/Event_(computing)>event extraction</a> and <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> are under development. As a demonstration case, we briefly discuss the analysis of historical data regarding <a href=https://en.wikipedia.org/wiki/2018_Chemnitz_protests>violent anti-migrant protests</a> and respective <a href=https://en.wikipedia.org/wiki/Counter-protest>counter-protests</a> that took place in <a href=https://en.wikipedia.org/wiki/Chemnitz>Chemnitz</a> in 2018.</div></div></div><hr><div id=2020trac-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.trac-1/>Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.trac-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.trac-1.0/>Proceedings of the Second Workshop on Trolling, Aggression and Cyberbullying</a></strong><br><a href=/people/r/ritesh-kumar/>Ritesh Kumar</a>
|
<a href=/people/a/atul-kr-ojha/>Atul Kr. Ojha</a>
|
<a href=/people/b/bornini-lahiri/>Bornini Lahiri</a>
|
<a href=/people/m/marcos-zampieri/>Marcos Zampieri</a>
|
<a href=/people/s/shervin-malmasi/>Shervin Malmasi</a>
|
<a href=/people/v/vanessa-murdock/>Vanessa Murdock</a>
|
<a href=/people/d/daniel-kadar/>Daniel Kadar</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.trac-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--trac-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.trac-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.trac-1.5/>Aggression Identification in <a href=https://en.wikipedia.org/wiki/Social_media>Social Media</a> : a Transfer Learning Based Approach</a></strong><br><a href=/people/f/faneva-ramiandrisoa/>Faneva Ramiandrisoa</a>
|
<a href=/people/j/josiane-mothe/>Josiane Mothe</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--trac-1--5><div class="card-body p-3 small">The way people communicate have changed in many ways with the outbreak of <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>. One of the aspects of <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> is the ability for their information producers to hide, fully or partially, their identity during a discussion ; leading to <a href=https://en.wikipedia.org/wiki/Cyber-aggression>cyber-aggression</a> and interpersonal aggression. Automatically monitoring <a href=https://en.wikipedia.org/wiki/User-generated_content>user-generated content</a> in order to help moderating it is thus a very hot topic. In this paper, we propose to use the transformer based language model BERT (Bidirectional Encoder Representation from Transformer) (Devlin et al., 2019) to identify aggressive content. Our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> is also used to predict the level of <a href=https://en.wikipedia.org/wiki/Aggression>aggressiveness</a>. The evaluation part of this paper is based on the <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> provided by the TRAC shared task (Kumar et al., 2018a). When compared to the other participants of this shared task, our <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> achieved the third best performance according to the weighted F1 measure on both Facebook and Twitter collections.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.trac-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--trac-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.trac-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.trac-1.7/>A Comparative Study of Different State-of-the-Art Hate Speech Detection Methods in Hindi-English Code-Mixed Data<span class=acl-fixed-case>H</span>indi-<span class=acl-fixed-case>E</span>nglish Code-Mixed Data</a></strong><br><a href=/people/p/priya-rani/>Priya Rani</a>
|
<a href=/people/s/shardul-suryawanshi/>Shardul Suryawanshi</a>
|
<a href=/people/k/koustava-goswami/>Koustava Goswami</a>
|
<a href=/people/b/bharathi-raja-chakravarthi/>Bharathi Raja Chakravarthi</a>
|
<a href=/people/t/theodorus-fransen/>Theodorus Fransen</a>
|
<a href=/people/j/john-philip-mccrae/>John Philip McCrae</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--trac-1--7><div class="card-body p-3 small">Hate speech detection in <a href=https://en.wikipedia.org/wiki/Social_media>social media communication</a> has become one of the primary concerns to avoid conflicts and curb undesired activities. In an environment where multilingual speakers switch among multiple languages, hate speech detection becomes a challenging task using methods that are designed for monolingual corpora. In our work, we attempt to analyze, detect and provide a comparative study of <a href=https://en.wikipedia.org/wiki/Hate_speech>hate speech</a> in a code-mixed social media text. We also provide a Hindi-English code-mixed data set consisting of Facebook and Twitter posts and comments. Our experiments show that <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning models</a> trained on this code-mixed corpus perform better.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.trac-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--trac-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.trac-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.trac-1.9" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.trac-1.9/>Bagging BERT Models for Robust Aggression Identification<span class=acl-fixed-case>BERT</span> Models for Robust Aggression Identification</a></strong><br><a href=/people/j/julian-risch/>Julian Risch</a>
|
<a href=/people/r/ralf-krestel/>Ralf Krestel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--trac-1--9><div class="card-body p-3 small">Modern transformer-based models with hundreds of millions of parameters, such as BERT, achieve impressive results at text classification tasks. This also holds for aggression identification and offensive language detection, where deep learning approaches consistently outperform less complex models, such as <a href=https://en.wikipedia.org/wiki/Decision_tree_learning>decision trees</a>. While the complex models fit training data well (low bias), they also come with an unwanted high variance. Especially when fine-tuning them on small datasets, the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> performance varies significantly for slightly different training data. To overcome the high variance and provide more robust predictions, we propose an ensemble of multiple fine-tuned BERT models based on bootstrap aggregating (bagging). In this paper, we describe such an ensemble system and present our submission to the shared tasks on aggression identification 2020 (team name : Julian). Our submission is the best-performing <a href=https://en.wikipedia.org/wiki/System>system</a> for five out of six subtasks. For example, we achieve a weighted F1-score of 80.3 % for task A on the test dataset of English social media posts. In our experiments, we compare different model configurations and vary the number of models used in the <a href=https://en.wikipedia.org/wiki/Statistical_ensemble_(mathematical_physics)>ensemble</a>. We find that the F1-score drastically increases when ensembling up to 15 models, but the returns diminish for more models.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.trac-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--trac-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.trac-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.trac-1.10/>Scmhl5 at TRAC-2 Shared Task on Aggression Identification : Bert Based Ensemble Learning Approach<span class=acl-fixed-case>TRAC</span>-2 Shared Task on Aggression Identification: Bert Based Ensemble Learning Approach</a></strong><br><a href=/people/h/han-liu/>Han Liu</a>
|
<a href=/people/p/pete-burnap/>Pete Burnap</a>
|
<a href=/people/w/wafa-alorainy/>Wafa Alorainy</a>
|
<a href=/people/m/matthew-williams/>Matthew Williams</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--trac-1--10><div class="card-body p-3 small">This paper presents a system developed during our participation (team name : scmhl5) in the TRAC-2 Shared Task on aggression identification. In particular, we participated in English Sub-task A on three-class classification (&#8216;Overtly Aggressive&#8217;, &#8216;Covertly Aggressive&#8217; and &#8216;Non-aggressive&#8217;) and English Sub-task B on binary classification for Misogynistic Aggression (&#8216;gendered&#8217; or &#8216;non-gendered&#8217;). For both sub-tasks, our method involves using the pre-trained Bert model for extracting the text of each instance into a 768-dimensional vector of embeddings, and then training an ensemble of <a href=https://en.wikipedia.org/wiki/Statistical_classification>classifiers</a> on the embedding features. Our method obtained <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> of 0.703 and <a href=https://en.wikipedia.org/wiki/Weighted_arithmetic_mean>weighted F-measure</a> of 0.664 for Sub-task A, whereas for Sub-task B the <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> was 0.869 and <a href=https://en.wikipedia.org/wiki/Weighted_arithmetic_mean>weighted F-measure</a> was 0.851. In terms of the rankings, the weighted F-measure obtained using our method for Sub-task A is ranked in the 10th out of 16 teams, whereas for Sub-task B the weighted F-measure is ranked in the 8th out of 15 teams.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.trac-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--trac-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.trac-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.trac-1.14/>Spyder : Aggression Detection on Multilingual Tweets<span class=acl-fixed-case>S</span>pyder: Aggression Detection on Multilingual Tweets</a></strong><br><a href=/people/a/anisha-datta/>Anisha Datta</a>
|
<a href=/people/s/shukrity-si/>Shukrity Si</a>
|
<a href=/people/u/urbi-chakraborty/>Urbi Chakraborty</a>
|
<a href=/people/s/sudip-kumar-naskar/>Sudip Kumar Naskar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--trac-1--14><div class="card-body p-3 small">In the last few years, <a href=https://en.wikipedia.org/wiki/Hate_speech>hate speech</a> and aggressive comments have covered almost all the social media platforms like <a href=https://en.wikipedia.org/wiki/Facebook>facebook</a>, <a href=https://en.wikipedia.org/wiki/Twitter>twitter</a> etc. As a result hatred is increasing. This paper describes our (Team name : Spyder) participation in the Shared Task on <a href=https://en.wikipedia.org/wiki/Aggression>Aggression Detection</a> organised by TRAC-2, Second Workshop on <a href=https://en.wikipedia.org/wiki/Internet_troll>Trolling</a>, <a href=https://en.wikipedia.org/wiki/Aggression>Aggression</a> and <a href=https://en.wikipedia.org/wiki/Cyberbullying>Cyberbullying</a>. The Organizers provided datasets in three languages <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a> and <a href=https://en.wikipedia.org/wiki/Bengali_language>Bengali</a>. The task was to classify each instance of the test sets into three categories Overtly Aggressive (OAG), Covertly Aggressive (CAG) and Non-Aggressive (NAG). In this paper, we propose three different models using Tf-Idf, sentiment polarity and <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning based classifiers</a>. We obtained <a href=https://en.wikipedia.org/wiki/F-number>f1 score</a> of 43.10 %, 59.45 % and 44.84 % respectively for <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a> and <a href=https://en.wikipedia.org/wiki/Bengali_language>Bengali</a>.<b>Team name:</b>\n <b>Spyder</b>) participation in the Shared Task on Aggression Detection organised by TRAC-2, Second Workshop on Trolling, Aggression and Cyberbullying. The Organizers provided datasets in three languages &#8211; English, Hindi and Bengali. The task was to classify each instance of the test sets into three categories &#8211; &#8220;Overtly Aggressive&#8221; (OAG), &#8220;Covertly Aggressive&#8221; (CAG) and &#8220;Non-Aggressive&#8221; (NAG). In this paper, we propose three different models using Tf-Idf, sentiment polarity and machine learning based classifiers. We obtained f1 score of 43.10%, 59.45% and 44.84% respectively for English, Hindi and Bengali.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.trac-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--trac-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.trac-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.trac-1.15/>BERT of all trades, master of some<span class=acl-fixed-case>BERT</span> of all trades, master of some</a></strong><br><a href=/people/d/denis-gordeev/>Denis Gordeev</a>
|
<a href=/people/o/olga-lykova/>Olga Lykova</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--trac-1--15><div class="card-body p-3 small">This paper describes our results for TRAC 2020 competition held together with the conference LREC 2020. Our team name was Ms8qQxMbnjJMgYcw. The competition consisted of 2 subtasks in 3 languages (Bengali, English and Hindi) where the participants&#8217; task was to classify aggression in short texts from <a href=https://en.wikipedia.org/wiki/Social_media>social media</a> and decide whether it is gendered or not. We used a single BERT-based system with two outputs for all tasks simultaneously. Our <a href=https://en.wikipedia.org/wiki/Conceptual_model>model</a> placed first in <a href=https://en.wikipedia.org/wiki/English_language>English</a> and second in Bengali gendered text classification competition tasks with 0.87 and 0.93 in F1-score respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.trac-1.17.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--trac-1--17 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.trac-1.17 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.trac-1.17/>FlorUniTo@TRAC-2 : Retrofitting Word Embeddings on an Abusive Lexicon for Aggressive Language Detection<span class=acl-fixed-case>F</span>lor<span class=acl-fixed-case>U</span>ni<span class=acl-fixed-case>T</span>o@<span class=acl-fixed-case>TRAC</span>-2: Retrofitting Word Embeddings on an Abusive Lexicon for Aggressive Language Detection</a></strong><br><a href=/people/a/anna-koufakou/>Anna Koufakou</a>
|
<a href=/people/v/valerio-basile/>Valerio Basile</a>
|
<a href=/people/v/viviana-patti/>Viviana Patti</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--trac-1--17><div class="card-body p-3 small">This paper describes our participation to the TRAC-2 Shared Tasks on Aggression Identification. Our team, FlorUniTo, investigated the applicability of using an abusive lexicon to enhance word embeddings towards improving detection of aggressive language. The embeddings used in our paper are word-aligned pre-trained vectors for <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a>, and <a href=https://en.wikipedia.org/wiki/Bengali_language>Bengali</a>, to reflect the languages in the shared task data sets. The embeddings are retrofitted to a multilingual abusive lexicon, HurtLex. We experimented with an LSTM model using the original as well as the transformed embeddings and different language and setting variations. Overall, our <a href=https://en.wikipedia.org/wiki/System>systems</a> placed toward the middle of the <a href=https://en.wikipedia.org/wiki/List_of_Formula_One_World_Drivers&#8217;_Champions>official rankings</a> based on <a href=https://en.wikipedia.org/wiki/Weighted_arithmetic_mean>weighted F1 score</a>. However, the results on the development and test sets show promising improvements across languages, especially on the misogynistic aggression sub-task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.trac-1.19.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--trac-1--19 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.trac-1.19 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.trac-1.19" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.trac-1.19/>Multilingual Joint Fine-tuning of Transformer models for identifying Trolling, Aggression and Cyberbullying at TRAC 2020<span class=acl-fixed-case>TRAC</span> 2020</a></strong><br><a href=/people/s/sudhanshu-mishra/>Sudhanshu Mishra</a>
|
<a href=/people/s/shivangi-prasad/>Shivangi Prasad</a>
|
<a href=/people/s/shubhanshu-mishra/>Shubhanshu Mishra</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--trac-1--19><div class="card-body p-3 small">We present our team &#8216;3Idiots&#8217; (referred as &#8216;sdhanshu&#8217; in the official rankings) approach for the Trolling, Aggression and Cyberbullying (TRAC) 2020 shared tasks. Our approach relies on fine-tuning various Transformer models on the different <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a>. We also investigated the utility of task label marginalization, joint label classification, and joint training on multilingual datasets as possible improvements to our models. Our team came second in English sub-task A, a close fourth in the English sub-task B and third in the remaining 4 sub-tasks. We find the multilingual joint training approach to be the best trade-off between computational efficiency of model deployment and <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a>&#8217;s evaluation performance. We open source our approach at https://github.com/socialmediaie/TRAC2020.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.trac-1.20.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--trac-1--20 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.trac-1.20 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-secondary align-middle mr-1 pwc-reduced-padding" href="https://paperswithcode.com/paper/?acl=2020.trac-1.20" data-toggle=tooltip data-placement=top title=Code><svg xmlns="http://www.w3.org/2000/svg" class="pwc-icon-small" viewBox="0 0 512 512"><path stroke="#4d8093" fill="#4d8093" d="M88 128h48v256H88zm144 0h48v256h-48zm-72 16h48v224h-48zm144 0h48v224h-48zm72-16h48v256h-48z"/><path stroke="#4d8093" fill="#4d8093" d="M104 104V56H16v4e2h88v-48H64V104zM408 56v48h40v304h-40v48h88V56z"/></svg></a></span><span class=d-block><strong><a class=align-middle href=/2020.trac-1.20/>Aggression and Misogyny Detection using <a href=https://en.wikipedia.org/wiki/BERT>BERT</a> : A Multi-Task Approach<span class=acl-fixed-case>BERT</span>: A Multi-Task Approach</a></strong><br><a href=/people/n/niloofar-safi-samghabadi/>Niloofar Safi Samghabadi</a>
|
<a href=/people/p/parth-patwa/>Parth Patwa</a>
|
<a href=/people/s/srinivas-pykl/>Srinivas PYKL</a>
|
<a href=/people/p/prerana-mukherjee/>Prerana Mukherjee</a>
|
<a href=/people/a/amitava-das/>Amitava Das</a>
|
<a href=/people/t/thamar-solorio/>Thamar Solorio</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--trac-1--20><div class="card-body p-3 small">In recent times, the focus of the NLP community has increased towards offensive language, aggression, and hate-speech detection. This paper presents our system for TRAC-2 shared task on Aggression Identification (sub-task A) and Misogynistic Aggression Identification (sub-task B). The data for this shared <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a> is provided in three different languages-English, <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a>, and <a href=https://en.wikipedia.org/wiki/Bengali_language>Bengali</a>. Each data instance is annotated into one of the three aggression classes-Not Aggressive, Covertly Aggressive, Overtly Aggressive, as well as one of the two misogyny classes-Gendered and Non-Gendered. We propose an end-to-end neural model using <a href=https://en.wikipedia.org/wiki/Attention>attention</a> on top of BERT that incorporates a multi-task learning paradigm to address both the sub-tasks simultaneously. Our team, na14, scored 0.8579 weighted F1-measure on the English sub-task B and secured 3rd rank out of 15 teams for the task. The code and the model weights are publicly available at https://github.com/NiloofarSafi/TRAC-2. Keywords : <a href=https://en.wikipedia.org/wiki/Aggression>Aggression</a>, <a href=https://en.wikipedia.org/wiki/Misogyny>Misogyny</a>, <a href=https://en.wikipedia.org/wiki/Abusive_language>Abusive Language</a>, Hate-Speech Detection, BERT, <a href=https://en.wikipedia.org/wiki/Natural_language_processing>NLP</a>, <a href=https://en.wikipedia.org/wiki/Neural_network>Neural Networks</a>, <a href=https://en.wikipedia.org/wiki/Social_media>Social Media</a></div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.trac-1.24.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--trac-1--24 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.trac-1.24 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.trac-1.24/>Lexicon-Enhancement of Embedding-based Approaches Towards the Detection of Abusive Language</a></strong><br><a href=/people/a/anna-koufakou/>Anna Koufakou</a>
|
<a href=/people/j/jason-scott/>Jason Scott</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--trac-1--24><div class="card-body p-3 small">Detecting abusive language is a significant research topic, which has received a lot of attention recently. Our work focuses on detecting personal attacks in <a href=https://en.wikipedia.org/wiki/Online_chat>online conversations</a>. As previous research on this task has largely used <a href=https://en.wikipedia.org/wiki/Deep_learning>deep learning</a> based on <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a>, we explore the use of <a href=https://en.wikipedia.org/wiki/Lexicon>lexicons</a> to enhance embedding-based methods in an effort to see how these methods apply in the particular task of detecting personal attacks. The methods implemented and experimented with in this paper are quite different from each other, not only in the type of lexicons they use (sentiment or semantic), but also in the way they use the knowledge from the <a href=https://en.wikipedia.org/wiki/Lexicon>lexicons</a>, in order to construct or to change embeddings that are ultimately fed into the learning model. The sentiment lexicon approaches focus on integrating <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment information</a> (in the form of sentiment embeddings) into the <a href=https://en.wikipedia.org/wiki/Machine_learning>learning model</a>. The <a href=https://en.wikipedia.org/wiki/Semantic_lexicon>semantic lexicon approaches</a> focus on transforming the original <a href=https://en.wikipedia.org/wiki/Word_embedding>word embeddings</a> so that they better represent relationships extracted from a <a href=https://en.wikipedia.org/wiki/Semantic_lexicon>semantic lexicon</a>. Based on our experimental results, semantic lexicon methods are superior to the rest of the <a href=https://en.wikipedia.org/wiki/Methodology>methods</a> in this paper, with at least 4 % macro-averaged F1 improvement over the baseline.</div></div></div><hr><div id=2020wac-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.wac-1/>Proceedings of the 12th Web as Corpus Workshop</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.wac-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.wac-1.0/>Proceedings of the 12th Web as Corpus Workshop</a></strong><br><a href=/people/a/adrien-barbaresi/>Adrien Barbaresi</a>
|
<a href=/people/f/felix-bildhauer/>Felix Bildhauer</a>
|
<a href=/people/r/roland-schafer/>Roland Schäfer</a>
|
<a href=/people/e/egon-stemle/>Egon Stemle</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.wac-1.1.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--wac-1--1 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.wac-1.1 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.wac-1.1/>Current Challenges in Web Corpus Building</a></strong><br><a href=/people/m/milos-jakubicek/>Miloš Jakubíček</a>
|
<a href=/people/v/vojtech-kovar/>Vojtěch Kovář</a>
|
<a href=/people/p/pavel-rychly/>Pavel Rychlý</a>
|
<a href=/people/v/vit-suchomel/>Vit Suchomel</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--wac-1--1><div class="card-body p-3 small">In this paper we discuss some of the current challenges in web corpus building that we faced in the recent years when expanding the corpora in <a href=https://en.wikipedia.org/wiki/Sketch_Engine>Sketch Engine</a>. The purpose of the paper is to provide an overview and raise discussion on possible solutions, rather than bringing ready solutions to the readers. For every issue we try to assess its severity and briefly discuss possible mitigation options.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.wac-1.5.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--wac-1--5 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.wac-1.5 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.wac-1.5/>The ELTE.DH Pilot Corpus Creating a Handcrafted Gigaword Web Corpus with Metadata<span class=acl-fixed-case>ELTE</span>.<span class=acl-fixed-case>DH</span> Pilot Corpus – Creating a Handcrafted <span class=acl-fixed-case>G</span>igaword Web Corpus with Metadata</a></strong><br><a href=/people/b/balazs-indig/>Balázs Indig</a>
|
<a href=/people/a/arpad-knap/>Árpád Knap</a>
|
<a href=/people/z/zsofia-sarkozi-lindner/>Zsófia Sárközi-Lindner</a>
|
<a href=/people/m/maria-timari/>Mária Timári</a>
|
<a href=/people/g/gabor-palko/>Gábor Palkó</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--wac-1--5><div class="card-body p-3 small">In this article, we present the method we used to create a middle-sized corpus using targeted web crawling. Our corpus contains news portal articles along with their metadata, that can be useful for diverse audiences, ranging from digital humanists to NLP users. The method presented in this paper applies rule-based components that allow the curation of the text and the <a href=https://en.wikipedia.org/wiki/Metadata>metadata content</a>. The curated data can thereon serve as a reference for various tasks and measurements. We designed our <a href=https://en.wikipedia.org/wiki/Workflow>workflow</a> to encourage modification and customisation. Our <a href=https://en.wikipedia.org/wiki/Concept>concept</a> can also be applied to other genres of <a href=https://en.wikipedia.org/wiki/Portal_(architecture)>portals</a> by using the discovered <a href=https://en.wikipedia.org/wiki/Pattern>patterns</a> in the architecture of the portals. We found that for a systematic creation or extension of a similar corpus, our method provides superior <a href=https://en.wikipedia.org/wiki/Accuracy_and_precision>accuracy</a> and ease of use compared to The <a href=https://en.wikipedia.org/wiki/Wayback_Machine>Wayback Machine</a>, while requiring minimal manpower and computational resources. Reproducing the corpus is possible if changes are introduced to the text-extraction process. The standard <a href=https://en.wikipedia.org/wiki/Text_Encoding_Initiative>TEI format</a> and Schema.org encoded metadata is used for the output format, but we stress that placing the <a href=https://en.wikipedia.org/wiki/Text_corpus>corpus</a> in a digital repository system is recommended in order to be able to define semantic relations between the segments and to add rich annotation.</div></div></div><hr><div id=2020wildre-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"></span>
<a class=align-middle href=/volumes/2020.wildre-1/>Proceedings of the WILDRE5– 5th Workshop on Indian Language Data: Resources and Evaluation</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.wildre-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.wildre-1.0/>Proceedings of the WILDRE5– 5th Workshop on Indian Language Data: Resources and Evaluation</a></strong><br><a href=/people/g/girish-nath-jha/>Girish Nath Jha</a>
|
<a href=/people/k/kalika-bali/>Kalika Bali</a>
|
<a href=/people/s/sobha-l/>Sobha L.</a>
|
<a href=/people/s/s-s-agrawal/>S. S. Agrawal</a>
|
<a href=/people/a/atul-kr-ojha/>Atul Kr. Ojha</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.wildre-1.4.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--wildre-1--4 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.wildre-1.4 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.wildre-1.4/>Handling Noun-Noun Coreference in Tamil<span class=acl-fixed-case>T</span>amil</a></strong><br><a href=/people/v/vijay-sundar-ram/>Vijay Sundar Ram</a>
|
<a href=/people/s/sobha-lalitha-devi/>Sobha Lalitha Devi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--wildre-1--4><div class="card-body p-3 small">Natural language understanding by automatic tools is the vital requirement for document processing tools. To achieve it, automatic system has to understand the coherence in the text. Co-reference chains bring coherence to the text. The commonly occurring reference markers which bring cohesiveness are Pronominal, Reflexives, Reciprocals, Distributives, One-anaphors, Nounnoun reference. Here in this paper, we deal with noun-noun reference in <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil</a>. We present the methodology to resolve these noun-noun anaphors and also present the challenges in handling the noun-noun anaphoric relations in <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.wildre-1.9.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--wildre-1--9 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.wildre-1.9 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.wildre-1.9/>Determination of Idiomatic Sentences in Paragraphs Using Statement Classification and Generalization of Grammar Rules</a></strong><br><a href=/people/n/naziya-shaikh/>Naziya Shaikh</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--wildre-1--9><div class="card-body p-3 small">The translation systems are often not able to determine the presence of an <a href=https://en.wikipedia.org/wiki/Idiom_(language_structure)>idiom</a> in a given paragraph. Due to this many systems tend to return the word-for-word translation of such statements leading to loss in the flavor of the <a href=https://en.wikipedia.org/wiki/Idiom_(language_structure)>idioms</a> in the paragraph. This paper suggests a novel approach to efficiently determine probability of any statement in a given English paragraph to be an <a href=https://en.wikipedia.org/wiki/Idiom>idiom</a>. This approach combines the rule-based generalization of idioms in <a href=https://en.wikipedia.org/wiki/English_language>English language</a> and classification of statements based on the context to determine the <a href=https://en.wikipedia.org/wiki/Idiom_(language_structure)>idioms</a> in the sentence. The context based classification method can be used further for determination of idioms in regional Indian languages such as <a href=https://en.wikipedia.org/wiki/Marathi_language>Marathi</a>, <a href=https://en.wikipedia.org/wiki/Konkani_language>Konkani</a> and <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a> as the difference in the semantic context of the proverb as compared to the context in a paragraph is also evident in these other languages.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.wildre-1.12.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--wildre-1--12 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.wildre-1.12 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.wildre-1.12/>A Deeper Study on <a href=https://en.wikipedia.org/wiki/Feature_(computer_vision)>Features</a> for Named Entity Recognition</a></strong><br><a href=/people/m/malarkodi-c-s/>Malarkodi C S</a>
|
<a href=/people/s/sobha-lalitha-devi/>Sobha Lalitha Devi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--wildre-1--12><div class="card-body p-3 small">This paper deals with the various <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>features</a> used for the identification of named entities. The performance of the <a href=https://en.wikipedia.org/wiki/Machine_learning>machine learning system</a> heavily depends on the feature selection criteria. The intention to trace the essential features required for the development of named entity system across languages motivated us to conduct this study. The <a href=https://en.wikipedia.org/wiki/Linguistic_description>linguistic analysis</a> was done to find out the part of speech patterns surrounding the context of named entities and from the observation linguistic oriented features are identified for both Indian and European languages. The Indian languages belongs to <a href=https://en.wikipedia.org/wiki/Dravidian_languages>Dravidian language family</a> such as <a href=https://en.wikipedia.org/wiki/Tamil_language>Tamil</a>, <a href=https://en.wikipedia.org/wiki/Telugu_language>Telugu</a>, <a href=https://en.wikipedia.org/wiki/Malayalam>Malayalam</a>, <a href=https://en.wikipedia.org/wiki/Indo-Aryan_languages>Indo-Aryan language family</a> such as <a href=https://en.wikipedia.org/wiki/Hindi>Hindi</a>, <a href=https://en.wikipedia.org/wiki/Punjabi_language>Punjabi</a>, <a href=https://en.wikipedia.org/wiki/Bengali_language>Bengali</a> and <a href=https://en.wikipedia.org/wiki/Marathi_language>Marathi</a>, European languages such as <a href=https://en.wikipedia.org/wiki/English_language>English</a>, <a href=https://en.wikipedia.org/wiki/Spanish_language>Spanish</a>, <a href=https://en.wikipedia.org/wiki/Dutch_language>Dutch</a>, <a href=https://en.wikipedia.org/wiki/German_language>German</a> and <a href=https://en.wikipedia.org/wiki/Hungarian_language>Hungarian</a> are used in this work. The machine learning technique CRFs was used for the system development. The experiments were conducted using the <a href=https://en.wikipedia.org/wiki/Feature_(linguistics)>linguistic features</a> and the results obtained for each languages are comparable with <a href=https://en.wikipedia.org/wiki/State_of_the_art>state-of-art systems</a>.</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>