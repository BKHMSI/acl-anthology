<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Workshop on Figurative Language Processing (2020) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Workshop on Figurative Language Processing (2020)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#2020figlang-1>Proceedings of the Second Workshop on Figurative Language Processing</a>
<span class="badge badge-info align-middle ml-1">14&nbsp;papers</span></li></ul></div></div><div id=2020figlang-1><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/2020.figlang-1/>Proceedings of the Second Workshop on Figurative Language Processing</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.0.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.figlang-1.0/>Proceedings of the Second Workshop on Figurative Language Processing</a></strong><br><a href=/people/b/beata-beigman-klebanov/>Beata Beigman Klebanov</a>
|
<a href=/people/e/ekaterina-shutova/>Ekaterina Shutova</a>
|
<a href=/people/p/patricia-lichtenstein/>Patricia Lichtenstein</a>
|
<a href=/people/s/smaranda-muresan/>Smaranda Muresan</a>
|
<a href=/people/c/chee-wee/>Chee Wee</a>
|
<a href=/people/a/anna-feldman/>Anna Feldman</a>
|
<a href=/people/d/debanjan-ghosh/>Debanjan Ghosh</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.7.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--7 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.7 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929697 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.7/>Sarcasm Detection in Tweets with BERT and GloVe Embeddings<span class=acl-fixed-case>BERT</span> and <span class=acl-fixed-case>G</span>lo<span class=acl-fixed-case>V</span>e Embeddings</a></strong><br><a href=/people/a/akshay-khatri/>Akshay Khatri</a>
|
<a href=/people/p/pranav-p/>Pranav P</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--7><div class="card-body p-3 small">Sarcasm is a form of communication in which the person states opposite of what he actually means. In this paper, we propose using machine learning techniques with BERT and GloVe embeddings to detect <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> in <a href=https://en.wikipedia.org/wiki/Twitter>tweets</a>. The <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a> is preprocessed before extracting the <a href=https://en.wikipedia.org/wiki/Embedding>embeddings</a>. The proposed <a href=https://en.wikipedia.org/wiki/Mathematical_model>model</a> also uses all of the context provided in the dataset to which the user is reacting along with his actual response.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.8.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--8 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.8 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929698 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.8/>C-Net : Contextual Network for Sarcasm Detection<span class=acl-fixed-case>C</span>-Net: Contextual Network for Sarcasm Detection</a></strong><br><a href=/people/a/amit-kumar-jena/>Amit Kumar Jena</a>
|
<a href=/people/a/aman-sinha/>Aman Sinha</a>
|
<a href=/people/r/rohit-agarwal/>Rohit Agarwal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--8><div class="card-body p-3 small">Automatic Sarcasm Detection in <a href=https://en.wikipedia.org/wiki/Conversation>conversations</a> is a difficult and tricky task. Classifying an utterance as sarcastic or not in isolation can be futile since most of the time the sarcastic nature of a sentence heavily relies on its context. This paper presents our proposed model, <a href=https://en.wikipedia.org/wiki/C-Net>C-Net</a>, which takes contextual information of a sentence in a sequential manner to classify it as sarcastic or non-sarcastic. Our <a href=https://en.wikipedia.org/wiki/Statistical_model>model</a> showcases competitive performance in the Sarcasm Detection shared task organised on CodaLab and achieved 75.0 % <a href=https://en.wikipedia.org/wiki/F-number>F1-score</a> on the Twitter dataset and 66.3 % <a href=https://en.wikipedia.org/wiki/F-number>F1-score</a> on Reddit dataset.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.10.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--10 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.10 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929700 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.10/>Sarcasm Identification and Detection in Conversion Context using BERT<span class=acl-fixed-case>BERT</span></a></strong><br><a href=/people/k/kalaivani-a/>Kalaivani A.</a>
|
<a href=/people/t/thenmozhi-d/>Thenmozhi D.</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--10><div class="card-body p-3 small">Sarcasm analysis in user conversion text is automatic detection of any irony, insult, hurting, painful, caustic, <a href=https://en.wikipedia.org/wiki/Humour>humour</a>, vulgarity that degrades an individual. It is helpful in the field of sentimental analysis and <a href=https://en.wikipedia.org/wiki/Cyberbullying>cyberbullying</a>. As an immense growth of <a href=https://en.wikipedia.org/wiki/Social_media>social media</a>, sarcasm analysis helps to avoid insult, hurts and <a href=https://en.wikipedia.org/wiki/Humour>humour</a> to affect someone. In this paper, we present traditional machine learning approaches, deep learning approach (LSTM -RNN) and BERT (Bidirectional Encoder Representations from Transformers) for identifying <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a>. We have used the approaches to build the model, to identify and categorize how much conversion context or response is needed for sarcasm detection and evaluated on the two social media forums that is twitter conversation dataset and reddit conversion dataset. We compare the performance based on the approaches and obtained the best F1 scores as 0.722, 0.679 for the <a href=https://en.wikipedia.org/wiki/Twitter>twitter forums</a> and <a href=https://en.wikipedia.org/wiki/Reddit>reddit forums</a> respectively.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.11.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--11 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.11 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929701 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.11/>Neural Sarcasm Detection using Conversation Context</a></strong><br><a href=/people/n/nikhil-jaiswal/>Nikhil Jaiswal</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--11><div class="card-body p-3 small">Social media platforms and <a href=https://en.wikipedia.org/wiki/Internet_forum>discussion forums</a> such as <a href=https://en.wikipedia.org/wiki/Reddit>Reddit</a>, <a href=https://en.wikipedia.org/wiki/Twitter>Twitter</a>, etc. are filled with <a href=https://en.wikipedia.org/wiki/Literal_and_figurative_language>figurative languages</a>. Sarcasm is one such category of <a href=https://en.wikipedia.org/wiki/Literal_and_figurative_language>figurative language</a> whose presence in a conversation makes <a href=https://en.wikipedia.org/wiki/Natural-language_understanding>language understanding</a> a challenging task. In this paper, we present a <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural architecture</a> for sarcasm detection. We investigate various pre-trained language representation models (PLRMs) like BERT, RoBERTa, etc. and fine-tune it on the Twitter dataset. We experiment with a variety of PLRMs either on the twitter utterance in isolation or utilizing the <a href=https://en.wikipedia.org/wiki/Context_(language_use)>contextual information</a> along with the utterance. Our findings indicate that by taking into consideration the previous three most recent utterances, the model is more accurately able to classify a conversation as being sarcastic or not. Our best performing <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensemble model</a> achieves an overall <a href=https://en.wikipedia.org/wiki/F-number>F1 score</a> of 0.790, which ranks us second on the leaderboard of the Sarcasm Shared Task 2020.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.14.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--14 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.14 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929704 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.14/>A Novel Hierarchical BERT Architecture for Sarcasm Detection<span class=acl-fixed-case>BERT</span> Architecture for Sarcasm Detection</a></strong><br><a href=/people/h/himani-srivastava/>Himani Srivastava</a>
|
<a href=/people/v/vaibhav-varshney/>Vaibhav Varshney</a>
|
<a href=/people/s/surabhi-kumari/>Surabhi Kumari</a>
|
<a href=/people/s/saurabh-srivastava/>Saurabh Srivastava</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--14><div class="card-body p-3 small">Online discussion platforms are often flooded with opinions from users across the world on a variety of topics. Many such posts, comments, or utterances are often sarcastic in nature, i.e., the actual intent is hidden in the sentence and is different from its literal meaning, making the detection of such utterances challenging without additional context. In this paper, we propose a novel deep learning-based approach to detect whether an utterance is sarcastic or non-sarcastic by utilizing the given contexts ina hierarchical manner. We have used <a href=https://en.wikipedia.org/wiki/Data_set>datasets</a> from two online discussion platforms-Twitter and Reddit1for our experiments. Experimental and error analysis shows that the hierarchical models can make full use of history to obtain a better representation of contexts and thus, in turn, can outperform their sequential counterparts.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.15.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--15 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.15 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.figlang-1.15/>Detecting Sarcasm in Conversation Context Using Transformer-Based Models<span class=acl-fixed-case>D</span>etecting <span class=acl-fixed-case>S</span>arcasm in <span class=acl-fixed-case>C</span>onversation <span class=acl-fixed-case>C</span>ontext <span class=acl-fixed-case>U</span>sing <span class=acl-fixed-case>T</span>ransformer-<span class=acl-fixed-case>B</span>ased <span class=acl-fixed-case>M</span>odels</a></strong><br><a href=/people/a/adithya-avvaru/>Adithya Avvaru</a>
|
<a href=/people/s/sanath-vobilisetty/>Sanath Vobilisetty</a>
|
<a href=/people/r/radhika-mamidi/>Radhika Mamidi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--15><div class="card-body p-3 small">Sarcasm detection, regarded as one of the sub-problems of <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a>, is a very typical task because the introduction of sarcastic words can flip the sentiment of the sentence itself. To date, many research works revolve around detecting <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> in one single sentence and there is very limited research to detect <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> resulting from multiple sentences. Current models used Long Short Term Memory (LSTM) variants with or without <a href=https://en.wikipedia.org/wiki/Attention>attention</a> to detect <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> in conversations. We showed that the <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> using state-of-the-art Bidirectional Encoder Representations from Transformers (BERT), to capture syntactic and semantic information across conversation sentences, performed better than the current <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a>. Based on the data analysis, we estimated that the number of sentences in the conversation that can contribute to the <a href=https://en.wikipedia.org/wiki/Sarcasm>sarcasm</a> and the results agrees to this estimation. We also perform a comparative study of our different versions of BERT-based model with other variants of LSTM model and XLNet (both using the estimated number of conversation sentences) and find out that BERT-based models outperformed them.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.16.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--16 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.16 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929723 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.16/>Using Conceptual Norms for Metaphor Detection</a></strong><br><a href=/people/m/mingyu-wan/>Mingyu Wan</a>
|
<a href=/people/k/kathleen-ahrens/>Kathleen Ahrens</a>
|
<a href=/people/e/emmanuele-chersoni/>Emmanuele Chersoni</a>
|
<a href=/people/m/menghan-jiang/>Menghan Jiang</a>
|
<a href=/people/q/qi-su/>Qi Su</a>
|
<a href=/people/r/rong-xiang/>Rong Xiang</a>
|
<a href=/people/c/chu-ren-huang/>Chu-Ren Huang</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--16><div class="card-body p-3 small">This paper reports a linguistically-enriched method of detecting token-level metaphors for the second shared task on Metaphor Detection. We participate in all four phases of competition with both <a href=https://en.wikipedia.org/wiki/Digital_data>datasets</a>, i.e. Verbs and AllPOS on the VUA and the TOFEL datasets. We use the modality exclusivity and embodiment norms for constructing a conceptual representation of the nodes and the context. Our <a href=https://en.wikipedia.org/wiki/System>system</a> obtains an <a href=https://en.wikipedia.org/wiki/International_Federation_of_the_Phonographic_Industry>F-score</a> of 0.652 for the VUA Verbs track, which is 5 % higher than the strong baselines. The experimental results across models and datasets indicate the salient contribution of using modality exclusivity and modality shift information for predicting <a href=https://en.wikipedia.org/wiki/Metaphor>metaphoricity</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.18.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--18 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.18 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929724 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.18/>Character aware models with <a href=https://en.wikipedia.org/wiki/Similarity_learning>similarity learning</a> for metaphor detection</a></strong><br><a href=/people/t/tarun-kumar/>Tarun Kumar</a>
|
<a href=/people/y/yashvardhan-sharma/>Yashvardhan Sharma</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--18><div class="card-body p-3 small">Recent work on automatic sequential metaphor detection has involved <a href=https://en.wikipedia.org/wiki/Recurrent_neural_network>recurrent neural networks</a> initialized with different pre-trained word embeddings and which are sometimes combined with hand engineered features. To capture lexical and orthographic information automatically, in this paper we propose to add character based word representation. Also, to contrast the difference between <a href=https://en.wikipedia.org/wiki/Literal_and_figurative_language>literal and contextual meaning</a>, we utilize a similarity network. We explore these components via two different architectures-a BiLSTM model and a Transformer Encoder model similar to BERT to perform metaphor identification. We participate in the Second Shared Task on Metaphor Detection on both the VUA and TOFEL datasets with the above models. The experimental results demonstrate the effectiveness of our <a href=https://en.wikipedia.org/wiki/Methodology>method</a> as it outperforms all the <a href=https://en.wikipedia.org/wiki/System>systems</a> which participated in the previous shared task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.20.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--20 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.20 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929717 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.20/>Recognizing Euphemisms and Dysphemisms Using <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>Sentiment Analysis</a></a></strong><br><a href=/people/c/christian-felt/>Christian Felt</a>
|
<a href=/people/e/ellen-riloff/>Ellen Riloff</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--20><div class="card-body p-3 small">This paper presents the first research aimed at recognizing euphemistic and dysphemistic phrases with <a href=https://en.wikipedia.org/wiki/Natural_language_processing>natural language processing</a>. Euphemisms soften references to topics that are sensitive, disagreeable, or taboo. Conversely, <a href=https://en.wikipedia.org/wiki/Dysphemism>dysphemisms</a> refer to sensitive topics in a harsh or rude way. For example, passed away and departed are <a href=https://en.wikipedia.org/wiki/Euphemism>euphemisms</a> for death, while croaked and six feet under are <a href=https://en.wikipedia.org/wiki/Dysphemism>dysphemisms</a> for death. Our work explores the use of <a href=https://en.wikipedia.org/wiki/Sentiment_analysis>sentiment analysis</a> to recognize euphemistic and dysphemistic language. First, we identify near-synonym phrases for three topics (firing, lying, and stealing) using a bootstrapping algorithm for semantic lexicon induction. Next, we classify phrases as <a href=https://en.wikipedia.org/wiki/Euphemism>euphemistic</a>, dysphemistic, or neutral using <a href=https://en.wikipedia.org/wiki/Lexical_analysis>lexical sentiment cues</a> and contextual sentiment analysis. We introduce a new gold standard data set and present our experimental results for this <a href=https://en.wikipedia.org/wiki/Task_(project_management)>task</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.23.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--23 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.23 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.figlang-1.23.Software.zip data-toggle=tooltip data-placement=top title=Software><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=https://aclanthology.org/attachments/2020.figlang-1.23.Dataset.pdf data-toggle=tooltip data-placement=top title=Dataset><i class="fas fa-file"></i>
</a><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929711 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.23/>Generating Ethnographic Models from Communities’ Online Data</a></strong><br><a href=/people/t/tomek-strzalkowski/>Tomek Strzalkowski</a>
|
<a href=/people/a/anna-newheiser/>Anna Newheiser</a>
|
<a href=/people/n/nathan-kemper/>Nathan Kemper</a>
|
<a href=/people/n/ning-sa/>Ning Sa</a>
|
<a href=/people/b/bharvee-acharya/>Bharvee Acharya</a>
|
<a href=/people/g/gregorios-katsios/>Gregorios Katsios</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--23><div class="card-body p-3 small">In this paper we describe computational ethnography study to demonstrate how machine learning techniques can be utilized to exploit bias resident in language data produced by communities with online presence. Specifically, we leverage the use of <a href=https://en.wikipedia.org/wiki/Figurative_language>figurative language</a> (i.e., the choice of metaphors) in <a href=https://en.wikipedia.org/wiki/Online_and_offline>online text</a> (e.g., <a href=https://en.wikipedia.org/wiki/News_media>news media</a>, blogs) produced by distinct communities to obtain models of community worldviews that can be shown to be distinctly biased and thus different from other communities&#8217; models. We automatically construct metaphor-based community models for two distinct scenarios : <a href=https://en.wikipedia.org/wiki/Gun_politics_in_the_United_States>gun rights</a> and <a href=https://en.wikipedia.org/wiki/Same-sex_marriage_in_the_United_States>marriage equality</a>. We then conduct a series of experiments to validate the hypothesis that the <a href=https://en.wikipedia.org/wiki/Metaphor>metaphors</a> found in each community&#8217;s online language convey the bias in the community&#8217;s worldview.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.28.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--28 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.28 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/2020.figlang-1.28/>Augmenting Neural Metaphor Detection with Concreteness</a></strong><br><a href=/people/g/ghadi-alnafesah/>Ghadi Alnafesah</a>
|
<a href=/people/h/harish-tayyar-madabushi/>Harish Tayyar Madabushi</a>
|
<a href=/people/m/mark-lee/>Mark Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--28><div class="card-body p-3 small">The idea that a shift in <a href=https://en.wikipedia.org/wiki/Concreteness>concreteness</a> within a sentence indicates the presence of a <a href=https://en.wikipedia.org/wiki/Metaphor>metaphor</a> has been around for a while. However, recent methods of detecting metaphor that have relied on <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural models</a> have ignored <a href=https://en.wikipedia.org/wiki/Concreteness>concreteness</a> and related psycholinguistic information. We hypothesis that this <a href=https://en.wikipedia.org/wiki/Information>information</a> is not available to these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> and that their addition will boost the performance of these <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> in detecting <a href=https://en.wikipedia.org/wiki/Metaphor>metaphor</a>. We test this hypothesis on the Metaphor Detection Shared Task 2020 and find that the addition of concreteness information does in fact boost <a href=https://en.wikipedia.org/wiki/Deep_learning>deep neural models</a>. We also run tests on data from a previous <a href=https://en.wikipedia.org/wiki/Task_(computing)>shared task</a> and show similar results.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.33.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--33 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.33 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929728 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.33/>Metaphor Detection using Ensembles of Bidirectional Recurrent Neural Networks</a></strong><br><a href=/people/j/jennifer-brooks/>Jennifer Brooks</a>
|
<a href=/people/a/abdou-youssef/>Abdou Youssef</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--33><div class="card-body p-3 small">In this paper we present our results from the Second Shared Task on Metaphor Detection, hosted by the Second Workshop on Figurative Language Processing. We use an ensemble of RNN models with bidirectional LSTMs and bidirectional attention mechanisms. Some of the <a href=https://en.wikipedia.org/wiki/Conceptual_model>models</a> were trained on all parts of speech. Each of the other models was trained on one of four categories for <a href=https://en.wikipedia.org/wiki/Part_of_speech>parts of speech</a> : <a href=https://en.wikipedia.org/wiki/Noun>nouns</a>, <a href=https://en.wikipedia.org/wiki/Verb>verbs</a>, <a href=https://en.wikipedia.org/wiki/Adjective>adverbs / adjectives</a>, or other. The <a href=https://en.wikipedia.org/wiki/Mathematical_model>models</a> were combined into voting pools and the voting pools were combined using the logical OR operator.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/2020.figlang-1.35.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-2020--figlang-1--35 data-toggle=collapse aria-expanded=false aria-controls=abstract-2020.figlang-1.35 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"><a class="badge badge-attachment align-middle mr-1" href=http://slideslive.com/38929730 data-toggle=tooltip data-placement=top title=Video><i class="fas fa-video"></i></a></span>
<span class=d-block><strong><a class=align-middle href=/2020.figlang-1.35/>Testing the role of <a href=https://en.wikipedia.org/wiki/Metadata>metadata</a> in metaphor identification</a></strong><br><a href=/people/e/egon-stemle/>Egon Stemle</a>
|
<a href=/people/a/alexander-onysko/>Alexander Onysko</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-2020--figlang-1--35><div class="card-body p-3 small">This paper describes the adaptation and application of a <a href=https://en.wikipedia.org/wiki/Neural_network>neural network system</a> for the automatic detection of metaphors. The LSTM BiRNN system participated in the shared task of metaphor identification that was part of the Second Workshop of Figurative Language Processing (FigLang2020) held at the Annual Conference of the Association for Computational Linguistics (ACL2020). The particular focus of our approach is on the potential influence that the <a href=https://en.wikipedia.org/wiki/Metadata>metadata</a> given in the ETS Corpus of Non-Native Written English might have on the automatic detection of metaphors in this <a href=https://en.wikipedia.org/wiki/Data_set>dataset</a>. The article first discusses the annotated ETS learner data, highlighting some of its peculiarities and inherent biases of metaphor use. A series of evaluations follow in order to test whether specific <a href=https://en.wikipedia.org/wiki/Metadata>metadata</a> influence the <a href=https://en.wikipedia.org/wiki/System>system</a> performance in the task of automatic metaphor identification. The <a href=https://en.wikipedia.org/wiki/System>system</a> is available under the APLv2 open-source license.</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>