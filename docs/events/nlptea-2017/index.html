<!doctype html><html lang=en-us><head><meta charset=utf-8><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><!--[if IEMobile]><meta http-equiv=cleartype content="on"><![endif]--><title>Workshop on Natural Language Processing Techniques for Educational Applications (2017) - ACL Anthology</title><meta name=generator content="Hugo 0.98.0"><link href=/aclicon.ico rel="shortcut icon" type=image/x-icon><link rel=stylesheet href=/css/main.min.b1d14a9a8f6bb9c608ca4de9aad72a6e06945119f97951f2908522dc220e6277.css media=screen><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.7.2/css/all.css integrity=sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr crossorigin=anonymous><link rel=stylesheet href=/css/academicons.min.css></head><body><nav class="navbar navbar-expand-sm navbar-dark bg-dark bg-gradient-dark shadow-sm py-0 mb-3 mb-md-4 mb-xl-5"><div id=navbar-container class=container><a class=navbar-brand href=/><img src=/images/acl-logo.svg width=56 alt="ACL Logo">
<span class="d-none d-md-inline pl-md-2">ACL 2022 D&I Special Initiative</span></a>
<button class=navbar-toggler type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse" id=navbarSupportedContent><ul class="navbar-nav mr-auto"><li class=nav-item><a class=nav-link href=/>Papers<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/terms/>Terminology<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/>Videos<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/corrections/>Corrections<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/info/credits/>Credits<span class=sr-only>(current)</span></a></li><li class=nav-item><a class=nav-link href=/faq/>FAQ<span class=sr-only>(current)</span></a></li></ul><form class="form-inline my-2 my-lg-0" action=/search/? method=get><input id=acl-search-box class="form-control mr-sm-2" name=q type=search placeholder=Search... aria-label=Search>
<button class="btn btn-outline-secondary" type=submit><i class="fas fa-search"></i></button></form></div></div></nav><div id=main-container class=container><section id=main><h2 id=title>Workshop on Natural Language Processing Techniques for Educational Applications (2017)</h2><hr><div class="card bg-light mb-2 mb-lg-4"><div class=card-body><h4 class=card-title>Contents</h4><ul class=list-pl-responsive><li><a class=align-middle href=#w17-59>Proceedings of the 4th Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA 2017)</a>
<span class="badge badge-info align-middle ml-1">10&nbsp;papers</span></li></ul></div></div><div id=w17-59><small><a href=# class=text-muted><i class="fas fa-arrow-up"></i> up</a></small><h4 class="d-sm-flex pb-2 border-bottom"><span class="d-block mr-2 list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-59.pdf data-toggle=tooltip data-placement=top title="Open full proceedings volume as PDF">pdf&nbsp;(full)</a><br class="d-none d-sm-inline-block"></span><a class=align-middle href=/volumes/W17-59/>Proceedings of the 4th Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA 2017)</a></h4><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5900.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5900/>Proceedings of the 4th Workshop on Natural Language Processing Techniques for Educational Applications (<span class=acl-fixed-case>NLPTEA</span> 2017)</a></strong><br><a href=/people/y/yuen-hsien-tseng/>Yuen-Hsien Tseng</a>
|
<a href=/people/h/hsin-hsi-chen/>Hsin-Hsi Chen</a>
|
<a href=/people/l/lung-hao-lee/>Lung-Hao Lee</a>
|
<a href=/people/l/liang-chih-yu/>Liang-Chih Yu</a></span></p><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5902.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5902 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5902 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5902/>Understanding Non-Native Writings : Can a <a href=https://en.wikipedia.org/wiki/Parsis>Parser</a> Help?</a></strong><br><a href=/people/j/jirka-hana/>Jirka Hana</a>
|
<a href=/people/b/barbora-hladka/>Barbora Hladk√°</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5902><div class="card-body p-3 small">We present a pilot study on parsing non-native texts written by learners of <a href=https://en.wikipedia.org/wiki/Czech_language>Czech</a>. We performed experiments that have shown that at least high-level syntactic functions, like subject, predicate, and object, can be assigned based on a <a href=https://en.wikipedia.org/wiki/Parsing>parser</a> trained on standard <a href=https://en.wikipedia.org/wiki/First_language>native language</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5903.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5903 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5903 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5903/>Carrier Sentence Selection for Fill-in-the-blank Items<span class=acl-fixed-case>C</span>arrier Sentence Selection for Fill-in-the-blank Items</a></strong><br><a href=/people/s/shu-jiang/>Shu Jiang</a>
|
<a href=/people/j/john-s-y-lee/>John Lee</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5903><div class="card-body p-3 small">Fill-in-the-blank items are a common form of exercise in computer-assisted language learning systems. To automatically generate an effective item, the system must be able to select a high-quality carrier sentence that illustrates the usage of the target word. Previous approaches for carrier sentence selection have considered <a href=https://en.wikipedia.org/wiki/Sentence_(linguistics)>sentence length</a>, vocabulary difficulty, the position of the target word and the presence of <a href=https://en.wikipedia.org/wiki/Finite_verb>finite verbs</a>. This paper investigates the utility of word co-occurrence statistics and <a href=https://en.wikipedia.org/wiki/Lexical_similarity>lexical similarity</a> as selection criteria. In an evaluation on generating fill-in-the-blank items for learning <a href=https://en.wikipedia.org/wiki/Chinese_language>Chinese</a> as a foreign language, we show that these two criteria can improve carrier sentence quality.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5906.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5906 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5906 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5906/>Chinese Spelling Check based on N-gram and String Matching Algorithm<span class=acl-fixed-case>C</span>hinese Spelling Check based on N-gram and String Matching Algorithm</a></strong><br><a href=/people/j/jui-feng-yeh/>Jui-Feng Yeh</a>
|
<a href=/people/l/li-ting-chang/>Li-Ting Chang</a>
|
<a href=/people/c/chan-yi-liu/>Chan-Yi Liu</a>
|
<a href=/people/t/tsung-wei-hsu/>Tsung-Wei Hsu</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5906><div class="card-body p-3 small">This paper presents a Chinese spelling check approach based on <a href=https://en.wikipedia.org/wiki/Language_model>language models</a> combined with string match algorithm to treat the problems resulted from the influence caused by Cantonese mother tone. N-grams first used to detecting the probability of sentence constructed by the writers, a string matching algorithm called Knuth-Morris-Pratt (KMP) Algorithm is used to detect and correct the error. According to the experimental results, the proposed approach can detect the error and provide the corresponding correction.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5907.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5907 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5907 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5907/>N-gram Model for Chinese Grammatical Error Diagnosis<span class=acl-fixed-case>C</span>hinese Grammatical Error Diagnosis</a></strong><br><a href=/people/j/jianbo-zhao/>Jianbo Zhao</a>
|
<a href=/people/h/hao-liu/>Hao Liu</a>
|
<a href=/people/z/zuyi-bao/>Zuyi Bao</a>
|
<a href=/people/x/xiaopeng-bai/>Xiaopeng Bai</a>
|
<a href=/people/s/si-li/>Si Li</a>
|
<a href=/people/z/zhiqing-lin/>Zhiqing Lin</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5907><div class="card-body p-3 small">Detection and correction of Chinese grammatical errors have been two of major challenges for Chinese automatic grammatical error diagnosis. This paper presents an <a href=https://en.wikipedia.org/wiki/N-gram_model>N-gram model</a> for automatic detection and correction of Chinese grammatical errors in NLPTEA 2017 task. The experiment results show that the proposed <a href=https://en.wikipedia.org/wiki/Methodology>method</a> is good at correction of <a href=https://en.wikipedia.org/wiki/Chinese_grammar>Chinese grammatical errors</a>.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5908.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5908 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5908 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5908/>The Influence of Spelling Errors on Content Scoring Performance</a></strong><br><a href=/people/a/andrea-horbach/>Andrea Horbach</a>
|
<a href=/people/y/yuning-ding/>Yuning Ding</a>
|
<a href=/people/t/torsten-zesch/>Torsten Zesch</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5908><div class="card-body p-3 small">Spelling errors occur frequently in educational settings, but their influence on <a href=https://en.wikipedia.org/wiki/Score_(game)>automatic scoring</a> is largely unknown. We therefore investigate the influence of spelling errors on content scoring performance using the example of the ASAP corpus. We conduct an annotation study on the nature of spelling errors in the ASAP dataset and utilize these finding in machine learning experiments that measure the influence of spelling errors on automatic content scoring. Our main finding is that scoring methods using both token and character n-gram features are robust against spelling errors up to the error frequency in ASAP.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5909.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5909 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5909 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5909/>Analyzing the Impact of Spelling Errors on POS-Tagging and Chunking in Learner English<span class=acl-fixed-case>POS</span>-Tagging and Chunking in Learner <span class=acl-fixed-case>E</span>nglish</a></strong><br><a href=/people/t/tomoya-mizumoto/>Tomoya Mizumoto</a>
|
<a href=/people/r/ryo-nagata/>Ryo Nagata</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5909><div class="card-body p-3 small">Part-of-speech (POS) tagging and chunking have been used in tasks targeting learner English ; however, to the best our knowledge, few studies have evaluated their performance and no studies have revealed the causes of POS-tagging / chunking errors in detail. Therefore, we investigate performance and analyze the causes of failure. We focus on spelling errors that occur frequently in learner English. We demonstrate that spelling errors reduced POS-tagging performance by 0.23 % owing to spelling errors, and that a <a href=https://en.wikipedia.org/wiki/Spell_checker>spell checker</a> is not necessary for POS-tagging / chunking of learner English.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5910.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5910 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5910 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5910/>Complex Word Identification : Challenges in Data Annotation and System Performance</a></strong><br><a href=/people/m/marcos-zampieri/>Marcos Zampieri</a>
|
<a href=/people/s/shervin-malmasi/>Shervin Malmasi</a>
|
<a href=/people/g/gustavo-paetzold/>Gustavo Paetzold</a>
|
<a href=/people/l/lucia-specia/>Lucia Specia</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5910><div class="card-body p-3 small">This paper revisits the problem of complex word identification (CWI) following up the SemEval CWI shared task. We use <a href=https://en.wikipedia.org/wiki/Ensemble_learning>ensemble classifiers</a> to investigate how well <a href=https://en.wikipedia.org/wiki/Computational_complexity_theory>computational methods</a> can discriminate between complex and non-complex words. Furthermore, we analyze the <a href=https://en.wikipedia.org/wiki/Statistical_classification>classification</a> performance to understand what makes lexical complexity challenging. Our findings show that most systems performed poorly on the SemEval CWI dataset, and one of the reasons for that is the way in which human annotation was performed.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5911.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5911 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5911 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5911/>Suggesting Sentences for <a href=https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language>ESL</a> using Kernel Embeddings<span class=acl-fixed-case>ESL</span> using Kernel Embeddings</a></strong><br><a href=/people/k/kent-shioda/>Kent Shioda</a>
|
<a href=/people/m/mamoru-komachi/>Mamoru Komachi</a>
|
<a href=/people/r/rue-ikeya/>Rue Ikeya</a>
|
<a href=/people/d/daichi-mochihashi/>Daichi Mochihashi</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5911><div class="card-body p-3 small">Sentence retrieval is an important NLP application for <a href=https://en.wikipedia.org/wiki/English_language>English</a> as a Second Language (ESL) learners. ESL learners are familiar with <a href=https://en.wikipedia.org/wiki/Web_search_engine>web search engines</a>, but generic web search results may not be adequate for composing documents in a specific domain. However, if we build our own <a href=https://en.wikipedia.org/wiki/Web_search_engine>search system</a> specialized to a domain, it may be subject to the data sparseness problem. Recently proposed <a href=https://en.wikipedia.org/wiki/Word2vec>word2vec</a> partially addresses the data sparseness problem, but fails to extract sentences relevant to queries owing to the modeling of the latent intent of the query. Thus, we propose a method of retrieving example sentences using kernel embeddings and N-gram windows. This method implicitly models latent intent of query and sentences, and alleviates the problem of noisy alignment. Our results show that our method achieved higher precision in sentence retrieval for <a href=https://en.wikipedia.org/wiki/English_as_a_second_or_foreign_language>ESL</a> in the domain of a university press release corpus, as compared to a previous unsupervised method used for a semantic textual similarity task.</div></div><p class="d-sm-flex align-items-stretch"><span class="d-block mr-2 text-nowrap list-button-row"><a class="badge badge-primary align-middle mr-1" href=https://aclanthology.org/W17-5912.pdf data-toggle=tooltip data-placement=top title="Open PDF">pdf
</a><a class="badge badge-info align-middle mr-1" href=#abstract-W17-5912 data-toggle=collapse aria-expanded=false aria-controls=abstract-W17-5912 title="Show Abstract">abs</a><br class="d-none d-sm-inline-block"></span><span class=d-block><strong><a class=align-middle href=/W17-5912/>Event Timeline Generation from History Textbooks</a></strong><br><a href=/people/h/harsimran-bedi/>Harsimran Bedi</a>
|
<a href=/people/s/sangameshwar-patil/>Sangameshwar Patil</a>
|
<a href=/people/s/swapnil-hingmire/>Swapnil Hingmire</a>
|
<a href=/people/g/girish-palshikar/>Girish Palshikar</a></span></p><div class="card bg-light mb-2 mb-lg-3 collapse abstract-collapse" id=abstract-W17-5912><div class="card-body p-3 small">Event timeline serves as the basic structure of history, and it is used as a disposition of key phenomena in studying history as a subject in secondary school. In order to enable a student to understand a historical phenomenon as a series of connected events, we present a system for automatic event timeline generation from <a href=https://en.wikipedia.org/wiki/Textbook>history textbooks</a>. Additionally, we propose Message Sequence Chart (MSC) and time-map based visualization techniques to visualize an event timeline. We also identify key computational challenges in developing <a href=https://en.wikipedia.org/wiki/Natural-language_user_interface>natural language processing based applications</a> for <a href=https://en.wikipedia.org/wiki/Textbook>history textbooks</a>.</div></div></div><hr></section></div><footer class="bg-gradient-dark py-2 py-xl-3 mt-3 mt-md-4 mt-xl-5" style=color:#fff><div class=container><p class="small px-1"><span class="float-right mt-2 ml-2"><a rel=license href=http://creativecommons.org/licenses/by/4.0/><img alt="Creative Commons License" style=border-width:0 src=https://i.creativecommons.org/l/by/4.0/88x31.png></a></span>
ACL materials are Copyright ¬©&nbsp;1963&ndash;2022 ACL; other materials are copyrighted by their respective copyright holders. Materials prior to 2016 here are licensed under the <a href=https://creativecommons.org/licenses/by-nc-sa/3.0/>Creative Commons Attribution-NonCommercial-ShareAlike 3.0 International License</a>. Permission is granted to make copies for the purposes of teaching and research. Materials published in or after 2016 are licensed on a <a href=https://creativecommons.org/licenses/by/4.0/>Creative Commons Attribution 4.0 International License</a>.</p><p class="small px-1">The ACL Anthology is managed and built by the <a href=/info/credits/>ACL Anthology team</a> of volunteers.</p><p class="small px-1"><i>Site last built on 23 May 2022 at 01:26 UTC with <a href=https://github.com/acl-org/acl-anthology/tree/6b5537cdc480294721047e4e67eca5cb2bec4ab4>commit 6b5537cd</a>.</i></p></div></footer><script src=https://code.jquery.com/jquery-3.3.1.slim.min.js integrity=sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.6/umd/popper.min.js integrity=sha384-wHAiFfRlMFy6i5SRaxvfOCifBUQy1xHdJ/yoi7FRNXMRBu5WHdZYu1hA6ZOblgut crossorigin=anonymous></script>
<script src=https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js integrity=sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k crossorigin=anonymous></script>
<script>$(function(){$('[data-toggle="tooltip"]').tooltip(),$("#toggle-all-abstracts")&&($("#toggle-all-abstracts").click(function(){var e=$("#toggle-all-abstracts");e.attr("disabled",!0),e.attr("data-toggle-state")=="hide"?($(".abstract-collapse").collapse("show"),e.attr("data-toggle-state","show")):($(".abstract-collapse").collapse("hide"),e.attr("data-toggle-state","hide")),e.attr("disabled",!1)}),$("#toggle-all-abstracts").attr("disabled",!1))})</script></body></html>